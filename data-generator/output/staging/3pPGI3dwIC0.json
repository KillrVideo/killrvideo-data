{
  "video_id": "3pPGI3dwIC0",
  "title": "DS210.08 Other nodetool Functionality | Operations with Apache Cassandra",
  "description": "#DataStaxAcademy #DS210\nDS210.08 OTHER nodetool FUNCTIONALITY\nIn this unit, we learn about some of the functionality in nodetool that is not only useful for diagnostics, but also provide us with general information.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-11T11:43:03Z",
  "thumbnail": "https://i.ytimg.com/vi/3pPGI3dwIC0/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax",
    "tutorial",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=3pPGI3dwIC0",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] so let's talk about some of the other functionality in nodetool that could be useful not only in diagnosis if there's a problem but just general information the first that we're going to look at is gc stats not something you use all the time but it is helpful if you think that you're having some garbage collection issues and this is java garbage collection gc stats gives you some really in-depth information about what's happening in gc land gc can be very detrimental to your node if it starts doing things like full gcs this is how you're going to find out what's happening if you're having full gcs you'll know it but this is how you can actually measure it it gives you that length of time understanding of how much heat memory is being flushed all of that very important information in a running java process the output is very interesting it's very basic but it has some really important information like how long it's taken for the gc to elapse the standard deviation of that gc elapse like how long it usually takes for it to run the higher these numbers the worse off you are java garbage collection is a problem that you need to keep track of if it's a big problem it will ruin your node and so these are the numbers that you need to be keeping an eye on if these numbers are staying low you're all good but again this is whenever you have a bad situation you're trying to figure out what's going on if the node just randomly stops this is a good place to look the next one is gossip info gossip is a concept in cassandra of course which is about node information being transmitted around the cluster it's meant to transmit information about the cluster state to other nodes in the system basically keeping each other informed this command is showing you if that's actually happening so there's state information which level or generation is being told everyone else if it's falling behind that sort of thing this information can be helpful if you're looking for a potentially bad situation such as a split brain you'll start seeing that maybe the gossip information isn't quite right the output can be pretty long if you look at the output you're seeing a lot of complicated information however some of it really is important that you need to focus in on for instance the status is everything good is it normal yes the other thing is the schema if you ever have a schema mismatch you need to match this number up with other schema a schema mismatch is one of those common problems that you're not really sure if it's happening until you look and when you do have that problem it can be pretty detrimental so this is one of the ways you can measure it this is what it's telling everyone hey here's my schema number also it's node information about its topology the topology information for instance what dc and rack what is it telling the rest of the cluster and when it tells it that is it in cahoots with the rest of the cluster or is it kind of off in left field you don't want any of that to be in a weird place so this is where you're going to find out what that node is telling everyone and then finally there's some things below gives load information that sort of thing really important because that's what makes sure that the other nodes are aware of that node's information as well so whenever you're doing coordinators trying to figure out which nodes are healthy or not that information gets sent out you want to know what's happening there too then there's the good old no tool ring no tool ring is one of those commands that used to be typed all the time it's fallen out of favor with a lot of cassandra people because let's face it no tool status is a better command to use but no tool ring gives you really in-depth information about token range assignments and that can be helpful if you're looking for an imbalance in your ring or if you're looking for hot spots say for instance if you see one node that's getting hit with a lot of data this will give you some indication so the output is very verbose especially whenever you're using virtual nodes you'll see every single token range in the system it also shows you what the data center is so the overall topology if there's a rack situation going on and all the other nodes in the system so you can see in the cluster the status up on all other nodes all three nodes online how much it runs etc those statistics are all based on token ranges so if you have a large amount of virtual nodes on one node this list is going to get really long quickly just keep that in mind another really interesting and probably useful command whenever you're trying to do more data modeling checks is table info and the reason i say it's for data modeling this is how you can double check some things like did i get the partition key right am i overloading one node a little bit too much how's my row count looking so when you use a table info you're getting a lot of statistics on a particular table on that node so in this example the output is for an entire key space killer video and it shows you how many tables are in it now this can be a very long output if you have a lot of tables in one key space this is going to go on and on and on but know that they're pretty much the same thing over and over again so for instance what key space it's in how many times it's been read important numbers like latency numbers read and write these are point-in-time statistics and you'll get these off of each table on the running node this is not total cluster statistics table histograms gives you more of a long view of how that node has been treating that particular table so for instance this is how you could figure out if there's a lot of data in that one table that is not acting properly say for instance if you have a really large row that's consuming a lot of extra resources that you didn't know about so the output is based on buckets and it's percentiles the 50th percentile all the way up to the 99th percentile including the minimum and the maximum of those numbers when you read this example you can see that we're looking at right latency and read latency that means that 99 of the writes this is a p99 were 88 microseconds that's what you can see but the read latency is really up there 464 milliseconds so that's a long time for a 99th percentile something to look at it also gives you the partition size and bytes and the cell count meaning how many actual cells were being used in this case it's two which is really tiny but the cells translate to rows which gives you that larger partition if we had millions and millions in that cell count we could say aha we have a really large partition we need to manage that may be a problem so this gives you some bit of a overall long view of what your tables are doing the last command i'm going to talk about is tp stats now this used to be my go-to move all the time tp stats is thread pool statistics and in the early days of cassandra thread pools are really important with the ceta architecture since cassandra's moved a lot away from ceta this isn't quite as important but it still gives you some really useful information thread pools are pretty much what's running inside of the cassandra node itself and you can see some really interesting statistics in there that give you a clue of what's actually happening especially with performance remember things that are blocking or causing more trouble because they're being used more than any other process are things to investigate so the states of those nodes are really important active pended completed blocked those are all the four states that you can see running inside of the node now of course you never want to see blocked and that's probably the number we want to focus on if i see something that's been blocked ever i want to know why so this example output gives you all of the different thread pools that are active so for instance we have the mem table flush writer one of those things that are really important so whenever you fill up a mem table and it's flush to disk that becomes active and it will write out to the disk if the mem table flush rider is ever blocked that's bad that means that your jvm is unable to flush that memory out and it's gonna sit there we all know that memory in the java virtual machine is a premium and if you have large blocks of memory just sitting there not getting flushed out that can turn into a really bad problem that's when you start seeing gc the number of blocked on any of these could be translated back to something really simple which could be something like a disk which isn't allowing any writes so you can start seeing those block counts go up on mem table flush writers for instance so again these are clues but really big clues because this is saying hey as a running node i'm unhappy and here's what's happening and you can use that to go diagnose other problems i used to use this quite often i could look at those numbers and tell you if you had a gc problem or if you had a memory problem or if you had a disc problem pretty quickly because those numbers would always pop to the top this is a good command to get to know so this is a really good overview i think of those commands that you don't use all the time but in cases where you really need to understand what's happening in the running node itself these will help you",
    "segments": [
      {
        "start": 1.43,
        "duration": 5.33,
        "text": "[Music]"
      },
      {
        "start": 7.12,
        "duration": 3.439,
        "text": "so let's talk about some of the other"
      },
      {
        "start": 8.8,
        "duration": 3.919,
        "text": "functionality in nodetool"
      },
      {
        "start": 10.559,
        "duration": 4.08,
        "text": "that could be useful not only in"
      },
      {
        "start": 12.719,
        "duration": 4.241,
        "text": "diagnosis if there's a problem"
      },
      {
        "start": 14.639,
        "duration": 4.8,
        "text": "but just general information the first"
      },
      {
        "start": 16.96,
        "duration": 4.88,
        "text": "that we're going to look at is gc stats"
      },
      {
        "start": 19.439,
        "duration": 4.08,
        "text": "not something you use all the time but"
      },
      {
        "start": 21.84,
        "duration": 3.359,
        "text": "it is helpful if you think that you're"
      },
      {
        "start": 23.519,
        "duration": 2.241,
        "text": "having some garbage collection issues"
      },
      {
        "start": 25.199,
        "duration": 3.281,
        "text": "and this is"
      },
      {
        "start": 25.76,
        "duration": 4.4,
        "text": "java garbage collection gc stats gives"
      },
      {
        "start": 28.48,
        "duration": 4.88,
        "text": "you some really in-depth information"
      },
      {
        "start": 30.16,
        "duration": 5.6,
        "text": "about what's happening in gc land"
      },
      {
        "start": 33.36,
        "duration": 5.039,
        "text": "gc can be very detrimental to your node"
      },
      {
        "start": 35.76,
        "duration": 3.84,
        "text": "if it starts doing things like full gcs"
      },
      {
        "start": 38.399,
        "duration": 3.281,
        "text": "this is how you're going to find out"
      },
      {
        "start": 39.6,
        "duration": 3.52,
        "text": "what's happening if you're having full"
      },
      {
        "start": 41.68,
        "duration": 3.28,
        "text": "gcs you'll know it"
      },
      {
        "start": 43.12,
        "duration": 4.08,
        "text": "but this is how you can actually measure"
      },
      {
        "start": 44.96,
        "duration": 4.4,
        "text": "it it gives you that length of time"
      },
      {
        "start": 47.2,
        "duration": 3.359,
        "text": "understanding of how much heat memory is"
      },
      {
        "start": 49.36,
        "duration": 2.96,
        "text": "being flushed"
      },
      {
        "start": 50.559,
        "duration": 4.0,
        "text": "all of that very important information"
      },
      {
        "start": 52.32,
        "duration": 4.8,
        "text": "in a running java process"
      },
      {
        "start": 54.559,
        "duration": 4.241,
        "text": "the output is very interesting it's very"
      },
      {
        "start": 57.12,
        "duration": 2.32,
        "text": "basic but it has some really important"
      },
      {
        "start": 58.8,
        "duration": 3.12,
        "text": "information"
      },
      {
        "start": 59.44,
        "duration": 3.36,
        "text": "like how long it's taken for the gc to"
      },
      {
        "start": 61.92,
        "duration": 3.279,
        "text": "elapse"
      },
      {
        "start": 62.8,
        "duration": 3.999,
        "text": "the standard deviation of that gc elapse"
      },
      {
        "start": 65.199,
        "duration": 2.161,
        "text": "like how long it usually takes for it to"
      },
      {
        "start": 66.799,
        "duration": 2.481,
        "text": "run"
      },
      {
        "start": 67.36,
        "duration": 3.36,
        "text": "the higher these numbers the worse off"
      },
      {
        "start": 69.28,
        "duration": 3.28,
        "text": "you are java"
      },
      {
        "start": 70.72,
        "duration": 3.28,
        "text": "garbage collection is a problem that you"
      },
      {
        "start": 72.56,
        "duration": 3.68,
        "text": "need to keep track of"
      },
      {
        "start": 74.0,
        "duration": 3.759,
        "text": "if it's a big problem it will ruin your"
      },
      {
        "start": 76.24,
        "duration": 3.36,
        "text": "node and so these are the numbers that"
      },
      {
        "start": 77.759,
        "duration": 4.081,
        "text": "you need to be keeping an eye on"
      },
      {
        "start": 79.6,
        "duration": 3.199,
        "text": "if these numbers are staying low you're"
      },
      {
        "start": 81.84,
        "duration": 2.72,
        "text": "all good"
      },
      {
        "start": 82.799,
        "duration": 3.121,
        "text": "but again this is whenever you have a"
      },
      {
        "start": 84.56,
        "duration": 2.96,
        "text": "bad situation you're trying to figure"
      },
      {
        "start": 85.92,
        "duration": 3.36,
        "text": "out what's going on if the node just"
      },
      {
        "start": 87.52,
        "duration": 2.16,
        "text": "randomly stops this is a good place to"
      },
      {
        "start": 89.28,
        "duration": 3.28,
        "text": "look"
      },
      {
        "start": 89.68,
        "duration": 4.88,
        "text": "the next one is gossip info gossip is a"
      },
      {
        "start": 92.56,
        "duration": 4.559,
        "text": "concept in cassandra of course"
      },
      {
        "start": 94.56,
        "duration": 3.919,
        "text": "which is about node information being"
      },
      {
        "start": 97.119,
        "duration": 3.841,
        "text": "transmitted around the cluster"
      },
      {
        "start": 98.479,
        "duration": 3.6,
        "text": "it's meant to transmit information about"
      },
      {
        "start": 100.96,
        "duration": 3.119,
        "text": "the cluster state"
      },
      {
        "start": 102.079,
        "duration": 3.521,
        "text": "to other nodes in the system basically"
      },
      {
        "start": 104.079,
        "duration": 3.441,
        "text": "keeping each other informed"
      },
      {
        "start": 105.6,
        "duration": 3.28,
        "text": "this command is showing you if that's"
      },
      {
        "start": 107.52,
        "duration": 3.919,
        "text": "actually happening"
      },
      {
        "start": 108.88,
        "duration": 4.559,
        "text": "so there's state information which level"
      },
      {
        "start": 111.439,
        "duration": 2.561,
        "text": "or generation is being told everyone"
      },
      {
        "start": 113.439,
        "duration": 2.561,
        "text": "else"
      },
      {
        "start": 114.0,
        "duration": 4.0,
        "text": "if it's falling behind that sort of"
      },
      {
        "start": 116.0,
        "duration": 3.68,
        "text": "thing this information can be helpful"
      },
      {
        "start": 118.0,
        "duration": 3.52,
        "text": "if you're looking for a potentially bad"
      },
      {
        "start": 119.68,
        "duration": 2.96,
        "text": "situation such as a split brain"
      },
      {
        "start": 121.52,
        "duration": 3.12,
        "text": "you'll start seeing that maybe the"
      },
      {
        "start": 122.64,
        "duration": 4.079,
        "text": "gossip information isn't quite right"
      },
      {
        "start": 124.64,
        "duration": 3.28,
        "text": "the output can be pretty long if you"
      },
      {
        "start": 126.719,
        "duration": 2.721,
        "text": "look at the output you're seeing a lot"
      },
      {
        "start": 127.92,
        "duration": 3.92,
        "text": "of complicated information"
      },
      {
        "start": 129.44,
        "duration": 4.159,
        "text": "however some of it really is important"
      },
      {
        "start": 131.84,
        "duration": 4.32,
        "text": "that you need to focus in on"
      },
      {
        "start": 133.599,
        "duration": 3.041,
        "text": "for instance the status is everything"
      },
      {
        "start": 136.16,
        "duration": 3.36,
        "text": "good"
      },
      {
        "start": 136.64,
        "duration": 4.08,
        "text": "is it normal yes the other thing is the"
      },
      {
        "start": 139.52,
        "duration": 3.2,
        "text": "schema"
      },
      {
        "start": 140.72,
        "duration": 3.84,
        "text": "if you ever have a schema mismatch you"
      },
      {
        "start": 142.72,
        "duration": 2.72,
        "text": "need to match this number up with other"
      },
      {
        "start": 144.56,
        "duration": 2.96,
        "text": "schema"
      },
      {
        "start": 145.44,
        "duration": 4.159,
        "text": "a schema mismatch is one of those common"
      },
      {
        "start": 147.52,
        "duration": 3.999,
        "text": "problems that you're not really sure"
      },
      {
        "start": 149.599,
        "duration": 3.36,
        "text": "if it's happening until you look and"
      },
      {
        "start": 151.519,
        "duration": 2.481,
        "text": "when you do have that problem it can be"
      },
      {
        "start": 152.959,
        "duration": 2.401,
        "text": "pretty detrimental"
      },
      {
        "start": 154.0,
        "duration": 3.28,
        "text": "so this is one of the ways you can"
      },
      {
        "start": 155.36,
        "duration": 4.08,
        "text": "measure it this is what it's telling"
      },
      {
        "start": 157.28,
        "duration": 4.64,
        "text": "everyone hey here's my schema number"
      },
      {
        "start": 159.44,
        "duration": 4.64,
        "text": "also it's node information about its"
      },
      {
        "start": 161.92,
        "duration": 4.0,
        "text": "topology the topology information for"
      },
      {
        "start": 164.08,
        "duration": 3.04,
        "text": "instance what dc and rack"
      },
      {
        "start": 165.92,
        "duration": 3.28,
        "text": "what is it telling the rest of the"
      },
      {
        "start": 167.12,
        "duration": 3.92,
        "text": "cluster and when it tells it that"
      },
      {
        "start": 169.2,
        "duration": 3.44,
        "text": "is it in cahoots with the rest of the"
      },
      {
        "start": 171.04,
        "duration": 2.16,
        "text": "cluster or is it kind of off in left"
      },
      {
        "start": 172.64,
        "duration": 2.16,
        "text": "field"
      },
      {
        "start": 173.2,
        "duration": 3.44,
        "text": "you don't want any of that to be in a"
      },
      {
        "start": 174.8,
        "duration": 3.359,
        "text": "weird place so this is where you're"
      },
      {
        "start": 176.64,
        "duration": 2.879,
        "text": "going to find out what that node is"
      },
      {
        "start": 178.159,
        "duration": 2.641,
        "text": "telling everyone"
      },
      {
        "start": 179.519,
        "duration": 3.281,
        "text": "and then finally there's some things"
      },
      {
        "start": 180.8,
        "duration": 4.32,
        "text": "below gives load information"
      },
      {
        "start": 182.8,
        "duration": 3.92,
        "text": "that sort of thing really important"
      },
      {
        "start": 185.12,
        "duration": 2.96,
        "text": "because that's what makes sure that the"
      },
      {
        "start": 186.72,
        "duration": 2.56,
        "text": "other nodes are aware of that node's"
      },
      {
        "start": 188.08,
        "duration": 3.28,
        "text": "information as well"
      },
      {
        "start": 189.28,
        "duration": 3.44,
        "text": "so whenever you're doing coordinators"
      },
      {
        "start": 191.36,
        "duration": 2.32,
        "text": "trying to figure out which nodes are"
      },
      {
        "start": 192.72,
        "duration": 2.48,
        "text": "healthy or not"
      },
      {
        "start": 193.68,
        "duration": 3.6,
        "text": "that information gets sent out you want"
      },
      {
        "start": 195.2,
        "duration": 5.039,
        "text": "to know what's happening there too"
      },
      {
        "start": 197.28,
        "duration": 3.28,
        "text": "then there's the good old no tool ring"
      },
      {
        "start": 200.239,
        "duration": 3.041,
        "text": "no"
      },
      {
        "start": 200.56,
        "duration": 4.399,
        "text": "tool ring is one of those commands that"
      },
      {
        "start": 203.28,
        "duration": 3.36,
        "text": "used to be typed all the time"
      },
      {
        "start": 204.959,
        "duration": 3.28,
        "text": "it's fallen out of favor with a lot of"
      },
      {
        "start": 206.64,
        "duration": 3.76,
        "text": "cassandra people because"
      },
      {
        "start": 208.239,
        "duration": 3.28,
        "text": "let's face it no tool status is a better"
      },
      {
        "start": 210.4,
        "duration": 2.8,
        "text": "command to use"
      },
      {
        "start": 211.519,
        "duration": 3.521,
        "text": "but no tool ring gives you really"
      },
      {
        "start": 213.2,
        "duration": 2.88,
        "text": "in-depth information about token range"
      },
      {
        "start": 215.04,
        "duration": 2.72,
        "text": "assignments"
      },
      {
        "start": 216.08,
        "duration": 3.68,
        "text": "and that can be helpful if you're"
      },
      {
        "start": 217.76,
        "duration": 4.399,
        "text": "looking for an imbalance in your ring"
      },
      {
        "start": 219.76,
        "duration": 3.039,
        "text": "or if you're looking for hot spots say"
      },
      {
        "start": 222.159,
        "duration": 2.08,
        "text": "for instance"
      },
      {
        "start": 222.799,
        "duration": 3.201,
        "text": "if you see one node that's getting hit"
      },
      {
        "start": 224.239,
        "duration": 2.64,
        "text": "with a lot of data this will give you"
      },
      {
        "start": 226.0,
        "duration": 4.159,
        "text": "some indication"
      },
      {
        "start": 226.879,
        "duration": 5.201,
        "text": "so the output is very verbose especially"
      },
      {
        "start": 230.159,
        "duration": 4.241,
        "text": "whenever you're using virtual nodes"
      },
      {
        "start": 232.08,
        "duration": 3.439,
        "text": "you'll see every single token range in"
      },
      {
        "start": 234.4,
        "duration": 2.88,
        "text": "the system"
      },
      {
        "start": 235.519,
        "duration": 3.36,
        "text": "it also shows you what the data center"
      },
      {
        "start": 237.28,
        "duration": 3.76,
        "text": "is so the overall topology"
      },
      {
        "start": 238.879,
        "duration": 3.681,
        "text": "if there's a rack situation going on and"
      },
      {
        "start": 241.04,
        "duration": 3.52,
        "text": "all the other nodes in the system"
      },
      {
        "start": 242.56,
        "duration": 3.36,
        "text": "so you can see in the cluster the status"
      },
      {
        "start": 244.56,
        "duration": 3.84,
        "text": "up on all other nodes"
      },
      {
        "start": 245.92,
        "duration": 3.84,
        "text": "all three nodes online how much it runs"
      },
      {
        "start": 248.4,
        "duration": 3.919,
        "text": "etc"
      },
      {
        "start": 249.76,
        "duration": 4.24,
        "text": "those statistics are all based on token"
      },
      {
        "start": 252.319,
        "duration": 2.56,
        "text": "ranges so if you have a large amount of"
      },
      {
        "start": 254.0,
        "duration": 2.959,
        "text": "virtual nodes"
      },
      {
        "start": 254.879,
        "duration": 3.36,
        "text": "on one node this list is going to get"
      },
      {
        "start": 256.959,
        "duration": 3.441,
        "text": "really long quickly"
      },
      {
        "start": 258.239,
        "duration": 3.201,
        "text": "just keep that in mind another really"
      },
      {
        "start": 260.4,
        "duration": 2.799,
        "text": "interesting and"
      },
      {
        "start": 261.44,
        "duration": 4.08,
        "text": "probably useful command whenever you're"
      },
      {
        "start": 263.199,
        "duration": 4.401,
        "text": "trying to do more data modeling checks"
      },
      {
        "start": 265.52,
        "duration": 3.2,
        "text": "is table info and the reason i say it's"
      },
      {
        "start": 267.6,
        "duration": 2.56,
        "text": "for data modeling"
      },
      {
        "start": 268.72,
        "duration": 3.12,
        "text": "this is how you can double check some"
      },
      {
        "start": 270.16,
        "duration": 2.08,
        "text": "things like did i get the partition key"
      },
      {
        "start": 271.84,
        "duration": 2.56,
        "text": "right"
      },
      {
        "start": 272.24,
        "duration": 4.48,
        "text": "am i overloading one node a little bit"
      },
      {
        "start": 274.4,
        "duration": 4.0,
        "text": "too much how's my row count looking"
      },
      {
        "start": 276.72,
        "duration": 3.199,
        "text": "so when you use a table info you're"
      },
      {
        "start": 278.4,
        "duration": 4.32,
        "text": "getting a lot of statistics"
      },
      {
        "start": 279.919,
        "duration": 3.521,
        "text": "on a particular table on that node so in"
      },
      {
        "start": 282.72,
        "duration": 3.44,
        "text": "this example"
      },
      {
        "start": 283.44,
        "duration": 3.68,
        "text": "the output is for an entire key space"
      },
      {
        "start": 286.16,
        "duration": 2.64,
        "text": "killer video"
      },
      {
        "start": 287.12,
        "duration": 3.92,
        "text": "and it shows you how many tables are in"
      },
      {
        "start": 288.8,
        "duration": 4.24,
        "text": "it now this can be a very long"
      },
      {
        "start": 291.04,
        "duration": 3.04,
        "text": "output if you have a lot of tables in"
      },
      {
        "start": 293.04,
        "duration": 3.12,
        "text": "one key space"
      },
      {
        "start": 294.08,
        "duration": 3.04,
        "text": "this is going to go on and on and on but"
      },
      {
        "start": 296.16,
        "duration": 2.56,
        "text": "know that they're"
      },
      {
        "start": 297.12,
        "duration": 3.28,
        "text": "pretty much the same thing over and over"
      },
      {
        "start": 298.72,
        "duration": 3.6,
        "text": "again so for instance"
      },
      {
        "start": 300.4,
        "duration": 3.28,
        "text": "what key space it's in how many times"
      },
      {
        "start": 302.32,
        "duration": 3.12,
        "text": "it's been read"
      },
      {
        "start": 303.68,
        "duration": 3.28,
        "text": "important numbers like latency numbers"
      },
      {
        "start": 305.44,
        "duration": 4.0,
        "text": "read and write these are"
      },
      {
        "start": 306.96,
        "duration": 3.44,
        "text": "point-in-time statistics and you'll get"
      },
      {
        "start": 309.44,
        "duration": 3.12,
        "text": "these off of"
      },
      {
        "start": 310.4,
        "duration": 4.799,
        "text": "each table on the running node this is"
      },
      {
        "start": 312.56,
        "duration": 5.04,
        "text": "not total cluster statistics"
      },
      {
        "start": 315.199,
        "duration": 3.28,
        "text": "table histograms gives you more of a"
      },
      {
        "start": 317.6,
        "duration": 3.12,
        "text": "long view"
      },
      {
        "start": 318.479,
        "duration": 3.681,
        "text": "of how that node has been treating that"
      },
      {
        "start": 320.72,
        "duration": 3.28,
        "text": "particular table"
      },
      {
        "start": 322.16,
        "duration": 3.44,
        "text": "so for instance this is how you could"
      },
      {
        "start": 324.0,
        "duration": 3.52,
        "text": "figure out if there's a lot of data in"
      },
      {
        "start": 325.6,
        "duration": 3.52,
        "text": "that one table that is not acting"
      },
      {
        "start": 327.52,
        "duration": 2.88,
        "text": "properly say for instance if you have a"
      },
      {
        "start": 329.12,
        "duration": 2.799,
        "text": "really large row"
      },
      {
        "start": 330.4,
        "duration": 3.519,
        "text": "that's consuming a lot of extra"
      },
      {
        "start": 331.919,
        "duration": 4.72,
        "text": "resources that you didn't know about"
      },
      {
        "start": 333.919,
        "duration": 4.081,
        "text": "so the output is based on buckets and"
      },
      {
        "start": 336.639,
        "duration": 2.961,
        "text": "it's percentiles the"
      },
      {
        "start": 338.0,
        "duration": 3.039,
        "text": "50th percentile all the way up to the"
      },
      {
        "start": 339.6,
        "duration": 3.84,
        "text": "99th percentile"
      },
      {
        "start": 341.039,
        "duration": 3.281,
        "text": "including the minimum and the maximum of"
      },
      {
        "start": 343.44,
        "duration": 2.479,
        "text": "those numbers"
      },
      {
        "start": 344.32,
        "duration": 3.04,
        "text": "when you read this example you can see"
      },
      {
        "start": 345.919,
        "duration": 2.56,
        "text": "that we're looking at right latency and"
      },
      {
        "start": 347.36,
        "duration": 4.48,
        "text": "read latency"
      },
      {
        "start": 348.479,
        "duration": 7.44,
        "text": "that means that 99 of the writes"
      },
      {
        "start": 351.84,
        "duration": 6.4,
        "text": "this is a p99 were 88 microseconds"
      },
      {
        "start": 355.919,
        "duration": 4.041,
        "text": "that's what you can see but the read"
      },
      {
        "start": 358.24,
        "duration": 5.12,
        "text": "latency is really up there"
      },
      {
        "start": 359.96,
        "duration": 5.079,
        "text": "464 milliseconds so that's a long time"
      },
      {
        "start": 363.36,
        "duration": 3.6,
        "text": "for a 99th percentile"
      },
      {
        "start": 365.039,
        "duration": 3.6,
        "text": "something to look at it also gives you"
      },
      {
        "start": 366.96,
        "duration": 3.519,
        "text": "the partition size and bytes"
      },
      {
        "start": 368.639,
        "duration": 4.081,
        "text": "and the cell count meaning how many"
      },
      {
        "start": 370.479,
        "duration": 3.84,
        "text": "actual cells were being used"
      },
      {
        "start": 372.72,
        "duration": 3.36,
        "text": "in this case it's two which is really"
      },
      {
        "start": 374.319,
        "duration": 4.0,
        "text": "tiny but the cells"
      },
      {
        "start": 376.08,
        "duration": 3.76,
        "text": "translate to rows which gives you that"
      },
      {
        "start": 378.319,
        "duration": 3.121,
        "text": "larger partition"
      },
      {
        "start": 379.84,
        "duration": 3.52,
        "text": "if we had millions and millions in that"
      },
      {
        "start": 381.44,
        "duration": 4.0,
        "text": "cell count we could say aha we have a"
      },
      {
        "start": 383.36,
        "duration": 4.48,
        "text": "really large partition we need to manage"
      },
      {
        "start": 385.44,
        "duration": 3.52,
        "text": "that may be a problem so this gives you"
      },
      {
        "start": 387.84,
        "duration": 3.52,
        "text": "some bit of a"
      },
      {
        "start": 388.96,
        "duration": 3.6,
        "text": "overall long view of what your tables"
      },
      {
        "start": 391.36,
        "duration": 2.64,
        "text": "are doing"
      },
      {
        "start": 392.56,
        "duration": 4.56,
        "text": "the last command i'm going to talk about"
      },
      {
        "start": 394.0,
        "duration": 3.68,
        "text": "is tp stats now this used to be my go-to"
      },
      {
        "start": 397.12,
        "duration": 4.0,
        "text": "move"
      },
      {
        "start": 397.68,
        "duration": 4.639,
        "text": "all the time tp stats is thread pool"
      },
      {
        "start": 401.12,
        "duration": 3.919,
        "text": "statistics"
      },
      {
        "start": 402.319,
        "duration": 4.16,
        "text": "and in the early days of cassandra"
      },
      {
        "start": 405.039,
        "duration": 3.521,
        "text": "thread pools are really important with"
      },
      {
        "start": 406.479,
        "duration": 3.761,
        "text": "the ceta architecture since cassandra's"
      },
      {
        "start": 408.56,
        "duration": 4.24,
        "text": "moved a lot away from ceta"
      },
      {
        "start": 410.24,
        "duration": 4.16,
        "text": "this isn't quite as important but it"
      },
      {
        "start": 412.8,
        "duration": 2.64,
        "text": "still gives you some really useful"
      },
      {
        "start": 414.4,
        "duration": 2.72,
        "text": "information"
      },
      {
        "start": 415.44,
        "duration": 3.599,
        "text": "thread pools are pretty much what's"
      },
      {
        "start": 417.12,
        "duration": 2.56,
        "text": "running inside of the cassandra node"
      },
      {
        "start": 419.039,
        "duration": 2.081,
        "text": "itself"
      },
      {
        "start": 419.68,
        "duration": 3.2,
        "text": "and you can see some really interesting"
      },
      {
        "start": 421.12,
        "duration": 3.44,
        "text": "statistics in there that give you a clue"
      },
      {
        "start": 422.88,
        "duration": 4.4,
        "text": "of what's actually happening"
      },
      {
        "start": 424.56,
        "duration": 4.16,
        "text": "especially with performance remember"
      },
      {
        "start": 427.28,
        "duration": 3.12,
        "text": "things that are blocking"
      },
      {
        "start": 428.72,
        "duration": 3.759,
        "text": "or causing more trouble because they're"
      },
      {
        "start": 430.4,
        "duration": 4.4,
        "text": "being used more than any other process"
      },
      {
        "start": 432.479,
        "duration": 4.401,
        "text": "are things to investigate so the states"
      },
      {
        "start": 434.8,
        "duration": 4.239,
        "text": "of those nodes are really important"
      },
      {
        "start": 436.88,
        "duration": 3.52,
        "text": "active pended completed blocked those"
      },
      {
        "start": 439.039,
        "duration": 3.681,
        "text": "are all the four states"
      },
      {
        "start": 440.4,
        "duration": 3.04,
        "text": "that you can see running inside of the"
      },
      {
        "start": 442.72,
        "duration": 2.4,
        "text": "node"
      },
      {
        "start": 443.44,
        "duration": 3.12,
        "text": "now of course you never want to see"
      },
      {
        "start": 445.12,
        "duration": 3.04,
        "text": "blocked and that's probably the number"
      },
      {
        "start": 446.56,
        "duration": 3.359,
        "text": "we want to focus on"
      },
      {
        "start": 448.16,
        "duration": 4.24,
        "text": "if i see something that's been blocked"
      },
      {
        "start": 449.919,
        "duration": 5.28,
        "text": "ever i want to know why"
      },
      {
        "start": 452.4,
        "duration": 4.239,
        "text": "so this example output gives you all of"
      },
      {
        "start": 455.199,
        "duration": 2.161,
        "text": "the different thread pools that are"
      },
      {
        "start": 456.639,
        "duration": 3.361,
        "text": "active"
      },
      {
        "start": 457.36,
        "duration": 3.679,
        "text": "so for instance we have the mem table"
      },
      {
        "start": 460.0,
        "duration": 2.24,
        "text": "flush writer"
      },
      {
        "start": 461.039,
        "duration": 3.6,
        "text": "one of those things that are really"
      },
      {
        "start": 462.24,
        "duration": 4.16,
        "text": "important so whenever you fill up a mem"
      },
      {
        "start": 464.639,
        "duration": 3.921,
        "text": "table and it's flush to disk"
      },
      {
        "start": 466.4,
        "duration": 3.6,
        "text": "that becomes active and it will write"
      },
      {
        "start": 468.56,
        "duration": 4.079,
        "text": "out to the disk"
      },
      {
        "start": 470.0,
        "duration": 3.52,
        "text": "if the mem table flush rider is ever"
      },
      {
        "start": 472.639,
        "duration": 3.201,
        "text": "blocked"
      },
      {
        "start": 473.52,
        "duration": 3.92,
        "text": "that's bad that means that your jvm is"
      },
      {
        "start": 475.84,
        "duration": 4.4,
        "text": "unable to flush that memory"
      },
      {
        "start": 477.44,
        "duration": 3.92,
        "text": "out and it's gonna sit there we all know"
      },
      {
        "start": 480.24,
        "duration": 3.6,
        "text": "that memory"
      },
      {
        "start": 481.36,
        "duration": 4.16,
        "text": "in the java virtual machine is a premium"
      },
      {
        "start": 483.84,
        "duration": 3.199,
        "text": "and if you have large blocks of memory"
      },
      {
        "start": 485.52,
        "duration": 2.16,
        "text": "just sitting there not getting flushed"
      },
      {
        "start": 487.039,
        "duration": 2.321,
        "text": "out"
      },
      {
        "start": 487.68,
        "duration": 3.44,
        "text": "that can turn into a really bad problem"
      },
      {
        "start": 489.36,
        "duration": 3.76,
        "text": "that's when you start seeing gc"
      },
      {
        "start": 491.12,
        "duration": 3.44,
        "text": "the number of blocked on any of these"
      },
      {
        "start": 493.12,
        "duration": 2.479,
        "text": "could be translated back to something"
      },
      {
        "start": 494.56,
        "duration": 2.4,
        "text": "really simple"
      },
      {
        "start": 495.599,
        "duration": 3.201,
        "text": "which could be something like a disk"
      },
      {
        "start": 496.96,
        "duration": 3.6,
        "text": "which isn't allowing any writes"
      },
      {
        "start": 498.8,
        "duration": 4.32,
        "text": "so you can start seeing those block"
      },
      {
        "start": 500.56,
        "duration": 3.28,
        "text": "counts go up on mem table flush writers"
      },
      {
        "start": 503.12,
        "duration": 3.44,
        "text": "for instance"
      },
      {
        "start": 503.84,
        "duration": 4.32,
        "text": "so again these are clues but really big"
      },
      {
        "start": 506.56,
        "duration": 4.0,
        "text": "clues because this is saying"
      },
      {
        "start": 508.16,
        "duration": 3.68,
        "text": "hey as a running node i'm unhappy and"
      },
      {
        "start": 510.56,
        "duration": 2.959,
        "text": "here's what's happening"
      },
      {
        "start": 511.84,
        "duration": 3.999,
        "text": "and you can use that to go diagnose"
      },
      {
        "start": 513.519,
        "duration": 2.96,
        "text": "other problems i used to use this quite"
      },
      {
        "start": 515.839,
        "duration": 1.921,
        "text": "often"
      },
      {
        "start": 516.479,
        "duration": 3.12,
        "text": "i could look at those numbers and tell"
      },
      {
        "start": 517.76,
        "duration": 2.32,
        "text": "you if you had a gc problem or if you"
      },
      {
        "start": 519.599,
        "duration": 2.161,
        "text": "had a"
      },
      {
        "start": 520.08,
        "duration": 3.28,
        "text": "memory problem or if you had a disc"
      },
      {
        "start": 521.76,
        "duration": 3.44,
        "text": "problem pretty quickly because those"
      },
      {
        "start": 523.36,
        "duration": 4.24,
        "text": "numbers would always pop to the top"
      },
      {
        "start": 525.2,
        "duration": 4.0,
        "text": "this is a good command to get to know so"
      },
      {
        "start": 527.6,
        "duration": 3.04,
        "text": "this is a really good overview i think"
      },
      {
        "start": 529.2,
        "duration": 2.319,
        "text": "of those commands that you don't use all"
      },
      {
        "start": 530.64,
        "duration": 2.319,
        "text": "the time"
      },
      {
        "start": 531.519,
        "duration": 2.641,
        "text": "but in cases where you really need to"
      },
      {
        "start": 532.959,
        "duration": 2.56,
        "text": "understand what's happening in the"
      },
      {
        "start": 534.16,
        "duration": 7.2,
        "text": "running node itself"
      },
      {
        "start": 535.519,
        "duration": 5.841,
        "text": "these will help you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T01:40:31.113668+00:00"
}