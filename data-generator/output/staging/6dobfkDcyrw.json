{
  "video_id": "6dobfkDcyrw",
  "title": "Prototyping a RAG Application Without Code",
  "description": "This video video is about simulating interactions with language models when building RAG applications. Before you write any code, you can test your idea by simulating the retrieval and the various prompts needed for generation. It's a great way to get started and helps you refine your idea before committing into the development stage. \n\nThis is also a great way to try different LLMs and find which works best for your application. \n\nNeed a great vector database fro your RAG Application? Astra DB has a easy free tier to get started today: https://dtsx.io/3jyh4gq\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastaxdevs?sub_confirmation=1 \nTwitter: https://twitter.com/datastaxdevs\nTwitch: https://www.twitch.tv/datastaxdevs\n\nAbout DataStax:\nDataStax is the company behind the massively scalable, highly available, cloud-native NoSQL data platform built on Apache Cassandra™. DataStax gives developers and enterprises the freedom to run data in any cloud, Kubernetes, hybrid or bare metal at global scale with zero downtime and zero lock-in. More than 450 of the world’s leading enterprises including Capital One, Cisco, Comcast, Delta Airlines, Macy’s, McDonald’s, Safeway, Sony, and Walmart use DataStax to build transformational data architectures for real-world outcomes. For more, visit DataStax.com and @DataStax.\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2024-03-25T22:58:29Z",
  "thumbnail": "https://i.ytimg.com/vi/6dobfkDcyrw/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "scalable",
    "workshop",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "vector",
    "nosql",
    "astra",
    "architecture",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=6dobfkDcyrw",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "building a rag application doesn't have to be complicated to start with you can prototype something pretty easily without writing a single bit of code so stick with me and I'm going to show you how to do it so let's start here this is just a basic document where I just wrote out my idea the example website that I have is this old one this killer video and it's a video sharing website the thing that I want to do is add a rag based feature that is going to let people find new videos so it'll take a description from some like in a chat window and then it'll go through and say oh yeah here's a bunch of videos that are just like that it's a similarity search right but it has to do the search and so it has to ask for something and then get it back and so I just write it up real quick now I could use chat GPT or any of the AI out there all the large language models to come up with some of these things but in this case I just typed it up here's what I want to do and just think about it like if you're brainstorming with a colleague the thing that it has to do is it has to ask a user for a description some sort of a chat window and then get the videos they like back you know so like say like they love cat videos right I'm going to simulate this whole thing using one of the there's multiple playgrounds so instance you don't have to use chat GPT to do this we want to simulate what it's like interacting with the llm and see what happens that's the thing that we want to do is like do a search and then come back with some data and then how are we going to prompt the llm to like when the retrieval happens we augment that Generation Well the generation what does the generation look like the G part and it sometimes it's playing around with the prompts and so we can simulate how this would look and we can play around with those prompts to make it happen so quick example here I you know what I'm expecting is that if I do a similarity search hey here's all the things that I'll get back so couple of things to think about here so I'm G to I can use this I can use just the this hey you're a great marketing bot any prompt is going to have the best prompts are going to have something that will be like a roll hey you are this it will have instructions do that and then in some cases most cases though an example so that that usually solidifies what's going on in this case because this is a retrieval thing what I what I'm simulating here in this Doc is I just made up a quick table actually told jat DPT to create this table for me uh so I'm using all the AIS for this but just this this retrieval like all right here's I I asked for top 10 similarity for cat videos and this is what it came back with Okay so let's simulate that so I'm going to copy all of this business right here copy it all the way down cool copy so this is open AI playground I'm just going to put some stuff in here and see what happens I'm going to take that prompt that I created in the doc and I'm just going to act like it just did a retrieval right so hey you're a great marketing bot good job and I'm asking it to take this oops spelled that wrong I'm going to ask it to take this table of data and that's the thing I'm going to be playing around with my formatting too do I need to put it in Json or is it happy with just tab delimited or a dict or something like that from a python app whatever right so I'm going to go ahead and hit the submit button on this here I'm going to move myself over here so I'm not in your way all right let's let's see what happens now what it's doing and now it's using GPT 4 it's coming back with like hey here are the top videos and like why and what's cool is I'm I'm playing around with this this idea that it's going to do some generation so I I passed it in like these videos with all these names in it and I'm playing around with this with this particular prom now maybe I don't like that you know it's like well all right let's let's go back and play around with the prompt a little bit so I'm back here playing around with my prompt and I should probably change the spelling here take the top three videos and explain why the user should go watch these but let's let's add a little bit let's let let's take out this part right here that'll be a that's a prompt that we don't need let's see like I I want to have it a little more a little more exciting right take the top three videos why each you should go see these and and make it exciting be a marketing marketing but okay I don't know what it's going to do with that that but see what I'm doing here is I'm playing around with my prompts now and now that I'm back over here I can try this again all right one more time let's see what it has to say about that there we go now it's getting a little crazy buckle up cat Enthusiast there you go so now what we're getting is a much more enhanced now I this may not be what you want in your rag application but we're still simulating I don't have to build no code has been written here and that's awesome and I don't have to do this with just open a I know a lot of you want to avoid open AI That's cool you can do the same thing over here this is uh this is on AWS this is bedrock and this is a clae 3 Sonet and uh yeah let's see how that goes again and you know this is the thing we can take the same prompt and play around with it maybe these llms are easier like if you can find a more lowcost llm great and if it gives you good responses so let's see what Claude has to say oh boy cu's dramatic announcer voice well maybe we can dial that back back a little bit but I you know it's funny to me because this is a completely different response different llm different response and this is a little over the top I'm going to dial hey hey dial it back here so on the top here let's see I don't want to do that anymore let's not let you be a marketing bot see what it comes back but see what I'm doing here is I'm playing with the prompt a little bit I'm taking the same data the data is going to come back from the database when you do the retrieval that's not the problem at this point that's the different problem but what we're doing with with the data is playing around with the prompt and see which one makes it better uh if I'm going to use CLA 3 Sonic it's clear that Claude wants to turn this into like a countdown from like David Letterman or something so okay I just want to do something let see I would take take the top three explain and I would say list them in a bullet list them with bullets I can be instructive and sometimes you have to be instructive some s it doesn't listen to your instructions here we go there we go I've done the tweaking do you see what I did there I tweaked and I made it work really well for me that's awesome um now let's let's go over to our good friends at Google new Gemini 1.5 and see how that goes let's see how Gemini does we'll start with the one it's like be a marketing bot and let's see how that goes right all right now one thing about Gemini is it doesn't do streaming it calculates and then it goes blurp there's your data and there it is oh man meic yeah see this is why we want a prototype because we just don't know what language models are going to come up with Gemini 1.5 Pro sweet uh way over the top so I even put emojis in there I right on you know I'm going to take the marketing bot out of there and see what happens this is and we could also play with the temperature things like that but right now I'm just playing around with it really wants to do meow nificent okay well maybe I don't want to use Gemini maybe I do but you can see I mean what I'm going to do is I'm going to further refine this and this is a really great place to start with like a rag application and thinking about prompts because ultimately what rag does is it takes data and communicates with humans and how you communicate with humans is all in the language model um it takes data or information and converts into human that's us and and how do you want to communicate with them this completely Over the Top Copy okay maybe this is forget Netflix it's time for catflex I man this is great you can't even make this up anyway I hope this helps this is a great way to start and as you're beginning your journey with AI think about things in this terms this isn't just sitting down at a prompt and writing out some codes sometimes you got to play around with the tools and the tools in this case are large language models have a good day",
    "segments": [
      {
        "start": 0.88,
        "duration": 4.12,
        "text": "building a rag application doesn't have"
      },
      {
        "start": 2.56,
        "duration": 4.44,
        "text": "to be complicated to start with you can"
      },
      {
        "start": 5.0,
        "duration": 4.28,
        "text": "prototype something pretty easily"
      },
      {
        "start": 7.0,
        "duration": 3.599,
        "text": "without writing a single bit of code so"
      },
      {
        "start": 9.28,
        "duration": 3.96,
        "text": "stick with me and I'm going to show you"
      },
      {
        "start": 10.599,
        "duration": 4.681,
        "text": "how to do it so let's start here this is"
      },
      {
        "start": 13.24,
        "duration": 4.6,
        "text": "just a basic document where I just wrote"
      },
      {
        "start": 15.28,
        "duration": 4.32,
        "text": "out my idea the example website that I"
      },
      {
        "start": 17.84,
        "duration": 4.32,
        "text": "have is this old one this killer video"
      },
      {
        "start": 19.6,
        "duration": 4.8,
        "text": "and it's a video sharing website the"
      },
      {
        "start": 22.16,
        "duration": 4.16,
        "text": "thing that I want to do is add a rag"
      },
      {
        "start": 24.4,
        "duration": 4.719,
        "text": "based feature that is going to let"
      },
      {
        "start": 26.32,
        "duration": 4.4,
        "text": "people find new videos so it'll take a"
      },
      {
        "start": 29.119,
        "duration": 3.521,
        "text": "description from some like in a chat"
      },
      {
        "start": 30.72,
        "duration": 3.28,
        "text": "window and then it'll go through and say"
      },
      {
        "start": 32.64,
        "duration": 3.12,
        "text": "oh yeah here's a bunch of videos that"
      },
      {
        "start": 34.0,
        "duration": 3.64,
        "text": "are just like that it's a similarity"
      },
      {
        "start": 35.76,
        "duration": 3.68,
        "text": "search right but it has to do the search"
      },
      {
        "start": 37.64,
        "duration": 3.64,
        "text": "and so it has to ask for something and"
      },
      {
        "start": 39.44,
        "duration": 5.32,
        "text": "then get it back and so I just write it"
      },
      {
        "start": 41.28,
        "duration": 6.0,
        "text": "up real quick now I could use chat GPT"
      },
      {
        "start": 44.76,
        "duration": 5.08,
        "text": "or any of the AI out there all the large"
      },
      {
        "start": 47.28,
        "duration": 3.959,
        "text": "language models to come up with some of"
      },
      {
        "start": 49.84,
        "duration": 3.48,
        "text": "these things but in this case I just"
      },
      {
        "start": 51.239,
        "duration": 3.241,
        "text": "typed it up here's what I want to do and"
      },
      {
        "start": 53.32,
        "duration": 3.239,
        "text": "just think about it like if you're"
      },
      {
        "start": 54.48,
        "duration": 4.2,
        "text": "brainstorming with a colleague the thing"
      },
      {
        "start": 56.559,
        "duration": 3.881,
        "text": "that it has to do is it has to ask a"
      },
      {
        "start": 58.68,
        "duration": 4.48,
        "text": "user for a description some sort of a"
      },
      {
        "start": 60.44,
        "duration": 4.719,
        "text": "chat window and then get the videos they"
      },
      {
        "start": 63.16,
        "duration": 4.8,
        "text": "like back you know so like say like they"
      },
      {
        "start": 65.159,
        "duration": 5.401,
        "text": "love cat videos right I'm going to"
      },
      {
        "start": 67.96,
        "duration": 4.839,
        "text": "simulate this whole thing using one of"
      },
      {
        "start": 70.56,
        "duration": 4.239,
        "text": "the there's multiple playgrounds so"
      },
      {
        "start": 72.799,
        "duration": 4.881,
        "text": "instance you don't have to use chat GPT"
      },
      {
        "start": 74.799,
        "duration": 5.041,
        "text": "to do this we want to simulate what it's"
      },
      {
        "start": 77.68,
        "duration": 3.759,
        "text": "like interacting with the llm and see"
      },
      {
        "start": 79.84,
        "duration": 3.919,
        "text": "what happens that's the thing that we"
      },
      {
        "start": 81.439,
        "duration": 4.201,
        "text": "want to do is like do a search and then"
      },
      {
        "start": 83.759,
        "duration": 4.841,
        "text": "come back with some data and then how"
      },
      {
        "start": 85.64,
        "duration": 5.0,
        "text": "are we going to prompt the llm to like"
      },
      {
        "start": 88.6,
        "duration": 4.0,
        "text": "when the retrieval happens we augment"
      },
      {
        "start": 90.64,
        "duration": 5.4,
        "text": "that Generation Well the generation what"
      },
      {
        "start": 92.6,
        "duration": 4.92,
        "text": "does the generation look like the G part"
      },
      {
        "start": 96.04,
        "duration": 3.439,
        "text": "and it sometimes it's playing around"
      },
      {
        "start": 97.52,
        "duration": 3.279,
        "text": "with the prompts and so we can simulate"
      },
      {
        "start": 99.479,
        "duration": 2.561,
        "text": "how this would look and we can play"
      },
      {
        "start": 100.799,
        "duration": 4.401,
        "text": "around with those prompts to make it"
      },
      {
        "start": 102.04,
        "duration": 5.079,
        "text": "happen so quick example here I you know"
      },
      {
        "start": 105.2,
        "duration": 4.44,
        "text": "what I'm expecting is that if I do a"
      },
      {
        "start": 107.119,
        "duration": 5.04,
        "text": "similarity search hey here's all the"
      },
      {
        "start": 109.64,
        "duration": 4.92,
        "text": "things that I'll get back so couple of"
      },
      {
        "start": 112.159,
        "duration": 5.041,
        "text": "things to think about here so I'm G to I"
      },
      {
        "start": 114.56,
        "duration": 5.04,
        "text": "can use this I can use just the this hey"
      },
      {
        "start": 117.2,
        "duration": 3.879,
        "text": "you're a great marketing bot any prompt"
      },
      {
        "start": 119.6,
        "duration": 3.519,
        "text": "is going to have the best prompts are"
      },
      {
        "start": 121.079,
        "duration": 5.281,
        "text": "going to have something that will be"
      },
      {
        "start": 123.119,
        "duration": 6.161,
        "text": "like a roll hey you are this it will"
      },
      {
        "start": 126.36,
        "duration": 5.599,
        "text": "have instructions do that and then in"
      },
      {
        "start": 129.28,
        "duration": 4.84,
        "text": "some cases most cases though an example"
      },
      {
        "start": 131.959,
        "duration": 4.681,
        "text": "so that that usually solidifies what's"
      },
      {
        "start": 134.12,
        "duration": 4.479,
        "text": "going on in this case because this is a"
      },
      {
        "start": 136.64,
        "duration": 3.64,
        "text": "retrieval thing what I what I'm"
      },
      {
        "start": 138.599,
        "duration": 3.681,
        "text": "simulating here in this Doc is I just"
      },
      {
        "start": 140.28,
        "duration": 4.8,
        "text": "made up a quick table actually told jat"
      },
      {
        "start": 142.28,
        "duration": 5.56,
        "text": "DPT to create this table for me uh so"
      },
      {
        "start": 145.08,
        "duration": 4.12,
        "text": "I'm using all the AIS for this but just"
      },
      {
        "start": 147.84,
        "duration": 4.88,
        "text": "this this retrieval like all right"
      },
      {
        "start": 149.2,
        "duration": 5.2,
        "text": "here's I I asked for top 10 similarity"
      },
      {
        "start": 152.72,
        "duration": 3.799,
        "text": "for cat videos and this is what it came"
      },
      {
        "start": 154.4,
        "duration": 5.04,
        "text": "back with Okay so let's simulate that so"
      },
      {
        "start": 156.519,
        "duration": 6.0,
        "text": "I'm going to copy all of this business"
      },
      {
        "start": 159.44,
        "duration": 4.879,
        "text": "right here copy it all the way down"
      },
      {
        "start": 162.519,
        "duration": 4.8,
        "text": "cool"
      },
      {
        "start": 164.319,
        "duration": 4.601,
        "text": "copy so this is open AI playground I'm"
      },
      {
        "start": 167.319,
        "duration": 3.241,
        "text": "just going to put some stuff in here and"
      },
      {
        "start": 168.92,
        "duration": 3.76,
        "text": "see what happens I'm going to take that"
      },
      {
        "start": 170.56,
        "duration": 3.84,
        "text": "prompt that I created in the doc and I'm"
      },
      {
        "start": 172.68,
        "duration": 3.559,
        "text": "just going to act like it just did a"
      },
      {
        "start": 174.4,
        "duration": 4.08,
        "text": "retrieval right so hey you're a great"
      },
      {
        "start": 176.239,
        "duration": 4.36,
        "text": "marketing bot good job and I'm asking it"
      },
      {
        "start": 178.48,
        "duration": 3.839,
        "text": "to take this oops spelled that wrong I'm"
      },
      {
        "start": 180.599,
        "duration": 3.161,
        "text": "going to ask it to take this table of"
      },
      {
        "start": 182.319,
        "duration": 3.361,
        "text": "data and that's the thing I'm going to"
      },
      {
        "start": 183.76,
        "duration": 3.64,
        "text": "be playing around with my formatting too"
      },
      {
        "start": 185.68,
        "duration": 3.72,
        "text": "do I need to put it in Json or is it"
      },
      {
        "start": 187.4,
        "duration": 4.04,
        "text": "happy with just tab delimited or a dict"
      },
      {
        "start": 189.4,
        "duration": 4.6,
        "text": "or something like that from a python app"
      },
      {
        "start": 191.44,
        "duration": 4.359,
        "text": "whatever right so I'm going to go ahead"
      },
      {
        "start": 194.0,
        "duration": 3.44,
        "text": "and hit the submit button on this here"
      },
      {
        "start": 195.799,
        "duration": 3.681,
        "text": "I'm going to move myself over here so"
      },
      {
        "start": 197.44,
        "duration": 3.4,
        "text": "I'm not in your way all right let's"
      },
      {
        "start": 199.48,
        "duration": 5.119,
        "text": "let's see what"
      },
      {
        "start": 200.84,
        "duration": 6.2,
        "text": "happens now what it's doing and now it's"
      },
      {
        "start": 204.599,
        "duration": 5.92,
        "text": "using GPT 4 it's coming back with like"
      },
      {
        "start": 207.04,
        "duration": 5.0,
        "text": "hey here are the top videos and like why"
      },
      {
        "start": 210.519,
        "duration": 4.201,
        "text": "and what's cool is I'm I'm playing"
      },
      {
        "start": 212.04,
        "duration": 5.08,
        "text": "around with this this idea that it's"
      },
      {
        "start": 214.72,
        "duration": 4.439,
        "text": "going to do some generation so I I"
      },
      {
        "start": 217.12,
        "duration": 4.119,
        "text": "passed it in like these videos with all"
      },
      {
        "start": 219.159,
        "duration": 4.28,
        "text": "these names in it and I'm playing around"
      },
      {
        "start": 221.239,
        "duration": 4.681,
        "text": "with this with this particular"
      },
      {
        "start": 223.439,
        "duration": 4.561,
        "text": "prom now maybe I don't like that you"
      },
      {
        "start": 225.92,
        "duration": 3.319,
        "text": "know it's like well all right let's"
      },
      {
        "start": 228.0,
        "duration": 3.56,
        "text": "let's go back and play around with the"
      },
      {
        "start": 229.239,
        "duration": 3.56,
        "text": "prompt a little bit so I'm back here"
      },
      {
        "start": 231.56,
        "duration": 2.679,
        "text": "playing around with my prompt and I"
      },
      {
        "start": 232.799,
        "duration": 3.16,
        "text": "should probably change the spelling here"
      },
      {
        "start": 234.239,
        "duration": 3.961,
        "text": "take the top three videos and explain"
      },
      {
        "start": 235.959,
        "duration": 3.84,
        "text": "why the user should go watch these but"
      },
      {
        "start": 238.2,
        "duration": 3.039,
        "text": "let's let's add a little bit let's let"
      },
      {
        "start": 239.799,
        "duration": 3.0,
        "text": "let's take out this part right here"
      },
      {
        "start": 241.239,
        "duration": 3.801,
        "text": "that'll be a that's a prompt that we"
      },
      {
        "start": 242.799,
        "duration": 4.36,
        "text": "don't need let's see like I I want to"
      },
      {
        "start": 245.04,
        "duration": 4.6,
        "text": "have it a little more a little more"
      },
      {
        "start": 247.159,
        "duration": 6.201,
        "text": "exciting right take the top three videos"
      },
      {
        "start": 249.64,
        "duration": 8.439,
        "text": "why each you should go see these"
      },
      {
        "start": 253.36,
        "duration": 4.719,
        "text": "and and make it"
      },
      {
        "start": 258.44,
        "duration": 6.24,
        "text": "exciting be a"
      },
      {
        "start": 261.68,
        "duration": 3.0,
        "text": "marketing"
      },
      {
        "start": 264.72,
        "duration": 4.72,
        "text": "marketing"
      },
      {
        "start": 266.24,
        "duration": 4.6,
        "text": "but okay I don't know what it's going to"
      },
      {
        "start": 269.44,
        "duration": 2.4,
        "text": "do with that that but see what I'm doing"
      },
      {
        "start": 270.84,
        "duration": 3.56,
        "text": "here is I'm playing around with my"
      },
      {
        "start": 271.84,
        "duration": 4.16,
        "text": "prompts now and now that I'm back over"
      },
      {
        "start": 274.4,
        "duration": 3.92,
        "text": "here I can try this"
      },
      {
        "start": 276.0,
        "duration": 4.6,
        "text": "again all right one more time let's see"
      },
      {
        "start": 278.32,
        "duration": 4.04,
        "text": "what it has to say about that there we"
      },
      {
        "start": 280.6,
        "duration": 5.64,
        "text": "go now it's getting a little crazy"
      },
      {
        "start": 282.36,
        "duration": 7.119,
        "text": "buckle up cat Enthusiast there you go so"
      },
      {
        "start": 286.24,
        "duration": 5.16,
        "text": "now what we're getting is a much more"
      },
      {
        "start": 289.479,
        "duration": 3.521,
        "text": "enhanced now I this may not be what you"
      },
      {
        "start": 291.4,
        "duration": 3.519,
        "text": "want in your rag application but we're"
      },
      {
        "start": 293.0,
        "duration": 4.199,
        "text": "still simulating I don't have to build"
      },
      {
        "start": 294.919,
        "duration": 4.28,
        "text": "no code has been written here and that's"
      },
      {
        "start": 297.199,
        "duration": 3.761,
        "text": "awesome and I don't have to do this with"
      },
      {
        "start": 299.199,
        "duration": 3.761,
        "text": "just open a I know a lot of you want to"
      },
      {
        "start": 300.96,
        "duration": 4.36,
        "text": "avoid open AI That's"
      },
      {
        "start": 302.96,
        "duration": 4.4,
        "text": "cool you can do the same thing over here"
      },
      {
        "start": 305.32,
        "duration": 5.56,
        "text": "this is uh this is on AWS this is"
      },
      {
        "start": 307.36,
        "duration": 6.04,
        "text": "bedrock and this is a clae 3 Sonet and"
      },
      {
        "start": 310.88,
        "duration": 3.72,
        "text": "uh yeah let's see how that goes again"
      },
      {
        "start": 313.4,
        "duration": 2.68,
        "text": "and you know this is the thing we can"
      },
      {
        "start": 314.6,
        "duration": 4.64,
        "text": "take the same prompt and play around"
      },
      {
        "start": 316.08,
        "duration": 5.52,
        "text": "with it maybe these llms are easier like"
      },
      {
        "start": 319.24,
        "duration": 4.44,
        "text": "if you can find a more lowcost llm great"
      },
      {
        "start": 321.6,
        "duration": 5.2,
        "text": "and if it gives you good responses so"
      },
      {
        "start": 323.68,
        "duration": 5.2,
        "text": "let's see what Claude has to say oh boy"
      },
      {
        "start": 326.8,
        "duration": 3.679,
        "text": "cu's dramatic announcer voice well maybe"
      },
      {
        "start": 328.88,
        "duration": 4.64,
        "text": "we can dial that back back a little bit"
      },
      {
        "start": 330.479,
        "duration": 5.681,
        "text": "but I you know it's funny to me because"
      },
      {
        "start": 333.52,
        "duration": 5.6,
        "text": "this is a completely different response"
      },
      {
        "start": 336.16,
        "duration": 4.64,
        "text": "different llm different response and"
      },
      {
        "start": 339.12,
        "duration": 4.12,
        "text": "this is a little over the top I'm going"
      },
      {
        "start": 340.8,
        "duration": 4.64,
        "text": "to dial hey hey dial it back here so on"
      },
      {
        "start": 343.24,
        "duration": 5.679,
        "text": "the top here let's see I don't want to"
      },
      {
        "start": 345.44,
        "duration": 5.52,
        "text": "do that anymore let's not let you be a"
      },
      {
        "start": 348.919,
        "duration": 3.201,
        "text": "marketing bot see what it comes back but"
      },
      {
        "start": 350.96,
        "duration": 2.64,
        "text": "see what I'm doing here is I'm playing"
      },
      {
        "start": 352.12,
        "duration": 2.919,
        "text": "with the prompt a little bit I'm taking"
      },
      {
        "start": 353.6,
        "duration": 3.039,
        "text": "the same data the data is going to come"
      },
      {
        "start": 355.039,
        "duration": 3.72,
        "text": "back from the database when you do the"
      },
      {
        "start": 356.639,
        "duration": 3.641,
        "text": "retrieval that's not the problem at this"
      },
      {
        "start": 358.759,
        "duration": 3.601,
        "text": "point that's the different problem but"
      },
      {
        "start": 360.28,
        "duration": 3.4,
        "text": "what we're doing with with the data is"
      },
      {
        "start": 362.36,
        "duration": 3.32,
        "text": "playing around with the prompt and see"
      },
      {
        "start": 363.68,
        "duration": 4.84,
        "text": "which one makes it better uh if I'm"
      },
      {
        "start": 365.68,
        "duration": 4.72,
        "text": "going to use CLA 3 Sonic it's clear that"
      },
      {
        "start": 368.52,
        "duration": 3.6,
        "text": "Claude wants to turn this into like a"
      },
      {
        "start": 370.4,
        "duration": 3.919,
        "text": "countdown from like David Letterman or"
      },
      {
        "start": 372.12,
        "duration": 4.0,
        "text": "something so okay I just want to do"
      },
      {
        "start": 374.319,
        "duration": 3.44,
        "text": "something let see I would take take the"
      },
      {
        "start": 376.12,
        "duration": 4.44,
        "text": "top three"
      },
      {
        "start": 377.759,
        "duration": 7.201,
        "text": "explain and I would say"
      },
      {
        "start": 380.56,
        "duration": 6.96,
        "text": "list them in a bullet list them with"
      },
      {
        "start": 384.96,
        "duration": 4.28,
        "text": "bullets I can be instructive and"
      },
      {
        "start": 387.52,
        "duration": 4.6,
        "text": "sometimes you have to be instructive"
      },
      {
        "start": 389.24,
        "duration": 6.079,
        "text": "some s it doesn't listen to your"
      },
      {
        "start": 392.12,
        "duration": 4.72,
        "text": "instructions here we go there we go I've"
      },
      {
        "start": 395.319,
        "duration": 3.241,
        "text": "done the tweaking do you see what I did"
      },
      {
        "start": 396.84,
        "duration": 4.639,
        "text": "there I tweaked and I made it work"
      },
      {
        "start": 398.56,
        "duration": 5.44,
        "text": "really well for me that's awesome um now"
      },
      {
        "start": 401.479,
        "duration": 5.041,
        "text": "let's let's go over to our good friends"
      },
      {
        "start": 404.0,
        "duration": 5.319,
        "text": "at Google new Gemini 1.5 and see how"
      },
      {
        "start": 406.52,
        "duration": 4.56,
        "text": "that goes let's see how Gemini does"
      },
      {
        "start": 409.319,
        "duration": 3.44,
        "text": "we'll start with the one it's like be a"
      },
      {
        "start": 411.08,
        "duration": 4.959,
        "text": "marketing bot and let's see how that"
      },
      {
        "start": 412.759,
        "duration": 5.12,
        "text": "goes right all right now one thing about"
      },
      {
        "start": 416.039,
        "duration": 3.761,
        "text": "Gemini is it doesn't do streaming it"
      },
      {
        "start": 417.879,
        "duration": 3.681,
        "text": "calculates and then it goes blurp"
      },
      {
        "start": 419.8,
        "duration": 6.0,
        "text": "there's your"
      },
      {
        "start": 421.56,
        "duration": 6.68,
        "text": "data and there it is oh man"
      },
      {
        "start": 425.8,
        "duration": 4.56,
        "text": "meic yeah see this is why we want a"
      },
      {
        "start": 428.24,
        "duration": 4.28,
        "text": "prototype because we just don't know"
      },
      {
        "start": 430.36,
        "duration": 6.08,
        "text": "what language models are going to come"
      },
      {
        "start": 432.52,
        "duration": 7.6,
        "text": "up with Gemini 1.5 Pro sweet uh way over"
      },
      {
        "start": 436.44,
        "duration": 5.84,
        "text": "the top so I even put emojis in there I"
      },
      {
        "start": 440.12,
        "duration": 4.88,
        "text": "right on you know I'm going to take the"
      },
      {
        "start": 442.28,
        "duration": 4.4,
        "text": "marketing bot out of there and see what"
      },
      {
        "start": 445.0,
        "duration": 3.12,
        "text": "happens this is and we could also play"
      },
      {
        "start": 446.68,
        "duration": 4.32,
        "text": "with the temperature things like that"
      },
      {
        "start": 448.12,
        "duration": 6.0,
        "text": "but right now I'm just playing around"
      },
      {
        "start": 451.0,
        "duration": 5.56,
        "text": "with it really wants to do meow nificent"
      },
      {
        "start": 454.12,
        "duration": 5.519,
        "text": "okay well maybe I don't want to use"
      },
      {
        "start": 456.56,
        "duration": 4.16,
        "text": "Gemini maybe I do but you can see I mean"
      },
      {
        "start": 459.639,
        "duration": 2.881,
        "text": "what I'm going to do is I'm going to"
      },
      {
        "start": 460.72,
        "duration": 3.439,
        "text": "further refine this and this is a really"
      },
      {
        "start": 462.52,
        "duration": 4.359,
        "text": "great place to start with like a rag"
      },
      {
        "start": 464.159,
        "duration": 5.641,
        "text": "application and thinking about prompts"
      },
      {
        "start": 466.879,
        "duration": 6.241,
        "text": "because ultimately what rag does is it"
      },
      {
        "start": 469.8,
        "duration": 5.239,
        "text": "takes data and communicates with humans"
      },
      {
        "start": 473.12,
        "duration": 4.079,
        "text": "and how you communicate with humans is"
      },
      {
        "start": 475.039,
        "duration": 5.041,
        "text": "all in the language model um it takes"
      },
      {
        "start": 477.199,
        "duration": 6.641,
        "text": "data or information and converts into"
      },
      {
        "start": 480.08,
        "duration": 6.04,
        "text": "human that's us and and how do you want"
      },
      {
        "start": 483.84,
        "duration": 5.44,
        "text": "to communicate with them this completely"
      },
      {
        "start": 486.12,
        "duration": 5.84,
        "text": "Over the Top Copy okay maybe this is"
      },
      {
        "start": 489.28,
        "duration": 4.12,
        "text": "forget Netflix it's time for catflex I"
      },
      {
        "start": 491.96,
        "duration": 3.6,
        "text": "man this is great you can't even make"
      },
      {
        "start": 493.4,
        "duration": 3.68,
        "text": "this up anyway I hope this helps this is"
      },
      {
        "start": 495.56,
        "duration": 3.919,
        "text": "a great way to start and as you're"
      },
      {
        "start": 497.08,
        "duration": 4.119,
        "text": "beginning your journey with AI think"
      },
      {
        "start": 499.479,
        "duration": 2.921,
        "text": "about things in this terms this isn't"
      },
      {
        "start": 501.199,
        "duration": 2.641,
        "text": "just sitting down at a prompt and"
      },
      {
        "start": 502.4,
        "duration": 3.12,
        "text": "writing out some codes sometimes you got"
      },
      {
        "start": 503.84,
        "duration": 3.24,
        "text": "to play around with the tools and the"
      },
      {
        "start": 505.52,
        "duration": 5.92,
        "text": "tools in this case are large language"
      },
      {
        "start": 507.08,
        "duration": 4.36,
        "text": "models have a good day"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T17:21:30.272616+00:00"
}