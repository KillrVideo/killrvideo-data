{
  "video_id": "ACsKiiR_4uY",
  "title": "The Generative AI Stack",
  "description": "Generative AI is the biggest platform shift since the original internet tidal wave, and maybe bigger. How do LLMs impact each part of the stack? How will your real-time data create differentiated Generative AI?\n\nAbout DataStax:\nDataStax is the company behind the massively scalable, highly available, cloud-native NoSQL data platform built on Apache Cassandra™. DataStax gives developers and enterprises the freedom to run data in any cloud, Kubernetes, hybrid or bare metal at global scale with zero downtime and zero lock-in. More than 450 of the world’s leading enterprises including Capital One, Cisco, Comcast, Delta Airlines, Macy’s, McDonald’s, Safeway, Sony, and Walmart use DataStax to build transformational data architectures for real-world outcomes. For more, visit DataStax.com and @DataStax.\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2023-07-11T19:15:00Z",
  "thumbnail": "https://i.ytimg.com/vi/ACsKiiR_4uY/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "scalable",
    "workshop",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "nosql",
    "architecture",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=ACsKiiR_4uY",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "foreign [Music] the chief product officer of data stacks today I'm going to talk to you about how generative AI has completely redefined the software stack for building applications in many ways the disruption that we're seeing is the most pronounced we've seen since 1994. when every company needed to get online needed to build websites needed to build e-commerce experiences now every company is trying to figure out how to build generative AI into every customer every partner every employee experience that they're delivering we can see this with the growth of chat GPT plugins we've all used chat GPT and recently they've made it available for developers to extend building plug-ins that hook into the chat gbt experience and allow you to go and couple it with external services and hundreds of developers have gone and built plugins and we can see here the growth of the chat gbt plug-in ecosystem now in many ways what we've seen with chat GPT is the emergence of generative AI as the latest step in a number of advances that we've seen within AI we saw deep learning machine learning become a very big deal a few years ago many of us started to research and learn this technology many of us have taken the lessons from Coursera and read all of the great O'Reilly books and all of that predictive AI was what we used this technology for how to figure out what a next best action would be or how to identify from an image whether it's a picture of a cat for example but along those same lines we saw generative AI emerge starting from text completion and text prediction to suddenly with the emergence of GPT gpt3 and now most recently gpt4 where we're able to create conversational experiences that are really remarkable and we're seeing the next Generations of that we're seeing things like Lang chain being used to build more complicated language interfaces towards the creation of autonomous agents at the same time we're seeing a lot of optimization happening where models are actually running on your device so a lot of exciting stuff has happened a lot of development that has happened to get here in fact if we were to look at the entire history of AI this stretches Back 40 or more years but certainly in the last decade we've started to see this accelerate and I think anybody who's following social media feeds or reading the latest developments have seen just how fast it's moving now so what's exciting to us is how we use this to build applications because the technology itself is very interesting but what's really cool is putting this to work in a way that users can actually experience and can benefit from and so as we look at that let's take a look at the application stack and see how it's being reinvented how every stage of it is being changed by the emergence and application of generative AI so let's take a look at how generative AI has redefined the application here if we look at every level of the stack everything from the user experience through business logic through the integration tier through the data tier we can see that generative AI is transforming every piece of the stack at the ux tier generative AI is not just powering the textual interaction a lot of people look at generative Ai and they go and they say look I don't like chat interfaces well the reality is you're actually going to see graphical user interfaces you see image recognition in addition to actual voice as well as chat all able to be used as inputs and outputs at the ux tier so this isn't going to just be chat Bots or chat agents although many of the early applications do take that form at the business logic level we see the ability to actually go and Define the business actions in more of a do what I mean format versus actually having to go and code explicit up programmatic rules for how the application works at the integration tier we've seen examples of this with the way that chatgpt plugins are built where they're able to couple directly to API definitions so the integration tier being able to pull in data and connect to other services is actually going to be more powerful and easier to do than it ever has been in previous generations of software development and then finally in order for this stall to be possible you need a very robust high performance data tier that's actually able to go and speak the native language of llms which is vectors so that you can have your large language models retrieve the data that they need as they need it so from an end standpoint we see that the stack is has been pretty significantly impacted so let's take a look at how that's typically used from an architectural standpoint so the typical way that an application that uses llms is built is using something called retrieval augmented generation and what this means is that when I'm building the context that I'm sending to the llm I actually am using existing data sources many of them are going to be within databases although they can be also retrieved from apis and other sources that context is what provides memory to the llm and also is what makes it personalized it's what allows it to provide real-time relevant responses llms are stateless they don't learn except at training time and that training time may have happened days weeks months even years ago so how is it possible that an llm is able to give you a response that might have the latest weather as of this morning or stock prices from 15 minutes ago retrieval augmented generation is what makes it possible that data the data that the llm needs is retrieved real time and passed into the context and then llm takes that and uses it as a crafts the response so part of how we build a generative AI application is typically to use one or more models you may use a small data set which I just talked about that data set in fact might be real-time data that comes from your databases and you might have a smaller model which pre-processes that data and determines what additional data is required that then goes into the larger foundational model which perhaps you've tuned for your use cases but many times that's not even necessary but you're providing a robust set of context that comes from your data sources that's processed by one or more models that gets augmented as necessary using Vector retrieval from your database and then goes into these foundational models you often hear about Technologies like Lang chain that are used to make this possible as the name would imply you typically have two or more models that go into the processing and generation of a response before it goes to the users so these models are chained together they build and augment context and then deliver that personalized response one of the things that I touched on was that llms are stateless I often hear about people going and saying oh you know gpt4 it's going to steal your information be careful what you give it well the model itself isn't going to steal anything the model itself has no memory as I said it is frozen in time from the point that it's been trained but clearly we've all experienced using chat GPT and other you know agents that they do have a memory well the memory comes from the database so it's the database that remembers what you input and as we're using databases with llms one of the things that makes them more effective is if the database is able to query on vectors if we think about what a vector is a vector is a mathematical representation of a concept it basically goes and takes whatever the topic is whatever the content is and Maps it in multiple dimensions and the important thing about exploding this data out or embedding it in a dimensional space is that you can compare the distance from any two positions in space and those positions determine the distance goes into determining the the similarity so if I am looking conceptually for something if I am shopping and I am looking for for you know one type of product and another product is very similar to it they're going to be close similar in dimensional space and llms typically represent their knowledge particularly when they're inputting and outputting uh either the taking in context or outputting a response in the form of these vectors so you can take those vectors and use them to look something up if you have a product catalog for example that's in a vector database you can now look up your products by concept is it summertime outdoor furniture is it indoor living room furniture obviously there are different concepts associated with those and so if I'm going and saying Recon recommend to me furniture for my living room it's going to be able to go and find a set of furniture that's appropriate for that versus what perhaps I want to go and put out in my backyard by the pool so this allows me to take the data sets that I already have that I've Vector encoded and use them with my llms it's an important capability that makes it possible to build these types of applications so typically when I build this out I do this in an architecture that leverages Vector databases leverages an embedding API that allows me to convert unstructured content perhaps a question from the user into a vector that I can be used for looking things up and I'm delivering that at runtime you know microservice based application that can be used to deliver application experiences wherever my users are interacting whether it's mobile apps whether it's web apps however they are interacting with my systems because llms typically are powering not exclusively but typically are powering interactive applications that's where you're probably going to put these agents agents is on the front lines of where customers are interacting with your business and as we look at the technologies that go into this architecture we can see that Vector databases like Cassandra that is part of our Astra database as well as Predictive Technologies all play A Part within this you'll also Leverage online inference Services things like vertex AI from Google or sagemaker to generate embeddings and also to go and refine your data and actually help build better context that goes into these llms and that's part of what slide talks about which is that when you're building these real-time apps you're actually combining generative Ai and predictive AI predictive AI allows me to go and look at historical data sets and perhaps generate Dynamic pricing offering up a discount for example it might be able to go and look at a set of data points coming from an iot application to determine maintenance is necessary or it might be able to go and look at inventory stock levels and figure out do I need to reorder or do I have a surplus that perhaps would generate a flash sale for an e-commerce site but all of those inputs need to be delivered to the user in a form that makes sense to them and that's where generative AI fits into the picture general of AI is fantastic at the places where the user is interacting whether it's conversationally whether it's for example many of us experience with GitHub co-pilot where code Auto completion happens as you're typing and fills out sections of your code base allowing you to develop in a much more rapid fashion obviously generative AI is and predictive AI are used within advertising predictive AI figures out which ad to show to which person but generative AI can actually create an advertisement and offer a promotion an email that's tailored to an individual it's a very powerful conversation combination or going and taking a set of content and going and condensing it down and delivering the right message at the right time so we've actually practiced what we preached we've used these capabilities to build something that we call the Astra assistant which is designed to make it possible for any developer that is using Cassandra that's using Astra DB to be able to go and build queries to be able to go and Define their database schemas or generate sample code that they can use in their applications and this is something that's live today we're talking about it in some of the other sessions today on how we built it it's a very cool use case that will give you a tangible perspective of how you can put one of these applications to use for you so stick around a lot more great stuff to show you thank you foreign [Music]",
    "segments": [
      {
        "start": 2.04,
        "duration": 6.26,
        "text": "foreign"
      },
      {
        "start": 4.0,
        "duration": 4.3,
        "text": "[Music]"
      },
      {
        "start": 9.62,
        "duration": 4.96,
        "text": "the chief product officer of data stacks"
      },
      {
        "start": 12.78,
        "duration": 4.38,
        "text": "today I'm going to talk to you about how"
      },
      {
        "start": 14.58,
        "duration": 4.5,
        "text": "generative AI has completely redefined"
      },
      {
        "start": 17.16,
        "duration": 3.36,
        "text": "the software stack for building"
      },
      {
        "start": 19.08,
        "duration": 3.359,
        "text": "applications"
      },
      {
        "start": 20.52,
        "duration": 4.32,
        "text": "in many ways the disruption that we're"
      },
      {
        "start": 22.439,
        "duration": 4.321,
        "text": "seeing is the most pronounced we've seen"
      },
      {
        "start": 24.84,
        "duration": 3.96,
        "text": "since 1994."
      },
      {
        "start": 26.76,
        "duration": 4.5,
        "text": "when every company needed to get online"
      },
      {
        "start": 28.8,
        "duration": 5.46,
        "text": "needed to build websites needed to build"
      },
      {
        "start": 31.26,
        "duration": 5.34,
        "text": "e-commerce experiences now every company"
      },
      {
        "start": 34.26,
        "duration": 6.72,
        "text": "is trying to figure out how to build"
      },
      {
        "start": 36.6,
        "duration": 6.479,
        "text": "generative AI into every customer every"
      },
      {
        "start": 40.98,
        "duration": 3.48,
        "text": "partner every employee experience that"
      },
      {
        "start": 43.079,
        "duration": 3.361,
        "text": "they're delivering"
      },
      {
        "start": 44.46,
        "duration": 5.88,
        "text": "we can see this with the growth of chat"
      },
      {
        "start": 46.44,
        "duration": 6.42,
        "text": "GPT plugins we've all used chat GPT and"
      },
      {
        "start": 50.34,
        "duration": 5.28,
        "text": "recently they've made it available for"
      },
      {
        "start": 52.86,
        "duration": 6.0,
        "text": "developers to extend building plug-ins"
      },
      {
        "start": 55.62,
        "duration": 5.7,
        "text": "that hook into the chat gbt experience"
      },
      {
        "start": 58.86,
        "duration": 4.199,
        "text": "and allow you to go and couple it with"
      },
      {
        "start": 61.32,
        "duration": 4.44,
        "text": "external services"
      },
      {
        "start": 63.059,
        "duration": 6.301,
        "text": "and hundreds of developers have gone and"
      },
      {
        "start": 65.76,
        "duration": 8.46,
        "text": "built plugins and we can see here the"
      },
      {
        "start": 69.36,
        "duration": 6.24,
        "text": "growth of the chat gbt plug-in ecosystem"
      },
      {
        "start": 74.22,
        "duration": 3.719,
        "text": "now"
      },
      {
        "start": 75.6,
        "duration": 7.26,
        "text": "in many ways what we've seen with chat"
      },
      {
        "start": 77.939,
        "duration": 8.521,
        "text": "GPT is the emergence of generative AI as"
      },
      {
        "start": 82.86,
        "duration": 5.579,
        "text": "the latest step in a number of advances"
      },
      {
        "start": 86.46,
        "duration": 4.199,
        "text": "that we've seen within AI"
      },
      {
        "start": 88.439,
        "duration": 4.801,
        "text": "we saw deep learning machine learning"
      },
      {
        "start": 90.659,
        "duration": 6.021,
        "text": "become a very big deal a few years ago"
      },
      {
        "start": 93.24,
        "duration": 6.72,
        "text": "many of us started to research and learn"
      },
      {
        "start": 96.68,
        "duration": 5.86,
        "text": "this technology many of us have taken"
      },
      {
        "start": 99.96,
        "duration": 4.38,
        "text": "the lessons from Coursera and read all"
      },
      {
        "start": 102.54,
        "duration": 6.18,
        "text": "of the great O'Reilly books and all of"
      },
      {
        "start": 104.34,
        "duration": 8.279,
        "text": "that predictive AI was what we used this"
      },
      {
        "start": 108.72,
        "duration": 5.52,
        "text": "technology for how to figure out what a"
      },
      {
        "start": 112.619,
        "duration": 4.381,
        "text": "next best action would be or how to"
      },
      {
        "start": 114.24,
        "duration": 5.339,
        "text": "identify from an image whether it's a"
      },
      {
        "start": 117.0,
        "duration": 4.92,
        "text": "picture of a cat for example but along"
      },
      {
        "start": 119.579,
        "duration": 5.101,
        "text": "those same lines we saw generative AI"
      },
      {
        "start": 121.92,
        "duration": 6.539,
        "text": "emerge starting from text completion and"
      },
      {
        "start": 124.68,
        "duration": 7.5,
        "text": "text prediction to suddenly with the"
      },
      {
        "start": 128.459,
        "duration": 7.701,
        "text": "emergence of GPT gpt3 and now most"
      },
      {
        "start": 132.18,
        "duration": 5.72,
        "text": "recently gpt4 where we're able to create"
      },
      {
        "start": 136.16,
        "duration": 5.2,
        "text": "conversational"
      },
      {
        "start": 137.9,
        "duration": 6.46,
        "text": "experiences that are really remarkable"
      },
      {
        "start": 141.36,
        "duration": 5.16,
        "text": "and we're seeing the next Generations of"
      },
      {
        "start": 144.36,
        "duration": 5.239,
        "text": "that we're seeing things like Lang chain"
      },
      {
        "start": 146.52,
        "duration": 6.48,
        "text": "being used to build more complicated"
      },
      {
        "start": 149.599,
        "duration": 5.86,
        "text": "language interfaces towards the creation"
      },
      {
        "start": 153.0,
        "duration": 3.84,
        "text": "of autonomous agents at the same time"
      },
      {
        "start": 155.459,
        "duration": 3.961,
        "text": "we're seeing a lot of optimization"
      },
      {
        "start": 156.84,
        "duration": 5.64,
        "text": "happening where models are actually"
      },
      {
        "start": 159.42,
        "duration": 4.8,
        "text": "running on your device so a lot of"
      },
      {
        "start": 162.48,
        "duration": 4.56,
        "text": "exciting stuff has happened a lot of"
      },
      {
        "start": 164.22,
        "duration": 4.379,
        "text": "development that has happened to get"
      },
      {
        "start": 167.04,
        "duration": 3.54,
        "text": "here in fact if we were to look at the"
      },
      {
        "start": 168.599,
        "duration": 5.041,
        "text": "entire history of AI this stretches Back"
      },
      {
        "start": 170.58,
        "duration": 5.22,
        "text": "40 or more years but certainly in the"
      },
      {
        "start": 173.64,
        "duration": 3.959,
        "text": "last decade we've started to see this"
      },
      {
        "start": 175.8,
        "duration": 4.68,
        "text": "accelerate and I think anybody who's"
      },
      {
        "start": 177.599,
        "duration": 4.321,
        "text": "following social media feeds or reading"
      },
      {
        "start": 180.48,
        "duration": 3.06,
        "text": "the latest developments have seen just"
      },
      {
        "start": 181.92,
        "duration": 5.22,
        "text": "how fast it's moving now"
      },
      {
        "start": 183.54,
        "duration": 6.12,
        "text": "so what's exciting to us is how we use"
      },
      {
        "start": 187.14,
        "duration": 4.44,
        "text": "this to build applications because the"
      },
      {
        "start": 189.66,
        "duration": 4.62,
        "text": "technology itself is very interesting"
      },
      {
        "start": 191.58,
        "duration": 6.12,
        "text": "but what's really cool is putting this"
      },
      {
        "start": 194.28,
        "duration": 5.94,
        "text": "to work in a way that users can actually"
      },
      {
        "start": 197.7,
        "duration": 5.819,
        "text": "experience and can benefit from"
      },
      {
        "start": 200.22,
        "duration": 5.96,
        "text": "and so as we look at that let's take a"
      },
      {
        "start": 203.519,
        "duration": 5.821,
        "text": "look at the application stack and see"
      },
      {
        "start": 206.18,
        "duration": 6.639,
        "text": "how it's being reinvented how every"
      },
      {
        "start": 209.34,
        "duration": 6.42,
        "text": "stage of it is being changed by the"
      },
      {
        "start": 212.819,
        "duration": 3.84,
        "text": "emergence and application of generative"
      },
      {
        "start": 215.76,
        "duration": 2.94,
        "text": "AI"
      },
      {
        "start": 216.659,
        "duration": 5.281,
        "text": "so let's take a look at how generative"
      },
      {
        "start": 218.7,
        "duration": 5.34,
        "text": "AI has redefined the application here if"
      },
      {
        "start": 221.94,
        "duration": 4.56,
        "text": "we look at every level of the stack"
      },
      {
        "start": 224.04,
        "duration": 4.86,
        "text": "everything from the user experience"
      },
      {
        "start": 226.5,
        "duration": 4.86,
        "text": "through business logic through the"
      },
      {
        "start": 228.9,
        "duration": 4.5,
        "text": "integration tier through the data tier"
      },
      {
        "start": 231.36,
        "duration": 4.92,
        "text": "we can see that generative AI is"
      },
      {
        "start": 233.4,
        "duration": 4.86,
        "text": "transforming every piece of the stack"
      },
      {
        "start": 236.28,
        "duration": 5.28,
        "text": "at the ux tier"
      },
      {
        "start": 238.26,
        "duration": 5.399,
        "text": "generative AI is not just powering the"
      },
      {
        "start": 241.56,
        "duration": 3.84,
        "text": "textual interaction a lot of people look"
      },
      {
        "start": 243.659,
        "duration": 3.781,
        "text": "at"
      },
      {
        "start": 245.4,
        "duration": 4.199,
        "text": "generative Ai and they go and they say"
      },
      {
        "start": 247.44,
        "duration": 3.84,
        "text": "look I don't like chat interfaces well"
      },
      {
        "start": 249.599,
        "duration": 4.2,
        "text": "the reality is you're actually going to"
      },
      {
        "start": 251.28,
        "duration": 7.019,
        "text": "see graphical user interfaces you see"
      },
      {
        "start": 253.799,
        "duration": 7.981,
        "text": "image recognition in addition to actual"
      },
      {
        "start": 258.299,
        "duration": 7.261,
        "text": "voice as well as chat all able to be"
      },
      {
        "start": 261.78,
        "duration": 5.76,
        "text": "used as inputs and outputs at the ux"
      },
      {
        "start": 265.56,
        "duration": 4.44,
        "text": "tier so this isn't going to just be chat"
      },
      {
        "start": 267.54,
        "duration": 5.7,
        "text": "Bots or chat agents although many of the"
      },
      {
        "start": 270.0,
        "duration": 5.46,
        "text": "early applications do take that form"
      },
      {
        "start": 273.24,
        "duration": 5.16,
        "text": "at the business logic level we see the"
      },
      {
        "start": 275.46,
        "duration": 5.64,
        "text": "ability to actually go and Define the"
      },
      {
        "start": 278.4,
        "duration": 5.28,
        "text": "business actions in more of a do what I"
      },
      {
        "start": 281.1,
        "duration": 6.56,
        "text": "mean format versus actually having to go"
      },
      {
        "start": 283.68,
        "duration": 6.66,
        "text": "and code explicit up"
      },
      {
        "start": 287.66,
        "duration": 4.72,
        "text": "programmatic rules for how the"
      },
      {
        "start": 290.34,
        "duration": 4.62,
        "text": "application works at the integration"
      },
      {
        "start": 292.38,
        "duration": 4.74,
        "text": "tier we've seen examples of this with"
      },
      {
        "start": 294.96,
        "duration": 4.5,
        "text": "the way that chatgpt plugins are built"
      },
      {
        "start": 297.12,
        "duration": 4.98,
        "text": "where they're able to couple directly to"
      },
      {
        "start": 299.46,
        "duration": 5.4,
        "text": "API definitions so the integration tier"
      },
      {
        "start": 302.1,
        "duration": 5.099,
        "text": "being able to pull in data and connect"
      },
      {
        "start": 304.86,
        "duration": 5.22,
        "text": "to other services is actually going to"
      },
      {
        "start": 307.199,
        "duration": 5.461,
        "text": "be more powerful and easier to do than"
      },
      {
        "start": 310.08,
        "duration": 4.74,
        "text": "it ever has been in previous generations"
      },
      {
        "start": 312.66,
        "duration": 4.14,
        "text": "of software development and then finally"
      },
      {
        "start": 314.82,
        "duration": 5.04,
        "text": "in order for this stall to be possible"
      },
      {
        "start": 316.8,
        "duration": 6.42,
        "text": "you need a very robust high performance"
      },
      {
        "start": 319.86,
        "duration": 6.54,
        "text": "data tier that's actually able to go and"
      },
      {
        "start": 323.22,
        "duration": 7.319,
        "text": "speak the native language of llms which"
      },
      {
        "start": 326.4,
        "duration": 6.359,
        "text": "is vectors so that you can have your"
      },
      {
        "start": 330.539,
        "duration": 5.761,
        "text": "large language models retrieve the data"
      },
      {
        "start": 332.759,
        "duration": 7.021,
        "text": "that they need as they need it so"
      },
      {
        "start": 336.3,
        "duration": 5.7,
        "text": "from an end standpoint we see that the"
      },
      {
        "start": 339.78,
        "duration": 3.419,
        "text": "stack is has been pretty significantly"
      },
      {
        "start": 342.0,
        "duration": 2.4,
        "text": "impacted"
      },
      {
        "start": 343.199,
        "duration": 3.901,
        "text": "so"
      },
      {
        "start": 344.4,
        "duration": 4.5,
        "text": "let's take a look at how that's"
      },
      {
        "start": 347.1,
        "duration": 6.36,
        "text": "typically used from an architectural"
      },
      {
        "start": 348.9,
        "duration": 7.68,
        "text": "standpoint so the typical way that an"
      },
      {
        "start": 353.46,
        "duration": 4.799,
        "text": "application that uses llms is built is"
      },
      {
        "start": 356.58,
        "duration": 3.42,
        "text": "using something called retrieval"
      },
      {
        "start": 358.259,
        "duration": 5.041,
        "text": "augmented generation"
      },
      {
        "start": 360.0,
        "duration": 5.52,
        "text": "and what this means is that when I'm"
      },
      {
        "start": 363.3,
        "duration": 5.94,
        "text": "building the context that I'm sending to"
      },
      {
        "start": 365.52,
        "duration": 6.119,
        "text": "the llm I actually am using existing"
      },
      {
        "start": 369.24,
        "duration": 4.44,
        "text": "data sources many of them are going to"
      },
      {
        "start": 371.639,
        "duration": 3.961,
        "text": "be within databases although they can be"
      },
      {
        "start": 373.68,
        "duration": 3.6,
        "text": "also retrieved from apis and other"
      },
      {
        "start": 375.6,
        "duration": 5.4,
        "text": "sources"
      },
      {
        "start": 377.28,
        "duration": 4.859,
        "text": "that context is what provides memory to"
      },
      {
        "start": 381.0,
        "duration": 4.62,
        "text": "the llm"
      },
      {
        "start": 382.139,
        "duration": 6.801,
        "text": "and also is what makes it personalized"
      },
      {
        "start": 385.62,
        "duration": 5.72,
        "text": "it's what allows it to provide real-time"
      },
      {
        "start": 388.94,
        "duration": 5.8,
        "text": "relevant responses"
      },
      {
        "start": 391.34,
        "duration": 5.62,
        "text": "llms are stateless they don't learn"
      },
      {
        "start": 394.74,
        "duration": 4.86,
        "text": "except at training time and that"
      },
      {
        "start": 396.96,
        "duration": 5.4,
        "text": "training time may have happened days"
      },
      {
        "start": 399.6,
        "duration": 5.64,
        "text": "weeks months even years ago"
      },
      {
        "start": 402.36,
        "duration": 6.3,
        "text": "so how is it possible that an llm is"
      },
      {
        "start": 405.24,
        "duration": 5.7,
        "text": "able to give you a response that might"
      },
      {
        "start": 408.66,
        "duration": 5.22,
        "text": "have the latest weather as of this"
      },
      {
        "start": 410.94,
        "duration": 4.14,
        "text": "morning or stock prices from 15 minutes"
      },
      {
        "start": 413.88,
        "duration": 3.06,
        "text": "ago"
      },
      {
        "start": 415.08,
        "duration": 4.14,
        "text": "retrieval augmented generation is what"
      },
      {
        "start": 416.94,
        "duration": 5.94,
        "text": "makes it possible that data the data"
      },
      {
        "start": 419.22,
        "duration": 6.24,
        "text": "that the llm needs is retrieved real"
      },
      {
        "start": 422.88,
        "duration": 4.379,
        "text": "time and passed into the context"
      },
      {
        "start": 425.46,
        "duration": 5.28,
        "text": "and then llm"
      },
      {
        "start": 427.259,
        "duration": 5.521,
        "text": "takes that and uses it as a crafts the"
      },
      {
        "start": 430.74,
        "duration": 3.48,
        "text": "response"
      },
      {
        "start": 432.78,
        "duration": 4.32,
        "text": "so"
      },
      {
        "start": 434.22,
        "duration": 5.46,
        "text": "part of how we build"
      },
      {
        "start": 437.1,
        "duration": 5.159,
        "text": "a generative AI application is typically"
      },
      {
        "start": 439.68,
        "duration": 5.579,
        "text": "to use one or more models"
      },
      {
        "start": 442.259,
        "duration": 4.741,
        "text": "you may use a small data set which I"
      },
      {
        "start": 445.259,
        "duration": 5.761,
        "text": "just talked about that data set in fact"
      },
      {
        "start": 447.0,
        "duration": 5.58,
        "text": "might be real-time data that comes from"
      },
      {
        "start": 451.02,
        "duration": 5.28,
        "text": "your databases"
      },
      {
        "start": 452.58,
        "duration": 6.72,
        "text": "and you might have a smaller model which"
      },
      {
        "start": 456.3,
        "duration": 5.64,
        "text": "pre-processes that data and determines"
      },
      {
        "start": 459.3,
        "duration": 4.5,
        "text": "what additional data is required"
      },
      {
        "start": 461.94,
        "duration": 4.14,
        "text": "that then goes into the larger"
      },
      {
        "start": 463.8,
        "duration": 4.799,
        "text": "foundational model which perhaps you've"
      },
      {
        "start": 466.08,
        "duration": 4.26,
        "text": "tuned for your use cases but many times"
      },
      {
        "start": 468.599,
        "duration": 5.22,
        "text": "that's not even necessary"
      },
      {
        "start": 470.34,
        "duration": 4.919,
        "text": "but you're providing a robust set of"
      },
      {
        "start": 473.819,
        "duration": 3.901,
        "text": "context"
      },
      {
        "start": 475.259,
        "duration": 5.761,
        "text": "that comes from your data sources"
      },
      {
        "start": 477.72,
        "duration": 6.66,
        "text": "that's processed by one or more models"
      },
      {
        "start": 481.02,
        "duration": 5.88,
        "text": "that gets augmented as necessary using"
      },
      {
        "start": 484.38,
        "duration": 4.2,
        "text": "Vector retrieval from your database"
      },
      {
        "start": 486.9,
        "duration": 4.139,
        "text": "and then goes into these foundational"
      },
      {
        "start": 488.58,
        "duration": 5.94,
        "text": "models you often hear about Technologies"
      },
      {
        "start": 491.039,
        "duration": 5.641,
        "text": "like Lang chain that are used to make"
      },
      {
        "start": 494.52,
        "duration": 4.56,
        "text": "this possible as the name would imply"
      },
      {
        "start": 496.68,
        "duration": 5.12,
        "text": "you typically have"
      },
      {
        "start": 499.08,
        "duration": 5.76,
        "text": "two or more models that go into the"
      },
      {
        "start": 501.8,
        "duration": 4.78,
        "text": "processing and generation of a response"
      },
      {
        "start": 504.84,
        "duration": 3.6,
        "text": "before it goes to the users so these"
      },
      {
        "start": 506.58,
        "duration": 5.16,
        "text": "models are chained together"
      },
      {
        "start": 508.44,
        "duration": 7.159,
        "text": "they build and augment context and then"
      },
      {
        "start": 511.74,
        "duration": 3.859,
        "text": "deliver that personalized response"
      },
      {
        "start": 516.419,
        "duration": 4.98,
        "text": "one of the things that"
      },
      {
        "start": 518.159,
        "duration": 5.341,
        "text": "I touched on was that llms are stateless"
      },
      {
        "start": 521.399,
        "duration": 3.301,
        "text": "I often hear about people going and"
      },
      {
        "start": 523.5,
        "duration": 3.72,
        "text": "saying oh"
      },
      {
        "start": 524.7,
        "duration": 4.5,
        "text": "you know gpt4 it's going to steal your"
      },
      {
        "start": 527.22,
        "duration": 4.38,
        "text": "information be careful what you give it"
      },
      {
        "start": 529.2,
        "duration": 4.38,
        "text": "well the model itself isn't going to"
      },
      {
        "start": 531.6,
        "duration": 5.46,
        "text": "steal anything the model itself has no"
      },
      {
        "start": 533.58,
        "duration": 6.54,
        "text": "memory as I said it is frozen in time"
      },
      {
        "start": 537.06,
        "duration": 5.82,
        "text": "from the point that it's been trained"
      },
      {
        "start": 540.12,
        "duration": 7.32,
        "text": "but clearly we've all experienced using"
      },
      {
        "start": 542.88,
        "duration": 6.48,
        "text": "chat GPT and other you know agents that"
      },
      {
        "start": 547.44,
        "duration": 3.899,
        "text": "they do have a memory well the memory"
      },
      {
        "start": 549.36,
        "duration": 4.26,
        "text": "comes from the database"
      },
      {
        "start": 551.339,
        "duration": 3.601,
        "text": "so it's the database that remembers what"
      },
      {
        "start": 553.62,
        "duration": 5.04,
        "text": "you input"
      },
      {
        "start": 554.94,
        "duration": 6.839,
        "text": "and as we're using databases with llms"
      },
      {
        "start": 558.66,
        "duration": 6.0,
        "text": "one of the things that makes them more"
      },
      {
        "start": 561.779,
        "duration": 4.921,
        "text": "effective is if the database is able to"
      },
      {
        "start": 564.66,
        "duration": 4.2,
        "text": "query on vectors"
      },
      {
        "start": 566.7,
        "duration": 4.4,
        "text": "if we think about what a vector is a"
      },
      {
        "start": 568.86,
        "duration": 4.68,
        "text": "vector is a mathematical representation"
      },
      {
        "start": 571.1,
        "duration": 6.88,
        "text": "of a concept"
      },
      {
        "start": 573.54,
        "duration": 6.9,
        "text": "it basically goes and takes whatever the"
      },
      {
        "start": 577.98,
        "duration": 5.58,
        "text": "topic is whatever the content is and"
      },
      {
        "start": 580.44,
        "duration": 5.399,
        "text": "Maps it in multiple dimensions and the"
      },
      {
        "start": 583.56,
        "duration": 4.74,
        "text": "important thing about exploding this"
      },
      {
        "start": 585.839,
        "duration": 4.56,
        "text": "data out or embedding it in a"
      },
      {
        "start": 588.3,
        "duration": 3.84,
        "text": "dimensional space is that you can"
      },
      {
        "start": 590.399,
        "duration": 4.081,
        "text": "compare the distance from any two"
      },
      {
        "start": 592.14,
        "duration": 4.199,
        "text": "positions in space"
      },
      {
        "start": 594.48,
        "duration": 4.919,
        "text": "and those positions"
      },
      {
        "start": 596.339,
        "duration": 6.361,
        "text": "determine the distance"
      },
      {
        "start": 599.399,
        "duration": 6.661,
        "text": "goes into determining the the similarity"
      },
      {
        "start": 602.7,
        "duration": 6.12,
        "text": "so if I am looking conceptually for"
      },
      {
        "start": 606.06,
        "duration": 5.1,
        "text": "something if I am shopping and I am"
      },
      {
        "start": 608.82,
        "duration": 5.34,
        "text": "looking for for"
      },
      {
        "start": 611.16,
        "duration": 5.52,
        "text": "you know one type of product and another"
      },
      {
        "start": 614.16,
        "duration": 4.859,
        "text": "product is very similar to it they're"
      },
      {
        "start": 616.68,
        "duration": 3.42,
        "text": "going to be close similar in dimensional"
      },
      {
        "start": 619.019,
        "duration": 5.101,
        "text": "space"
      },
      {
        "start": 620.1,
        "duration": 5.28,
        "text": "and llms typically represent their"
      },
      {
        "start": 624.12,
        "duration": 4.08,
        "text": "knowledge particularly when they're"
      },
      {
        "start": 625.38,
        "duration": 4.62,
        "text": "inputting and outputting uh either the"
      },
      {
        "start": 628.2,
        "duration": 4.68,
        "text": "taking in context or outputting a"
      },
      {
        "start": 630.0,
        "duration": 4.32,
        "text": "response in the form of these vectors so"
      },
      {
        "start": 632.88,
        "duration": 3.36,
        "text": "you can take those vectors and use them"
      },
      {
        "start": 634.32,
        "duration": 4.38,
        "text": "to look something up if you have a"
      },
      {
        "start": 636.24,
        "duration": 5.039,
        "text": "product catalog for example that's in a"
      },
      {
        "start": 638.7,
        "duration": 5.4,
        "text": "vector database you can now look up your"
      },
      {
        "start": 641.279,
        "duration": 6.06,
        "text": "products by concept"
      },
      {
        "start": 644.1,
        "duration": 5.34,
        "text": "is it summertime outdoor furniture"
      },
      {
        "start": 647.339,
        "duration": 4.321,
        "text": "is it indoor living room furniture"
      },
      {
        "start": 649.44,
        "duration": 4.44,
        "text": "obviously there are different concepts"
      },
      {
        "start": 651.66,
        "duration": 4.44,
        "text": "associated with those and so if I'm"
      },
      {
        "start": 653.88,
        "duration": 4.32,
        "text": "going and saying Recon recommend to me"
      },
      {
        "start": 656.1,
        "duration": 5.16,
        "text": "furniture for my living room"
      },
      {
        "start": 658.2,
        "duration": 4.68,
        "text": "it's going to be able to go and find a"
      },
      {
        "start": 661.26,
        "duration": 3.6,
        "text": "set of furniture that's appropriate for"
      },
      {
        "start": 662.88,
        "duration": 5.22,
        "text": "that versus what perhaps I want to go"
      },
      {
        "start": 664.86,
        "duration": 6.659,
        "text": "and put out in my backyard by the pool"
      },
      {
        "start": 668.1,
        "duration": 5.52,
        "text": "so this allows me to take the data sets"
      },
      {
        "start": 671.519,
        "duration": 5.041,
        "text": "that I already have that I've Vector"
      },
      {
        "start": 673.62,
        "duration": 5.1,
        "text": "encoded and use them"
      },
      {
        "start": 676.56,
        "duration": 3.959,
        "text": "with my llms it's an important"
      },
      {
        "start": 678.72,
        "duration": 4.14,
        "text": "capability that makes it possible to"
      },
      {
        "start": 680.519,
        "duration": 5.461,
        "text": "build these types of applications"
      },
      {
        "start": 682.86,
        "duration": 6.659,
        "text": "so typically when I build this out I do"
      },
      {
        "start": 685.98,
        "duration": 7.68,
        "text": "this in an architecture that"
      },
      {
        "start": 689.519,
        "duration": 6.541,
        "text": "leverages Vector databases leverages an"
      },
      {
        "start": 693.66,
        "duration": 4.679,
        "text": "embedding API that allows me to convert"
      },
      {
        "start": 696.06,
        "duration": 5.1,
        "text": "unstructured content perhaps a question"
      },
      {
        "start": 698.339,
        "duration": 5.401,
        "text": "from the user into a vector that I can"
      },
      {
        "start": 701.16,
        "duration": 5.64,
        "text": "be used for looking things up"
      },
      {
        "start": 703.74,
        "duration": 4.8,
        "text": "and I'm delivering that at runtime you"
      },
      {
        "start": 706.8,
        "duration": 3.36,
        "text": "know microservice based application that"
      },
      {
        "start": 708.54,
        "duration": 4.68,
        "text": "can be used to deliver application"
      },
      {
        "start": 710.16,
        "duration": 4.14,
        "text": "experiences wherever my users are"
      },
      {
        "start": 713.22,
        "duration": 2.64,
        "text": "interacting"
      },
      {
        "start": 714.3,
        "duration": 4.62,
        "text": "whether it's mobile apps whether it's"
      },
      {
        "start": 715.86,
        "duration": 5.52,
        "text": "web apps however they are interacting"
      },
      {
        "start": 718.92,
        "duration": 4.62,
        "text": "with my systems because llms typically"
      },
      {
        "start": 721.38,
        "duration": 4.44,
        "text": "are powering not exclusively but"
      },
      {
        "start": 723.54,
        "duration": 3.66,
        "text": "typically are powering interactive"
      },
      {
        "start": 725.82,
        "duration": 2.88,
        "text": "applications that's where you're"
      },
      {
        "start": 727.2,
        "duration": 5.759,
        "text": "probably going to put these agents"
      },
      {
        "start": 728.7,
        "duration": 6.48,
        "text": "agents is on the front lines of where"
      },
      {
        "start": 732.959,
        "duration": 4.341,
        "text": "customers are interacting with your"
      },
      {
        "start": 735.18,
        "duration": 2.12,
        "text": "business"
      },
      {
        "start": 738.12,
        "duration": 4.5,
        "text": "and as we look at the technologies that"
      },
      {
        "start": 740.279,
        "duration": 4.441,
        "text": "go into this architecture we can see"
      },
      {
        "start": 742.62,
        "duration": 5.88,
        "text": "that Vector databases like Cassandra"
      },
      {
        "start": 744.72,
        "duration": 6.66,
        "text": "that is part of our Astra database as"
      },
      {
        "start": 748.5,
        "duration": 7.44,
        "text": "well as Predictive Technologies all play"
      },
      {
        "start": 751.38,
        "duration": 6.72,
        "text": "A Part within this you'll also Leverage"
      },
      {
        "start": 755.94,
        "duration": 6.78,
        "text": "online"
      },
      {
        "start": 758.1,
        "duration": 7.799,
        "text": "inference Services things like vertex AI"
      },
      {
        "start": 762.72,
        "duration": 7.26,
        "text": "from Google or sagemaker"
      },
      {
        "start": 765.899,
        "duration": 6.361,
        "text": "to generate embeddings and also to go"
      },
      {
        "start": 769.98,
        "duration": 5.099,
        "text": "and refine your data and actually help"
      },
      {
        "start": 772.26,
        "duration": 5.28,
        "text": "build better context that goes into"
      },
      {
        "start": 775.079,
        "duration": 4.021,
        "text": "these llms"
      },
      {
        "start": 777.54,
        "duration": 5.34,
        "text": "and that's part of what"
      },
      {
        "start": 779.1,
        "duration": 5.76,
        "text": "slide talks about which is that when"
      },
      {
        "start": 782.88,
        "duration": 5.22,
        "text": "you're building these real-time apps"
      },
      {
        "start": 784.86,
        "duration": 6.18,
        "text": "you're actually combining generative Ai"
      },
      {
        "start": 788.1,
        "duration": 6.539,
        "text": "and predictive AI predictive AI allows"
      },
      {
        "start": 791.04,
        "duration": 5.58,
        "text": "me to go and look at historical data"
      },
      {
        "start": 794.639,
        "duration": 3.541,
        "text": "sets and perhaps generate Dynamic"
      },
      {
        "start": 796.62,
        "duration": 4.2,
        "text": "pricing"
      },
      {
        "start": 798.18,
        "duration": 6.779,
        "text": "offering up a discount for example"
      },
      {
        "start": 800.82,
        "duration": 5.699,
        "text": "it might be able to go and look at a set"
      },
      {
        "start": 804.959,
        "duration": 3.361,
        "text": "of data points coming from an iot"
      },
      {
        "start": 806.519,
        "duration": 4.741,
        "text": "application to determine maintenance is"
      },
      {
        "start": 808.32,
        "duration": 4.92,
        "text": "necessary or it might be able to go and"
      },
      {
        "start": 811.26,
        "duration": 4.86,
        "text": "look at inventory stock levels and"
      },
      {
        "start": 813.24,
        "duration": 4.74,
        "text": "figure out do I need to reorder or do I"
      },
      {
        "start": 816.12,
        "duration": 4.68,
        "text": "have a surplus that perhaps"
      },
      {
        "start": 817.98,
        "duration": 6.479,
        "text": "would generate a flash sale for an"
      },
      {
        "start": 820.8,
        "duration": 6.719,
        "text": "e-commerce site but all of those inputs"
      },
      {
        "start": 824.459,
        "duration": 5.041,
        "text": "need to be delivered to the user in a"
      },
      {
        "start": 827.519,
        "duration": 4.5,
        "text": "form that makes sense to them and that's"
      },
      {
        "start": 829.5,
        "duration": 6.839,
        "text": "where generative AI fits into the"
      },
      {
        "start": 832.019,
        "duration": 6.301,
        "text": "picture general of AI is fantastic at"
      },
      {
        "start": 836.339,
        "duration": 4.5,
        "text": "the places where the user is interacting"
      },
      {
        "start": 838.32,
        "duration": 5.519,
        "text": "whether it's conversationally whether"
      },
      {
        "start": 840.839,
        "duration": 6.661,
        "text": "it's for example many of us experience"
      },
      {
        "start": 843.839,
        "duration": 6.781,
        "text": "with GitHub co-pilot where code Auto"
      },
      {
        "start": 847.5,
        "duration": 5.519,
        "text": "completion happens as you're typing"
      },
      {
        "start": 850.62,
        "duration": 4.019,
        "text": "and fills out sections of your code base"
      },
      {
        "start": 853.019,
        "duration": 3.361,
        "text": "allowing you to develop in a much more"
      },
      {
        "start": 854.639,
        "duration": 5.281,
        "text": "rapid fashion"
      },
      {
        "start": 856.38,
        "duration": 4.92,
        "text": "obviously generative AI is and"
      },
      {
        "start": 859.92,
        "duration": 2.64,
        "text": "predictive AI are used within"
      },
      {
        "start": 861.3,
        "duration": 3.42,
        "text": "advertising"
      },
      {
        "start": 862.56,
        "duration": 4.079,
        "text": "predictive AI figures out which ad to"
      },
      {
        "start": 864.72,
        "duration": 3.78,
        "text": "show to which person but generative AI"
      },
      {
        "start": 866.639,
        "duration": 4.2,
        "text": "can actually create an advertisement and"
      },
      {
        "start": 868.5,
        "duration": 4.38,
        "text": "offer a promotion an email that's"
      },
      {
        "start": 870.839,
        "duration": 4.881,
        "text": "tailored to an individual it's a very"
      },
      {
        "start": 872.88,
        "duration": 7.8,
        "text": "powerful conversation combination"
      },
      {
        "start": 875.72,
        "duration": 6.34,
        "text": "or going and taking a set of content and"
      },
      {
        "start": 880.68,
        "duration": 3.3,
        "text": "going and condensing it down and"
      },
      {
        "start": 882.06,
        "duration": 3.54,
        "text": "delivering the right message at the"
      },
      {
        "start": 883.98,
        "duration": 4.02,
        "text": "right time"
      },
      {
        "start": 885.6,
        "duration": 4.2,
        "text": "so"
      },
      {
        "start": 888.0,
        "duration": 4.32,
        "text": "we've actually practiced what we"
      },
      {
        "start": 889.8,
        "duration": 4.68,
        "text": "preached we've used these capabilities"
      },
      {
        "start": 892.32,
        "duration": 3.48,
        "text": "to build something that we call the"
      },
      {
        "start": 894.48,
        "duration": 3.359,
        "text": "Astra assistant"
      },
      {
        "start": 895.8,
        "duration": 4.74,
        "text": "which is designed to make it possible"
      },
      {
        "start": 897.839,
        "duration": 5.94,
        "text": "for any developer that is using"
      },
      {
        "start": 900.54,
        "duration": 6.9,
        "text": "Cassandra that's using Astra DB to be"
      },
      {
        "start": 903.779,
        "duration": 6.961,
        "text": "able to go and build queries to be able"
      },
      {
        "start": 907.44,
        "duration": 6.6,
        "text": "to go and Define their database schemas"
      },
      {
        "start": 910.74,
        "duration": 5.219,
        "text": "or generate sample code that they can"
      },
      {
        "start": 914.04,
        "duration": 3.659,
        "text": "use in their applications"
      },
      {
        "start": 915.959,
        "duration": 3.541,
        "text": "and this is something that's live today"
      },
      {
        "start": 917.699,
        "duration": 4.621,
        "text": "we're talking about it in some of the"
      },
      {
        "start": 919.5,
        "duration": 6.959,
        "text": "other sessions today on how we built it"
      },
      {
        "start": 922.32,
        "duration": 7.319,
        "text": "it's a very cool use case that will give"
      },
      {
        "start": 926.459,
        "duration": 4.801,
        "text": "you a tangible perspective of how you"
      },
      {
        "start": 929.639,
        "duration": 3.841,
        "text": "can put one of these applications to use"
      },
      {
        "start": 931.26,
        "duration": 4.92,
        "text": "for you so"
      },
      {
        "start": 933.48,
        "duration": 5.159,
        "text": "stick around a lot more great stuff to"
      },
      {
        "start": 936.18,
        "duration": 4.92,
        "text": "show you thank you"
      },
      {
        "start": 938.639,
        "duration": 5.691,
        "text": "foreign"
      },
      {
        "start": 941.1,
        "duration": 3.23,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T17:47:43.195494+00:00"
}