{
  "video_id": "-dMxIU69kuY",
  "title": "CDC for Astra DB Demo: Sink to ElasticSearch",
  "description": "7 minutes with David Dieruf, who will show you how to enable CDC for Astra DB, configure it to watch a Cassandra table on the Astra DB database, and then automatically propagate that change via Astra Streaming, built on Apache Pulsar, to Elasticsearch on Elastic Cloud.  Of course, CDC can be configured to watch Cassandra tables and propagate changes to other DBs like PostGres, SnowFlake and other Cassandra DBs on Astra DB.\n\nLearn more: https://docs.datastax.com/en/streaming/astra-streaming/developing/astream-cdc.html\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastaxdevs?sub_confirmation=1 \nTwitter: https://twitter.com/datastaxdevs\nTwitch: https://www.twitch.tv/datastaxdevs\n\nAbout DataStax:\nDataStax is the company behind the massively scalable, highly available, cloud-native NoSQL data platform built on Apache Cassandra™. DataStax gives developers and enterprises the freedom to run data in any cloud, Kubernetes, hybrid or bare metal at global scale with zero downtime and zero lock-in. More than 450 of the world’s leading enterprises including Capital One, Cisco, Comcast, Delta Airlines, Macy’s, McDonald’s, Safeway, Sony, and Walmart use DataStax to build transformational data architectures for real-world outcomes. For more, visit DataStax.com and @DataStax.\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2023-01-03T19:03:02Z",
  "thumbnail": "https://i.ytimg.com/vi/-dMxIU69kuY/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "scalable",
    "demo",
    "workshop",
    "cassandra",
    "search",
    "database",
    "apache_cassandra",
    "tutorial",
    "nosql",
    "astra",
    "architecture",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=-dMxIU69kuY",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "foreign in this session we're going to be following a step-by-step guide to enabling CDC for Astra DB using elasticsearch the goal is to get updates in elasticsearch when data in an Astra DB table changes we'll accomplish this through the change data capture pattern the prerequisites for this session are to have an active Astra paid account to have the CDC feature enabled and a publicly accessible running instance of elasticsearch and kibada we'll be using a trial account from elastic.io that really has no pre-existing configurations so to get started we're going to confirm which Cloud region we'll be using uh for this demonstration so we head to the Astra streaming regions page in the documentation and we notice that three clouds are supported some with multiple regions for this demonstration we're going to be using Google cloud and we're going to choose us Central One this is a key choice because we need a region that both Astra DB and Astrid streaming support so let's head over and log into our astrodb account and now the first step is to create a database so we click on create database we're going to give it a name of my company we're going to give it a key space name of our product and I'm going to choose Google Cloud North America U.S Central One and create and now we'll wait until the database has a status of active and with our database created now we'll go in and create a table so we'll head over to the cql console within our database and we'll paste a create table statement we're creating a table called all accounts with three columns an ID a full name and an email and with that created now we're going to create our streaming tenant so we'll head to create streaming we'll choose a tenant name of my company streams we'll choose Google Cloud as our provider and U.S Central one as our region to match where our database is now with the tenant created we'll go back and enable CDC so we head to our company database to the CDC tab and we click on enable CDC choose our new tenant that we just created the key space that we created for the database and the table name and now we'll wait for a status of active for our CDC enablement and with our CDC feature enabled now we'll head over back to our streaming tenant and we're going to create the sync to connect to elasticsearch so we head into sinks we create the sink we're going to choose a namespace of Astra CDC this namespace was created for us when we enabled the CDC feature we're going to choose a sync type of elasticsearch we're going to name it es account sync we're going to choose a topic of the data topic for our table all accounts this was created for us also when we enabled the CDC feature and now we need to input some connection information for our sync to make it to elastic cloud so we'll head over to our elasticsearch service go into the deployment and we're going to go to management for this workspace and for our elasticsearch application there is a endpoint option to copy to clipboard so we'll copy that we'll come back over and here we'll paste it in there we're going to name the index something memorable CDC account messages the default username for the account is elastic I will bring in my password for this the token and API key can be left alone because we're using our username and password we're going to say ignore record key to false these are fine we're going to say strip nulls we're going to leave that to true the enable schema we're going to make Mark that true and the copy key Fields we're going to leave that at false all right and so now let's let the sink get created and we'll wait for a status of running all right and our sync now has a status of running and so with our CDC feature enabled and our elasticsearch sync running and active now we're going to add a little bit of data to the table and this should be pushed over to elasticsearch automatically via our CDC features so we're going to insert one row of data to our all accounts with just some nice information okay nothing good all good there now we're going to head over to our elastic search engine and since we're going to go into the deployment and now some things have been created in our elasticsearch environment so we're going to on the menu here we're going to go to management and we're going to go to stack management and then we're going to go to the kibana data views and in there because we have information that's been added elastic tells us we see that and so let's automatically create a data view for it we're going to name it the same the data view is same as the index that we chose and create good everything is saved here it's it's all automatic not a whole lot of work to do just clicking now let's go back and now we actually want to see the data so we're going to go to our kibana analytics area to the Discover Tab and there we have it because we created that data view it automatically brought it up and it saw that we had one record added there's the information for the record that we added and we have accomplished the change data capture pattern foreign",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 7.259,
        "duration": 4.141,
        "text": "in this session we're going to be"
      },
      {
        "start": 9.0,
        "duration": 5.759,
        "text": "following a step-by-step guide to"
      },
      {
        "start": 11.4,
        "duration": 4.86,
        "text": "enabling CDC for Astra DB using"
      },
      {
        "start": 14.759,
        "duration": 3.721,
        "text": "elasticsearch"
      },
      {
        "start": 16.26,
        "duration": 5.22,
        "text": "the goal is to get updates in"
      },
      {
        "start": 18.48,
        "duration": 5.28,
        "text": "elasticsearch when data in an Astra DB"
      },
      {
        "start": 21.48,
        "duration": 4.799,
        "text": "table changes we'll accomplish this"
      },
      {
        "start": 23.76,
        "duration": 4.62,
        "text": "through the change data capture pattern"
      },
      {
        "start": 26.279,
        "duration": 5.4,
        "text": "the prerequisites for this session are"
      },
      {
        "start": 28.38,
        "duration": 6.0,
        "text": "to have an active Astra paid account to"
      },
      {
        "start": 31.679,
        "duration": 5.461,
        "text": "have the CDC feature enabled"
      },
      {
        "start": 34.38,
        "duration": 5.88,
        "text": "and a publicly accessible running"
      },
      {
        "start": 37.14,
        "duration": 5.78,
        "text": "instance of elasticsearch and kibada"
      },
      {
        "start": 40.26,
        "duration": 5.58,
        "text": "we'll be using a trial account from"
      },
      {
        "start": 42.92,
        "duration": 5.38,
        "text": "elastic.io that really has no"
      },
      {
        "start": 45.84,
        "duration": 4.32,
        "text": "pre-existing configurations so to get"
      },
      {
        "start": 48.3,
        "duration": 4.919,
        "text": "started we're going to confirm which"
      },
      {
        "start": 50.16,
        "duration": 4.2,
        "text": "Cloud region we'll be using uh for this"
      },
      {
        "start": 53.219,
        "duration": 3.801,
        "text": "demonstration"
      },
      {
        "start": 54.36,
        "duration": 5.94,
        "text": "so we head to the Astra streaming"
      },
      {
        "start": 57.02,
        "duration": 5.379,
        "text": "regions page in the documentation and we"
      },
      {
        "start": 60.3,
        "duration": 5.039,
        "text": "notice that three clouds are supported"
      },
      {
        "start": 62.399,
        "duration": 4.381,
        "text": "some with multiple regions for this"
      },
      {
        "start": 65.339,
        "duration": 3.6,
        "text": "demonstration we're going to be using"
      },
      {
        "start": 66.78,
        "duration": 4.14,
        "text": "Google cloud and we're going to choose"
      },
      {
        "start": 68.939,
        "duration": 4.921,
        "text": "us Central One"
      },
      {
        "start": 70.92,
        "duration": 5.699,
        "text": "this is a key choice because we need a"
      },
      {
        "start": 73.86,
        "duration": 5.7,
        "text": "region that both Astra DB and Astrid"
      },
      {
        "start": 76.619,
        "duration": 7.201,
        "text": "streaming support so let's head over and"
      },
      {
        "start": 79.56,
        "duration": 7.02,
        "text": "log into our astrodb account"
      },
      {
        "start": 83.82,
        "duration": 6.24,
        "text": "and now the first step is to create a"
      },
      {
        "start": 86.58,
        "duration": 6.12,
        "text": "database so we click on create database"
      },
      {
        "start": 90.06,
        "duration": 3.78,
        "text": "we're going to give it a name of my"
      },
      {
        "start": 92.7,
        "duration": 3.12,
        "text": "company"
      },
      {
        "start": 93.84,
        "duration": 4.319,
        "text": "we're going to give it a key space name"
      },
      {
        "start": 95.82,
        "duration": 4.38,
        "text": "of our product"
      },
      {
        "start": 98.159,
        "duration": 3.96,
        "text": "and I'm going to choose Google Cloud"
      },
      {
        "start": 100.2,
        "duration": 3.84,
        "text": "North America"
      },
      {
        "start": 102.119,
        "duration": 3.601,
        "text": "U.S Central One"
      },
      {
        "start": 104.04,
        "duration": 3.78,
        "text": "and create"
      },
      {
        "start": 105.72,
        "duration": 6.12,
        "text": "and now we'll wait until the database"
      },
      {
        "start": 107.82,
        "duration": 6.6,
        "text": "has a status of active"
      },
      {
        "start": 111.84,
        "duration": 5.279,
        "text": "and with our database created now we'll"
      },
      {
        "start": 114.42,
        "duration": 5.28,
        "text": "go in and create a table"
      },
      {
        "start": 117.119,
        "duration": 4.201,
        "text": "so we'll head over to the cql console"
      },
      {
        "start": 119.7,
        "duration": 4.86,
        "text": "within our database"
      },
      {
        "start": 121.32,
        "duration": 5.7,
        "text": "and we'll paste a create table statement"
      },
      {
        "start": 124.56,
        "duration": 6.36,
        "text": "we're creating a table called all"
      },
      {
        "start": 127.02,
        "duration": 6.84,
        "text": "accounts with three columns an ID a full"
      },
      {
        "start": 130.92,
        "duration": 6.12,
        "text": "name and an email"
      },
      {
        "start": 133.86,
        "duration": 5.94,
        "text": "and with that created now we're going to"
      },
      {
        "start": 137.04,
        "duration": 5.279,
        "text": "create our streaming tenant so we'll"
      },
      {
        "start": 139.8,
        "duration": 5.82,
        "text": "head to create streaming"
      },
      {
        "start": 142.319,
        "duration": 4.741,
        "text": "we'll choose a tenant name of my company"
      },
      {
        "start": 145.62,
        "duration": 3.36,
        "text": "streams"
      },
      {
        "start": 147.06,
        "duration": 5.1,
        "text": "we'll choose Google Cloud as our"
      },
      {
        "start": 148.98,
        "duration": 8.18,
        "text": "provider and U.S Central one as our"
      },
      {
        "start": 152.16,
        "duration": 5.0,
        "text": "region to match where our database is"
      },
      {
        "start": 157.68,
        "duration": 5.639,
        "text": "now with the tenant created we'll go"
      },
      {
        "start": 160.2,
        "duration": 6.42,
        "text": "back and enable CDC"
      },
      {
        "start": 163.319,
        "duration": 5.041,
        "text": "so we head to our company database to"
      },
      {
        "start": 166.62,
        "duration": 5.699,
        "text": "the CDC tab"
      },
      {
        "start": 168.36,
        "duration": 6.06,
        "text": "and we click on enable CDC"
      },
      {
        "start": 172.319,
        "duration": 3.121,
        "text": "choose our new tenant that we just"
      },
      {
        "start": 174.42,
        "duration": 3.0,
        "text": "created"
      },
      {
        "start": 175.44,
        "duration": 3.18,
        "text": "the key space that we created for the"
      },
      {
        "start": 177.42,
        "duration": 5.22,
        "text": "database"
      },
      {
        "start": 178.62,
        "duration": 6.72,
        "text": "and the table name"
      },
      {
        "start": 182.64,
        "duration": 6.06,
        "text": "and now we'll wait for a status of"
      },
      {
        "start": 185.34,
        "duration": 6.6,
        "text": "active for our CDC enablement and with"
      },
      {
        "start": 188.7,
        "duration": 5.7,
        "text": "our CDC feature enabled"
      },
      {
        "start": 191.94,
        "duration": 4.32,
        "text": "now we'll head over back to our"
      },
      {
        "start": 194.4,
        "duration": 4.02,
        "text": "streaming tenant and we're going to"
      },
      {
        "start": 196.26,
        "duration": 3.78,
        "text": "create the sync to connect to"
      },
      {
        "start": 198.42,
        "duration": 6.48,
        "text": "elasticsearch"
      },
      {
        "start": 200.04,
        "duration": 6.8,
        "text": "so we head into sinks we create the sink"
      },
      {
        "start": 204.9,
        "duration": 5.58,
        "text": "we're going to choose a namespace of"
      },
      {
        "start": 206.84,
        "duration": 6.22,
        "text": "Astra CDC this namespace was created for"
      },
      {
        "start": 210.48,
        "duration": 5.94,
        "text": "us when we enabled the CDC feature"
      },
      {
        "start": 213.06,
        "duration": 5.099,
        "text": "we're going to choose a sync type of"
      },
      {
        "start": 216.42,
        "duration": 3.539,
        "text": "elasticsearch"
      },
      {
        "start": 218.159,
        "duration": 4.561,
        "text": "we're going to name it"
      },
      {
        "start": 219.959,
        "duration": 4.981,
        "text": "es account sync"
      },
      {
        "start": 222.72,
        "duration": 4.92,
        "text": "we're going to choose a topic of the"
      },
      {
        "start": 224.94,
        "duration": 5.04,
        "text": "data topic for our table all accounts"
      },
      {
        "start": 227.64,
        "duration": 4.26,
        "text": "this was created for us also when we"
      },
      {
        "start": 229.98,
        "duration": 3.78,
        "text": "enabled the CDC feature"
      },
      {
        "start": 231.9,
        "duration": 3.14,
        "text": "and now we need to input some connection"
      },
      {
        "start": 233.76,
        "duration": 5.22,
        "text": "information"
      },
      {
        "start": 235.04,
        "duration": 5.38,
        "text": "for our sync to make it to elastic cloud"
      },
      {
        "start": 238.98,
        "duration": 3.78,
        "text": "so"
      },
      {
        "start": 240.42,
        "duration": 3.959,
        "text": "we'll head over to our elasticsearch"
      },
      {
        "start": 242.76,
        "duration": 4.74,
        "text": "service"
      },
      {
        "start": 244.379,
        "duration": 6.72,
        "text": "go into the deployment and we're going"
      },
      {
        "start": 247.5,
        "duration": 5.4,
        "text": "to go to management"
      },
      {
        "start": 251.099,
        "duration": 3.92,
        "text": "for this workspace"
      },
      {
        "start": 252.9,
        "duration": 5.1,
        "text": "and for our elasticsearch application"
      },
      {
        "start": 255.019,
        "duration": 5.5,
        "text": "there is a endpoint option to copy to"
      },
      {
        "start": 258.0,
        "duration": 5.34,
        "text": "clipboard so we'll copy that"
      },
      {
        "start": 260.519,
        "duration": 4.501,
        "text": "we'll come back over and here we'll"
      },
      {
        "start": 263.34,
        "duration": 4.799,
        "text": "paste it in there"
      },
      {
        "start": 265.02,
        "duration": 6.6,
        "text": "we're going to name the index something"
      },
      {
        "start": 268.139,
        "duration": 6.481,
        "text": "memorable CDC account messages"
      },
      {
        "start": 271.62,
        "duration": 7.079,
        "text": "the default username for the account is"
      },
      {
        "start": 274.62,
        "duration": 6.18,
        "text": "elastic I will bring in my password for"
      },
      {
        "start": 278.699,
        "duration": 4.321,
        "text": "this"
      },
      {
        "start": 280.8,
        "duration": 4.02,
        "text": "the token and API key can be left alone"
      },
      {
        "start": 283.02,
        "duration": 3.54,
        "text": "because we're using our username and"
      },
      {
        "start": 284.82,
        "duration": 4.319,
        "text": "password"
      },
      {
        "start": 286.56,
        "duration": 5.699,
        "text": "we're going to say ignore record key to"
      },
      {
        "start": 289.139,
        "duration": 5.461,
        "text": "false these are fine we're going to say"
      },
      {
        "start": 292.259,
        "duration": 4.141,
        "text": "strip nulls we're going to leave that to"
      },
      {
        "start": 294.6,
        "duration": 4.379,
        "text": "true the enable schema we're going to"
      },
      {
        "start": 296.4,
        "duration": 4.62,
        "text": "make Mark that true and the copy key"
      },
      {
        "start": 298.979,
        "duration": 3.301,
        "text": "Fields we're going to leave that at"
      },
      {
        "start": 301.02,
        "duration": 2.58,
        "text": "false"
      },
      {
        "start": 302.28,
        "duration": 4.139,
        "text": "all right"
      },
      {
        "start": 303.6,
        "duration": 5.4,
        "text": "and so now let's let the sink get"
      },
      {
        "start": 306.419,
        "duration": 4.081,
        "text": "created and we'll wait for a status of"
      },
      {
        "start": 309.0,
        "duration": 4.02,
        "text": "running"
      },
      {
        "start": 310.5,
        "duration": 3.84,
        "text": "all right and our sync now has a status"
      },
      {
        "start": 313.02,
        "duration": 5.459,
        "text": "of running"
      },
      {
        "start": 314.34,
        "duration": 7.139,
        "text": "and so with our CDC feature enabled and"
      },
      {
        "start": 318.479,
        "duration": 4.261,
        "text": "our elasticsearch sync running and"
      },
      {
        "start": 321.479,
        "duration": 3.541,
        "text": "active"
      },
      {
        "start": 322.74,
        "duration": 4.32,
        "text": "now we're going to add a little bit of"
      },
      {
        "start": 325.02,
        "duration": 5.22,
        "text": "data to the table"
      },
      {
        "start": 327.06,
        "duration": 6.6,
        "text": "and this should be pushed over to"
      },
      {
        "start": 330.24,
        "duration": 4.739,
        "text": "elasticsearch automatically via our CDC"
      },
      {
        "start": 333.66,
        "duration": 4.02,
        "text": "features"
      },
      {
        "start": 334.979,
        "duration": 5.28,
        "text": "so we're going to insert one row of data"
      },
      {
        "start": 337.68,
        "duration": 6.06,
        "text": "to our all accounts with just some nice"
      },
      {
        "start": 340.259,
        "duration": 4.321,
        "text": "information okay nothing good all good"
      },
      {
        "start": 343.74,
        "duration": 3.12,
        "text": "there"
      },
      {
        "start": 344.58,
        "duration": 4.679,
        "text": "now we're going to head over to our"
      },
      {
        "start": 346.86,
        "duration": 4.86,
        "text": "elastic search engine and since we're"
      },
      {
        "start": 349.259,
        "duration": 5.701,
        "text": "going to go into the deployment"
      },
      {
        "start": 351.72,
        "duration": 5.699,
        "text": "and now some things have been created in"
      },
      {
        "start": 354.96,
        "duration": 5.04,
        "text": "our elasticsearch environment"
      },
      {
        "start": 357.419,
        "duration": 4.441,
        "text": "so we're going to on the menu here we're"
      },
      {
        "start": 360.0,
        "duration": 4.199,
        "text": "going to go to management and we're"
      },
      {
        "start": 361.86,
        "duration": 4.86,
        "text": "going to go to stack management"
      },
      {
        "start": 364.199,
        "duration": 4.44,
        "text": "and then we're going to go to the kibana"
      },
      {
        "start": 366.72,
        "duration": 4.68,
        "text": "data views"
      },
      {
        "start": 368.639,
        "duration": 4.5,
        "text": "and in there because we have information"
      },
      {
        "start": 371.4,
        "duration": 5.1,
        "text": "that's been added"
      },
      {
        "start": 373.139,
        "duration": 5.221,
        "text": "elastic tells us we see that and so"
      },
      {
        "start": 376.5,
        "duration": 6.66,
        "text": "let's automatically create a data view"
      },
      {
        "start": 378.36,
        "duration": 7.08,
        "text": "for it we're going to name it the same"
      },
      {
        "start": 383.16,
        "duration": 4.2,
        "text": "the data view is same as the index that"
      },
      {
        "start": 385.44,
        "duration": 3.599,
        "text": "we chose"
      },
      {
        "start": 387.36,
        "duration": 3.72,
        "text": "and create"
      },
      {
        "start": 389.039,
        "duration": 4.44,
        "text": "good everything is saved here it's it's"
      },
      {
        "start": 391.08,
        "duration": 3.6,
        "text": "all automatic not a whole lot of work to"
      },
      {
        "start": 393.479,
        "duration": 3.0,
        "text": "do just clicking"
      },
      {
        "start": 394.68,
        "duration": 3.48,
        "text": "now let's go back and now we actually"
      },
      {
        "start": 396.479,
        "duration": 4.141,
        "text": "want to see the data so we're going to"
      },
      {
        "start": 398.16,
        "duration": 4.379,
        "text": "go to our kibana analytics area to the"
      },
      {
        "start": 400.62,
        "duration": 4.26,
        "text": "Discover Tab and there we have it"
      },
      {
        "start": 402.539,
        "duration": 4.021,
        "text": "because we created that data view it"
      },
      {
        "start": 404.88,
        "duration": 4.02,
        "text": "automatically brought it up and it saw"
      },
      {
        "start": 406.56,
        "duration": 4.139,
        "text": "that we had one record added there's the"
      },
      {
        "start": 408.9,
        "duration": 4.799,
        "text": "information for the record that we added"
      },
      {
        "start": 410.699,
        "duration": 7.381,
        "text": "and we have accomplished the change data"
      },
      {
        "start": 413.699,
        "duration": 4.381,
        "text": "capture pattern foreign"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T18:22:59.750546+00:00"
}