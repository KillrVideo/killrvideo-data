{
  "video_id": "YscdBD5iHsM",
  "title": "DS320.44 Spark SQL: Language Integrated Queries | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.44 Spark SQL: Language Integrated Queries\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:34:05Z",
  "thumbnail": "https://i.ytimg.com/vi/YscdBD5iHsM/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=YscdBD5iHsM",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] when we look at how to create data frames we saw a way to send a cql query to cassandra and get a data frame back out of it now what if we had say a few data frames lying around from a few different queries and we wanted to use the data frame api to do the querying what does that api look like well it turns out it does a pretty good job of recreating the relational algebra that we would find in standard sql we're going to go over that api show a few key methods in it you're going to see all of them look incredibly familiar from the standpoint of sql we won't give you exhaustive examples showing all of them because if you know sql you probably have an idea how to do that already i do want to show you what they are point at the documentation for further details and show you a couple quick examples of how you might use them these are methods we're going to call on a data frame object if i've created a data frame based on some sql query i can for example do a projection on it i can call the select method and create a new data frame that has only the columns that i pass into the select method i can rename columns if i've got a column in the source data frame that i don't want in the new data frame i can rename that with the with column renamed method i've got a distinct method that works a lot like select distinct in sql that's going to give me a new data frame that has only the distinct rows from the source data frame if i want to do some filtering on a data frame i've got the where method or its alias filter and i just pass in conditions to that if i want to do aggregation like averaging or counting i've got a method that lets me do that i can group by i can order by order by has an alias called sort and finally i can limit just like i typically can in sql so a lot of this stuff as i said recreates a part of the relational algebra let's take a look at a few more methods and we'll get the rest of it that might be missing and here we are with join this is a method that gets a lot of people excited of course it's a thing that exists in the rdd api but it also exists in the data frame api you call this on one data frame you pass in the other data frame potentially giving it a join condition and a type now that type lets us switch between inner and left outer and right outer type joins clearly here in the slide we're not giving you the whole api you want to consult the spark documentation for that that's always the best source to go to but this gives you an idea of how to get started we also have the union all intersect and accept methods union all gives us a data frame that has rows that are a combination of the source data frame and the other data frame as long as they're union compatible that is as long as they have the same primary key similarly intersect is going to give us a data frame that has the rows that occur in both the source and the other data frame accept is kind of the opposite of that it's going to give us all the rows that are in the source data frame but not in the other data frame and just look at all these supporting functions i'm not even going to read through all these you can see there's a tremendous number of them and to learn how to use each one please consult the documentation but this lets you know this is a pretty serious api once you get a row out of a cassandra table and you've got it in a data frame there's a lot of work you can do with it all right let's just show a quick example of how to use a little bit of this again exhaustive examples would take forever and this is the kind of thing you want to read the docs for to dig into in detail but let's take a look here now we're going to use the read method on the cassandra sql context and tell it that we want all of the rows from the movies by actor table in the killer video namespace and that's it we're going to load those those are in our data frame now let's walk through this code now you can see we're doing sql kinds of things we're using the relational algebra on this data frame and creating new data frames as we walk through each method call of this fluent api so the first thing we're going to do is filter that's a lot like the where clause we want everything where the actor is johnny depp then we're going to group by the release here then we're going to do two aggregations you recall seeing that aggregate method a couple of slides back what you do with the aggregate method is you give it a map you give it key value pairs the key in each case is going to be the column name that contains the result of the aggregation and the value is going to be the type of aggregation function to run you see we're counting and we're averaging so we're returning two aggregate results for each group however we don't like the default names count one and average rating those lack a certain panache so we're going to rename those to total movies and average rating respectively that data frame that we've got at this point and if you're typing this into a spark shell you'll be able to stop the code at that point run it and see what the schema is but that's got columns in it that we don't want so we're going to call select and we're just going to take out release year total movies and average rating the second two being the newly renamed columns that we've just created then finally we're gonna do some ordering we're gonna order by total movies first and average rating second limit it by three and finally show it and that show is going to trigger the computation and dump the results out in tabular form to the screen just like you see on the slide and look at that we've got three release years 2004 2000 and 2011 shown that's because remember there are other release years in the data set but we're limiting by three and ordering by total movies descending so these are the three if you will most productive johnny depp years that we've got in the data those second two years 2000 and 2011 both had three years in them so those rows get ordered by the average rating of the films released in those years now as a sql query this is intermediate at best right this is not a particularly complex thing if we did this in ansi sql it's the kind of query that relational database developers do all the time and cassandra users have a tough time with in cql this is a thing we would have to come by some other way but it's actually pretty easy to do in spark sql we get access to meaningful analytic capabilities with a pretty simple api",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.799,
        "duration": 4.081,
        "text": "when we look at how to create data"
      },
      {
        "start": 8.16,
        "duration": 5.04,
        "text": "frames we saw a way to send a cql query"
      },
      {
        "start": 10.88,
        "duration": 3.2,
        "text": "to cassandra and get a data frame back"
      },
      {
        "start": 13.2,
        "duration": 3.76,
        "text": "out of it now"
      },
      {
        "start": 14.08,
        "duration": 4.0,
        "text": "what if we had say a few data frames"
      },
      {
        "start": 16.96,
        "duration": 1.84,
        "text": "lying around from a few different"
      },
      {
        "start": 18.08,
        "duration": 3.52,
        "text": "queries"
      },
      {
        "start": 18.8,
        "duration": 3.36,
        "text": "and we wanted to use the data frame api"
      },
      {
        "start": 21.6,
        "duration": 3.759,
        "text": "to"
      },
      {
        "start": 22.16,
        "duration": 5.439,
        "text": "do the querying what does that api"
      },
      {
        "start": 25.359,
        "duration": 3.92,
        "text": "look like well it turns out it does a"
      },
      {
        "start": 27.599,
        "duration": 4.161,
        "text": "pretty good job of recreating the"
      },
      {
        "start": 29.279,
        "duration": 4.96,
        "text": "relational algebra that we would find"
      },
      {
        "start": 31.76,
        "duration": 4.319,
        "text": "in standard sql we're going to go over"
      },
      {
        "start": 34.239,
        "duration": 2.961,
        "text": "that api show a few key methods in it"
      },
      {
        "start": 36.079,
        "duration": 2.64,
        "text": "you're going to see all of them look"
      },
      {
        "start": 37.2,
        "duration": 4.56,
        "text": "incredibly familiar"
      },
      {
        "start": 38.719,
        "duration": 4.801,
        "text": "from the standpoint of sql we won't give"
      },
      {
        "start": 41.76,
        "duration": 2.24,
        "text": "you exhaustive examples showing all of"
      },
      {
        "start": 43.52,
        "duration": 2.08,
        "text": "them"
      },
      {
        "start": 44.0,
        "duration": 3.44,
        "text": "because if you know sql you probably"
      },
      {
        "start": 45.6,
        "duration": 3.04,
        "text": "have an idea how to do that already i do"
      },
      {
        "start": 47.44,
        "duration": 2.959,
        "text": "want to show you what they are"
      },
      {
        "start": 48.64,
        "duration": 3.439,
        "text": "point at the documentation for further"
      },
      {
        "start": 50.399,
        "duration": 3.201,
        "text": "details and show you a couple quick"
      },
      {
        "start": 52.079,
        "duration": 2.64,
        "text": "examples of how you might use them these"
      },
      {
        "start": 53.6,
        "duration": 3.2,
        "text": "are methods we're going to call"
      },
      {
        "start": 54.719,
        "duration": 4.48,
        "text": "on a data frame object if i've created a"
      },
      {
        "start": 56.8,
        "duration": 4.399,
        "text": "data frame based on some sql query"
      },
      {
        "start": 59.199,
        "duration": 4.321,
        "text": "i can for example do a projection on it"
      },
      {
        "start": 61.199,
        "duration": 4.721,
        "text": "i can call the select method"
      },
      {
        "start": 63.52,
        "duration": 4.639,
        "text": "and create a new data frame that has"
      },
      {
        "start": 65.92,
        "duration": 4.96,
        "text": "only the columns that i pass into"
      },
      {
        "start": 68.159,
        "duration": 4.0,
        "text": "the select method i can rename columns"
      },
      {
        "start": 70.88,
        "duration": 2.8,
        "text": "if i've got a column in the source data"
      },
      {
        "start": 72.159,
        "duration": 1.921,
        "text": "frame that i don't want in the new data"
      },
      {
        "start": 73.68,
        "duration": 2.079,
        "text": "frame"
      },
      {
        "start": 74.08,
        "duration": 4.079,
        "text": "i can rename that with the with column"
      },
      {
        "start": 75.759,
        "duration": 4.161,
        "text": "renamed method i've got a distinct"
      },
      {
        "start": 78.159,
        "duration": 3.121,
        "text": "method that works a lot like select"
      },
      {
        "start": 79.92,
        "duration": 2.96,
        "text": "distinct in sql"
      },
      {
        "start": 81.28,
        "duration": 3.36,
        "text": "that's going to give me a new data frame"
      },
      {
        "start": 82.88,
        "duration": 4.16,
        "text": "that has only the distinct"
      },
      {
        "start": 84.64,
        "duration": 3.68,
        "text": "rows from the source data frame if i"
      },
      {
        "start": 87.04,
        "duration": 3.28,
        "text": "want to do some filtering"
      },
      {
        "start": 88.32,
        "duration": 3.68,
        "text": "on a data frame i've got the where"
      },
      {
        "start": 90.32,
        "duration": 3.92,
        "text": "method or its alias"
      },
      {
        "start": 92.0,
        "duration": 3.6,
        "text": "filter and i just pass in conditions to"
      },
      {
        "start": 94.24,
        "duration": 4.0,
        "text": "that if i want to do"
      },
      {
        "start": 95.6,
        "duration": 4.4,
        "text": "aggregation like averaging or counting"
      },
      {
        "start": 98.24,
        "duration": 4.879,
        "text": "i've got a method that lets me do that"
      },
      {
        "start": 100.0,
        "duration": 3.84,
        "text": "i can group by i can order by order by"
      },
      {
        "start": 103.119,
        "duration": 2.721,
        "text": "has an"
      },
      {
        "start": 103.84,
        "duration": 3.44,
        "text": "alias called sort and finally i can"
      },
      {
        "start": 105.84,
        "duration": 4.08,
        "text": "limit just like i typically can"
      },
      {
        "start": 107.28,
        "duration": 4.159,
        "text": "in sql so a lot of this stuff as i said"
      },
      {
        "start": 109.92,
        "duration": 3.44,
        "text": "recreates a part of"
      },
      {
        "start": 111.439,
        "duration": 3.281,
        "text": "the relational algebra let's take a look"
      },
      {
        "start": 113.36,
        "duration": 2.799,
        "text": "at a few more methods and we'll get the"
      },
      {
        "start": 114.72,
        "duration": 3.6,
        "text": "rest of it that might be missing"
      },
      {
        "start": 116.159,
        "duration": 3.6,
        "text": "and here we are with join this is a"
      },
      {
        "start": 118.32,
        "duration": 2.799,
        "text": "method that gets a lot of people excited"
      },
      {
        "start": 119.759,
        "duration": 2.72,
        "text": "of course it's a thing that exists in"
      },
      {
        "start": 121.119,
        "duration": 3.841,
        "text": "the rdd api"
      },
      {
        "start": 122.479,
        "duration": 4.32,
        "text": "but it also exists in the data frame api"
      },
      {
        "start": 124.96,
        "duration": 2.24,
        "text": "you call this on one data frame you pass"
      },
      {
        "start": 126.799,
        "duration": 2.561,
        "text": "in"
      },
      {
        "start": 127.2,
        "duration": 3.6,
        "text": "the other data frame potentially giving"
      },
      {
        "start": 129.36,
        "duration": 3.76,
        "text": "it a join condition"
      },
      {
        "start": 130.8,
        "duration": 4.32,
        "text": "and a type now that type lets us switch"
      },
      {
        "start": 133.12,
        "duration": 2.56,
        "text": "between inner and left outer and right"
      },
      {
        "start": 135.12,
        "duration": 2.32,
        "text": "outer"
      },
      {
        "start": 135.68,
        "duration": 3.36,
        "text": "type joins clearly here in the slide"
      },
      {
        "start": 137.44,
        "duration": 3.2,
        "text": "we're not giving you the whole api you"
      },
      {
        "start": 139.04,
        "duration": 2.08,
        "text": "want to consult the spark documentation"
      },
      {
        "start": 140.64,
        "duration": 2.239,
        "text": "for that"
      },
      {
        "start": 141.12,
        "duration": 3.28,
        "text": "that's always the best source to go to"
      },
      {
        "start": 142.879,
        "duration": 3.201,
        "text": "but this gives you an idea of"
      },
      {
        "start": 144.4,
        "duration": 3.36,
        "text": "how to get started we also have the"
      },
      {
        "start": 146.08,
        "duration": 4.64,
        "text": "union all intersect"
      },
      {
        "start": 147.76,
        "duration": 4.32,
        "text": "and accept methods union all gives us a"
      },
      {
        "start": 150.72,
        "duration": 4.239,
        "text": "data frame that has rows"
      },
      {
        "start": 152.08,
        "duration": 4.159,
        "text": "that are a combination of the source"
      },
      {
        "start": 154.959,
        "duration": 3.28,
        "text": "data frame and the"
      },
      {
        "start": 156.239,
        "duration": 3.681,
        "text": "other data frame as long as they're"
      },
      {
        "start": 158.239,
        "duration": 3.601,
        "text": "union compatible"
      },
      {
        "start": 159.92,
        "duration": 3.12,
        "text": "that is as long as they have the same"
      },
      {
        "start": 161.84,
        "duration": 2.96,
        "text": "primary key"
      },
      {
        "start": 163.04,
        "duration": 3.52,
        "text": "similarly intersect is going to give us"
      },
      {
        "start": 164.8,
        "duration": 4.799,
        "text": "a data frame that has the rows that"
      },
      {
        "start": 166.56,
        "duration": 5.36,
        "text": "occur in both the source and the other"
      },
      {
        "start": 169.599,
        "duration": 3.201,
        "text": "data frame accept is kind of the"
      },
      {
        "start": 171.92,
        "duration": 2.08,
        "text": "opposite of that"
      },
      {
        "start": 172.8,
        "duration": 3.439,
        "text": "it's going to give us all the rows that"
      },
      {
        "start": 174.0,
        "duration": 4.879,
        "text": "are in the source data frame but not"
      },
      {
        "start": 176.239,
        "duration": 3.92,
        "text": "in the other data frame and just look at"
      },
      {
        "start": 178.879,
        "duration": 2.561,
        "text": "all these supporting functions"
      },
      {
        "start": 180.159,
        "duration": 3.36,
        "text": "i'm not even going to read through all"
      },
      {
        "start": 181.44,
        "duration": 2.56,
        "text": "these you can see there's a tremendous"
      },
      {
        "start": 183.519,
        "duration": 2.64,
        "text": "number of"
      },
      {
        "start": 184.0,
        "duration": 4.08,
        "text": "them and to learn how to use each one"
      },
      {
        "start": 186.159,
        "duration": 4.321,
        "text": "please consult the documentation"
      },
      {
        "start": 188.08,
        "duration": 3.519,
        "text": "but this lets you know this is a pretty"
      },
      {
        "start": 190.48,
        "duration": 2.88,
        "text": "serious api"
      },
      {
        "start": 191.599,
        "duration": 3.841,
        "text": "once you get a row out of a cassandra"
      },
      {
        "start": 193.36,
        "duration": 4.239,
        "text": "table and you've got it in a data frame"
      },
      {
        "start": 195.44,
        "duration": 3.84,
        "text": "there's a lot of work you can do with it"
      },
      {
        "start": 197.599,
        "duration": 3.441,
        "text": "all right let's just show a quick"
      },
      {
        "start": 199.28,
        "duration": 3.28,
        "text": "example of how to use a little bit of"
      },
      {
        "start": 201.04,
        "duration": 2.4,
        "text": "this again exhaustive examples would"
      },
      {
        "start": 202.56,
        "duration": 2.0,
        "text": "take forever"
      },
      {
        "start": 203.44,
        "duration": 2.799,
        "text": "and this is the kind of thing you want"
      },
      {
        "start": 204.56,
        "duration": 3.679,
        "text": "to read the docs for to dig into in"
      },
      {
        "start": 206.239,
        "duration": 4.401,
        "text": "detail but let's take a look here"
      },
      {
        "start": 208.239,
        "duration": 4.0,
        "text": "now we're going to use the read method"
      },
      {
        "start": 210.64,
        "duration": 4.0,
        "text": "on the cassandra sql context"
      },
      {
        "start": 212.239,
        "duration": 4.56,
        "text": "and tell it that we want all of the rows"
      },
      {
        "start": 214.64,
        "duration": 4.48,
        "text": "from the movies by actor table"
      },
      {
        "start": 216.799,
        "duration": 3.44,
        "text": "in the killer video namespace and that's"
      },
      {
        "start": 219.12,
        "duration": 2.8,
        "text": "it we're going to load those"
      },
      {
        "start": 220.239,
        "duration": 3.201,
        "text": "those are in our data frame now let's"
      },
      {
        "start": 221.92,
        "duration": 2.48,
        "text": "walk through this code now you can see"
      },
      {
        "start": 223.44,
        "duration": 3.2,
        "text": "we're doing"
      },
      {
        "start": 224.4,
        "duration": 3.68,
        "text": "sql kinds of things we're using the"
      },
      {
        "start": 226.64,
        "duration": 3.44,
        "text": "relational algebra"
      },
      {
        "start": 228.08,
        "duration": 3.519,
        "text": "on this data frame and creating new data"
      },
      {
        "start": 230.08,
        "duration": 2.0,
        "text": "frames as we walk through each method"
      },
      {
        "start": 231.599,
        "duration": 2.64,
        "text": "call"
      },
      {
        "start": 232.08,
        "duration": 3.12,
        "text": "of this fluent api so the first thing"
      },
      {
        "start": 234.239,
        "duration": 2.801,
        "text": "we're going to do is"
      },
      {
        "start": 235.2,
        "duration": 3.52,
        "text": "filter that's a lot like the where"
      },
      {
        "start": 237.04,
        "duration": 2.399,
        "text": "clause we want everything where the"
      },
      {
        "start": 238.72,
        "duration": 3.28,
        "text": "actor"
      },
      {
        "start": 239.439,
        "duration": 4.401,
        "text": "is johnny depp then we're going to group"
      },
      {
        "start": 242.0,
        "duration": 4.319,
        "text": "by the release here"
      },
      {
        "start": 243.84,
        "duration": 4.16,
        "text": "then we're going to do two aggregations"
      },
      {
        "start": 246.319,
        "duration": 3.441,
        "text": "you recall seeing that aggregate method"
      },
      {
        "start": 248.0,
        "duration": 3.519,
        "text": "a couple of slides back what you do with"
      },
      {
        "start": 249.76,
        "duration": 4.08,
        "text": "the aggregate method is you give it a"
      },
      {
        "start": 251.519,
        "duration": 4.0,
        "text": "map you give it key value pairs the key"
      },
      {
        "start": 253.84,
        "duration": 2.08,
        "text": "in each case is going to be the column"
      },
      {
        "start": 255.519,
        "duration": 1.84,
        "text": "name"
      },
      {
        "start": 255.92,
        "duration": 3.36,
        "text": "that contains the result of the"
      },
      {
        "start": 257.359,
        "duration": 3.84,
        "text": "aggregation and the value"
      },
      {
        "start": 259.28,
        "duration": 4.0,
        "text": "is going to be the type of aggregation"
      },
      {
        "start": 261.199,
        "duration": 4.161,
        "text": "function to run you see we're counting"
      },
      {
        "start": 263.28,
        "duration": 4.479,
        "text": "and we're averaging so we're returning"
      },
      {
        "start": 265.36,
        "duration": 4.88,
        "text": "two aggregate results"
      },
      {
        "start": 267.759,
        "duration": 4.321,
        "text": "for each group however we don't like the"
      },
      {
        "start": 270.24,
        "duration": 3.679,
        "text": "default names count one and"
      },
      {
        "start": 272.08,
        "duration": 3.52,
        "text": "average rating those lack a certain"
      },
      {
        "start": 273.919,
        "duration": 2.961,
        "text": "panache so we're going to rename those"
      },
      {
        "start": 275.6,
        "duration": 4.08,
        "text": "to total movies"
      },
      {
        "start": 276.88,
        "duration": 4.8,
        "text": "and average rating respectively that"
      },
      {
        "start": 279.68,
        "duration": 3.6,
        "text": "data frame that we've got at this point"
      },
      {
        "start": 281.68,
        "duration": 3.519,
        "text": "and if you're typing this into"
      },
      {
        "start": 283.28,
        "duration": 3.12,
        "text": "a spark shell you'll be able to stop the"
      },
      {
        "start": 285.199,
        "duration": 3.361,
        "text": "code at that point"
      },
      {
        "start": 286.4,
        "duration": 3.84,
        "text": "run it and see what the schema is but"
      },
      {
        "start": 288.56,
        "duration": 2.079,
        "text": "that's got columns in it that we don't"
      },
      {
        "start": 290.24,
        "duration": 1.92,
        "text": "want"
      },
      {
        "start": 290.639,
        "duration": 3.441,
        "text": "so we're going to call select and we're"
      },
      {
        "start": 292.16,
        "duration": 4.08,
        "text": "just going to take out release year"
      },
      {
        "start": 294.08,
        "duration": 4.72,
        "text": "total movies and average rating the"
      },
      {
        "start": 296.24,
        "duration": 4.72,
        "text": "second two being the newly renamed"
      },
      {
        "start": 298.8,
        "duration": 3.92,
        "text": "columns that we've just created then"
      },
      {
        "start": 300.96,
        "duration": 3.76,
        "text": "finally we're gonna do some ordering"
      },
      {
        "start": 302.72,
        "duration": 4.8,
        "text": "we're gonna order by total movies first"
      },
      {
        "start": 304.72,
        "duration": 3.28,
        "text": "and average rating second limit it by"
      },
      {
        "start": 307.52,
        "duration": 3.2,
        "text": "three"
      },
      {
        "start": 308.0,
        "duration": 4.16,
        "text": "and finally show it and that show is"
      },
      {
        "start": 310.72,
        "duration": 3.759,
        "text": "going to trigger the computation"
      },
      {
        "start": 312.16,
        "duration": 3.36,
        "text": "and dump the results out in tabular form"
      },
      {
        "start": 314.479,
        "duration": 3.121,
        "text": "to the screen"
      },
      {
        "start": 315.52,
        "duration": 3.28,
        "text": "just like you see on the slide and look"
      },
      {
        "start": 317.6,
        "duration": 4.72,
        "text": "at that we've got"
      },
      {
        "start": 318.8,
        "duration": 6.16,
        "text": "three release years 2004 2000 and 2011"
      },
      {
        "start": 322.32,
        "duration": 4.08,
        "text": "shown that's because remember there are"
      },
      {
        "start": 324.96,
        "duration": 3.28,
        "text": "other release years in the data set but"
      },
      {
        "start": 326.4,
        "duration": 3.44,
        "text": "we're limiting by three and ordering by"
      },
      {
        "start": 328.24,
        "duration": 4.08,
        "text": "total movies descending"
      },
      {
        "start": 329.84,
        "duration": 4.4,
        "text": "so these are the three if you will most"
      },
      {
        "start": 332.32,
        "duration": 3.76,
        "text": "productive johnny depp years"
      },
      {
        "start": 334.24,
        "duration": 3.84,
        "text": "that we've got in the data those second"
      },
      {
        "start": 336.08,
        "duration": 3.839,
        "text": "two years 2000 and 2011"
      },
      {
        "start": 338.08,
        "duration": 4.08,
        "text": "both had three years in them so those"
      },
      {
        "start": 339.919,
        "duration": 4.801,
        "text": "rows get ordered by the average rating"
      },
      {
        "start": 342.16,
        "duration": 5.92,
        "text": "of the films released in those years now"
      },
      {
        "start": 344.72,
        "duration": 5.28,
        "text": "as a sql query this is intermediate at"
      },
      {
        "start": 348.08,
        "duration": 3.6,
        "text": "best right this is not a particularly"
      },
      {
        "start": 350.0,
        "duration": 4.4,
        "text": "complex thing if we did this"
      },
      {
        "start": 351.68,
        "duration": 4.32,
        "text": "in ansi sql it's the kind of query that"
      },
      {
        "start": 354.4,
        "duration": 2.239,
        "text": "relational database developers do all"
      },
      {
        "start": 356.0,
        "duration": 3.36,
        "text": "the time"
      },
      {
        "start": 356.639,
        "duration": 3.041,
        "text": "and cassandra users have a tough time"
      },
      {
        "start": 359.36,
        "duration": 2.08,
        "text": "with"
      },
      {
        "start": 359.68,
        "duration": 3.359,
        "text": "in cql this is a thing we would have to"
      },
      {
        "start": 361.44,
        "duration": 4.4,
        "text": "come by some other way"
      },
      {
        "start": 363.039,
        "duration": 4.961,
        "text": "but it's actually pretty easy to do in"
      },
      {
        "start": 365.84,
        "duration": 4.079,
        "text": "spark sql we get access to meaningful"
      },
      {
        "start": 368.0,
        "duration": 11.36,
        "text": "analytic capabilities with a pretty"
      },
      {
        "start": 369.919,
        "duration": 9.441,
        "text": "simple api"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:10:21.120824+00:00"
}