{
  "video_id": "-MkFhtnT2d8",
  "title": "DS220.23 Data Model Migration | Data Modeling with Apache Cassandra",
  "description": "#DataStaxAcademy #DS220\nDS220.23 Data Model Migration\nHow do we migrate our existing data model into a new one when using Apache Cassandra? In this unit, we will explore different way that it can be done, and go through some important points to keep in mind while doing so.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-14T09:30:05Z",
  "thumbnail": "https://i.ytimg.com/vi/-MkFhtnT2d8/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "data_modeling",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=-MkFhtnT2d8",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] nobody should really want to change their data model but it is something that may come up from time to time when it happens one common issue that people run into is how to migrate their data from their existing data model into the new one in this video we'll be exploring different ways it can be done and reviewing some of the important points to keep in mind while doing so earlier when we talked about designing the primary key for a table there was a lot of emphasis on the idea that cannot be changed once you created the table with the primary key and started loading data it's not simple to change it afterwards however when you get to the end of the road there just may not be any alternative but to make use of a new primary key and what that means is that you'll need to create a completely new table to use that new primary key with and then migrate your data into that table assuming that you complete that without any issues you can either just keep the old table or drop it depending on your use case often enough a large data model can be stored completely in a cql file as a set of create table statements which can then be easily executed be careful if you intend to make data model changes using a script though when it comes to schema changes cassandra does it in a way that is separate from normal write operations in particular the schema is something that is propagated to all of the nodes in a cluster with sufficiently large clusters this can be problematic if trying to execute these schema changes as quickly as possible there is no guaranteed ordering in which the schema propagates so it is possible to run into race conditions which can cause schemas on different nodes to be out of sync when out of sync this can cause all sorts of bad things to happen you can use the following as a guideline to safely make changes to your table schema first make sure that you only execute one create or drop statement at a time make sure you wait long enough so that the schema change completely propagates to every node in the cluster before moving to the next one you can use the node tool command describe cluster to check the schema version for each node and ensure that they match before moving on to the next create or drop command and so on with a new set of tables in place you'll need to move your data somewhere from the old table to the new fortunately with data sacs enterprise there are several options that will allow you to do so in particular is the analytics component which makes use of the integrated apache spark platform since it allows you to perform analytics across your entire cluster it is the perfect candidate to help migrate data across tables especially since the etl operations needed to migrate the data is generally straightforward and shouldn't need any complicated coding if it's just the primary key being changed migrating your data may be as simple as extracting and loading using the cassandra table and saved to cassandra functions in spark all you need to do is specify the old table name and the new table name in the appropriate functions however even if the table has changed significantly spark will enable you to transform the old data so that it matches how it needs to be loaded in the new table this would require getting more in-depth into spark than i'd want to right now but feel free to check out our ds320 course on dse analytics which will cover not only reading and writing data into tables but also the different ways you can transform and manipulate that data another consideration is with live data what happens if you're trying to migrate to the new data model while keeping your application online and available that basically means that the new updates are being made to the base table while the etl process is running that means that it's possible that the new table may miss out on that new data to handle that it's important to plan ahead change the application so that it writes to both your base and your new table as any new updates are applied to both tables you can go ahead with the etl while any read requests will still query from the base table once completed the data in both tables should be exactly the same go ahead and then have your application switch over to only using your new table for both reads and writes finally you have the option to drop the old table if it's not still being used in other parts of your application however if you want to stay fairly cautious you can always continue to write to the old table for some period of time until you know for sure that the new table is working as expected although spark would be one of the most convenient ways to migrate your data there are some other alternatives they may not necessarily be better but they are alternatives and in some cases it may make more sense for one you can use the cql shell tool to export your data using the copy command with the data saved as a csv file you can then transform the data as needed for your new data model and then copy to export your data back into the database another way would be to use the dataset drivers to actually query the data transform as necessary on the application side and then write it back to the new table yeah maybe it's better you just stick with spark then so i'm saying that you may need to change the primary key for a table but what's the justification behind it well obviously we wouldn't want to change anything if it's working however if there is something that is causing a problem it's better to fix that sooner rather than later are there certain partitions that are too large the new requirements get passed down for your application keep in mind that even if you do create a new table with a different primary key the original table may still be used in other parts of your application so don't drop it just yet with the new tables that you create don't forget to go over the analysis and validation steps again to make sure that your new data model does not contain easily avoidable problems",
    "segments": [
      {
        "start": 1.47,
        "duration": 5.32,
        "text": "[Music]"
      },
      {
        "start": 7.279,
        "duration": 2.24,
        "text": "nobody should really want to change"
      },
      {
        "start": 8.639,
        "duration": 2.241,
        "text": "their data model"
      },
      {
        "start": 9.519,
        "duration": 3.521,
        "text": "but it is something that may come up"
      },
      {
        "start": 10.88,
        "duration": 4.48,
        "text": "from time to time when it happens"
      },
      {
        "start": 13.04,
        "duration": 3.76,
        "text": "one common issue that people run into is"
      },
      {
        "start": 15.36,
        "duration": 2.56,
        "text": "how to migrate their data from their"
      },
      {
        "start": 16.8,
        "duration": 3.44,
        "text": "existing data model"
      },
      {
        "start": 17.92,
        "duration": 4.24,
        "text": "into the new one in this video we'll be"
      },
      {
        "start": 20.24,
        "duration": 3.36,
        "text": "exploring different ways it can be done"
      },
      {
        "start": 22.16,
        "duration": 3.84,
        "text": "and reviewing some of the important"
      },
      {
        "start": 23.6,
        "duration": 3.999,
        "text": "points to keep in mind while doing so"
      },
      {
        "start": 26.0,
        "duration": 3.199,
        "text": "earlier when we talked about designing"
      },
      {
        "start": 27.599,
        "duration": 3.44,
        "text": "the primary key for a table"
      },
      {
        "start": 29.199,
        "duration": 3.2,
        "text": "there was a lot of emphasis on the idea"
      },
      {
        "start": 31.039,
        "duration": 2.641,
        "text": "that cannot be changed"
      },
      {
        "start": 32.399,
        "duration": 3.601,
        "text": "once you created the table with the"
      },
      {
        "start": 33.68,
        "duration": 4.24,
        "text": "primary key and started loading data"
      },
      {
        "start": 36.0,
        "duration": 3.6,
        "text": "it's not simple to change it afterwards"
      },
      {
        "start": 37.92,
        "duration": 2.24,
        "text": "however when you get to the end of the"
      },
      {
        "start": 39.6,
        "duration": 2.32,
        "text": "road"
      },
      {
        "start": 40.16,
        "duration": 3.84,
        "text": "there just may not be any alternative"
      },
      {
        "start": 41.92,
        "duration": 3.76,
        "text": "but to make use of a new primary key"
      },
      {
        "start": 44.0,
        "duration": 3.68,
        "text": "and what that means is that you'll need"
      },
      {
        "start": 45.68,
        "duration": 3.52,
        "text": "to create a completely new table to use"
      },
      {
        "start": 47.68,
        "duration": 3.28,
        "text": "that new primary key with"
      },
      {
        "start": 49.2,
        "duration": 3.92,
        "text": "and then migrate your data into that"
      },
      {
        "start": 50.96,
        "duration": 3.36,
        "text": "table assuming that you complete that"
      },
      {
        "start": 53.12,
        "duration": 2.88,
        "text": "without any issues"
      },
      {
        "start": 54.32,
        "duration": 3.919,
        "text": "you can either just keep the old table"
      },
      {
        "start": 56.0,
        "duration": 4.32,
        "text": "or drop it depending on your use case"
      },
      {
        "start": 58.239,
        "duration": 4.16,
        "text": "often enough a large data model can be"
      },
      {
        "start": 60.32,
        "duration": 3.919,
        "text": "stored completely in a cql file"
      },
      {
        "start": 62.399,
        "duration": 4.161,
        "text": "as a set of create table statements"
      },
      {
        "start": 64.239,
        "duration": 4.001,
        "text": "which can then be easily executed"
      },
      {
        "start": 66.56,
        "duration": 3.44,
        "text": "be careful if you intend to make data"
      },
      {
        "start": 68.24,
        "duration": 3.44,
        "text": "model changes using a script though"
      },
      {
        "start": 70.0,
        "duration": 3.36,
        "text": "when it comes to schema changes"
      },
      {
        "start": 71.68,
        "duration": 3.84,
        "text": "cassandra does it in a way that is"
      },
      {
        "start": 73.36,
        "duration": 4.16,
        "text": "separate from normal write operations"
      },
      {
        "start": 75.52,
        "duration": 3.76,
        "text": "in particular the schema is something"
      },
      {
        "start": 77.52,
        "duration": 2.56,
        "text": "that is propagated to all of the nodes"
      },
      {
        "start": 79.28,
        "duration": 2.8,
        "text": "in a cluster"
      },
      {
        "start": 80.08,
        "duration": 3.28,
        "text": "with sufficiently large clusters this"
      },
      {
        "start": 82.08,
        "duration": 2.88,
        "text": "can be problematic"
      },
      {
        "start": 83.36,
        "duration": 3.439,
        "text": "if trying to execute these schema"
      },
      {
        "start": 84.96,
        "duration": 3.839,
        "text": "changes as quickly as possible"
      },
      {
        "start": 86.799,
        "duration": 3.36,
        "text": "there is no guaranteed ordering in which"
      },
      {
        "start": 88.799,
        "duration": 3.041,
        "text": "the schema propagates"
      },
      {
        "start": 90.159,
        "duration": 3.681,
        "text": "so it is possible to run into race"
      },
      {
        "start": 91.84,
        "duration": 2.72,
        "text": "conditions which can cause schemas on"
      },
      {
        "start": 93.84,
        "duration": 3.76,
        "text": "different nodes"
      },
      {
        "start": 94.56,
        "duration": 4.64,
        "text": "to be out of sync when out of sync this"
      },
      {
        "start": 97.6,
        "duration": 2.159,
        "text": "can cause all sorts of bad things to"
      },
      {
        "start": 99.2,
        "duration": 2.4,
        "text": "happen"
      },
      {
        "start": 99.759,
        "duration": 3.441,
        "text": "you can use the following as a guideline"
      },
      {
        "start": 101.6,
        "duration": 2.4,
        "text": "to safely make changes to your table"
      },
      {
        "start": 103.2,
        "duration": 2.72,
        "text": "schema"
      },
      {
        "start": 104.0,
        "duration": 4.32,
        "text": "first make sure that you only execute"
      },
      {
        "start": 105.92,
        "duration": 3.92,
        "text": "one create or drop statement at a time"
      },
      {
        "start": 108.32,
        "duration": 3.439,
        "text": "make sure you wait long enough so that"
      },
      {
        "start": 109.84,
        "duration": 3.36,
        "text": "the schema change completely propagates"
      },
      {
        "start": 111.759,
        "duration": 3.68,
        "text": "to every node in the cluster"
      },
      {
        "start": 113.2,
        "duration": 3.84,
        "text": "before moving to the next one you can"
      },
      {
        "start": 115.439,
        "duration": 2.32,
        "text": "use the node tool command describe"
      },
      {
        "start": 117.04,
        "duration": 2.48,
        "text": "cluster"
      },
      {
        "start": 117.759,
        "duration": 3.761,
        "text": "to check the schema version for each"
      },
      {
        "start": 119.52,
        "duration": 3.68,
        "text": "node and ensure that they match before"
      },
      {
        "start": 121.52,
        "duration": 4.32,
        "text": "moving on to the next create"
      },
      {
        "start": 123.2,
        "duration": 3.84,
        "text": "or drop command and so on with a new set"
      },
      {
        "start": 125.84,
        "duration": 2.72,
        "text": "of tables in place"
      },
      {
        "start": 127.04,
        "duration": 3.359,
        "text": "you'll need to move your data somewhere"
      },
      {
        "start": 128.56,
        "duration": 3.84,
        "text": "from the old table to the new"
      },
      {
        "start": 130.399,
        "duration": 3.521,
        "text": "fortunately with data sacs enterprise"
      },
      {
        "start": 132.4,
        "duration": 3.12,
        "text": "there are several options that will"
      },
      {
        "start": 133.92,
        "duration": 3.76,
        "text": "allow you to do so"
      },
      {
        "start": 135.52,
        "duration": 4.0,
        "text": "in particular is the analytics component"
      },
      {
        "start": 137.68,
        "duration": 3.52,
        "text": "which makes use of the integrated apache"
      },
      {
        "start": 139.52,
        "duration": 3.52,
        "text": "spark platform"
      },
      {
        "start": 141.2,
        "duration": 3.44,
        "text": "since it allows you to perform analytics"
      },
      {
        "start": 143.04,
        "duration": 3.199,
        "text": "across your entire cluster"
      },
      {
        "start": 144.64,
        "duration": 3.28,
        "text": "it is the perfect candidate to help"
      },
      {
        "start": 146.239,
        "duration": 3.601,
        "text": "migrate data across tables"
      },
      {
        "start": 147.92,
        "duration": 3.76,
        "text": "especially since the etl operations"
      },
      {
        "start": 149.84,
        "duration": 2.64,
        "text": "needed to migrate the data is generally"
      },
      {
        "start": 151.68,
        "duration": 2.32,
        "text": "straightforward"
      },
      {
        "start": 152.48,
        "duration": 3.52,
        "text": "and shouldn't need any complicated"
      },
      {
        "start": 154.0,
        "duration": 4.239,
        "text": "coding if it's just the primary key"
      },
      {
        "start": 156.0,
        "duration": 4.08,
        "text": "being changed migrating your data may be"
      },
      {
        "start": 158.239,
        "duration": 3.201,
        "text": "as simple as extracting and loading"
      },
      {
        "start": 160.08,
        "duration": 3.68,
        "text": "using the cassandra table"
      },
      {
        "start": 161.44,
        "duration": 4.64,
        "text": "and saved to cassandra functions in"
      },
      {
        "start": 163.76,
        "duration": 3.199,
        "text": "spark all you need to do is specify the"
      },
      {
        "start": 166.08,
        "duration": 2.159,
        "text": "old table name"
      },
      {
        "start": 166.959,
        "duration": 3.041,
        "text": "and the new table name in the"
      },
      {
        "start": 168.239,
        "duration": 3.841,
        "text": "appropriate functions"
      },
      {
        "start": 170.0,
        "duration": 3.28,
        "text": "however even if the table has changed"
      },
      {
        "start": 172.08,
        "duration": 3.04,
        "text": "significantly"
      },
      {
        "start": 173.28,
        "duration": 3.84,
        "text": "spark will enable you to transform the"
      },
      {
        "start": 175.12,
        "duration": 3.6,
        "text": "old data so that it matches how it needs"
      },
      {
        "start": 177.12,
        "duration": 3.119,
        "text": "to be loaded in the new table"
      },
      {
        "start": 178.72,
        "duration": 3.36,
        "text": "this would require getting more in-depth"
      },
      {
        "start": 180.239,
        "duration": 4.08,
        "text": "into spark than i'd want to right now"
      },
      {
        "start": 182.08,
        "duration": 3.92,
        "text": "but feel free to check out our ds320"
      },
      {
        "start": 184.319,
        "duration": 3.28,
        "text": "course on dse analytics"
      },
      {
        "start": 186.0,
        "duration": 3.04,
        "text": "which will cover not only reading and"
      },
      {
        "start": 187.599,
        "duration": 2.801,
        "text": "writing data into tables"
      },
      {
        "start": 189.04,
        "duration": 3.52,
        "text": "but also the different ways you can"
      },
      {
        "start": 190.4,
        "duration": 4.64,
        "text": "transform and manipulate that data"
      },
      {
        "start": 192.56,
        "duration": 4.16,
        "text": "another consideration is with live data"
      },
      {
        "start": 195.04,
        "duration": 2.96,
        "text": "what happens if you're trying to migrate"
      },
      {
        "start": 196.72,
        "duration": 2.96,
        "text": "to the new data model"
      },
      {
        "start": 198.0,
        "duration": 3.28,
        "text": "while keeping your application online"
      },
      {
        "start": 199.68,
        "duration": 3.04,
        "text": "and available"
      },
      {
        "start": 201.28,
        "duration": 3.44,
        "text": "that basically means that the new"
      },
      {
        "start": 202.72,
        "duration": 4.4,
        "text": "updates are being made to the base table"
      },
      {
        "start": 204.72,
        "duration": 4.0,
        "text": "while the etl process is running that"
      },
      {
        "start": 207.12,
        "duration": 3.759,
        "text": "means that it's possible that the new"
      },
      {
        "start": 208.72,
        "duration": 3.92,
        "text": "table may miss out on that new data"
      },
      {
        "start": 210.879,
        "duration": 3.92,
        "text": "to handle that it's important to plan"
      },
      {
        "start": 212.64,
        "duration": 4.0,
        "text": "ahead change the application"
      },
      {
        "start": 214.799,
        "duration": 3.121,
        "text": "so that it writes to both your base and"
      },
      {
        "start": 216.64,
        "duration": 3.04,
        "text": "your new table"
      },
      {
        "start": 217.92,
        "duration": 4.08,
        "text": "as any new updates are applied to both"
      },
      {
        "start": 219.68,
        "duration": 4.32,
        "text": "tables you can go ahead with the etl"
      },
      {
        "start": 222.0,
        "duration": 3.36,
        "text": "while any read requests will still query"
      },
      {
        "start": 224.0,
        "duration": 3.68,
        "text": "from the base table"
      },
      {
        "start": 225.36,
        "duration": 4.239,
        "text": "once completed the data in both tables"
      },
      {
        "start": 227.68,
        "duration": 3.68,
        "text": "should be exactly the same"
      },
      {
        "start": 229.599,
        "duration": 4.0,
        "text": "go ahead and then have your application"
      },
      {
        "start": 231.36,
        "duration": 5.12,
        "text": "switch over to only using your new table"
      },
      {
        "start": 233.599,
        "duration": 4.64,
        "text": "for both reads and writes finally you"
      },
      {
        "start": 236.48,
        "duration": 3.36,
        "text": "have the option to drop the old table"
      },
      {
        "start": 238.239,
        "duration": 3.2,
        "text": "if it's not still being used in other"
      },
      {
        "start": 239.84,
        "duration": 3.2,
        "text": "parts of your application"
      },
      {
        "start": 241.439,
        "duration": 3.52,
        "text": "however if you want to stay fairly"
      },
      {
        "start": 243.04,
        "duration": 3.119,
        "text": "cautious you can always continue to"
      },
      {
        "start": 244.959,
        "duration": 3.2,
        "text": "write to the old table"
      },
      {
        "start": 246.159,
        "duration": 3.681,
        "text": "for some period of time until you know"
      },
      {
        "start": 248.159,
        "duration": 2.8,
        "text": "for sure that the new table is working"
      },
      {
        "start": 249.84,
        "duration": 2.8,
        "text": "as expected"
      },
      {
        "start": 250.959,
        "duration": 3.441,
        "text": "although spark would be one of the most"
      },
      {
        "start": 252.64,
        "duration": 4.319,
        "text": "convenient ways to migrate your data"
      },
      {
        "start": 254.4,
        "duration": 4.239,
        "text": "there are some other alternatives they"
      },
      {
        "start": 256.959,
        "duration": 3.601,
        "text": "may not necessarily be better"
      },
      {
        "start": 258.639,
        "duration": 3.84,
        "text": "but they are alternatives and in some"
      },
      {
        "start": 260.56,
        "duration": 4.32,
        "text": "cases it may make more sense"
      },
      {
        "start": 262.479,
        "duration": 3.44,
        "text": "for one you can use the cql shell tool"
      },
      {
        "start": 264.88,
        "duration": 3.28,
        "text": "to export your data"
      },
      {
        "start": 265.919,
        "duration": 3.28,
        "text": "using the copy command with the data"
      },
      {
        "start": 268.16,
        "duration": 3.12,
        "text": "saved as a csv"
      },
      {
        "start": 269.199,
        "duration": 3.601,
        "text": "file you can then transform the data as"
      },
      {
        "start": 271.28,
        "duration": 3.52,
        "text": "needed for your new data model"
      },
      {
        "start": 272.8,
        "duration": 3.2,
        "text": "and then copy to export your data back"
      },
      {
        "start": 274.8,
        "duration": 3.119,
        "text": "into the database"
      },
      {
        "start": 276.0,
        "duration": 4.16,
        "text": "another way would be to use the dataset"
      },
      {
        "start": 277.919,
        "duration": 3.601,
        "text": "drivers to actually query the data"
      },
      {
        "start": 280.16,
        "duration": 3.52,
        "text": "transform as necessary on the"
      },
      {
        "start": 281.52,
        "duration": 3.44,
        "text": "application side and then write it back"
      },
      {
        "start": 283.68,
        "duration": 2.88,
        "text": "to the new table"
      },
      {
        "start": 284.96,
        "duration": 3.2,
        "text": "yeah maybe it's better you just stick"
      },
      {
        "start": 286.56,
        "duration": 2.96,
        "text": "with spark then"
      },
      {
        "start": 288.16,
        "duration": 3.039,
        "text": "so i'm saying that you may need to"
      },
      {
        "start": 289.52,
        "duration": 3.84,
        "text": "change the primary key for a table"
      },
      {
        "start": 291.199,
        "duration": 3.121,
        "text": "but what's the justification behind it"
      },
      {
        "start": 293.36,
        "duration": 2.32,
        "text": "well obviously"
      },
      {
        "start": 294.32,
        "duration": 3.04,
        "text": "we wouldn't want to change anything if"
      },
      {
        "start": 295.68,
        "duration": 3.36,
        "text": "it's working however"
      },
      {
        "start": 297.36,
        "duration": 3.76,
        "text": "if there is something that is causing a"
      },
      {
        "start": 299.04,
        "duration": 4.159,
        "text": "problem it's better to fix that sooner"
      },
      {
        "start": 301.12,
        "duration": 3.68,
        "text": "rather than later are there certain"
      },
      {
        "start": 303.199,
        "duration": 3.361,
        "text": "partitions that are too large"
      },
      {
        "start": 304.8,
        "duration": 4.16,
        "text": "the new requirements get passed down for"
      },
      {
        "start": 306.56,
        "duration": 4.079,
        "text": "your application keep in mind that even"
      },
      {
        "start": 308.96,
        "duration": 3.2,
        "text": "if you do create a new table with a"
      },
      {
        "start": 310.639,
        "duration": 3.601,
        "text": "different primary key"
      },
      {
        "start": 312.16,
        "duration": 3.52,
        "text": "the original table may still be used in"
      },
      {
        "start": 314.24,
        "duration": 4.16,
        "text": "other parts of your application"
      },
      {
        "start": 315.68,
        "duration": 4.079,
        "text": "so don't drop it just yet with the new"
      },
      {
        "start": 318.4,
        "duration": 3.28,
        "text": "tables that you create"
      },
      {
        "start": 319.759,
        "duration": 3.361,
        "text": "don't forget to go over the analysis and"
      },
      {
        "start": 321.68,
        "duration": 3.2,
        "text": "validation steps again"
      },
      {
        "start": 323.12,
        "duration": 5.519,
        "text": "to make sure that your new data model"
      },
      {
        "start": 324.88,
        "duration": 3.759,
        "text": "does not contain easily avoidable"
      },
      {
        "start": 329.24,
        "duration": 3.0,
        "text": "problems"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T00:39:00.677496+00:00"
}