{
  "video_id": "p2lho6Duq1g",
  "title": "How to Build a Multimodal Music Search App with AI",
  "description": "Struggling to find the perfect soundtrack for every moment? Whether you're powering through a workout, setting the mood for a dinner party, or studying for a big exam, having the right songs playing can make all the difference.\r\n\r\nIntroducing Vibe Check! In this livestream, we'll show you how we built a multimodal music search application that seamlessly integrates with your Spotify account.\r\n\r\nDuring this session, you’ll learn:\r\nWhat multimodal models are and how they can enhance search and recommendations\r\nWhy we incorporated a vector database to efficiently store and retrieve music data\r\nHow we pieced it all together to build Vibe Check\r\nTune in to explore the power of AI and discover how to curate the perfect playlist for any occasion!\n\nResources:\nGithub Repo: https://github.com/datastax/vibe-check\nAstra DB signup: https://bit.ly/3A0rOQ1\n\r\n\r\nAbout DataStax Developer:\r\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2024-10-24T06:12:25Z",
  "thumbnail": "https://i.ytimg.com/vi/p2lho6Duq1g/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax",
    "vector",
    "workshop",
    "search",
    "apache_cassandra",
    "astra",
    "database",
    "tutorial"
  ],
  "url": "https://www.youtube.com/watch?v=p2lho6Duq1g",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "hello hey hey hey how's it going everyone Hi everyone let me know if you guys can hear us okay it's great to meet you all let me see give us a quick thumbs up or a yes in the chat if the audio is okay from both of us real quick loud and clear thank you Tom we can hear you perect perfect great um yeah Olga has already asked if we're sharing the recording this is being recorded we will send out a link to the recording after uh the cast is done it'll go to your email perfect yeah can everyone drop where they're currently actually watching this live stream from I know we have uh seen some messages earlier and it looks like we have people from all over the world so that's awesome UK nice Phoenix a okay nice hey Donald Italy Ireland wow okay I actually just went to Dublin um a couple months ago great Denver San Diego did you get people to sign up in person you were recruiting them to yes yes Street for sure for sure Houston Vancouver that's great place wow okay so we have we have everyone from all over the world that's awesome Munich Germany great um should we uh go ahead and dive into live stream Annie yeah yeah yeah um maybe maybe give it another minute or so I see the number of people joining is still increasing so yeah if you want to get the slides up I think we can start in about a minute sounds great Dallas Texas that's awesome wow people are from all over a global live stream love it um let me go ahead and just get everything all ready and we can get started shortly awesome let me know if everyone's able to see my screen all right looks great to me perfect actually we do stop my screen share awesome I think we can uh we can go ah go ahead and get started and um if anyone wants to trickle in while we while we start more than happy to do so um so let me share my screen with Y all again awesome looks like we have the wrong screen Nick yes this session is being recorded uh the link will get sent out afterwards awesome okay well welcome everyone we are stoked to have you for our live stream today uh today we will be talking about one of the uh applications that Amy and I built called Vibe Che and also be going more in depth regarding how you can create a multim mutal m multimodal music search application with AI um and so we'll be doing a quick little overview um over all these topics we'll show you a demo and we'll give you a full in-depth walk through of how we created this and so uh if I go into the agenda real quick we'll just do a quick round of introductions you can meet the speakers then we'll do a background regarding Vector search multimodal models how they work hand inand with one another so on and so forth and then we'll dive into the demo um and go through the walk through and lastly we will do a Q&A but we want to keep this as interactive as possible so if you have any questions along the way feel free to drop in the chat we'll be monitoring it during the entire time um and we'll just stop intermittently and answer any questions along the way and so uh let's get into it so meet your hosts I'm currently Andy G draw I'm a Solutions engineer here at data Stacks I've been with the company for a little bit over a year and a half now um based out of Phoenix Arizona and I work very closely with Annie which I'll let her introduce yourself real quick great thanks thanks for doing the intro Andy my name is Annie fan I am a lead Solutions engineer for data Stacks I actually joined like just a month before Andy so we've been at the company for about the same amount of time and have worked on the same team for like the entire time we've been part of data Stacks so um yeah I thought I thought it was really cool that we got the opportunity to run this live stream together it's like not something we typically do um we we came up with like this idea for a demo and something that we wanted to Showcase that we thought would be pretty cool to show folks um I'm based in Chicago Illinois been here for a number of years um and I wanted to get a little seasonal and topical uh Halloween is coming up uh this is going to be like Hollow weekend most likely unless people want to celebrate November which you know to each their own but I'm going to be celebrating Halloween this weekend if people in the chat could share uh do you have any favorite Halloween candy what do you think is the best treat I'm a sucker for Twix because uh I like the chocolate the crunchy the texture so good love it it's it's honestly hard to kind of choose one but I will have to say I'd have to go with Reese's anything chocolate and peanut butter is man that's my go-to anytime I get it it never stays in the house for longer than a couple days nice yeah I see Michelle likes hero gummy bears that's a hot I feel like it sticks to the teeth so I'm not into that pumpkin shaped candy bars Snickers Snickers candy corn oh man tooly for sure it's too early for me to be hungry for candy oh goodness as long as it's got sugar that's fine that's fine with me cool okay thank thanks for sharing we can we can move on for sure yeah let's dive into it and so today majority of this live stream we'll be talking about our demo called Vibe check and how we came about this project was Annie and I were sitting down one day and we are two music Fanatics we love music however we can never choose the right song for the right moment we have tons and tons of playlists but whenever we're driving or working out we can never find that right song for that right moment um and so we just decided to try to solve this issue by building this demo called Vibe check which is essentially a song recommendation system um where a user can put in their current setting either a description or a picture of what they're doing and then essentially songs from their playlists on Spotify would be recommended to them to play in that exact moment and you kind of see a little um you know quick little screenshot of it right here on the right hand side and we'll be you know kind of doing the full demo but also talking to you regarding all the different components that went into this and so we primar primarily used python to build this application uh so when we link the GitHub repo and all things like that it is all built in Python and then for the front end framework we use streamlit uh to essentially have all these button text boxes and display the application to the user and then you see here we use Spotify obviously you know Vibe check we wanted it to integrate with our Spotify playlist and so we use the Spotify API to get all that information and then we also use open AI specifically to different things from open AI we use their GPT 40 for our llm on the back end and then we also use their text embedding 3 small model to generate Vector embeddings of Our Song data and then lastly we used ashb um as the main Vector database to perform these similarity searches on the back end and so I know I kind of just ran through a whole lot of things there but we will go far more in depth into each of these things shortly um and show how they all interwork with with one another and so one thing to keep in mind as well is that Vibe check is a demo it's not necessarily a full production grade application so keep that in mind while you while you're playing around with it while you're testing um this is just meant for for demo purposes yeah we we built this over the course of like a week like we spent a couple days on this uh so it's very like proof of concept sort of thing uh and we we're basically showcasing what you can do with like multimodel and with Vector databases so yeah just just for full context there for sure it was just Annie and I hacking away at it for for a couple days so and so to kind of set the scene um we can talk a little B about Vector search because that's what's going on on the back end with our database to essentially perform these similarity searches and so one question that comes to mind is what even is Vector search well essentially it's a method of finding semantically relevant information um from one another and we can convert this type of you know data text images audio to something called embeddings or you know a long list of numbers and this is a one toone match with the piece of data that way you know when meaningful embeddings are stored within like a vector database like astb for example we can search for similar unstructured data without having to rely on key words or structured filters and so that's kind of the the core backend framework for this application a really cool example that I like to think about is is hey let's take the the fruit apple for example well you can see here that the vector embedding in this you know 300 dimensional space here is you know somewhat over here but if I were to take the fruit banana right it's going to be mapped or plotted very similar to Apple because they're semantically or contextually relevant to one another um and that way when I take the you know company Apple you see right over here um it'll be stored a little bit further away than apple and banana because it doesn't really have the same semantic meaning or contextual characteristics of our fruit and so you can see here that you know the company Apple is actually closer to the company Google and they would be kind of returned within the same vector or similarity search and so that's really what Vector search at the end of the day is it's really good for you know taking unstructured data and finding similarities between one another and with that being said we can maybe dive into a little bit about multimodal model mod and then we'll get into how Vector search and multimodal models kind of work together with one another and so what are multimodal models well you know in the AI space how I like to think about it is a mode or modality is essentially a type of data that we can either use as an input or an output to a gen model and so what you see here in this diagram is we can take things like text images audio you know video so on and so forth and we can either you know build this knowledge BAS base or insert it into our gen model and either you know use it as an input or retrieve output from it um and these multimodal models allow you know these these gen models to essentially have a um a broader you know characteristics of our data and understand you know a better definition of our knowledge base so what are examples well you know llms for example you know we have some uh you know chat GPT Bard um there's a variety of different multi modal llms that are provided out there in the world that we can use secondly our embedding models we have open AI Ada 002 model you know nvidia's embed Q&A model so on and so forth um there's tons of embedding models out there in the world um that we can use that are multimodel you know capable and then lastly our diffusion models we have stable diffusion Dolly etc etc um and all of these fit under this umbrella of multimodal models great uh I'm going to pause you for a second for a question so uh someone's asking so the word Apple could appear several times in a vector database uh yeah for sure it could um depending on how you you structure your database you can either have only just one um you know one piece of data stored within the database or you can have apple multiple times um it's really up to you but it's more for that Vector search part where if you were to search for something like a banana or or another fruit then maybe you know an apple and all the other fruits would be returned back to the user um if there's anything else you wanted to add to that Annie yeah yeah I think I think like in this situation I think the data being stored wouldn't be just the word Apple it would be like apple plus some surrounding context um so the way that you different like the only way to get different embeddings for Apple the company and apple the fruit is if you also have text describing kind of like giving context on what which Apple you're actually talking about so maybe you'd have a sentence that's like someone plugged an apple from a tree and then the other sentence would be like apple made1 billion dollar last year um and so if you were doing a vector search for like apple the company the sentence that you'd get back is probably related to Apple making however much money instead of the Apple getting plucked from the tree so that that's like how like what what you're giving to the model allows it to differentiate based on existing context that's a I think that's it's a very good point Annie um very rarely do we actually embed just a singular word um usually we actually have something called chunks um which are um you know a long list of you know either a paragraph or a full image and things like that things where we have the full context of what's going on and then we can embed that into the vector database any other questions let me look over onto our chat real quick awesome we should be good great question and so right how does Vector search and multimodal models kind of work hand inand well really there's two ways of doing this method one is we can take a piece of multiply medal data say an audio file right and use an audio embedding model which you see right over here to generate Vector embeddings which we can then store into a vector database and so there's tons of you know multimodal embedding models that match the type of data and you can use those that's kind of like the direct conversion method it's very simple but actually there's also a method too where we use an llm as a Transformer to essentially take this multimodal data pass it to an llm for interpretation and then the llm will usually spit back some description or its response and we can actually embed the response given back from the llm and use that to store it within our Vector database and this is actually what we will be demonstrating this is what vibe Che uses uh we are not necessarily taking songs and embedding the songs directly we're actually passing them to an llm to generate a description of the song and then you know embed that in stor in astb but we will go far more in depth into that and actually show you how we've done it um via the code but this method to um is usually what we like to do for um you know working with multimodal data great and yes llm is a large language model sweet okay before we kind of hop into the demo and stuff I just want to check if all of that context makes sense to folks if there's any other questions before we dive into it or if we're ready to just kind of get going sweet yeah let's see let's see the code um it do you want to Great okay let me present my screen now and then can people see my screen here so I have slides I have code a terminal file explorer sorry you're able to see okay great great great great okay okay um sweet so I'm going to uh basically we have this um project this streamlit project um and we have it as a GitHub repository which let me actually pull that up for folks if they want to take a look um great and then if you wanted to like afterwards make a copy of the repo to check out the code and try it running try and run it yourself on your own playlist data uh there's there's full instructions on how to do that and the GitHub repo and some other other useful links um but let's go ahead and get this app running so I'm going to use this command streamlet run streamlet app.py uh and that opens up our Vibe check demo here um and then would it be useful for me to zoom more or does this look okay it looks good to me but if folks want us to zoom in a little bit more we can more than you know definitely do so okay I'll I'll leave it unless someone in the chat requests a little Zoom okay let's go zoom in a little bit more cool great okay so so this is what the UI of the demo looks like uh it's kind of split into two sections so this section is where you connect to your playlist and do the ingestion and this one is where we actually are finding our songs so this is connected to my camera here you can actually see um see a preview of of what we can do um but I'll just kind of demonstrate like what that final end result is supposed to look like um so what we wanted to do is to be able to take a picture of our setting and then from that get recommendations of songs that would match that setting um this this app is currently connected to a playlist that we created for this demo um so if we want to take a look at that um we've loaded all of the data from this playlist uh into into our Astro database to be accessed by Vi Che so here we have 18 songs with a pretty wide variety some tame andala some espresso by Sabrina Carpenter stronger uh we also added a couple of Halloween songs down here um so there's kind of a wide variety of moods in this playlist that might not match like all of the songs don't match every single situation that you're in um so just to kind of show what that search functionality looks like if I uploaded for example this picture um it's it's this one it's a picture of a bunch of Jacko lanterns very spooky very Halloween um and then wanted to find songs within that playlist that match this uh here it's running a bit and then we can see a preview of the image and then here we see top recommended songs from that playlist spooky scary skeletons Monster Mash Ghostbusters and those are all three of the Halloween songs that we got um that we have in this playlist so all of those were returned as well as a couple of other ones that also have some similarity so yeah this this is like the result that we wanted um we using this image we got a recommendation um so let's let's kind of back up a little bit and we're going to talk about the architecture of the full app like what the ingestion actually looks like and what the querying looks like um and here we have our architecture slide where we can talk through that uh I do see a couple of questions in the chat so before we start talking about this um do we want to go through a couple of those let's do it yeah I see one right here saying what's more efficient should we do a direct conversion or through an llm um any thoughts on that Annie sorry let me let me see the is it in the Q&A or is it in the chat section looks to be in the chat um direct conversion or through llm I think um honestly I think both are useful it kind of depends on what your use case in in in both cases you would be sending the same amount of tokens to whatever model it is that you're using um honestly honestly direct conversion might be more efficient because you're only using a model once whereas in this situation we're using a large language model to do one step which is converting the non-text data into Text data and then we're using an embeddings model for another step which is converting that text Data into um into an actual embedding uh so into that like string long array of numbers that represents that text so there that's like two steps of querying models versus if you do a direct conversion um of like taking an image and creating embeddings directly from the image uh but also I feel like image embeddings models might be like more expensive uh they're more specialized so there there's a chance that it might it might not work exactly the way that you want um but but yeah it it kind of comes down to what exactly you're doing anything else you'd add there andy no I totally agree I think both of them are totally fine it just really depends on the type of data that you want to be stored in the database so obviously multimodal data let's take an audio file or an image for example right this has a lot of noise in it where sometimes you don't want to be embedding um all those external factors so for example if I have a picture of myself right as a piece of multimodal data Maybe I only want to focus on what I'm wearing for example right and nothing to do with my background or um what's going on in the Forefront of the photo things like that that's where you'd probably want to pass it to an llm to write a description of exactly you know you'd give it a prompt of hey describe only what the user is wearing so on and so forth and then embed that rather than the image itself because if you were to do the entire image you know all those characteristics of the entire image are going to be embedded um and sometimes you don't want that extra noise um you know within you know your vector database or within your embedding great well can the similar logic and principle be applied to videos instead of a Spotify playlist uh I would I would assume yes if you're as long as you're able to pass uh info about the video so maybe a couple frames from the video I mean a video is just like a ton of images right so you if you wanted you could pass all of those images to the llm and have it do the same thing or take a couple of snapshots and have it make a guess related to that in order to generate some sort of um text text data about that video and then um when you say multimodal does it have to be diffusion Plus llm for example it can't be two llms operating in an agent manner um in this case we're using using one llm in an agentic Manner and then we're using an embeddings model um directly on that text so we're not using diffusion for this example um but if you want to use multiple llms to do different agentic actions that's totally a valid approach cool and then there's a couple more in the Q&A we can we could just like burn through those real quick perfect yeah um where does rag fit into all of this that is an awesome question um essentially where this fits in this is more of a similarity search that uses an llm to write a description of the song We embed it and then search um so it's not necessarily a onetoone fit with rag but it's very easily doable um because we can take all the songs that are provided by the database and then feed it back to an llm for further augmentation and so I'd say the the retrieval and you know the pre-processing step is very similar it's a one toone match to rag um all you would need to do is just take that data that's returned from the vector database and feed it to an llm for further augmentation and you know generate response back to the user and so this might not be 100% you know a rag use case but it's 90% of the way there um we're literally probably missing just one llm call at the end for further refinement but in our case it's not necessarily needed because all of our data is already stored within the database that we need AK the song name the URL to it the artist destion so on and so forth so there's no really need to have an llm augment that data um is that what you were going to say too Annie yeah yeah I think that's a great answer cool um let's so I see there are more questions I think let's let's get into the demo a little more and kind of show the code and maybe that'll answer some of them and then if we have more time at the end we can address some of the questions that we missed um but here yeah I've add this up for a couple minutes now this is the architecture diagram um our app is split into two main functions one is ingesting the data and then the other part is querying the data so ingesting the data that is what's necessary to do we need to put everything into a vector database in order to be able to then query it with the user setting images or text descriptions so I'll talk through how the ingestion portion Works um first we give the application a Spotify playlist ID in this case it's the playlist ID for that um this Vibe check playlist which is just right here um so we copi and pasted that into our app uh sent it to our application and then using the Spotify API we got back a whole bunch of song data for every single song that is in that spotifi playlist um so we have the song name we have the artist name and then the song ID so that we can serve up URLs that point directly to the the songs that we will eventually retrieve um but that's not enough right we need we need some sort of text description and embeddings so that um we can do that similarity search when we get the user query and how do we generate those uh we used the open AI GPT 40 model to generate the queries I'll show you the code on what that actually looks like in a second um but the llm the large language model generates text describing the settings that match each song in that spoify playlist and then once we have those text descriptions we send those to Astra DB um ashtra actually has this feature called vectorize where you don't have to create the embeddings manually before uploading your data plus embeddings to the database you can actually just send the text directly to astb and we've already set up an integration with open AI text embedding three small so that when it receives that text Data it converts it to the embedding all those numbers um and then stores it in Astra all in one step so that's something that's getting abstracted by this Astra vectorized feature so so that's the ingestion piece of things um Andy do you want to talk about the querying portion yeah for sure uh the quering portion or when a user submits their their picture their image of themselves is very similar actually to what's going on with the data ingestion minus a few tweaks here and there and so essentially a user will upload and take a picture of themselves or upload an image into the streamlet application and from that streamlet application it's actually rep passing this image to openi you know GPT 40 model um to essentially generate a description of the user setting and so that's what I was kind of talking to regarding um you know using an llm as a Transformer stage where we're not just embedding the the image itself but we're actually telling chat GPT to hey generate a description of the user setting what are they doing what are their Vibes you know what's this paint paint the picture for us and essentially chat GPT will do so because it's a multimodal model um and it will uh give us back a full description and we can then take that description embed it and perform a vector search using asra's vectorized feature as well um so that's also you know this vectorize as Annie mentioned it is you know embedding the data being returned back from open AI um and then also performing a vector search on the Fly um together and so then you know once we have that we have a list of similar songs based off of the users's you know setting and we can return this uh back to the stream Lo application so the user can you know click on it and play the song directly and so that's the query portion great yeah so that's that's the full architecture um let's go ahead and dive into the code now and and what it actually looks like um so I'm going to talk about the ingestion piece of things and also show you kind of what the data looks like when it's in Astra so right now um we have all 18 of those Vibe check songs of these Vibe check songs uploaded into our database here we can see exactly 18 records in our Astra database um but I'll remove a few of them so that I can show you what it actually looks like when we're doing that ingestion and also talk through the code um so this is just removing a couple songs then we're going to dive into this file called ingest dopy uh which actually does the ingestion so um when sorry did you want to say something Andy yeah I wanted to just bring a quick point before we hop into the code um I I see a question right here what is orchestrating all of this just P just custom python code or Lang chain or etc etc um are are we are we using any tools on the back end yeah so this is a pretty sparse implementation we're not with this is um custom python code like we're using streamlet we're using asrai which is the client to connect to astrab Via Python and then we're using the open AI client and sending requests directly to the Spotify API so we're we're working directly with all the different pieces that we talked about earlier um I think if you want to add like more advanced functionality and more like decision making that uses Lang chain for example you could do that but we we kind of went fast and loose with this one and just kind of made the fastest possible implementation that wouldn't require us to like learn Frameworks um and it works pretty well it works pretty well cool awesome thank you cool um okay so I'll go ahead and talk a a little bit more about this code um so when we load the full playlist to Astra we're calling this function load tracks to Astra given the playlist ID and I'll just talk through what what happens from top to bottom here so the first thing we do is hit that Spotify API to get all of that song data from the Spotify API given the playlist ID so if I scroll up to this helper function get tracks from Spotify we can see uh where literally just sending um a request to the Spotify API to get all of that song data and so um this is our like access token this is the API we're using and then we get back um the response Json items as as playlist tracks and then we get that uh returned so here we're just kind of checking if we've done any of this before so that we don't need to like redo um loads of songs that we've done already um and then uh we're verifying that we did get tracks back from that Spotify playlist um and so that's that's what this section is doing and then from here below is when we're actually iterating through every single song formatting the data retrieving our descriptions for each song and uploading them to astrab so this first section here is um kind of organizing and pulling out relevant information from that API response so for each song we're getting um the song name here uh the artist name here and then a song URL which points directly to the song in Spotify uh and we're just kind of saving these as variables to be used later um here's some stuff for uh if if a song is already been loaded so we don't like redo llm calls unnecessarily um but in this case uh we hit this block if we encounter a song that is not yet loaded into the Astra database um and so we encounter the song we have the song data but we don't have a description for the song so that's when we call this function called get song description given the song name and the artist name so this is pulled out into another helper function right here um and this function uses the Open aai chat client uh and the GPT 40 model in order to generate a description of the song um and so so here's the prompt that we used you're an AI agent that helps users determine what songs to play to match their setting based on the song name and the artist name write up a description of what kind of setting would be appropriate to listen to this song don't make any assumptions based on the name try and use real information about the song to come up with your description oops I accidentally clicked down so here is the prompt right here um so yeah go ahead go ahead I was going to say that this is a very important part of the application um this is kind of what where we're getting these song descriptions right we're generating them through chat GPT 40's model um and not just necessarily coming up with them on our own or you know using a data set that's already provided we are using the llm to generate these descriptions yeah um so again this like llms are not fully deterministic like you're not going to get exactly the same description every single time but we did a little bit of prompt engineering to try and make this reliable to a certain extent and then after we got back our descriptions for the song we kind of checked them by eye because they're all songs that we know and then we saw like yeah we're we're getting good descriptions for these things um so this is where we're generating the song description using the openai llm GPT 40 so that is what's happening on this line right here and now that we have that song description we can add it to as a field to our document and then this data for every single song in that playlist is getting uploaded to astrab right here so this this um statement Song collection insert one document um and here is just kind of some progress tracking to see what that looks like but um I'll show you kind of what that looks like in real time so I'd already removed two songs from the Astra database if I reload this I'll see I only have 16 records in here and the two songs that got deleted uh if I check my terminal here my console uh two site and Monster Mash got deleted from the Astra database so I can try to reload that same playlist again it Should Skip both over all of the 16 songs that are already in there but it'll try and reload those two that are missing and we'll see in real time that our application generates descriptions for those two songs and then loads them into Astra so here it's working right now but we can already see um it generated this text for two Suite uh and then loaded to asach jdb it's skipping over a bunch of the other ones and then here for Monster Mash the llm generated this text for that song and then uploaded it to the database so if we come back to ashtra and refresh it here uh we can see now we have 18 records all all of the songs are now once again in this database and ready to be searched so that's how the ingestion works for this application um cool yeah that that's what I wanted to show that is awesome could we actually hop into the database real quick Annie and show them the descriptions that were generated by the llm Yeah Yeah that's that's a great idea so here we can see all of the fields for each of the songs we have song name artist song URL so this link would open the track and then this vectorized field is uh the text that was generated by the llm that describes this song and then this Vector is the vector representation of the highlighted text um generated by this model which uh which is this this collection is integrated with the open AI text embedding 3 small model and the vectorized feature allows us to create these every time we upload a new dock as long as we say yeah I want a vector created for this specific field so that's that's what it looks like in here that's kind of what's happening in Astra that is awesome thanks for walking us through that um so yeah now that we have all of our data within the database we're able to upload you know a user's playlist ID get all their songs you know generate these descriptions of the songs llms now let's you know get into the code of how we actually you know query these these songs and so we have this query. piy file which we can hop into and essentially the main part starts here at line 64 where you know a user presses the submit button on the application and so they take a photo either upload load it or use the camera and once they press that submit button here on line 67 we're essentially getting a description of the users's you know uh setting and we're going to this get setting description from image function which we have defined up here online 14 and what this does is very similarly to how the song descriptions are made um we are also going to chat GPT 40 and we are asking it to you know generate a description of the user setting and so you can see the prompt that we have here you're an AI agent that helps users find music that matches their current setting please describe the Ambiance and the vibe included in the image right what kind of music would be fitting for you know the setting that the user uploaded you know what kind of mood is there so on and so forth so a little bit of prompt engineering and then we're going to the GPT 40 model and receiving this um you know description from you know the llm and that is what we're using as you know the the vector embedding great and one oh go ahead go ahead um I was just going to ask like so this prompt doesn't have any information about what we're looking for right so like how how how does the llm know like what exactly it's supposed to be describing amazing question so kind of like in your scenario right we had passed the song name and the artist name into the prompt but here you know we're just giving the prompt um we're hard coding it and we're telling it to to look at the image and that's what you see here actually on line 38 um where we are actually passing the image of what the user uploaded to GPT 40 because it is a multimodal model it is able to accept images and it can essentially um interpret them based off of this prompt um and so we're telling you know we're giving GPT The Prompt we're giving it the image um and we're telling it based off of the two respond um and it's very important to know that gbt 40 right it is a multimodal model another example of an llm that is very capable of doing this is Google Gemini's provision model it's great as well um very similarly set up um to this but this is how it knows you know we're passing the image rather than you know a song name or a a artist name and then we're receiving that description awesome perect okay so back to here go yep so great now we have the setting description based off of the users uploaded image but now let's find similar songs off of that description that you know GPT 40 returned back to us and so if we go to this find songs function which we have what this is doing is it's going into astb it's using our vectorized feature to essentially vectorize or embed that setting description and then it's performing a vector search within the DB and pulling out the nearest matches to whatever the user had uploaded to the to the user setting description and that's what you see right over here return the top songs back to the user for them to play and if we hop into the um the stream L side we can actually you know upload a variety of different images and test this out so let's let's try it out we have a picture of you know Annie and I at the gym right over here one that we photoshopped right before this and let's see which um which songs are returned back to us so if we upload that what it's do is it's going to GPT 40 it's generating a description um of the image that we uploaded and so you can see this is the uploaded image we can you know toggle the show prompt sent llm button right here and you can see that this is what GPT 40 returned you know it said the image depicts a playful and energetic scene with characters lifting weights right suggesting a workout or Fitness theme these are you know songs or you know settings that you know kind of fit this Vibe a pop you know electric Dan EDM hip hop Rock right all of these kind of fit the same Vibe of working out or at the gym and then if we go down we can see the best matches that are returned from our database off of the song U off the setting description and so we have the song name say Stronger by Kanye West right over here that seems like a pretty good one um we have the song URL to go play it we have essentially that vectorized feel to say hey what is you know the song description off of the you know gp40 and then lastly we can also see the coine similarity score so how close of a match was this and we can see here you know 79 um is that coine similarity or that Vector search similarity score Annie and I were doing some playing around and we realized that anything above 7 is usually a pretty good match to return back to the user it's somewhat relevant um to what they're asking for and so great we we have all these list of songs and then lastly we just display this song where um you know you can click on stronger and it should open up the uh the URL to play it within Spotify which is pretty cool for sure um something that we were trying to implement but didn't end up doing because it just was taking too much time like ideally we could like get a Spotify player embedded into this app and start to play the songs automatically but we kind of didn't want to spend too much time doing that so um but but that would be like a great next step for this application so that you don't have to like open up the songs on your own maybe you could make like a new playlist that only includes songs that have a similarity score over s uh and then start to automatically play it for whatever event that you're currently at um so so there's like a lot of possibility I if if this like becomes something a little more fleshed out I could see myself using this all day like I would hook this up to my liked songs on Spotify which is like 3,000 songs long and then wherever I'm at I would just take a picture and then have like a 30 song playlist to match whatever it is I'm doing at that moment and have it automatically play that that's like kind of the vision here for what what it could turn into um for sure I think uh it's important to note that we are showing this kind of on the desktop application so it's more for you know uploading images right now is what we're showcasing but you can also run this on your phone and take a picture in real time of what your current setting is and you know have those songs play on the Fly based off of that I think that's kind of where the vision of this application you know would go yeah um how about we try a few more image prompts like image or um or text prompts so let's see I just kind of want to see what comes up for these different things so here I have a picture of a candle at dinner um and if we try this hopefully it doesn't recommend Monster Mash sweet and yeah we see the llm came up with this description uh and then we're getting back songs that kind of match that two sweet birds of a feather take five um pretty pretty accurate there and the cool part is that we can also not only just use an image to you know have this similarity search but you can also put in a description or type something out and then see um where you know what what's returned from just you know a sentence do you have any suggestions there andy um that's a good one let's try um I always need songs for you know a joy ride in my car great cool and here we can see um this is the full prompt that got sent uh there's nothing to generate something based off of um but here we see the first song returned is driveby uh a little on the nose but honestly that's pretty good Rip Tide yeah I could see myself going on a road trip to these that's pretty good for sure I think uh we need to put this into our to our actual playlists and give it a try yeah for sure um and then the last thing I wanted to show here is just this camera input so you can see I'm in my room here um we could take a live photo and see what the model thinks is going on great so here's the uploaded image it's me giving a thumbs up um and here relaxed and cozy room casual and positive calm and simple environment lowii hip hop chill pop casual relaxation work and study and that's that's what we're getting back here that is awesome cool I think we actually have a couple questions any that we can maybe answer um I see a really good one right over here um asking if we could re explain why we are vectorizing the image description sent by the llm do you want to take that one or should I go for it sure I I can take it I think I think we were looking for something like pretty simple to implement um and also like something that would focus more on the setting of what we're doing as opposed to the image itself because if you took a picture of what you're doing and then created em an embedding only on that picture um the the embedding would probably be like a descriptor of like what is in the image so instead of like saying anything about like the vibe um what sort of songs might be a good match it would just say like there is a person in a room with headphones on um and it wouldn't give any of that sort of like it wouldn't make any guesses about the Ambiance or like what what sort of mood that person might be in so um we we felt like an easy way to get that information would just be to ask an llm for that specific information like hey here's this picture we're trying to do this with it try and give me the most valuable text um to do these similarity searches in order to give good song recommendations so giving all of that context to create data that is hyp specific to this use case um which might not be captured if we were to embed the images directly perfect I think even we had someone in the chat even give their answer to give the embedding more context that's exactly it um we want to give the embedding as much context as possible um and all the things that we're looking for right if we were to just take the image sometimes it might embed some characteristics such as you know demographic age height so on and so forth these are all things that we don't necessarily want or need for this application right and that's why we're going to the llm to essentially provide these descriptions for us and then embed those so we know exactly what we're looking for we're embeding exactly what we need awesome great well any any other questions here you want to get to uh I see in the chat how do you deal with the subjectivity of the description generated by chaty BT sometimes a song can be considered motivating for someone and not for other people how can I be sure that my description is generic enough to cover the majority of CAS cases um someone else responds you can deal with that via prompt or you can train a different model um you can chunk and train based on what your version of motivating is yeah if if you're trying to make this hypers specific for yourself you can add criteria to The Prompt that says like this is what I think of these songs generally and then have the llm try and uh and apply that to whatever it's getting um if you're trying to keep it more General then you can explicitly state that in the prompts that you're giving to the llm um and here I mean I didn't tell the llm to do this explicitly but it's kind of um doing that on its own it's giving four different options for types of music or settings that would fit the image um and so there there's definitely prompt engineering you can do to kind of fit whatever functionality you're looking for uh but then yeah um training training based on how you want the model to behave is also another really great approach yeah I think prompting is kind of the art here right um multiple different ways of doing it you can do it kind of in a very simple simple way that Annie and I did where you just kind of you know give a description of what you'd like um but there's also prompting techniques such as fuse shot prompting right where you actually give examples to the llm of what you consider songs of motivating are or scary or sad or so on and so forth right so the llm has extra context to know um how to classify these groups before doing it um but that really all goes into the prompt um if if you really don't want to train you know another llm for for this exact use case cool uh any other question question question on LinkedIn what technology is being used to get the labels for a given image for example Google Vision um so we're we're using open AI GPT 40 um so right here we are sending this prompt with the song name and artist name oh give an image my bad my bad that's on the query side uh we're still using gp40 um we're sending this prompt so we're asking the llm like we're saying hey llm we're gonna give you um an image and please describe it using this prompt um so so that's what's happening we're using GPT 4L first we did actually implement this using with with Gemini provision uh but then um we decided to switch everything over to open AI because we were doing embeddings with one like with one provider and the llm stuff with another but we figured if we're using things within the same like Universe perhaps they're trained on more similar data so you'd get like more consistent results so but yeah you could swap this out for for kind of whatever llm embedding combo that you want any other questions that we can [Music] answer I want to get I just want to get the Halloween example back up there it is awesome I see here so this this question is this might be too complicated to answer in the time frame but how are the distances between individual vectors determined for similarity and how granular can these be well that's a really good question um there's really three main ways to perform these Vector similarity searches um one of them or the one that we're using here is called cosine similarity and we're essentially finding the distances between the vectors or how far away they are from one another um and that's what you were seeing when we would show the 7 or you know the coine similarity scores here all the way on the right of this table um this is being provided by that that similarity search or that metric called cosine similarity but there's also you know a variety of others out there there's one called dot product or ukian distance all of these are different ways of calculating distances between vectors U and Performing these similarity searches but Annie and I chose to go with cosine similarity that's usually kind of the de facto you know Norm um when working with Vector search um but that's you know how how we how we do this and how the distances are are calculated like different different embeddings models already by default use different similarity metrics um so if we were tried to use this text embedding 3 model with DOT product similarity it wouldn't it wouldn't work well like it wouldn't be an accurate representation because the the dimensions are sorry the vectors are created um assuming that like distances are calculated with cosine so whatever model you're using um that kind of determines what distance metrics make the most sense for it awesome how do you approach training the AI models for different music genres and Regional preferences ensuring that the model understands cultural and genre specific nuances yeah that's that's a really interesting question so that's not something that we've implemented here um but what I could see happening is if you have user data um and maybe like you want to only recommend certain songs if the user is based in uh APAC for example like what you could do is add another field here um to kind of indicate whether a song should or should not be shown to someone who's searching from APAC so maybe you could do like a like the column name would be APAC it would just be like true or false um and then if you want to limit results to for a specific person when you do your similarity search you can do something called a hybrid search where you add a filter before you do that Vector search so um instead of searching over the entire database you would say I want to filter my results to only this subsection of the database where the apack flag is true and then do my Vector search within that um so that's like a pretty um like you you can add a lot of like variables to that that you want to include uh if if you're trying to do some sort of structured filtering uh add more personalization then there are ways to like add additional Fields like metadata um so that you could do that sort of thing but we didn't we didn't Implement that in this example it's all just like full playlist is own into Astra we're searching across the the entire thing but but there's a lot of like cool things you could do if you needed to have some more granularity there yeah that's a great question and a great answer I think that metadata one is a great next step right if you already know uh the genres of of the different songs that you're uploading right might as well just use that in a hybrid search um to essentially have that as a subset of data that you're recommending so you know for a fact that you know if I'm have some Loi songs right I can put that as maybe a calming genre or something like that or study genre and then maybe have the llm return hey this setting you know seems like this type of genre right Andy's working maybe you know put it for for study or working genre and then perform a hybrid search so you're only you know returning or limiting your results to songs in that genre sweet cool um any any last questions I know I know we're at time now um I'm glad we're able get through everything and show the code uh the GitHub repo for this project is still up on the cast so if you want to take a look yourself and run it yourself um that's an option um let's see is there is there anything else that we want to get to before we end the stream I think we should be all good if they want to maybe use that QR code that we have on our last slide um to access that GitHub repo um they're they're more than welcome to do so sweet yeah let's I'll pull that up right here here cool um yeah yeah this this is like this was a really fun thing for us to work on and um we really appreciate the opportunity to kind of speak to people outside of the company about like something cool that you can build with AI and with Astra um and yeah all the code is available so take a look yourself um if you want to submit issues on the repo or contribute that's like totally an option if you want to ask questions about it uh there's a link to the uh data sex developer uh Discord where you could join and like message us directly about it or just like talk about things that you're doing um yeah and and if you're building anything cool with Astro we obviously want to want to hear about it but um yeah this was this was a great time yeah I had an absolute blast and feel free to Fork it and as Annie mentioned you can hit us up on the developer Discord more than happy to chat more about it if you have any feature requests things like that um kind of want to keep this as a collaborative project with everyone um since this is something that Anie and I thought would be kind of cool for for us to use at home and so with that being said any questions feel free to reach out um and we had an absolute blast thanks for spending the last hour with us awesome yeah thank you everyone once again the this is recorded the link will go out as soon as it's ready following the cast um and yeah reach out to us whenever you want with any questions you have via that Discord also uh any any slack sorry any chat message that you send um on data sax pages that probably actually goes to us so um if you need to reach out we're we're available great okay um yeah thanks again for your time uh that was a really fun hour I hope everyone has a good rest of your day and again let us know if anything interesting comes up I had so much fun today take care I'm here have a good one y'all see you",
    "segments": [
      {
        "start": 4.799,
        "duration": 7.441,
        "text": "hello hey hey hey how's it going"
      },
      {
        "start": 8.96,
        "duration": 5.759,
        "text": "everyone Hi"
      },
      {
        "start": 12.24,
        "duration": 5.68,
        "text": "everyone let me know if you guys can"
      },
      {
        "start": 14.719,
        "duration": 5.841,
        "text": "hear us okay it's great to meet you"
      },
      {
        "start": 17.92,
        "duration": 5.199,
        "text": "all let me"
      },
      {
        "start": 20.56,
        "duration": 4.559,
        "text": "see give us a quick thumbs up or a yes"
      },
      {
        "start": 23.119,
        "duration": 4.881,
        "text": "in the chat if the audio is okay from"
      },
      {
        "start": 25.119,
        "duration": 6.201,
        "text": "both of us real"
      },
      {
        "start": 28.0,
        "duration": 5.48,
        "text": "quick loud and clear thank you Tom we"
      },
      {
        "start": 31.32,
        "duration": 6.44,
        "text": "can hear you perect"
      },
      {
        "start": 33.48,
        "duration": 6.079,
        "text": "perfect great um yeah Olga has already"
      },
      {
        "start": 37.76,
        "duration": 4.319,
        "text": "asked if we're sharing the recording"
      },
      {
        "start": 39.559,
        "duration": 5.801,
        "text": "this is being recorded we will send out"
      },
      {
        "start": 42.079,
        "duration": 6.401,
        "text": "a link to the recording after uh the"
      },
      {
        "start": 45.36,
        "duration": 6.28,
        "text": "cast is done it'll go to your"
      },
      {
        "start": 48.48,
        "duration": 4.28,
        "text": "email perfect yeah can everyone drop"
      },
      {
        "start": 51.64,
        "duration": 3.52,
        "text": "where they're currently actually"
      },
      {
        "start": 52.76,
        "duration": 4.2,
        "text": "watching this live stream from I know we"
      },
      {
        "start": 55.16,
        "duration": 2.76,
        "text": "have uh seen some messages earlier and"
      },
      {
        "start": 56.96,
        "duration": 4.84,
        "text": "it looks like we have people from all"
      },
      {
        "start": 57.92,
        "duration": 3.88,
        "text": "over the world so that's awesome"
      },
      {
        "start": 63.799,
        "duration": 8.521,
        "text": "UK nice Phoenix a okay nice hey Donald"
      },
      {
        "start": 69.84,
        "duration": 5.12,
        "text": "Italy Ireland wow okay I actually just"
      },
      {
        "start": 72.32,
        "duration": 7.32,
        "text": "went to Dublin um a couple months"
      },
      {
        "start": 74.96,
        "duration": 6.839,
        "text": "ago great Denver San Diego did you get"
      },
      {
        "start": 79.64,
        "duration": 6.64,
        "text": "people to sign up in person you were"
      },
      {
        "start": 81.799,
        "duration": 8.28,
        "text": "recruiting them to yes yes Street for"
      },
      {
        "start": 86.28,
        "duration": 5.839,
        "text": "sure for sure Houston Vancouver that's"
      },
      {
        "start": 90.079,
        "duration": 4.121,
        "text": "great place wow okay so we have we have"
      },
      {
        "start": 92.119,
        "duration": 5.441,
        "text": "everyone from all over the world that's"
      },
      {
        "start": 94.2,
        "duration": 6.64,
        "text": "awesome Munich"
      },
      {
        "start": 97.56,
        "duration": 5.32,
        "text": "Germany great um should we uh go ahead"
      },
      {
        "start": 100.84,
        "duration": 5.72,
        "text": "and dive into live stream"
      },
      {
        "start": 102.88,
        "duration": 6.72,
        "text": "Annie yeah yeah yeah um maybe maybe give"
      },
      {
        "start": 106.56,
        "duration": 6.12,
        "text": "it another minute or so I see the number"
      },
      {
        "start": 109.6,
        "duration": 4.479,
        "text": "of people joining is still increasing so"
      },
      {
        "start": 112.68,
        "duration": 3.799,
        "text": "yeah if you want to get the slides up I"
      },
      {
        "start": 114.079,
        "duration": 5.96,
        "text": "think we can start in about a minute"
      },
      {
        "start": 116.479,
        "duration": 3.56,
        "text": "sounds great"
      },
      {
        "start": 123.32,
        "duration": 3.719,
        "text": "Dallas Texas that's"
      },
      {
        "start": 127.56,
        "duration": 6.16,
        "text": "awesome wow people are from all over a"
      },
      {
        "start": 131.28,
        "duration": 4.84,
        "text": "global live"
      },
      {
        "start": 133.72,
        "duration": 5.159,
        "text": "stream love"
      },
      {
        "start": 136.12,
        "duration": 5.32,
        "text": "it um let me go ahead and just get"
      },
      {
        "start": 138.879,
        "duration": 5.921,
        "text": "everything all ready and we can get"
      },
      {
        "start": 141.44,
        "duration": 3.36,
        "text": "started shortly"
      },
      {
        "start": 155.879,
        "duration": 4.401,
        "text": "awesome let me know if everyone's able"
      },
      {
        "start": 157.879,
        "duration": 5.36,
        "text": "to see my screen all"
      },
      {
        "start": 160.28,
        "duration": 5.959,
        "text": "right looks great to"
      },
      {
        "start": 163.239,
        "duration": 3.0,
        "text": "me"
      },
      {
        "start": 177.64,
        "duration": 5.519,
        "text": "perfect actually we do"
      },
      {
        "start": 180.44,
        "duration": 2.719,
        "text": "stop my screen"
      },
      {
        "start": 186.239,
        "duration": 5.64,
        "text": "share awesome I think we can uh we can"
      },
      {
        "start": 188.599,
        "duration": 4.801,
        "text": "go ah go ahead and get started and um if"
      },
      {
        "start": 191.879,
        "duration": 3.881,
        "text": "anyone wants to trickle in while we"
      },
      {
        "start": 193.4,
        "duration": 5.36,
        "text": "while we start more than happy to do"
      },
      {
        "start": 195.76,
        "duration": 5.039,
        "text": "so um so let me share my screen with Y"
      },
      {
        "start": 198.76,
        "duration": 5.039,
        "text": "all"
      },
      {
        "start": 200.799,
        "duration": 3.0,
        "text": "again"
      },
      {
        "start": 205.519,
        "duration": 5.72,
        "text": "awesome looks like we have the wrong"
      },
      {
        "start": 208.799,
        "duration": 5.561,
        "text": "screen"
      },
      {
        "start": 211.239,
        "duration": 6.601,
        "text": "Nick yes this session is being recorded"
      },
      {
        "start": 214.36,
        "duration": 3.48,
        "text": "uh the link will get sent out"
      },
      {
        "start": 220.84,
        "duration": 5.36,
        "text": "afterwards awesome okay well welcome"
      },
      {
        "start": 223.64,
        "duration": 5.0,
        "text": "everyone we are stoked to have you for"
      },
      {
        "start": 226.2,
        "duration": 5.119,
        "text": "our live stream today uh today we will"
      },
      {
        "start": 228.64,
        "duration": 4.799,
        "text": "be talking about one of the uh"
      },
      {
        "start": 231.319,
        "duration": 5.161,
        "text": "applications that Amy and I built called"
      },
      {
        "start": 233.439,
        "duration": 5.44,
        "text": "Vibe Che and also be going more in depth"
      },
      {
        "start": 236.48,
        "duration": 4.8,
        "text": "regarding how you can create a multim"
      },
      {
        "start": 238.879,
        "duration": 5.041,
        "text": "mutal m multimodal music search"
      },
      {
        "start": 241.28,
        "duration": 5.08,
        "text": "application with AI um and so we'll be"
      },
      {
        "start": 243.92,
        "duration": 4.399,
        "text": "doing a quick little overview um over"
      },
      {
        "start": 246.36,
        "duration": 3.719,
        "text": "all these topics we'll show you a demo"
      },
      {
        "start": 248.319,
        "duration": 5.64,
        "text": "and we'll give you a full in-depth walk"
      },
      {
        "start": 250.079,
        "duration": 5.561,
        "text": "through of how we created this and so uh"
      },
      {
        "start": 253.959,
        "duration": 3.041,
        "text": "if I go into the agenda real quick we'll"
      },
      {
        "start": 255.64,
        "duration": 3.319,
        "text": "just do a quick round of introductions"
      },
      {
        "start": 257.0,
        "duration": 4.28,
        "text": "you can meet the speakers then we'll do"
      },
      {
        "start": 258.959,
        "duration": 4.161,
        "text": "a background regarding Vector search"
      },
      {
        "start": 261.28,
        "duration": 3.96,
        "text": "multimodal models how they work hand"
      },
      {
        "start": 263.12,
        "duration": 4.6,
        "text": "inand with one another so on and so"
      },
      {
        "start": 265.24,
        "duration": 4.08,
        "text": "forth and then we'll dive into the demo"
      },
      {
        "start": 267.72,
        "duration": 4.64,
        "text": "um and go through the walk through and"
      },
      {
        "start": 269.32,
        "duration": 4.96,
        "text": "lastly we will do a Q&A but we want to"
      },
      {
        "start": 272.36,
        "duration": 3.72,
        "text": "keep this as interactive as possible so"
      },
      {
        "start": 274.28,
        "duration": 3.16,
        "text": "if you have any questions along the way"
      },
      {
        "start": 276.08,
        "duration": 3.6,
        "text": "feel free to drop in the chat we'll be"
      },
      {
        "start": 277.44,
        "duration": 3.84,
        "text": "monitoring it during the entire time um"
      },
      {
        "start": 279.68,
        "duration": 3.64,
        "text": "and we'll just stop intermittently and"
      },
      {
        "start": 281.28,
        "duration": 5.56,
        "text": "answer any questions along the way and"
      },
      {
        "start": 283.32,
        "duration": 5.76,
        "text": "so uh let's get into it so meet your"
      },
      {
        "start": 286.84,
        "duration": 3.96,
        "text": "hosts I'm currently Andy G draw I'm a"
      },
      {
        "start": 289.08,
        "duration": 3.8,
        "text": "Solutions engineer here at data Stacks"
      },
      {
        "start": 290.8,
        "duration": 4.839,
        "text": "I've been with the company for a little"
      },
      {
        "start": 292.88,
        "duration": 5.159,
        "text": "bit over a year and a half now um based"
      },
      {
        "start": 295.639,
        "duration": 3.681,
        "text": "out of Phoenix Arizona and I work very"
      },
      {
        "start": 298.039,
        "duration": 3.841,
        "text": "closely with Annie which I'll let her"
      },
      {
        "start": 299.32,
        "duration": 4.92,
        "text": "introduce yourself real quick great"
      },
      {
        "start": 301.88,
        "duration": 4.84,
        "text": "thanks thanks for doing the intro Andy"
      },
      {
        "start": 304.24,
        "duration": 4.92,
        "text": "my name is Annie fan I am a lead"
      },
      {
        "start": 306.72,
        "duration": 4.52,
        "text": "Solutions engineer for data Stacks I"
      },
      {
        "start": 309.16,
        "duration": 4.2,
        "text": "actually joined like just a month before"
      },
      {
        "start": 311.24,
        "duration": 4.08,
        "text": "Andy so we've been at the company for"
      },
      {
        "start": 313.36,
        "duration": 4.44,
        "text": "about the same amount of time and have"
      },
      {
        "start": 315.32,
        "duration": 3.96,
        "text": "worked on the same team for like the"
      },
      {
        "start": 317.8,
        "duration": 4.16,
        "text": "entire time we've been part of data"
      },
      {
        "start": 319.28,
        "duration": 4.199,
        "text": "Stacks so um yeah I thought I thought it"
      },
      {
        "start": 321.96,
        "duration": 4.2,
        "text": "was really cool that we got the"
      },
      {
        "start": 323.479,
        "duration": 4.28,
        "text": "opportunity to run this live stream"
      },
      {
        "start": 326.16,
        "duration": 5.56,
        "text": "together it's like not something we"
      },
      {
        "start": 327.759,
        "duration": 6.0,
        "text": "typically do um we we came up with like"
      },
      {
        "start": 331.72,
        "duration": 3.919,
        "text": "this idea for a demo and something that"
      },
      {
        "start": 333.759,
        "duration": 4.601,
        "text": "we wanted to Showcase that we thought"
      },
      {
        "start": 335.639,
        "duration": 6.161,
        "text": "would be pretty cool to show folks um"
      },
      {
        "start": 338.36,
        "duration": 7.6,
        "text": "I'm based in Chicago Illinois been here"
      },
      {
        "start": 341.8,
        "duration": 7.44,
        "text": "for a number of years um and I wanted to"
      },
      {
        "start": 345.96,
        "duration": 6.079,
        "text": "get a little seasonal and topical uh"
      },
      {
        "start": 349.24,
        "duration": 5.399,
        "text": "Halloween is coming up uh this is going"
      },
      {
        "start": 352.039,
        "duration": 4.401,
        "text": "to be like Hollow weekend most likely"
      },
      {
        "start": 354.639,
        "duration": 5.081,
        "text": "unless people want to celebrate November"
      },
      {
        "start": 356.44,
        "duration": 4.879,
        "text": "which you know to each their own but I'm"
      },
      {
        "start": 359.72,
        "duration": 4.039,
        "text": "going to be celebrating Halloween this"
      },
      {
        "start": 361.319,
        "duration": 4.761,
        "text": "weekend if people in the chat could"
      },
      {
        "start": 363.759,
        "duration": 4.681,
        "text": "share uh do you have any favorite"
      },
      {
        "start": 366.08,
        "duration": 3.399,
        "text": "Halloween candy what do you think is the"
      },
      {
        "start": 368.44,
        "duration": 5.319,
        "text": "best"
      },
      {
        "start": 369.479,
        "duration": 6.481,
        "text": "treat I'm a sucker for Twix because uh I"
      },
      {
        "start": 373.759,
        "duration": 5.121,
        "text": "like the chocolate the crunchy the"
      },
      {
        "start": 375.96,
        "duration": 4.239,
        "text": "texture so good love it it's it's"
      },
      {
        "start": 378.88,
        "duration": 3.08,
        "text": "honestly hard to kind of choose one but"
      },
      {
        "start": 380.199,
        "duration": 3.881,
        "text": "I will have to say I'd have to go with"
      },
      {
        "start": 381.96,
        "duration": 4.639,
        "text": "Reese's anything chocolate and peanut"
      },
      {
        "start": 384.08,
        "duration": 4.08,
        "text": "butter is man that's my go-to anytime I"
      },
      {
        "start": 386.599,
        "duration": 4.961,
        "text": "get it it never stays in the house for"
      },
      {
        "start": 388.16,
        "duration": 3.4,
        "text": "longer than a couple days"
      },
      {
        "start": 392.28,
        "duration": 5.44,
        "text": "nice yeah I see Michelle likes hero"
      },
      {
        "start": 394.88,
        "duration": 6.039,
        "text": "gummy bears that's a hot I feel like it"
      },
      {
        "start": 397.72,
        "duration": 7.16,
        "text": "sticks to the teeth so I'm not into"
      },
      {
        "start": 400.919,
        "duration": 8.481,
        "text": "that pumpkin shaped candy bars Snickers"
      },
      {
        "start": 404.88,
        "duration": 6.599,
        "text": "Snickers candy corn oh man tooly for"
      },
      {
        "start": 409.4,
        "duration": 3.799,
        "text": "sure it's too early for me to be hungry"
      },
      {
        "start": 411.479,
        "duration": 3.84,
        "text": "for candy oh"
      },
      {
        "start": 413.199,
        "duration": 5.12,
        "text": "goodness as long as it's got sugar"
      },
      {
        "start": 415.319,
        "duration": 6.201,
        "text": "that's fine that's fine with"
      },
      {
        "start": 418.319,
        "duration": 5.801,
        "text": "me cool okay thank thanks for sharing we"
      },
      {
        "start": 421.52,
        "duration": 5.44,
        "text": "can we can move on for sure yeah let's"
      },
      {
        "start": 424.12,
        "duration": 4.4,
        "text": "dive into it and so today majority of"
      },
      {
        "start": 426.96,
        "duration": 4.239,
        "text": "this live stream we'll be talking about"
      },
      {
        "start": 428.52,
        "duration": 4.6,
        "text": "our demo called Vibe check and how we"
      },
      {
        "start": 431.199,
        "duration": 4.081,
        "text": "came about this project was Annie and I"
      },
      {
        "start": 433.12,
        "duration": 5.079,
        "text": "were sitting down one day and we are two"
      },
      {
        "start": 435.28,
        "duration": 4.759,
        "text": "music Fanatics we love music however we"
      },
      {
        "start": 438.199,
        "duration": 3.641,
        "text": "can never choose the right song for the"
      },
      {
        "start": 440.039,
        "duration": 4.241,
        "text": "right moment we have tons and tons of"
      },
      {
        "start": 441.84,
        "duration": 4.44,
        "text": "playlists but whenever we're driving or"
      },
      {
        "start": 444.28,
        "duration": 5.039,
        "text": "working out we can never find that right"
      },
      {
        "start": 446.28,
        "duration": 4.599,
        "text": "song for that right moment um and so we"
      },
      {
        "start": 449.319,
        "duration": 3.641,
        "text": "just decided to try to solve this issue"
      },
      {
        "start": 450.879,
        "duration": 3.681,
        "text": "by building this demo called Vibe check"
      },
      {
        "start": 452.96,
        "duration": 4.04,
        "text": "which is essentially a song"
      },
      {
        "start": 454.56,
        "duration": 4.56,
        "text": "recommendation system um where a user"
      },
      {
        "start": 457.0,
        "duration": 3.639,
        "text": "can put in their current setting either"
      },
      {
        "start": 459.12,
        "duration": 3.96,
        "text": "a description or a picture of what"
      },
      {
        "start": 460.639,
        "duration": 4.881,
        "text": "they're doing and then essentially songs"
      },
      {
        "start": 463.08,
        "duration": 3.839,
        "text": "from their playlists on Spotify would be"
      },
      {
        "start": 465.52,
        "duration": 3.359,
        "text": "recommended to them to play in that"
      },
      {
        "start": 466.919,
        "duration": 4.12,
        "text": "exact moment and you kind of see a"
      },
      {
        "start": 468.879,
        "duration": 3.641,
        "text": "little um you know quick little"
      },
      {
        "start": 471.039,
        "duration": 3.361,
        "text": "screenshot of it right here on the right"
      },
      {
        "start": 472.52,
        "duration": 3.519,
        "text": "hand side and we'll be you know kind of"
      },
      {
        "start": 474.4,
        "duration": 3.12,
        "text": "doing the full demo but also talking to"
      },
      {
        "start": 476.039,
        "duration": 4.72,
        "text": "you regarding all the different"
      },
      {
        "start": 477.52,
        "duration": 5.519,
        "text": "components that went into this and so we"
      },
      {
        "start": 480.759,
        "duration": 4.481,
        "text": "primar primarily used python to build"
      },
      {
        "start": 483.039,
        "duration": 3.84,
        "text": "this application uh so when we link the"
      },
      {
        "start": 485.24,
        "duration": 3.639,
        "text": "GitHub repo and all things like that it"
      },
      {
        "start": 486.879,
        "duration": 4.32,
        "text": "is all built in Python and then for the"
      },
      {
        "start": 488.879,
        "duration": 3.841,
        "text": "front end framework we use streamlit uh"
      },
      {
        "start": 491.199,
        "duration": 3.84,
        "text": "to essentially have all these button"
      },
      {
        "start": 492.72,
        "duration": 5.28,
        "text": "text boxes and display the application"
      },
      {
        "start": 495.039,
        "duration": 5.56,
        "text": "to the user and then you see here we use"
      },
      {
        "start": 498.0,
        "duration": 4.199,
        "text": "Spotify obviously you know Vibe check we"
      },
      {
        "start": 500.599,
        "duration": 4.121,
        "text": "wanted it to integrate with our Spotify"
      },
      {
        "start": 502.199,
        "duration": 4.761,
        "text": "playlist and so we use the Spotify API"
      },
      {
        "start": 504.72,
        "duration": 4.879,
        "text": "to get all that information and then we"
      },
      {
        "start": 506.96,
        "duration": 4.679,
        "text": "also use open AI specifically to"
      },
      {
        "start": 509.599,
        "duration": 6.0,
        "text": "different things from open AI we use"
      },
      {
        "start": 511.639,
        "duration": 5.681,
        "text": "their GPT 40 for our llm on the back end"
      },
      {
        "start": 515.599,
        "duration": 4.161,
        "text": "and then we also use their text"
      },
      {
        "start": 517.32,
        "duration": 5.76,
        "text": "embedding 3 small model to generate"
      },
      {
        "start": 519.76,
        "duration": 6.759,
        "text": "Vector embeddings of Our Song data and"
      },
      {
        "start": 523.08,
        "duration": 4.96,
        "text": "then lastly we used ashb um as the main"
      },
      {
        "start": 526.519,
        "duration": 4.121,
        "text": "Vector database to perform these"
      },
      {
        "start": 528.04,
        "duration": 4.4,
        "text": "similarity searches on the back end and"
      },
      {
        "start": 530.64,
        "duration": 3.639,
        "text": "so I know I kind of just ran through a"
      },
      {
        "start": 532.44,
        "duration": 3.68,
        "text": "whole lot of things there but we will go"
      },
      {
        "start": 534.279,
        "duration": 3.8,
        "text": "far more in depth into each of these"
      },
      {
        "start": 536.12,
        "duration": 5.32,
        "text": "things shortly um and show how they all"
      },
      {
        "start": 538.079,
        "duration": 3.361,
        "text": "interwork with with one another"
      },
      {
        "start": 541.48,
        "duration": 3.96,
        "text": "and so one thing to keep in mind as well"
      },
      {
        "start": 543.6,
        "duration": 3.08,
        "text": "is that Vibe check is a demo it's not"
      },
      {
        "start": 545.44,
        "duration": 2.88,
        "text": "necessarily a full production grade"
      },
      {
        "start": 546.68,
        "duration": 2.92,
        "text": "application so keep that in mind while"
      },
      {
        "start": 548.32,
        "duration": 2.92,
        "text": "you while you're playing around with it"
      },
      {
        "start": 549.6,
        "duration": 4.4,
        "text": "while you're testing um this is just"
      },
      {
        "start": 551.24,
        "duration": 5.279,
        "text": "meant for for demo purposes yeah we we"
      },
      {
        "start": 554.0,
        "duration": 5.12,
        "text": "built this over the course of like a"
      },
      {
        "start": 556.519,
        "duration": 5.481,
        "text": "week like we spent a couple days on this"
      },
      {
        "start": 559.12,
        "duration": 5.36,
        "text": "uh so it's very like proof of concept"
      },
      {
        "start": 562.0,
        "duration": 4.92,
        "text": "sort of thing uh and we we're basically"
      },
      {
        "start": 564.48,
        "duration": 5.359,
        "text": "showcasing what you can do with like"
      },
      {
        "start": 566.92,
        "duration": 5.76,
        "text": "multimodel and with Vector databases so"
      },
      {
        "start": 569.839,
        "duration": 4.321,
        "text": "yeah just just for full context there"
      },
      {
        "start": 572.68,
        "duration": 4.56,
        "text": "for sure it was just Annie and I hacking"
      },
      {
        "start": 574.16,
        "duration": 6.32,
        "text": "away at it for for a couple days"
      },
      {
        "start": 577.24,
        "duration": 4.719,
        "text": "so and so to kind of set the scene um we"
      },
      {
        "start": 580.48,
        "duration": 2.76,
        "text": "can talk a little B about Vector search"
      },
      {
        "start": 581.959,
        "duration": 2.921,
        "text": "because that's what's going on on the"
      },
      {
        "start": 583.24,
        "duration": 3.159,
        "text": "back end with our database to"
      },
      {
        "start": 584.88,
        "duration": 3.88,
        "text": "essentially perform these similarity"
      },
      {
        "start": 586.399,
        "duration": 4.641,
        "text": "searches and so one question that comes"
      },
      {
        "start": 588.76,
        "duration": 3.84,
        "text": "to mind is what even is Vector search"
      },
      {
        "start": 591.04,
        "duration": 3.88,
        "text": "well essentially it's a method of"
      },
      {
        "start": 592.6,
        "duration": 4.919,
        "text": "finding semantically relevant"
      },
      {
        "start": 594.92,
        "duration": 4.919,
        "text": "information um from one another and we"
      },
      {
        "start": 597.519,
        "duration": 5.641,
        "text": "can convert this type of you know data"
      },
      {
        "start": 599.839,
        "duration": 5.841,
        "text": "text images audio to something called"
      },
      {
        "start": 603.16,
        "duration": 5.16,
        "text": "embeddings or you know a long list of"
      },
      {
        "start": 605.68,
        "duration": 5.399,
        "text": "numbers and this is a one toone match"
      },
      {
        "start": 608.32,
        "duration": 4.8,
        "text": "with the piece of data that way you know"
      },
      {
        "start": 611.079,
        "duration": 4.32,
        "text": "when meaningful embeddings are stored"
      },
      {
        "start": 613.12,
        "duration": 4.64,
        "text": "within like a vector database like astb"
      },
      {
        "start": 615.399,
        "duration": 4.841,
        "text": "for example we can search for similar"
      },
      {
        "start": 617.76,
        "duration": 5.639,
        "text": "unstructured data without having to rely"
      },
      {
        "start": 620.24,
        "duration": 5.48,
        "text": "on key words or structured filters and"
      },
      {
        "start": 623.399,
        "duration": 4.44,
        "text": "so that's kind of the the core backend"
      },
      {
        "start": 625.72,
        "duration": 3.48,
        "text": "framework for this application a really"
      },
      {
        "start": 627.839,
        "duration": 3.841,
        "text": "cool example that I like to think about"
      },
      {
        "start": 629.2,
        "duration": 5.72,
        "text": "is is hey let's take the the fruit apple"
      },
      {
        "start": 631.68,
        "duration": 5.599,
        "text": "for example well you can see here that"
      },
      {
        "start": 634.92,
        "duration": 5.24,
        "text": "the vector embedding in this you know"
      },
      {
        "start": 637.279,
        "duration": 5.601,
        "text": "300 dimensional space here is you know"
      },
      {
        "start": 640.16,
        "duration": 5.4,
        "text": "somewhat over here but if I were to take"
      },
      {
        "start": 642.88,
        "duration": 5.24,
        "text": "the fruit banana right it's going to be"
      },
      {
        "start": 645.56,
        "duration": 3.719,
        "text": "mapped or plotted very similar to Apple"
      },
      {
        "start": 648.12,
        "duration": 4.2,
        "text": "because they're semantically or"
      },
      {
        "start": 649.279,
        "duration": 4.921,
        "text": "contextually relevant to one another um"
      },
      {
        "start": 652.32,
        "duration": 4.4,
        "text": "and that way when I take the you know"
      },
      {
        "start": 654.2,
        "duration": 4.439,
        "text": "company Apple you see right over here um"
      },
      {
        "start": 656.72,
        "duration": 4.0,
        "text": "it'll be stored a little bit further"
      },
      {
        "start": 658.639,
        "duration": 3.841,
        "text": "away than apple and banana because it"
      },
      {
        "start": 660.72,
        "duration": 4.4,
        "text": "doesn't really have the same semantic"
      },
      {
        "start": 662.48,
        "duration": 5.12,
        "text": "meaning or contextual characteristics of"
      },
      {
        "start": 665.12,
        "duration": 4.76,
        "text": "our fruit and so you can see here that"
      },
      {
        "start": 667.6,
        "duration": 4.359,
        "text": "you know the company Apple is actually"
      },
      {
        "start": 669.88,
        "duration": 3.56,
        "text": "closer to the company Google and they"
      },
      {
        "start": 671.959,
        "duration": 4.481,
        "text": "would be kind of returned within the"
      },
      {
        "start": 673.44,
        "duration": 4.199,
        "text": "same vector or similarity search and so"
      },
      {
        "start": 676.44,
        "duration": 3.8,
        "text": "that's really what Vector search at the"
      },
      {
        "start": 677.639,
        "duration": 4.561,
        "text": "end of the day is it's really good for"
      },
      {
        "start": 680.24,
        "duration": 5.12,
        "text": "you know taking unstructured data and"
      },
      {
        "start": 682.2,
        "duration": 5.12,
        "text": "finding similarities between one another"
      },
      {
        "start": 685.36,
        "duration": 3.64,
        "text": "and with that being said we can maybe"
      },
      {
        "start": 687.32,
        "duration": 3.6,
        "text": "dive into a little bit about multimodal"
      },
      {
        "start": 689.0,
        "duration": 3.88,
        "text": "model mod and then we'll get into how"
      },
      {
        "start": 690.92,
        "duration": 5.159,
        "text": "Vector search and multimodal models kind"
      },
      {
        "start": 692.88,
        "duration": 3.199,
        "text": "of work together with one"
      },
      {
        "start": 696.16,
        "duration": 4.96,
        "text": "another and so what are multimodal"
      },
      {
        "start": 698.32,
        "duration": 4.959,
        "text": "models well you know in the AI space how"
      },
      {
        "start": 701.12,
        "duration": 4.64,
        "text": "I like to think about it is a mode or"
      },
      {
        "start": 703.279,
        "duration": 4.881,
        "text": "modality is essentially a type of data"
      },
      {
        "start": 705.76,
        "duration": 5.04,
        "text": "that we can either use as an input or an"
      },
      {
        "start": 708.16,
        "duration": 4.32,
        "text": "output to a gen model and so what you"
      },
      {
        "start": 710.8,
        "duration": 4.24,
        "text": "see here in this diagram is we can take"
      },
      {
        "start": 712.48,
        "duration": 4.76,
        "text": "things like text images audio you know"
      },
      {
        "start": 715.04,
        "duration": 4.239,
        "text": "video so on and so forth and we can"
      },
      {
        "start": 717.24,
        "duration": 4.839,
        "text": "either you know build this knowledge BAS"
      },
      {
        "start": 719.279,
        "duration": 4.641,
        "text": "base or insert it into our gen model and"
      },
      {
        "start": 722.079,
        "duration": 4.801,
        "text": "either you know use it as an input or"
      },
      {
        "start": 723.92,
        "duration": 6.039,
        "text": "retrieve output from it um and these"
      },
      {
        "start": 726.88,
        "duration": 6.04,
        "text": "multimodal models allow you know these"
      },
      {
        "start": 729.959,
        "duration": 5.44,
        "text": "these gen models to essentially have a"
      },
      {
        "start": 732.92,
        "duration": 5.039,
        "text": "um a broader you know characteristics of"
      },
      {
        "start": 735.399,
        "duration": 4.841,
        "text": "our data and understand you know a"
      },
      {
        "start": 737.959,
        "duration": 5.041,
        "text": "better definition of our knowledge base"
      },
      {
        "start": 740.24,
        "duration": 5.2,
        "text": "so what are examples well you know llms"
      },
      {
        "start": 743.0,
        "duration": 5.519,
        "text": "for example you know we have some uh you"
      },
      {
        "start": 745.44,
        "duration": 4.8,
        "text": "know chat GPT Bard um there's a variety"
      },
      {
        "start": 748.519,
        "duration": 3.281,
        "text": "of different multi modal llms that are"
      },
      {
        "start": 750.24,
        "duration": 4.52,
        "text": "provided out there in the world that we"
      },
      {
        "start": 751.8,
        "duration": 5.599,
        "text": "can use secondly our embedding models we"
      },
      {
        "start": 754.76,
        "duration": 5.48,
        "text": "have open AI Ada 002 model you know"
      },
      {
        "start": 757.399,
        "duration": 4.961,
        "text": "nvidia's embed Q&A model so on and so"
      },
      {
        "start": 760.24,
        "duration": 3.92,
        "text": "forth um there's tons of embedding"
      },
      {
        "start": 762.36,
        "duration": 3.719,
        "text": "models out there in the world um that we"
      },
      {
        "start": 764.16,
        "duration": 4.08,
        "text": "can use that are multimodel you know"
      },
      {
        "start": 766.079,
        "duration": 5.081,
        "text": "capable and then lastly our diffusion"
      },
      {
        "start": 768.24,
        "duration": 5.76,
        "text": "models we have stable diffusion Dolly"
      },
      {
        "start": 771.16,
        "duration": 6.16,
        "text": "etc etc um and all of these fit under"
      },
      {
        "start": 774.0,
        "duration": 5.279,
        "text": "this umbrella of multimodal models great"
      },
      {
        "start": 777.32,
        "duration": 5.879,
        "text": "uh I'm going to pause you for a second"
      },
      {
        "start": 779.279,
        "duration": 6.161,
        "text": "for a question so uh someone's asking so"
      },
      {
        "start": 783.199,
        "duration": 5.2,
        "text": "the word Apple could appear several"
      },
      {
        "start": 785.44,
        "duration": 2.959,
        "text": "times in a vector"
      },
      {
        "start": 789.6,
        "duration": 5.039,
        "text": "database uh yeah for sure it could um"
      },
      {
        "start": 792.6,
        "duration": 4.239,
        "text": "depending on how you you structure your"
      },
      {
        "start": 794.639,
        "duration": 5.841,
        "text": "database you can either have only just"
      },
      {
        "start": 796.839,
        "duration": 5.041,
        "text": "one um you know one piece of data stored"
      },
      {
        "start": 800.48,
        "duration": 3.56,
        "text": "within the database or you can have"
      },
      {
        "start": 801.88,
        "duration": 4.199,
        "text": "apple multiple times um it's really up"
      },
      {
        "start": 804.04,
        "duration": 3.479,
        "text": "to you but it's more for that Vector"
      },
      {
        "start": 806.079,
        "duration": 3.161,
        "text": "search part where if you were to search"
      },
      {
        "start": 807.519,
        "duration": 3.76,
        "text": "for something like a banana or or"
      },
      {
        "start": 809.24,
        "duration": 3.52,
        "text": "another fruit then maybe you know an"
      },
      {
        "start": 811.279,
        "duration": 3.961,
        "text": "apple and all the other fruits would be"
      },
      {
        "start": 812.76,
        "duration": 3.8,
        "text": "returned back to the user um if there's"
      },
      {
        "start": 815.24,
        "duration": 4.039,
        "text": "anything else you wanted to add to that"
      },
      {
        "start": 816.56,
        "duration": 5.0,
        "text": "Annie yeah yeah I think I think like in"
      },
      {
        "start": 819.279,
        "duration": 5.201,
        "text": "this situation I think the data being"
      },
      {
        "start": 821.56,
        "duration": 5.839,
        "text": "stored wouldn't be just the word Apple"
      },
      {
        "start": 824.48,
        "duration": 6.599,
        "text": "it would be like apple plus some"
      },
      {
        "start": 827.399,
        "duration": 5.281,
        "text": "surrounding context um so the way that"
      },
      {
        "start": 831.079,
        "duration": 3.401,
        "text": "you different like the only way to get"
      },
      {
        "start": 832.68,
        "duration": 3.76,
        "text": "different embeddings for Apple the"
      },
      {
        "start": 834.48,
        "duration": 4.64,
        "text": "company and apple the fruit is if you"
      },
      {
        "start": 836.44,
        "duration": 5.04,
        "text": "also have text describing kind of like"
      },
      {
        "start": 839.12,
        "duration": 5.12,
        "text": "giving context on what which Apple"
      },
      {
        "start": 841.48,
        "duration": 4.479,
        "text": "you're actually talking about so maybe"
      },
      {
        "start": 844.24,
        "duration": 3.959,
        "text": "you'd have a sentence that's like"
      },
      {
        "start": 845.959,
        "duration": 4.641,
        "text": "someone plugged an apple from a tree and"
      },
      {
        "start": 848.199,
        "duration": 6.521,
        "text": "then the other sentence would be like"
      },
      {
        "start": 850.6,
        "duration": 6.4,
        "text": "apple made1 billion dollar last year um"
      },
      {
        "start": 854.72,
        "duration": 5.44,
        "text": "and so if you were doing a vector search"
      },
      {
        "start": 857.0,
        "duration": 5.32,
        "text": "for like apple the company the sentence"
      },
      {
        "start": 860.16,
        "duration": 5.119,
        "text": "that you'd get back is probably related"
      },
      {
        "start": 862.32,
        "duration": 4.639,
        "text": "to Apple making however much money"
      },
      {
        "start": 865.279,
        "duration": 4.521,
        "text": "instead of the Apple getting plucked"
      },
      {
        "start": 866.959,
        "duration": 5.0,
        "text": "from the tree so that that's like"
      },
      {
        "start": 869.8,
        "duration": 4.56,
        "text": "how like what what you're giving to the"
      },
      {
        "start": 871.959,
        "duration": 6.281,
        "text": "model allows it to differentiate based"
      },
      {
        "start": 874.36,
        "duration": 6.32,
        "text": "on existing context that's a I think"
      },
      {
        "start": 878.24,
        "duration": 4.64,
        "text": "that's it's a very good point Annie um"
      },
      {
        "start": 880.68,
        "duration": 4.8,
        "text": "very rarely do we actually embed just a"
      },
      {
        "start": 882.88,
        "duration": 4.84,
        "text": "singular word um usually we actually"
      },
      {
        "start": 885.48,
        "duration": 4.96,
        "text": "have something called chunks um which"
      },
      {
        "start": 887.72,
        "duration": 4.72,
        "text": "are um you know a long list of you know"
      },
      {
        "start": 890.44,
        "duration": 3.759,
        "text": "either a paragraph or a full image and"
      },
      {
        "start": 892.44,
        "duration": 4.28,
        "text": "things like that things where we have"
      },
      {
        "start": 894.199,
        "duration": 4.08,
        "text": "the full context of what's going on and"
      },
      {
        "start": 896.72,
        "duration": 4.32,
        "text": "then we can embed that into the vector"
      },
      {
        "start": 898.279,
        "duration": 2.761,
        "text": "database"
      },
      {
        "start": 901.72,
        "duration": 3.919,
        "text": "any other questions let me look over"
      },
      {
        "start": 904.16,
        "duration": 6.44,
        "text": "onto our chat real"
      },
      {
        "start": 905.639,
        "duration": 7.76,
        "text": "quick awesome we should be good great"
      },
      {
        "start": 910.6,
        "duration": 4.76,
        "text": "question and so right how does Vector"
      },
      {
        "start": 913.399,
        "duration": 4.641,
        "text": "search and multimodal models kind of"
      },
      {
        "start": 915.36,
        "duration": 5.24,
        "text": "work hand inand well really there's two"
      },
      {
        "start": 918.04,
        "duration": 5.359,
        "text": "ways of doing this method one is we can"
      },
      {
        "start": 920.6,
        "duration": 5.32,
        "text": "take a piece of multiply medal data say"
      },
      {
        "start": 923.399,
        "duration": 4.521,
        "text": "an audio file right and use an audio"
      },
      {
        "start": 925.92,
        "duration": 4.12,
        "text": "embedding model which you see right over"
      },
      {
        "start": 927.92,
        "duration": 4.88,
        "text": "here to generate Vector embeddings which"
      },
      {
        "start": 930.04,
        "duration": 4.479,
        "text": "we can then store into a vector database"
      },
      {
        "start": 932.8,
        "duration": 4.159,
        "text": "and so there's tons of you know"
      },
      {
        "start": 934.519,
        "duration": 4.521,
        "text": "multimodal embedding models that match"
      },
      {
        "start": 936.959,
        "duration": 3.44,
        "text": "the type of data and you can use those"
      },
      {
        "start": 939.04,
        "duration": 3.84,
        "text": "that's kind of like the direct"
      },
      {
        "start": 940.399,
        "duration": 4.44,
        "text": "conversion method it's very simple but"
      },
      {
        "start": 942.88,
        "duration": 4.6,
        "text": "actually there's also a method too where"
      },
      {
        "start": 944.839,
        "duration": 5.201,
        "text": "we use an llm as a Transformer to"
      },
      {
        "start": 947.48,
        "duration": 5.919,
        "text": "essentially take this multimodal data"
      },
      {
        "start": 950.04,
        "duration": 5.479,
        "text": "pass it to an llm for interpretation and"
      },
      {
        "start": 953.399,
        "duration": 4.761,
        "text": "then the llm will usually spit back some"
      },
      {
        "start": 955.519,
        "duration": 4.961,
        "text": "description or its response and we can"
      },
      {
        "start": 958.16,
        "duration": 4.88,
        "text": "actually embed the response given back"
      },
      {
        "start": 960.48,
        "duration": 5.039,
        "text": "from the llm and use that to store it"
      },
      {
        "start": 963.04,
        "duration": 3.919,
        "text": "within our Vector database and this is"
      },
      {
        "start": 965.519,
        "duration": 3.721,
        "text": "actually what we will be demonstrating"
      },
      {
        "start": 966.959,
        "duration": 4.12,
        "text": "this is what vibe Che uses uh we are not"
      },
      {
        "start": 969.24,
        "duration": 3.32,
        "text": "necessarily taking songs and embedding"
      },
      {
        "start": 971.079,
        "duration": 3.601,
        "text": "the songs directly we're actually"
      },
      {
        "start": 972.56,
        "duration": 4.24,
        "text": "passing them to an llm to generate a"
      },
      {
        "start": 974.68,
        "duration": 4.959,
        "text": "description of the song and then you"
      },
      {
        "start": 976.8,
        "duration": 4.519,
        "text": "know embed that in stor in astb but we"
      },
      {
        "start": 979.639,
        "duration": 3.601,
        "text": "will go far more in depth into that and"
      },
      {
        "start": 981.319,
        "duration": 5.041,
        "text": "actually show you how we've done it um"
      },
      {
        "start": 983.24,
        "duration": 5.44,
        "text": "via the code but this method to um is"
      },
      {
        "start": 986.36,
        "duration": 5.32,
        "text": "usually what we like to do for um you"
      },
      {
        "start": 988.68,
        "duration": 6.24,
        "text": "know working with multimodal"
      },
      {
        "start": 991.68,
        "duration": 5.0,
        "text": "data great and yes llm is a large"
      },
      {
        "start": 994.92,
        "duration": 5.2,
        "text": "language"
      },
      {
        "start": 996.68,
        "duration": 5.36,
        "text": "model sweet okay before we kind of hop"
      },
      {
        "start": 1000.12,
        "duration": 4.76,
        "text": "into the demo and stuff I just want to"
      },
      {
        "start": 1002.04,
        "duration": 5.4,
        "text": "check if all of that context makes sense"
      },
      {
        "start": 1004.88,
        "duration": 5.199,
        "text": "to folks if there's any other questions"
      },
      {
        "start": 1007.44,
        "duration": 5.8,
        "text": "before we dive into it or if we're ready"
      },
      {
        "start": 1010.079,
        "duration": 3.161,
        "text": "to just kind of get"
      },
      {
        "start": 1016.279,
        "duration": 7.081,
        "text": "going sweet yeah let's see let's see the"
      },
      {
        "start": 1019.12,
        "duration": 7.959,
        "text": "code um it do you want to Great okay let"
      },
      {
        "start": 1023.36,
        "duration": 3.719,
        "text": "me present my screen"
      },
      {
        "start": 1032.24,
        "duration": 7.679,
        "text": "now and then can people see my screen"
      },
      {
        "start": 1035.28,
        "duration": 8.039,
        "text": "here so I have slides I have code a"
      },
      {
        "start": 1039.919,
        "duration": 3.4,
        "text": "terminal file"
      },
      {
        "start": 1044.28,
        "duration": 5.92,
        "text": "explorer sorry you're able to see okay"
      },
      {
        "start": 1047.439,
        "duration": 6.001,
        "text": "great great great great okay okay um"
      },
      {
        "start": 1050.2,
        "duration": 6.719,
        "text": "sweet so I'm going to uh basically we"
      },
      {
        "start": 1053.44,
        "duration": 6.52,
        "text": "have this um project this streamlit"
      },
      {
        "start": 1056.919,
        "duration": 5.921,
        "text": "project um and we have it as a GitHub"
      },
      {
        "start": 1059.96,
        "duration": 5.4,
        "text": "repository which let me actually pull"
      },
      {
        "start": 1062.84,
        "duration": 5.24,
        "text": "that up for folks if they want to take a"
      },
      {
        "start": 1065.36,
        "duration": 6.08,
        "text": "look"
      },
      {
        "start": 1068.08,
        "duration": 5.68,
        "text": "um great and then if you wanted to like"
      },
      {
        "start": 1071.44,
        "duration": 4.119,
        "text": "afterwards make a copy of the repo to"
      },
      {
        "start": 1073.76,
        "duration": 3.48,
        "text": "check out the code and try it running"
      },
      {
        "start": 1075.559,
        "duration": 3.681,
        "text": "try and run it yourself on your own"
      },
      {
        "start": 1077.24,
        "duration": 4.16,
        "text": "playlist data uh there's there's full"
      },
      {
        "start": 1079.24,
        "duration": 4.52,
        "text": "instructions on how to do that and the"
      },
      {
        "start": 1081.4,
        "duration": 5.44,
        "text": "GitHub repo and some other other useful"
      },
      {
        "start": 1083.76,
        "duration": 6.44,
        "text": "links um but let's go ahead and get this"
      },
      {
        "start": 1086.84,
        "duration": 8.0,
        "text": "app running so I'm going to use this"
      },
      {
        "start": 1090.2,
        "duration": 8.32,
        "text": "command streamlet run streamlet"
      },
      {
        "start": 1094.84,
        "duration": 7.199,
        "text": "app.py uh and that opens up our Vibe"
      },
      {
        "start": 1098.52,
        "duration": 5.159,
        "text": "check demo here um and then would it be"
      },
      {
        "start": 1102.039,
        "duration": 3.12,
        "text": "useful for me to zoom more or does this"
      },
      {
        "start": 1103.679,
        "duration": 4.441,
        "text": "look"
      },
      {
        "start": 1105.159,
        "duration": 4.441,
        "text": "okay it looks good to me but if folks"
      },
      {
        "start": 1108.12,
        "duration": 3.679,
        "text": "want us to zoom in a little bit more we"
      },
      {
        "start": 1109.6,
        "duration": 4.52,
        "text": "can more than you know definitely do"
      },
      {
        "start": 1111.799,
        "duration": 4.641,
        "text": "so okay I'll I'll leave it unless"
      },
      {
        "start": 1114.12,
        "duration": 6.2,
        "text": "someone in the chat requests a little"
      },
      {
        "start": 1116.44,
        "duration": 7.88,
        "text": "Zoom okay let's go zoom in a little bit"
      },
      {
        "start": 1120.32,
        "duration": 7.44,
        "text": "more cool great okay so so this is what"
      },
      {
        "start": 1124.32,
        "duration": 7.44,
        "text": "the UI of the demo looks like uh it's"
      },
      {
        "start": 1127.76,
        "duration": 5.6,
        "text": "kind of split into two sections so this"
      },
      {
        "start": 1131.76,
        "duration": 4.12,
        "text": "section is where you connect to your"
      },
      {
        "start": 1133.36,
        "duration": 5.6,
        "text": "playlist and do the ingestion and this"
      },
      {
        "start": 1135.88,
        "duration": 6.0,
        "text": "one is where we actually are finding our"
      },
      {
        "start": 1138.96,
        "duration": 5.959,
        "text": "songs so this is connected to my camera"
      },
      {
        "start": 1141.88,
        "duration": 6.64,
        "text": "here you can actually see um see a"
      },
      {
        "start": 1144.919,
        "duration": 6.081,
        "text": "preview of of what we can do um but I'll"
      },
      {
        "start": 1148.52,
        "duration": 4.68,
        "text": "just kind of demonstrate like what that"
      },
      {
        "start": 1151.0,
        "duration": 5.44,
        "text": "final end result is supposed to look"
      },
      {
        "start": 1153.2,
        "duration": 5.959,
        "text": "like um so what we wanted to do is to be"
      },
      {
        "start": 1156.44,
        "duration": 5.599,
        "text": "able to take a picture of our setting"
      },
      {
        "start": 1159.159,
        "duration": 5.841,
        "text": "and then from that get recommendations"
      },
      {
        "start": 1162.039,
        "duration": 5.52,
        "text": "of songs that would match that setting"
      },
      {
        "start": 1165.0,
        "duration": 5.44,
        "text": "um this this app is currently connected"
      },
      {
        "start": 1167.559,
        "duration": 5.841,
        "text": "to a playlist that we created for this"
      },
      {
        "start": 1170.44,
        "duration": 6.32,
        "text": "demo um so if we want to take a look at"
      },
      {
        "start": 1173.4,
        "duration": 6.8,
        "text": "that um we've loaded all of the data"
      },
      {
        "start": 1176.76,
        "duration": 6.48,
        "text": "from this playlist uh"
      },
      {
        "start": 1180.2,
        "duration": 6.64,
        "text": "into into our Astro database to be"
      },
      {
        "start": 1183.24,
        "duration": 6.559,
        "text": "accessed by Vi Che so here we have 18"
      },
      {
        "start": 1186.84,
        "duration": 6.719,
        "text": "songs with a pretty wide variety some"
      },
      {
        "start": 1189.799,
        "duration": 6.921,
        "text": "tame andala some espresso by Sabrina"
      },
      {
        "start": 1193.559,
        "duration": 7.441,
        "text": "Carpenter stronger uh we also added a"
      },
      {
        "start": 1196.72,
        "duration": 6.319,
        "text": "couple of Halloween songs down here um"
      },
      {
        "start": 1201.0,
        "duration": 4.96,
        "text": "so there's kind of a wide variety of"
      },
      {
        "start": 1203.039,
        "duration": 5.0,
        "text": "moods in this playlist that might not"
      },
      {
        "start": 1205.96,
        "duration": 4.839,
        "text": "match like all of the songs don't match"
      },
      {
        "start": 1208.039,
        "duration": 5.12,
        "text": "every single situation that you're in um"
      },
      {
        "start": 1210.799,
        "duration": 6.441,
        "text": "so just to kind of show what that search"
      },
      {
        "start": 1213.159,
        "duration": 6.561,
        "text": "functionality looks like if I uploaded"
      },
      {
        "start": 1217.24,
        "duration": 7.52,
        "text": "for example this"
      },
      {
        "start": 1219.72,
        "duration": 7.56,
        "text": "picture um it's it's this one it's a"
      },
      {
        "start": 1224.76,
        "duration": 4.84,
        "text": "picture of a bunch of Jacko lanterns"
      },
      {
        "start": 1227.28,
        "duration": 4.8,
        "text": "very spooky very Halloween"
      },
      {
        "start": 1229.6,
        "duration": 6.24,
        "text": "um and then wanted to find songs within"
      },
      {
        "start": 1232.08,
        "duration": 5.839,
        "text": "that playlist that match this uh here"
      },
      {
        "start": 1235.84,
        "duration": 4.44,
        "text": "it's running a bit and then we can see a"
      },
      {
        "start": 1237.919,
        "duration": 4.88,
        "text": "preview of the image and then here we"
      },
      {
        "start": 1240.28,
        "duration": 6.04,
        "text": "see top recommended songs from that"
      },
      {
        "start": 1242.799,
        "duration": 6.24,
        "text": "playlist spooky scary skeletons Monster"
      },
      {
        "start": 1246.32,
        "duration": 6.16,
        "text": "Mash Ghostbusters and those are all"
      },
      {
        "start": 1249.039,
        "duration": 5.321,
        "text": "three of the Halloween songs that we got"
      },
      {
        "start": 1252.48,
        "duration": 3.28,
        "text": "um that we have in this playlist so all"
      },
      {
        "start": 1254.36,
        "duration": 5.08,
        "text": "of those were returned as well as a"
      },
      {
        "start": 1255.76,
        "duration": 6.88,
        "text": "couple of other ones that also have some"
      },
      {
        "start": 1259.44,
        "duration": 6.92,
        "text": "similarity so yeah this this is like the"
      },
      {
        "start": 1262.64,
        "duration": 6.519,
        "text": "result that we wanted um we using this"
      },
      {
        "start": 1266.36,
        "duration": 4.84,
        "text": "image we got a recommendation um so"
      },
      {
        "start": 1269.159,
        "duration": 4.0,
        "text": "let's let's kind of back up a little bit"
      },
      {
        "start": 1271.2,
        "duration": 4.079,
        "text": "and we're going to talk about the"
      },
      {
        "start": 1273.159,
        "duration": 4.241,
        "text": "architecture of the full app like what"
      },
      {
        "start": 1275.279,
        "duration": 5.361,
        "text": "the ingestion actually looks like and"
      },
      {
        "start": 1277.4,
        "duration": 6.759,
        "text": "what the querying looks like"
      },
      {
        "start": 1280.64,
        "duration": 5.639,
        "text": "um and here we have our architecture"
      },
      {
        "start": 1284.159,
        "duration": 4.481,
        "text": "slide where we can talk through that uh"
      },
      {
        "start": 1286.279,
        "duration": 4.601,
        "text": "I do see a couple of questions in the"
      },
      {
        "start": 1288.64,
        "duration": 4.399,
        "text": "chat so before we start talking about"
      },
      {
        "start": 1290.88,
        "duration": 4.88,
        "text": "this um do we want to go through a"
      },
      {
        "start": 1293.039,
        "duration": 4.921,
        "text": "couple of those let's do it yeah I see"
      },
      {
        "start": 1295.76,
        "duration": 4.159,
        "text": "one right here saying what's more"
      },
      {
        "start": 1297.96,
        "duration": 4.68,
        "text": "efficient should we do a direct"
      },
      {
        "start": 1299.919,
        "duration": 6.24,
        "text": "conversion or through an"
      },
      {
        "start": 1302.64,
        "duration": 5.84,
        "text": "llm um any thoughts on that Annie sorry"
      },
      {
        "start": 1306.159,
        "duration": 4.4,
        "text": "let me let me see the is it in the Q&A"
      },
      {
        "start": 1308.48,
        "duration": 3.36,
        "text": "or is it in the chat section looks to be"
      },
      {
        "start": 1310.559,
        "duration": 5.281,
        "text": "in the"
      },
      {
        "start": 1311.84,
        "duration": 5.12,
        "text": "chat um direct conversion or through llm"
      },
      {
        "start": 1315.84,
        "duration": 4.48,
        "text": "I"
      },
      {
        "start": 1316.96,
        "duration": 5.92,
        "text": "think um"
      },
      {
        "start": 1320.32,
        "duration": 5.599,
        "text": "honestly I think both are useful it kind"
      },
      {
        "start": 1322.88,
        "duration": 6.36,
        "text": "of depends on what your use case in in"
      },
      {
        "start": 1325.919,
        "duration": 6.0,
        "text": "in both cases you would be sending the"
      },
      {
        "start": 1329.24,
        "duration": 3.88,
        "text": "same amount of tokens to whatever model"
      },
      {
        "start": 1331.919,
        "duration": 2.88,
        "text": "it is that you're"
      },
      {
        "start": 1333.12,
        "duration": 5.4,
        "text": "using"
      },
      {
        "start": 1334.799,
        "duration": 5.36,
        "text": "um honestly honestly direct conversion"
      },
      {
        "start": 1338.52,
        "duration": 5.24,
        "text": "might be more efficient because you're"
      },
      {
        "start": 1340.159,
        "duration": 6.281,
        "text": "only using a model once whereas in this"
      },
      {
        "start": 1343.76,
        "duration": 6.24,
        "text": "situation we're using a large language"
      },
      {
        "start": 1346.44,
        "duration": 7.0,
        "text": "model to do one step which is converting"
      },
      {
        "start": 1350.0,
        "duration": 5.84,
        "text": "the non-text data into Text data and"
      },
      {
        "start": 1353.44,
        "duration": 4.44,
        "text": "then we're using an embeddings model for"
      },
      {
        "start": 1355.84,
        "duration": 5.719,
        "text": "another step which is converting that"
      },
      {
        "start": 1357.88,
        "duration": 6.32,
        "text": "text Data into um into an actual"
      },
      {
        "start": 1361.559,
        "duration": 5.201,
        "text": "embedding uh so into that like string"
      },
      {
        "start": 1364.2,
        "duration": 4.88,
        "text": "long array of numbers that represents"
      },
      {
        "start": 1366.76,
        "duration": 4.799,
        "text": "that text so there that's like two steps"
      },
      {
        "start": 1369.08,
        "duration": 6.32,
        "text": "of querying models versus if you do a"
      },
      {
        "start": 1371.559,
        "duration": 5.801,
        "text": "direct conversion um of like taking an"
      },
      {
        "start": 1375.4,
        "duration": 5.24,
        "text": "image and creating embeddings directly"
      },
      {
        "start": 1377.36,
        "duration": 5.199,
        "text": "from the image uh but also I feel like"
      },
      {
        "start": 1380.64,
        "duration": 4.56,
        "text": "image embeddings models might be like"
      },
      {
        "start": 1382.559,
        "duration": 5.521,
        "text": "more expensive uh they're more"
      },
      {
        "start": 1385.2,
        "duration": 5.719,
        "text": "specialized so there there's a chance"
      },
      {
        "start": 1388.08,
        "duration": 5.76,
        "text": "that it might it might not work exactly"
      },
      {
        "start": 1390.919,
        "duration": 4.36,
        "text": "the way that you want um but but yeah it"
      },
      {
        "start": 1393.84,
        "duration": 2.719,
        "text": "it kind of comes down to what exactly"
      },
      {
        "start": 1395.279,
        "duration": 4.0,
        "text": "you're doing anything else you'd add"
      },
      {
        "start": 1396.559,
        "duration": 4.6,
        "text": "there andy no I totally agree I think"
      },
      {
        "start": 1399.279,
        "duration": 4.481,
        "text": "both of them are totally fine it just"
      },
      {
        "start": 1401.159,
        "duration": 4.241,
        "text": "really depends on the type of data that"
      },
      {
        "start": 1403.76,
        "duration": 3.56,
        "text": "you want to be stored in the database so"
      },
      {
        "start": 1405.4,
        "duration": 4.72,
        "text": "obviously multimodal data let's take an"
      },
      {
        "start": 1407.32,
        "duration": 4.52,
        "text": "audio file or an image for example right"
      },
      {
        "start": 1410.12,
        "duration": 3.559,
        "text": "this has a lot of noise in it where"
      },
      {
        "start": 1411.84,
        "duration": 3.64,
        "text": "sometimes you don't want to be embedding"
      },
      {
        "start": 1413.679,
        "duration": 3.321,
        "text": "um all those external factors so for"
      },
      {
        "start": 1415.48,
        "duration": 3.199,
        "text": "example if I have a picture of myself"
      },
      {
        "start": 1417.0,
        "duration": 3.279,
        "text": "right as a piece of multimodal data"
      },
      {
        "start": 1418.679,
        "duration": 3.561,
        "text": "Maybe I only want to focus on what I'm"
      },
      {
        "start": 1420.279,
        "duration": 4.721,
        "text": "wearing for example right and nothing to"
      },
      {
        "start": 1422.24,
        "duration": 4.52,
        "text": "do with my background or um what's going"
      },
      {
        "start": 1425.0,
        "duration": 3.24,
        "text": "on in the Forefront of the photo things"
      },
      {
        "start": 1426.76,
        "duration": 3.2,
        "text": "like that that's where you'd probably"
      },
      {
        "start": 1428.24,
        "duration": 3.4,
        "text": "want to pass it to an llm to write a"
      },
      {
        "start": 1429.96,
        "duration": 3.959,
        "text": "description of exactly you know you'd"
      },
      {
        "start": 1431.64,
        "duration": 4.2,
        "text": "give it a prompt of hey describe only"
      },
      {
        "start": 1433.919,
        "duration": 3.801,
        "text": "what the user is wearing so on and so"
      },
      {
        "start": 1435.84,
        "duration": 3.56,
        "text": "forth and then embed that rather than"
      },
      {
        "start": 1437.72,
        "duration": 3.72,
        "text": "the image itself because if you were to"
      },
      {
        "start": 1439.4,
        "duration": 3.519,
        "text": "do the entire image you know all those"
      },
      {
        "start": 1441.44,
        "duration": 3.32,
        "text": "characteristics of the entire image are"
      },
      {
        "start": 1442.919,
        "duration": 4.24,
        "text": "going to be embedded um and sometimes"
      },
      {
        "start": 1444.76,
        "duration": 4.0,
        "text": "you don't want that extra noise um you"
      },
      {
        "start": 1447.159,
        "duration": 3.801,
        "text": "know within you know your vector"
      },
      {
        "start": 1448.76,
        "duration": 4.44,
        "text": "database or within your"
      },
      {
        "start": 1450.96,
        "duration": 5.48,
        "text": "embedding"
      },
      {
        "start": 1453.2,
        "duration": 5.079,
        "text": "great well can the similar logic and"
      },
      {
        "start": 1456.44,
        "duration": 4.96,
        "text": "principle be applied to videos instead"
      },
      {
        "start": 1458.279,
        "duration": 4.441,
        "text": "of a Spotify playlist uh I would I would"
      },
      {
        "start": 1461.4,
        "duration": 5.159,
        "text": "assume yes if you're as long as you're"
      },
      {
        "start": 1462.72,
        "duration": 6.36,
        "text": "able to pass uh info about the video so"
      },
      {
        "start": 1466.559,
        "duration": 4.321,
        "text": "maybe a couple frames from the video"
      },
      {
        "start": 1469.08,
        "duration": 3.56,
        "text": "I mean a video is just like a ton of"
      },
      {
        "start": 1470.88,
        "duration": 4.12,
        "text": "images right so you if you wanted you"
      },
      {
        "start": 1472.64,
        "duration": 3.96,
        "text": "could pass all of those images to the"
      },
      {
        "start": 1475.0,
        "duration": 3.6,
        "text": "llm and have it do the same thing or"
      },
      {
        "start": 1476.6,
        "duration": 4.48,
        "text": "take a couple of snapshots and have it"
      },
      {
        "start": 1478.6,
        "duration": 6.52,
        "text": "make a guess related to that in order to"
      },
      {
        "start": 1481.08,
        "duration": 5.36,
        "text": "generate some sort of um text text data"
      },
      {
        "start": 1485.12,
        "duration": 4.08,
        "text": "about that"
      },
      {
        "start": 1486.44,
        "duration": 4.68,
        "text": "video and then um when you say"
      },
      {
        "start": 1489.2,
        "duration": 4.4,
        "text": "multimodal does it have to be diffusion"
      },
      {
        "start": 1491.12,
        "duration": 6.0,
        "text": "Plus llm for example it can't be two"
      },
      {
        "start": 1493.6,
        "duration": 6.36,
        "text": "llms operating in an agent manner um in"
      },
      {
        "start": 1497.12,
        "duration": 4.76,
        "text": "this case we're using using one llm in"
      },
      {
        "start": 1499.96,
        "duration": 5.0,
        "text": "an agentic Manner and then we're using"
      },
      {
        "start": 1501.88,
        "duration": 5.76,
        "text": "an embeddings model um directly on that"
      },
      {
        "start": 1504.96,
        "duration": 5.319,
        "text": "text so we're not using diffusion for"
      },
      {
        "start": 1507.64,
        "duration": 6.24,
        "text": "this example um but if you want to use"
      },
      {
        "start": 1510.279,
        "duration": 7.601,
        "text": "multiple llms to do different agentic"
      },
      {
        "start": 1513.88,
        "duration": 6.32,
        "text": "actions that's totally a valid"
      },
      {
        "start": 1517.88,
        "duration": 4.0,
        "text": "approach cool and then there's a couple"
      },
      {
        "start": 1520.2,
        "duration": 4.52,
        "text": "more in the Q&A we can we could just"
      },
      {
        "start": 1521.88,
        "duration": 5.84,
        "text": "like burn through those real quick"
      },
      {
        "start": 1524.72,
        "duration": 4.6,
        "text": "perfect yeah um where does rag fit into"
      },
      {
        "start": 1527.72,
        "duration": 4.439,
        "text": "all of this"
      },
      {
        "start": 1529.32,
        "duration": 5.239,
        "text": "that is an awesome question um"
      },
      {
        "start": 1532.159,
        "duration": 5.041,
        "text": "essentially where this fits in this is"
      },
      {
        "start": 1534.559,
        "duration": 4.72,
        "text": "more of a similarity search that uses an"
      },
      {
        "start": 1537.2,
        "duration": 4.8,
        "text": "llm to write a description of the song"
      },
      {
        "start": 1539.279,
        "duration": 5.361,
        "text": "We embed it and then search um so it's"
      },
      {
        "start": 1542.0,
        "duration": 5.159,
        "text": "not necessarily a onetoone fit with rag"
      },
      {
        "start": 1544.64,
        "duration": 4.0,
        "text": "but it's very easily doable um because"
      },
      {
        "start": 1547.159,
        "duration": 3.601,
        "text": "we can take all the songs that are"
      },
      {
        "start": 1548.64,
        "duration": 3.6,
        "text": "provided by the database and then feed"
      },
      {
        "start": 1550.76,
        "duration": 4.32,
        "text": "it back to an llm for further"
      },
      {
        "start": 1552.24,
        "duration": 4.4,
        "text": "augmentation and so I'd say the the"
      },
      {
        "start": 1555.08,
        "duration": 3.76,
        "text": "retrieval and you know the"
      },
      {
        "start": 1556.64,
        "duration": 5.039,
        "text": "pre-processing step is very similar it's"
      },
      {
        "start": 1558.84,
        "duration": 4.52,
        "text": "a one toone match to rag um all you"
      },
      {
        "start": 1561.679,
        "duration": 3.441,
        "text": "would need to do is just take that data"
      },
      {
        "start": 1563.36,
        "duration": 3.4,
        "text": "that's returned from the vector database"
      },
      {
        "start": 1565.12,
        "duration": 3.559,
        "text": "and feed it to an llm for further"
      },
      {
        "start": 1566.76,
        "duration": 4.159,
        "text": "augmentation and you know generate"
      },
      {
        "start": 1568.679,
        "duration": 5.041,
        "text": "response back to the user and so this"
      },
      {
        "start": 1570.919,
        "duration": 5.041,
        "text": "might not be 100% you know a rag use"
      },
      {
        "start": 1573.72,
        "duration": 3.8,
        "text": "case but it's 90% of the way there um"
      },
      {
        "start": 1575.96,
        "duration": 3.36,
        "text": "we're literally probably missing just"
      },
      {
        "start": 1577.52,
        "duration": 3.6,
        "text": "one llm call at the end for further"
      },
      {
        "start": 1579.32,
        "duration": 3.68,
        "text": "refinement but in our case it's not"
      },
      {
        "start": 1581.12,
        "duration": 3.0,
        "text": "necessarily needed because all of our"
      },
      {
        "start": 1583.0,
        "duration": 3.679,
        "text": "data is already stored within the"
      },
      {
        "start": 1584.12,
        "duration": 4.919,
        "text": "database that we need AK the song name"
      },
      {
        "start": 1586.679,
        "duration": 4.041,
        "text": "the URL to it the artist destion so on"
      },
      {
        "start": 1589.039,
        "duration": 5.321,
        "text": "and so forth so there's no really need"
      },
      {
        "start": 1590.72,
        "duration": 4.64,
        "text": "to have an llm augment that data um is"
      },
      {
        "start": 1594.36,
        "duration": 3.28,
        "text": "that what you were going to say too"
      },
      {
        "start": 1595.36,
        "duration": 6.559,
        "text": "Annie yeah yeah I think that's a great"
      },
      {
        "start": 1597.64,
        "duration": 6.12,
        "text": "answer cool um let's so I see there are"
      },
      {
        "start": 1601.919,
        "duration": 4.081,
        "text": "more questions I think let's let's get"
      },
      {
        "start": 1603.76,
        "duration": 3.799,
        "text": "into the demo a little more and kind of"
      },
      {
        "start": 1606.0,
        "duration": 2.88,
        "text": "show the code and maybe that'll answer"
      },
      {
        "start": 1607.559,
        "duration": 2.921,
        "text": "some of them and then if we have more"
      },
      {
        "start": 1608.88,
        "duration": 5.44,
        "text": "time at the end we can address some of"
      },
      {
        "start": 1610.48,
        "duration": 5.64,
        "text": "the questions that we missed um but here"
      },
      {
        "start": 1614.32,
        "duration": 3.32,
        "text": "yeah I've add this up for a couple"
      },
      {
        "start": 1616.12,
        "duration": 2.76,
        "text": "minutes now this is the architecture"
      },
      {
        "start": 1617.64,
        "duration": 3.759,
        "text": "diagram"
      },
      {
        "start": 1618.88,
        "duration": 5.72,
        "text": "um our app is split into two main"
      },
      {
        "start": 1621.399,
        "duration": 5.961,
        "text": "functions one is ingesting the data and"
      },
      {
        "start": 1624.6,
        "duration": 5.16,
        "text": "then the other part is querying the data"
      },
      {
        "start": 1627.36,
        "duration": 4.16,
        "text": "so ingesting the data that is what's"
      },
      {
        "start": 1629.76,
        "duration": 4.6,
        "text": "necessary to do we need to put"
      },
      {
        "start": 1631.52,
        "duration": 6.279,
        "text": "everything into a vector database in"
      },
      {
        "start": 1634.36,
        "duration": 6.64,
        "text": "order to be able to then query it with"
      },
      {
        "start": 1637.799,
        "duration": 5.48,
        "text": "the user setting images or text"
      },
      {
        "start": 1641.0,
        "duration": 6.32,
        "text": "descriptions so I'll talk through how"
      },
      {
        "start": 1643.279,
        "duration": 6.841,
        "text": "the ingestion portion Works um first we"
      },
      {
        "start": 1647.32,
        "duration": 6.4,
        "text": "give the application a Spotify playlist"
      },
      {
        "start": 1650.12,
        "duration": 6.32,
        "text": "ID in this case it's the playlist ID for"
      },
      {
        "start": 1653.72,
        "duration": 6.24,
        "text": "that um this Vibe check playlist which"
      },
      {
        "start": 1656.44,
        "duration": 6.16,
        "text": "is just right here um so we copi and"
      },
      {
        "start": 1659.96,
        "duration": 5.36,
        "text": "pasted that into our app uh sent it to"
      },
      {
        "start": 1662.6,
        "duration": 5.52,
        "text": "our application and then using the"
      },
      {
        "start": 1665.32,
        "duration": 6.0,
        "text": "Spotify API we got back a whole bunch of"
      },
      {
        "start": 1668.12,
        "duration": 6.84,
        "text": "song data for every single song that is"
      },
      {
        "start": 1671.32,
        "duration": 6.4,
        "text": "in that spotifi playlist um so we have"
      },
      {
        "start": 1674.96,
        "duration": 5.439,
        "text": "the song name we have the artist name"
      },
      {
        "start": 1677.72,
        "duration": 5.72,
        "text": "and then the song ID so that we can"
      },
      {
        "start": 1680.399,
        "duration": 5.12,
        "text": "serve up URLs that point directly to the"
      },
      {
        "start": 1683.44,
        "duration": 4.359,
        "text": "the songs that we will eventually"
      },
      {
        "start": 1685.519,
        "duration": 5.121,
        "text": "retrieve um but that's not enough right"
      },
      {
        "start": 1687.799,
        "duration": 6.281,
        "text": "we need we need some sort of text"
      },
      {
        "start": 1690.64,
        "duration": 5.44,
        "text": "description and embeddings so that um we"
      },
      {
        "start": 1694.08,
        "duration": 4.0,
        "text": "can do that similarity search when we"
      },
      {
        "start": 1696.08,
        "duration": 4.88,
        "text": "get the user query and how do we"
      },
      {
        "start": 1698.08,
        "duration": 5.719,
        "text": "generate those uh we used the open AI"
      },
      {
        "start": 1700.96,
        "duration": 4.68,
        "text": "GPT 40 model to generate the queries"
      },
      {
        "start": 1703.799,
        "duration": 4.521,
        "text": "I'll show you the code on what that"
      },
      {
        "start": 1705.64,
        "duration": 4.72,
        "text": "actually looks like in a second um but"
      },
      {
        "start": 1708.32,
        "duration": 5.68,
        "text": "the llm the large language model"
      },
      {
        "start": 1710.36,
        "duration": 6.08,
        "text": "generates text describing the settings"
      },
      {
        "start": 1714.0,
        "duration": 4.88,
        "text": "that match each song in that spoify"
      },
      {
        "start": 1716.44,
        "duration": 5.719,
        "text": "playlist and then once we have those"
      },
      {
        "start": 1718.88,
        "duration": 5.799,
        "text": "text descriptions we send those to Astra"
      },
      {
        "start": 1722.159,
        "duration": 5.201,
        "text": "DB um ashtra actually has this feature"
      },
      {
        "start": 1724.679,
        "duration": 5.36,
        "text": "called vectorize where you don't have to"
      },
      {
        "start": 1727.36,
        "duration": 5.24,
        "text": "create the embeddings manually before"
      },
      {
        "start": 1730.039,
        "duration": 4.841,
        "text": "uploading your data plus embeddings to"
      },
      {
        "start": 1732.6,
        "duration": 5.559,
        "text": "the database you can actually just send"
      },
      {
        "start": 1734.88,
        "duration": 5.6,
        "text": "the text directly to astb and we've"
      },
      {
        "start": 1738.159,
        "duration": 5.161,
        "text": "already set up an integration with open"
      },
      {
        "start": 1740.48,
        "duration": 5.76,
        "text": "AI text embedding three small so that"
      },
      {
        "start": 1743.32,
        "duration": 5.56,
        "text": "when it receives that text Data it"
      },
      {
        "start": 1746.24,
        "duration": 5.679,
        "text": "converts it to the embedding all those"
      },
      {
        "start": 1748.88,
        "duration": 4.48,
        "text": "numbers um and then stores it in Astra"
      },
      {
        "start": 1751.919,
        "duration": 4.0,
        "text": "all in one step so that's something"
      },
      {
        "start": 1753.36,
        "duration": 5.0,
        "text": "that's getting abstracted by this Astra"
      },
      {
        "start": 1755.919,
        "duration": 5.12,
        "text": "vectorized feature so so that's the"
      },
      {
        "start": 1758.36,
        "duration": 5.12,
        "text": "ingestion piece of things um Andy do you"
      },
      {
        "start": 1761.039,
        "duration": 4.961,
        "text": "want to talk about the querying portion"
      },
      {
        "start": 1763.48,
        "duration": 4.64,
        "text": "yeah for sure uh the quering portion or"
      },
      {
        "start": 1766.0,
        "duration": 3.72,
        "text": "when a user submits their their picture"
      },
      {
        "start": 1768.12,
        "duration": 2.919,
        "text": "their image of themselves is very"
      },
      {
        "start": 1769.72,
        "duration": 3.28,
        "text": "similar actually to what's going on with"
      },
      {
        "start": 1771.039,
        "duration": 4.801,
        "text": "the data ingestion minus a few tweaks"
      },
      {
        "start": 1773.0,
        "duration": 4.84,
        "text": "here and there and so essentially a user"
      },
      {
        "start": 1775.84,
        "duration": 4.199,
        "text": "will upload and take a picture of"
      },
      {
        "start": 1777.84,
        "duration": 4.319,
        "text": "themselves or upload an image into the"
      },
      {
        "start": 1780.039,
        "duration": 4.12,
        "text": "streamlet application and from that"
      },
      {
        "start": 1782.159,
        "duration": 4.841,
        "text": "streamlet application it's actually rep"
      },
      {
        "start": 1784.159,
        "duration": 5.841,
        "text": "passing this image to openi you know GPT"
      },
      {
        "start": 1787.0,
        "duration": 5.399,
        "text": "40 model um to essentially generate a"
      },
      {
        "start": 1790.0,
        "duration": 3.84,
        "text": "description of the user setting and so"
      },
      {
        "start": 1792.399,
        "duration": 4.041,
        "text": "that's what I was kind of talking to"
      },
      {
        "start": 1793.84,
        "duration": 4.4,
        "text": "regarding um you know using an llm as a"
      },
      {
        "start": 1796.44,
        "duration": 4.239,
        "text": "Transformer stage where we're not just"
      },
      {
        "start": 1798.24,
        "duration": 4.88,
        "text": "embedding the the image itself but we're"
      },
      {
        "start": 1800.679,
        "duration": 4.321,
        "text": "actually telling chat GPT to hey"
      },
      {
        "start": 1803.12,
        "duration": 3.279,
        "text": "generate a description of the user"
      },
      {
        "start": 1805.0,
        "duration": 3.44,
        "text": "setting what are they doing what are"
      },
      {
        "start": 1806.399,
        "duration": 4.241,
        "text": "their Vibes you know what's this paint"
      },
      {
        "start": 1808.44,
        "duration": 3.719,
        "text": "paint the picture for us and essentially"
      },
      {
        "start": 1810.64,
        "duration": 4.8,
        "text": "chat GPT will do so because it's a"
      },
      {
        "start": 1812.159,
        "duration": 5.76,
        "text": "multimodal model um and it will uh give"
      },
      {
        "start": 1815.44,
        "duration": 4.599,
        "text": "us back a full description and we can"
      },
      {
        "start": 1817.919,
        "duration": 4.6,
        "text": "then take that description embed it and"
      },
      {
        "start": 1820.039,
        "duration": 5.12,
        "text": "perform a vector search using asra's"
      },
      {
        "start": 1822.519,
        "duration": 4.28,
        "text": "vectorized feature as well um so that's"
      },
      {
        "start": 1825.159,
        "duration": 3.281,
        "text": "also you know this vectorize as Annie"
      },
      {
        "start": 1826.799,
        "duration": 4.321,
        "text": "mentioned it is you know embedding the"
      },
      {
        "start": 1828.44,
        "duration": 4.52,
        "text": "data being returned back from open AI um"
      },
      {
        "start": 1831.12,
        "duration": 5.559,
        "text": "and then also performing a vector search"
      },
      {
        "start": 1832.96,
        "duration": 6.28,
        "text": "on the Fly um together and so then you"
      },
      {
        "start": 1836.679,
        "duration": 4.72,
        "text": "know once we have that we have a list of"
      },
      {
        "start": 1839.24,
        "duration": 4.88,
        "text": "similar songs based off of the users's"
      },
      {
        "start": 1841.399,
        "duration": 4.52,
        "text": "you know setting and we can return this"
      },
      {
        "start": 1844.12,
        "duration": 4.279,
        "text": "uh back to the stream Lo application so"
      },
      {
        "start": 1845.919,
        "duration": 4.681,
        "text": "the user can you know click on it and"
      },
      {
        "start": 1848.399,
        "duration": 3.841,
        "text": "play the song directly and so that's the"
      },
      {
        "start": 1850.6,
        "duration": 4.28,
        "text": "query"
      },
      {
        "start": 1852.24,
        "duration": 6.36,
        "text": "portion great yeah so that's that's the"
      },
      {
        "start": 1854.88,
        "duration": 6.6,
        "text": "full architecture um let's go ahead and"
      },
      {
        "start": 1858.6,
        "duration": 5.6,
        "text": "dive into the code now and and what it"
      },
      {
        "start": 1861.48,
        "duration": 4.96,
        "text": "actually looks like um so I'm going to"
      },
      {
        "start": 1864.2,
        "duration": 4.52,
        "text": "talk about the ingestion piece of things"
      },
      {
        "start": 1866.44,
        "duration": 4.68,
        "text": "and also show you kind of what the data"
      },
      {
        "start": 1868.72,
        "duration": 6.64,
        "text": "looks like when it's in Astra so right"
      },
      {
        "start": 1871.12,
        "duration": 6.559,
        "text": "now um we have all 18 of those Vibe"
      },
      {
        "start": 1875.36,
        "duration": 4.159,
        "text": "check songs of these Vibe check songs"
      },
      {
        "start": 1877.679,
        "duration": 5.321,
        "text": "uploaded into our database here we can"
      },
      {
        "start": 1879.519,
        "duration": 6.64,
        "text": "see exactly 18 records in our Astra"
      },
      {
        "start": 1883.0,
        "duration": 5.559,
        "text": "database um but I'll remove a few of"
      },
      {
        "start": 1886.159,
        "duration": 3.76,
        "text": "them so that I can show you what it"
      },
      {
        "start": 1888.559,
        "duration": 3.161,
        "text": "actually looks like when we're doing"
      },
      {
        "start": 1889.919,
        "duration": 4.441,
        "text": "that ingestion and also talk through the"
      },
      {
        "start": 1891.72,
        "duration": 4.72,
        "text": "code um so this is just removing a"
      },
      {
        "start": 1894.36,
        "duration": 6.08,
        "text": "couple songs then we're going to dive"
      },
      {
        "start": 1896.44,
        "duration": 7.88,
        "text": "into this file called ingest dopy uh"
      },
      {
        "start": 1900.44,
        "duration": 5.92,
        "text": "which actually does the ingestion so um"
      },
      {
        "start": 1904.32,
        "duration": 4.04,
        "text": "when sorry did you want to say something"
      },
      {
        "start": 1906.36,
        "duration": 5.319,
        "text": "Andy yeah I wanted to just bring a quick"
      },
      {
        "start": 1908.36,
        "duration": 4.439,
        "text": "point before we hop into the code um I I"
      },
      {
        "start": 1911.679,
        "duration": 3.36,
        "text": "see a question right here what is"
      },
      {
        "start": 1912.799,
        "duration": 5.84,
        "text": "orchestrating all of this just P just"
      },
      {
        "start": 1915.039,
        "duration": 7.081,
        "text": "custom python code or Lang chain or etc"
      },
      {
        "start": 1918.639,
        "duration": 6.321,
        "text": "etc um are are we are we using any tools"
      },
      {
        "start": 1922.12,
        "duration": 5.64,
        "text": "on the back end yeah so this is a pretty"
      },
      {
        "start": 1924.96,
        "duration": 6.319,
        "text": "sparse implementation we're not with"
      },
      {
        "start": 1927.76,
        "duration": 6.84,
        "text": "this is um custom python code like we're"
      },
      {
        "start": 1931.279,
        "duration": 6.4,
        "text": "using streamlet we're using asrai which"
      },
      {
        "start": 1934.6,
        "duration": 5.84,
        "text": "is the client to connect to astrab Via"
      },
      {
        "start": 1937.679,
        "duration": 6.281,
        "text": "Python and then we're using the open AI"
      },
      {
        "start": 1940.44,
        "duration": 6.199,
        "text": "client and sending requests directly to"
      },
      {
        "start": 1943.96,
        "duration": 4.64,
        "text": "the Spotify API so we're we're working"
      },
      {
        "start": 1946.639,
        "duration": 5.201,
        "text": "directly with all the different pieces"
      },
      {
        "start": 1948.6,
        "duration": 5.76,
        "text": "that we talked about earlier um I think"
      },
      {
        "start": 1951.84,
        "duration": 4.839,
        "text": "if you want to add like more advanced"
      },
      {
        "start": 1954.36,
        "duration": 4.76,
        "text": "functionality and more like decision"
      },
      {
        "start": 1956.679,
        "duration": 4.96,
        "text": "making that uses Lang chain for example"
      },
      {
        "start": 1959.12,
        "duration": 4.36,
        "text": "you could do that but we we kind of went"
      },
      {
        "start": 1961.639,
        "duration": 3.64,
        "text": "fast and loose with this one and just"
      },
      {
        "start": 1963.48,
        "duration": 3.24,
        "text": "kind of made the fastest possible"
      },
      {
        "start": 1965.279,
        "duration": 4.321,
        "text": "implementation that wouldn't require us"
      },
      {
        "start": 1966.72,
        "duration": 4.799,
        "text": "to like learn Frameworks um and it works"
      },
      {
        "start": 1969.6,
        "duration": 4.919,
        "text": "pretty well it works pretty"
      },
      {
        "start": 1971.519,
        "duration": 5.961,
        "text": "well cool awesome thank"
      },
      {
        "start": 1974.519,
        "duration": 5.481,
        "text": "you cool um okay so I'll go ahead and"
      },
      {
        "start": 1977.48,
        "duration": 6.159,
        "text": "talk a a little bit more about this"
      },
      {
        "start": 1980.0,
        "duration": 5.519,
        "text": "code um so when we load the full"
      },
      {
        "start": 1983.639,
        "duration": 4.64,
        "text": "playlist to Astra we're calling this"
      },
      {
        "start": 1985.519,
        "duration": 5.16,
        "text": "function load tracks to Astra given the"
      },
      {
        "start": 1988.279,
        "duration": 4.36,
        "text": "playlist ID and I'll just talk through"
      },
      {
        "start": 1990.679,
        "duration": 5.161,
        "text": "what what happens from top to bottom"
      },
      {
        "start": 1992.639,
        "duration": 5.961,
        "text": "here so the first thing we do is hit"
      },
      {
        "start": 1995.84,
        "duration": 4.959,
        "text": "that Spotify API to get all of that song"
      },
      {
        "start": 1998.6,
        "duration": 4.6,
        "text": "data from the Spotify API given the"
      },
      {
        "start": 2000.799,
        "duration": 5.201,
        "text": "playlist ID so if I scroll up to this"
      },
      {
        "start": 2003.2,
        "duration": 5.76,
        "text": "helper function get tracks from Spotify"
      },
      {
        "start": 2006.0,
        "duration": 7.12,
        "text": "we can see uh where literally just"
      },
      {
        "start": 2008.96,
        "duration": 7.88,
        "text": "sending um a request to the Spotify API"
      },
      {
        "start": 2013.12,
        "duration": 5.559,
        "text": "to get all of that song data and so um"
      },
      {
        "start": 2016.84,
        "duration": 4.6,
        "text": "this is our like access token this is"
      },
      {
        "start": 2018.679,
        "duration": 6.041,
        "text": "the API we're using and then we get back"
      },
      {
        "start": 2021.44,
        "duration": 6.119,
        "text": "um the response Json items as as"
      },
      {
        "start": 2024.72,
        "duration": 5.959,
        "text": "playlist tracks and then we get that uh"
      },
      {
        "start": 2027.559,
        "duration": 5.201,
        "text": "returned so here we're just kind of"
      },
      {
        "start": 2030.679,
        "duration": 5.041,
        "text": "checking if we've done any of this"
      },
      {
        "start": 2032.76,
        "duration": 6.08,
        "text": "before so that we don't need to like"
      },
      {
        "start": 2035.72,
        "duration": 7.079,
        "text": "redo um loads of songs that we've done"
      },
      {
        "start": 2038.84,
        "duration": 6.16,
        "text": "already um and then uh we're verifying"
      },
      {
        "start": 2042.799,
        "duration": 6.201,
        "text": "that we did get tracks back from that"
      },
      {
        "start": 2045.0,
        "duration": 6.48,
        "text": "Spotify playlist um and so that's that's"
      },
      {
        "start": 2049.0,
        "duration": 4.2,
        "text": "what this section is doing and then from"
      },
      {
        "start": 2051.48,
        "duration": 4.24,
        "text": "here below is when we're actually"
      },
      {
        "start": 2053.2,
        "duration": 4.679,
        "text": "iterating through every single song"
      },
      {
        "start": 2055.72,
        "duration": 4.439,
        "text": "formatting the data retrieving our"
      },
      {
        "start": 2057.879,
        "duration": 5.601,
        "text": "descriptions for each song and uploading"
      },
      {
        "start": 2060.159,
        "duration": 6.96,
        "text": "them to astrab so this first section"
      },
      {
        "start": 2063.48,
        "duration": 6.199,
        "text": "here is um kind of organizing and"
      },
      {
        "start": 2067.119,
        "duration": 5.76,
        "text": "pulling out relevant information from"
      },
      {
        "start": 2069.679,
        "duration": 7.321,
        "text": "that API response so for each song we're"
      },
      {
        "start": 2072.879,
        "duration": 7.401,
        "text": "getting um the song name here uh the"
      },
      {
        "start": 2077.0,
        "duration": 5.56,
        "text": "artist name here and then a song URL"
      },
      {
        "start": 2080.28,
        "duration": 4.52,
        "text": "which points directly to the song in"
      },
      {
        "start": 2082.56,
        "duration": 5.559,
        "text": "Spotify uh and we're just kind of saving"
      },
      {
        "start": 2084.8,
        "duration": 6.92,
        "text": "these as variables to be used later um"
      },
      {
        "start": 2088.119,
        "duration": 5.24,
        "text": "here's some stuff for uh if if a song is"
      },
      {
        "start": 2091.72,
        "duration": 3.8,
        "text": "already been loaded so we don't like"
      },
      {
        "start": 2093.359,
        "duration": 5.801,
        "text": "redo llm calls"
      },
      {
        "start": 2095.52,
        "duration": 7.44,
        "text": "unnecessarily um but in this case uh we"
      },
      {
        "start": 2099.16,
        "duration": 6.36,
        "text": "hit this block if we encounter a song"
      },
      {
        "start": 2102.96,
        "duration": 6.08,
        "text": "that is not yet loaded into the Astra"
      },
      {
        "start": 2105.52,
        "duration": 5.88,
        "text": "database um and so we encounter the song"
      },
      {
        "start": 2109.04,
        "duration": 4.72,
        "text": "we have the song data but we don't have"
      },
      {
        "start": 2111.4,
        "duration": 5.04,
        "text": "a description for the song so that's"
      },
      {
        "start": 2113.76,
        "duration": 5.52,
        "text": "when we call this function called get"
      },
      {
        "start": 2116.44,
        "duration": 5.72,
        "text": "song description given the song name and"
      },
      {
        "start": 2119.28,
        "duration": 4.88,
        "text": "the artist name so this is pulled out"
      },
      {
        "start": 2122.16,
        "duration": 6.4,
        "text": "into another helper function right"
      },
      {
        "start": 2124.16,
        "duration": 8.16,
        "text": "here um and this function uses the Open"
      },
      {
        "start": 2128.56,
        "duration": 6.2,
        "text": "aai chat client uh and the GPT 40 model"
      },
      {
        "start": 2132.32,
        "duration": 6.96,
        "text": "in order to generate a description of"
      },
      {
        "start": 2134.76,
        "duration": 7.079,
        "text": "the song um and so so here's the prompt"
      },
      {
        "start": 2139.28,
        "duration": 4.28,
        "text": "that we used you're an AI agent that"
      },
      {
        "start": 2141.839,
        "duration": 4.641,
        "text": "helps users determine what songs to play"
      },
      {
        "start": 2143.56,
        "duration": 5.0,
        "text": "to match their setting based on the song"
      },
      {
        "start": 2146.48,
        "duration": 3.72,
        "text": "name and the artist name write up a"
      },
      {
        "start": 2148.56,
        "duration": 3.32,
        "text": "description of what kind of setting"
      },
      {
        "start": 2150.2,
        "duration": 4.24,
        "text": "would be appropriate to listen to this"
      },
      {
        "start": 2151.88,
        "duration": 5.16,
        "text": "song don't make any assumptions based on"
      },
      {
        "start": 2154.44,
        "duration": 4.8,
        "text": "the name try and use real information"
      },
      {
        "start": 2157.04,
        "duration": 4.64,
        "text": "about the song to come up with your"
      },
      {
        "start": 2159.24,
        "duration": 7.359,
        "text": "description oops I accidentally clicked"
      },
      {
        "start": 2161.68,
        "duration": 7.56,
        "text": "down so here is the prompt right here um"
      },
      {
        "start": 2166.599,
        "duration": 4.601,
        "text": "so yeah go ahead go ahead I was going to"
      },
      {
        "start": 2169.24,
        "duration": 4.16,
        "text": "say that this is a very important part"
      },
      {
        "start": 2171.2,
        "duration": 3.6,
        "text": "of the application um this is kind of"
      },
      {
        "start": 2173.4,
        "duration": 3.719,
        "text": "what where we're getting these song"
      },
      {
        "start": 2174.8,
        "duration": 5.24,
        "text": "descriptions right we're generating them"
      },
      {
        "start": 2177.119,
        "duration": 4.601,
        "text": "through chat GPT 40's model um and not"
      },
      {
        "start": 2180.04,
        "duration": 3.84,
        "text": "just necessarily coming up with them on"
      },
      {
        "start": 2181.72,
        "duration": 3.92,
        "text": "our own or you know using a data set"
      },
      {
        "start": 2183.88,
        "duration": 5.08,
        "text": "that's already provided we are using the"
      },
      {
        "start": 2185.64,
        "duration": 7.479,
        "text": "llm to generate these descriptions"
      },
      {
        "start": 2188.96,
        "duration": 6.24,
        "text": "yeah um so again this like llms are not"
      },
      {
        "start": 2193.119,
        "duration": 4.081,
        "text": "fully deterministic like you're not"
      },
      {
        "start": 2195.2,
        "duration": 4.639,
        "text": "going to get exactly the same"
      },
      {
        "start": 2197.2,
        "duration": 4.399,
        "text": "description every single time but we did"
      },
      {
        "start": 2199.839,
        "duration": 4.801,
        "text": "a little bit of prompt engineering to"
      },
      {
        "start": 2201.599,
        "duration": 6.24,
        "text": "try and make this reliable to a certain"
      },
      {
        "start": 2204.64,
        "duration": 4.439,
        "text": "extent and then after we got back our"
      },
      {
        "start": 2207.839,
        "duration": 2.841,
        "text": "descriptions for the song we kind of"
      },
      {
        "start": 2209.079,
        "duration": 3.441,
        "text": "checked them by eye because they're all"
      },
      {
        "start": 2210.68,
        "duration": 3.12,
        "text": "songs that we know and then we saw like"
      },
      {
        "start": 2212.52,
        "duration": 4.12,
        "text": "yeah we're we're getting good"
      },
      {
        "start": 2213.8,
        "duration": 4.64,
        "text": "descriptions for these things um so this"
      },
      {
        "start": 2216.64,
        "duration": 5.959,
        "text": "is where we're generating the song"
      },
      {
        "start": 2218.44,
        "duration": 7.12,
        "text": "description using the openai llm GPT"
      },
      {
        "start": 2222.599,
        "duration": 5.081,
        "text": "40 so that is what's happening on this"
      },
      {
        "start": 2225.56,
        "duration": 4.84,
        "text": "line right here and now that we have"
      },
      {
        "start": 2227.68,
        "duration": 6.12,
        "text": "that song description we can add it to"
      },
      {
        "start": 2230.4,
        "duration": 5.04,
        "text": "as a field to our document and then this"
      },
      {
        "start": 2233.8,
        "duration": 5.279,
        "text": "data for every single song in that"
      },
      {
        "start": 2235.44,
        "duration": 6.72,
        "text": "playlist is getting uploaded to astrab"
      },
      {
        "start": 2239.079,
        "duration": 5.76,
        "text": "right here so this this um statement"
      },
      {
        "start": 2242.16,
        "duration": 5.08,
        "text": "Song collection insert one"
      },
      {
        "start": 2244.839,
        "duration": 4.081,
        "text": "document um and here is just kind of"
      },
      {
        "start": 2247.24,
        "duration": 4.64,
        "text": "some progress tracking to see what that"
      },
      {
        "start": 2248.92,
        "duration": 4.6,
        "text": "looks like but um I'll show you kind of"
      },
      {
        "start": 2251.88,
        "duration": 4.64,
        "text": "what that looks like in real time so I'd"
      },
      {
        "start": 2253.52,
        "duration": 6.28,
        "text": "already removed two songs from the Astra"
      },
      {
        "start": 2256.52,
        "duration": 6.4,
        "text": "database if I reload this I'll see I"
      },
      {
        "start": 2259.8,
        "duration": 6.72,
        "text": "only have 16 records in here and the two"
      },
      {
        "start": 2262.92,
        "duration": 6.8,
        "text": "songs that got deleted uh if I check my"
      },
      {
        "start": 2266.52,
        "duration": 6.2,
        "text": "terminal here my console uh two site and"
      },
      {
        "start": 2269.72,
        "duration": 5.96,
        "text": "Monster Mash got deleted from the Astra"
      },
      {
        "start": 2272.72,
        "duration": 4.879,
        "text": "database so I can try to reload that"
      },
      {
        "start": 2275.68,
        "duration": 5.04,
        "text": "same playlist again it Should Skip both"
      },
      {
        "start": 2277.599,
        "duration": 4.76,
        "text": "over all of the 16 songs that are"
      },
      {
        "start": 2280.72,
        "duration": 3.84,
        "text": "already in there but it'll try and"
      },
      {
        "start": 2282.359,
        "duration": 5.48,
        "text": "reload those two that are missing and"
      },
      {
        "start": 2284.56,
        "duration": 5.92,
        "text": "we'll see in real time that our"
      },
      {
        "start": 2287.839,
        "duration": 5.401,
        "text": "application generates descriptions for"
      },
      {
        "start": 2290.48,
        "duration": 5.599,
        "text": "those two songs and then loads them into"
      },
      {
        "start": 2293.24,
        "duration": 6.52,
        "text": "Astra so here it's working right now but"
      },
      {
        "start": 2296.079,
        "duration": 7.201,
        "text": "we can already see um it generated this"
      },
      {
        "start": 2299.76,
        "duration": 5.64,
        "text": "text for two Suite uh and then loaded to"
      },
      {
        "start": 2303.28,
        "duration": 4.64,
        "text": "asach jdb it's skipping over a bunch of"
      },
      {
        "start": 2305.4,
        "duration": 6.28,
        "text": "the other ones and then here for Monster"
      },
      {
        "start": 2307.92,
        "duration": 6.159,
        "text": "Mash the llm generated this text for"
      },
      {
        "start": 2311.68,
        "duration": 5.76,
        "text": "that song and then uploaded it to the"
      },
      {
        "start": 2314.079,
        "duration": 5.481,
        "text": "database so if we come back to ashtra"
      },
      {
        "start": 2317.44,
        "duration": 4.6,
        "text": "and refresh it"
      },
      {
        "start": 2319.56,
        "duration": 5.0,
        "text": "here uh we can see now we have 18"
      },
      {
        "start": 2322.04,
        "duration": 5.2,
        "text": "records all all of the songs are now"
      },
      {
        "start": 2324.56,
        "duration": 5.84,
        "text": "once again in this database and ready to"
      },
      {
        "start": 2327.24,
        "duration": 5.0,
        "text": "be searched so that's how the ingestion"
      },
      {
        "start": 2330.4,
        "duration": 4.88,
        "text": "works for this"
      },
      {
        "start": 2332.24,
        "duration": 5.24,
        "text": "application um cool yeah that that's"
      },
      {
        "start": 2335.28,
        "duration": 3.68,
        "text": "what I wanted to show that is awesome"
      },
      {
        "start": 2337.48,
        "duration": 2.96,
        "text": "could we actually hop into the database"
      },
      {
        "start": 2338.96,
        "duration": 2.96,
        "text": "real quick Annie and show them the"
      },
      {
        "start": 2340.44,
        "duration": 3.76,
        "text": "descriptions that were generated by the"
      },
      {
        "start": 2341.92,
        "duration": 4.48,
        "text": "llm Yeah Yeah that's that's a great idea"
      },
      {
        "start": 2344.2,
        "duration": 4.76,
        "text": "so here we can see all of the fields for"
      },
      {
        "start": 2346.4,
        "duration": 5.679,
        "text": "each of the songs we have song name"
      },
      {
        "start": 2348.96,
        "duration": 6.399,
        "text": "artist song URL so this link would open"
      },
      {
        "start": 2352.079,
        "duration": 7.201,
        "text": "the track and then this vectorized field"
      },
      {
        "start": 2355.359,
        "duration": 7.201,
        "text": "is uh the text that was generated by the"
      },
      {
        "start": 2359.28,
        "duration": 6.44,
        "text": "llm that describes this song and then"
      },
      {
        "start": 2362.56,
        "duration": 7.32,
        "text": "this Vector is the vector representation"
      },
      {
        "start": 2365.72,
        "duration": 8.76,
        "text": "of the highlighted text um generated by"
      },
      {
        "start": 2369.88,
        "duration": 7.0,
        "text": "this model which uh which is this this"
      },
      {
        "start": 2374.48,
        "duration": 5.08,
        "text": "collection is integrated with the open"
      },
      {
        "start": 2376.88,
        "duration": 5.64,
        "text": "AI text embedding 3 small model and the"
      },
      {
        "start": 2379.56,
        "duration": 6.16,
        "text": "vectorized feature allows us to create"
      },
      {
        "start": 2382.52,
        "duration": 5.24,
        "text": "these every time we upload a new dock as"
      },
      {
        "start": 2385.72,
        "duration": 4.32,
        "text": "long as we say yeah I want a vector"
      },
      {
        "start": 2387.76,
        "duration": 3.92,
        "text": "created for this specific field so"
      },
      {
        "start": 2390.04,
        "duration": 3.52,
        "text": "that's that's what it looks like in here"
      },
      {
        "start": 2391.68,
        "duration": 4.76,
        "text": "that's kind of what's happening in"
      },
      {
        "start": 2393.56,
        "duration": 5.279,
        "text": "Astra that is awesome thanks for walking"
      },
      {
        "start": 2396.44,
        "duration": 4.28,
        "text": "us through that um so yeah now that we"
      },
      {
        "start": 2398.839,
        "duration": 4.121,
        "text": "have all of our data within the database"
      },
      {
        "start": 2400.72,
        "duration": 5.08,
        "text": "we're able to upload you know a user's"
      },
      {
        "start": 2402.96,
        "duration": 4.68,
        "text": "playlist ID get all their songs you know"
      },
      {
        "start": 2405.8,
        "duration": 4.36,
        "text": "generate these descriptions of the songs"
      },
      {
        "start": 2407.64,
        "duration": 4.92,
        "text": "llms now let's you know get into the"
      },
      {
        "start": 2410.16,
        "duration": 5.28,
        "text": "code of how we actually you know query"
      },
      {
        "start": 2412.56,
        "duration": 5.84,
        "text": "these these songs and so we have this"
      },
      {
        "start": 2415.44,
        "duration": 4.8,
        "text": "query. piy file which we can hop into"
      },
      {
        "start": 2418.4,
        "duration": 4.439,
        "text": "and essentially the main part starts"
      },
      {
        "start": 2420.24,
        "duration": 4.52,
        "text": "here at line 64 where you know a user"
      },
      {
        "start": 2422.839,
        "duration": 4.0,
        "text": "presses the submit button on the"
      },
      {
        "start": 2424.76,
        "duration": 4.0,
        "text": "application and so they take a photo"
      },
      {
        "start": 2426.839,
        "duration": 4.0,
        "text": "either upload load it or use the camera"
      },
      {
        "start": 2428.76,
        "duration": 4.96,
        "text": "and once they press that submit button"
      },
      {
        "start": 2430.839,
        "duration": 6.0,
        "text": "here on line 67 we're essentially"
      },
      {
        "start": 2433.72,
        "duration": 5.599,
        "text": "getting a description of the users's you"
      },
      {
        "start": 2436.839,
        "duration": 4.441,
        "text": "know uh setting and we're going to this"
      },
      {
        "start": 2439.319,
        "duration": 3.681,
        "text": "get setting description from image"
      },
      {
        "start": 2441.28,
        "duration": 4.6,
        "text": "function which we have defined up here"
      },
      {
        "start": 2443.0,
        "duration": 4.68,
        "text": "online 14 and what this does is very"
      },
      {
        "start": 2445.88,
        "duration": 3.92,
        "text": "similarly to how the song descriptions"
      },
      {
        "start": 2447.68,
        "duration": 5.399,
        "text": "are made um we are also going to chat"
      },
      {
        "start": 2449.8,
        "duration": 4.76,
        "text": "GPT 40 and we are asking it to you know"
      },
      {
        "start": 2453.079,
        "duration": 3.561,
        "text": "generate a description of the user"
      },
      {
        "start": 2454.56,
        "duration": 3.2,
        "text": "setting and so you can see the prompt"
      },
      {
        "start": 2456.64,
        "duration": 3.439,
        "text": "that we have here"
      },
      {
        "start": 2457.76,
        "duration": 4.28,
        "text": "you're an AI agent that helps users find"
      },
      {
        "start": 2460.079,
        "duration": 3.641,
        "text": "music that matches their current setting"
      },
      {
        "start": 2462.04,
        "duration": 3.48,
        "text": "please describe the Ambiance and the"
      },
      {
        "start": 2463.72,
        "duration": 3.48,
        "text": "vibe included in the image right what"
      },
      {
        "start": 2465.52,
        "duration": 3.68,
        "text": "kind of music would be fitting for you"
      },
      {
        "start": 2467.2,
        "duration": 3.96,
        "text": "know the setting that the user uploaded"
      },
      {
        "start": 2469.2,
        "duration": 3.96,
        "text": "you know what kind of mood is there so"
      },
      {
        "start": 2471.16,
        "duration": 4.0,
        "text": "on and so forth so a little bit of"
      },
      {
        "start": 2473.16,
        "duration": 5.24,
        "text": "prompt engineering and then we're going"
      },
      {
        "start": 2475.16,
        "duration": 5.6,
        "text": "to the GPT 40 model and receiving this"
      },
      {
        "start": 2478.4,
        "duration": 4.919,
        "text": "um you know description from you know"
      },
      {
        "start": 2480.76,
        "duration": 4.559,
        "text": "the llm and that is what we're using as"
      },
      {
        "start": 2483.319,
        "duration": 4.481,
        "text": "you know the the vector"
      },
      {
        "start": 2485.319,
        "duration": 4.481,
        "text": "embedding great and one"
      },
      {
        "start": 2487.8,
        "duration": 5.519,
        "text": "oh go ahead go ahead um I was just going"
      },
      {
        "start": 2489.8,
        "duration": 6.08,
        "text": "to ask like so this prompt doesn't have"
      },
      {
        "start": 2493.319,
        "duration": 7.401,
        "text": "any information about what we're looking"
      },
      {
        "start": 2495.88,
        "duration": 8.439,
        "text": "for right so like how how how does the"
      },
      {
        "start": 2500.72,
        "duration": 5.0,
        "text": "llm know like what exactly it's supposed"
      },
      {
        "start": 2504.319,
        "duration": 4.361,
        "text": "to be"
      },
      {
        "start": 2505.72,
        "duration": 4.48,
        "text": "describing amazing question so kind of"
      },
      {
        "start": 2508.68,
        "duration": 3.56,
        "text": "like in your scenario right we had"
      },
      {
        "start": 2510.2,
        "duration": 4.2,
        "text": "passed the song name and the artist name"
      },
      {
        "start": 2512.24,
        "duration": 4.16,
        "text": "into the prompt but here you know we're"
      },
      {
        "start": 2514.4,
        "duration": 3.4,
        "text": "just giving the prompt um we're hard"
      },
      {
        "start": 2516.4,
        "duration": 2.64,
        "text": "coding it and we're telling it to to"
      },
      {
        "start": 2517.8,
        "duration": 4.319,
        "text": "look at the image and that's what you"
      },
      {
        "start": 2519.04,
        "duration": 5.92,
        "text": "see here actually on line 38 um where we"
      },
      {
        "start": 2522.119,
        "duration": 5.841,
        "text": "are actually passing the image of what"
      },
      {
        "start": 2524.96,
        "duration": 5.359,
        "text": "the user uploaded to GPT 40 because it"
      },
      {
        "start": 2527.96,
        "duration": 4.76,
        "text": "is a multimodal model it is able to"
      },
      {
        "start": 2530.319,
        "duration": 5.04,
        "text": "accept images and it can essentially um"
      },
      {
        "start": 2532.72,
        "duration": 4.48,
        "text": "interpret them based off of this prompt"
      },
      {
        "start": 2535.359,
        "duration": 3.76,
        "text": "um and so we're telling you know we're"
      },
      {
        "start": 2537.2,
        "duration": 4.0,
        "text": "giving GPT The Prompt we're giving it"
      },
      {
        "start": 2539.119,
        "duration": 4.801,
        "text": "the image um and we're telling it based"
      },
      {
        "start": 2541.2,
        "duration": 4.72,
        "text": "off of the two respond um and it's very"
      },
      {
        "start": 2543.92,
        "duration": 4.12,
        "text": "important to know that gbt 40 right it"
      },
      {
        "start": 2545.92,
        "duration": 3.919,
        "text": "is a multimodal model another example of"
      },
      {
        "start": 2548.04,
        "duration": 4.72,
        "text": "an llm that is very capable of doing"
      },
      {
        "start": 2549.839,
        "duration": 5.681,
        "text": "this is Google Gemini's provision model"
      },
      {
        "start": 2552.76,
        "duration": 6.0,
        "text": "it's great as well um very similarly set"
      },
      {
        "start": 2555.52,
        "duration": 4.839,
        "text": "up um to this but this is how it knows"
      },
      {
        "start": 2558.76,
        "duration": 4.839,
        "text": "you know we're passing the image rather"
      },
      {
        "start": 2560.359,
        "duration": 5.601,
        "text": "than you know a song name or a a artist"
      },
      {
        "start": 2563.599,
        "duration": 4.24,
        "text": "name and then we're receiving that"
      },
      {
        "start": 2565.96,
        "duration": 6.399,
        "text": "description"
      },
      {
        "start": 2567.839,
        "duration": 7.321,
        "text": "awesome perect okay so back to here go"
      },
      {
        "start": 2572.359,
        "duration": 4.281,
        "text": "yep so great now we have the setting"
      },
      {
        "start": 2575.16,
        "duration": 3.84,
        "text": "description based off of the users"
      },
      {
        "start": 2576.64,
        "duration": 4.52,
        "text": "uploaded image but now let's find"
      },
      {
        "start": 2579.0,
        "duration": 5.359,
        "text": "similar songs off of that description"
      },
      {
        "start": 2581.16,
        "duration": 4.8,
        "text": "that you know GPT 40 returned back to us"
      },
      {
        "start": 2584.359,
        "duration": 3.561,
        "text": "and so if we go to this find songs"
      },
      {
        "start": 2585.96,
        "duration": 5.0,
        "text": "function which we have what this is"
      },
      {
        "start": 2587.92,
        "duration": 5.24,
        "text": "doing is it's going into astb it's using"
      },
      {
        "start": 2590.96,
        "duration": 4.44,
        "text": "our vectorized feature to essentially"
      },
      {
        "start": 2593.16,
        "duration": 4.52,
        "text": "vectorize or embed that setting"
      },
      {
        "start": 2595.4,
        "duration": 4.52,
        "text": "description and then it's performing a"
      },
      {
        "start": 2597.68,
        "duration": 5.24,
        "text": "vector search within the DB and pulling"
      },
      {
        "start": 2599.92,
        "duration": 4.919,
        "text": "out the nearest matches to whatever the"
      },
      {
        "start": 2602.92,
        "duration": 3.84,
        "text": "user had uploaded to the to the user"
      },
      {
        "start": 2604.839,
        "duration": 4.401,
        "text": "setting description and that's what you"
      },
      {
        "start": 2606.76,
        "duration": 5.319,
        "text": "see right over here return the top songs"
      },
      {
        "start": 2609.24,
        "duration": 6.079,
        "text": "back to the user for them to"
      },
      {
        "start": 2612.079,
        "duration": 5.361,
        "text": "play and if we hop into the um the"
      },
      {
        "start": 2615.319,
        "duration": 4.121,
        "text": "stream L side we can actually you know"
      },
      {
        "start": 2617.44,
        "duration": 6.399,
        "text": "upload a variety of different images and"
      },
      {
        "start": 2619.44,
        "duration": 4.399,
        "text": "test this out so let's let's try it"
      },
      {
        "start": 2624.52,
        "duration": 6.2,
        "text": "out we have a picture of you know Annie"
      },
      {
        "start": 2627.96,
        "duration": 4.399,
        "text": "and I at the gym right over here one"
      },
      {
        "start": 2630.72,
        "duration": 3.96,
        "text": "that we photoshopped right before this"
      },
      {
        "start": 2632.359,
        "duration": 4.24,
        "text": "and let's see which um which songs are"
      },
      {
        "start": 2634.68,
        "duration": 4.04,
        "text": "returned back to us so if we upload that"
      },
      {
        "start": 2636.599,
        "duration": 5.281,
        "text": "what it's do is it's going to GPT 40"
      },
      {
        "start": 2638.72,
        "duration": 5.48,
        "text": "it's generating a description um of the"
      },
      {
        "start": 2641.88,
        "duration": 4.239,
        "text": "image that we uploaded and so you can"
      },
      {
        "start": 2644.2,
        "duration": 4.359,
        "text": "see this is the uploaded image we can"
      },
      {
        "start": 2646.119,
        "duration": 4.24,
        "text": "you know toggle the show prompt sent llm"
      },
      {
        "start": 2648.559,
        "duration": 4.28,
        "text": "button right here and you can see that"
      },
      {
        "start": 2650.359,
        "duration": 4.2,
        "text": "this is what GPT 40 returned you know it"
      },
      {
        "start": 2652.839,
        "duration": 3.801,
        "text": "said the image depicts a playful and"
      },
      {
        "start": 2654.559,
        "duration": 4.0,
        "text": "energetic scene with characters lifting"
      },
      {
        "start": 2656.64,
        "duration": 4.64,
        "text": "weights right suggesting a workout or"
      },
      {
        "start": 2658.559,
        "duration": 5.121,
        "text": "Fitness theme these are you know songs"
      },
      {
        "start": 2661.28,
        "duration": 5.2,
        "text": "or you know settings that you know kind"
      },
      {
        "start": 2663.68,
        "duration": 4.04,
        "text": "of fit this Vibe a pop you know electric"
      },
      {
        "start": 2666.48,
        "duration": 3.2,
        "text": "Dan EDM"
      },
      {
        "start": 2667.72,
        "duration": 3.96,
        "text": "hip hop Rock right all of these kind of"
      },
      {
        "start": 2669.68,
        "duration": 4.679,
        "text": "fit the same Vibe of working out or at"
      },
      {
        "start": 2671.68,
        "duration": 4.52,
        "text": "the gym and then if we go down we can"
      },
      {
        "start": 2674.359,
        "duration": 4.321,
        "text": "see the best matches that are returned"
      },
      {
        "start": 2676.2,
        "duration": 4.68,
        "text": "from our database off of the song U off"
      },
      {
        "start": 2678.68,
        "duration": 4.8,
        "text": "the setting description and so we have"
      },
      {
        "start": 2680.88,
        "duration": 3.76,
        "text": "the song name say Stronger by Kanye West"
      },
      {
        "start": 2683.48,
        "duration": 3.92,
        "text": "right over here that seems like a pretty"
      },
      {
        "start": 2684.64,
        "duration": 4.8,
        "text": "good one um we have the song URL to go"
      },
      {
        "start": 2687.4,
        "duration": 4.32,
        "text": "play it we have essentially that"
      },
      {
        "start": 2689.44,
        "duration": 4.36,
        "text": "vectorized feel to say hey what is you"
      },
      {
        "start": 2691.72,
        "duration": 2.8,
        "text": "know the song description off of the you"
      },
      {
        "start": 2693.8,
        "duration": 4.0,
        "text": "know"
      },
      {
        "start": 2694.52,
        "duration": 5.92,
        "text": "gp40 and then lastly we can also see the"
      },
      {
        "start": 2697.8,
        "duration": 5.039,
        "text": "coine similarity score so how close of a"
      },
      {
        "start": 2700.44,
        "duration": 5.72,
        "text": "match was this and we can see here you"
      },
      {
        "start": 2702.839,
        "duration": 5.441,
        "text": "know 79 um is that coine similarity or"
      },
      {
        "start": 2706.16,
        "duration": 3.399,
        "text": "that Vector search similarity score"
      },
      {
        "start": 2708.28,
        "duration": 3.2,
        "text": "Annie and I were doing some playing"
      },
      {
        "start": 2709.559,
        "duration": 4.76,
        "text": "around and we realized that anything"
      },
      {
        "start": 2711.48,
        "duration": 5.04,
        "text": "above 7 is usually a pretty good match"
      },
      {
        "start": 2714.319,
        "duration": 4.641,
        "text": "to return back to the user it's somewhat"
      },
      {
        "start": 2716.52,
        "duration": 4.96,
        "text": "relevant um to what they're asking for"
      },
      {
        "start": 2718.96,
        "duration": 4.639,
        "text": "and so great we we have all these list"
      },
      {
        "start": 2721.48,
        "duration": 4.359,
        "text": "of songs and then lastly we just display"
      },
      {
        "start": 2723.599,
        "duration": 4.96,
        "text": "this song where um you know you can"
      },
      {
        "start": 2725.839,
        "duration": 5.52,
        "text": "click on stronger and it should open up"
      },
      {
        "start": 2728.559,
        "duration": 5.721,
        "text": "the uh the URL to play it within Spotify"
      },
      {
        "start": 2731.359,
        "duration": 4.801,
        "text": "which is pretty cool for sure um"
      },
      {
        "start": 2734.28,
        "duration": 4.0,
        "text": "something that we were trying to"
      },
      {
        "start": 2736.16,
        "duration": 4.72,
        "text": "implement but didn't end up doing"
      },
      {
        "start": 2738.28,
        "duration": 5.079,
        "text": "because it just was taking too much time"
      },
      {
        "start": 2740.88,
        "duration": 5.64,
        "text": "like ideally we could like get a Spotify"
      },
      {
        "start": 2743.359,
        "duration": 6.76,
        "text": "player embedded into this app and start"
      },
      {
        "start": 2746.52,
        "duration": 5.16,
        "text": "to play the songs automatically but we"
      },
      {
        "start": 2750.119,
        "duration": 3.921,
        "text": "kind of didn't want to spend too much"
      },
      {
        "start": 2751.68,
        "duration": 4.04,
        "text": "time doing that so um but but that would"
      },
      {
        "start": 2754.04,
        "duration": 3.799,
        "text": "be like a great next step for this"
      },
      {
        "start": 2755.72,
        "duration": 4.52,
        "text": "application so that you don't have to"
      },
      {
        "start": 2757.839,
        "duration": 4.601,
        "text": "like open up the songs on your own maybe"
      },
      {
        "start": 2760.24,
        "duration": 4.76,
        "text": "you could make like a new playlist that"
      },
      {
        "start": 2762.44,
        "duration": 6.0,
        "text": "only includes songs that have a"
      },
      {
        "start": 2765.0,
        "duration": 5.44,
        "text": "similarity score over s uh and then"
      },
      {
        "start": 2768.44,
        "duration": 4.28,
        "text": "start to automatically play it for"
      },
      {
        "start": 2770.44,
        "duration": 3.679,
        "text": "whatever event that you're currently at"
      },
      {
        "start": 2772.72,
        "duration": 4.04,
        "text": "um so so there's like a lot of"
      },
      {
        "start": 2774.119,
        "duration": 3.921,
        "text": "possibility I if if this like becomes"
      },
      {
        "start": 2776.76,
        "duration": 3.799,
        "text": "something a little more fleshed out I"
      },
      {
        "start": 2778.04,
        "duration": 5.4,
        "text": "could see myself using this all day like"
      },
      {
        "start": 2780.559,
        "duration": 5.961,
        "text": "I would hook this up to my liked songs"
      },
      {
        "start": 2783.44,
        "duration": 6.0,
        "text": "on Spotify which is like 3,000 songs"
      },
      {
        "start": 2786.52,
        "duration": 5.319,
        "text": "long and then wherever I'm at I would"
      },
      {
        "start": 2789.44,
        "duration": 4.52,
        "text": "just take a picture and then have like a"
      },
      {
        "start": 2791.839,
        "duration": 3.801,
        "text": "30 song playlist to match whatever it is"
      },
      {
        "start": 2793.96,
        "duration": 3.68,
        "text": "I'm doing at that moment and have it"
      },
      {
        "start": 2795.64,
        "duration": 5.32,
        "text": "automatically play that that's like kind"
      },
      {
        "start": 2797.64,
        "duration": 7.04,
        "text": "of the vision here for what what it"
      },
      {
        "start": 2800.96,
        "duration": 4.84,
        "text": "could turn into um for sure I think uh"
      },
      {
        "start": 2804.68,
        "duration": 2.56,
        "text": "it's important to note that we are"
      },
      {
        "start": 2805.8,
        "duration": 3.4,
        "text": "showing this kind of on the desktop"
      },
      {
        "start": 2807.24,
        "duration": 3.24,
        "text": "application so it's more for you know"
      },
      {
        "start": 2809.2,
        "duration": 3.399,
        "text": "uploading images right now is what we're"
      },
      {
        "start": 2810.48,
        "duration": 4.119,
        "text": "showcasing but you can also run this on"
      },
      {
        "start": 2812.599,
        "duration": 4.601,
        "text": "your phone and take a picture in real"
      },
      {
        "start": 2814.599,
        "duration": 4.24,
        "text": "time of what your current setting is and"
      },
      {
        "start": 2817.2,
        "duration": 3.32,
        "text": "you know have those songs play on the"
      },
      {
        "start": 2818.839,
        "duration": 3.28,
        "text": "Fly based off of that I think that's"
      },
      {
        "start": 2820.52,
        "duration": 3.72,
        "text": "kind of where the vision of this"
      },
      {
        "start": 2822.119,
        "duration": 7.0,
        "text": "application you know would"
      },
      {
        "start": 2824.24,
        "duration": 9.319,
        "text": "go yeah um how about we try a few more"
      },
      {
        "start": 2829.119,
        "duration": 8.641,
        "text": "image prompts like image or um or text"
      },
      {
        "start": 2833.559,
        "duration": 6.0,
        "text": "prompts so let's see I just kind of want"
      },
      {
        "start": 2837.76,
        "duration": 3.599,
        "text": "to see what comes up for these different"
      },
      {
        "start": 2839.559,
        "duration": 3.601,
        "text": "things so here I have a picture of a"
      },
      {
        "start": 2841.359,
        "duration": 6.121,
        "text": "candle at"
      },
      {
        "start": 2843.16,
        "duration": 8.199,
        "text": "dinner um and if we try this"
      },
      {
        "start": 2847.48,
        "duration": 3.879,
        "text": "hopefully it doesn't recommend Monster"
      },
      {
        "start": 2852.0,
        "duration": 4.64,
        "text": "Mash sweet and yeah we see the llm came"
      },
      {
        "start": 2855.2,
        "duration": 3.28,
        "text": "up with this"
      },
      {
        "start": 2856.64,
        "duration": 3.8,
        "text": "description uh and then we're getting"
      },
      {
        "start": 2858.48,
        "duration": 5.119,
        "text": "back songs that kind of match that two"
      },
      {
        "start": 2860.44,
        "duration": 6.36,
        "text": "sweet birds of a feather take five um"
      },
      {
        "start": 2863.599,
        "duration": 5.361,
        "text": "pretty pretty accurate"
      },
      {
        "start": 2866.8,
        "duration": 4.48,
        "text": "there and the cool part is that we can"
      },
      {
        "start": 2868.96,
        "duration": 4.0,
        "text": "also not only just use an image to you"
      },
      {
        "start": 2871.28,
        "duration": 4.24,
        "text": "know have this similarity search but you"
      },
      {
        "start": 2872.96,
        "duration": 5.68,
        "text": "can also put in a description or type"
      },
      {
        "start": 2875.52,
        "duration": 4.96,
        "text": "something out and then see um where you"
      },
      {
        "start": 2878.64,
        "duration": 2.8,
        "text": "know what what's returned from just you"
      },
      {
        "start": 2880.48,
        "duration": 3.2,
        "text": "know a"
      },
      {
        "start": 2881.44,
        "duration": 3.04,
        "text": "sentence do you have any suggestions"
      },
      {
        "start": 2883.68,
        "duration": 5.04,
        "text": "there"
      },
      {
        "start": 2884.48,
        "duration": 5.92,
        "text": "andy um that's a good one let's try um I"
      },
      {
        "start": 2888.72,
        "duration": 4.2,
        "text": "always need songs for you know a joy"
      },
      {
        "start": 2890.4,
        "duration": 2.52,
        "text": "ride in my"
      },
      {
        "start": 2893.079,
        "duration": 3.0,
        "text": "car"
      },
      {
        "start": 2897.96,
        "duration": 5.96,
        "text": "great cool and here we can see um this"
      },
      {
        "start": 2901.4,
        "duration": 4.88,
        "text": "is the full prompt that got sent uh"
      },
      {
        "start": 2903.92,
        "duration": 6.08,
        "text": "there's nothing to generate something"
      },
      {
        "start": 2906.28,
        "duration": 5.52,
        "text": "based off of um but here we see the"
      },
      {
        "start": 2910.0,
        "duration": 5.64,
        "text": "first song returned is"
      },
      {
        "start": 2911.8,
        "duration": 7.12,
        "text": "driveby uh a little on the nose"
      },
      {
        "start": 2915.64,
        "duration": 5.76,
        "text": "but honestly that's pretty good Rip Tide"
      },
      {
        "start": 2918.92,
        "duration": 5.159,
        "text": "yeah I could see myself going on a road"
      },
      {
        "start": 2921.4,
        "duration": 5.08,
        "text": "trip to these that's pretty good for"
      },
      {
        "start": 2924.079,
        "duration": 4.681,
        "text": "sure I think uh we need to put this into"
      },
      {
        "start": 2926.48,
        "duration": 4.96,
        "text": "our to our actual playlists and give it"
      },
      {
        "start": 2928.76,
        "duration": 4.599,
        "text": "a try yeah for sure um and then the last"
      },
      {
        "start": 2931.44,
        "duration": 6.399,
        "text": "thing I wanted to show here is just this"
      },
      {
        "start": 2933.359,
        "duration": 8.2,
        "text": "camera input so you can see I'm in my"
      },
      {
        "start": 2937.839,
        "duration": 4.601,
        "text": "room here um we could take a live photo"
      },
      {
        "start": 2941.559,
        "duration": 5.52,
        "text": "and"
      },
      {
        "start": 2942.44,
        "duration": 4.639,
        "text": "see what the model thinks is going"
      },
      {
        "start": 2948.96,
        "duration": 7.2,
        "text": "on great so here's the uploaded"
      },
      {
        "start": 2952.04,
        "duration": 7.88,
        "text": "image it's me giving a thumbs up um and"
      },
      {
        "start": 2956.16,
        "duration": 7.0,
        "text": "here relaxed and cozy room casual and"
      },
      {
        "start": 2959.92,
        "duration": 7.32,
        "text": "positive calm and simple environment"
      },
      {
        "start": 2963.16,
        "duration": 6.0,
        "text": "lowii hip hop chill pop casual"
      },
      {
        "start": 2967.24,
        "duration": 4.28,
        "text": "relaxation work and study and that's"
      },
      {
        "start": 2969.16,
        "duration": 4.639,
        "text": "that's what we're getting back here that"
      },
      {
        "start": 2971.52,
        "duration": 4.12,
        "text": "is awesome cool I think we actually have"
      },
      {
        "start": 2973.799,
        "duration": 4.8,
        "text": "a couple questions any that we can maybe"
      },
      {
        "start": 2975.64,
        "duration": 5.8,
        "text": "answer um I see a really good one right"
      },
      {
        "start": 2978.599,
        "duration": 5.561,
        "text": "over here um asking if we could re"
      },
      {
        "start": 2981.44,
        "duration": 6.159,
        "text": "explain why we are vectorizing the image"
      },
      {
        "start": 2984.16,
        "duration": 3.439,
        "text": "description sent by the"
      },
      {
        "start": 2988.72,
        "duration": 3.56,
        "text": "llm do you want to take that one or"
      },
      {
        "start": 2990.799,
        "duration": 5.0,
        "text": "should I go for"
      },
      {
        "start": 2992.28,
        "duration": 5.72,
        "text": "it sure I I can take it I think I think"
      },
      {
        "start": 2995.799,
        "duration": 7.681,
        "text": "we were looking for something like"
      },
      {
        "start": 2998.0,
        "duration": 9.28,
        "text": "pretty simple to implement um and also"
      },
      {
        "start": 3003.48,
        "duration": 5.119,
        "text": "like something that would focus more on"
      },
      {
        "start": 3007.28,
        "duration": 4.079,
        "text": "the setting of what we're doing as"
      },
      {
        "start": 3008.599,
        "duration": 6.161,
        "text": "opposed to the image itself because if"
      },
      {
        "start": 3011.359,
        "duration": 6.401,
        "text": "you took a picture of what you're doing"
      },
      {
        "start": 3014.76,
        "duration": 6.24,
        "text": "and then created em an embedding only on"
      },
      {
        "start": 3017.76,
        "duration": 6.72,
        "text": "that picture um the the embedding would"
      },
      {
        "start": 3021.0,
        "duration": 5.799,
        "text": "probably be like a descriptor of like"
      },
      {
        "start": 3024.48,
        "duration": 6.079,
        "text": "what is in the image so instead of like"
      },
      {
        "start": 3026.799,
        "duration": 5.961,
        "text": "saying anything about like the vibe um"
      },
      {
        "start": 3030.559,
        "duration": 5.04,
        "text": "what sort of songs might be a good match"
      },
      {
        "start": 3032.76,
        "duration": 5.76,
        "text": "it would just say like there is a person"
      },
      {
        "start": 3035.599,
        "duration": 6.881,
        "text": "in a room with headphones on um and it"
      },
      {
        "start": 3038.52,
        "duration": 6.88,
        "text": "wouldn't give any of that sort of like"
      },
      {
        "start": 3042.48,
        "duration": 5.599,
        "text": "it wouldn't make any guesses about the"
      },
      {
        "start": 3045.4,
        "duration": 6.32,
        "text": "Ambiance or like what what sort of mood"
      },
      {
        "start": 3048.079,
        "duration": 5.681,
        "text": "that person might be in so um we we felt"
      },
      {
        "start": 3051.72,
        "duration": 5.119,
        "text": "like an easy way to get that information"
      },
      {
        "start": 3053.76,
        "duration": 5.4,
        "text": "would just be to ask an llm"
      },
      {
        "start": 3056.839,
        "duration": 4.76,
        "text": "for that specific information like hey"
      },
      {
        "start": 3059.16,
        "duration": 5.04,
        "text": "here's this picture we're trying to do"
      },
      {
        "start": 3061.599,
        "duration": 5.681,
        "text": "this with it try and give me the most"
      },
      {
        "start": 3064.2,
        "duration": 5.84,
        "text": "valuable text um to do these similarity"
      },
      {
        "start": 3067.28,
        "duration": 4.6,
        "text": "searches in order to give good song"
      },
      {
        "start": 3070.04,
        "duration": 5.559,
        "text": "recommendations so giving all of that"
      },
      {
        "start": 3071.88,
        "duration": 6.12,
        "text": "context to create data that is hyp"
      },
      {
        "start": 3075.599,
        "duration": 4.921,
        "text": "specific to this use case um which might"
      },
      {
        "start": 3078.0,
        "duration": 4.72,
        "text": "not be captured if we were to embed the"
      },
      {
        "start": 3080.52,
        "duration": 4.64,
        "text": "images"
      },
      {
        "start": 3082.72,
        "duration": 3.879,
        "text": "directly perfect I think even we had"
      },
      {
        "start": 3085.16,
        "duration": 3.399,
        "text": "someone in the chat even give their"
      },
      {
        "start": 3086.599,
        "duration": 5.161,
        "text": "answer to give the embedding more"
      },
      {
        "start": 3088.559,
        "duration": 5.201,
        "text": "context that's exactly it um we want to"
      },
      {
        "start": 3091.76,
        "duration": 4.039,
        "text": "give the embedding as much context as"
      },
      {
        "start": 3093.76,
        "duration": 3.839,
        "text": "possible um and all the things that"
      },
      {
        "start": 3095.799,
        "duration": 4.121,
        "text": "we're looking for right if we were to"
      },
      {
        "start": 3097.599,
        "duration": 4.52,
        "text": "just take the image sometimes it might"
      },
      {
        "start": 3099.92,
        "duration": 5.12,
        "text": "embed some characteristics such as you"
      },
      {
        "start": 3102.119,
        "duration": 5.2,
        "text": "know demographic age height so on and so"
      },
      {
        "start": 3105.04,
        "duration": 4.0,
        "text": "forth these are all things that we don't"
      },
      {
        "start": 3107.319,
        "duration": 3.641,
        "text": "necessarily want or need for this"
      },
      {
        "start": 3109.04,
        "duration": 4.319,
        "text": "application right and that's why we're"
      },
      {
        "start": 3110.96,
        "duration": 4.44,
        "text": "going to the llm to essentially provide"
      },
      {
        "start": 3113.359,
        "duration": 3.361,
        "text": "these descriptions for us and then embed"
      },
      {
        "start": 3115.4,
        "duration": 3.159,
        "text": "those so we know exactly what we're"
      },
      {
        "start": 3116.72,
        "duration": 4.04,
        "text": "looking for we're embeding exactly what"
      },
      {
        "start": 3118.559,
        "duration": 2.201,
        "text": "we"
      },
      {
        "start": 3121.64,
        "duration": 6.0,
        "text": "need awesome great well any any other"
      },
      {
        "start": 3124.72,
        "duration": 5.96,
        "text": "questions here you want to get"
      },
      {
        "start": 3127.64,
        "duration": 5.32,
        "text": "to uh I see in the chat how do you deal"
      },
      {
        "start": 3130.68,
        "duration": 5.159,
        "text": "with the subjectivity of the description"
      },
      {
        "start": 3132.96,
        "duration": 4.839,
        "text": "generated by chaty BT sometimes a song"
      },
      {
        "start": 3135.839,
        "duration": 3.96,
        "text": "can be considered motivating for someone"
      },
      {
        "start": 3137.799,
        "duration": 3.76,
        "text": "and not for other people how can I be"
      },
      {
        "start": 3139.799,
        "duration": 4.0,
        "text": "sure that my description is generic"
      },
      {
        "start": 3141.559,
        "duration": 6.201,
        "text": "enough to cover the majority of CAS"
      },
      {
        "start": 3143.799,
        "duration": 6.32,
        "text": "cases um someone else responds"
      },
      {
        "start": 3147.76,
        "duration": 4.799,
        "text": "you can deal with that via prompt or you"
      },
      {
        "start": 3150.119,
        "duration": 4.121,
        "text": "can train a different model um you can"
      },
      {
        "start": 3152.559,
        "duration": 4.401,
        "text": "chunk and train based on what your"
      },
      {
        "start": 3154.24,
        "duration": 4.4,
        "text": "version of motivating is yeah if if"
      },
      {
        "start": 3156.96,
        "duration": 3.8,
        "text": "you're trying to make this hypers"
      },
      {
        "start": 3158.64,
        "duration": 5.479,
        "text": "specific for yourself you can add"
      },
      {
        "start": 3160.76,
        "duration": 5.72,
        "text": "criteria to The Prompt that says like"
      },
      {
        "start": 3164.119,
        "duration": 4.921,
        "text": "this is what I think of these songs"
      },
      {
        "start": 3166.48,
        "duration": 4.24,
        "text": "generally and then have the llm try and"
      },
      {
        "start": 3169.04,
        "duration": 4.12,
        "text": "uh and apply that to whatever it's"
      },
      {
        "start": 3170.72,
        "duration": 4.359,
        "text": "getting um if you're trying to keep it"
      },
      {
        "start": 3173.16,
        "duration": 3.72,
        "text": "more General then you can explicitly"
      },
      {
        "start": 3175.079,
        "duration": 5.321,
        "text": "state that in the prompts that you're"
      },
      {
        "start": 3176.88,
        "duration": 5.959,
        "text": "giving to the llm um and here I mean I"
      },
      {
        "start": 3180.4,
        "duration": 5.959,
        "text": "didn't tell the llm to do this"
      },
      {
        "start": 3182.839,
        "duration": 6.121,
        "text": "explicitly but it's kind of um doing"
      },
      {
        "start": 3186.359,
        "duration": 5.641,
        "text": "that on its own it's giving four"
      },
      {
        "start": 3188.96,
        "duration": 6.159,
        "text": "different options for types of music or"
      },
      {
        "start": 3192.0,
        "duration": 5.28,
        "text": "settings that would fit the image um and"
      },
      {
        "start": 3195.119,
        "duration": 4.601,
        "text": "so there there's definitely prompt"
      },
      {
        "start": 3197.28,
        "duration": 4.24,
        "text": "engineering you can do to kind of fit"
      },
      {
        "start": 3199.72,
        "duration": 4.879,
        "text": "whatever functionality you're looking"
      },
      {
        "start": 3201.52,
        "duration": 6.559,
        "text": "for uh but then yeah um training"
      },
      {
        "start": 3204.599,
        "duration": 8.321,
        "text": "training based on how you want the model"
      },
      {
        "start": 3208.079,
        "duration": 7.441,
        "text": "to behave is also another really great"
      },
      {
        "start": 3212.92,
        "duration": 5.159,
        "text": "approach yeah I think prompting is kind"
      },
      {
        "start": 3215.52,
        "duration": 4.2,
        "text": "of the art here right um multiple"
      },
      {
        "start": 3218.079,
        "duration": 3.401,
        "text": "different ways of doing it you can do it"
      },
      {
        "start": 3219.72,
        "duration": 3.599,
        "text": "kind of in a very simple simple way that"
      },
      {
        "start": 3221.48,
        "duration": 3.44,
        "text": "Annie and I did where you just kind of"
      },
      {
        "start": 3223.319,
        "duration": 4.121,
        "text": "you know give a description of what"
      },
      {
        "start": 3224.92,
        "duration": 4.48,
        "text": "you'd like um but there's also prompting"
      },
      {
        "start": 3227.44,
        "duration": 3.76,
        "text": "techniques such as fuse shot prompting"
      },
      {
        "start": 3229.4,
        "duration": 4.439,
        "text": "right where you actually give examples"
      },
      {
        "start": 3231.2,
        "duration": 5.24,
        "text": "to the llm of what you consider songs of"
      },
      {
        "start": 3233.839,
        "duration": 5.0,
        "text": "motivating are or scary or sad or so on"
      },
      {
        "start": 3236.44,
        "duration": 5.52,
        "text": "and so forth right so the llm has extra"
      },
      {
        "start": 3238.839,
        "duration": 5.76,
        "text": "context to know um how to classify these"
      },
      {
        "start": 3241.96,
        "duration": 5.24,
        "text": "groups before doing it um but that"
      },
      {
        "start": 3244.599,
        "duration": 3.921,
        "text": "really all goes into the prompt um if if"
      },
      {
        "start": 3247.2,
        "duration": 5.48,
        "text": "you really don't want to train you know"
      },
      {
        "start": 3248.52,
        "duration": 4.16,
        "text": "another llm for for this exact use"
      },
      {
        "start": 3253.92,
        "duration": 5.56,
        "text": "case cool uh any other question question"
      },
      {
        "start": 3257.48,
        "duration": 4.92,
        "text": "question on LinkedIn what technology is"
      },
      {
        "start": 3259.48,
        "duration": 6.48,
        "text": "being used to get the labels for a given"
      },
      {
        "start": 3262.4,
        "duration": 7.52,
        "text": "image for example Google Vision um so"
      },
      {
        "start": 3265.96,
        "duration": 9.48,
        "text": "we're we're using open AI GPT"
      },
      {
        "start": 3269.92,
        "duration": 7.76,
        "text": "40 um so right here we are sending this"
      },
      {
        "start": 3275.44,
        "duration": 5.76,
        "text": "prompt with the song name and artist"
      },
      {
        "start": 3277.68,
        "duration": 5.24,
        "text": "name oh give an image my bad my bad"
      },
      {
        "start": 3281.2,
        "duration": 4.04,
        "text": "that's on the query side uh we're still"
      },
      {
        "start": 3282.92,
        "duration": 2.32,
        "text": "using"
      },
      {
        "start": 3285.64,
        "duration": 5.919,
        "text": "gp40 um we're sending this prompt so"
      },
      {
        "start": 3289.0,
        "duration": 6.88,
        "text": "we're asking the llm like we're saying"
      },
      {
        "start": 3291.559,
        "duration": 8.04,
        "text": "hey llm we're gonna give you um an image"
      },
      {
        "start": 3295.88,
        "duration": 5.0,
        "text": "and please describe it using this prompt"
      },
      {
        "start": 3299.599,
        "duration": 3.52,
        "text": "um so so that's what's happening we're"
      },
      {
        "start": 3300.88,
        "duration": 5.4,
        "text": "using GPT 4L first we did actually"
      },
      {
        "start": 3303.119,
        "duration": 7.0,
        "text": "implement this using with with Gemini"
      },
      {
        "start": 3306.28,
        "duration": 5.4,
        "text": "provision uh but then um we decided to"
      },
      {
        "start": 3310.119,
        "duration": 3.24,
        "text": "switch everything over to open AI"
      },
      {
        "start": 3311.68,
        "duration": 5.28,
        "text": "because we were doing embeddings with"
      },
      {
        "start": 3313.359,
        "duration": 5.801,
        "text": "one like with one provider and the llm"
      },
      {
        "start": 3316.96,
        "duration": 5.2,
        "text": "stuff with another but we figured if"
      },
      {
        "start": 3319.16,
        "duration": 5.199,
        "text": "we're using things within the same like"
      },
      {
        "start": 3322.16,
        "duration": 3.72,
        "text": "Universe perhaps they're trained on more"
      },
      {
        "start": 3324.359,
        "duration": 3.841,
        "text": "similar data so you'd get like more"
      },
      {
        "start": 3325.88,
        "duration": 5.76,
        "text": "consistent results so but yeah you could"
      },
      {
        "start": 3328.2,
        "duration": 7.56,
        "text": "swap this out for for kind of whatever"
      },
      {
        "start": 3331.64,
        "duration": 4.12,
        "text": "llm embedding combo that you"
      },
      {
        "start": 3337.799,
        "duration": 3.481,
        "text": "want any other questions that we can"
      },
      {
        "start": 3340.2,
        "duration": 3.28,
        "text": "[Music]"
      },
      {
        "start": 3341.28,
        "duration": 5.4,
        "text": "answer I want to"
      },
      {
        "start": 3343.48,
        "duration": 5.2,
        "text": "get I just want to get the Halloween"
      },
      {
        "start": 3346.68,
        "duration": 4.24,
        "text": "example back"
      },
      {
        "start": 3348.68,
        "duration": 5.76,
        "text": "up there it"
      },
      {
        "start": 3350.92,
        "duration": 4.6,
        "text": "is awesome I see here so this this"
      },
      {
        "start": 3354.44,
        "duration": 2.879,
        "text": "question is this might be too"
      },
      {
        "start": 3355.52,
        "duration": 3.96,
        "text": "complicated to answer in the time frame"
      },
      {
        "start": 3357.319,
        "duration": 5.0,
        "text": "but how are the distances between"
      },
      {
        "start": 3359.48,
        "duration": 6.92,
        "text": "individual vectors determined for"
      },
      {
        "start": 3362.319,
        "duration": 5.881,
        "text": "similarity and how granular can these be"
      },
      {
        "start": 3366.4,
        "duration": 3.52,
        "text": "well that's a really good question um"
      },
      {
        "start": 3368.2,
        "duration": 4.879,
        "text": "there's really three main ways to"
      },
      {
        "start": 3369.92,
        "duration": 4.919,
        "text": "perform these Vector similarity searches"
      },
      {
        "start": 3373.079,
        "duration": 4.081,
        "text": "um one of them or the one that we're"
      },
      {
        "start": 3374.839,
        "duration": 3.641,
        "text": "using here is called cosine similarity"
      },
      {
        "start": 3377.16,
        "duration": 3.439,
        "text": "and we're essentially finding the"
      },
      {
        "start": 3378.48,
        "duration": 4.359,
        "text": "distances between the vectors or how far"
      },
      {
        "start": 3380.599,
        "duration": 3.401,
        "text": "away they are from one another um and"
      },
      {
        "start": 3382.839,
        "duration": 4.161,
        "text": "that's what you were seeing when we"
      },
      {
        "start": 3384.0,
        "duration": 4.52,
        "text": "would show the 7 or you know the coine"
      },
      {
        "start": 3387.0,
        "duration": 4.039,
        "text": "similarity scores here all the way on"
      },
      {
        "start": 3388.52,
        "duration": 4.92,
        "text": "the right of this table um this is being"
      },
      {
        "start": 3391.039,
        "duration": 4.921,
        "text": "provided by that that similarity search"
      },
      {
        "start": 3393.44,
        "duration": 4.04,
        "text": "or that metric called cosine similarity"
      },
      {
        "start": 3395.96,
        "duration": 3.28,
        "text": "but there's also you know a variety of"
      },
      {
        "start": 3397.48,
        "duration": 4.2,
        "text": "others out there there's one called dot"
      },
      {
        "start": 3399.24,
        "duration": 4.2,
        "text": "product or ukian distance all of these"
      },
      {
        "start": 3401.68,
        "duration": 3.84,
        "text": "are different ways of calculating"
      },
      {
        "start": 3403.44,
        "duration": 4.44,
        "text": "distances between vectors U and"
      },
      {
        "start": 3405.52,
        "duration": 3.76,
        "text": "Performing these similarity searches but"
      },
      {
        "start": 3407.88,
        "duration": 3.84,
        "text": "Annie and I chose to go with cosine"
      },
      {
        "start": 3409.28,
        "duration": 5.0,
        "text": "similarity that's usually kind of the de"
      },
      {
        "start": 3411.72,
        "duration": 5.24,
        "text": "facto you know Norm um when working with"
      },
      {
        "start": 3414.28,
        "duration": 4.039,
        "text": "Vector search um but that's you know how"
      },
      {
        "start": 3416.96,
        "duration": 3.48,
        "text": "how we how we do this and how the"
      },
      {
        "start": 3418.319,
        "duration": 4.201,
        "text": "distances are are calculated like"
      },
      {
        "start": 3420.44,
        "duration": 4.52,
        "text": "different different embeddings models"
      },
      {
        "start": 3422.52,
        "duration": 6.079,
        "text": "already by default use different"
      },
      {
        "start": 3424.96,
        "duration": 7.72,
        "text": "similarity metrics um so if we were"
      },
      {
        "start": 3428.599,
        "duration": 7.281,
        "text": "tried to use this text embedding 3 model"
      },
      {
        "start": 3432.68,
        "duration": 4.639,
        "text": "with DOT product similarity it wouldn't"
      },
      {
        "start": 3435.88,
        "duration": 3.08,
        "text": "it wouldn't work well like it wouldn't"
      },
      {
        "start": 3437.319,
        "duration": 5.24,
        "text": "be an accurate representation because"
      },
      {
        "start": 3438.96,
        "duration": 8.04,
        "text": "the the dimensions are sorry the vectors"
      },
      {
        "start": 3442.559,
        "duration": 7.52,
        "text": "are created um assuming that like"
      },
      {
        "start": 3447.0,
        "duration": 5.599,
        "text": "distances are calculated with cosine so"
      },
      {
        "start": 3450.079,
        "duration": 4.841,
        "text": "whatever model you're using um that kind"
      },
      {
        "start": 3452.599,
        "duration": 5.161,
        "text": "of determines what distance metrics make"
      },
      {
        "start": 3454.92,
        "duration": 2.84,
        "text": "the most sense for"
      },
      {
        "start": 3458.319,
        "duration": 4.76,
        "text": "it awesome how do you approach training"
      },
      {
        "start": 3460.799,
        "duration": 4.121,
        "text": "the AI models for different music genres"
      },
      {
        "start": 3463.079,
        "duration": 4.96,
        "text": "and Regional preferences ensuring that"
      },
      {
        "start": 3464.92,
        "duration": 5.36,
        "text": "the model understands cultural and genre"
      },
      {
        "start": 3468.039,
        "duration": 4.641,
        "text": "specific"
      },
      {
        "start": 3470.28,
        "duration": 4.68,
        "text": "nuances yeah that's that's a really"
      },
      {
        "start": 3472.68,
        "duration": 6.04,
        "text": "interesting question so that's not"
      },
      {
        "start": 3474.96,
        "duration": 7.119,
        "text": "something that we've implemented here um"
      },
      {
        "start": 3478.72,
        "duration": 8.52,
        "text": "but what I could see happening is if you"
      },
      {
        "start": 3482.079,
        "duration": 8.48,
        "text": "have user data um and maybe like you"
      },
      {
        "start": 3487.24,
        "duration": 7.96,
        "text": "want to only recommend certain songs if"
      },
      {
        "start": 3490.559,
        "duration": 7.04,
        "text": "the user is based in uh APAC for example"
      },
      {
        "start": 3495.2,
        "duration": 6.68,
        "text": "like what you could do is add another"
      },
      {
        "start": 3497.599,
        "duration": 6.681,
        "text": "field here um to kind of indicate"
      },
      {
        "start": 3501.88,
        "duration": 4.32,
        "text": "whether a song should or should not be"
      },
      {
        "start": 3504.28,
        "duration": 4.92,
        "text": "shown to someone who's searching from"
      },
      {
        "start": 3506.2,
        "duration": 4.52,
        "text": "APAC so maybe you could do like a like"
      },
      {
        "start": 3509.2,
        "duration": 4.2,
        "text": "the column name would be APAC it would"
      },
      {
        "start": 3510.72,
        "duration": 4.92,
        "text": "just be like true or false um and then"
      },
      {
        "start": 3513.4,
        "duration": 4.639,
        "text": "if you want to limit results to for a"
      },
      {
        "start": 3515.64,
        "duration": 4.08,
        "text": "specific person when you do your"
      },
      {
        "start": 3518.039,
        "duration": 3.8,
        "text": "similarity search you can do something"
      },
      {
        "start": 3519.72,
        "duration": 5.24,
        "text": "called a hybrid search where you add a"
      },
      {
        "start": 3521.839,
        "duration": 5.52,
        "text": "filter before you do that Vector search"
      },
      {
        "start": 3524.96,
        "duration": 4.639,
        "text": "so um instead of searching over the"
      },
      {
        "start": 3527.359,
        "duration": 4.2,
        "text": "entire database you would say I want to"
      },
      {
        "start": 3529.599,
        "duration": 4.44,
        "text": "filter my results to only this"
      },
      {
        "start": 3531.559,
        "duration": 6.121,
        "text": "subsection of the database where the"
      },
      {
        "start": 3534.039,
        "duration": 6.28,
        "text": "apack flag is true and then do my Vector"
      },
      {
        "start": 3537.68,
        "duration": 6.639,
        "text": "search within that um so that's like a"
      },
      {
        "start": 3540.319,
        "duration": 5.841,
        "text": "pretty um like you you can add a lot of"
      },
      {
        "start": 3544.319,
        "duration": 4.601,
        "text": "like variables to that that you want to"
      },
      {
        "start": 3546.16,
        "duration": 4.639,
        "text": "include uh if if you're trying to do"
      },
      {
        "start": 3548.92,
        "duration": 5.159,
        "text": "some sort of structured"
      },
      {
        "start": 3550.799,
        "duration": 5.121,
        "text": "filtering uh add more personalization"
      },
      {
        "start": 3554.079,
        "duration": 5.201,
        "text": "then there are ways to like add"
      },
      {
        "start": 3555.92,
        "duration": 5.24,
        "text": "additional Fields like metadata um so"
      },
      {
        "start": 3559.28,
        "duration": 3.519,
        "text": "that you could do that sort of thing but"
      },
      {
        "start": 3561.16,
        "duration": 4.12,
        "text": "we didn't we didn't Implement that in"
      },
      {
        "start": 3562.799,
        "duration": 4.681,
        "text": "this example it's all just like full"
      },
      {
        "start": 3565.28,
        "duration": 4.16,
        "text": "playlist is own into Astra we're"
      },
      {
        "start": 3567.48,
        "duration": 3.639,
        "text": "searching across the the entire thing"
      },
      {
        "start": 3569.44,
        "duration": 4.04,
        "text": "but but there's a lot of like cool"
      },
      {
        "start": 3571.119,
        "duration": 5.601,
        "text": "things you could do if you needed to"
      },
      {
        "start": 3573.48,
        "duration": 5.559,
        "text": "have some more granularity"
      },
      {
        "start": 3576.72,
        "duration": 4.24,
        "text": "there yeah that's a great question and a"
      },
      {
        "start": 3579.039,
        "duration": 3.56,
        "text": "great answer I think that metadata one"
      },
      {
        "start": 3580.96,
        "duration": 4.04,
        "text": "is a great next step right if you"
      },
      {
        "start": 3582.599,
        "duration": 3.841,
        "text": "already know uh the genres of of the"
      },
      {
        "start": 3585.0,
        "duration": 3.359,
        "text": "different songs that you're uploading"
      },
      {
        "start": 3586.44,
        "duration": 4.0,
        "text": "right might as well just use that in a"
      },
      {
        "start": 3588.359,
        "duration": 3.72,
        "text": "hybrid search um to essentially have"
      },
      {
        "start": 3590.44,
        "duration": 3.879,
        "text": "that as a subset of data that you're"
      },
      {
        "start": 3592.079,
        "duration": 4.76,
        "text": "recommending so you know for a fact that"
      },
      {
        "start": 3594.319,
        "duration": 4.04,
        "text": "you know if I'm have some Loi songs"
      },
      {
        "start": 3596.839,
        "duration": 3.041,
        "text": "right I can put that as maybe a calming"
      },
      {
        "start": 3598.359,
        "duration": 4.2,
        "text": "genre or something like that or study"
      },
      {
        "start": 3599.88,
        "duration": 4.28,
        "text": "genre and then maybe have the llm return"
      },
      {
        "start": 3602.559,
        "duration": 3.441,
        "text": "hey this setting you know seems like"
      },
      {
        "start": 3604.16,
        "duration": 4.0,
        "text": "this type of genre right Andy's working"
      },
      {
        "start": 3606.0,
        "duration": 4.2,
        "text": "maybe you know put it for for study or"
      },
      {
        "start": 3608.16,
        "duration": 4.199,
        "text": "working genre and then perform a hybrid"
      },
      {
        "start": 3610.2,
        "duration": 4.639,
        "text": "search so you're only you know returning"
      },
      {
        "start": 3612.359,
        "duration": 4.161,
        "text": "or limiting your results to songs in"
      },
      {
        "start": 3614.839,
        "duration": 3.681,
        "text": "that"
      },
      {
        "start": 3616.52,
        "duration": 5.519,
        "text": "genre"
      },
      {
        "start": 3618.52,
        "duration": 6.92,
        "text": "sweet cool um any any last questions I"
      },
      {
        "start": 3622.039,
        "duration": 5.0,
        "text": "know I know we're at time now um I'm"
      },
      {
        "start": 3625.44,
        "duration": 4.399,
        "text": "glad we're able get through everything"
      },
      {
        "start": 3627.039,
        "duration": 6.0,
        "text": "and show the code uh the GitHub repo for"
      },
      {
        "start": 3629.839,
        "duration": 4.641,
        "text": "this project is still up on the cast so"
      },
      {
        "start": 3633.039,
        "duration": 4.28,
        "text": "if you want to take a look yourself and"
      },
      {
        "start": 3634.48,
        "duration": 5.44,
        "text": "run it yourself um that's an"
      },
      {
        "start": 3637.319,
        "duration": 4.161,
        "text": "option um let's see is there is there"
      },
      {
        "start": 3639.92,
        "duration": 4.52,
        "text": "anything else that we want to get to"
      },
      {
        "start": 3641.48,
        "duration": 4.16,
        "text": "before we end the stream I think we"
      },
      {
        "start": 3644.44,
        "duration": 2.879,
        "text": "should be all good if they want to maybe"
      },
      {
        "start": 3645.64,
        "duration": 5.0,
        "text": "use that QR code that we have on our"
      },
      {
        "start": 3647.319,
        "duration": 4.52,
        "text": "last slide um to access that GitHub repo"
      },
      {
        "start": 3650.64,
        "duration": 4.88,
        "text": "um they're they're more than welcome to"
      },
      {
        "start": 3651.839,
        "duration": 6.081,
        "text": "do so sweet yeah let's I'll pull that up"
      },
      {
        "start": 3655.52,
        "duration": 2.4,
        "text": "right here"
      },
      {
        "start": 3658.44,
        "duration": 7.08,
        "text": "here cool um yeah yeah this this is like"
      },
      {
        "start": 3663.52,
        "duration": 5.2,
        "text": "this was a really fun thing for us to"
      },
      {
        "start": 3665.52,
        "duration": 6.36,
        "text": "work on and um we really appreciate the"
      },
      {
        "start": 3668.72,
        "duration": 6.04,
        "text": "opportunity to kind of speak to people"
      },
      {
        "start": 3671.88,
        "duration": 5.239,
        "text": "outside of the company about like"
      },
      {
        "start": 3674.76,
        "duration": 5.799,
        "text": "something cool that you can build with"
      },
      {
        "start": 3677.119,
        "duration": 5.24,
        "text": "AI and with Astra um and yeah all the"
      },
      {
        "start": 3680.559,
        "duration": 5.52,
        "text": "code is available so take a look"
      },
      {
        "start": 3682.359,
        "duration": 6.641,
        "text": "yourself um if you want to submit issues"
      },
      {
        "start": 3686.079,
        "duration": 5.24,
        "text": "on the repo or contribute that's like"
      },
      {
        "start": 3689.0,
        "duration": 5.079,
        "text": "totally an option if you want to ask"
      },
      {
        "start": 3691.319,
        "duration": 5.161,
        "text": "questions about it uh there's a link to"
      },
      {
        "start": 3694.079,
        "duration": 5.48,
        "text": "the uh data sex"
      },
      {
        "start": 3696.48,
        "duration": 5.92,
        "text": "developer uh Discord where you could"
      },
      {
        "start": 3699.559,
        "duration": 4.28,
        "text": "join and like message us directly about"
      },
      {
        "start": 3702.4,
        "duration": 4.24,
        "text": "it or just like talk about things that"
      },
      {
        "start": 3703.839,
        "duration": 4.76,
        "text": "you're doing um yeah and and if you're"
      },
      {
        "start": 3706.64,
        "duration": 3.919,
        "text": "building anything cool with Astro we"
      },
      {
        "start": 3708.599,
        "duration": 5.76,
        "text": "obviously want to want to hear about it"
      },
      {
        "start": 3710.559,
        "duration": 5.56,
        "text": "but um yeah this was this was a great"
      },
      {
        "start": 3714.359,
        "duration": 4.121,
        "text": "time"
      },
      {
        "start": 3716.119,
        "duration": 4.361,
        "text": "yeah I had an absolute blast and feel"
      },
      {
        "start": 3718.48,
        "duration": 3.4,
        "text": "free to Fork it and as Annie mentioned"
      },
      {
        "start": 3720.48,
        "duration": 3.48,
        "text": "you can hit us up on the developer"
      },
      {
        "start": 3721.88,
        "duration": 3.199,
        "text": "Discord more than happy to chat more"
      },
      {
        "start": 3723.96,
        "duration": 3.319,
        "text": "about it if you have any feature"
      },
      {
        "start": 3725.079,
        "duration": 3.561,
        "text": "requests things like that um kind of"
      },
      {
        "start": 3727.279,
        "duration": 3.361,
        "text": "want to keep this as a collaborative"
      },
      {
        "start": 3728.64,
        "duration": 3.56,
        "text": "project with everyone um since this is"
      },
      {
        "start": 3730.64,
        "duration": 3.199,
        "text": "something that Anie and I thought would"
      },
      {
        "start": 3732.2,
        "duration": 3.76,
        "text": "be kind of cool for for us to use at"
      },
      {
        "start": 3733.839,
        "duration": 5.2,
        "text": "home and so with that being said any"
      },
      {
        "start": 3735.96,
        "duration": 4.56,
        "text": "questions feel free to reach out um and"
      },
      {
        "start": 3739.039,
        "duration": 3.641,
        "text": "we had an absolute blast thanks for"
      },
      {
        "start": 3740.52,
        "duration": 4.559,
        "text": "spending the last hour with us awesome"
      },
      {
        "start": 3742.68,
        "duration": 4.84,
        "text": "yeah thank you everyone once again the"
      },
      {
        "start": 3745.079,
        "duration": 5.881,
        "text": "this is recorded the link will go out as"
      },
      {
        "start": 3747.52,
        "duration": 5.88,
        "text": "soon as it's ready following the cast um"
      },
      {
        "start": 3750.96,
        "duration": 3.92,
        "text": "and yeah reach out to us whenever you"
      },
      {
        "start": 3753.4,
        "duration": 5.36,
        "text": "want with any questions you have via"
      },
      {
        "start": 3754.88,
        "duration": 6.8,
        "text": "that Discord also uh any any slack sorry"
      },
      {
        "start": 3758.76,
        "duration": 4.92,
        "text": "any chat message that you send um on"
      },
      {
        "start": 3761.68,
        "duration": 5.04,
        "text": "data sax pages that probably actually"
      },
      {
        "start": 3763.68,
        "duration": 4.919,
        "text": "goes to us so um if you need to reach"
      },
      {
        "start": 3766.72,
        "duration": 6.0,
        "text": "out we're we're"
      },
      {
        "start": 3768.599,
        "duration": 6.52,
        "text": "available great okay um yeah thanks"
      },
      {
        "start": 3772.72,
        "duration": 5.0,
        "text": "again for your time uh that was a really"
      },
      {
        "start": 3775.119,
        "duration": 6.081,
        "text": "fun hour I hope everyone has a good rest"
      },
      {
        "start": 3777.72,
        "duration": 6.2,
        "text": "of your day and again let us know if"
      },
      {
        "start": 3781.2,
        "duration": 5.76,
        "text": "anything interesting comes up I had so"
      },
      {
        "start": 3783.92,
        "duration": 6.6,
        "text": "much fun today take care I'm here have a"
      },
      {
        "start": 3786.96,
        "duration": 3.56,
        "text": "good one y'all see you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-10T23:50:05.462281+00:00"
}