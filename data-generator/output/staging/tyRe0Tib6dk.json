{
  "video_id": "tyRe0Tib6dk",
  "title": "DS320.14 Optimization: Broadcast Variables | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.14 Optimization: Broadcast Variables\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:27:53Z",
  "thumbnail": "https://i.ytimg.com/vi/tyRe0Tib6dk/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=tyRe0Tib6dk",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] spark is built to be fast but that doesn't mean there's nothing you can do to make it go faster we're going to look at a few techniques for that here one common optimization is to use shared variables which break down into two categories broadcast variables and accumulators let's take a look at those in turn broadcast variables are read only variables whose values are broadcasted and cached on each node in a cluster and are visible to all tasks of an application now when i say read only i mean they are read-only with respect to tasks with respect to the computation that's going on in the spark cluster of course they're not read-only from the perspective of the driver the driver is able to change them these are a good idea when my spark job may result in many separate tasks having access to the same immutable data set especially if that data set is large broadcast variables become a very good thing the api is very simple i create one with the broadcast method on the spark context and i pass to that method the initial value of the broadcast variable and if i want to read a broadcast variable i simply call its value method now let's walk through this code here's an example of a naive implementation of a certain computation not using the broadcast variables optimization that first line up top creating the popular titles value is a set that's a statically initialized set of a few film names we then do a query on a cassandra table in that next line and then call a filter transformation and save that back to cassandra and another filter transformation and save that back to another cassandra table now take a look at those last two filters notice in the anonymous function that we pass into them we use popular titles we test whether each data item is a member of that popular title set that means that that set is going to have to be shipped around the cluster by the client to each task that does that work and we can probably do better let's look at how now not much has changed from the previous example to this one really just the first line instead of creating a statically initialized set on that first line we call the broadcast method on the spark context and then pass in that same statically initialized set that we would have created the popular titles value is now a broadcast variable that gets sent by the spark client one time into the cluster and the cluster uses a peer-to-peer replication protocol to move that efficiently to the nodes that need it those worker nodes do the work of shipping that data around the cluster the driver is not a bottleneck in a trivially sized cluster of a few nodes this isn't a big win but the bigger your cluster gets the more work you have to do the more of a win this is with the workers sharing the job of moving that data around you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.879,
        "duration": 3.361,
        "text": "spark is built to be fast but that"
      },
      {
        "start": 8.639,
        "duration": 3.441,
        "text": "doesn't mean there's nothing you can do"
      },
      {
        "start": 10.24,
        "duration": 3.519,
        "text": "to make it go faster we're going to look"
      },
      {
        "start": 12.08,
        "duration": 3.84,
        "text": "at a few techniques for that here"
      },
      {
        "start": 13.759,
        "duration": 3.681,
        "text": "one common optimization is to use shared"
      },
      {
        "start": 15.92,
        "duration": 2.56,
        "text": "variables which break down into two"
      },
      {
        "start": 17.44,
        "duration": 3.52,
        "text": "categories"
      },
      {
        "start": 18.48,
        "duration": 4.24,
        "text": "broadcast variables and accumulators"
      },
      {
        "start": 20.96,
        "duration": 3.84,
        "text": "let's take a look at those in turn"
      },
      {
        "start": 22.72,
        "duration": 4.16,
        "text": "broadcast variables are read only"
      },
      {
        "start": 24.8,
        "duration": 4.08,
        "text": "variables whose values are broadcasted"
      },
      {
        "start": 26.88,
        "duration": 4.639,
        "text": "and cached on each node in a cluster"
      },
      {
        "start": 28.88,
        "duration": 4.32,
        "text": "and are visible to all tasks of an"
      },
      {
        "start": 31.519,
        "duration": 3.601,
        "text": "application now when i say read only i"
      },
      {
        "start": 33.2,
        "duration": 3.76,
        "text": "mean they are read-only with respect to"
      },
      {
        "start": 35.12,
        "duration": 3.04,
        "text": "tasks with respect to the computation"
      },
      {
        "start": 36.96,
        "duration": 3.2,
        "text": "that's going on"
      },
      {
        "start": 38.16,
        "duration": 3.6,
        "text": "in the spark cluster of course they're"
      },
      {
        "start": 40.16,
        "duration": 3.36,
        "text": "not read-only from the perspective"
      },
      {
        "start": 41.76,
        "duration": 3.44,
        "text": "of the driver the driver is able to"
      },
      {
        "start": 43.52,
        "duration": 4.48,
        "text": "change them these are a good idea"
      },
      {
        "start": 45.2,
        "duration": 3.92,
        "text": "when my spark job may result in many"
      },
      {
        "start": 48.0,
        "duration": 3.84,
        "text": "separate tasks"
      },
      {
        "start": 49.12,
        "duration": 4.64,
        "text": "having access to the same immutable data"
      },
      {
        "start": 51.84,
        "duration": 4.32,
        "text": "set especially if that data set is large"
      },
      {
        "start": 53.76,
        "duration": 3.68,
        "text": "broadcast variables become a very good"
      },
      {
        "start": 56.16,
        "duration": 3.52,
        "text": "thing the api"
      },
      {
        "start": 57.44,
        "duration": 4.56,
        "text": "is very simple i create one with the"
      },
      {
        "start": 59.68,
        "duration": 3.76,
        "text": "broadcast method on the spark context"
      },
      {
        "start": 62.0,
        "duration": 3.199,
        "text": "and i pass to that method"
      },
      {
        "start": 63.44,
        "duration": 3.679,
        "text": "the initial value of the broadcast"
      },
      {
        "start": 65.199,
        "duration": 3.441,
        "text": "variable and if i want to read a"
      },
      {
        "start": 67.119,
        "duration": 3.121,
        "text": "broadcast variable i simply call its"
      },
      {
        "start": 68.64,
        "duration": 3.04,
        "text": "value method"
      },
      {
        "start": 70.24,
        "duration": 4.0,
        "text": "now let's walk through this code here's"
      },
      {
        "start": 71.68,
        "duration": 3.84,
        "text": "an example of a naive implementation of"
      },
      {
        "start": 74.24,
        "duration": 3.04,
        "text": "a certain computation"
      },
      {
        "start": 75.52,
        "duration": 3.84,
        "text": "not using the broadcast variables"
      },
      {
        "start": 77.28,
        "duration": 4.32,
        "text": "optimization that first line up top"
      },
      {
        "start": 79.36,
        "duration": 5.119,
        "text": "creating the popular titles value"
      },
      {
        "start": 81.6,
        "duration": 3.44,
        "text": "is a set that's a statically initialized"
      },
      {
        "start": 84.479,
        "duration": 3.921,
        "text": "set"
      },
      {
        "start": 85.04,
        "duration": 4.48,
        "text": "of a few film names we then do a query"
      },
      {
        "start": 88.4,
        "duration": 3.28,
        "text": "on a cassandra table"
      },
      {
        "start": 89.52,
        "duration": 3.68,
        "text": "in that next line and then call a filter"
      },
      {
        "start": 91.68,
        "duration": 3.04,
        "text": "transformation and save that back to"
      },
      {
        "start": 93.2,
        "duration": 2.48,
        "text": "cassandra and another filter"
      },
      {
        "start": 94.72,
        "duration": 3.039,
        "text": "transformation"
      },
      {
        "start": 95.68,
        "duration": 4.24,
        "text": "and save that back to another cassandra"
      },
      {
        "start": 97.759,
        "duration": 2.961,
        "text": "table now take a look at those last two"
      },
      {
        "start": 99.92,
        "duration": 2.32,
        "text": "filters"
      },
      {
        "start": 100.72,
        "duration": 3.439,
        "text": "notice in the anonymous function that we"
      },
      {
        "start": 102.24,
        "duration": 4.64,
        "text": "pass into them we use"
      },
      {
        "start": 104.159,
        "duration": 3.121,
        "text": "popular titles we test whether each data"
      },
      {
        "start": 106.88,
        "duration": 2.72,
        "text": "item"
      },
      {
        "start": 107.28,
        "duration": 3.839,
        "text": "is a member of that popular title set"
      },
      {
        "start": 109.6,
        "duration": 2.72,
        "text": "that means that that set"
      },
      {
        "start": 111.119,
        "duration": 3.04,
        "text": "is going to have to be shipped around"
      },
      {
        "start": 112.32,
        "duration": 4.56,
        "text": "the cluster by the client"
      },
      {
        "start": 114.159,
        "duration": 3.6,
        "text": "to each task that does that work and we"
      },
      {
        "start": 116.88,
        "duration": 2.96,
        "text": "can probably"
      },
      {
        "start": 117.759,
        "duration": 4.161,
        "text": "do better let's look at how now not much"
      },
      {
        "start": 119.84,
        "duration": 2.639,
        "text": "has changed from the previous example to"
      },
      {
        "start": 121.92,
        "duration": 2.559,
        "text": "this one"
      },
      {
        "start": 122.479,
        "duration": 3.841,
        "text": "really just the first line instead of"
      },
      {
        "start": 124.479,
        "duration": 2.721,
        "text": "creating a statically initialized set on"
      },
      {
        "start": 126.32,
        "duration": 2.88,
        "text": "that first line"
      },
      {
        "start": 127.2,
        "duration": 4.08,
        "text": "we call the broadcast method on the"
      },
      {
        "start": 129.2,
        "duration": 3.84,
        "text": "spark context and then pass in"
      },
      {
        "start": 131.28,
        "duration": 3.2,
        "text": "that same statically initialized set"
      },
      {
        "start": 133.04,
        "duration": 3.919,
        "text": "that we would have created"
      },
      {
        "start": 134.48,
        "duration": 3.68,
        "text": "the popular titles value is now a"
      },
      {
        "start": 136.959,
        "duration": 3.601,
        "text": "broadcast variable"
      },
      {
        "start": 138.16,
        "duration": 3.12,
        "text": "that gets sent by the spark client one"
      },
      {
        "start": 140.56,
        "duration": 3.28,
        "text": "time"
      },
      {
        "start": 141.28,
        "duration": 3.44,
        "text": "into the cluster and the cluster uses a"
      },
      {
        "start": 143.84,
        "duration": 3.2,
        "text": "peer-to-peer"
      },
      {
        "start": 144.72,
        "duration": 3.76,
        "text": "replication protocol to move that"
      },
      {
        "start": 147.04,
        "duration": 3.919,
        "text": "efficiently to the nodes"
      },
      {
        "start": 148.48,
        "duration": 4.24,
        "text": "that need it those worker nodes do the"
      },
      {
        "start": 150.959,
        "duration": 2.321,
        "text": "work of shipping that data around the"
      },
      {
        "start": 152.72,
        "duration": 2.879,
        "text": "cluster"
      },
      {
        "start": 153.28,
        "duration": 3.36,
        "text": "the driver is not a bottleneck in a"
      },
      {
        "start": 155.599,
        "duration": 3.121,
        "text": "trivially sized"
      },
      {
        "start": 156.64,
        "duration": 4.16,
        "text": "cluster of a few nodes this isn't a big"
      },
      {
        "start": 158.72,
        "duration": 4.4,
        "text": "win but the bigger your cluster gets"
      },
      {
        "start": 160.8,
        "duration": 3.439,
        "text": "the more work you have to do the more of"
      },
      {
        "start": 163.12,
        "duration": 2.72,
        "text": "a win this is"
      },
      {
        "start": 164.239,
        "duration": 7.601,
        "text": "with the workers sharing the job of"
      },
      {
        "start": 165.84,
        "duration": 6.0,
        "text": "moving that data around"
      },
      {
        "start": 172.959,
        "duration": 2.081,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:44:35.634950+00:00"
}