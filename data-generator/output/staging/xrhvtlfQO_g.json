{
  "video_id": "xrhvtlfQO_g",
  "title": "DS320.40 Spark SQL: Spark SQL Basics | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.40 Spark SQL: Spark SQL Basics\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:33:18Z",
  "thumbnail": "https://i.ytimg.com/vi/xrhvtlfQO_g/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=xrhvtlfQO_g",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] now once you get going using spark with cassandra and you really get to know the rdd api and you become productive it might occur to you that you're doing a lot of the kinds of things that you might have done in sql in a smaller database well to that end spark gives us spark sql it's a relational engine built on top of spark as a starting point we'll have a few new objects that we'll interact with at the spark shell and in our spark applications without spark sql we've just used the spark context well now we'll have the cassandra sql context the sql context and the hive context to play around with we're also going to introduce a very important new abstraction the data frame we'll dig into those in a little bit of detail ultimately though we're going to be able to produce structured sql queries just like we would have in a smaller database let's take a look at the basics the cassandra sql context is the entry point we're going to use in most of our examples it's another native object available to us in the spark shell instead of being called sc it's called csc and on the slide there there's a little bit of a standalone application that you can look at where we create a cassandra sql context in addition to the spark context that we would have had if we weren't using spark sql likewise that hive context object called hc in the spark shell that's available to you in the data stacks enterprise spark shell if you need to execute any hive ql queries you can use that guy and again there's code here that shows you how you would instantiate one of those in a standalone spark application we're not going to spend a bunch of time with hive context we're going to be focusing on the cassandra sql context but this is here in case you need it now i mentioned data frames as a new programming abstraction in spark sql you can think of a data frame like an rdd that has named columns so it's like if you took a relational database table and an rdd and merged them together you'd get a data frame so it's a lot like a table it has schema it has rows it has columns with names and data types like an rdd it's distributed and spark manages where it lives and how computation is distributed over it you can see on the slide here we actually create a data frame by calling the sql method on the cassandra spark context object passing in a simple query we haven't really gone over any of this but you can see trivially that's executing a query and getting some results back and those results come back in terms of this data frame type and if you look at the output there you can see it's a collection of column names and data types clearly we'll dig into that api a bit more as we move through this module a bit more explicitly here is how to execute a straight sql query on the cassandra sql context object simply pass the string in and there we're done now that's going to return a data frame we're calling a method called show we'll look at that in its particulars later on but show is just going to print out in tabular form the results of the query that's just one example of an action we can call on a data frame object analogous to an action that you call on an rdd they really do have a lot of similarities now here's what we're calling a language integrated query you might by looking at the code think language integrated as a euphemism for difficult but really it isn't this is using the api of the cassandra sql context to express the same query that we had expressed in just raw sql before on the cassandra sql context object we call the read method which tells us that we're going to create a data frame and then we specify the format of that data frame we're saying this is going to be a query from a cassandra table by passing in the class that you see in that third line there then we pass it some options which really are just the key space in the table it ends up being a select star from that table and then we load the results in and then having created that data frame we can do some other things to it we can effectively apply the filter transformation which is like a where clause on a sql query then an aggregation transformation we're asking to count everything and just returning that count as the result finally calling the show action like we saw in the slide earlier printing out that results so for this example this looks like a much more painful way of doing something that was so easily expressed in cql just a little bit ago but there will be cases where we're really glad we have this api and we're able to program data frames directly this way and if you had a hive ql query you wanted to execute you'd do it this way on the hc object in this case it looks just like sql just like cql so no big surprises here but the api for the hc object is very similar",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.399,
        "duration": 2.561,
        "text": "now once you get going"
      },
      {
        "start": 7.44,
        "duration": 3.279,
        "text": "using spark with cassandra and you"
      },
      {
        "start": 8.96,
        "duration": 2.719,
        "text": "really get to know the rdd api and you"
      },
      {
        "start": 10.719,
        "duration": 2.641,
        "text": "become productive"
      },
      {
        "start": 11.679,
        "duration": 3.201,
        "text": "it might occur to you that you're doing"
      },
      {
        "start": 13.36,
        "duration": 2.56,
        "text": "a lot of the kinds of things that you"
      },
      {
        "start": 14.88,
        "duration": 3.76,
        "text": "might have done"
      },
      {
        "start": 15.92,
        "duration": 3.199,
        "text": "in sql in a smaller database well to"
      },
      {
        "start": 18.64,
        "duration": 2.639,
        "text": "that end"
      },
      {
        "start": 19.119,
        "duration": 3.121,
        "text": "spark gives us spark sql it's a"
      },
      {
        "start": 21.279,
        "duration": 2.881,
        "text": "relational engine"
      },
      {
        "start": 22.24,
        "duration": 3.44,
        "text": "built on top of spark as a starting"
      },
      {
        "start": 24.16,
        "duration": 3.199,
        "text": "point we'll have a few new objects that"
      },
      {
        "start": 25.68,
        "duration": 3.999,
        "text": "we'll interact with at the spark shell"
      },
      {
        "start": 27.359,
        "duration": 4.08,
        "text": "and in our spark applications without"
      },
      {
        "start": 29.679,
        "duration": 2.88,
        "text": "spark sql we've just used the spark"
      },
      {
        "start": 31.439,
        "duration": 2.721,
        "text": "context well now we'll have the"
      },
      {
        "start": 32.559,
        "duration": 4.16,
        "text": "cassandra sql context"
      },
      {
        "start": 34.16,
        "duration": 3.44,
        "text": "the sql context and the hive context to"
      },
      {
        "start": 36.719,
        "duration": 2.321,
        "text": "play around with"
      },
      {
        "start": 37.6,
        "duration": 3.68,
        "text": "we're also going to introduce a very"
      },
      {
        "start": 39.04,
        "duration": 3.76,
        "text": "important new abstraction the data frame"
      },
      {
        "start": 41.28,
        "duration": 2.959,
        "text": "we'll dig into those in a little bit of"
      },
      {
        "start": 42.8,
        "duration": 2.16,
        "text": "detail ultimately though we're going to"
      },
      {
        "start": 44.239,
        "duration": 3.041,
        "text": "be able to produce"
      },
      {
        "start": 44.96,
        "duration": 4.16,
        "text": "structured sql queries just like we"
      },
      {
        "start": 47.28,
        "duration": 3.439,
        "text": "would have in a smaller database"
      },
      {
        "start": 49.12,
        "duration": 3.439,
        "text": "let's take a look at the basics the"
      },
      {
        "start": 50.719,
        "duration": 2.881,
        "text": "cassandra sql context is the entry point"
      },
      {
        "start": 52.559,
        "duration": 3.441,
        "text": "we're going to use in"
      },
      {
        "start": 53.6,
        "duration": 3.84,
        "text": "most of our examples it's another native"
      },
      {
        "start": 56.0,
        "duration": 1.84,
        "text": "object available to us in the spark"
      },
      {
        "start": 57.44,
        "duration": 2.08,
        "text": "shell"
      },
      {
        "start": 57.84,
        "duration": 3.84,
        "text": "instead of being called sc it's called"
      },
      {
        "start": 59.52,
        "duration": 4.0,
        "text": "csc and on the slide there there's a"
      },
      {
        "start": 61.68,
        "duration": 3.519,
        "text": "little bit of a standalone application"
      },
      {
        "start": 63.52,
        "duration": 4.16,
        "text": "that you can look at where we create"
      },
      {
        "start": 65.199,
        "duration": 3.6,
        "text": "a cassandra sql context in addition to"
      },
      {
        "start": 67.68,
        "duration": 2.479,
        "text": "the spark context"
      },
      {
        "start": 68.799,
        "duration": 3.201,
        "text": "that we would have had if we weren't"
      },
      {
        "start": 70.159,
        "duration": 4.401,
        "text": "using spark sql likewise that"
      },
      {
        "start": 72.0,
        "duration": 4.32,
        "text": "hive context object called hc in the"
      },
      {
        "start": 74.56,
        "duration": 3.599,
        "text": "spark shell that's available to you in"
      },
      {
        "start": 76.32,
        "duration": 3.76,
        "text": "the data stacks enterprise spark shell"
      },
      {
        "start": 78.159,
        "duration": 3.681,
        "text": "if you need to execute any hive ql"
      },
      {
        "start": 80.08,
        "duration": 3.039,
        "text": "queries you can use that guy"
      },
      {
        "start": 81.84,
        "duration": 2.72,
        "text": "and again there's code here that shows"
      },
      {
        "start": 83.119,
        "duration": 2.081,
        "text": "you how you would instantiate one of"
      },
      {
        "start": 84.56,
        "duration": 2.8,
        "text": "those"
      },
      {
        "start": 85.2,
        "duration": 3.52,
        "text": "in a standalone spark application we're"
      },
      {
        "start": 87.36,
        "duration": 3.04,
        "text": "not going to spend a bunch of time with"
      },
      {
        "start": 88.72,
        "duration": 2.16,
        "text": "hive context we're going to be focusing"
      },
      {
        "start": 90.4,
        "duration": 2.24,
        "text": "on"
      },
      {
        "start": 90.88,
        "duration": 3.279,
        "text": "the cassandra sql context but this is"
      },
      {
        "start": 92.64,
        "duration": 2.4,
        "text": "here in case you need it now i mentioned"
      },
      {
        "start": 94.159,
        "duration": 3.761,
        "text": "data frames as"
      },
      {
        "start": 95.04,
        "duration": 3.52,
        "text": "a new programming abstraction in spark"
      },
      {
        "start": 97.92,
        "duration": 2.48,
        "text": "sql"
      },
      {
        "start": 98.56,
        "duration": 3.04,
        "text": "you can think of a data frame like an"
      },
      {
        "start": 100.4,
        "duration": 3.44,
        "text": "rdd that has"
      },
      {
        "start": 101.6,
        "duration": 3.6,
        "text": "named columns so it's like if you took a"
      },
      {
        "start": 103.84,
        "duration": 3.599,
        "text": "relational database table"
      },
      {
        "start": 105.2,
        "duration": 3.599,
        "text": "and an rdd and merged them together"
      },
      {
        "start": 107.439,
        "duration": 4.561,
        "text": "you'd get a data frame"
      },
      {
        "start": 108.799,
        "duration": 3.761,
        "text": "so it's a lot like a table it has schema"
      },
      {
        "start": 112.0,
        "duration": 3.68,
        "text": "it has"
      },
      {
        "start": 112.56,
        "duration": 3.68,
        "text": "rows it has columns with names and data"
      },
      {
        "start": 115.68,
        "duration": 2.479,
        "text": "types"
      },
      {
        "start": 116.24,
        "duration": 3.28,
        "text": "like an rdd it's distributed and spark"
      },
      {
        "start": 118.159,
        "duration": 3.28,
        "text": "manages where it lives"
      },
      {
        "start": 119.52,
        "duration": 3.44,
        "text": "and how computation is distributed over"
      },
      {
        "start": 121.439,
        "duration": 3.36,
        "text": "it you can see on the slide here we"
      },
      {
        "start": 122.96,
        "duration": 3.68,
        "text": "actually create a data frame by calling"
      },
      {
        "start": 124.799,
        "duration": 2.64,
        "text": "the sql method on the cassandra spark"
      },
      {
        "start": 126.64,
        "duration": 2.88,
        "text": "context"
      },
      {
        "start": 127.439,
        "duration": 3.52,
        "text": "object passing in a simple query we"
      },
      {
        "start": 129.52,
        "duration": 3.359,
        "text": "haven't really gone over any of this but"
      },
      {
        "start": 130.959,
        "duration": 3.28,
        "text": "you can see trivially that's executing a"
      },
      {
        "start": 132.879,
        "duration": 3.201,
        "text": "query and getting some results back and"
      },
      {
        "start": 134.239,
        "duration": 3.36,
        "text": "those results come back in terms of this"
      },
      {
        "start": 136.08,
        "duration": 3.2,
        "text": "data frame type and if you look at the"
      },
      {
        "start": 137.599,
        "duration": 3.36,
        "text": "output there you can see it's a"
      },
      {
        "start": 139.28,
        "duration": 3.52,
        "text": "collection of column names"
      },
      {
        "start": 140.959,
        "duration": 3.041,
        "text": "and data types clearly we'll dig into"
      },
      {
        "start": 142.8,
        "duration": 3.36,
        "text": "that api a bit more"
      },
      {
        "start": 144.0,
        "duration": 3.12,
        "text": "as we move through this module a bit"
      },
      {
        "start": 146.16,
        "duration": 3.28,
        "text": "more explicitly"
      },
      {
        "start": 147.12,
        "duration": 4.32,
        "text": "here is how to execute a straight sql"
      },
      {
        "start": 149.44,
        "duration": 2.72,
        "text": "query on the cassandra sql context"
      },
      {
        "start": 151.44,
        "duration": 3.04,
        "text": "object"
      },
      {
        "start": 152.16,
        "duration": 4.24,
        "text": "simply pass the string in and there"
      },
      {
        "start": 154.48,
        "duration": 3.6,
        "text": "we're done now that's going to return"
      },
      {
        "start": 156.4,
        "duration": 3.6,
        "text": "a data frame we're calling a method"
      },
      {
        "start": 158.08,
        "duration": 3.04,
        "text": "called show we'll look at that in its"
      },
      {
        "start": 160.0,
        "duration": 2.48,
        "text": "particulars later on"
      },
      {
        "start": 161.12,
        "duration": 3.28,
        "text": "but show is just going to print out in"
      },
      {
        "start": 162.48,
        "duration": 3.44,
        "text": "tabular form the results of the query"
      },
      {
        "start": 164.4,
        "duration": 3.36,
        "text": "that's just one example of an action we"
      },
      {
        "start": 165.92,
        "duration": 3.92,
        "text": "can call on a data frame object"
      },
      {
        "start": 167.76,
        "duration": 3.759,
        "text": "analogous to an action that you call on"
      },
      {
        "start": 169.84,
        "duration": 2.96,
        "text": "an rdd they really do have a lot of"
      },
      {
        "start": 171.519,
        "duration": 2.481,
        "text": "similarities now here's what we're"
      },
      {
        "start": 172.8,
        "duration": 3.68,
        "text": "calling a language"
      },
      {
        "start": 174.0,
        "duration": 3.12,
        "text": "integrated query you might by looking at"
      },
      {
        "start": 176.48,
        "duration": 2.479,
        "text": "the code"
      },
      {
        "start": 177.12,
        "duration": 3.839,
        "text": "think language integrated as a euphemism"
      },
      {
        "start": 178.959,
        "duration": 4.321,
        "text": "for difficult but really it isn't"
      },
      {
        "start": 180.959,
        "duration": 3.36,
        "text": "this is using the api of the cassandra"
      },
      {
        "start": 183.28,
        "duration": 3.36,
        "text": "sql context"
      },
      {
        "start": 184.319,
        "duration": 3.121,
        "text": "to express the same query that we had"
      },
      {
        "start": 186.64,
        "duration": 3.599,
        "text": "expressed"
      },
      {
        "start": 187.44,
        "duration": 4.96,
        "text": "in just raw sql before on the cassandra"
      },
      {
        "start": 190.239,
        "duration": 2.881,
        "text": "sql context object we call the read"
      },
      {
        "start": 192.4,
        "duration": 2.0,
        "text": "method"
      },
      {
        "start": 193.12,
        "duration": 3.68,
        "text": "which tells us that we're going to"
      },
      {
        "start": 194.4,
        "duration": 3.68,
        "text": "create a data frame and then we specify"
      },
      {
        "start": 196.8,
        "duration": 2.56,
        "text": "the format of that data frame we're"
      },
      {
        "start": 198.08,
        "duration": 3.68,
        "text": "saying this is going to be a query"
      },
      {
        "start": 199.36,
        "duration": 4.159,
        "text": "from a cassandra table by passing in the"
      },
      {
        "start": 201.76,
        "duration": 2.16,
        "text": "class that you see in that third line"
      },
      {
        "start": 203.519,
        "duration": 2.0,
        "text": "there"
      },
      {
        "start": 203.92,
        "duration": 2.959,
        "text": "then we pass it some options which"
      },
      {
        "start": 205.519,
        "duration": 2.0,
        "text": "really are just the key space in the"
      },
      {
        "start": 206.879,
        "duration": 2.561,
        "text": "table"
      },
      {
        "start": 207.519,
        "duration": 3.44,
        "text": "it ends up being a select star from that"
      },
      {
        "start": 209.44,
        "duration": 3.359,
        "text": "table and then we load"
      },
      {
        "start": 210.959,
        "duration": 3.681,
        "text": "the results in and then having created"
      },
      {
        "start": 212.799,
        "duration": 3.601,
        "text": "that data frame we can do some other"
      },
      {
        "start": 214.64,
        "duration": 4.0,
        "text": "things to it we can effectively apply"
      },
      {
        "start": 216.4,
        "duration": 3.36,
        "text": "the filter transformation which is like"
      },
      {
        "start": 218.64,
        "duration": 3.36,
        "text": "a where clause"
      },
      {
        "start": 219.76,
        "duration": 3.039,
        "text": "on a sql query then an aggregation"
      },
      {
        "start": 222.0,
        "duration": 3.28,
        "text": "transformation"
      },
      {
        "start": 222.799,
        "duration": 3.52,
        "text": "we're asking to count everything and"
      },
      {
        "start": 225.28,
        "duration": 3.2,
        "text": "just returning"
      },
      {
        "start": 226.319,
        "duration": 3.361,
        "text": "that count as the result finally calling"
      },
      {
        "start": 228.48,
        "duration": 3.36,
        "text": "the show action"
      },
      {
        "start": 229.68,
        "duration": 3.68,
        "text": "like we saw in the slide earlier"
      },
      {
        "start": 231.84,
        "duration": 2.959,
        "text": "printing out that results so for this"
      },
      {
        "start": 233.36,
        "duration": 2.64,
        "text": "example this looks like a much more"
      },
      {
        "start": 234.799,
        "duration": 2.401,
        "text": "painful way of doing something that was"
      },
      {
        "start": 236.0,
        "duration": 3.519,
        "text": "so easily expressed"
      },
      {
        "start": 237.2,
        "duration": 4.0,
        "text": "in cql just a little bit ago but there"
      },
      {
        "start": 239.519,
        "duration": 2.881,
        "text": "will be cases where we're really glad we"
      },
      {
        "start": 241.2,
        "duration": 3.2,
        "text": "have this api"
      },
      {
        "start": 242.4,
        "duration": 3.039,
        "text": "and we're able to program data frames"
      },
      {
        "start": 244.4,
        "duration": 2.64,
        "text": "directly this way"
      },
      {
        "start": 245.439,
        "duration": 3.201,
        "text": "and if you had a hive ql query you"
      },
      {
        "start": 247.04,
        "duration": 2.399,
        "text": "wanted to execute you'd do it this way"
      },
      {
        "start": 248.64,
        "duration": 2.56,
        "text": "on the hc"
      },
      {
        "start": 249.439,
        "duration": 3.36,
        "text": "object in this case it looks just like"
      },
      {
        "start": 251.2,
        "duration": 4.319,
        "text": "sql just like cql"
      },
      {
        "start": 252.799,
        "duration": 3.761,
        "text": "so no big surprises here but the api for"
      },
      {
        "start": 255.519,
        "duration": 10.081,
        "text": "the hc"
      },
      {
        "start": 256.56,
        "duration": 9.04,
        "text": "object is very similar"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:16:23.596543+00:00"
}