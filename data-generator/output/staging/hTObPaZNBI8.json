{
  "video_id": "hTObPaZNBI8",
  "title": "Application Development Bootcamp Week I: NoSQL Databases for Beginners",
  "description": "Please find below links that could be useful to you during the session (expand)ðŸ‘‡\n\nWelcome to Week 1 of our Application Development Workshop series!\n\nIf youâ€™re new to the world of NoSQL and havenâ€™t used Cassandra before, you can expect to leave our 2-hour introductory session with your own database running in the cloud along with an understanding of data modeling principles.\n\n- Discover what NoSQL is and what it can do\n- Learn the fundamental NoSQL concepts with Apache Cassandra\n- Get hands-on with NoSQL data modeling concepts\n- Set up your own NoSQL database\n\nðŸ’¬ DISCORD - chat, questions\nhttps://dtsx.io/discord\n\nðŸ“š GITHUB  - materials\nhttps://github.com/datastaxdevs/workshop-cassandra-fundamentals\n\nREGISTER for ASTRADB\nhttps://astra.dev/yt-01-11-23\n\nðŸ“… UPCOMING EVENTS\nhttps://www.datastax.com/workshops\n\nðŸš€ ðŸš€ ENJOY !! ðŸš€ ðŸš€",
  "published_at": "2023-01-11T19:04:58Z",
  "thumbnail": "https://i.ytimg.com/vi/hTObPaZNBI8/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "nosql_database",
    "workshop",
    "data_modeling",
    "cassandra",
    "database",
    "apache_cassandra",
    "nosql",
    "astra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=hTObPaZNBI8",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] thank you [Music] foreign [Music] foreign [Music] [Music] thank you [Music] thank you [Music] foreign [Music] foreign [Music] foreign [Music] foreign [Music] foreign [Music] hey one two three one two three if you can hear us if you can see us please set the thumbs up in the YouTube chat so we know we can start we hello everyone yep hi hi Tom hi Alex that's yeah looks like we are good at hi pravajal uh prajaval sorry Laura hi Billy Alessandro perfect perfect many people many dozens of people actually today with us that is amazing cool skit so looks like we are good so with that I want to start immediately because we have so I have a lot of topics yeah so many topics to cover we want it to be very intensive you came to learn so let's go with that right now uh that is the first Workshop in boot camp application development series which will consist of free workshops first one is today I hope you watch it live if you watch it recorded no big deal then um because we you still can get everything from this boot camp um some more links coming soon so you can stay in touch with us first Workshop we want to focus on nosql databases or to be more particular on one specific nosql database call it Apache Cassandra uh it's one of the most powerful and scalable databases in the world used by few just companies we will discuss it soon so that one really helps you to build a high growth High scale Global applications available from customer for customers from all around the world second Workshop will be about data modeling today with me and then at the next week you see artwork PhD who developed data modeling methodology for nosql databases so how do you build data model for applications this way so your applications will be efficient we'll stay efficient under any workloads even working with hundreds millions of customers and then at the third Workshop we put it all together with the database with the proper data model with applications and make it a real life running application deployed and see it in progress and you can pick language of your choice so I believe most of you familiar with python Java or JavaScript and you can pick a language of your choice of this list so let's go uh I'm developer Advocate lead at data Stacks Alex Volusia my job is to help developers not fail with Advanced distributed Technologies like Apache Cassandra and you will meet me multiple times during this boot camp today with me uh could you please introduce yourself yes sure hi everyone I'm glad to be here so um I have 10 years experience of working with Cassandra and I like uh like Alex mentioned already I authored the Cassandra data modern methodology we're gonna talk about it next week this week I'm helping with the Hands-On and a couple of sessions related to um capsirium and some other stuff cool so uh but this session is not about us so let's move on a little bit of explanation we believe in Hands-On practical education we don't believe in just the boring theory that means what you will need to push some buttons it's all free and available for everyone as all the software we are using will be running in a cloud so you can do it basically with whatever laptop or PC you have everything all the materials for The Bootcamp is available on GitHub it's all open source you can use it in any moment send it to your friend whatever then uh to uh develop it and to run it to make it operational we will use gitbot gitbot is a great platform so you can develop code right in your browser and you don't have to install ID you don't have to run it locally so it's like I really love it and it helps developers a lot and then finally to avoid deploying Cassandra clusters and running everything on your own machine which well software we are going to run is quite demanding in the points of resources points of view we will be using astrodb astrodb is a budget Cassandra in the cloud it has very generous free tier so again it's free you don't pay anything for that and we will use multiple features of Apache Cassandra if you are already familiar with this database you can deploy it locally and do all the same exercises but to simplify maintenance and our help to you during the workshop we will be using Cloud deployment this Workshop you know is developers focused not operations Focus um if you complete for each Workshop of this series you complete you can get a special page to break on LinkedIn or Facebook or whatever social network you use if you would like to get some acknowledgments some achievements then that is totally possible to do that you will need to do two things first uh first watch these Workshop live or recorded this and all the follow-up workshops and second complete the Hands-On part you can do it with artem during this Workshop or after that on your own free time later it's also supported by us and submit this as a homework more details coming in the end of the workshop and with that I want to ask few questions about you we will use medium and mentee is a platform for us to ask questions to you and you can answer life to join our quiz please scan the QR code or you see on the screen or just go to mentee.com and enter the code again you see on the screen easiest way and the most recommended way to do it is just to use your mobile phone it's uh like the most convenient way to use the main team but I see people are joining so let's start I don't want to wait for too long uh first question I want to know how experienced you are so what's your experience with relational databases okay so we see people of different experience very well if you didn't join yet you can see instructions on top of the screen go to manchester.com and use the code 6291-8600 we will ask questions during the workshop so you better please join okay I see with us some software developers mostly probably and I guess some students if you have no experience with relational databases this one might be a little bit rough right because well no SQL databases experience often base it on SQL databases experience right but still keep learning keep doing even if you are now just Zero by the end of this series you will have running application and you will get better understanding of how database and nosql databases work don't hesitate to ask questions on the YouTube chat or on Discord versus Cedric will event to answer questions and we will do our best to answer those questions as well now next question do you already have experience with any nosql databases okay so I see some people get some experience that is good if you have no experience then congratulations because you are right in the right place to be to learn something nosql world is great and very interesting many powerful and interesting Technologies and today I will we will introduce you one of the best of them uh for the Discord link I will send you a link the ps6 record and https that is a link to our Discord server and homework it's explained at the GitHub repository link posted by nightbot just a couple of messages above GitHub data Stacks devs Workshop yep thank you Cedric good so very well uh welcome you are on the right place to be right now then finally where are you now like it's very curious from how many countries we have people that the same Workshop but how Global is our world isn't that amazing okay looks like someone is on the ship uh have a good uh travel uh some people from Europe I see UK I see Africa amazing I see United States of course pretty much expected a lot uh people from India Africa again cool any Australians Australians must be sleeping right now okay okay it's deep night oh not Auckland California not too far from data Stacks headquarters welcome welcome uh cool so very well and then final question database you use the most or maybe if you're a student the only database you know so far also will work to me hey Aaron uh Aeron plots is in the chat he is one of the best in Cassandra experts and I'm adding him as a moderator by the way beware good also so MySQL Oracle pretty much expected well well well well good postgres again oh there are some people using Cassandra already nice I see Dynamite beam well so there is a quite plenty of different databases MySQL stays number one so far uh with some value uh significant part of and that is great uh the most funniest part about nosql is what it's actually pretty bad definition because it tries to group very different databases mongodb is a great database I was using for use and I like it and uh Cassandra is a great database I love it and I use it also for many years but there's a totally different we shouldn't group together I know submarines and spaceships those are different for different purposes today those if you use already you will be introduced to your second nosql database and that is great oh I see people working with teradata interesting good so with that beginning ends and we will proceed to the next part um quick introduction how to use or how it works internally I'm focusing on the question how it works internally because you know what I want you to be software Engineers not just people pushing red button if red light is blinking okay I need you to get some internal understanding that What Makes Us Engineers so today we speak a lot about how it works internally and of course we also work with how to use that for sure you need to know how to use that but that will be mostly for the third Workshop today I want to get to the internals I'm just curious if in the chat people can answer whether they came to learn how to use it or how to uh how it works internally it's one or two uh you want me to switch to a previous slide sure okay sure it would be nice feedback from attendees if if they can so they like both that works internally yeah actually both are important but I see now many students rushing to use without willingness to get understanding of the um under the hood Parts but it's very important to understand how it works internally you know how to use like we can train a monkey in the advanced or question how to use but how it works internally that is something what makes engineer yeah so thank you so much for your answer yes we need to take care of both that is good that's a good answer right yeah same again okay so let's move on um we now going to speak about why Cassandra but that's not why because why you should use Cassandra no no marketing no selling beaches no no no no no I want to answer a question first why Cassandra was developed or invented if you prefer my point here is um it's very important to understand the reasons of the Technologies happen to be because to build successful projects we all even they are not Architects just developers um junior or even maybe developers we all need to think architecturally think as an architect and to get that we need to understand the reasons and internals and whys of how these or very technology works so here I'm going to answer a question why Cassandra was invented or developed and to answer this question we are going to get my time machine my DeLorean and jump back to year 2008. not so long time ago just 14 years ago 15 technically already has 15 good so the story started in the year 2008 then Facebook reached their first 100 million users and that is a very big number now there are plenty of companies with discount of customers maybe even more people using that but I believe Facebook was the very first one to reach this number and that wasn't just a very very big number but more problems actually came to a place to solve and I would first mention four of them users all around the world before most of the businesses were all completely local or Regional or at least we were running as branches with not a lot of cooperation in between by these years already they were truly global companies for example Facebook second thing and that is a pretty big thing fast internet connection now in year 2023 people start to think like okay everyone hasn't we take it as given okay fast internet connection everyone has it uh but that time it was a game changer beforehand your database wasn't a bottleneck doesn't matter how fast your database if a Last Mile internet connection from internet service provider to your customer will be slow anyway you don't need fast database it's okay he will wait anyway and now we fast internet connections database started to be uh bottleneck so it changed a lot now then a lot of data more and more datum that the volume would never was uh in action before and and finally with all of these also new availability requirements came if you ever heard about SLA service level agreement service level agreement means of how many or how fast your data how fast your application should be or what this should be uh uptime desire it for your application when it must be available and those slas for the performance for like how can we responds should be they also started to get more and more strict and uh scaling applications is a known problem and that is a solvable problem but by that time real problem was scaling of a database so wherever no database like that we were looking for a better database and there were no way to get something like that um that what led to a creation of a new database we are going to use today but before developing a new product as we have to think as Architects even when we aren't we still need to think architecturally we need to Define requirements because without requirements you are not going to build any successful projects first you define requirements and then based on these requirements you make architectural decisions so let's first talk about what requirements do we put on our database management system first we speak about globally distributed system with our customers all around the world single region deployment is no goal for us I mean however fast even if your database magically fast but it's deployed in Australia and you are located near Frankfurt you're going to wait for quite some time you know we cannot beat light of speed uh speed of light yet maybe in the future so we need to keep our database and our applications close to our customers even if they are in the Brazil or maybe I don't know Japan or any region doesn't matter our database needs to be closed second we are going to speak of volume and velocity we are going to handle data of any size and by any size I mean petabytes of data and also millions of queries per second so we are developing a highly intensive application what's in use by hundreds millions of customers well we need it to be very fast we have very strict requirements on response time basically response must be newly immediate and then finally we have very strict service level agreement on high availability that means what our database must be available most of the time if you are familiar with knights so-called definition of how many how much time your database or application must stay online we usually speak about 4 9 so 99.99 persons it's called four nines maybe five nines 99.99 persons of a time and so on so requirements are going to be very strict maybe six nines maybe even more it's actually like few seconds per year we can afford a downtime that benefit of these requirements we start to speak about architectural decisions we are making on that so we speak about geographical replication and we need our data to be present everywhere that means we will need to have multiple data centers in different regions one one data center maybe in the United States maybe even two on different costs uh data center in the South America data center in Europe data send a couple of data centers in Asia and so on and so forth and moreover if you're familiar with relational databases you know they can support multi-dc deployments but that is very typical for them to have active passive so you have one single active Data Center where you can read and write data and multiple one or more passive data centers where you can read data but cannot write it in our case we need to overwrite data as fast as we read the two so that means again what we will need active active data centers all around the world that is not easy people like that's not easy at all then for volume we are going to have a lot of data and we are going to have millions of queries per second what that will be our architectural decision based on that we have no other choice to split uh them our data in the chunks the story is working with relational databases you have your data all stored on a single server there must be there can be leader follower architecture with multiple servers but still each one of them stores all the data you have and you know what that's great that's very convenient really but that doesn't work with big data then you have petabytes of data of hundreds millions of customers there is no server in the Earth on the earth what could handle such volume and still be capable of responding very quickly so we will have to split our data into multiple chunks or we will call that partitions and keep different partitions or different servers that helps us to put the to spread the workload spread the queries over multiple servers so we can handle more then for service level agreement for time we will need to use two things first to keep our database quick for response we will need to use generalization normalization denormalization will be more discussed on the second Workshop so today it will be just like a very brief introduction and when we as we partitioned our data and we may have a lot of partitions over thousand servers we need uh to root our queries to exact the servers storing our data we discussed it very soon today during these Workshop and then finally for service level agreement on high availability requirements we are going to use two more Technologies for replication and death centralization what replication means replication means what as long as you have as long as you have your data single piece on your data just once on a single server as soon as the square server is down this piece of data cannot be accessed anymore and you have down time replication means what we copy this piece of data under multiple servers and if one of them is not uh is one of them is down we still can fetch this information from another servers that is a replication obviously replication means to a higher disk space consumption but let's say big companies can afford that okay then that centralization is our idea we don't want to follow follow a leader follower architecture when you write to your leader or Master server and read from replica's follower replicants we don't want it that's a traditional database architecture but that's fragile as soon as leader is down you cannot write your application is not operational no go so replication in debt centralization so we discussed with the customer requirements we discussed the situation many customers around the world fast internet a lot of data we defined our requirements and we discussed our architectural decisions um and that leads us to a problem in the world of the databases in the law in the in any field basically there is no Silver Bullet one size fits all maybe no you uh we do we need more sport cars or tracks trucks we need both okay for different purposes uh when very many thousands years before hundreds thousands years before each person each human being was a hunter hunter gatherer I don't know firmer whatever Warrior is required all the things together but over time we as Humanity we developed specializations why because specializations are more efficient basically exactly the same is happening with databases on the database field from a generalization from multipurpose general purpose databases we go more and more into specialized Solutions because the problem is if you want to have it all all those multiple active disease partitional data their normalized replica replicated decentralizer get back here there is no database like that or there were no database like that at all and you know in 2008 there were plenty of great databases like postgres for example postgres is great but it's more multi-purpose and we need something more specialized well Alex to be fair big table existed at that time but yeah okay it was not available to Facebook uh uh Solutions database Solutions what are based on the same white paper and uh share the same concepts for example we can mention Google uh bigtable or Amazon Dynamics they are good databases so I don't want to say anything bad about those they have one limitation they both share the same limitation you really need to understand they are proprietary vendor login database so if for example you run your application on Google and you stick to Google big table that is a great one it will work well but if for any reason you are not happy with Google and you want to migrate to Amazon or you want to migrate to your own cloud to your own data center you will have to rework half of your application basically that is a very important story uh part of a story to me so yes a big table was present it's I believe like from 2005 maybe was available right I don't remember exactly but um it's a proprietary database well I don't know about you guys but I'm a big fan of Open Source things and I see there is a question about the slides uh slides are available and they must be way much present and the GitHub repository and James Wong asks uh will we stream live will we stream available on YouTube channel later answer is yes the same link oh thank you said we so uh and uh my point on this way from generalization to specialization um there are two sides on this field ltp kind of workloads and or love kind of workloads what is that about so see oil TB stands for online transaction processing uh it's usually customer facing databases with a lot of operations per second and very strict service level agreements um and that is very specialization like they have to be all the time up serving a lot of queries very very quickly that is very specialization another side of this field opposite side of this field is pull up type of workloads olap stands for online analytical processing and that is a very different kind of workload that's usually about data exploration that is usually about like analysis of your data a lot of data very often historical so-called call data and very often it includes some kind of a very complex queries to run like with dozens of joins let's find all the customers who have bought car tires last year but did not vote any kind of I don't know laptops for previews here and then they've bought car tires it was rainy and if they are younger than 30 years old but older than 15 years old and so on and so forth like with dozens of joints with very different aspects the classic example in that field is the the question that was asked for like grocery stores with tailors find the fathers who bought diapers and beer at the same time on the same trip so essentially what would help what would Place beer and diapers in the same old same section or nearby so that customers can find uh those items yep uh so and the story of this is um you cannot be simultaneously on the both sides with a single project so uh most of the relational databases they are more multi-purpose they're trying to stay in between and that brings us to a problem Jack of all trains must drop known so they can try to get into OTP processing but they are not perfect in it they're trying to get to a lab a side of the things but again there are much better Solutions what are specialized for Analytics and that's why that was the reason why a relational databases were dominating databases market for those and spheres they are versatile they can be a little bit on each side of the field but if you need to have more if you really need to have petabytes over multiple regions answering 15 single digit milliseconds you need to sacrifice something what is the simplification idea is very simple the more you get to the right side of the field better you are on olap but worse you are in oil tipping and opposite the more you get to the left side of a thing better you are on Fast dispatching millions of queries but not as good in search capabilities and analytics capabilities for example it all comes with a price right so um what uh World desperately needed there was an open source distribute and decentralized oil TP database customer facing database with the ability to have uh in press to have to have a presence basically everywhere in all the regions uh answer all the questions very quickly and we are ready to pay for it sacrificing some of the alarm capabilities of the databases what is it now so AdWords or all the story about Cassandra what is Cassandra today now Cassandra is used basically by all or almost all of the future transnational corporations uh biggest Cassandra users include uh Apple Huawei Netflix Instagram IBM and many many many many many hours basically you all use Cassandra even if you don't know it all the global companies are using Cassandra or at least it's a proprietary idea a proprietary to implemented Solutions of the same style um Cassandra scale what Apple uses is at apachecon here 2022 last year so Apple reported what may have over 300 000 database servers for Apache Cassandra they store hundreds petabytes of data and they dispatch millions of queries per second with Cassandra uh when my favorite example of Cassandra usage is actually in Netflix probably with apple is what Apple doesn't tell us a lot about how they use that um it's secret you know but Netflix is much more friendly and much more open to us so Netflix shares a lot of rare details on how do we use Cassandra uh regularly and Cassandra is the primary database for Netflix so when Netflix of course uses multiple different databases but Cassandra is definitely primary uh they single most active cluster and they have multiple clusters handles 30 Millions operations per second reads and writes and uh overall they have hundreds thousands of clusters hundreds or thousands of clusters by now I believe again hundreds petabytes of data if you're more interested in how Netflix uh uses Apache Cassandra you can follow this link dts6.io Cassandra at Netflix is there a talk what uh was done by Cloud database architect uh marchella at the last Cassandra de India I recorded this one so question oops first real question speech momentum and tell me Cassandra is better fit four all up workloads oltp workloads or both types of workloads let's see who paid attention that is actually a little bit tricky question I will explain when you will answer don't be afraid to make mistakes you better answer using main team so your vote will count so yeah there is a tricky question Cassandra was designed to be much more on ltp side of the things that is for sure but there are some kinds of lab workloads what also can be answered for Cassandra if it doesn't include a lot of joints for example and then you just want to see a Time series data of what it is temperature change in particular region of a particular temperature sensor storage in Cassandra then you can see this data easily yes that kind of works but that is a very limited site very small part of what's happening on the lab side of world Cassandra was designed to be oltp database and there is no simple solution to answer both type of workloads because there are no silver bullets in the software development in anyone anyone comes to you and says like hey you should try this database it's just the best don't try this person he's going to tell you something idea is uh there is it's just not possible what is better a submarine or airplane that is a stupid question people that is a really stupid question they both are good it just depends so do you have to type in a c or do you have to fly above the uh Skies like you know you are not going to fly very high in a submarine right but that doesn't make submarine bad you just need to have some specialization okay foreign so what are the features we speak about whatever primary features we speak about Cassandra is built internally first it is partitioning whiskey we split over data we store into multiple different chunks it is very important for us because those chunks can be stored on different servers and if we need to store more data we simply can add more nodes and put those chunks on the multi on Wheels new nodes and we will be good the partitioning is very important don't get me wrong partitioning creates also quite some problems you will see it soon but it helps with scaling that's for sure of course very important thing for us as a oltp database is very high read write performance Cassandra is very well optimized for both writes and reads and it's definitely one of the fastest databases in the world even a single Cassandra node is very performant but as the nodes work together that always helps with read write performance for example one node is slow but your query still will be processed and dispatched sooner with another node which is not slow it down for whatever reason very cool thing like a scalability team but not just scalability um the idea is first Cassandra scales horizontally most of the databases you are familiar with pay scale vertically that means what if your database cannot cope with the workloads you put on it you buy a bigger server migrate your data to a bigger server mostly probably it's a downtime operation so your application will not be available during this time then you launch it again and then what happens next then your new database again cannot cope with this workload you have more and more customers you get more you get another server migrate your data and some vertical scaling means getting more bigger and bigger servers you know what at some point you realize there are no servers bigger than yours and you still get more and more queries from more and more customers vertical scaling has limits and also getting prohibitively expensive very soon Cassandra scales horizontal it means what we don't upgrade our notes but just add more nodes add more servers to a cluster let's call it horizontal scaling or scale out or volume or velocity if you need to process more queries or if you need to process a bigger data or volume you just need to add more nodes but my favorite thing is how exactly it scales the story is for most of the database introducing new servers to a cluster had its overhead it means what each next server will bring you less and less performance and take a look Netflix did a very interesting research some time ago scaling their cluster um from approximately 50 servers to approximately 300 servers and meanwhile measuring workloads and take a look at this nice straight line the story is for most of the databases capable of cleaning this line would get somewhere here much below it wouldn't be straight because each next server adds some overhead and more and more until the situation then every next server gives you nothing and this line basically shows like how Cassandra scales linearly and adding more nodes you get more and more volume and ability to process queries and still get that on time please notice this Mark you know when you read uh contracts I don't know whatever mortgage or loan contracts or job contracts you really need to pay attention to a very small text on the bottom of your document and do marks like that those marks are very important here is the same trigger this scalability works but it's not only Cassandra's job to do it to reach the scalability you need to very well understand how to do your data model right and if you don't do your job it will not work like that so you still have to do your job lucky for you guys that uh inventor developer of data modeling methodology is we fast today and he will be with us next week and next week Workshop is all dedicated to data modeling and how do you do your data model right so your application may work efficiently and your system will scale even handling millions and millions and millions of customers from very different regions hi Alex I would add for this graph so when we talk about scalability we sometimes say okay will it scale from gigabytes to terabytes to petabytes and this is one notion like ability to store large data sets and on this graph we're actually looking at different type of scalability it's It's a throughput high throughput so essentially we measuring how many operations per second can a cluster process and you of course with when we add those nodes we can also store data more and more data on those nodes but also you can see it scales linearly in terms of this throughput and and the big question here is why why do you care about this right yeah so if you expect to build an application that is high growth application that is going to eventually grow and grow and and add more and more users that generate more and more data then you you should care about this because this is going to be a the only way how you're gonna scale you don't want to non-linear scalability you want to scale linearly in this case yep good okay uh yes games of course for reads you see uh yeah a very good point from James Wong that is about client rights uh but point is why we show rights here is scaling for reads is easy scaling for reads you just even in traditional architecture primary server a follower server you just add more follower servers you spread read workloads over multiple servers and you will be good um then uh scaling for right is a real problem because in traditional architecture you cannot just have to master servers or to lead your servers that is a problem yep and um to Adriana I see Cedric answer it already in Cassandra terminology node and server is basically the same it's just synonyms note is the server with Cassandra running on it so simple as that yeah uh load balancing we will explain soon it comes it comes you will see it good next thing highest availability we discussed that already what we want our application to be available all the time first thing we cannot have high availability without replication we need to have a very same data but copy it on multiple different servers and that is a very important thing so the data is placed on different servers on usually on different regions then death centralization that centralization mean version no idea of a master server all servers are the same it's decentralized peer-to-peer architecture RTM will soon say more about that so no single point of failure there is no outage of the leader server uh then Network topology aware data placement so here is a thing like if you do a backup of your laptop disk you will not store this backup on the same disk on your laptop right it makes no sense then if your disk is damaged or I don't know stolen you don't have access to the backup files right if you make a backup you put it to a different place preferably different physical location Cassandra is very smart from Network topology point of view so those different replicas must be first on for obviously on different servers but preferably on different server racks or if we speak Cloud on different availability zones so uh outage of availability zone or outage of a single server rack doesn't lead to outage of all available replicas obviously and then finally cloud a very smart client-side reconnection and retry mechanism so Cassandra drivers mostly developed by data Stacks also very smart and they know how to reconnect how to find different nodes and so on and so forth I see there are some great questions in the chat uh I hope you will have a chance to answer them soon I want to get to a date but first I want to finish this part of them slides now very important five thing for me per person as someone also responsible for operations for some big applications clusters and things operations and maintenance of a huge cluster can be very exhaustive Apache Cassandra clusters are very smart and there are many of operations automated so introducing a new node moving data recovering from inconsistency recovery from outage changing data placement because of some changes very many operations are automated whereas some level of self-healing introduce it and very often we can recover from a bad State uh completely automatically with no manual operations required not always but very often and that like I'm a lazy engineer if I can avoid some work I will avoid this work and then database is doing my work for me I'm totally happy good and well uh geographical distribution already discussed so I don't want to stick on this slide for too long or just one more thing just one thing again openly misunderstood data centers all are active so you can write and read to and from any of the data centers in this case one in United States one in Europe and one in Asia now Fink mentioned it before uh by artem uh Cassandra is a open source platform agnostic so you can run it only on your own data center on Google cloud and Microsoft Azure or Amazon web services simultaneously and all those data centers can build a single cluster so you can survive outage of the wall cloud even if the wall AWS gets down somehow you still will have three data centers here on this example running successfully same data same Data Center good uh and yeah as mentioned it Cassandra is well many people know what data Stacks is like commercial face of Apache Cassandra we could say uh but actually Cassandra does not belong to any commercial lavender Cassandra belongs to and control it by a non-profit open source a bunch of software Foundation which you might know by projects like Apache Kafka zookeeper Maven Hadoop spark and many many others maybe airflow a Vera plenty of different products you may know uh last thing on this part before we will be answering questions yep there is a price to pay you remember before we said what specialization is if it is effective yes but specialization means what you cannot be good in all the things you spend some time becoming a doctor I don't know dentist or whatever cardiologist that mostly probably means what you are not going to be a very good race driver right because your time is dedicated for like biology all the kind of things that relate to human body and so on and you don't have time to become a race driver because it also requires a lot of time and the same with race drivers they're not going to be good doctors most of them right so what are the limitations we are going to encounter very soon first Cassandra's Apache Cassandra supports no joints there cannot be joins between multiple tables so you will see this operating data you need to know the partition case because data is data distribution partitioning is based on the key we show it soon in a moment don't focus on that right now but there are some limitations on how could we execute the queries very limited search capabilities so if you need to have a full text search then mostly probably you will need some collaboration between Cassandra and for example elastic Church and of course running big clusters usually require a lot of qualified personnel developers operators and so on we at data Stacks work hard to make things simpler for their Global software development Community around the world so first thing require first my answer to the required qualified personnel first of all yep you want to say something yeah Alex how about asset transactions that's okay as a transaction because this is usually pretty important for well and pretty standard in relational database uh yes right well it's a complicated question because a current current version does not uh but uh it comes in garbage Cassandra version 5 to be expected release somewhere 2023 somewhere this year oh this year already amazing yeah so yeah I have to add this thing to this slide right consistency may be challenging in some situations so with all this limitation limitations what why would I want to use Cassandra because it's if you want to have all of this most of all uh Cassandra faces oltp workloads but for many scenarios you may need to use a data platform like we have for example with Astra data Stacks Astra is a data platform based on Apache Cassandra but extended with some new capabilities well this Workshop we are focused on the open source side of things but if you want to answer dozens millions of queries per second uh over the world you need to pay something for that right and you don't mean money but I mean capabilities can so scalability is unmatched relational database cannot scale nope the way Cassandra scales and the other thing is the availability right the relational database cannot uh cannot do that cannot uh provide High availability that we talked about that thank you so much for mentioning that like I was many times in a situation when I talk with some developers at the conference and I say like Cassandra skills better than the database you are current currently using and like what do you mean our database scales too what do you use postgres okay postgres is a good database amazing database it's like for many use cases postgres will be better than Cassandra I I mean like uh yes sure but what is that what do you call scale like what is your workload currently oh we handle up to 30 000 operations per second that's cute that's cute uh then I speak about scale I mean Millions operations per second not thousands not thousands thousands not hundreds thousands like and there at this place or uh multi-data Center um active active uh postgres try to have a multi multi-active DC but uh with traditional relational databases it's nearly impossible yeah so that is the benefit let's say we have a good question whether I'm sorry I have to finish this slide first and let's uh get to questions afterwards so required qualified personal there are two answers from me first one very important one there were a question in the chat before uh what about the certification data stocks sponsors your education and certification uh as Apache Cassandra developer or administrator so you can get your trainings pass yours plus you take your exam and become a certified Cassandra developer administrator completely for free sponsored by data stacks and that's our first answer second answer is Astra Astro you will see today Astra is the way for you to use Cassandra as a database as a service with no need for you to maintain and service and do all the things required by a database cluster it will be done by data stacks so it's really a very good solution for the cases you focus on your customer needs and don't spend your time maintaining a database a very limited search capabilities very limited search capabilities also has an answer so Cassandra works perfectly for example working with elasticsearch with for some cases you may need a patch spark so for uh huge deployments with multiple requirements from both olap and oltp uh you may need to use multiple projects simultaneously recently we introduced a change data capture for Apache Cassandra and open source it's a change data capture for Apache Cassandra which helps to communicate Cassandra with multiple different Technologies you may need to work together with and um so wherever questions you wanted us to answer right yeah that was a interesting question whether if we introduce multiple uh data centers will performance slow down a little bit slower will it will there be overhead I'm rephrasing it okay uh you mean question by Mao Andy yes in real world setting do we have many cases to set up different to see in different content in which includes higher latency no so I mean so first answer is yes there are many scenarios where you want to have your data centers in different regions first of all for disaster tolerance second of all for uh to keep your Australian clients working with Australian instance of a database so it will be quick uh it's gonna be faster response but there is a point what like in cure higher latency and that is wrong the story is your application server in Australia will work with our Australian Data Center and we will not wait for European to answer it's writes data to Australian Data Center and when Australian data center will communicate this mutation to all the other data centers asynchronously well it depends on your consistency level settings so where um maybe different scenarios but in short working with Australian data center you don't want for European data center to answer okay um yep but but for your application from one data center data is replicated to another data center in real time so that latency will increase of course because we're talking about larger distances but like Alex said your application will work with one data center which is which is the closest to to that application decreases in that case sorry uh there is a good question by uh Josh Kumar Patel in relational databases real application cluster give horizontal scalability how it differ uh the short answer is no in relational databases horizontal scalability is reachable only for read-only replica so-called slaves or follower servers and for them you can have horizontal scaling but notice you have horizontal scaling only for reads because why you cannot write follower servers they are read only so and to get horizontal scalability for rights in relational databases it's technically just impossible because for most of them you cannot have multiple Master servers simple as that um okay melro italis uh sorry yeah you wanted to add something yeah it's a loaded question uh I don't want to go deep into it but we will talk about a little bit about scalability next in the next session session yeah um sorry um multiple data centers might also be a setup to comply with data localization requirements by governments yes absolutely it's one of the things where you can put your different data into different data centers uh depending on the region yes that's how it works and uh boom which language will you use for the hand Zone activity for this Workshop we will stick to Cassandra query language which you will soon discover and this one looks very familiar to you uh because it's very similar to SQL except some capabilities like joins um uh uh Mohan paliwal asks about Cassandra DB data modeling comparing to relational light model it comes it comes next week so see you next week with that and next week we will talk about it a lot balancing is to be explained soon uh okay hours um this uh set okay then I asked your questions now it's time for you to answer my question and that's going to be question number nine number two switch to 90 answer my question how do we scale Cassandra cluster scale up by upgrading servers scale out by adding servers Cassandra cluster does not need scaling meanwhile there is CGR asks um how a data center uh belongs a data center cluster terminology uh installed uh cluster consists of multiple or one or multiple data centers data center consists or one or multiple nodes or servers node and server basically synonyms in this terminology and Cassandra scales horizontally by scaling out uh that is the way how you scale Cassandra cluster horizontally not vertically not by scaling up okay so it's one cluster multiple data centers one or one or many good well then uh that brings me to a point I have to switch the screen to yours uh are you sharing I am yes perfect so give me a moment s I think you are live okay try to change the slide so we have five more sections five more hours to go just kidding the um so let's talk about some of the concepts that uh we briefly touched uh so one of the important things that you want to remember about Cassandra is that all nodes all servers are equal so they appears there is no uh special server that is doing more than other servers and that means why is it important that means that if we lose one server we basically can easily replace it with another clear server so there is there is no concept of of master or later um and and this is this is probably one of the most important things to understand in the architecture and the cluster architecture so um traditional architecture many times we see distributed databases they they follow this design pattern where they have leader and they have have followers so essentially they um uh you can think about the the leader is going to uh always get all the rights and will will send those rights to all all the followers server servers or you can say they are replica servers as well so they will will store the data they will replicate the data uh but however so they when you're doing right in this architecture it always has to go through through the leader and that's a problem this is a single point of failure and rights will not scale with this architecture so what there are multiple solutions that different databases to try to improve scalability for rights they create multiple leaders they have standby leaders so if one fails they they come up they bring another one quickly and all of that but it's still very hard to scale right so if you're worried about rights you should look at the database that does not follow these architecture however for reads if we're talking about reads um we we can process reads using a follower servers so reads do not have to go through the leader they can go directly to the followers and therefore because there are many followers we can actually scale reads pretty well okay so in those databases scaling reads is easy scaling writes is hard and now the so-called peer-to-peer architecture which is Cassandra architecture and a few other databases use the same type of architecture uh here each node each server is essentially identical and they talk to each other they know which server stores which data and and if one sir so the the data is also replicated if one server fails it's not a big deal because there are replicas and and they can answer the same exactly the same reads read requests so they can read this retrieve the same data so no single point of failure and that means High availability but also we can scale reads and write very well in this architecture now Focus Sandra specifically we we had a little bit of discussion earlier uh right uh very efficient you cannot find a database that would do much faster than Cassandra those those that do faster will be very simple key value restores most likely so because because Cassandra simply writes data into commit log and it it right is done and then it does additional but reads can be more expensive in Cassandra so um because certain data structures need to be processed and data need to be retrieved and they can be multiple of them we're not going to attach that that's mostly internals but what you need to remember it's that both reads and writes will ski scale grades rights will always be super efficient reads maybe less efficient but still very efficient real time uh performance so we're talking about single digit millisecond performance so also the data is partitioned uh data is stored in tables but those tables are partitioned and and since we already mentioned horizontal partitioning indeed we are using horizontal partitioning there they are partitioned based on uh on a partition key so here is an example of a table sensors by Network and we have three columns here we have rows uh so columns Network sensor ID and temperature so this is how defined pretty similar to SQL if I didn't tell you that this is Cassandra Queen which you would easily think that this is a structured query language used in relational databases so the difference is to do the partitioning we need to assign one key one of the columns to be a partition key so in this case we're assign a network as a partition key and that means that any rule that has the same value for the network will end up in the same group of rows called Partition thank you so and essentially those partitions so everything with a network in California will end up all those rows in the same partition and Alabama the same thing Kansas the same thing and then there will be distribution data distribution uh that each node will be responsible for certain partitions so the data will ideally be identically distributed across modes in the cluster okay so we are talking about distributed table here this is how partition key defined in Cassandra query language cql it's a network column so you can see the same three columns Network sensor temperature and network is here defined as part of the primary key but it has a special uh dedication as a partition key so one way to to to dedicate a column as a partition key is to add additional parenthesis or by default the First Column will be the partition key so the partitioning of the table will happen based on the network column and distribution will also have have this um on this partition key so you may wonder what is this sensor it's part of the primary key why do we have it it's actually called clustering key because within a partition you also want to be able to identify different rows what what makes those rows within a partition unique and if you go back so California is a partition key so two rows will end up in the same partition what makes them unique the the sensor ID makes them unique so you can distinguish if you want to retrieve whole partition you specify partition key if you want to retrieve one specific row you need to specify partition key and clustering key so it's like row ID inside of a partition okay so based on the on the partition key the valers in the partition key column there will be murmurs 3 hash and partitioner used that will convert those values Alabama California into numbers those numbers can be will will be large numbers we're using small numbers just for uh for the sake of Simplicity for this example and then so they all of them will be converted to numbers and then uh Cassandra nodes will be assigned ranges of those numbers those numbers are called tokens so each Cassandra node will have a range of tokens that it will be responsible for storing and in reality there will be multiple ranges assigned so if we have four focused under nodes here then the first one and we have 100 tokens of course the value is much larger but for the simplest you only have 100 tokens and the first one store one force so it's one it but uh one uh to 25 the second one 26 to 50 and so on so what's what's fishing in Alex I can hear a lot of noise on the background oh sorry uh so why partitioning um and how it's related to sharding um so because scaling doesn't have to be sharp I think I may have t-shirt from 10 years ago that says that but Chardon went actually a long way it's not no longer it's not manual Chardon um so the the relationship of these two concept is partitioning is more General uh notion of dividing a table or data set in our case it's a table in two chunks and and uh we can divide it either vertically so we decide okay this part of the table some of the columns will go to a different table and the other counts will go to another table so we get two tables um that's vertical partition we are not using it here and horizontal position is we divide table horizontally so chunks of rows groups of rows will go to different uh different partitions right so that's what we're using here and Chardon is actually refers to that horizontal partitioning so it's one special case of partitioning is is horizontal one special case of horizontal partition here okay and um so here is an example with uh uh um of scaling your cluster whatever so if you have this uh token ranges if you have four nodes in your data center or even just in the in the cluster just think about it as a cluster uh with one Data Center if we add another note we basically need to redistribute the data right so we are going to scale out each node will be responsible for smaller token ranges okay but there will be more nodes and therefore they there's throughput increases how much data they can store in those ranges increases and all of that and this operation is not necessarily um uh super efficient or inexpensive it's it's not an inexpensive duration uh because um you have to move data between different nodes right so scaling in is when you no longer need that many nodes you your throughput is lower you you don't need to store that much data so you can decrease to three nodes and then you basically have to repair those nodes to move data around uh and repair by by saying repair this is the utility that you run in Cassandra it's not it's not manual process so this is how it can scale out scale in and some systems like asterdb do it for you automatically so you don't even know how many nodes you have in your cluster they all basically whatever throughput increases we increase the number of modes for you freezes and we will decrease it and that therefore it's you saving on sources and all of that so another important notion in Cassandra is replication data replication uh Alex could you please mute yourself oh sorry so replication Factor uh the duplication is done based on the application factor in the cluster or it can be if you have multiple data center you can specify a replication factor for each Data Center so the application factor means the number of nodes that will store the same uh partition so the same position will be stored in in multiple replicas so if replication so how how replication factor is specified is again when you create the key space and key space is basically represents your database it stores it will be a container for tables for indexes for user defined types for all the schema elements so um when you create the key space you specify replication strategy in this case it's a network topology strategy and replication uh Define the duplication Factor defined for each data center Us West one e and EU is two we get three and five okay so in the First Data Center we're gonna have three replicas of the same data and in the second data center we'll have five replicas of the same data so totally eight replicas so we can lose as many as seven nodes seven replicas and we still have the data of course we we never want to wait until that situation when we have the last one we need to because with uh like afford to losing seven notes and still get our data uh it works it's achievable but it brings some implications what we what our term will say soon at the fourth part of a workshop yep so with the replication Factor one we only store one copy of that partition with replication Factor two we store two copies that we have two replicas those are different nodes and we store two copies on different or one copy on each node with replication factor of C we have three different copies and and so on right and what it looks like in internally is basically with replication factor of two the this node is now responsible for two token ranges it used to be with the pH Factor one it was responsible for one now it's responsible for two token ranges and and this node is responsible for two token ranges as well but it doesn't make them special notes they just assign different token ranges that's it they they kind they function identically and all of that so with the replication factor of C when we combine in partitioning and replicate replication what happens so we need to store this partition with two rows in our cluster this Forest uh partition key will be converted to a token let's say it's 59 and based on the this 59 token so the the the application can send this request to any node in the cluster and that node becomes a coordinator of the request so we get 59 to this node blue node and this coordinator knows exactly which replicas are responsible for 59 for token 59 because it knows ranges of all the other nodes okay so it will take the data and will send that data to all three replicas because replication factor is three so it will send the data to all three replicas and in the normal circumstances all three nodes will get that data stored okay and of course to optimize it right to optimize it the um uh in Cassandra when when you write in your application with data stack driver and and data API the the interfaces I uh token aware interfaces so essentially your driver will also know which nodes are responsible for uh your driver also know with which nodes are responsible for for the data so it will not just speak any coordinator it will pick one of the replicas as a coordinator so that it speeds up things you have to do less work uh I want to uh say a word here I don't like the word coordinator because it's actually misleading I prefer to call it query coordinator and whatever node has got your query is that query coordinator because people often start to think about that uh like masternode which is wrong yeah every node is query coordinator node as soon as it processes your query and each query each node may get your query depending on how driver is behaving no answer to Adriana Cassandra driver is a Cassandra driver a query coordinator is one of the nodes it's decided to conduct in most of the cases query coordinator will conduct one of the replicas for web partition you are trying to work with yeah even better term is request coordinator right so it's not only query it's both reads and writes indeed coordinator has nothing to do with with a master or leader that we discuss in the architecture it's just the temporary role that just to perform that request just to forward that request to correct replicas um yeah and Cassandra Cassandra driver one of the questions uh is it is it coordinator Knox undertale it's just a library that allows you to connect to Cassandra cluster from your application written in Java python JavaScript and so on so now we're gonna do um our first Hands-On with Cassandra but we are not gonna use the um local installation we we're gonna use instead the um cloud-based service that is built based on Cassandra it's called astridbe so for our purposes what we will use is is gonna be a free part of free plan you may have to register sign up uh for for that plan and you get a large number a large amount of storage and large number of operations every month so um you don't need to worry there will be no credit card asked or anything else why why do we want to use this well for Hands-On we are not worrying about operations it we we want to start using the database without dealing with installing uh Cassandra on a note installing the second node connecting them I I would say about Astra this Workshop would be like uh four or five hours the duration right not to indeed okay we will not feed gender two but two and a half let's say yeah so I will so there are many good features about this cloud service called Astrid B but I will just mention too that uh for me it make a lot of difference is one no operation so you don't need to install anything you just click on the buttons and and the cluster is running in the cloud for you you just start interacting with it in our case we will use cql shell to interact with that classroom and the second one is this serverless feature remember when we talked about scaling in and scaling out so all of this is done for you automatically so it's Auto scaling that is built in as a feature of this database so you don't need to worry about adding nodes if if you need to store more data or you need to process more concurrent requests and you don't need to worry about scaling out so in case for example you have the during the day the usage is higher automatically you will get the logic Blaster built for you and you don't need to you don't worry about it at all you don't do anything about it it's just automatic if and it denied the usage is lower and and the number of nodes decreases automatically for you so you don't need need to spend extra resources so our first lab will be to use this Magic database called Astrid B we will create and it's it's built on Cassandra again we are not going to use any features that are not Cassandra features as well so we'll create a tables we will insert data we will create data okay so let me so this is the URL that you can use to access the Hands-On instructions and the first one is it's gonna be really easy okay so this is the first one create your database okay so this is the link you can follow to go to astrodb website okay and there you will if you don't have account already you can sign up and you can sign up with your Google account if you already have an account you can sign in what we will do there we will simply create a database with name workshops okay and key space name sensor underscore data we will use Google cloud provider um to deploy our cluster in and you will see what happens whether it's difficult or not so I'm clicking this create Astra DB foreign okay and I get to this screen so I'm going to sign in in this case uh with Google account okay and I get to this screen okay I will wait a little bit how many people are already signed into Astra website um can you confirm can can you confirm in the chat or do you need time to sign up first okay so people like it I mean like sign up using Google account or GitHub account is uh there are just a few extra questions there yeah okay we're getting the sign in sign in yeah so the next step you can go to databases and it's if you haven't used this database before there is nothing here so it says the create database in my case I don't have any databases so I will create database foreign we need to specify the name of the database and key space name so workshops is the one the name of database and key space name is sensor data okay pretty simple and you can see this is a free plan this there are certain restrictions on on on where I can deploy my cluster and essentially I can deploy it in the foreign okay and I will use North America I don't think any other or there are some other agents if you're in Europe you can use Belgium if you're an AJ you can use Mumbai India in my case I'm not I'm in North America so I will use the South Carolina Us East one as my um the region in in Google Cloud to to deploy the database so these are three steps right or two steps technically right the database name key space name and the provider then create database and at this point you it may take a couple of minutes what happens be behind the scenes is you will get um three node cluster created for you automatically okay and you will also get these tokens generated these are different tokens that we we discussed these are tokens related to security these are not tokens that produced by partitioner right so um and we don't need to use them so you just can go to so anything here is is uh something that you will need when you write your application we're not going to write an application yet we're gonna use built-in clients to work with this database so at this point you can see workshops database oh it's already active that's really cool and in the next exercise or lab we will go to cql console to work with this database okay and with this Alex yes thank you so much I think I switched to I think I switch us to my screen thank you and good okay before we proceed I want to answer two questions there are two great questions in the chat uh one from Mallory telis and thank you for asking uh great questions in a row how do the Cassandra driver and nodes perform service Discovery uh in short idea uh each node communicates with each node then you launch a cluster nodes uh can join this cluster and each server understands how many nodes are in the cluster but that's only half of the answer the second answer is when you have a cluster like a originally consisting of one node two nodes like small amount of nodes in the beginning they share those token ranges what are John was talking earlier so each server let's say we have free cluster a free node cluster each server responsible of free uh observed approximately third of a token ranges you have next server they are being recalculated and next server will be responsible and the servers will be responsible for quarter of them uh tokens like work water 25 percent of a token range let's say uh it's a little bit more complicated because of replication but that is a general idea now each server not only knows a knows which token ranges it's responsible for but also knows which token ranges are its neighbors and other servers in the cluster responsible for and the same goes to a driver then you launch an application you have to specify IP address of some nodes that is important but a traditional approach in a relational databases for example use petsify IP address of a node in the beginning like Master server legal server and your um application will work with this and this only server and that is for Cassandra a complete misconception because you your node your application driver your Cassandra driver will use EVS IP address in the beginning to bootstrap information to load information about the cluster then driver starts it will go to this IP address and ask what is a cluster what are the nodes which node is responsible for which particular token range then you execute a query driver calculates the partition token from the partition key you gave and then makes a query uh do a particular server already knowing which servers are responsible for which partition because it knows nodes and token range and allocation which server responsible for which partition tokens simple as that and then these actually answers the second question by another person Mahmoud akhtar asks is the request coordinator similar to Lord balancer no request coordinator isn't similar to Lord balancer because Lord balancer is the client the driver for example you have replication Factor free that means what were a free replicas of your partition is stored on three different servers there you try to retrieve a data from this partition or maybe write something to this partition you have to give a partition key then driver calculates a partition token based on the partition key you gave it knows which pre-servers store your data and then base it on the route Robin balancing policy it may change from version to version but the general idea it tries to ask the least loaded server of those three to get your data so client-side load balancing all right it's built in into driver yep yeah yes a good question melroy uh friend you really need to get the Cassandra certification like it's free and it really helped you to get your LinkedIn profile page to look better and make more money in the end I'll really like your question man uh so if a node receives a request for a partition with a token outside the token range it will behave like a query coordinator so it sees what I'm not responsible for this token but I know who is responsible so I become a query coordinator or request coordinator and root this query to a proper servers coordinate their efforts and return the result as soon as I have this result that's the answer so no request is rejected okay I have answered all the questions now it's my time to ask you some questions right uh two two questions in a row yes two questions in a row actually even three questions in a row and question number uh one of those three will be how many masternodes Cassandra cluster needs minimum free per Data Center follow replica divided by three no masternodes I'm quite curious about the answers people okay 23 persons answer it right no master notes there are no concept of a master node in Cassandra no master notes in Cassandra nope okay very well let me see how it will go with the next question how is data for a table distributed each server has all data one table on one server by partitions by shards okay yes right by partitions uh we cannot have things like each server has all data um oh yeah because it will just not feed like we speak about 100 terabytes we speak about petabytes of data there are no server to hold this data and still answer within milliseconds yeah and there is a question where should we answer those questions answer is on top of the screen go to mention.com and use the code 6291-8600 or you can just get the link in the chat I will answer your question after this uh quiz good right transfer is by partitions and then finally last question what is the biggest problem of replication uh we are getting to the next section I will be doing and what is the biggest problem of replicated data increase disk space consumption more networks transaction or potential Cruise node inconsistency that is a treaty question I made it intentionally very team so I'm very curious of what your answer will be and time is up yeah nice nice so very good very good now it is a tricky question so if you gave a kind of wrong answer wait for a second I will explain take a look all of those answers are technically correct because it all those all are the problems of replicated data replicated data leads to increased disk space consumption replicated data leads to more Network transactions and definitely replicated data leads to potential gross node inconsistency but the question was what is the biggest problem of replicated data and the biggest problem is potential inconsistency let me explain first two disk space or network transactions you know there is a very good phrase if you can solve a problem with money it's not a problem it's expenses and that's exactly the same Cassandra is used by companies like apple or Netflix or Instagram those guys have money for disks and disk space is cheap what is priceless is your reputation and reputation for engineers very often defined by the uptime of the application so yeah replication is not possible without some disk space consumption and that is expenses not a problem exacting okay problem problem but solvable Problem solvable by money same with network transactions modern software-defined networks even sustained software-defined networks are extremely fast not to say fiber optics blah blah blah also very very fast so it is a problem yes it's solvable yes uh but potential gross node and consistency is a real deal breaker so let me show you what do I mean take a look you have your data replicated on multiple servers for example price for the goods you are selling and then there is an update you want to update a price sell it more expensive for example I don't know inflation or whatever but for whatever reason Network outage power outage I don't know server kidnapped by aliens uh server stolen violence uh this update didn't reach your one of your servers and as an outcome two server have new most up-to-date price and second server does not a third server does not that is called that cross node inconsistency when one of the servers stole serves stale data what happens I mean if you ask visor web server for the data you get your answer and everyone escapee but if you ask this one and this one only that may lead to a real problem because with even one dollar difference over time on a big um intensive cell may lead to Big losses but we don't want you to have um so to protect itself from a potential gross node inconsistency Cassandra has multiple tools or layered defense first one we already discussed it first one was hinted uh handoffs briefly mentioned before uh hinted handoff means when for example we process this data and this node is a query coordinator but not replica who are the replicas because this network forest makes token 59 and those three servers are responsible for this uh token then that means what we will send these data to those three replicas query coordinator sees what one of the servers does not return the answer so not confirms receivable of this update what happens then query coordinator stores hind hint it's a persistent data basically it's a file what keeps this information as soon as this server recovers as servers are communicating with each other this server knows what this server has recovered and it dispatches the screen to them to do a replica failed replica so cross node consistency is recovered but this mechanism although it's magical it works perfectly it has um some limitations as well for example you don't want to keep your hints for too long for example if this server was out for a couple of days whatever bad happened to it it was not available for today's then it will get a real storm of hints when it recovers what may bring him to down again well not exactly like this I'm simplifying but um the story is hints usually store it only to only about three or four hours depends on the version and after that we will be discarded if node was out less than three or four hours it will be recovered automatically if it isn't you may want to execute repairs or you may want to take it off the cluster and bring it again to a cluster as new uh we will C other mechanisms also we will discuss some other mechanisms to control consistency so hinted handoffs we just discussed it it's a Cassandra job Cassandra is very good with it and it's fully automated you don't have to think about it that there is a repair on read we will see you soon in progress good then repairs repairs and his administrator's job to configure so it's not covered by today Workshop if you are interested in operation and maintenance for Cassandra clusters we have a free course or Cassandra operations available on academy.datastacks.com for free it's called a ds210 ds210 and you are very welcome to take this one and then finally consistency levels consistency level is a developer job and as this Workshop is for developers we will be focusing mostly on the consistency levels today uh before two questions and they are really related okay so uh first question uh from the Josh Kumar partitioning key details are stored on all nodes means for each table index is created on each node yes and no I mean it's not index in the normal understanding like for indexing data for search capabilities no um it is we can call it an index but the general idea is what each node nodes token ranges uh allocation over the cluster so each node knows what for example token is 14 or 42 and who uh it knows token ranges what for tokens from 40 to 50 server a is responsible so it knows which server to ask to take care of his data and an index but not in the normal relational database understanding of the index okay I hope I answered this one yeah well let me add it's it's a very small data that metadata that needs to be stored about token ranges so there is no need to store details of each partition key when the data comes that value of a partition key is run through the uh a partitioner murmur Suite partition that generates a token so it's just very simple and quick operation so whatever text you give or integer you give you get one number and that number will fall into one of the ranges and that's very very easy to find which which range it's gonna fall there are not millions of those ranges right so yep and that also probably answers the the next question that we have how do we know something is a replica or not it's based on the murmurc partitioner converting to the token and the token range is assigned to the different nodes a question from a CGR do you have visual slide which shows the overall right or read process from a series of steps answer is yes but it's not the part of this Workshop it's a part of a deeper uh Apache Cassandra fundamental scores at the data Stacks Academy and this this is a read pass write pass they are not necessarily super simple there are many different things involved there like memory data structure some indexes uh something on multiple files on this so these are internals to be able to successfully use Cassandra you don't really need to know that much in terms of uh the the all of those data structures and how they interact yeah and now to answer a question by Adriana um how do we know something is a replica or not uh short answer is each node is a replica for some partitions right um each node stores data each node is a replica the real question is what will be the replica for the partition we are currently working with we working with Partition like we work with these temperature data of Texas for example and uh partition as a partition key Texas we know what will be the token of this partition as we give it to more more free partitioner hashing algorithm it gives us some integer and we know what each server in our cluster for example we have six servers it's responsible for uh like 18 persons of um of the potential tokens and we know what replication factor is free we already know these uh token ranges are location over the cluster so when we just make this quick quick comparison over the data what uh RTO mentioned already and then we know which node is a replica for this data it's better explain it in more details let's explain it in our Cassandra fundamental scores at the Academy yeah and again your application can connect to any node and and Magic happens for you you don't really need to you you you you don't need to deal with tokens directly you just deal with your data and and tables schema that you create so so then we switch to your part number four right uh yes so in this section uh we're gonna talk about cap cerium and the this Serum is is very fundamental to not only do Cassandra but to any distributed system okay any distributed system so it operates with these three um features or three properties availability consistency partition tolerance and the ethereum essentially says that um the the in a in any distributed system in any distributed data store you can only choose two of this system you can only guarantee two of these two of these properties availability consistency or petition tolerance so pick two you cannot have all three so let's look more closely at each one what do they mean so the availability again we're talking about distributed system multiple nodes in a cluster and availability means uptime but essentially the availability means that if you send a request the application sends a request to the database uh you will get a response so database was available uh it doesn't say notice it doesn't say whether response is consistent or not whether it's 100 correct or maybe you got stale data remember because different replicas it it doesn't take one replica maybe it takes three milliseconds to to get the data another one may take seven milliseconds so um there is this very short period of time where there may be discrepancy inconsistency in data so availability simply says that the the there will be non-error response you will get something whether it's empty or there is some data but it's not that you will not get an error that system is not available that's what availability means and and we usually want to have availability right uh the other one uh consistency means that you always get the um the you always read the data that was most recently written so you're not gonna get non-stay no you will not get stale data okay the the old data so in this case in this example we have three replicas one of them still has 12 so it didn't finish the update for some reason so in this case uh this is stale data so if we read from only this replica we will actually get inconsistent data because the most recent value is 13 right so that what consistency inconsistency means so you kind of want to get that too but remember you cannot get all three you need to you need to settle on two so it's it's not an easy Choice sometimes so the third one is partition tolerance because we are talking about cluster of nodes um things bad things will happen in that cluster right so some notes will go down and will no longer be in in the uh available to respond to anything to interact even you can you can have the network partitioning like in this example when uh these two nodes are no longer communicating to these four nodes so it's like you you have a brain split so-called brain split uh using proper technology and you have the group a and Group B and they are independent and some applications may be interacting with these four nodes and other applications may be interacting with these two two nodes and so they they uh long story short so these three properties the because we are working with distributed system and multiple node clusters right uh we will things will happen notes will go down and and just a single node going down it's basically a network partitioning already but think about those data centers right the one in in New York due to snowstorm is down right so uh the whole data center cannot communicate with data center in California right so in distribute system everyone always chooses partition tolerance so this is fixed basically property every database wants to be partition tolerant otherwise it's very hard to function in distributed uh world so we only have one more um Peak so we can use either consistency or availability and and therefore those systems are usually they they're called CP systems or AP systems okay so in case of uh in case of Cassandra I'm gonna tell you right away the um the Cassandra is known as an AP system even so we can tune it and make it a CPE system but that's not necessary um the best choice or the best way to use Cassandra so Cassandra can um use consistency levels to configure consistency or or it's so-called tunable consistency it has tunable consists you can tune it you can change it to a different you can you can use different consistency levels for different requests and essentially each request each insert each delete each update each select that you will use in Cassandra has Associated consistency level they can be different for different requests but they can also be the same so it all depends on your it so you tune your consistency based on based on your needs so it you may um right with one consistency and read with different consistency which is pretty common okay so here is an example consistency level consistency level used in Java application this is how it's set for statement and this is how it's used in SQL sh SQL shell where you can read what what is current consistency level by executing consistency command or statement or you can change sorry you can change the consistency by saying consistency and then specify level in this case it's consistency level all um so what it means what consistency level means is uh how many replicas how many replicas will have to acknowledge that the operation or request was executed uh for the for the client um uh to get the successful response right so we will talk about consistency levels um based on some examples for so here is an example of we are writing with consistency level one okay and replication factor is V so client sends the request to write something and that requires is always transferred to all replicas in this case three replicas but we only science consists level is one we only need acknowledgment from one replica that request was successful so out of three replicas the first one that says I'm done the coordinator will re respond to client the operation request was successful it succeeded the right succeeded Okay so no matter what happens with the other two maybe they will fail but most likely in normal operations all of them will succeed but we are waiting for the fastest one to respond if you need stronger guarantee then you may use something like Quorum majority of the replicas so in case of three replicas the majority will be two and we will wait the the coordinator is going to wait for two replicas to confirm that they wrote the data for telling the client that operation succeeded okay this is Quorum consistent as well so and you can change it for each ride something that is maybe less important consistency level one or there are others like local one something more important uh maybe quorum and consistency level all will require all replicas to confirm that they read in the data and consistency level all is a bad one so we don't don't ever want to use it why because if you're gonna wait for all replicas essentially we are going to enforce consistent right but we are going to um uh make our system unavailable we are going to lose sacrifice availability because if one of those replicas goes down we will not be able to perform completely right because there are only three replicas if one of them is done down then consistency level all cannot be satisfied Quorum can be satisfied right because two out of three is still available one can be satisfied one out of three still available but just one failure in your system is not available so that's not a good situation essentially this is example of when we sacrifice in availability and and using Cassandra as CP system which is not recommended don't don't use consistency level okay uh but then you may ask well I don't want to ever read stale data I want to have consistency it it doesn't matter I want availability I want some consistency and we can do that as well we can still sacrifice some availability but make sure we have a better consistency and that better consistency essentially is called the uh immediate consistency or strong consistency so let's see let's see how it works um essentially the the formula for so you need to if you want to make sure that you write something and then you immediately read and you use you read most recent data no stale data then you need to make sure that your consistency level for rights plus consistency level for each is greater than replication Factor so the in this example this is the case so replication factor is three and consistency level Quorum majority of three is two so we're leading with two we're writing we're writing these two and we're leaving with Quorum which is two as well so two plus two is four is greater than three right so we are gonna get immediate or strong consistency in this case so this client writes the data it writes into three replicas and waits for two confirmations so these two confirm this one may be slow it maybe it's gonna take uh 10 milliseconds and these two did it in three milliseconds immediately we have a client that is reading the same data and doing it for us so less than 10 milliseconds passed and it's in in case of reading because we didn't we score them we don't have to contact all the replicas we are going to contact only two um so let's say we contacting these two this one actually has the most up-to-date data and this one still has stale data because it the right didn't complete so what happens we get both of them on the coordinator node uh the request coordinator nodes and based on the timestamp every every piece of data in Cassandra has a timestamp that is there automatically So based on the timestamp the the most recent data is going to be identified and returned to the client and besides that even there is a chance that the coordinator will send the most recent data to this node to make sure it's gonna have it next time it talks to it so this is essentially allows you to always be consistent and allows you for availability if one node fails in in with replication factor of C your system still functions um you will basically not notice your application will continue to serve the requests now there are many consistency levels this is not the complete list so the edge cases any and all it's something you should not use so any is only used for rights and it's when no replicas available available so the the coordinator note is going to store the data as a hint so this is something that you you don't want to use and all you know well it very depends on the use case I mean like in general case yes you don't want to use any you don't want to use all but don't forget what consistency level is configurable per query and it also may depend on the what kind of a data you are storing there are plenty of scenarios uh when you when any will be fine for you but it's not as a general rule not as a rule of thumb only when you work with the data you can afford to lose but you have really intensive right uh performance for example for locks for the data which is being outdated within a few seconds for so there are some scenarios when Annie is a good thing I don't want uh like to say never use any but definitely as a rule of a thumb we don't use it and you have to be very careful it may potentially lead to the inconsistency the story is various of scenarios you can afford some consistency well they yeah I've never heard anyone using any in production and you that the cluster will be in a very bad condition if you have to use any essential biggest all replicas are down and they it's uh the data is not going to be stored properly it's going to be stored on on the other node but it's not going to be in proper data structures and all that anyway the the most important ones will be one local one some two three is okay but uh most of the most important ones will be one local one um Quorum local Quorum each Quorum so what one means if you have these three three data centers but one cluster they all in one cluster so one means that any no any any replica in this whole cluster can respond can acknowledge okay your write or read um local one means that if you your client connects to this left Data Center leftmost then the replica in this data center must respond and that brings us the the the question we had earlier will multiple data centers affect latency so if you're using local one it will not because you're only going to get response from replica in the same data center that you connect it to so you don't need to you if you connect it to one in New York you don't need to to get the response from Tokyo data center okay uh the two three two nodes or three two replicas or three replicas in the whole cluster so that's not super useful actually uh Quorum means majority of the replicas in the whole cluster so we have three replicas in each one so we have nine replicas in the cluster we need to get response from five of them okay so again if you're using multi data center environment then you probably like to use a local Quorum because it's gonna be Quorum of the replicas in local data center if I'm connected to leftmost I'm gonna and there are three replicas local Quorum means I want to get response from two I don't need a game to go to Tokyo or go to um New Zealand to get the uh my answers right because I'm in California I want the data to that is stored here locally it's going to be more efficient and each Quorum is a quorum in each data center so if we have replication Factory in all three of them we need to get a response from two two and two so totally six notes six note notes need to be respond uh need to respond pretty geographically distributed nodes it's not going to be fast it's not going to be it's fast yes it's it's gonna it's it's the most expensive out of uh all of this except of all of course so all is gonna require nine replica respond so you get the idea each request write or read will have to use some consistency level and and you may easily write so when you for example if you write with local one the data will get you'll get information the the application will get confirmation from only one right the one replica it doesn't mean that the others are not writing they are writing at that time and one of them becomes the coordinator for replication with another Data Center and and they these two coordinators communicate and write into these replicas all of this happens for you but you are not waiting for this process to complete you just wait wait in one local node acknowledgment so that's gonna be very fast then you may decide reads are more important I'm gonna read with local forum or something like that okay and with this set we can proceed to the second lab okay so again I'm going back to our GitHub repo and we are going to create tables those tables will look very much like um cql tables very much like SQL tables right and even so the Ezekiel Cassandra query language the Central Language so let's take a look what we need to do we can describe key spaces this command so we will basically see what can spaces will have in our system I will do that for you you will you will take take a look at that we will then choose to use sensor data as a key space and then we will create three tables one is Network stable which is a table with name so it stores sensor and network information about set sensor Network's name description and region so name will be partition key and we can later check that we we did create this table and then we create two more two more tables one is sensors by Network and the other one is temperatures by Network bad so this is going to be a bad table um and the reason it's bad is because um partitions that's something that Alex will talk in the next section but essentially the um the the partition key is sensor and and all the temperatures measured by that sensor will be stored in that partition but you can think that if we that sensor is working for many years it's going to collect data for many years and collect data regularly every second every five seconds every minute and so on then that partition will grow it's gonna have many many rows over time and we don't want that to happen we want to put a limit on the size and therefore later we will drop this table drop table and create table temperatures by sensors where we will add date as part of the partition key in this case we collecting the measurements of each sensor on a specific date okay on a specific date so this allows us to limit the size whatever data is collected on that date the partition stops right then the next partition is created tomorrow and so on and so on so only three tables at the end Let's uh see what we can do let me copy the first table okay okay and I was logged out I will log in again go to databases okay I have my workshop database I will click on it you have the same workshops database and we will use built-in client to interact okay so essentially it's the client someone reading for us in Python and we are going to use it to interact with our database so first uh describe key spaces okay so the key space that we are interested in is this sensor data other key spaces here are key spaces that are related to the database metadata functioning uh and so on and so on so these are basically internal key spaces that you should not work with the one we created is sensor data and we are going to use it so we're going to select it as a default key space all our statements will be executed within this key space okay okay now let me copy again okay so I'm going to create this table done describe tables okay I only have one describe this table Networks oh you can see the same code create table but there are a bunch of other properties that you can actually change for the table We're not gonna talk about them today um so the other two tables okay sensors by Network and temperatures by sensor bad okay and the last command that we need here is to drop that I explain why the why that table schema was not great the selection of primary key was not great so we added date so we will drop the table and create a new one okay now let's describe our tables and we have we have three tables right and now in the next exercise we will be able to populate those tables okay so we'll be able to insert delete update so if you're familiar with relational databases with SQL then you probably feel comfortable using cql Cassandra queue language create table insert delete update select all similar statements all similar statements but there are some differences we've seen already like the partition key and this clustering order by is something new what it does is basically specify specifies how you're gonna how the data will be sort within each partition within each partition the data is sorted based on clustering key in this case timestamp and we're saying let's sort them in descending order so the the most recent data is going to be first and this is kind of optimization that that allows you to efficiently retrieve the data and do some specific queries um that that clustering clustering order helps in in that case but that's out of scope for today Alex back to you yep good oh so questions are answering shot and let me switch to my screen yes good so with that say it and done uh let me ask you a couple of questions uh to be basically very very last questions of ah okay almost the last question cep theorem says what a failure C A and P are guaranteed if C fails so do A and B only CA or CP can be guaranteed foreign yes CA or CP can be guaranteed you cannot that would be great to have C A and B on failure magically somehow but there are no unicorns I'm sorry uh also that would be great yeah and if C fails A and B still can be feasible good then second question uh recommended consistency level for the immediate consistency read write one one read write one all read write Warren quorum yeah read write Forum Quorum is recommended level for immediate consistency those four persons who answer it one all technically you are right one all also read let you reach immediate consistency but it's not recommended way because this way you are in a trap of all consistency level which require all nodes to be available and the slowest one good so we are getting to the very end uh final part and let me uh go let me lead you for a bit so data structure in Cassandra starts with a cell a seller's intersection of a Rowan column that stores data then row is a single structured data item in a table that must be familiar to you already then partition is a group of rows having the same partition token it's a base unit of access in Cassandra it's important what all rows of the same partition will be stored together on the same server close to each hour it's important for the smooth retrieval of this data then finally table is a group of columns or rows storing the partition in Cassandra data is organized as distributed tables so tables are present but parts of them are spreaded over multiple nodes and then responsible for that is a partition key then you create a table you must Define primary key and primary key consists of two parts first part is a partition key first argument in a primary key definition it may consist or one or multiple columns but must present and must have at least one column otherwise we cannot calculate the token uh there are different ways but the general idea is all the fields of the partition key in this case for example only sensor we will have as many partitions as many sensors we have is it good or bad well it depends on your situation might be good or bad depending on how many sensors do you have well you can have many partitions it's totally fine but maybe you want to improve something on that in this case you see sensor and timestamp partition token will be generated based on sensor ID and timestamp of a temperature record that means we will have as many partitions as many records we have per sensor and that might be good on the right time but it might be bad on the read time there is important thing to understand when we're thinking about uh creating partitions we speak more about that uh next Workshop but briefly I want to introduce it when thinking of partitions we need to remember two operations right and read what is important during all the operations when we write data when we retrieve data we need to know all the parts of the partition key can we write data with this partition key for example temperature sensor reports its temperature to be I don't know 30 degrees Celsius can be right with data yes we can we know sensor ID we know timestamp then this recording was done when we can just go through it to the database and we will be happy new Partition will be created this partition will have only one record and all of this is totally fine and good but you should not forget about the second operation which is a read and in this case we might run into trouble because to retrieve this data again we need to know all the parts of a partition key and then take a look if you're going to retrieve data about the sensor I think we might have we may have its ID okay but also to retrieve data safely in the right way we will need to know all the time steps when these recordings were done and that sounds already not so easy so this partition key might be optimal for right but not so optimal for read so we could think of something better in the future then second part of a primary key are the clustering columns what is a clustering column it's a special column a part of your table definition in this case for example timestamp what has two purposes it's a user to ensure uniqueness and its second duty is to ensure sorting order first let's think about uniqueness why do we use uh or why do we use clustering column imagine primary key like that we don't have clustering columns at all we have only partition key and partition key is sensor so sensor ID with this design we will have one recording per sensor because primary key will be always matching Cassandra follows the logic of absurd or update or insert are exactly the same operations so with that if you use a primary key like that every next temperature recording will overwrite the previous recording is it good or bad it depends on your it depends on what do you want to have if you are fine saving only the last recording then maybe it's totally fine as designed but if you are going to uh see like how temperature changes over time that's obviously not going to be the good idea so short answer is not an eager then uh for example second duty of it is to have sorted uh sorted defaults this idea is much better sensor as a partition key timestamp as a as a clustering column this way because they both build together the same primary key each new recording will be unique and available for sensor for timestamp and that is the first thing so data is unique uh and next there are timestamp recording will next temperature recording will not overwrite the previous one uh and in this case we will be able to sort by time and that is already pretty good for us because for example we want to so we want to sort our temperatures by time to see how it changes over time um in this case it's a pretty good example how timestamp is used for both uniqueness of the record and for sorting and uh that is a pretty good example let's move on then primary key is partition key and clustering column all together you already seen how we're working uh partitioning so partition key is used to define partitions clustering column is used for uniqueness and core sorting order and this V clustering order by is used to explain in which sorting order we need to have it ascending or descending uh so those are typical examples of a primary key for example for these kind of datum can we mention clustering order out of a primary key columns and ah so I'm not sure if I can get the question um non-primary keycombs can we use non-primary key columns too for sorting yeah yes uh maybe so the story is in Cassandra uh uh clustering or okay so the story is we have three uh kinds of columns uh prior partition columns so censoring date in this example clustering columns timestamp in this example and data columns value in this case y value is a data column because it's not mentioned in primary key nowhere and in Cassandra partition key clustering columns work as primary indexes so you can use them for search and clustering columns for filtering for sorting data columns cannot be used for search for filtering for sorting and so on they are just to store data there are tools to enable it like secondary indexes but secondary indexes Cassandra is a pretty complex topic they have their own issues they um uh partition based and there are like plenty of issues with that so uh short answer is for sorting uh only clustering accounts yeah for sorting for only inequality operations only clustering columns I told you in the very beginning Cassandra is a real Firepower on the database Market extremely fast extremely powerful scalable and high availability and everything but there are plenty of limitations too there is a price to pay and inability to search by data columns or inability to use inequalities on a partition Keys is part of this price uh we will discuss it more I believe in the next Workshop good now very important thing now please Focus they are getting to the end and this part is important partition keys Define data distribution over cluster all right a different partition key and your data goes to in our server clustering columns Define how data is physically stored how it's physically written on disk so there is a a very important thing you need to understand because of it once created data model cannot be changed you will need if you find what your data model is not right if you have something maybe it was right before but now it's changed now your application has new business requirements you may need to create new tables and migrate your data and there is no things like alter table change primary key it's not possible for a simple reason schema is immutable because changing any kind of a partition key will lead to changing partition tokens will lead to moving all data all the cluster and basically web can take weeks and your cluster will be busy moving data not answering customers same with clustering columns change of the clustering column will lead to a need to rewrite all data on your cluster which again will take weeks of cluster being busy or rewriting your data so it's again not possible you can change only data columns you cannot change anything what is or was a part or is a part of a primary key nothing schema is immutable good and that uh last few slides partitioning as you can understand is the key to success if you do your partitioning right your application you'll work very fast and it will be very scalable do your partitioning wrong and you will have a lot of fun later I mean fun in the very bad meaning of this world so no fun at all uh very free simple rules of a good partition first store together what you retrieve together that means think about how you are going to load the data select read these data the data makes sense to group together what we are going to retrieve together we have to try to group our data away so everything will be retrieved from one single server so it will belong to one single partition because data is isolated on the partition level that's it second rule avoid big partitions don't forget we introduce partitions to avoid having too much data per server and introducing two peak partitions you get to exactly the same problem you just get too much data on the server your server will need to spend a lot of time trying to retrieve your data it will be unmaintainable and very many other problems uh for example we do not recommend you to have more than 100 000 rows in a partition or more than 100 megabytes of data in a partition those are recommendations but the hard limit you cannot have more than 2 billion sales per partition but my advice is not to try to get any close to this number because it's going to be a very very very very very very bad idea um for example here we can say what writing comments per video on YouTube for example um there's a small entity so sometimes there can be more than 100 000 rows in a partition but at least they are small there is a text comment ID out already outer name timestamp and text and usually comments on YouTube is pretty small pretty small so in this case partition per video for most of the cases will be reopen reasonable size but if you group your data of customer data your users based on the country there are countries like Vatican or San Marino there's like a couple of thousands of people and there are countries like China India and with hundreds Millions uh maybe billions of people and this case your first introduced Big partitions which is bad and second you introduce uneven partitions which is even worse you see Cassandra scalability works best then your partitions of a similar size or rare more or less even than spreading uh things uh like that based on the country is basically obviously a wrong idea and then uh another Point what is very often forgotten designing partitioning for these tables people forget what size may change over time for example if you write these temperature sensor and you do it like that sensor ID times temp the example we are speaking over day today with temperature recordings if these sensors report they stayed frequently like every few seconds if you speak not about uh like nature uh research but we speak about internet of things temperature of an engine temperature of oil in the engine then this temperature can be recorded every few seconds and then over time if the beginning this model will work partitioning based on the sensor rating then over months the partitions will start to become too big and obviously that's getting dangerous our partitions are too big another one of the solutions possible in this scenario would be introduce some sort of bucketing uh where we have these uh where we add one more field to a partition key to be the month and the year of when this recording was done so that is the January of 2023 and then this value will be 2023.01. then what happens then this month is over and February starts so it will be 2023-02 that means what for the very same sensor this value will be different which brings us a new token and very for a new Partition is created automatically you don't have to think about it but then just you have new Partition and it all works uh on the new node and it's scalable very forward when you will add more servers will partition will move to different places uh to different service very well sometimes people ask me why not to put timestamp in the partition key or not build your base it on month but pay build it based on um week maybe day maybe hour things like that don't forget two access buttons write and read can I write sensor ID month here yes I can can I write sensor ID timestamp yes I can but then second access pattern read can I read sensor ID in month year if customer asks me to show data values of the sensor for last three months it will be January December November so plus the same sense already I will hit three different partitions not a big deal it's okay but if I have my partitioning based on a week or a day for free last months I will need to hit like 90 plus partitions that is obviously a bad idea foreign partitions imagine for our temperature recordings we do partitioning like that date and sensor with partitioning based on the date current date then take a look I have a cluster of 10 servers and replication Factor free so today all sensors write to those free servers servers are very busy because I have a lot of sensors maybe billion of them maybe multiple billions a lot of Rights and servers are basically dying because there's too much pressure on them they cannot process all the queries and that is a bad and then I think okay I work for a big company we have a lot of money we will buy 10 more servers so my cluster will be 20 servers and we do will that work no that will not because despite now I have 20 servers very same partitions allocated on the very same server or maybe new servers but it's still the same free servers are overloaded because of replication Factor free partition is hot it's being accessed all the time while all the other partitions are not being accessed at all or only for reads that means we need to think about the size of a partition about how often those partitions are being accessed in the terms of Rights and reads avoid what partitions partitions being accessed all the time while others are hiding so this approach is much better because when I need to scale I add more servers and those workloads being distributed across multiple servers each server has less amount of queries per second basically last question uh all right all right two last questions question number eight select without partition key syntax error okay to get all data very bad illegal and punishable by law now as an officer of nosql police I have to say what transfer number four is right I will get to you in a resume if you are trying to do select remote partition key in Cassandra yeah so now it's not a syntax server you can do select without partition key you will get a new role by default but it's not a syntax error uh and you can make select without partition key working with a low filtering uh statement but it's a bad idea second it's okay to get all data no it's not okay to get all data uh it is indeed very bad its own scenarios it might work if you use a low filtering and last one uh whatever you are whoever you are who said illegal and punishable by law thank you so much like and I'm all with you uh good and the last question for today question number nine is what is the most important rule of partition data try to have as many partitions as possible in Partition size under control keep together what you retrieve together and last one make partitions bigger okay don't make me angry don't pick before okay thank you thank you thank you yes so no came together what you retrieve together is a question of convenience it's important rule it may be very helpful on the read time that is a very good group but uh when your cluster is operational you can remodel it you can create um new tables you can migrate your data but when your partitions went crazy size and you your nodes just irresponsive and you cannot do anything that is a really bad situation so the most important rule is key partition size or under control don't make the big card partitions or avoid big partitions avoid hold partitions that brings us to the last slide of the quiz who made the best work answering questions and like each question uh worth 9 000 points so many thanks to the judge Kumar with uh seven right answers then James melroy Natalia Sultan Bell evil ranji Twitter and JD thank you so much for making it and uh Tejas Kumar that was incredible job perfect uh V that thank you for participating you are the best uh I think uh what do you think if we keep a last step of the homework to be the homework that is the first step of the homework it's assigned to be homework yeah I I don't mind because it's it's very easy and and the instructions are quite comprehensive so yeah updates deletes and and selects yeah uh there is a good question from James Wong do we need to constantly archive all data to keep database clean I guess so James uh first of all Cassandra has native uh Tool uh to uh wipe out old data if you don't need it so for example if you define what you're not going to need temperature recordings for longer than uh for uh for one year or more uh you can creating or writing data you can specify GTL time to leave so this data will be automatically deleted then this time is expired which is pretty cool uh and uh but in some scenarios you do need to keep data for longer times and you do want to keep it still under control in some scenarios you indeed may want to unload some old data put it on AWS S3 or some another kind of a cold storage if you are not going to access it often and you will be fine with that but the story is you don't necessarily have to like if you're going to really read this data from time to time and access this data from time to time then it may be perfectly fine to just uh keep it better as long as your partitions are designed it well and you need to store more data don't forget you want to store more data add more nodes and it will be scaled automatically that is uh like very typical thing good question from Andrei there is a tool for archiving gesture so um two recently uh our published well cow recently some years ago were published by data Stacks call it DS bulk uh Diaz bulk for some scenarios you might want to use a patch spark to get some more advanced access to data um yeah and things like that uh thank you so much for uh thank you so much to Jeff Kumar for your kind words yeah Billy do we do have all the recordings for this and other workshops same link so coming in after some data is deleted how is that reordered on the physical level oh great question Evo rumbaldem a very good question that's completely out of scope for today's Workshop but in short there is a process similar to vacuuming in relational databases uh call it um compassion compaction comes in order um regularly to clean up deleted data to clean up um updated information what is not in the previous version the story is like a U.S state do you you are here every past you have a very very end even out even over time so I want to open some secrets story is Cassandra is extremely fast for rights but it requires requires some very Advanced optimizations on right buff then you write data some very Advanced temporary optimizations one of them um very interesting take a look in Cassandra insert update and delete exactly the same operation internally now you might be surprised insert or update our same operation okay that's understandable but how come Delete is the same operation the story is when we write data what is the slowest operation in software development in software uh operations in general it's changing data on disk any kind of disk operations but especially changing something so you need to find you need to update you need to move like a lot of things it's slow Cassandra designed it to be very fast so every time you do anything any mutation with your data it's always append only operation what goes on the bottom let's say of things and uh over time you get info formation uh like uh being stored too much time first value update for the same value update for the same value and then finally it's deleted you don't sell these uh think anymore and you don't want to store its data and you want to retrieve some disk space that as a result it will be original value new value next value and dump Stone dump stone is a special marker what this data has been deleted so you have basically poor entries for the same data although technically it's kind of deleted compaction is the process what takes these immutable files those files are called SS tables um sorted string table files and then it makes compaction on them removing all the old values removing all the dumb Stones deleting all data and writing a new file on disk which now will be it alone and the old files will be deleted this process happens in background uh so uh you don't encounter it when you originally write on read date it happens in background um and that is a story how insert update and delete are the same operation internally and that is just one of the many cool uh optimizations inside the Cassandra I hope I answered this question evil what happened if there is a Mis inconsistent data read is there a way to acknowledge or recover so when we read data so it depends on your consistency level if you read datum and then you require consistency level Quorum or all or can see any consistency level high enough and then node sees query coordinator sees what someone is outdated then query coordinator will initiate repair and consistency will be recovered it happens in background it's automated um but if you read with consistency level low if you read with consistency level 1 for example and your node stores in consistent information then you will get inconsistent information and that might happen if you use two upgrades of consistency levels like one for example so you have to be careful with that um does this method not preserve a meant order um so this method compaction indeed preserves cement order it preserves the order defined by clustering columns does Cassandra support updating multiple roles in a single query a short answer is it's complicated because you see if roads are in different partitions they will belong to different servers and that is going to be a totally different story so you can actually Arjun if I'm trying to make an update I have to specify partition key yeah well so yes answer is yes yes well well uh okay so it's not gonna be in One update statement so you you will have to issue multiple updates state state statements but uh the internally if those update or insert statements belong to the same partition internal optimization will do that update as as one single single update even so you issued multiple update statements and there is a corner case uh static columns if you update a static column in in in the partition all rows will be affected yeah so short answer is yes uh good so it looks like there are no more questions then I proceed to the very last slide what's next homework is to finish the Hands-On lab and submit your uh homework for this Workshop using the link which is mentioned in the GitHub repo you will find it in the homework part uh links you might want to have our Discord server to talk to us and to have us answering your questions in between of workshops esport I'm showing it https um yep Academy so if you decide what yes you want to work with Cassandra it's powerful it probably going to make me some money and very interesting technology to work with then you can proceed at the academy.dentastacks.com to get your developer path or administrator path and get certified for free link for the workshops is on the screen see you next week uh one more time if okay in case you missed that I posted already links to our LinkedIn so if you aren't in then please jump in and add us on LinkedIn always pleasure to answer your questions uh with that that was our job and Alex wolship thank you thank you for being with us and see you next week then it will be a comment uh who will be with you tomorrow or next week we won the chat today yes yeah and uh a great expert book author or like one of the best experts in the Cassandra field so you are like him then uh good luck so don't forget to submit your homework and see you next week see you next week thank you",
    "segments": [
      {
        "start": 0.2,
        "duration": 7.59,
        "text": "[Music]"
      },
      {
        "start": 8.72,
        "duration": 24.64,
        "text": "thank you"
      },
      {
        "start": 10.08,
        "duration": 23.28,
        "text": "[Music]"
      },
      {
        "start": 37.68,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 41.36,
        "duration": 31.39,
        "text": "[Music]"
      },
      {
        "start": 75.36,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 80.37,
        "duration": 22.429,
        "text": "[Music]"
      },
      {
        "start": 105.94,
        "duration": 8.2,
        "text": "[Music]"
      },
      {
        "start": 118.1,
        "duration": 7.56,
        "text": "thank you"
      },
      {
        "start": 119.79,
        "duration": 5.87,
        "text": "[Music]"
      },
      {
        "start": 136.5,
        "duration": 2.48,
        "text": "thank you"
      },
      {
        "start": 139.48,
        "duration": 4.49,
        "text": "[Music]"
      },
      {
        "start": 141.9,
        "duration": 30.119,
        "text": "foreign"
      },
      {
        "start": 143.97,
        "duration": 31.049,
        "text": "[Music]"
      },
      {
        "start": 172.019,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 175.08,
        "duration": 35.82,
        "text": "[Music]"
      },
      {
        "start": 207.9,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 212.25,
        "duration": 29.64,
        "text": "[Music]"
      },
      {
        "start": 239.819,
        "duration": 11.69,
        "text": "foreign"
      },
      {
        "start": 241.89,
        "duration": 9.619,
        "text": "[Music]"
      },
      {
        "start": 273.3,
        "duration": 5.399,
        "text": "foreign"
      },
      {
        "start": 275.87,
        "duration": 5.35,
        "text": "[Music]"
      },
      {
        "start": 278.699,
        "duration": 7.021,
        "text": "hey"
      },
      {
        "start": 281.22,
        "duration": 7.44,
        "text": "one two three one two three if you can"
      },
      {
        "start": 285.72,
        "duration": 4.919,
        "text": "hear us if you can see us please set the"
      },
      {
        "start": 288.66,
        "duration": 5.479,
        "text": "thumbs up in the YouTube chat"
      },
      {
        "start": 290.639,
        "duration": 3.5,
        "text": "so we know we can start"
      },
      {
        "start": 294.419,
        "duration": 5.641,
        "text": "we hello everyone yep hi hi Tom"
      },
      {
        "start": 298.62,
        "duration": 4.44,
        "text": "hi Alex"
      },
      {
        "start": 300.06,
        "duration": 6.66,
        "text": "that's yeah looks like we are good at hi"
      },
      {
        "start": 303.06,
        "duration": 5.4,
        "text": "pravajal uh prajaval sorry Laura hi"
      },
      {
        "start": 306.72,
        "duration": 4.68,
        "text": "Billy Alessandro"
      },
      {
        "start": 308.46,
        "duration": 5.16,
        "text": "perfect perfect many people many dozens"
      },
      {
        "start": 311.4,
        "duration": 3.299,
        "text": "of people actually today with us that is"
      },
      {
        "start": 313.62,
        "duration": 2.7,
        "text": "amazing"
      },
      {
        "start": 314.699,
        "duration": 4.621,
        "text": "cool skit"
      },
      {
        "start": 316.32,
        "duration": 5.64,
        "text": "so looks like we are good so with that I"
      },
      {
        "start": 319.32,
        "duration": 3.54,
        "text": "want to start immediately because we"
      },
      {
        "start": 321.96,
        "duration": 2.34,
        "text": "have"
      },
      {
        "start": 322.86,
        "duration": 4.2,
        "text": "so"
      },
      {
        "start": 324.3,
        "duration": 5.04,
        "text": "I have a lot of topics yeah so many"
      },
      {
        "start": 327.06,
        "duration": 6.06,
        "text": "topics to cover we want it to be very"
      },
      {
        "start": 329.34,
        "duration": 7.079,
        "text": "intensive you came to learn so let's go"
      },
      {
        "start": 333.12,
        "duration": 6.06,
        "text": "with that right now uh that is the first"
      },
      {
        "start": 336.419,
        "duration": 6.0,
        "text": "Workshop in boot camp application"
      },
      {
        "start": 339.18,
        "duration": 7.5,
        "text": "development series which will consist of"
      },
      {
        "start": 342.419,
        "duration": 5.881,
        "text": "free workshops first one is today I hope"
      },
      {
        "start": 346.68,
        "duration": 4.44,
        "text": "you watch it live if you watch it"
      },
      {
        "start": 348.3,
        "duration": 5.52,
        "text": "recorded no big deal then"
      },
      {
        "start": 351.12,
        "duration": 6.06,
        "text": "um because we you still can get"
      },
      {
        "start": 353.82,
        "duration": 5.7,
        "text": "everything from this boot camp"
      },
      {
        "start": 357.18,
        "duration": 4.26,
        "text": "um some more links coming soon so you"
      },
      {
        "start": 359.52,
        "duration": 5.34,
        "text": "can stay in touch with us"
      },
      {
        "start": 361.44,
        "duration": 5.819,
        "text": "first Workshop we want to focus on nosql"
      },
      {
        "start": 364.86,
        "duration": 4.619,
        "text": "databases or to be more particular on"
      },
      {
        "start": 367.259,
        "duration": 5.22,
        "text": "one specific nosql database call it"
      },
      {
        "start": 369.479,
        "duration": 5.701,
        "text": "Apache Cassandra uh it's one of the most"
      },
      {
        "start": 372.479,
        "duration": 5.101,
        "text": "powerful and scalable databases in the"
      },
      {
        "start": 375.18,
        "duration": 5.459,
        "text": "world used by few just companies we will"
      },
      {
        "start": 377.58,
        "duration": 6.3,
        "text": "discuss it soon so that one really helps"
      },
      {
        "start": 380.639,
        "duration": 5.28,
        "text": "you to build a high growth High scale"
      },
      {
        "start": 383.88,
        "duration": 3.96,
        "text": "Global applications available from"
      },
      {
        "start": 385.919,
        "duration": 3.301,
        "text": "customer for customers from all around"
      },
      {
        "start": 387.84,
        "duration": 3.18,
        "text": "the world"
      },
      {
        "start": 389.22,
        "duration": 4.979,
        "text": "second Workshop"
      },
      {
        "start": 391.02,
        "duration": 6.36,
        "text": "will be about data modeling today with"
      },
      {
        "start": 394.199,
        "duration": 9.081,
        "text": "me and then at the next week you see"
      },
      {
        "start": 397.38,
        "duration": 9.96,
        "text": "artwork PhD who developed data modeling"
      },
      {
        "start": 403.28,
        "duration": 6.039,
        "text": "methodology for nosql databases so how"
      },
      {
        "start": 407.34,
        "duration": 4.62,
        "text": "do you build data model for applications"
      },
      {
        "start": 409.319,
        "duration": 5.16,
        "text": "this way so your applications will be"
      },
      {
        "start": 411.96,
        "duration": 5.76,
        "text": "efficient we'll stay efficient under any"
      },
      {
        "start": 414.479,
        "duration": 4.861,
        "text": "workloads even working with hundreds"
      },
      {
        "start": 417.72,
        "duration": 4.62,
        "text": "millions of customers"
      },
      {
        "start": 419.34,
        "duration": 5.699,
        "text": "and then at the third Workshop we put it"
      },
      {
        "start": 422.34,
        "duration": 5.579,
        "text": "all together with the database with the"
      },
      {
        "start": 425.039,
        "duration": 5.22,
        "text": "proper data model with applications"
      },
      {
        "start": 427.919,
        "duration": 4.5,
        "text": "and make it a real life running"
      },
      {
        "start": 430.259,
        "duration": 4.681,
        "text": "application deployed and see it in"
      },
      {
        "start": 432.419,
        "duration": 4.861,
        "text": "progress and you can pick language of"
      },
      {
        "start": 434.94,
        "duration": 5.9,
        "text": "your choice so I believe most of you"
      },
      {
        "start": 437.28,
        "duration": 6.06,
        "text": "familiar with python Java or JavaScript"
      },
      {
        "start": 440.84,
        "duration": 4.24,
        "text": "and you can pick a language of your"
      },
      {
        "start": 443.34,
        "duration": 4.44,
        "text": "choice of this list"
      },
      {
        "start": 445.08,
        "duration": 5.64,
        "text": "so let's go"
      },
      {
        "start": 447.78,
        "duration": 5.46,
        "text": "uh I'm developer Advocate lead at data"
      },
      {
        "start": 450.72,
        "duration": 4.8,
        "text": "Stacks Alex Volusia my job is to help"
      },
      {
        "start": 453.24,
        "duration": 4.26,
        "text": "developers not fail with Advanced"
      },
      {
        "start": 455.52,
        "duration": 3.32,
        "text": "distributed Technologies like Apache"
      },
      {
        "start": 457.5,
        "duration": 4.62,
        "text": "Cassandra"
      },
      {
        "start": 458.84,
        "duration": 8.22,
        "text": "and you will meet me multiple times"
      },
      {
        "start": 462.12,
        "duration": 7.68,
        "text": "during this boot camp today with me uh"
      },
      {
        "start": 467.06,
        "duration": 5.68,
        "text": "could you please introduce yourself"
      },
      {
        "start": 469.8,
        "duration": 5.64,
        "text": "yes sure hi everyone I'm glad to be here"
      },
      {
        "start": 472.74,
        "duration": 5.22,
        "text": "so um I have 10 years experience of"
      },
      {
        "start": 475.44,
        "duration": 5.039,
        "text": "working with Cassandra and I like uh"
      },
      {
        "start": 477.96,
        "duration": 4.139,
        "text": "like Alex mentioned already I authored"
      },
      {
        "start": 480.479,
        "duration": 4.141,
        "text": "the Cassandra data modern methodology"
      },
      {
        "start": 482.099,
        "duration": 6.301,
        "text": "we're gonna talk about it next week this"
      },
      {
        "start": 484.62,
        "duration": 7.139,
        "text": "week I'm helping with the Hands-On and a"
      },
      {
        "start": 488.4,
        "duration": 7.199,
        "text": "couple of sessions related to"
      },
      {
        "start": 491.759,
        "duration": 7.62,
        "text": "um capsirium and some other stuff"
      },
      {
        "start": 495.599,
        "duration": 6.061,
        "text": "cool so uh but this session is not about"
      },
      {
        "start": 499.379,
        "duration": 5.701,
        "text": "us so let's move on"
      },
      {
        "start": 501.66,
        "duration": 7.08,
        "text": "a little bit of explanation we believe"
      },
      {
        "start": 505.08,
        "duration": 7.379,
        "text": "in Hands-On practical education we don't"
      },
      {
        "start": 508.74,
        "duration": 5.46,
        "text": "believe in just the boring theory that"
      },
      {
        "start": 512.459,
        "duration": 4.681,
        "text": "means what you will need to push some"
      },
      {
        "start": 514.2,
        "duration": 5.16,
        "text": "buttons it's all free and available for"
      },
      {
        "start": 517.14,
        "duration": 4.319,
        "text": "everyone as all the software we are"
      },
      {
        "start": 519.36,
        "duration": 4.44,
        "text": "using will be running in a cloud"
      },
      {
        "start": 521.459,
        "duration": 4.801,
        "text": "so you can do it basically with whatever"
      },
      {
        "start": 523.8,
        "duration": 4.74,
        "text": "laptop or PC you have"
      },
      {
        "start": 526.26,
        "duration": 5.16,
        "text": "everything all the materials for The"
      },
      {
        "start": 528.54,
        "duration": 5.52,
        "text": "Bootcamp is available on GitHub it's all"
      },
      {
        "start": 531.42,
        "duration": 4.919,
        "text": "open source you can use it in any moment"
      },
      {
        "start": 534.06,
        "duration": 7.14,
        "text": "send it to your friend whatever"
      },
      {
        "start": 536.339,
        "duration": 7.62,
        "text": "then uh to uh develop it and to run it"
      },
      {
        "start": 541.2,
        "duration": 6.06,
        "text": "to make it operational we will use"
      },
      {
        "start": 543.959,
        "duration": 5.701,
        "text": "gitbot gitbot is a great platform so you"
      },
      {
        "start": 547.26,
        "duration": 4.56,
        "text": "can develop code right in your browser"
      },
      {
        "start": 549.66,
        "duration": 4.2,
        "text": "and you don't have to install ID you"
      },
      {
        "start": 551.82,
        "duration": 5.04,
        "text": "don't have to run it locally"
      },
      {
        "start": 553.86,
        "duration": 5.64,
        "text": "so it's like I really love it and it"
      },
      {
        "start": 556.86,
        "duration": 6.06,
        "text": "helps developers a lot and then finally"
      },
      {
        "start": 559.5,
        "duration": 5.88,
        "text": "to avoid deploying Cassandra clusters"
      },
      {
        "start": 562.92,
        "duration": 5.76,
        "text": "and running everything on your own"
      },
      {
        "start": 565.38,
        "duration": 5.88,
        "text": "machine which well software we are going"
      },
      {
        "start": 568.68,
        "duration": 5.64,
        "text": "to run is quite demanding in the points"
      },
      {
        "start": 571.26,
        "duration": 5.519,
        "text": "of resources points of view we will be"
      },
      {
        "start": 574.32,
        "duration": 4.56,
        "text": "using astrodb astrodb is a budget"
      },
      {
        "start": 576.779,
        "duration": 4.62,
        "text": "Cassandra in the cloud it has very"
      },
      {
        "start": 578.88,
        "duration": 4.56,
        "text": "generous free tier so again it's free"
      },
      {
        "start": 581.399,
        "duration": 4.921,
        "text": "you don't pay anything for that"
      },
      {
        "start": 583.44,
        "duration": 4.62,
        "text": "and we will use multiple features of"
      },
      {
        "start": 586.32,
        "duration": 3.959,
        "text": "Apache Cassandra if you are already"
      },
      {
        "start": 588.06,
        "duration": 4.2,
        "text": "familiar with this database you can"
      },
      {
        "start": 590.279,
        "duration": 4.921,
        "text": "deploy it locally and do all the same"
      },
      {
        "start": 592.26,
        "duration": 6.0,
        "text": "exercises but to simplify maintenance"
      },
      {
        "start": 595.2,
        "duration": 4.8,
        "text": "and our help to you during the workshop"
      },
      {
        "start": 598.26,
        "duration": 3.66,
        "text": "we will be using"
      },
      {
        "start": 600.0,
        "duration": 4.2,
        "text": "Cloud deployment"
      },
      {
        "start": 601.92,
        "duration": 5.64,
        "text": "this Workshop you know is developers"
      },
      {
        "start": 604.2,
        "duration": 6.42,
        "text": "focused not operations Focus"
      },
      {
        "start": 607.56,
        "duration": 5.64,
        "text": "um if you complete for each Workshop of"
      },
      {
        "start": 610.62,
        "duration": 5.279,
        "text": "this series you complete you can get a"
      },
      {
        "start": 613.2,
        "duration": 4.86,
        "text": "special page to break on LinkedIn or"
      },
      {
        "start": 615.899,
        "duration": 4.581,
        "text": "Facebook or whatever social network you"
      },
      {
        "start": 618.06,
        "duration": 5.52,
        "text": "use if you would like to get some"
      },
      {
        "start": 620.48,
        "duration": 5.68,
        "text": "acknowledgments some achievements then"
      },
      {
        "start": 623.58,
        "duration": 5.34,
        "text": "that is totally possible to do that you"
      },
      {
        "start": 626.16,
        "duration": 5.82,
        "text": "will need to do two things first uh"
      },
      {
        "start": 628.92,
        "duration": 5.16,
        "text": "first watch these Workshop live or"
      },
      {
        "start": 631.98,
        "duration": 3.539,
        "text": "recorded this and all the follow-up"
      },
      {
        "start": 634.08,
        "duration": 4.14,
        "text": "workshops"
      },
      {
        "start": 635.519,
        "duration": 5.461,
        "text": "and second complete the Hands-On part"
      },
      {
        "start": 638.22,
        "duration": 6.059,
        "text": "you can do it with artem during this"
      },
      {
        "start": 640.98,
        "duration": 7.02,
        "text": "Workshop or after that on your own free"
      },
      {
        "start": 644.279,
        "duration": 6.0,
        "text": "time later it's also supported by us and"
      },
      {
        "start": 648.0,
        "duration": 6.06,
        "text": "submit this as a homework more details"
      },
      {
        "start": 650.279,
        "duration": 6.12,
        "text": "coming in the end of the workshop"
      },
      {
        "start": 654.06,
        "duration": 4.14,
        "text": "and with that I want to ask few"
      },
      {
        "start": 656.399,
        "duration": 5.581,
        "text": "questions about you"
      },
      {
        "start": 658.2,
        "duration": 5.819,
        "text": "we will use medium and mentee is a"
      },
      {
        "start": 661.98,
        "duration": 6.0,
        "text": "platform for us to ask questions to you"
      },
      {
        "start": 664.019,
        "duration": 6.901,
        "text": "and you can answer life to join our quiz"
      },
      {
        "start": 667.98,
        "duration": 4.14,
        "text": "please scan the QR code or you see on"
      },
      {
        "start": 670.92,
        "duration": 5.039,
        "text": "the screen"
      },
      {
        "start": 672.12,
        "duration": 6.779,
        "text": "or just go to mentee.com and enter the"
      },
      {
        "start": 675.959,
        "duration": 4.801,
        "text": "code again you see on the screen easiest"
      },
      {
        "start": 678.899,
        "duration": 5.341,
        "text": "way and the most recommended way to do"
      },
      {
        "start": 680.76,
        "duration": 6.66,
        "text": "it is just to use your mobile phone"
      },
      {
        "start": 684.24,
        "duration": 4.62,
        "text": "it's uh like the most convenient way to"
      },
      {
        "start": 687.42,
        "duration": 3.359,
        "text": "use"
      },
      {
        "start": 688.86,
        "duration": 3.3,
        "text": "the"
      },
      {
        "start": 690.779,
        "duration": 3.361,
        "text": "main team"
      },
      {
        "start": 692.16,
        "duration": 4.5,
        "text": "but I see people are joining so let's"
      },
      {
        "start": 694.14,
        "duration": 4.199,
        "text": "start I don't want to wait for too long"
      },
      {
        "start": 696.66,
        "duration": 4.26,
        "text": "uh"
      },
      {
        "start": 698.339,
        "duration": 4.68,
        "text": "first question I want to know how"
      },
      {
        "start": 700.92,
        "duration": 5.88,
        "text": "experienced you are so what's your"
      },
      {
        "start": 703.019,
        "duration": 7.56,
        "text": "experience with relational databases"
      },
      {
        "start": 706.8,
        "duration": 5.279,
        "text": "okay so we see people of different"
      },
      {
        "start": 710.579,
        "duration": 4.38,
        "text": "experience"
      },
      {
        "start": 712.079,
        "duration": 5.641,
        "text": "very well if you didn't join yet you can"
      },
      {
        "start": 714.959,
        "duration": 6.62,
        "text": "see instructions on top of the screen go"
      },
      {
        "start": 717.72,
        "duration": 7.32,
        "text": "to manchester.com and use the code"
      },
      {
        "start": 721.579,
        "duration": 6.82,
        "text": "6291-8600 we will ask questions during"
      },
      {
        "start": 725.04,
        "duration": 4.68,
        "text": "the workshop so you better please join"
      },
      {
        "start": 728.399,
        "duration": 4.44,
        "text": "okay"
      },
      {
        "start": 729.72,
        "duration": 5.66,
        "text": "I see with us some software developers"
      },
      {
        "start": 732.839,
        "duration": 6.541,
        "text": "mostly probably and I guess some"
      },
      {
        "start": 735.38,
        "duration": 7.06,
        "text": "students if you have no experience with"
      },
      {
        "start": 739.38,
        "duration": 6.24,
        "text": "relational databases this one might be a"
      },
      {
        "start": 742.44,
        "duration": 6.36,
        "text": "little bit rough right because well no"
      },
      {
        "start": 745.62,
        "duration": 6.3,
        "text": "SQL databases experience often base it"
      },
      {
        "start": 748.8,
        "duration": 6.3,
        "text": "on SQL databases experience right but"
      },
      {
        "start": 751.92,
        "duration": 5.88,
        "text": "still keep learning keep doing even if"
      },
      {
        "start": 755.1,
        "duration": 6.0,
        "text": "you are now just Zero by the end of this"
      },
      {
        "start": 757.8,
        "duration": 5.88,
        "text": "series you will have running application"
      },
      {
        "start": 761.1,
        "duration": 5.039,
        "text": "and you will get better understanding of"
      },
      {
        "start": 763.68,
        "duration": 4.86,
        "text": "how database and nosql databases work"
      },
      {
        "start": 766.139,
        "duration": 5.221,
        "text": "don't hesitate to ask questions on the"
      },
      {
        "start": 768.54,
        "duration": 5.28,
        "text": "YouTube chat or on Discord versus Cedric"
      },
      {
        "start": 771.36,
        "duration": 3.96,
        "text": "will event to answer questions and we"
      },
      {
        "start": 773.82,
        "duration": 5.04,
        "text": "will do our best to answer those"
      },
      {
        "start": 775.32,
        "duration": 5.16,
        "text": "questions as well now next question do"
      },
      {
        "start": 778.86,
        "duration": 4.86,
        "text": "you already have experience with any"
      },
      {
        "start": 780.48,
        "duration": 5.94,
        "text": "nosql databases"
      },
      {
        "start": 783.72,
        "duration": 5.34,
        "text": "okay so I see some people get some"
      },
      {
        "start": 786.42,
        "duration": 4.919,
        "text": "experience that is good if you have no"
      },
      {
        "start": 789.06,
        "duration": 5.64,
        "text": "experience then congratulations because"
      },
      {
        "start": 791.339,
        "duration": 6.661,
        "text": "you are right in the right place to be"
      },
      {
        "start": 794.7,
        "duration": 5.579,
        "text": "to learn something nosql world is great"
      },
      {
        "start": 798.0,
        "duration": 4.98,
        "text": "and very interesting many powerful and"
      },
      {
        "start": 800.279,
        "duration": 6.481,
        "text": "interesting Technologies"
      },
      {
        "start": 802.98,
        "duration": 5.88,
        "text": "and today I will we will introduce you"
      },
      {
        "start": 806.76,
        "duration": 6.18,
        "text": "one of the best of them"
      },
      {
        "start": 808.86,
        "duration": 7.58,
        "text": "uh for the Discord link I will send you"
      },
      {
        "start": 812.94,
        "duration": 6.74,
        "text": "a link the ps6"
      },
      {
        "start": 816.44,
        "duration": 6.519,
        "text": "record and https"
      },
      {
        "start": 819.68,
        "duration": 6.82,
        "text": "that is a link to our Discord server"
      },
      {
        "start": 822.959,
        "duration": 5.82,
        "text": "and homework it's explained at the"
      },
      {
        "start": 826.5,
        "duration": 4.92,
        "text": "GitHub repository link posted by"
      },
      {
        "start": 828.779,
        "duration": 5.761,
        "text": "nightbot just a couple of messages above"
      },
      {
        "start": 831.42,
        "duration": 6.719,
        "text": "GitHub data Stacks devs Workshop"
      },
      {
        "start": 834.54,
        "duration": 6.599,
        "text": "yep thank you Cedric good so"
      },
      {
        "start": 838.139,
        "duration": 4.921,
        "text": "very well uh welcome you are on the"
      },
      {
        "start": 841.139,
        "duration": 5.161,
        "text": "right place to be right now"
      },
      {
        "start": 843.06,
        "duration": 5.579,
        "text": "then finally where are you now like it's"
      },
      {
        "start": 846.3,
        "duration": 6.0,
        "text": "very curious from how many countries we"
      },
      {
        "start": 848.639,
        "duration": 6.481,
        "text": "have people that the same Workshop"
      },
      {
        "start": 852.3,
        "duration": 5.339,
        "text": "but how Global is our world isn't that"
      },
      {
        "start": 855.12,
        "duration": 7.519,
        "text": "amazing okay looks like someone is on"
      },
      {
        "start": 857.639,
        "duration": 9.061,
        "text": "the ship uh have a good uh travel"
      },
      {
        "start": 862.639,
        "duration": 6.7,
        "text": "uh some people from Europe I see UK I"
      },
      {
        "start": 866.7,
        "duration": 5.28,
        "text": "see Africa amazing I see United States"
      },
      {
        "start": 869.339,
        "duration": 5.821,
        "text": "of course pretty much expected a lot uh"
      },
      {
        "start": 871.98,
        "duration": 5.7,
        "text": "people from India Africa again cool"
      },
      {
        "start": 875.16,
        "duration": 5.52,
        "text": "any Australians Australians must be"
      },
      {
        "start": 877.68,
        "duration": 4.08,
        "text": "sleeping right now okay okay it's deep"
      },
      {
        "start": 880.68,
        "duration": 4.019,
        "text": "night"
      },
      {
        "start": 881.76,
        "duration": 4.68,
        "text": "oh not Auckland California not too far"
      },
      {
        "start": 884.699,
        "duration": 2.841,
        "text": "from data Stacks headquarters welcome"
      },
      {
        "start": 886.44,
        "duration": 3.3,
        "text": "welcome"
      },
      {
        "start": 887.54,
        "duration": 5.76,
        "text": "uh cool"
      },
      {
        "start": 889.74,
        "duration": 7.08,
        "text": "so very well and then final question"
      },
      {
        "start": 893.3,
        "duration": 5.62,
        "text": "database you use the most or maybe if"
      },
      {
        "start": 896.82,
        "duration": 5.579,
        "text": "you're a student the only database you"
      },
      {
        "start": 898.92,
        "duration": 7.62,
        "text": "know so far also will work to me hey"
      },
      {
        "start": 902.399,
        "duration": 6.601,
        "text": "Aaron uh Aeron plots is in the chat he"
      },
      {
        "start": 906.54,
        "duration": 5.46,
        "text": "is one of the best in Cassandra experts"
      },
      {
        "start": 909.0,
        "duration": 4.68,
        "text": "and I'm adding him as a moderator by the"
      },
      {
        "start": 912.0,
        "duration": 5.339,
        "text": "way beware"
      },
      {
        "start": 913.68,
        "duration": 7.86,
        "text": "good also so MySQL Oracle pretty"
      },
      {
        "start": 917.339,
        "duration": 6.661,
        "text": "much expected well well well well good"
      },
      {
        "start": 921.54,
        "duration": 5.159,
        "text": "postgres again oh there are some people"
      },
      {
        "start": 924.0,
        "duration": 5.399,
        "text": "using Cassandra already nice I see"
      },
      {
        "start": 926.699,
        "duration": 5.161,
        "text": "Dynamite beam well so there is a quite"
      },
      {
        "start": 929.399,
        "duration": 5.521,
        "text": "plenty of different databases MySQL"
      },
      {
        "start": 931.86,
        "duration": 5.94,
        "text": "stays number one so far uh with some"
      },
      {
        "start": 934.92,
        "duration": 5.3,
        "text": "value uh significant part of and"
      },
      {
        "start": 937.8,
        "duration": 2.42,
        "text": "that is great"
      },
      {
        "start": 940.38,
        "duration": 4.8,
        "text": "uh the most funniest part about nosql is"
      },
      {
        "start": 943.62,
        "duration": 3.959,
        "text": "what it's actually pretty bad definition"
      },
      {
        "start": 945.18,
        "duration": 5.88,
        "text": "because it tries to group very different"
      },
      {
        "start": 947.579,
        "duration": 6.06,
        "text": "databases mongodb is a great database I"
      },
      {
        "start": 951.06,
        "duration": 5.94,
        "text": "was using for use and I like it"
      },
      {
        "start": 953.639,
        "duration": 5.281,
        "text": "and uh Cassandra is a great database I"
      },
      {
        "start": 957.0,
        "duration": 4.38,
        "text": "love it and I use it also for many years"
      },
      {
        "start": 958.92,
        "duration": 4.26,
        "text": "but there's a totally different we"
      },
      {
        "start": 961.38,
        "duration": 4.38,
        "text": "shouldn't group together I know"
      },
      {
        "start": 963.18,
        "duration": 4.98,
        "text": "submarines and spaceships those are"
      },
      {
        "start": 965.76,
        "duration": 5.1,
        "text": "different for different purposes today"
      },
      {
        "start": 968.16,
        "duration": 4.56,
        "text": "those if you use already you will"
      },
      {
        "start": 970.86,
        "duration": 4.08,
        "text": "be introduced to your second nosql"
      },
      {
        "start": 972.72,
        "duration": 4.799,
        "text": "database and that is great oh I see"
      },
      {
        "start": 974.94,
        "duration": 3.899,
        "text": "people working with teradata interesting"
      },
      {
        "start": 977.519,
        "duration": 3.32,
        "text": "good"
      },
      {
        "start": 978.839,
        "duration": 6.541,
        "text": "so with that beginning"
      },
      {
        "start": 980.839,
        "duration": 6.841,
        "text": "ends and we will proceed to the next"
      },
      {
        "start": 985.38,
        "duration": 2.3,
        "text": "part"
      },
      {
        "start": 989.04,
        "duration": 5.64,
        "text": "um quick introduction"
      },
      {
        "start": 991.5,
        "duration": 6.24,
        "text": "how to use or how it works internally"
      },
      {
        "start": 994.68,
        "duration": 5.159,
        "text": "I'm focusing on the question how it"
      },
      {
        "start": 997.74,
        "duration": 4.74,
        "text": "works internally because you know what I"
      },
      {
        "start": 999.839,
        "duration": 3.781,
        "text": "want you to be software Engineers not"
      },
      {
        "start": 1002.48,
        "duration": 3.719,
        "text": "just"
      },
      {
        "start": 1003.62,
        "duration": 5.519,
        "text": "people pushing red button if red light"
      },
      {
        "start": 1006.199,
        "duration": 4.801,
        "text": "is blinking okay I need you to get some"
      },
      {
        "start": 1009.139,
        "duration": 4.26,
        "text": "internal understanding that What Makes"
      },
      {
        "start": 1011.0,
        "duration": 4.98,
        "text": "Us Engineers so today we speak a lot"
      },
      {
        "start": 1013.399,
        "duration": 5.041,
        "text": "about how it works internally and of"
      },
      {
        "start": 1015.98,
        "duration": 4.859,
        "text": "course we also work with how to use that"
      },
      {
        "start": 1018.44,
        "duration": 5.28,
        "text": "for sure you need to know how to use"
      },
      {
        "start": 1020.839,
        "duration": 5.701,
        "text": "that but that will be mostly for the"
      },
      {
        "start": 1023.72,
        "duration": 4.68,
        "text": "third Workshop today I want to get to"
      },
      {
        "start": 1026.54,
        "duration": 4.98,
        "text": "the internals"
      },
      {
        "start": 1028.4,
        "duration": 5.159,
        "text": "I'm just curious if in the chat people"
      },
      {
        "start": 1031.52,
        "duration": 5.279,
        "text": "can answer whether they"
      },
      {
        "start": 1033.559,
        "duration": 6.0,
        "text": "came to learn how to use it or how to"
      },
      {
        "start": 1036.799,
        "duration": 4.941,
        "text": "uh how it works internally it's one or"
      },
      {
        "start": 1039.559,
        "duration": 2.181,
        "text": "two"
      },
      {
        "start": 1042.439,
        "duration": 3.661,
        "text": "uh you want me to switch to a previous"
      },
      {
        "start": 1044.66,
        "duration": 4.38,
        "text": "slide"
      },
      {
        "start": 1046.1,
        "duration": 6.14,
        "text": "sure okay sure"
      },
      {
        "start": 1049.04,
        "duration": 6.12,
        "text": "it would be nice feedback from"
      },
      {
        "start": 1052.24,
        "duration": 6.819,
        "text": "attendees if if they can so they like"
      },
      {
        "start": 1055.16,
        "duration": 7.259,
        "text": "both that works internally"
      },
      {
        "start": 1059.059,
        "duration": 5.821,
        "text": "yeah actually both are important but I"
      },
      {
        "start": 1062.419,
        "duration": 5.701,
        "text": "see now many students rushing to use"
      },
      {
        "start": 1064.88,
        "duration": 4.86,
        "text": "without willingness to get understanding"
      },
      {
        "start": 1068.12,
        "duration": 5.22,
        "text": "of the"
      },
      {
        "start": 1069.74,
        "duration": 5.28,
        "text": "um under the hood Parts but it's very"
      },
      {
        "start": 1073.34,
        "duration": 4.68,
        "text": "important to understand how it works"
      },
      {
        "start": 1075.02,
        "duration": 5.159,
        "text": "internally you know how to use like we"
      },
      {
        "start": 1078.02,
        "duration": 4.38,
        "text": "can train a monkey in the advanced or"
      },
      {
        "start": 1080.179,
        "duration": 4.021,
        "text": "question how to use but how it works"
      },
      {
        "start": 1082.4,
        "duration": 4.32,
        "text": "internally that is something what makes"
      },
      {
        "start": 1084.2,
        "duration": 4.8,
        "text": "engineer yeah so thank you so much for"
      },
      {
        "start": 1086.72,
        "duration": 4.16,
        "text": "your answer yes we need to take care of"
      },
      {
        "start": 1089.0,
        "duration": 4.559,
        "text": "both"
      },
      {
        "start": 1090.88,
        "duration": 5.86,
        "text": "that is good that's a good answer right"
      },
      {
        "start": 1093.559,
        "duration": 6.261,
        "text": "yeah same again okay"
      },
      {
        "start": 1096.74,
        "duration": 3.08,
        "text": "so let's move on"
      },
      {
        "start": 1101.419,
        "duration": 7.201,
        "text": "um we now going to speak about why"
      },
      {
        "start": 1105.2,
        "duration": 6.18,
        "text": "Cassandra but that's not why because why"
      },
      {
        "start": 1108.62,
        "duration": 5.82,
        "text": "you should use Cassandra no no marketing"
      },
      {
        "start": 1111.38,
        "duration": 5.46,
        "text": "no selling beaches no no no no no"
      },
      {
        "start": 1114.44,
        "duration": 5.82,
        "text": "I want to answer a question first why"
      },
      {
        "start": 1116.84,
        "duration": 4.56,
        "text": "Cassandra was developed or invented if"
      },
      {
        "start": 1120.26,
        "duration": 4.98,
        "text": "you prefer"
      },
      {
        "start": 1121.4,
        "duration": 6.96,
        "text": "my point here is um"
      },
      {
        "start": 1125.24,
        "duration": 5.16,
        "text": "it's very important to understand the"
      },
      {
        "start": 1128.36,
        "duration": 5.46,
        "text": "reasons of the Technologies happen to be"
      },
      {
        "start": 1130.4,
        "duration": 5.76,
        "text": "because to build successful projects we"
      },
      {
        "start": 1133.82,
        "duration": 3.96,
        "text": "all even they are not Architects just"
      },
      {
        "start": 1136.16,
        "duration": 2.22,
        "text": "developers"
      },
      {
        "start": 1137.78,
        "duration": 3.36,
        "text": "um"
      },
      {
        "start": 1138.38,
        "duration": 6.12,
        "text": "junior or even maybe developers we all"
      },
      {
        "start": 1141.14,
        "duration": 6.48,
        "text": "need to think architecturally think as"
      },
      {
        "start": 1144.5,
        "duration": 6.419,
        "text": "an architect and to get that we need to"
      },
      {
        "start": 1147.62,
        "duration": 6.059,
        "text": "understand the reasons and internals and"
      },
      {
        "start": 1150.919,
        "duration": 5.701,
        "text": "whys of how these or very technology"
      },
      {
        "start": 1153.679,
        "duration": 5.041,
        "text": "works so here I'm going to answer a"
      },
      {
        "start": 1156.62,
        "duration": 3.9,
        "text": "question why Cassandra was invented or"
      },
      {
        "start": 1158.72,
        "duration": 4.44,
        "text": "developed"
      },
      {
        "start": 1160.52,
        "duration": 5.22,
        "text": "and to answer this question we are going"
      },
      {
        "start": 1163.16,
        "duration": 5.34,
        "text": "to get my time machine my DeLorean and"
      },
      {
        "start": 1165.74,
        "duration": 4.86,
        "text": "jump back to year 2008. not so long time"
      },
      {
        "start": 1168.5,
        "duration": 5.82,
        "text": "ago just 14 years ago"
      },
      {
        "start": 1170.6,
        "duration": 6.54,
        "text": "15 technically already has 15 good"
      },
      {
        "start": 1174.32,
        "duration": 5.34,
        "text": "so the story started in the year 2008"
      },
      {
        "start": 1177.14,
        "duration": 5.52,
        "text": "then Facebook reached their first 100"
      },
      {
        "start": 1179.66,
        "duration": 5.46,
        "text": "million users"
      },
      {
        "start": 1182.66,
        "duration": 5.58,
        "text": "and that is"
      },
      {
        "start": 1185.12,
        "duration": 5.7,
        "text": "a very big number now there are plenty"
      },
      {
        "start": 1188.24,
        "duration": 6.54,
        "text": "of companies with discount of customers"
      },
      {
        "start": 1190.82,
        "duration": 5.88,
        "text": "maybe even more people using that but I"
      },
      {
        "start": 1194.78,
        "duration": 4.2,
        "text": "believe Facebook was the very first one"
      },
      {
        "start": 1196.7,
        "duration": 5.04,
        "text": "to reach this number"
      },
      {
        "start": 1198.98,
        "duration": 5.76,
        "text": "and that wasn't just a very very big"
      },
      {
        "start": 1201.74,
        "duration": 5.939,
        "text": "number but more problems actually came"
      },
      {
        "start": 1204.74,
        "duration": 7.559,
        "text": "to a place to solve"
      },
      {
        "start": 1207.679,
        "duration": 8.88,
        "text": "and I would first mention four of them"
      },
      {
        "start": 1212.299,
        "duration": 8.341,
        "text": "users all around the world before most"
      },
      {
        "start": 1216.559,
        "duration": 6.721,
        "text": "of the businesses were all completely"
      },
      {
        "start": 1220.64,
        "duration": 4.74,
        "text": "local or Regional or at least we were"
      },
      {
        "start": 1223.28,
        "duration": 3.98,
        "text": "running as branches with not a lot of"
      },
      {
        "start": 1225.38,
        "duration": 6.06,
        "text": "cooperation in between"
      },
      {
        "start": 1227.26,
        "duration": 6.039,
        "text": "by these years already they were truly"
      },
      {
        "start": 1231.44,
        "duration": 4.979,
        "text": "global companies for example Facebook"
      },
      {
        "start": 1233.299,
        "duration": 4.081,
        "text": "second thing and that is a pretty big"
      },
      {
        "start": 1236.419,
        "duration": 3.12,
        "text": "thing"
      },
      {
        "start": 1237.38,
        "duration": 5.64,
        "text": "fast internet connection"
      },
      {
        "start": 1239.539,
        "duration": 6.061,
        "text": "now in year 2023 people start to think"
      },
      {
        "start": 1243.02,
        "duration": 4.56,
        "text": "like okay everyone hasn't we take it as"
      },
      {
        "start": 1245.6,
        "duration": 3.66,
        "text": "given okay fast internet connection"
      },
      {
        "start": 1247.58,
        "duration": 4.32,
        "text": "everyone has it"
      },
      {
        "start": 1249.26,
        "duration": 5.159,
        "text": "uh but that time it was a game changer"
      },
      {
        "start": 1251.9,
        "duration": 4.68,
        "text": "beforehand"
      },
      {
        "start": 1254.419,
        "duration": 5.221,
        "text": "your database wasn't a bottleneck"
      },
      {
        "start": 1256.58,
        "duration": 5.76,
        "text": "doesn't matter how fast your database if"
      },
      {
        "start": 1259.64,
        "duration": 4.68,
        "text": "a Last Mile internet connection from"
      },
      {
        "start": 1262.34,
        "duration": 3.9,
        "text": "internet service provider to your"
      },
      {
        "start": 1264.32,
        "duration": 3.599,
        "text": "customer will be slow anyway you don't"
      },
      {
        "start": 1266.24,
        "duration": 5.28,
        "text": "need fast database"
      },
      {
        "start": 1267.919,
        "duration": 5.541,
        "text": "it's okay he will wait anyway and now we"
      },
      {
        "start": 1271.52,
        "duration": 4.26,
        "text": "fast internet connections database"
      },
      {
        "start": 1273.46,
        "duration": 5.8,
        "text": "started to be"
      },
      {
        "start": 1275.78,
        "duration": 6.42,
        "text": "uh bottleneck so it changed a lot now"
      },
      {
        "start": 1279.26,
        "duration": 6.299,
        "text": "then a lot of data more and more datum"
      },
      {
        "start": 1282.2,
        "duration": 6.479,
        "text": "that the volume would never was uh in"
      },
      {
        "start": 1285.559,
        "duration": 5.461,
        "text": "action before and and finally with all"
      },
      {
        "start": 1288.679,
        "duration": 4.561,
        "text": "of these also new availability"
      },
      {
        "start": 1291.02,
        "duration": 4.68,
        "text": "requirements came if you ever heard"
      },
      {
        "start": 1293.24,
        "duration": 5.4,
        "text": "about SLA service level agreement"
      },
      {
        "start": 1295.7,
        "duration": 3.959,
        "text": "service level agreement means of how"
      },
      {
        "start": 1298.64,
        "duration": 4.14,
        "text": "many"
      },
      {
        "start": 1299.659,
        "duration": 5.161,
        "text": "or how fast your data how fast your"
      },
      {
        "start": 1302.78,
        "duration": 4.2,
        "text": "application should be or what this"
      },
      {
        "start": 1304.82,
        "duration": 4.62,
        "text": "should be uh uptime desire it for your"
      },
      {
        "start": 1306.98,
        "duration": 5.34,
        "text": "application when it must be available"
      },
      {
        "start": 1309.44,
        "duration": 6.0,
        "text": "and those slas for the performance for"
      },
      {
        "start": 1312.32,
        "duration": 5.46,
        "text": "like how can we responds should be"
      },
      {
        "start": 1315.44,
        "duration": 4.64,
        "text": "they also started to get more and more"
      },
      {
        "start": 1317.78,
        "duration": 2.3,
        "text": "strict"
      },
      {
        "start": 1320.48,
        "duration": 4.8,
        "text": "and uh"
      },
      {
        "start": 1322.7,
        "duration": 4.68,
        "text": "scaling applications"
      },
      {
        "start": 1325.28,
        "duration": 5.58,
        "text": "is a known problem and that is a"
      },
      {
        "start": 1327.38,
        "duration": 6.419,
        "text": "solvable problem but by that time real"
      },
      {
        "start": 1330.86,
        "duration": 5.34,
        "text": "problem was scaling of a database"
      },
      {
        "start": 1333.799,
        "duration": 4.38,
        "text": "so wherever no database like that we"
      },
      {
        "start": 1336.2,
        "duration": 3.66,
        "text": "were looking for a better database and"
      },
      {
        "start": 1338.179,
        "duration": 3.921,
        "text": "there were no way to get something like"
      },
      {
        "start": 1339.86,
        "duration": 2.24,
        "text": "that"
      },
      {
        "start": 1342.38,
        "duration": 6.12,
        "text": "um that what led to a creation of a new"
      },
      {
        "start": 1345.799,
        "duration": 5.641,
        "text": "database we are going to use today"
      },
      {
        "start": 1348.5,
        "duration": 5.76,
        "text": "but before developing a new product as"
      },
      {
        "start": 1351.44,
        "duration": 4.859,
        "text": "we have to think as Architects even when"
      },
      {
        "start": 1354.26,
        "duration": 3.779,
        "text": "we aren't we still need to think"
      },
      {
        "start": 1356.299,
        "duration": 3.721,
        "text": "architecturally we need to Define"
      },
      {
        "start": 1358.039,
        "duration": 4.38,
        "text": "requirements because without"
      },
      {
        "start": 1360.02,
        "duration": 4.32,
        "text": "requirements you are not going to build"
      },
      {
        "start": 1362.419,
        "duration": 4.38,
        "text": "any successful projects first you define"
      },
      {
        "start": 1364.34,
        "duration": 4.68,
        "text": "requirements and then based on these"
      },
      {
        "start": 1366.799,
        "duration": 3.981,
        "text": "requirements you make architectural"
      },
      {
        "start": 1369.02,
        "duration": 4.56,
        "text": "decisions"
      },
      {
        "start": 1370.78,
        "duration": 5.8,
        "text": "so let's first talk about what"
      },
      {
        "start": 1373.58,
        "duration": 6.02,
        "text": "requirements do we put on our database"
      },
      {
        "start": 1376.58,
        "duration": 5.82,
        "text": "management system first we speak about"
      },
      {
        "start": 1379.6,
        "duration": 5.199,
        "text": "globally distributed system with our"
      },
      {
        "start": 1382.4,
        "duration": 5.22,
        "text": "customers all around the world single"
      },
      {
        "start": 1384.799,
        "duration": 5.101,
        "text": "region deployment is no goal for us I"
      },
      {
        "start": 1387.62,
        "duration": 4.5,
        "text": "mean however fast even if your database"
      },
      {
        "start": 1389.9,
        "duration": 4.92,
        "text": "magically fast but it's deployed in"
      },
      {
        "start": 1392.12,
        "duration": 5.76,
        "text": "Australia and you are located near"
      },
      {
        "start": 1394.82,
        "duration": 4.92,
        "text": "Frankfurt you're going to wait for quite"
      },
      {
        "start": 1397.88,
        "duration": 4.679,
        "text": "some time you know we cannot beat light"
      },
      {
        "start": 1399.74,
        "duration": 4.14,
        "text": "of speed uh speed of light yet maybe in"
      },
      {
        "start": 1402.559,
        "duration": 3.901,
        "text": "the future"
      },
      {
        "start": 1403.88,
        "duration": 4.62,
        "text": "so we need to keep our database and our"
      },
      {
        "start": 1406.46,
        "duration": 6.06,
        "text": "applications close to our customers even"
      },
      {
        "start": 1408.5,
        "duration": 6.9,
        "text": "if they are in the Brazil or maybe I"
      },
      {
        "start": 1412.52,
        "duration": 3.84,
        "text": "don't know Japan or any region doesn't"
      },
      {
        "start": 1415.4,
        "duration": 3.42,
        "text": "matter"
      },
      {
        "start": 1416.36,
        "duration": 4.799,
        "text": "our database needs to be closed second"
      },
      {
        "start": 1418.82,
        "duration": 5.16,
        "text": "we are going to speak of volume and"
      },
      {
        "start": 1421.159,
        "duration": 5.161,
        "text": "velocity we are going to handle data of"
      },
      {
        "start": 1423.98,
        "duration": 4.38,
        "text": "any size and by any size I mean"
      },
      {
        "start": 1426.32,
        "duration": 4.44,
        "text": "petabytes of data"
      },
      {
        "start": 1428.36,
        "duration": 5.4,
        "text": "and also millions of queries per second"
      },
      {
        "start": 1430.76,
        "duration": 5.64,
        "text": "so we are developing a highly intensive"
      },
      {
        "start": 1433.76,
        "duration": 4.52,
        "text": "application what's in use by hundreds"
      },
      {
        "start": 1436.4,
        "duration": 5.88,
        "text": "millions of customers"
      },
      {
        "start": 1438.28,
        "duration": 6.16,
        "text": "well we need it to be very fast we have"
      },
      {
        "start": 1442.28,
        "duration": 4.44,
        "text": "very strict requirements on response"
      },
      {
        "start": 1444.44,
        "duration": 5.28,
        "text": "time basically response must be newly"
      },
      {
        "start": 1446.72,
        "duration": 5.04,
        "text": "immediate and then finally we have very"
      },
      {
        "start": 1449.72,
        "duration": 4.26,
        "text": "strict service level agreement on high"
      },
      {
        "start": 1451.76,
        "duration": 4.5,
        "text": "availability that means what our"
      },
      {
        "start": 1453.98,
        "duration": 4.199,
        "text": "database must be available most of the"
      },
      {
        "start": 1456.26,
        "duration": 4.919,
        "text": "time if you are familiar with knights"
      },
      {
        "start": 1458.179,
        "duration": 5.641,
        "text": "so-called definition of how many"
      },
      {
        "start": 1461.179,
        "duration": 6.36,
        "text": "how much time your database or"
      },
      {
        "start": 1463.82,
        "duration": 5.839,
        "text": "application must stay online we usually"
      },
      {
        "start": 1467.539,
        "duration": 5.101,
        "text": "speak about 4 9 so"
      },
      {
        "start": 1469.659,
        "duration": 4.981,
        "text": "99.99 persons it's called four nines"
      },
      {
        "start": 1472.64,
        "duration": 6.56,
        "text": "maybe five nines"
      },
      {
        "start": 1474.64,
        "duration": 7.12,
        "text": "99.99 persons of a time and so on so"
      },
      {
        "start": 1479.2,
        "duration": 5.56,
        "text": "requirements are going to be very strict"
      },
      {
        "start": 1481.76,
        "duration": 6.659,
        "text": "maybe six nines maybe even more"
      },
      {
        "start": 1484.76,
        "duration": 6.419,
        "text": "it's actually like few seconds per year"
      },
      {
        "start": 1488.419,
        "duration": 4.861,
        "text": "we can afford a downtime that benefit of"
      },
      {
        "start": 1491.179,
        "duration": 4.62,
        "text": "these requirements we start to speak"
      },
      {
        "start": 1493.28,
        "duration": 5.1,
        "text": "about architectural decisions we are"
      },
      {
        "start": 1495.799,
        "duration": 4.74,
        "text": "making on that so we speak about"
      },
      {
        "start": 1498.38,
        "duration": 5.159,
        "text": "geographical replication and we need our"
      },
      {
        "start": 1500.539,
        "duration": 5.461,
        "text": "data to be present everywhere that means"
      },
      {
        "start": 1503.539,
        "duration": 5.821,
        "text": "we will need to have multiple data"
      },
      {
        "start": 1506.0,
        "duration": 5.159,
        "text": "centers in different regions one one"
      },
      {
        "start": 1509.36,
        "duration": 4.92,
        "text": "data center maybe in the United States"
      },
      {
        "start": 1511.159,
        "duration": 6.061,
        "text": "maybe even two on different costs uh"
      },
      {
        "start": 1514.28,
        "duration": 5.1,
        "text": "data center in the South America data"
      },
      {
        "start": 1517.22,
        "duration": 4.5,
        "text": "center in Europe data send a couple of"
      },
      {
        "start": 1519.38,
        "duration": 3.12,
        "text": "data centers in Asia and so on and so"
      },
      {
        "start": 1521.72,
        "duration": 2.64,
        "text": "forth"
      },
      {
        "start": 1522.5,
        "duration": 3.72,
        "text": "and moreover"
      },
      {
        "start": 1524.36,
        "duration": 4.1,
        "text": "if you're familiar with relational"
      },
      {
        "start": 1526.22,
        "duration": 5.22,
        "text": "databases you know they can support"
      },
      {
        "start": 1528.46,
        "duration": 4.959,
        "text": "multi-dc deployments but that is very"
      },
      {
        "start": 1531.44,
        "duration": 4.14,
        "text": "typical for them to have active passive"
      },
      {
        "start": 1533.419,
        "duration": 3.0,
        "text": "so you have one single active Data"
      },
      {
        "start": 1535.58,
        "duration": 3.479,
        "text": "Center"
      },
      {
        "start": 1536.419,
        "duration": 5.701,
        "text": "where you can read and write data and"
      },
      {
        "start": 1539.059,
        "duration": 4.921,
        "text": "multiple one or more passive data"
      },
      {
        "start": 1542.12,
        "duration": 3.78,
        "text": "centers where you can read data but"
      },
      {
        "start": 1543.98,
        "duration": 4.92,
        "text": "cannot write it"
      },
      {
        "start": 1545.9,
        "duration": 5.519,
        "text": "in our case we need to overwrite data as"
      },
      {
        "start": 1548.9,
        "duration": 4.68,
        "text": "fast as we read the two so that means"
      },
      {
        "start": 1551.419,
        "duration": 5.401,
        "text": "again what we will need active active"
      },
      {
        "start": 1553.58,
        "duration": 6.36,
        "text": "data centers all around the world"
      },
      {
        "start": 1556.82,
        "duration": 4.38,
        "text": "that is not easy people like that's not"
      },
      {
        "start": 1559.94,
        "duration": 3.119,
        "text": "easy at all"
      },
      {
        "start": 1561.2,
        "duration": 3.959,
        "text": "then for volume"
      },
      {
        "start": 1563.059,
        "duration": 4.561,
        "text": "we are going to have a lot of data and"
      },
      {
        "start": 1565.159,
        "duration": 5.041,
        "text": "we are going to have millions of queries"
      },
      {
        "start": 1567.62,
        "duration": 5.159,
        "text": "per second what that will be our"
      },
      {
        "start": 1570.2,
        "duration": 5.64,
        "text": "architectural decision based on that"
      },
      {
        "start": 1572.779,
        "duration": 7.081,
        "text": "we have no other choice"
      },
      {
        "start": 1575.84,
        "duration": 6.719,
        "text": "to split uh them"
      },
      {
        "start": 1579.86,
        "duration": 5.58,
        "text": "our data in the chunks the story is"
      },
      {
        "start": 1582.559,
        "duration": 5.641,
        "text": "working with relational databases you"
      },
      {
        "start": 1585.44,
        "duration": 5.52,
        "text": "have your data all stored on a single"
      },
      {
        "start": 1588.2,
        "duration": 4.92,
        "text": "server there must be there can be leader"
      },
      {
        "start": 1590.96,
        "duration": 3.839,
        "text": "follower architecture with multiple"
      },
      {
        "start": 1593.12,
        "duration": 4.14,
        "text": "servers but still each one of them"
      },
      {
        "start": 1594.799,
        "duration": 4.38,
        "text": "stores all the data you have and you"
      },
      {
        "start": 1597.26,
        "duration": 4.32,
        "text": "know what that's great that's very"
      },
      {
        "start": 1599.179,
        "duration": 4.98,
        "text": "convenient really but that doesn't work"
      },
      {
        "start": 1601.58,
        "duration": 4.86,
        "text": "with big data then you have petabytes of"
      },
      {
        "start": 1604.159,
        "duration": 4.681,
        "text": "data of hundreds millions of customers"
      },
      {
        "start": 1606.44,
        "duration": 5.04,
        "text": "there is no server in the Earth on the"
      },
      {
        "start": 1608.84,
        "duration": 4.8,
        "text": "earth what could handle such volume and"
      },
      {
        "start": 1611.48,
        "duration": 3.179,
        "text": "still be capable of responding very"
      },
      {
        "start": 1613.64,
        "duration": 5.1,
        "text": "quickly"
      },
      {
        "start": 1614.659,
        "duration": 6.0,
        "text": "so we will have to split our data into"
      },
      {
        "start": 1618.74,
        "duration": 4.319,
        "text": "multiple chunks or we will call that"
      },
      {
        "start": 1620.659,
        "duration": 5.4,
        "text": "partitions and keep different partitions"
      },
      {
        "start": 1623.059,
        "duration": 5.641,
        "text": "or different servers that helps us to"
      },
      {
        "start": 1626.059,
        "duration": 5.281,
        "text": "put the to spread the workload spread"
      },
      {
        "start": 1628.7,
        "duration": 4.68,
        "text": "the queries over multiple servers so we"
      },
      {
        "start": 1631.34,
        "duration": 4.62,
        "text": "can handle more"
      },
      {
        "start": 1633.38,
        "duration": 5.94,
        "text": "then for service level agreement for"
      },
      {
        "start": 1635.96,
        "duration": 4.5,
        "text": "time we will need to use two things"
      },
      {
        "start": 1639.32,
        "duration": 4.26,
        "text": "first"
      },
      {
        "start": 1640.46,
        "duration": 5.48,
        "text": "to keep our database quick for response"
      },
      {
        "start": 1643.58,
        "duration": 4.979,
        "text": "we will need to use generalization"
      },
      {
        "start": 1645.94,
        "duration": 5.739,
        "text": "normalization denormalization will be"
      },
      {
        "start": 1648.559,
        "duration": 5.461,
        "text": "more discussed on the second Workshop"
      },
      {
        "start": 1651.679,
        "duration": 5.401,
        "text": "so today it will be just like a very"
      },
      {
        "start": 1654.02,
        "duration": 5.519,
        "text": "brief introduction and when we as we"
      },
      {
        "start": 1657.08,
        "duration": 4.52,
        "text": "partitioned our data and we may have a"
      },
      {
        "start": 1659.539,
        "duration": 6.061,
        "text": "lot of partitions over thousand servers"
      },
      {
        "start": 1661.6,
        "duration": 7.12,
        "text": "we need uh to root our queries to exact"
      },
      {
        "start": 1665.6,
        "duration": 4.74,
        "text": "the servers storing our data we"
      },
      {
        "start": 1668.72,
        "duration": 4.62,
        "text": "discussed it very soon today during"
      },
      {
        "start": 1670.34,
        "duration": 4.62,
        "text": "these Workshop and then finally for"
      },
      {
        "start": 1673.34,
        "duration": 4.02,
        "text": "service level agreement on high"
      },
      {
        "start": 1674.96,
        "duration": 4.56,
        "text": "availability requirements we are going"
      },
      {
        "start": 1677.36,
        "duration": 5.04,
        "text": "to use two more Technologies for"
      },
      {
        "start": 1679.52,
        "duration": 6.06,
        "text": "replication and death centralization"
      },
      {
        "start": 1682.4,
        "duration": 6.0,
        "text": "what replication means replication means"
      },
      {
        "start": 1685.58,
        "duration": 5.04,
        "text": "what as long as you have as long as you"
      },
      {
        "start": 1688.4,
        "duration": 4.92,
        "text": "have your data single piece on your data"
      },
      {
        "start": 1690.62,
        "duration": 5.039,
        "text": "just once on a single server as soon as"
      },
      {
        "start": 1693.32,
        "duration": 4.68,
        "text": "the square server is down this piece of"
      },
      {
        "start": 1695.659,
        "duration": 4.26,
        "text": "data cannot be accessed anymore and you"
      },
      {
        "start": 1698.0,
        "duration": 4.74,
        "text": "have down time"
      },
      {
        "start": 1699.919,
        "duration": 5.88,
        "text": "replication means what we copy this"
      },
      {
        "start": 1702.74,
        "duration": 5.46,
        "text": "piece of data under multiple servers and"
      },
      {
        "start": 1705.799,
        "duration": 4.081,
        "text": "if one of them is not uh is one of them"
      },
      {
        "start": 1708.2,
        "duration": 4.2,
        "text": "is down we still can fetch this"
      },
      {
        "start": 1709.88,
        "duration": 4.26,
        "text": "information from another servers that is"
      },
      {
        "start": 1712.4,
        "duration": 3.96,
        "text": "a replication obviously replication"
      },
      {
        "start": 1714.14,
        "duration": 5.1,
        "text": "means to a higher disk space consumption"
      },
      {
        "start": 1716.36,
        "duration": 4.02,
        "text": "but let's say big companies can afford"
      },
      {
        "start": 1719.24,
        "duration": 5.34,
        "text": "that okay"
      },
      {
        "start": 1720.38,
        "duration": 7.08,
        "text": "then that centralization is our idea we"
      },
      {
        "start": 1724.58,
        "duration": 5.459,
        "text": "don't want to follow follow a leader"
      },
      {
        "start": 1727.46,
        "duration": 4.8,
        "text": "follower architecture when you write to"
      },
      {
        "start": 1730.039,
        "duration": 4.921,
        "text": "your leader or Master server and read"
      },
      {
        "start": 1732.26,
        "duration": 5.159,
        "text": "from replica's follower replicants we"
      },
      {
        "start": 1734.96,
        "duration": 5.339,
        "text": "don't want it that's a traditional"
      },
      {
        "start": 1737.419,
        "duration": 5.76,
        "text": "database architecture but that's fragile"
      },
      {
        "start": 1740.299,
        "duration": 4.201,
        "text": "as soon as leader is down you cannot"
      },
      {
        "start": 1743.179,
        "duration": 4.74,
        "text": "write your application is not"
      },
      {
        "start": 1744.5,
        "duration": 4.86,
        "text": "operational no go so replication in debt"
      },
      {
        "start": 1747.919,
        "duration": 3.661,
        "text": "centralization"
      },
      {
        "start": 1749.36,
        "duration": 4.08,
        "text": "so we discussed with the customer"
      },
      {
        "start": 1751.58,
        "duration": 4.14,
        "text": "requirements we discussed the situation"
      },
      {
        "start": 1753.44,
        "duration": 6.739,
        "text": "many customers around the world fast"
      },
      {
        "start": 1755.72,
        "duration": 7.199,
        "text": "internet a lot of data we defined our"
      },
      {
        "start": 1760.179,
        "duration": 5.941,
        "text": "requirements and we discussed our"
      },
      {
        "start": 1762.919,
        "duration": 3.201,
        "text": "architectural decisions"
      },
      {
        "start": 1766.94,
        "duration": 5.28,
        "text": "um and that leads us to a problem"
      },
      {
        "start": 1769.52,
        "duration": 6.899,
        "text": "in the world of the databases in the law"
      },
      {
        "start": 1772.22,
        "duration": 8.339,
        "text": "in the in any field basically there is"
      },
      {
        "start": 1776.419,
        "duration": 7.161,
        "text": "no Silver Bullet one size fits all"
      },
      {
        "start": 1780.559,
        "duration": 7.201,
        "text": "maybe no"
      },
      {
        "start": 1783.58,
        "duration": 7.599,
        "text": "you uh we do we need more sport cars or"
      },
      {
        "start": 1787.76,
        "duration": 7.08,
        "text": "tracks trucks we need both okay for"
      },
      {
        "start": 1791.179,
        "duration": 5.581,
        "text": "different purposes uh when very many"
      },
      {
        "start": 1794.84,
        "duration": 3.54,
        "text": "thousands years before hundreds"
      },
      {
        "start": 1796.76,
        "duration": 4.44,
        "text": "thousands years before"
      },
      {
        "start": 1798.38,
        "duration": 5.46,
        "text": "each person each human being was a"
      },
      {
        "start": 1801.2,
        "duration": 6.54,
        "text": "hunter hunter gatherer I don't know"
      },
      {
        "start": 1803.84,
        "duration": 6.839,
        "text": "firmer whatever Warrior is required all"
      },
      {
        "start": 1807.74,
        "duration": 5.159,
        "text": "the things together but over time we as"
      },
      {
        "start": 1810.679,
        "duration": 4.98,
        "text": "Humanity we developed specializations"
      },
      {
        "start": 1812.899,
        "duration": 3.721,
        "text": "why because specializations are more"
      },
      {
        "start": 1815.659,
        "duration": 3.661,
        "text": "efficient"
      },
      {
        "start": 1816.62,
        "duration": 5.9,
        "text": "basically exactly the same is happening"
      },
      {
        "start": 1819.32,
        "duration": 6.42,
        "text": "with databases on the database field"
      },
      {
        "start": 1822.52,
        "duration": 5.62,
        "text": "from a generalization from multipurpose"
      },
      {
        "start": 1825.74,
        "duration": 4.799,
        "text": "general purpose databases we go more and"
      },
      {
        "start": 1828.14,
        "duration": 4.86,
        "text": "more into specialized Solutions because"
      },
      {
        "start": 1830.539,
        "duration": 5.281,
        "text": "the problem is if you want to have it"
      },
      {
        "start": 1833.0,
        "duration": 4.919,
        "text": "all all those multiple active disease"
      },
      {
        "start": 1835.82,
        "duration": 5.04,
        "text": "partitional data their normalized"
      },
      {
        "start": 1837.919,
        "duration": 4.201,
        "text": "replica replicated decentralizer get"
      },
      {
        "start": 1840.86,
        "duration": 3.72,
        "text": "back here"
      },
      {
        "start": 1842.12,
        "duration": 5.299,
        "text": "there is no database like that or there"
      },
      {
        "start": 1844.58,
        "duration": 6.12,
        "text": "were no database like that at all"
      },
      {
        "start": 1847.419,
        "duration": 5.081,
        "text": "and you know in 2008 there were plenty"
      },
      {
        "start": 1850.7,
        "duration": 4.68,
        "text": "of great databases like postgres for"
      },
      {
        "start": 1852.5,
        "duration": 4.919,
        "text": "example postgres is great but it's more"
      },
      {
        "start": 1855.38,
        "duration": 3.299,
        "text": "multi-purpose and we need something more"
      },
      {
        "start": 1857.419,
        "duration": 4.561,
        "text": "specialized"
      },
      {
        "start": 1858.679,
        "duration": 6.0,
        "text": "well Alex to be fair big table existed"
      },
      {
        "start": 1861.98,
        "duration": 5.34,
        "text": "at that time but yeah okay it was not"
      },
      {
        "start": 1864.679,
        "duration": 5.641,
        "text": "available to Facebook"
      },
      {
        "start": 1867.32,
        "duration": 3.0,
        "text": "uh"
      },
      {
        "start": 1871.159,
        "duration": 6.301,
        "text": "uh Solutions database Solutions what are"
      },
      {
        "start": 1874.34,
        "duration": 5.64,
        "text": "based on the same white paper and uh"
      },
      {
        "start": 1877.46,
        "duration": 5.78,
        "text": "share the same concepts for example we"
      },
      {
        "start": 1879.98,
        "duration": 7.62,
        "text": "can mention Google uh bigtable or Amazon"
      },
      {
        "start": 1883.24,
        "duration": 5.919,
        "text": "Dynamics they are good databases so I"
      },
      {
        "start": 1887.6,
        "duration": 4.74,
        "text": "don't want to say anything bad about"
      },
      {
        "start": 1889.159,
        "duration": 5.461,
        "text": "those they have one limitation they both"
      },
      {
        "start": 1892.34,
        "duration": 5.059,
        "text": "share the same limitation you really"
      },
      {
        "start": 1894.62,
        "duration": 6.419,
        "text": "need to understand they are proprietary"
      },
      {
        "start": 1897.399,
        "duration": 5.561,
        "text": "vendor login database so if for example"
      },
      {
        "start": 1901.039,
        "duration": 4.26,
        "text": "you run your application on Google and"
      },
      {
        "start": 1902.96,
        "duration": 5.4,
        "text": "you stick to Google big table that is a"
      },
      {
        "start": 1905.299,
        "duration": 4.74,
        "text": "great one it will work well but if for"
      },
      {
        "start": 1908.36,
        "duration": 4.319,
        "text": "any reason you are not happy with Google"
      },
      {
        "start": 1910.039,
        "duration": 4.5,
        "text": "and you want to migrate to Amazon or you"
      },
      {
        "start": 1912.679,
        "duration": 4.441,
        "text": "want to migrate to your own cloud to"
      },
      {
        "start": 1914.539,
        "duration": 3.961,
        "text": "your own data center you will have to"
      },
      {
        "start": 1917.12,
        "duration": 3.0,
        "text": "rework half of your application"
      },
      {
        "start": 1918.5,
        "duration": 5.46,
        "text": "basically"
      },
      {
        "start": 1920.12,
        "duration": 7.5,
        "text": "that is a very important story uh part"
      },
      {
        "start": 1923.96,
        "duration": 8.36,
        "text": "of a story to me so yes a big table was"
      },
      {
        "start": 1927.62,
        "duration": 7.74,
        "text": "present it's I believe like from"
      },
      {
        "start": 1932.32,
        "duration": 6.719,
        "text": "2005 maybe was available"
      },
      {
        "start": 1935.36,
        "duration": 5.66,
        "text": "right I don't remember exactly but um"
      },
      {
        "start": 1939.039,
        "duration": 5.74,
        "text": "it's"
      },
      {
        "start": 1941.02,
        "duration": 6.039,
        "text": "a proprietary database well I don't know"
      },
      {
        "start": 1944.779,
        "duration": 4.26,
        "text": "about you guys but I'm a big fan of Open"
      },
      {
        "start": 1947.059,
        "duration": 4.441,
        "text": "Source things and I see there is a"
      },
      {
        "start": 1949.039,
        "duration": 6.36,
        "text": "question about the slides"
      },
      {
        "start": 1951.5,
        "duration": 5.64,
        "text": "uh slides are available and they must be"
      },
      {
        "start": 1955.399,
        "duration": 5.64,
        "text": "way much present and the GitHub"
      },
      {
        "start": 1957.14,
        "duration": 6.0,
        "text": "repository and James Wong asks uh will"
      },
      {
        "start": 1961.039,
        "duration": 4.681,
        "text": "we stream live will we stream available"
      },
      {
        "start": 1963.14,
        "duration": 4.08,
        "text": "on YouTube channel later answer is yes"
      },
      {
        "start": 1965.72,
        "duration": 4.52,
        "text": "the same link"
      },
      {
        "start": 1967.22,
        "duration": 7.559,
        "text": "oh thank you said we so"
      },
      {
        "start": 1970.24,
        "duration": 7.9,
        "text": "uh and uh my point on this way from"
      },
      {
        "start": 1974.779,
        "duration": 4.5,
        "text": "generalization to specialization"
      },
      {
        "start": 1978.14,
        "duration": 2.58,
        "text": "um"
      },
      {
        "start": 1979.279,
        "duration": 4.861,
        "text": "there are"
      },
      {
        "start": 1980.72,
        "duration": 5.88,
        "text": "two sides on this field ltp kind of"
      },
      {
        "start": 1984.14,
        "duration": 4.5,
        "text": "workloads and or love kind of workloads"
      },
      {
        "start": 1986.6,
        "duration": 4.799,
        "text": "what is that about"
      },
      {
        "start": 1988.64,
        "duration": 5.279,
        "text": "so see oil TB stands for online"
      },
      {
        "start": 1991.399,
        "duration": 4.741,
        "text": "transaction processing"
      },
      {
        "start": 1993.919,
        "duration": 4.921,
        "text": "uh it's usually customer facing"
      },
      {
        "start": 1996.14,
        "duration": 4.5,
        "text": "databases with a lot of operations per"
      },
      {
        "start": 1998.84,
        "duration": 3.6,
        "text": "second and very strict service level"
      },
      {
        "start": 2000.64,
        "duration": 2.7,
        "text": "agreements"
      },
      {
        "start": 2002.44,
        "duration": 3.239,
        "text": "um"
      },
      {
        "start": 2003.34,
        "duration": 5.64,
        "text": "and that is very specialization like"
      },
      {
        "start": 2005.679,
        "duration": 6.061,
        "text": "they have to be all the time up serving"
      },
      {
        "start": 2008.98,
        "duration": 5.4,
        "text": "a lot of queries very very quickly that"
      },
      {
        "start": 2011.74,
        "duration": 4.62,
        "text": "is very specialization another side of"
      },
      {
        "start": 2014.38,
        "duration": 5.34,
        "text": "this field opposite side of this field"
      },
      {
        "start": 2016.36,
        "duration": 6.0,
        "text": "is pull up type of workloads olap stands"
      },
      {
        "start": 2019.72,
        "duration": 4.199,
        "text": "for online analytical processing and"
      },
      {
        "start": 2022.36,
        "duration": 3.96,
        "text": "that is a very different kind of"
      },
      {
        "start": 2023.919,
        "duration": 5.24,
        "text": "workload that's usually about data"
      },
      {
        "start": 2026.32,
        "duration": 7.02,
        "text": "exploration that is usually about like"
      },
      {
        "start": 2029.159,
        "duration": 7.841,
        "text": "analysis of your data a lot of data very"
      },
      {
        "start": 2033.34,
        "duration": 6.36,
        "text": "often historical so-called call data and"
      },
      {
        "start": 2037.0,
        "duration": 5.94,
        "text": "very often it includes some kind of a"
      },
      {
        "start": 2039.7,
        "duration": 6.599,
        "text": "very complex queries to run like with"
      },
      {
        "start": 2042.94,
        "duration": 6.06,
        "text": "dozens of joins let's find all the"
      },
      {
        "start": 2046.299,
        "duration": 6.54,
        "text": "customers who have bought car tires last"
      },
      {
        "start": 2049.0,
        "duration": 4.94,
        "text": "year but did not vote any kind of I"
      },
      {
        "start": 2052.839,
        "duration": 3.961,
        "text": "don't know"
      },
      {
        "start": 2053.94,
        "duration": 6.12,
        "text": "laptops for previews here and then"
      },
      {
        "start": 2056.8,
        "duration": 6.48,
        "text": "they've bought car tires it was rainy"
      },
      {
        "start": 2060.06,
        "duration": 6.279,
        "text": "and if they are younger than 30 years"
      },
      {
        "start": 2063.28,
        "duration": 4.8,
        "text": "old but older than 15 years old and so"
      },
      {
        "start": 2066.339,
        "duration": 4.5,
        "text": "on and so forth like with dozens of"
      },
      {
        "start": 2068.08,
        "duration": 6.599,
        "text": "joints with very different aspects"
      },
      {
        "start": 2070.839,
        "duration": 6.901,
        "text": "the classic example in that field is the"
      },
      {
        "start": 2074.679,
        "duration": 6.601,
        "text": "the question that was asked for like"
      },
      {
        "start": 2077.74,
        "duration": 9.659,
        "text": "grocery stores with tailors find the"
      },
      {
        "start": 2081.28,
        "duration": 8.339,
        "text": "fathers who bought diapers and beer at"
      },
      {
        "start": 2087.399,
        "duration": 5.7,
        "text": "the same time on the same trip so"
      },
      {
        "start": 2089.619,
        "duration": 6.3,
        "text": "essentially what would help what would"
      },
      {
        "start": 2093.099,
        "duration": 5.76,
        "text": "Place beer and diapers in the same old"
      },
      {
        "start": 2095.919,
        "duration": 3.961,
        "text": "same section or nearby so that customers"
      },
      {
        "start": 2098.859,
        "duration": 4.081,
        "text": "can find"
      },
      {
        "start": 2099.88,
        "duration": 4.26,
        "text": "uh those items"
      },
      {
        "start": 2102.94,
        "duration": 5.159,
        "text": "yep"
      },
      {
        "start": 2104.14,
        "duration": 5.4,
        "text": "uh so and the story of this"
      },
      {
        "start": 2108.099,
        "duration": 4.081,
        "text": "is"
      },
      {
        "start": 2109.54,
        "duration": 4.98,
        "text": "um you cannot be simultaneously on the"
      },
      {
        "start": 2112.18,
        "duration": 5.22,
        "text": "both sides with a single project"
      },
      {
        "start": 2114.52,
        "duration": 4.74,
        "text": "so uh most of the relational databases"
      },
      {
        "start": 2117.4,
        "duration": 4.02,
        "text": "they are more multi-purpose they're"
      },
      {
        "start": 2119.26,
        "duration": 4.8,
        "text": "trying to stay in between"
      },
      {
        "start": 2121.42,
        "duration": 5.159,
        "text": "and that brings us to a problem Jack of"
      },
      {
        "start": 2124.06,
        "duration": 5.7,
        "text": "all trains must drop known so they can"
      },
      {
        "start": 2126.579,
        "duration": 5.221,
        "text": "try to get into OTP processing but they"
      },
      {
        "start": 2129.76,
        "duration": 4.92,
        "text": "are not perfect in it they're trying to"
      },
      {
        "start": 2131.8,
        "duration": 4.5,
        "text": "get to a lab a side of the things but"
      },
      {
        "start": 2134.68,
        "duration": 4.62,
        "text": "again there are much better Solutions"
      },
      {
        "start": 2136.3,
        "duration": 6.18,
        "text": "what are specialized for Analytics"
      },
      {
        "start": 2139.3,
        "duration": 5.1,
        "text": "and that's why that was the reason why a"
      },
      {
        "start": 2142.48,
        "duration": 4.68,
        "text": "relational databases were dominating"
      },
      {
        "start": 2144.4,
        "duration": 6.12,
        "text": "databases market for those and spheres"
      },
      {
        "start": 2147.16,
        "duration": 5.699,
        "text": "they are versatile they can"
      },
      {
        "start": 2150.52,
        "duration": 4.98,
        "text": "be a little bit on each side of the"
      },
      {
        "start": 2152.859,
        "duration": 4.561,
        "text": "field but if you need to have more if"
      },
      {
        "start": 2155.5,
        "duration": 4.68,
        "text": "you really need to have petabytes over"
      },
      {
        "start": 2157.42,
        "duration": 5.22,
        "text": "multiple regions answering 15 single"
      },
      {
        "start": 2160.18,
        "duration": 4.62,
        "text": "digit milliseconds you need to sacrifice"
      },
      {
        "start": 2162.64,
        "duration": 5.28,
        "text": "something what is the simplification"
      },
      {
        "start": 2164.8,
        "duration": 5.52,
        "text": "idea is very simple the more you get to"
      },
      {
        "start": 2167.92,
        "duration": 5.52,
        "text": "the right side of the field better you"
      },
      {
        "start": 2170.32,
        "duration": 5.64,
        "text": "are on olap but worse you are in oil"
      },
      {
        "start": 2173.44,
        "duration": 4.62,
        "text": "tipping and opposite the more you get to"
      },
      {
        "start": 2175.96,
        "duration": 4.46,
        "text": "the left side of a thing better you are"
      },
      {
        "start": 2178.06,
        "duration": 5.58,
        "text": "on Fast dispatching millions of queries"
      },
      {
        "start": 2180.42,
        "duration": 5.38,
        "text": "but not as good in search capabilities"
      },
      {
        "start": 2183.64,
        "duration": 5.34,
        "text": "and analytics capabilities for example"
      },
      {
        "start": 2185.8,
        "duration": 5.58,
        "text": "it all comes with a price right"
      },
      {
        "start": 2188.98,
        "duration": 5.099,
        "text": "so"
      },
      {
        "start": 2191.38,
        "duration": 5.04,
        "text": "um what uh World desperately needed"
      },
      {
        "start": 2194.079,
        "duration": 4.861,
        "text": "there was an open source distribute and"
      },
      {
        "start": 2196.42,
        "duration": 5.82,
        "text": "decentralized oil TP database customer"
      },
      {
        "start": 2198.94,
        "duration": 6.78,
        "text": "facing database with the ability to have"
      },
      {
        "start": 2202.24,
        "duration": 5.72,
        "text": "uh in press to have to have a presence"
      },
      {
        "start": 2205.72,
        "duration": 5.639,
        "text": "basically everywhere in all the regions"
      },
      {
        "start": 2207.96,
        "duration": 5.28,
        "text": "uh answer all the questions very quickly"
      },
      {
        "start": 2211.359,
        "duration": 3.781,
        "text": "and we are ready to pay for it"
      },
      {
        "start": 2213.24,
        "duration": 4.619,
        "text": "sacrificing some of the alarm"
      },
      {
        "start": 2215.14,
        "duration": 6.719,
        "text": "capabilities of the databases"
      },
      {
        "start": 2217.859,
        "duration": 5.921,
        "text": "what is it now so AdWords or all the"
      },
      {
        "start": 2221.859,
        "duration": 2.881,
        "text": "story about Cassandra what is Cassandra"
      },
      {
        "start": 2223.78,
        "duration": 3.66,
        "text": "today"
      },
      {
        "start": 2224.74,
        "duration": 5.06,
        "text": "now Cassandra is used basically by all"
      },
      {
        "start": 2227.44,
        "duration": 5.52,
        "text": "or almost all of the future"
      },
      {
        "start": 2229.8,
        "duration": 7.12,
        "text": "transnational corporations uh biggest"
      },
      {
        "start": 2232.96,
        "duration": 7.2,
        "text": "Cassandra users include uh Apple Huawei"
      },
      {
        "start": 2236.92,
        "duration": 6.06,
        "text": "Netflix Instagram IBM and many many many"
      },
      {
        "start": 2240.16,
        "duration": 6.54,
        "text": "many many hours basically you all use"
      },
      {
        "start": 2242.98,
        "duration": 5.94,
        "text": "Cassandra even if you don't know it all"
      },
      {
        "start": 2246.7,
        "duration": 4.56,
        "text": "the global companies are using Cassandra"
      },
      {
        "start": 2248.92,
        "duration": 4.64,
        "text": "or at least it's"
      },
      {
        "start": 2251.26,
        "duration": 4.92,
        "text": "a proprietary"
      },
      {
        "start": 2253.56,
        "duration": 5.98,
        "text": "idea a proprietary to implemented"
      },
      {
        "start": 2256.18,
        "duration": 8.159,
        "text": "Solutions of the same style"
      },
      {
        "start": 2259.54,
        "duration": 8.64,
        "text": "um Cassandra scale what Apple uses is at"
      },
      {
        "start": 2264.339,
        "duration": 7.621,
        "text": "apachecon here 2022 last year so Apple"
      },
      {
        "start": 2268.18,
        "duration": 6.179,
        "text": "reported what may have over 300"
      },
      {
        "start": 2271.96,
        "duration": 4.619,
        "text": "000 database servers for Apache"
      },
      {
        "start": 2274.359,
        "duration": 5.22,
        "text": "Cassandra they store hundreds petabytes"
      },
      {
        "start": 2276.579,
        "duration": 6.081,
        "text": "of data and they dispatch millions of"
      },
      {
        "start": 2279.579,
        "duration": 7.701,
        "text": "queries per second with Cassandra"
      },
      {
        "start": 2282.66,
        "duration": 6.88,
        "text": "uh when my favorite example of"
      },
      {
        "start": 2287.28,
        "duration": 5.98,
        "text": "Cassandra usage is actually in Netflix"
      },
      {
        "start": 2289.54,
        "duration": 6.18,
        "text": "probably with apple is what Apple"
      },
      {
        "start": 2293.26,
        "duration": 4.44,
        "text": "doesn't tell us a lot about how they use"
      },
      {
        "start": 2295.72,
        "duration": 5.399,
        "text": "that"
      },
      {
        "start": 2297.7,
        "duration": 5.7,
        "text": "um it's secret you know but Netflix is"
      },
      {
        "start": 2301.119,
        "duration": 4.681,
        "text": "much more friendly and much more open to"
      },
      {
        "start": 2303.4,
        "duration": 5.219,
        "text": "us so Netflix shares a lot of rare"
      },
      {
        "start": 2305.8,
        "duration": 4.22,
        "text": "details on how do we use Cassandra uh"
      },
      {
        "start": 2308.619,
        "duration": 4.321,
        "text": "regularly"
      },
      {
        "start": 2310.02,
        "duration": 4.839,
        "text": "and Cassandra is the primary database"
      },
      {
        "start": 2312.94,
        "duration": 3.84,
        "text": "for Netflix so when Netflix of course"
      },
      {
        "start": 2314.859,
        "duration": 3.961,
        "text": "uses multiple different databases but"
      },
      {
        "start": 2316.78,
        "duration": 5.64,
        "text": "Cassandra is definitely primary"
      },
      {
        "start": 2318.82,
        "duration": 6.5,
        "text": "uh they single most active cluster and"
      },
      {
        "start": 2322.42,
        "duration": 6.6,
        "text": "they have multiple clusters handles 30"
      },
      {
        "start": 2325.32,
        "duration": 4.96,
        "text": "Millions operations per second reads and"
      },
      {
        "start": 2329.02,
        "duration": 4.98,
        "text": "writes"
      },
      {
        "start": 2330.28,
        "duration": 5.7,
        "text": "and uh overall they have hundreds"
      },
      {
        "start": 2334.0,
        "duration": 5.359,
        "text": "thousands of clusters hundreds or"
      },
      {
        "start": 2335.98,
        "duration": 7.02,
        "text": "thousands of clusters by now I believe"
      },
      {
        "start": 2339.359,
        "duration": 6.161,
        "text": "again hundreds petabytes of data"
      },
      {
        "start": 2343.0,
        "duration": 6.119,
        "text": "if you're more interested in how Netflix"
      },
      {
        "start": 2345.52,
        "duration": 4.88,
        "text": "uh uses Apache Cassandra you can follow"
      },
      {
        "start": 2349.119,
        "duration": 5.46,
        "text": "this link"
      },
      {
        "start": 2350.4,
        "duration": 7.78,
        "text": "dts6.io Cassandra at Netflix"
      },
      {
        "start": 2354.579,
        "duration": 6.681,
        "text": "is there a talk what uh was done by"
      },
      {
        "start": 2358.18,
        "duration": 7.32,
        "text": "Cloud database architect uh"
      },
      {
        "start": 2361.26,
        "duration": 6.76,
        "text": "marchella at the last Cassandra de India"
      },
      {
        "start": 2365.5,
        "duration": 4.98,
        "text": "I recorded this one"
      },
      {
        "start": 2368.02,
        "duration": 4.74,
        "text": "so"
      },
      {
        "start": 2370.48,
        "duration": 4.82,
        "text": "question"
      },
      {
        "start": 2372.76,
        "duration": 2.54,
        "text": "oops"
      },
      {
        "start": 2375.94,
        "duration": 3.08,
        "text": "first real question"
      },
      {
        "start": 2380.44,
        "duration": 6.48,
        "text": "speech momentum"
      },
      {
        "start": 2382.72,
        "duration": 7.74,
        "text": "and tell me Cassandra is better fit four"
      },
      {
        "start": 2386.92,
        "duration": 5.46,
        "text": "all up workloads oltp workloads or both"
      },
      {
        "start": 2390.46,
        "duration": 4.98,
        "text": "types of workloads"
      },
      {
        "start": 2392.38,
        "duration": 5.4,
        "text": "let's see who paid attention that is"
      },
      {
        "start": 2395.44,
        "duration": 6.2,
        "text": "actually a little bit tricky question"
      },
      {
        "start": 2397.78,
        "duration": 3.86,
        "text": "I will explain when you will answer"
      },
      {
        "start": 2402.339,
        "duration": 5.581,
        "text": "don't be afraid to make mistakes"
      },
      {
        "start": 2405.099,
        "duration": 5.361,
        "text": "you better answer using main team so"
      },
      {
        "start": 2407.92,
        "duration": 5.46,
        "text": "your vote will count"
      },
      {
        "start": 2410.46,
        "duration": 5.26,
        "text": "so yeah there is a tricky question"
      },
      {
        "start": 2413.38,
        "duration": 5.64,
        "text": "Cassandra was designed to be much more"
      },
      {
        "start": 2415.72,
        "duration": 6.3,
        "text": "on ltp side of the things that is for"
      },
      {
        "start": 2419.02,
        "duration": 6.54,
        "text": "sure but there are some kinds of lab"
      },
      {
        "start": 2422.02,
        "duration": 6.3,
        "text": "workloads what also can be answered for"
      },
      {
        "start": 2425.56,
        "duration": 4.68,
        "text": "Cassandra if it doesn't include a lot of"
      },
      {
        "start": 2428.32,
        "duration": 4.74,
        "text": "joints for example"
      },
      {
        "start": 2430.24,
        "duration": 5.16,
        "text": "and then you just want to see a Time"
      },
      {
        "start": 2433.06,
        "duration": 4.98,
        "text": "series data of what it is temperature"
      },
      {
        "start": 2435.4,
        "duration": 4.74,
        "text": "change in particular region of a"
      },
      {
        "start": 2438.04,
        "duration": 4.559,
        "text": "particular temperature sensor storage in"
      },
      {
        "start": 2440.14,
        "duration": 4.26,
        "text": "Cassandra then you can see this data"
      },
      {
        "start": 2442.599,
        "duration": 5.461,
        "text": "easily yes that kind of works but that"
      },
      {
        "start": 2444.4,
        "duration": 5.64,
        "text": "is a very limited site very small part"
      },
      {
        "start": 2448.06,
        "duration": 4.74,
        "text": "of what's happening on the lab side of"
      },
      {
        "start": 2450.04,
        "duration": 5.88,
        "text": "world Cassandra was designed to be oltp"
      },
      {
        "start": 2452.8,
        "duration": 5.46,
        "text": "database and there is no simple solution"
      },
      {
        "start": 2455.92,
        "duration": 5.34,
        "text": "to answer both type of workloads because"
      },
      {
        "start": 2458.26,
        "duration": 5.88,
        "text": "there are no silver bullets in the"
      },
      {
        "start": 2461.26,
        "duration": 5.28,
        "text": "software development in anyone anyone"
      },
      {
        "start": 2464.14,
        "duration": 4.38,
        "text": "comes to you and says like hey you"
      },
      {
        "start": 2466.54,
        "duration": 2.7,
        "text": "should try this database it's just the"
      },
      {
        "start": 2468.52,
        "duration": 3.12,
        "text": "best"
      },
      {
        "start": 2469.24,
        "duration": 3.599,
        "text": "don't try this person he's going to tell"
      },
      {
        "start": 2471.64,
        "duration": 4.14,
        "text": "you something"
      },
      {
        "start": 2472.839,
        "duration": 6.24,
        "text": "idea is uh"
      },
      {
        "start": 2475.78,
        "duration": 6.54,
        "text": "there is it's just not possible what is"
      },
      {
        "start": 2479.079,
        "duration": 5.461,
        "text": "better a submarine or airplane"
      },
      {
        "start": 2482.32,
        "duration": 4.38,
        "text": "that is a stupid question people that is"
      },
      {
        "start": 2484.54,
        "duration": 4.02,
        "text": "a really stupid question they both are"
      },
      {
        "start": 2486.7,
        "duration": 4.56,
        "text": "good it just depends so do you have to"
      },
      {
        "start": 2488.56,
        "duration": 6.539,
        "text": "type in a c or do you have to fly above"
      },
      {
        "start": 2491.26,
        "duration": 6.12,
        "text": "the uh Skies like you know you are not"
      },
      {
        "start": 2495.099,
        "duration": 4.02,
        "text": "going to fly very high in a submarine"
      },
      {
        "start": 2497.38,
        "duration": 4.32,
        "text": "right but that doesn't make submarine"
      },
      {
        "start": 2499.119,
        "duration": 4.441,
        "text": "bad you just need to have some"
      },
      {
        "start": 2501.7,
        "duration": 4.159,
        "text": "specialization okay"
      },
      {
        "start": 2503.56,
        "duration": 2.299,
        "text": "foreign"
      },
      {
        "start": 2509.339,
        "duration": 5.981,
        "text": "so what are the features we speak about"
      },
      {
        "start": 2512.5,
        "duration": 6.3,
        "text": "whatever primary features we speak about"
      },
      {
        "start": 2515.32,
        "duration": 7.32,
        "text": "Cassandra is built internally first it"
      },
      {
        "start": 2518.8,
        "duration": 6.42,
        "text": "is partitioning whiskey we split over"
      },
      {
        "start": 2522.64,
        "duration": 5.34,
        "text": "data we store into multiple different"
      },
      {
        "start": 2525.22,
        "duration": 4.859,
        "text": "chunks it is very important for us"
      },
      {
        "start": 2527.98,
        "duration": 4.74,
        "text": "because those chunks can be stored on"
      },
      {
        "start": 2530.079,
        "duration": 5.28,
        "text": "different servers and if we need to"
      },
      {
        "start": 2532.72,
        "duration": 5.58,
        "text": "store more data we simply can add more"
      },
      {
        "start": 2535.359,
        "duration": 6.0,
        "text": "nodes and put those chunks on the multi"
      },
      {
        "start": 2538.3,
        "duration": 5.4,
        "text": "on Wheels new nodes and we will be good"
      },
      {
        "start": 2541.359,
        "duration": 4.801,
        "text": "the partitioning is very important don't"
      },
      {
        "start": 2543.7,
        "duration": 4.5,
        "text": "get me wrong partitioning creates also"
      },
      {
        "start": 2546.16,
        "duration": 4.62,
        "text": "quite some problems you will see it soon"
      },
      {
        "start": 2548.2,
        "duration": 4.139,
        "text": "but it helps with scaling that's for"
      },
      {
        "start": 2550.78,
        "duration": 4.26,
        "text": "sure"
      },
      {
        "start": 2552.339,
        "duration": 6.901,
        "text": "of course very important thing for us as"
      },
      {
        "start": 2555.04,
        "duration": 6.36,
        "text": "a oltp database is very high read write"
      },
      {
        "start": 2559.24,
        "duration": 4.44,
        "text": "performance Cassandra is very well"
      },
      {
        "start": 2561.4,
        "duration": 3.84,
        "text": "optimized for both writes and reads and"
      },
      {
        "start": 2563.68,
        "duration": 4.439,
        "text": "it's definitely one of the fastest"
      },
      {
        "start": 2565.24,
        "duration": 5.339,
        "text": "databases in the world even a single"
      },
      {
        "start": 2568.119,
        "duration": 4.5,
        "text": "Cassandra node is very performant but as"
      },
      {
        "start": 2570.579,
        "duration": 5.461,
        "text": "the nodes work together"
      },
      {
        "start": 2572.619,
        "duration": 5.761,
        "text": "that always helps with read write"
      },
      {
        "start": 2576.04,
        "duration": 4.92,
        "text": "performance for example one node is slow"
      },
      {
        "start": 2578.38,
        "duration": 4.92,
        "text": "but your query still will be processed"
      },
      {
        "start": 2580.96,
        "duration": 4.08,
        "text": "and dispatched sooner with another node"
      },
      {
        "start": 2583.3,
        "duration": 4.08,
        "text": "which is not slow it down for whatever"
      },
      {
        "start": 2585.04,
        "duration": 5.539,
        "text": "reason"
      },
      {
        "start": 2587.38,
        "duration": 3.199,
        "text": "very cool thing"
      },
      {
        "start": 2590.619,
        "duration": 5.46,
        "text": "like a scalability team but not just"
      },
      {
        "start": 2593.5,
        "duration": 5.76,
        "text": "scalability"
      },
      {
        "start": 2596.079,
        "duration": 5.701,
        "text": "um the idea is first Cassandra scales"
      },
      {
        "start": 2599.26,
        "duration": 4.62,
        "text": "horizontally most of the databases you"
      },
      {
        "start": 2601.78,
        "duration": 4.74,
        "text": "are familiar with pay scale vertically"
      },
      {
        "start": 2603.88,
        "duration": 4.68,
        "text": "that means what if your database cannot"
      },
      {
        "start": 2606.52,
        "duration": 5.339,
        "text": "cope with the workloads you put on it"
      },
      {
        "start": 2608.56,
        "duration": 5.94,
        "text": "you buy a bigger server migrate your"
      },
      {
        "start": 2611.859,
        "duration": 4.621,
        "text": "data to a bigger server mostly probably"
      },
      {
        "start": 2614.5,
        "duration": 3.66,
        "text": "it's a downtime operation so your"
      },
      {
        "start": 2616.48,
        "duration": 4.26,
        "text": "application will not be available during"
      },
      {
        "start": 2618.16,
        "duration": 4.919,
        "text": "this time then you launch it again and"
      },
      {
        "start": 2620.74,
        "duration": 4.26,
        "text": "then what happens next then your new"
      },
      {
        "start": 2623.079,
        "duration": 3.481,
        "text": "database again cannot cope with this"
      },
      {
        "start": 2625.0,
        "duration": 3.96,
        "text": "workload you have more and more"
      },
      {
        "start": 2626.56,
        "duration": 5.22,
        "text": "customers you get more"
      },
      {
        "start": 2628.96,
        "duration": 4.92,
        "text": "you get another server migrate your data"
      },
      {
        "start": 2631.78,
        "duration": 4.2,
        "text": "and some vertical scaling means getting"
      },
      {
        "start": 2633.88,
        "duration": 4.32,
        "text": "more bigger and bigger servers you know"
      },
      {
        "start": 2635.98,
        "duration": 4.859,
        "text": "what at some point you realize there are"
      },
      {
        "start": 2638.2,
        "duration": 4.74,
        "text": "no servers bigger than yours and you"
      },
      {
        "start": 2640.839,
        "duration": 3.901,
        "text": "still get more and more queries from"
      },
      {
        "start": 2642.94,
        "duration": 4.5,
        "text": "more and more customers"
      },
      {
        "start": 2644.74,
        "duration": 4.68,
        "text": "vertical scaling has limits and also"
      },
      {
        "start": 2647.44,
        "duration": 3.48,
        "text": "getting prohibitively expensive very"
      },
      {
        "start": 2649.42,
        "duration": 4.14,
        "text": "soon"
      },
      {
        "start": 2650.92,
        "duration": 5.1,
        "text": "Cassandra scales horizontal it means"
      },
      {
        "start": 2653.56,
        "duration": 5.34,
        "text": "what we don't upgrade our notes but just"
      },
      {
        "start": 2656.02,
        "duration": 5.46,
        "text": "add more nodes add more servers to a"
      },
      {
        "start": 2658.9,
        "duration": 4.56,
        "text": "cluster let's call it horizontal scaling"
      },
      {
        "start": 2661.48,
        "duration": 4.859,
        "text": "or scale out"
      },
      {
        "start": 2663.46,
        "duration": 4.92,
        "text": "or volume or velocity if you need to"
      },
      {
        "start": 2666.339,
        "duration": 5.881,
        "text": "process more queries or if you need to"
      },
      {
        "start": 2668.38,
        "duration": 6.06,
        "text": "process a bigger data or volume you just"
      },
      {
        "start": 2672.22,
        "duration": 5.46,
        "text": "need to add more nodes but my favorite"
      },
      {
        "start": 2674.44,
        "duration": 5.82,
        "text": "thing is how exactly it scales the story"
      },
      {
        "start": 2677.68,
        "duration": 5.28,
        "text": "is for most of the database introducing"
      },
      {
        "start": 2680.26,
        "duration": 5.52,
        "text": "new servers to a cluster had its"
      },
      {
        "start": 2682.96,
        "duration": 7.02,
        "text": "overhead it means what each next server"
      },
      {
        "start": 2685.78,
        "duration": 7.74,
        "text": "will bring you less and less performance"
      },
      {
        "start": 2689.98,
        "duration": 6.139,
        "text": "and take a look Netflix did a very"
      },
      {
        "start": 2693.52,
        "duration": 6.299,
        "text": "interesting research some time ago"
      },
      {
        "start": 2696.119,
        "duration": 6.7,
        "text": "scaling their cluster"
      },
      {
        "start": 2699.819,
        "duration": 5.701,
        "text": "um from approximately 50 servers to"
      },
      {
        "start": 2702.819,
        "duration": 5.101,
        "text": "approximately 300 servers and meanwhile"
      },
      {
        "start": 2705.52,
        "duration": 4.799,
        "text": "measuring workloads"
      },
      {
        "start": 2707.92,
        "duration": 5.04,
        "text": "and take a look at this nice straight"
      },
      {
        "start": 2710.319,
        "duration": 5.04,
        "text": "line the story is for most of the"
      },
      {
        "start": 2712.96,
        "duration": 5.28,
        "text": "databases capable of cleaning"
      },
      {
        "start": 2715.359,
        "duration": 5.821,
        "text": "this line would get somewhere here much"
      },
      {
        "start": 2718.24,
        "duration": 5.94,
        "text": "below it wouldn't be straight because"
      },
      {
        "start": 2721.18,
        "duration": 5.34,
        "text": "each next server adds some overhead and"
      },
      {
        "start": 2724.18,
        "duration": 4.98,
        "text": "more and more until the situation then"
      },
      {
        "start": 2726.52,
        "duration": 5.7,
        "text": "every next server gives you nothing"
      },
      {
        "start": 2729.16,
        "duration": 6.48,
        "text": "and this line basically shows like how"
      },
      {
        "start": 2732.22,
        "duration": 5.399,
        "text": "Cassandra scales linearly and adding"
      },
      {
        "start": 2735.64,
        "duration": 6.12,
        "text": "more nodes you get more and more volume"
      },
      {
        "start": 2737.619,
        "duration": 6.061,
        "text": "and ability to process queries"
      },
      {
        "start": 2741.76,
        "duration": 6.78,
        "text": "and still get"
      },
      {
        "start": 2743.68,
        "duration": 7.679,
        "text": "that on time please notice this Mark you"
      },
      {
        "start": 2748.54,
        "duration": 5.4,
        "text": "know when you read uh contracts I don't"
      },
      {
        "start": 2751.359,
        "duration": 5.281,
        "text": "know whatever mortgage or loan contracts"
      },
      {
        "start": 2753.94,
        "duration": 5.1,
        "text": "or job contracts you really need to pay"
      },
      {
        "start": 2756.64,
        "duration": 4.56,
        "text": "attention to a very small text on the"
      },
      {
        "start": 2759.04,
        "duration": 5.12,
        "text": "bottom of your document and do marks"
      },
      {
        "start": 2761.2,
        "duration": 5.46,
        "text": "like that those marks are very important"
      },
      {
        "start": 2764.16,
        "duration": 5.62,
        "text": "here is the same trigger this"
      },
      {
        "start": 2766.66,
        "duration": 5.82,
        "text": "scalability works but it's not only"
      },
      {
        "start": 2769.78,
        "duration": 4.74,
        "text": "Cassandra's job to do it to reach the"
      },
      {
        "start": 2772.48,
        "duration": 4.8,
        "text": "scalability you need to very well"
      },
      {
        "start": 2774.52,
        "duration": 4.079,
        "text": "understand how to do your data model"
      },
      {
        "start": 2777.28,
        "duration": 4.44,
        "text": "right"
      },
      {
        "start": 2778.599,
        "duration": 5.281,
        "text": "and if you don't do your job it will not"
      },
      {
        "start": 2781.72,
        "duration": 5.639,
        "text": "work like that so you still have to do"
      },
      {
        "start": 2783.88,
        "duration": 5.58,
        "text": "your job lucky for you guys that uh"
      },
      {
        "start": 2787.359,
        "duration": 4.381,
        "text": "inventor developer of data modeling"
      },
      {
        "start": 2789.46,
        "duration": 4.44,
        "text": "methodology is we fast today and he will"
      },
      {
        "start": 2791.74,
        "duration": 4.5,
        "text": "be with us next week and next week"
      },
      {
        "start": 2793.9,
        "duration": 4.14,
        "text": "Workshop is all dedicated to data"
      },
      {
        "start": 2796.24,
        "duration": 4.74,
        "text": "modeling and how do you do your data"
      },
      {
        "start": 2798.04,
        "duration": 5.039,
        "text": "model right so your application may work"
      },
      {
        "start": 2800.98,
        "duration": 5.099,
        "text": "efficiently and your system will scale"
      },
      {
        "start": 2803.079,
        "duration": 4.861,
        "text": "even handling millions and millions and"
      },
      {
        "start": 2806.079,
        "duration": 4.581,
        "text": "millions of customers from very"
      },
      {
        "start": 2807.94,
        "duration": 8.34,
        "text": "different regions"
      },
      {
        "start": 2810.66,
        "duration": 7.959,
        "text": "hi Alex I would add for this graph"
      },
      {
        "start": 2816.28,
        "duration": 4.559,
        "text": "so when we talk about scalability we"
      },
      {
        "start": 2818.619,
        "duration": 5.941,
        "text": "sometimes say okay will it scale from"
      },
      {
        "start": 2820.839,
        "duration": 6.181,
        "text": "gigabytes to terabytes to petabytes and"
      },
      {
        "start": 2824.56,
        "duration": 5.46,
        "text": "this is one notion like ability to store"
      },
      {
        "start": 2827.02,
        "duration": 5.099,
        "text": "large data sets and on this graph we're"
      },
      {
        "start": 2830.02,
        "duration": 4.86,
        "text": "actually looking at different type of"
      },
      {
        "start": 2832.119,
        "duration": 5.761,
        "text": "scalability it's It's a throughput high"
      },
      {
        "start": 2834.88,
        "duration": 6.06,
        "text": "throughput so essentially we measuring"
      },
      {
        "start": 2837.88,
        "duration": 7.199,
        "text": "how many operations per second can a"
      },
      {
        "start": 2840.94,
        "duration": 6.48,
        "text": "cluster process and you of course with"
      },
      {
        "start": 2845.079,
        "duration": 4.561,
        "text": "when we add those nodes we can also"
      },
      {
        "start": 2847.42,
        "duration": 4.62,
        "text": "store data more and more data on those"
      },
      {
        "start": 2849.64,
        "duration": 5.1,
        "text": "nodes but also you can see it scales"
      },
      {
        "start": 2852.04,
        "duration": 5.34,
        "text": "linearly in terms of this throughput and"
      },
      {
        "start": 2854.74,
        "duration": 5.28,
        "text": "and the big question here is why why do"
      },
      {
        "start": 2857.38,
        "duration": 5.34,
        "text": "you care about this right yeah so if you"
      },
      {
        "start": 2860.02,
        "duration": 6.36,
        "text": "expect to build an application that is"
      },
      {
        "start": 2862.72,
        "duration": 6.18,
        "text": "high growth application that is going to"
      },
      {
        "start": 2866.38,
        "duration": 5.219,
        "text": "eventually grow and grow and and add"
      },
      {
        "start": 2868.9,
        "duration": 5.04,
        "text": "more and more users that generate more"
      },
      {
        "start": 2871.599,
        "duration": 5.061,
        "text": "and more data then you you should care"
      },
      {
        "start": 2873.94,
        "duration": 5.639,
        "text": "about this because this is going to be a"
      },
      {
        "start": 2876.66,
        "duration": 5.439,
        "text": "the only way how you're gonna scale you"
      },
      {
        "start": 2879.579,
        "duration": 5.941,
        "text": "don't want to non-linear scalability you"
      },
      {
        "start": 2882.099,
        "duration": 4.921,
        "text": "want to scale linearly in this case"
      },
      {
        "start": 2885.52,
        "duration": 3.98,
        "text": "yep"
      },
      {
        "start": 2887.02,
        "duration": 2.48,
        "text": "good"
      },
      {
        "start": 2891.88,
        "duration": 2.479,
        "text": "okay"
      },
      {
        "start": 2894.88,
        "duration": 5.64,
        "text": "uh yes games of course for reads you see"
      },
      {
        "start": 2898.3,
        "duration": 6.84,
        "text": "uh yeah a very good point from James"
      },
      {
        "start": 2900.52,
        "duration": 7.079,
        "text": "Wong that is about client rights uh but"
      },
      {
        "start": 2905.14,
        "duration": 5.34,
        "text": "point is why we show rights here is"
      },
      {
        "start": 2907.599,
        "duration": 6.0,
        "text": "scaling for reads is easy"
      },
      {
        "start": 2910.48,
        "duration": 5.58,
        "text": "scaling for reads you just even in"
      },
      {
        "start": 2913.599,
        "duration": 5.461,
        "text": "traditional architecture primary server"
      },
      {
        "start": 2916.06,
        "duration": 6.12,
        "text": "a follower server you just add more"
      },
      {
        "start": 2919.06,
        "duration": 5.519,
        "text": "follower servers you spread read"
      },
      {
        "start": 2922.18,
        "duration": 4.86,
        "text": "workloads over multiple servers and you"
      },
      {
        "start": 2924.579,
        "duration": 4.321,
        "text": "will be good"
      },
      {
        "start": 2927.04,
        "duration": 5.1,
        "text": "um"
      },
      {
        "start": 2928.9,
        "duration": 4.8,
        "text": "then uh scaling for right is a real"
      },
      {
        "start": 2932.14,
        "duration": 3.959,
        "text": "problem because in traditional"
      },
      {
        "start": 2933.7,
        "duration": 5.82,
        "text": "architecture you cannot just have to"
      },
      {
        "start": 2936.099,
        "duration": 7.621,
        "text": "master servers or to lead your servers"
      },
      {
        "start": 2939.52,
        "duration": 6.839,
        "text": "that is a problem yep and um to Adriana"
      },
      {
        "start": 2943.72,
        "duration": 6.0,
        "text": "I see Cedric answer it already in"
      },
      {
        "start": 2946.359,
        "duration": 6.5,
        "text": "Cassandra terminology node and server is"
      },
      {
        "start": 2949.72,
        "duration": 5.82,
        "text": "basically the same it's just synonyms"
      },
      {
        "start": 2952.859,
        "duration": 6.101,
        "text": "note is the server with Cassandra"
      },
      {
        "start": 2955.54,
        "duration": 6.299,
        "text": "running on it so simple as that yeah"
      },
      {
        "start": 2958.96,
        "duration": 6.6,
        "text": "uh load balancing we will explain soon"
      },
      {
        "start": 2961.839,
        "duration": 6.661,
        "text": "it comes it comes you will see it good"
      },
      {
        "start": 2965.56,
        "duration": 4.68,
        "text": "next thing highest availability we"
      },
      {
        "start": 2968.5,
        "duration": 4.619,
        "text": "discussed that already what we want our"
      },
      {
        "start": 2970.24,
        "duration": 5.879,
        "text": "application to be available all the time"
      },
      {
        "start": 2973.119,
        "duration": 6.061,
        "text": "first thing we cannot have high"
      },
      {
        "start": 2976.119,
        "duration": 5.941,
        "text": "availability without replication we need"
      },
      {
        "start": 2979.18,
        "duration": 5.22,
        "text": "to have a very same data but copy it on"
      },
      {
        "start": 2982.06,
        "duration": 5.58,
        "text": "multiple different servers"
      },
      {
        "start": 2984.4,
        "duration": 6.02,
        "text": "and that is a very important thing so"
      },
      {
        "start": 2987.64,
        "duration": 6.24,
        "text": "the data is placed on different servers"
      },
      {
        "start": 2990.42,
        "duration": 6.04,
        "text": "on usually on different regions then"
      },
      {
        "start": 2993.88,
        "duration": 5.4,
        "text": "death centralization that centralization"
      },
      {
        "start": 2996.46,
        "duration": 5.159,
        "text": "mean version no idea of a master server"
      },
      {
        "start": 2999.28,
        "duration": 5.12,
        "text": "all servers are the same it's"
      },
      {
        "start": 3001.619,
        "duration": 6.421,
        "text": "decentralized peer-to-peer architecture"
      },
      {
        "start": 3004.4,
        "duration": 5.98,
        "text": "RTM will soon say more about that"
      },
      {
        "start": 3008.04,
        "duration": 5.88,
        "text": "so no single point of failure there is"
      },
      {
        "start": 3010.38,
        "duration": 6.54,
        "text": "no outage of the leader server uh then"
      },
      {
        "start": 3013.92,
        "duration": 4.98,
        "text": "Network topology aware data placement so"
      },
      {
        "start": 3016.92,
        "duration": 5.28,
        "text": "here is a thing like if you do a backup"
      },
      {
        "start": 3018.9,
        "duration": 6.36,
        "text": "of your laptop disk you will not store"
      },
      {
        "start": 3022.2,
        "duration": 5.399,
        "text": "this backup on the same disk on your"
      },
      {
        "start": 3025.26,
        "duration": 4.5,
        "text": "laptop right it makes no sense then if"
      },
      {
        "start": 3027.599,
        "duration": 4.5,
        "text": "your disk is damaged or I don't know"
      },
      {
        "start": 3029.76,
        "duration": 4.5,
        "text": "stolen you don't have access to the"
      },
      {
        "start": 3032.099,
        "duration": 3.72,
        "text": "backup files right if you make a backup"
      },
      {
        "start": 3034.26,
        "duration": 4.44,
        "text": "you put it to a different place"
      },
      {
        "start": 3035.819,
        "duration": 5.04,
        "text": "preferably different physical location"
      },
      {
        "start": 3038.7,
        "duration": 4.379,
        "text": "Cassandra is very smart from Network"
      },
      {
        "start": 3040.859,
        "duration": 5.521,
        "text": "topology point of view so those"
      },
      {
        "start": 3043.079,
        "duration": 5.161,
        "text": "different replicas must be first on for"
      },
      {
        "start": 3046.38,
        "duration": 5.16,
        "text": "obviously on different servers but"
      },
      {
        "start": 3048.24,
        "duration": 5.339,
        "text": "preferably on different server racks or"
      },
      {
        "start": 3051.54,
        "duration": 4.079,
        "text": "if we speak Cloud on different"
      },
      {
        "start": 3053.579,
        "duration": 5.341,
        "text": "availability zones"
      },
      {
        "start": 3055.619,
        "duration": 5.821,
        "text": "so uh outage of availability zone or"
      },
      {
        "start": 3058.92,
        "duration": 5.22,
        "text": "outage of a single server rack doesn't"
      },
      {
        "start": 3061.44,
        "duration": 7.679,
        "text": "lead to outage of all available replicas"
      },
      {
        "start": 3064.14,
        "duration": 4.979,
        "text": "obviously and then finally cloud"
      },
      {
        "start": 3069.599,
        "duration": 5.76,
        "text": "a very smart client-side reconnection"
      },
      {
        "start": 3072.54,
        "duration": 5.22,
        "text": "and retry mechanism so Cassandra drivers"
      },
      {
        "start": 3075.359,
        "duration": 5.161,
        "text": "mostly developed by data Stacks also"
      },
      {
        "start": 3077.76,
        "duration": 4.62,
        "text": "very smart and they know how to"
      },
      {
        "start": 3080.52,
        "duration": 4.319,
        "text": "reconnect how to find different nodes"
      },
      {
        "start": 3082.38,
        "duration": 5.58,
        "text": "and so on and so forth I see there are"
      },
      {
        "start": 3084.839,
        "duration": 4.621,
        "text": "some great questions in the chat uh I"
      },
      {
        "start": 3087.96,
        "duration": 2.46,
        "text": "hope you will have a chance to answer"
      },
      {
        "start": 3089.46,
        "duration": 3.48,
        "text": "them"
      },
      {
        "start": 3090.42,
        "duration": 5.46,
        "text": "soon I want to get to a date but first I"
      },
      {
        "start": 3092.94,
        "duration": 6.119,
        "text": "want to finish this part of them"
      },
      {
        "start": 3095.88,
        "duration": 6.739,
        "text": "slides now very important five thing for"
      },
      {
        "start": 3099.059,
        "duration": 7.26,
        "text": "me per person as someone also"
      },
      {
        "start": 3102.619,
        "duration": 5.881,
        "text": "responsible for operations for some big"
      },
      {
        "start": 3106.319,
        "duration": 5.04,
        "text": "applications clusters and things"
      },
      {
        "start": 3108.5,
        "duration": 5.98,
        "text": "operations and maintenance of a huge"
      },
      {
        "start": 3111.359,
        "duration": 5.341,
        "text": "cluster can be very exhaustive Apache"
      },
      {
        "start": 3114.48,
        "duration": 4.26,
        "text": "Cassandra clusters are very smart and"
      },
      {
        "start": 3116.7,
        "duration": 5.899,
        "text": "there are many of operations automated"
      },
      {
        "start": 3118.74,
        "duration": 6.72,
        "text": "so introducing a new node moving data"
      },
      {
        "start": 3122.599,
        "duration": 5.98,
        "text": "recovering from inconsistency recovery"
      },
      {
        "start": 3125.46,
        "duration": 6.0,
        "text": "from outage changing data placement"
      },
      {
        "start": 3128.579,
        "duration": 5.941,
        "text": "because of some changes very many"
      },
      {
        "start": 3131.46,
        "duration": 5.159,
        "text": "operations are automated whereas some"
      },
      {
        "start": 3134.52,
        "duration": 3.96,
        "text": "level of self-healing introduce it and"
      },
      {
        "start": 3136.619,
        "duration": 5.101,
        "text": "very often we can recover from a bad"
      },
      {
        "start": 3138.48,
        "duration": 6.66,
        "text": "State uh completely automatically with"
      },
      {
        "start": 3141.72,
        "duration": 6.839,
        "text": "no manual operations required not always"
      },
      {
        "start": 3145.14,
        "duration": 5.64,
        "text": "but very often and that like I'm a lazy"
      },
      {
        "start": 3148.559,
        "duration": 4.621,
        "text": "engineer if I can avoid some work I will"
      },
      {
        "start": 3150.78,
        "duration": 6.62,
        "text": "avoid this work and then database is"
      },
      {
        "start": 3153.18,
        "duration": 4.22,
        "text": "doing my work for me I'm totally happy"
      },
      {
        "start": 3157.559,
        "duration": 3.601,
        "text": "good"
      },
      {
        "start": 3158.76,
        "duration": 4.5,
        "text": "and well uh geographical distribution"
      },
      {
        "start": 3161.16,
        "duration": 4.919,
        "text": "already discussed so I don't want to"
      },
      {
        "start": 3163.26,
        "duration": 5.16,
        "text": "stick on this slide for too long or just"
      },
      {
        "start": 3166.079,
        "duration": 5.28,
        "text": "one more thing just one thing again"
      },
      {
        "start": 3168.42,
        "duration": 6.06,
        "text": "openly misunderstood data centers all"
      },
      {
        "start": 3171.359,
        "duration": 6.061,
        "text": "are active so you can write and read to"
      },
      {
        "start": 3174.48,
        "duration": 6.18,
        "text": "and from any of the data centers in this"
      },
      {
        "start": 3177.42,
        "duration": 5.96,
        "text": "case one in United States one in Europe"
      },
      {
        "start": 3180.66,
        "duration": 6.48,
        "text": "and one in Asia"
      },
      {
        "start": 3183.38,
        "duration": 7.42,
        "text": "now Fink mentioned it before uh by artem"
      },
      {
        "start": 3187.14,
        "duration": 6.3,
        "text": "uh Cassandra is a open source platform"
      },
      {
        "start": 3190.8,
        "duration": 5.039,
        "text": "agnostic so you can run it only on your"
      },
      {
        "start": 3193.44,
        "duration": 5.3,
        "text": "own data center on Google cloud and"
      },
      {
        "start": 3195.839,
        "duration": 5.581,
        "text": "Microsoft Azure or Amazon web services"
      },
      {
        "start": 3198.74,
        "duration": 5.98,
        "text": "simultaneously and all those data"
      },
      {
        "start": 3201.42,
        "duration": 6.179,
        "text": "centers can build a single cluster"
      },
      {
        "start": 3204.72,
        "duration": 6.839,
        "text": "so you can survive outage of the wall"
      },
      {
        "start": 3207.599,
        "duration": 6.601,
        "text": "cloud even if the wall AWS gets down"
      },
      {
        "start": 3211.559,
        "duration": 5.101,
        "text": "somehow you still will have three data"
      },
      {
        "start": 3214.2,
        "duration": 7.2,
        "text": "centers here on this example running"
      },
      {
        "start": 3216.66,
        "duration": 6.14,
        "text": "successfully same data same Data Center"
      },
      {
        "start": 3221.4,
        "duration": 5.1,
        "text": "good"
      },
      {
        "start": 3222.8,
        "duration": 5.74,
        "text": "uh and yeah as mentioned it Cassandra is"
      },
      {
        "start": 3226.5,
        "duration": 4.559,
        "text": "well"
      },
      {
        "start": 3228.54,
        "duration": 4.98,
        "text": "many people know what data Stacks is"
      },
      {
        "start": 3231.059,
        "duration": 5.581,
        "text": "like commercial face of Apache Cassandra"
      },
      {
        "start": 3233.52,
        "duration": 4.559,
        "text": "we could say uh but actually Cassandra"
      },
      {
        "start": 3236.64,
        "duration": 3.6,
        "text": "does not belong to any commercial"
      },
      {
        "start": 3238.079,
        "duration": 4.98,
        "text": "lavender Cassandra belongs to and"
      },
      {
        "start": 3240.24,
        "duration": 5.3,
        "text": "control it by a non-profit open source a"
      },
      {
        "start": 3243.059,
        "duration": 5.161,
        "text": "bunch of software Foundation"
      },
      {
        "start": 3245.54,
        "duration": 5.44,
        "text": "which you might know by projects like"
      },
      {
        "start": 3248.22,
        "duration": 5.22,
        "text": "Apache Kafka zookeeper Maven Hadoop"
      },
      {
        "start": 3250.98,
        "duration": 5.28,
        "text": "spark and many many others maybe airflow"
      },
      {
        "start": 3253.44,
        "duration": 4.44,
        "text": "a Vera plenty of different products you"
      },
      {
        "start": 3256.26,
        "duration": 4.319,
        "text": "may know"
      },
      {
        "start": 3257.88,
        "duration": 6.199,
        "text": "uh last thing on this part before we"
      },
      {
        "start": 3260.579,
        "duration": 3.5,
        "text": "will be answering questions yep"
      },
      {
        "start": 3265.74,
        "duration": 5.339,
        "text": "there is a price to pay you remember"
      },
      {
        "start": 3267.9,
        "duration": 5.82,
        "text": "before we said what specialization is if"
      },
      {
        "start": 3271.079,
        "duration": 5.881,
        "text": "it is effective yes but specialization"
      },
      {
        "start": 3273.72,
        "duration": 6.359,
        "text": "means what you cannot be good in all the"
      },
      {
        "start": 3276.96,
        "duration": 7.399,
        "text": "things you spend some time becoming a"
      },
      {
        "start": 3280.079,
        "duration": 8.341,
        "text": "doctor I don't know dentist or whatever"
      },
      {
        "start": 3284.359,
        "duration": 6.401,
        "text": "cardiologist that mostly probably means"
      },
      {
        "start": 3288.42,
        "duration": 5.04,
        "text": "what you are not going to be a very good"
      },
      {
        "start": 3290.76,
        "duration": 6.299,
        "text": "race driver right because your time is"
      },
      {
        "start": 3293.46,
        "duration": 5.7,
        "text": "dedicated for like biology all the kind"
      },
      {
        "start": 3297.059,
        "duration": 4.201,
        "text": "of things that relate to human body and"
      },
      {
        "start": 3299.16,
        "duration": 4.439,
        "text": "so on and you don't have time to become"
      },
      {
        "start": 3301.26,
        "duration": 3.839,
        "text": "a race driver because it also requires a"
      },
      {
        "start": 3303.599,
        "duration": 4.081,
        "text": "lot of time and the same with race"
      },
      {
        "start": 3305.099,
        "duration": 4.381,
        "text": "drivers they're not going to be good"
      },
      {
        "start": 3307.68,
        "duration": 4.74,
        "text": "doctors most of them right"
      },
      {
        "start": 3309.48,
        "duration": 6.02,
        "text": "so what are the limitations we are going"
      },
      {
        "start": 3312.42,
        "duration": 5.82,
        "text": "to encounter very soon first"
      },
      {
        "start": 3315.5,
        "duration": 5.619,
        "text": "Cassandra's Apache Cassandra supports no"
      },
      {
        "start": 3318.24,
        "duration": 4.619,
        "text": "joints there cannot be joins between"
      },
      {
        "start": 3321.119,
        "duration": 5.581,
        "text": "multiple tables"
      },
      {
        "start": 3322.859,
        "duration": 5.881,
        "text": "so you will see this operating data"
      },
      {
        "start": 3326.7,
        "duration": 5.359,
        "text": "you need to know the partition case"
      },
      {
        "start": 3328.74,
        "duration": 6.839,
        "text": "because data is data distribution"
      },
      {
        "start": 3332.059,
        "duration": 5.201,
        "text": "partitioning is based on the key we show"
      },
      {
        "start": 3335.579,
        "duration": 3.601,
        "text": "it soon in a moment don't focus on that"
      },
      {
        "start": 3337.26,
        "duration": 5.16,
        "text": "right now but there are some limitations"
      },
      {
        "start": 3339.18,
        "duration": 5.399,
        "text": "on how could we execute the queries very"
      },
      {
        "start": 3342.42,
        "duration": 4.919,
        "text": "limited search capabilities so if you"
      },
      {
        "start": 3344.579,
        "duration": 5.48,
        "text": "need to have a full text search then"
      },
      {
        "start": 3347.339,
        "duration": 5.461,
        "text": "mostly probably you will need some"
      },
      {
        "start": 3350.059,
        "duration": 4.3,
        "text": "collaboration between Cassandra and for"
      },
      {
        "start": 3352.8,
        "duration": 3.42,
        "text": "example elastic Church"
      },
      {
        "start": 3354.359,
        "duration": 5.041,
        "text": "and of course"
      },
      {
        "start": 3356.22,
        "duration": 5.3,
        "text": "running big clusters usually require a"
      },
      {
        "start": 3359.4,
        "duration": 5.219,
        "text": "lot of qualified personnel"
      },
      {
        "start": 3361.52,
        "duration": 5.62,
        "text": "developers operators and so on we at"
      },
      {
        "start": 3364.619,
        "duration": 4.861,
        "text": "data Stacks work hard to make things"
      },
      {
        "start": 3367.14,
        "duration": 5.16,
        "text": "simpler for their Global software"
      },
      {
        "start": 3369.48,
        "duration": 5.46,
        "text": "development Community around the world"
      },
      {
        "start": 3372.3,
        "duration": 6.0,
        "text": "so first thing require first my answer"
      },
      {
        "start": 3374.94,
        "duration": 5.94,
        "text": "to the required qualified personnel"
      },
      {
        "start": 3378.3,
        "duration": 3.72,
        "text": "first of all yep you want to say"
      },
      {
        "start": 3380.88,
        "duration": 3.66,
        "text": "something"
      },
      {
        "start": 3382.02,
        "duration": 6.36,
        "text": "yeah Alex how about asset transactions"
      },
      {
        "start": 3384.54,
        "duration": 6.36,
        "text": "that's okay as a transaction because"
      },
      {
        "start": 3388.38,
        "duration": 4.38,
        "text": "this is usually pretty important for"
      },
      {
        "start": 3390.9,
        "duration": 3.199,
        "text": "well and pretty standard in relational"
      },
      {
        "start": 3392.76,
        "duration": 4.62,
        "text": "database"
      },
      {
        "start": 3394.099,
        "duration": 5.74,
        "text": "uh yes right well it's a complicated"
      },
      {
        "start": 3397.38,
        "duration": 4.86,
        "text": "question because a current current"
      },
      {
        "start": 3399.839,
        "duration": 5.821,
        "text": "version does not"
      },
      {
        "start": 3402.24,
        "duration": 6.24,
        "text": "uh but uh it comes in garbage Cassandra"
      },
      {
        "start": 3405.66,
        "duration": 6.24,
        "text": "version 5 to be expected release"
      },
      {
        "start": 3408.48,
        "duration": 6.24,
        "text": "somewhere 2023 somewhere this year oh"
      },
      {
        "start": 3411.9,
        "duration": 4.02,
        "text": "this year already amazing"
      },
      {
        "start": 3414.72,
        "duration": 4.08,
        "text": "yeah"
      },
      {
        "start": 3415.92,
        "duration": 5.159,
        "text": "so yeah I have to add this thing to this"
      },
      {
        "start": 3418.8,
        "duration": 5.4,
        "text": "slide right consistency may be"
      },
      {
        "start": 3421.079,
        "duration": 6.54,
        "text": "challenging in some situations so with"
      },
      {
        "start": 3424.2,
        "duration": 5.639,
        "text": "all this limitation limitations what why"
      },
      {
        "start": 3427.619,
        "duration": 3.921,
        "text": "would I want to use"
      },
      {
        "start": 3429.839,
        "duration": 5.341,
        "text": "Cassandra"
      },
      {
        "start": 3431.54,
        "duration": 6.64,
        "text": "because it's if you want to have all of"
      },
      {
        "start": 3435.18,
        "duration": 6.24,
        "text": "this most of all uh"
      },
      {
        "start": 3438.18,
        "duration": 5.46,
        "text": "Cassandra faces oltp workloads but for"
      },
      {
        "start": 3441.42,
        "duration": 4.439,
        "text": "many scenarios you may need to use a"
      },
      {
        "start": 3443.64,
        "duration": 5.82,
        "text": "data platform like we have for example"
      },
      {
        "start": 3445.859,
        "duration": 5.7,
        "text": "with Astra data Stacks Astra is a data"
      },
      {
        "start": 3449.46,
        "duration": 4.68,
        "text": "platform based on Apache Cassandra but"
      },
      {
        "start": 3451.559,
        "duration": 4.921,
        "text": "extended with some new capabilities well"
      },
      {
        "start": 3454.14,
        "duration": 4.8,
        "text": "this Workshop we are focused on the open"
      },
      {
        "start": 3456.48,
        "duration": 5.04,
        "text": "source side of things but if you want to"
      },
      {
        "start": 3458.94,
        "duration": 3.619,
        "text": "answer dozens millions of queries per"
      },
      {
        "start": 3461.52,
        "duration": 3.599,
        "text": "second"
      },
      {
        "start": 3462.559,
        "duration": 4.121,
        "text": "uh over the world you need to pay"
      },
      {
        "start": 3465.119,
        "duration": 4.681,
        "text": "something for that right and you don't"
      },
      {
        "start": 3466.68,
        "duration": 7.02,
        "text": "mean money but I mean capabilities can"
      },
      {
        "start": 3469.8,
        "duration": 7.5,
        "text": "so scalability is unmatched relational"
      },
      {
        "start": 3473.7,
        "duration": 6.24,
        "text": "database cannot scale nope the way"
      },
      {
        "start": 3477.3,
        "duration": 4.799,
        "text": "Cassandra scales and the other thing is"
      },
      {
        "start": 3479.94,
        "duration": 6.06,
        "text": "the availability right the relational"
      },
      {
        "start": 3482.099,
        "duration": 6.901,
        "text": "database cannot uh cannot do that cannot"
      },
      {
        "start": 3486.0,
        "duration": 5.4,
        "text": "uh provide High availability that we"
      },
      {
        "start": 3489.0,
        "duration": 4.5,
        "text": "talked about that thank you so much for"
      },
      {
        "start": 3491.4,
        "duration": 4.5,
        "text": "mentioning that like I was many times in"
      },
      {
        "start": 3493.5,
        "duration": 4.44,
        "text": "a situation when I talk with some"
      },
      {
        "start": 3495.9,
        "duration": 4.679,
        "text": "developers at the conference"
      },
      {
        "start": 3497.94,
        "duration": 4.98,
        "text": "and I say like Cassandra skills better"
      },
      {
        "start": 3500.579,
        "duration": 4.201,
        "text": "than the database you are current"
      },
      {
        "start": 3502.92,
        "duration": 5.159,
        "text": "currently using and like what do you"
      },
      {
        "start": 3504.78,
        "duration": 5.16,
        "text": "mean our database scales too what do you"
      },
      {
        "start": 3508.079,
        "duration": 4.561,
        "text": "use postgres okay postgres is a good"
      },
      {
        "start": 3509.94,
        "duration": 4.86,
        "text": "database amazing database it's like for"
      },
      {
        "start": 3512.64,
        "duration": 5.76,
        "text": "many use cases postgres will be better"
      },
      {
        "start": 3514.8,
        "duration": 7.68,
        "text": "than Cassandra I I mean like uh yes sure"
      },
      {
        "start": 3518.4,
        "duration": 6.959,
        "text": "but what is that what do you call scale"
      },
      {
        "start": 3522.48,
        "duration": 6.54,
        "text": "like what is your workload currently oh"
      },
      {
        "start": 3525.359,
        "duration": 5.22,
        "text": "we handle up to 30 000 operations per"
      },
      {
        "start": 3529.02,
        "duration": 3.18,
        "text": "second"
      },
      {
        "start": 3530.579,
        "duration": 3.201,
        "text": "that's cute"
      },
      {
        "start": 3532.2,
        "duration": 4.68,
        "text": "that's cute"
      },
      {
        "start": 3533.78,
        "duration": 5.5,
        "text": "uh then I speak about scale I mean"
      },
      {
        "start": 3536.88,
        "duration": 5.699,
        "text": "Millions operations per second not"
      },
      {
        "start": 3539.28,
        "duration": 6.24,
        "text": "thousands not thousands thousands not"
      },
      {
        "start": 3542.579,
        "duration": 7.26,
        "text": "hundreds thousands like and there at"
      },
      {
        "start": 3545.52,
        "duration": 7.74,
        "text": "this place or uh multi-data Center"
      },
      {
        "start": 3549.839,
        "duration": 8.341,
        "text": "um active active uh postgres try to have"
      },
      {
        "start": 3553.26,
        "duration": 6.78,
        "text": "a multi multi-active DC but uh with"
      },
      {
        "start": 3558.18,
        "duration": 4.26,
        "text": "traditional relational databases it's"
      },
      {
        "start": 3560.04,
        "duration": 5.279,
        "text": "nearly impossible"
      },
      {
        "start": 3562.44,
        "duration": 6.06,
        "text": "yeah so that is the benefit let's say"
      },
      {
        "start": 3565.319,
        "duration": 4.98,
        "text": "we have a good question whether I'm"
      },
      {
        "start": 3568.5,
        "duration": 3.96,
        "text": "sorry I have to finish this slide first"
      },
      {
        "start": 3570.299,
        "duration": 4.861,
        "text": "and let's uh get to questions afterwards"
      },
      {
        "start": 3572.46,
        "duration": 5.58,
        "text": "so required qualified personal there are"
      },
      {
        "start": 3575.16,
        "duration": 4.86,
        "text": "two answers from me first one very"
      },
      {
        "start": 3578.04,
        "duration": 3.84,
        "text": "important one there were a question in"
      },
      {
        "start": 3580.02,
        "duration": 5.099,
        "text": "the chat before uh what about the"
      },
      {
        "start": 3581.88,
        "duration": 6.719,
        "text": "certification data stocks sponsors your"
      },
      {
        "start": 3585.119,
        "duration": 6.24,
        "text": "education and certification uh as Apache"
      },
      {
        "start": 3588.599,
        "duration": 5.401,
        "text": "Cassandra developer or administrator so"
      },
      {
        "start": 3591.359,
        "duration": 4.801,
        "text": "you can get your trainings pass yours"
      },
      {
        "start": 3594.0,
        "duration": 3.66,
        "text": "plus you take your exam and become a"
      },
      {
        "start": 3596.16,
        "duration": 3.419,
        "text": "certified Cassandra developer"
      },
      {
        "start": 3597.66,
        "duration": 4.86,
        "text": "administrator completely for free"
      },
      {
        "start": 3599.579,
        "duration": 5.901,
        "text": "sponsored by data stacks and that's our"
      },
      {
        "start": 3602.52,
        "duration": 5.7,
        "text": "first answer second answer is Astra"
      },
      {
        "start": 3605.48,
        "duration": 5.2,
        "text": "Astro you will see today Astra is the"
      },
      {
        "start": 3608.22,
        "duration": 5.7,
        "text": "way for you to use Cassandra as a"
      },
      {
        "start": 3610.68,
        "duration": 5.879,
        "text": "database as a service with no need for"
      },
      {
        "start": 3613.92,
        "duration": 5.639,
        "text": "you to maintain and"
      },
      {
        "start": 3616.559,
        "duration": 5.641,
        "text": "service and do all the things required"
      },
      {
        "start": 3619.559,
        "duration": 4.02,
        "text": "by a database cluster it will be done by"
      },
      {
        "start": 3622.2,
        "duration": 4.619,
        "text": "data stacks"
      },
      {
        "start": 3623.579,
        "duration": 5.641,
        "text": "so it's really a very good solution for"
      },
      {
        "start": 3626.819,
        "duration": 4.26,
        "text": "the cases you focus on your customer"
      },
      {
        "start": 3629.22,
        "duration": 4.32,
        "text": "needs and don't spend your time"
      },
      {
        "start": 3631.079,
        "duration": 5.04,
        "text": "maintaining a database"
      },
      {
        "start": 3633.54,
        "duration": 4.5,
        "text": "a very limited search capabilities very"
      },
      {
        "start": 3636.119,
        "duration": 2.72,
        "text": "limited search capabilities also has an"
      },
      {
        "start": 3638.04,
        "duration": 4.38,
        "text": "answer"
      },
      {
        "start": 3638.839,
        "duration": 7.121,
        "text": "so Cassandra works perfectly for example"
      },
      {
        "start": 3642.42,
        "duration": 6.659,
        "text": "working with elasticsearch with for some"
      },
      {
        "start": 3645.96,
        "duration": 5.58,
        "text": "cases you may need a patch spark so for"
      },
      {
        "start": 3649.079,
        "duration": 6.181,
        "text": "uh huge deployments with multiple"
      },
      {
        "start": 3651.54,
        "duration": 6.24,
        "text": "requirements from both olap and oltp"
      },
      {
        "start": 3655.26,
        "duration": 4.62,
        "text": "uh you may need to use multiple projects"
      },
      {
        "start": 3657.78,
        "duration": 4.38,
        "text": "simultaneously recently we introduced a"
      },
      {
        "start": 3659.88,
        "duration": 4.919,
        "text": "change data capture for Apache Cassandra"
      },
      {
        "start": 3662.16,
        "duration": 4.56,
        "text": "and open source it's a change data"
      },
      {
        "start": 3664.799,
        "duration": 4.081,
        "text": "capture for Apache Cassandra which helps"
      },
      {
        "start": 3666.72,
        "duration": 3.8,
        "text": "to communicate Cassandra with multiple"
      },
      {
        "start": 3668.88,
        "duration": 3.719,
        "text": "different"
      },
      {
        "start": 3670.52,
        "duration": 4.18,
        "text": "Technologies you may need to work"
      },
      {
        "start": 3672.599,
        "duration": 3.601,
        "text": "together with"
      },
      {
        "start": 3674.7,
        "duration": 2.22,
        "text": "and"
      },
      {
        "start": 3676.2,
        "duration": 4.26,
        "text": "um"
      },
      {
        "start": 3676.92,
        "duration": 6.72,
        "text": "so wherever questions you wanted us to"
      },
      {
        "start": 3680.46,
        "duration": 4.74,
        "text": "answer right yeah that was a interesting"
      },
      {
        "start": 3683.64,
        "duration": 4.5,
        "text": "question whether if we introduce"
      },
      {
        "start": 3685.2,
        "duration": 4.619,
        "text": "multiple uh data centers will"
      },
      {
        "start": 3688.14,
        "duration": 3.24,
        "text": "performance slow down a little bit"
      },
      {
        "start": 3689.819,
        "duration": 4.681,
        "text": "slower"
      },
      {
        "start": 3691.38,
        "duration": 5.28,
        "text": "will it will there be overhead I'm"
      },
      {
        "start": 3694.5,
        "duration": 5.04,
        "text": "rephrasing it"
      },
      {
        "start": 3696.66,
        "duration": 5.34,
        "text": "okay uh you mean question by Mao Andy"
      },
      {
        "start": 3699.54,
        "duration": 4.559,
        "text": "yes in real world setting do we have"
      },
      {
        "start": 3702.0,
        "duration": 3.54,
        "text": "many cases to set up different to see in"
      },
      {
        "start": 3704.099,
        "duration": 4.5,
        "text": "different content in which includes"
      },
      {
        "start": 3705.54,
        "duration": 5.22,
        "text": "higher latency no so I mean so first"
      },
      {
        "start": 3708.599,
        "duration": 4.74,
        "text": "answer is yes there are many scenarios"
      },
      {
        "start": 3710.76,
        "duration": 4.799,
        "text": "where you want to have your data centers"
      },
      {
        "start": 3713.339,
        "duration": 5.661,
        "text": "in different regions first of all for"
      },
      {
        "start": 3715.559,
        "duration": 6.0,
        "text": "disaster tolerance second of all for"
      },
      {
        "start": 3719.0,
        "duration": 4.78,
        "text": "uh to keep your Australian clients"
      },
      {
        "start": 3721.559,
        "duration": 4.861,
        "text": "working with Australian instance of a"
      },
      {
        "start": 3723.78,
        "duration": 5.0,
        "text": "database so it will be quick uh it's"
      },
      {
        "start": 3726.42,
        "duration": 6.72,
        "text": "gonna be faster response"
      },
      {
        "start": 3728.78,
        "duration": 8.019,
        "text": "but there is a point what like in cure"
      },
      {
        "start": 3733.14,
        "duration": 6.659,
        "text": "higher latency and that is wrong"
      },
      {
        "start": 3736.799,
        "duration": 6.121,
        "text": "the story is your application server in"
      },
      {
        "start": 3739.799,
        "duration": 5.401,
        "text": "Australia will work with our Australian"
      },
      {
        "start": 3742.92,
        "duration": 5.34,
        "text": "Data Center and we will not wait for"
      },
      {
        "start": 3745.2,
        "duration": 4.619,
        "text": "European to answer it's writes data to"
      },
      {
        "start": 3748.26,
        "duration": 3.839,
        "text": "Australian Data Center and when"
      },
      {
        "start": 3749.819,
        "duration": 4.621,
        "text": "Australian data center will communicate"
      },
      {
        "start": 3752.099,
        "duration": 4.561,
        "text": "this mutation to all the other data"
      },
      {
        "start": 3754.44,
        "duration": 4.5,
        "text": "centers asynchronously well it depends"
      },
      {
        "start": 3756.66,
        "duration": 3.36,
        "text": "on your consistency level settings so"
      },
      {
        "start": 3758.94,
        "duration": 3.48,
        "text": "where"
      },
      {
        "start": 3760.02,
        "duration": 4.559,
        "text": "um maybe different scenarios but in"
      },
      {
        "start": 3762.42,
        "duration": 4.74,
        "text": "short working with Australian data"
      },
      {
        "start": 3764.579,
        "duration": 5.341,
        "text": "center you don't want for European data"
      },
      {
        "start": 3767.16,
        "duration": 5.34,
        "text": "center to answer okay"
      },
      {
        "start": 3769.92,
        "duration": 4.679,
        "text": "um yep but but for your application from"
      },
      {
        "start": 3772.5,
        "duration": 4.74,
        "text": "one data center data is replicated to"
      },
      {
        "start": 3774.599,
        "duration": 4.681,
        "text": "another data center in real time so that"
      },
      {
        "start": 3777.24,
        "duration": 5.16,
        "text": "latency will increase of course because"
      },
      {
        "start": 3779.28,
        "duration": 5.279,
        "text": "we're talking about larger distances but"
      },
      {
        "start": 3782.4,
        "duration": 5.459,
        "text": "like Alex said your application will"
      },
      {
        "start": 3784.559,
        "duration": 7.28,
        "text": "work with one data center which is which"
      },
      {
        "start": 3787.859,
        "duration": 8.341,
        "text": "is the closest to to that application"
      },
      {
        "start": 3791.839,
        "duration": 6.821,
        "text": "decreases in that case sorry uh there is"
      },
      {
        "start": 3796.2,
        "duration": 5.159,
        "text": "a good question by uh Josh Kumar Patel"
      },
      {
        "start": 3798.66,
        "duration": 4.98,
        "text": "in relational databases real application"
      },
      {
        "start": 3801.359,
        "duration": 6.661,
        "text": "cluster give horizontal scalability how"
      },
      {
        "start": 3803.64,
        "duration": 6.36,
        "text": "it differ uh the short answer is no in"
      },
      {
        "start": 3808.02,
        "duration": 4.099,
        "text": "relational databases horizontal"
      },
      {
        "start": 3810.0,
        "duration": 5.16,
        "text": "scalability is reachable only for"
      },
      {
        "start": 3812.119,
        "duration": 4.601,
        "text": "read-only replica so-called slaves or"
      },
      {
        "start": 3815.16,
        "duration": 4.5,
        "text": "follower servers"
      },
      {
        "start": 3816.72,
        "duration": 5.04,
        "text": "and for them you can have horizontal"
      },
      {
        "start": 3819.66,
        "duration": 5.939,
        "text": "scaling but notice you have horizontal"
      },
      {
        "start": 3821.76,
        "duration": 6.66,
        "text": "scaling only for reads because why you"
      },
      {
        "start": 3825.599,
        "duration": 4.5,
        "text": "cannot write follower servers they are"
      },
      {
        "start": 3828.42,
        "duration": 4.5,
        "text": "read only"
      },
      {
        "start": 3830.099,
        "duration": 5.641,
        "text": "so and to get horizontal scalability for"
      },
      {
        "start": 3832.92,
        "duration": 5.28,
        "text": "rights in relational databases it's"
      },
      {
        "start": 3835.74,
        "duration": 4.619,
        "text": "technically just impossible because for"
      },
      {
        "start": 3838.2,
        "duration": 6.54,
        "text": "most of them you cannot have multiple"
      },
      {
        "start": 3840.359,
        "duration": 5.521,
        "text": "Master servers simple as that"
      },
      {
        "start": 3844.74,
        "duration": 4.619,
        "text": "um"
      },
      {
        "start": 3845.88,
        "duration": 4.919,
        "text": "okay melro italis uh sorry yeah you"
      },
      {
        "start": 3849.359,
        "duration": 3.841,
        "text": "wanted to add something"
      },
      {
        "start": 3850.799,
        "duration": 5.941,
        "text": "yeah it's a loaded question uh I don't"
      },
      {
        "start": 3853.2,
        "duration": 5.159,
        "text": "want to go deep into it but we will talk"
      },
      {
        "start": 3856.74,
        "duration": 4.619,
        "text": "about a little bit about scalability"
      },
      {
        "start": 3858.359,
        "duration": 5.0,
        "text": "next in the next session session yeah"
      },
      {
        "start": 3861.359,
        "duration": 2.0,
        "text": "um"
      },
      {
        "start": 3863.4,
        "duration": 2.54,
        "text": "sorry"
      },
      {
        "start": 3864.78,
        "duration": 3.779,
        "text": "um"
      },
      {
        "start": 3865.94,
        "duration": 4.48,
        "text": "multiple data centers might also be a"
      },
      {
        "start": 3868.559,
        "duration": 3.901,
        "text": "setup to comply with data localization"
      },
      {
        "start": 3870.42,
        "duration": 4.199,
        "text": "requirements by governments yes"
      },
      {
        "start": 3872.46,
        "duration": 4.32,
        "text": "absolutely it's one of the things where"
      },
      {
        "start": 3874.619,
        "duration": 5.641,
        "text": "you can put your different data into"
      },
      {
        "start": 3876.78,
        "duration": 5.76,
        "text": "different data centers uh depending on"
      },
      {
        "start": 3880.26,
        "duration": 5.52,
        "text": "the region yes that's how it works"
      },
      {
        "start": 3882.54,
        "duration": 5.64,
        "text": "and uh boom"
      },
      {
        "start": 3885.78,
        "duration": 4.92,
        "text": "which language will you use for the hand"
      },
      {
        "start": 3888.18,
        "duration": 4.74,
        "text": "Zone activity for this Workshop we will"
      },
      {
        "start": 3890.7,
        "duration": 4.379,
        "text": "stick to Cassandra query language which"
      },
      {
        "start": 3892.92,
        "duration": 4.98,
        "text": "you will soon discover and this one"
      },
      {
        "start": 3895.079,
        "duration": 5.581,
        "text": "looks very familiar to you uh because"
      },
      {
        "start": 3897.9,
        "duration": 5.939,
        "text": "it's very similar to SQL except some"
      },
      {
        "start": 3900.66,
        "duration": 4.679,
        "text": "capabilities like joins"
      },
      {
        "start": 3903.839,
        "duration": 2.821,
        "text": "um"
      },
      {
        "start": 3905.339,
        "duration": 4.46,
        "text": "uh"
      },
      {
        "start": 3906.66,
        "duration": 6.179,
        "text": "uh Mohan paliwal asks about"
      },
      {
        "start": 3909.799,
        "duration": 5.02,
        "text": "Cassandra DB data modeling comparing to"
      },
      {
        "start": 3912.839,
        "duration": 4.52,
        "text": "relational light model it comes it comes"
      },
      {
        "start": 3914.819,
        "duration": 6.0,
        "text": "next week so see you next week with that"
      },
      {
        "start": 3917.359,
        "duration": 6.301,
        "text": "and next week we will talk about it a"
      },
      {
        "start": 3920.819,
        "duration": 6.0,
        "text": "lot balancing is to be explained soon"
      },
      {
        "start": 3923.66,
        "duration": 7.0,
        "text": "uh okay hours"
      },
      {
        "start": 3926.819,
        "duration": 5.821,
        "text": "um this uh set okay then I asked your"
      },
      {
        "start": 3930.66,
        "duration": 4.38,
        "text": "questions now it's time for you to"
      },
      {
        "start": 3932.64,
        "duration": 4.26,
        "text": "answer my question and that's going to"
      },
      {
        "start": 3935.04,
        "duration": 5.519,
        "text": "be question number nine number two"
      },
      {
        "start": 3936.9,
        "duration": 7.1,
        "text": "switch to 90 answer my question how do"
      },
      {
        "start": 3940.559,
        "duration": 3.441,
        "text": "we scale Cassandra cluster"
      },
      {
        "start": 3944.339,
        "duration": 6.72,
        "text": "scale up by upgrading servers scale out"
      },
      {
        "start": 3947.88,
        "duration": 6.32,
        "text": "by adding servers Cassandra cluster does"
      },
      {
        "start": 3951.059,
        "duration": 3.141,
        "text": "not need scaling"
      },
      {
        "start": 3958.5,
        "duration": 7.92,
        "text": "meanwhile there is CGR asks"
      },
      {
        "start": 3962.04,
        "duration": 6.299,
        "text": "um how a data center uh belongs a data"
      },
      {
        "start": 3966.42,
        "duration": 5.3,
        "text": "center cluster terminology"
      },
      {
        "start": 3968.339,
        "duration": 3.381,
        "text": "uh installed"
      },
      {
        "start": 3971.78,
        "duration": 6.7,
        "text": "uh cluster consists of multiple or one"
      },
      {
        "start": 3975.839,
        "duration": 5.881,
        "text": "or multiple data centers data center"
      },
      {
        "start": 3978.48,
        "duration": 5.7,
        "text": "consists or one or multiple nodes or"
      },
      {
        "start": 3981.72,
        "duration": 4.8,
        "text": "servers node and server basically"
      },
      {
        "start": 3984.18,
        "duration": 5.22,
        "text": "synonyms in this terminology"
      },
      {
        "start": 3986.52,
        "duration": 4.86,
        "text": "and Cassandra scales horizontally by"
      },
      {
        "start": 3989.4,
        "duration": 4.26,
        "text": "scaling out"
      },
      {
        "start": 3991.38,
        "duration": 4.38,
        "text": "uh that is the way how you scale"
      },
      {
        "start": 3993.66,
        "duration": 4.5,
        "text": "Cassandra cluster horizontally not"
      },
      {
        "start": 3995.76,
        "duration": 3.66,
        "text": "vertically not by scaling up"
      },
      {
        "start": 3998.16,
        "duration": 3.659,
        "text": "okay"
      },
      {
        "start": 3999.42,
        "duration": 8.159,
        "text": "so it's one cluster multiple data"
      },
      {
        "start": 4001.819,
        "duration": 11.101,
        "text": "centers one or one or many good"
      },
      {
        "start": 4007.579,
        "duration": 6.48,
        "text": "well then uh that brings me to a point I"
      },
      {
        "start": 4012.92,
        "duration": 3.0,
        "text": "have to"
      },
      {
        "start": 4014.059,
        "duration": 5.701,
        "text": "switch"
      },
      {
        "start": 4015.92,
        "duration": 9.06,
        "text": "the screen to yours uh are you sharing"
      },
      {
        "start": 4019.76,
        "duration": 7.22,
        "text": "I am yes perfect so give me a moment"
      },
      {
        "start": 4024.98,
        "duration": 2.0,
        "text": "s"
      },
      {
        "start": 4028.119,
        "duration": 6.521,
        "text": "I think you are live okay try to change"
      },
      {
        "start": 4032.0,
        "duration": 5.88,
        "text": "the slide so we have"
      },
      {
        "start": 4034.64,
        "duration": 6.78,
        "text": "five more sections five more hours to go"
      },
      {
        "start": 4037.88,
        "duration": 5.76,
        "text": "just kidding the um so let's talk about"
      },
      {
        "start": 4041.42,
        "duration": 6.36,
        "text": "some of the concepts"
      },
      {
        "start": 4043.64,
        "duration": 6.24,
        "text": "that uh we briefly touched uh so one of"
      },
      {
        "start": 4047.78,
        "duration": 4.86,
        "text": "the important things that you want to"
      },
      {
        "start": 4049.88,
        "duration": 6.659,
        "text": "remember about Cassandra is that all"
      },
      {
        "start": 4052.64,
        "duration": 7.979,
        "text": "nodes all servers are equal so they"
      },
      {
        "start": 4056.539,
        "duration": 6.901,
        "text": "appears there is no uh special server"
      },
      {
        "start": 4060.619,
        "duration": 5.22,
        "text": "that is doing more than other servers"
      },
      {
        "start": 4063.44,
        "duration": 5.639,
        "text": "and that means why is it important that"
      },
      {
        "start": 4065.839,
        "duration": 5.22,
        "text": "means that if we lose one server we"
      },
      {
        "start": 4069.079,
        "duration": 4.381,
        "text": "basically can easily replace it with"
      },
      {
        "start": 4071.059,
        "duration": 6.121,
        "text": "another clear server so there is there"
      },
      {
        "start": 4073.46,
        "duration": 6.24,
        "text": "is no concept of of master or later"
      },
      {
        "start": 4077.18,
        "duration": 4.439,
        "text": "um and and this is this is probably one"
      },
      {
        "start": 4079.7,
        "duration": 5.639,
        "text": "of the most important things to"
      },
      {
        "start": 4081.619,
        "duration": 5.821,
        "text": "understand in the architecture and the"
      },
      {
        "start": 4085.339,
        "duration": 4.98,
        "text": "cluster architecture"
      },
      {
        "start": 4087.44,
        "duration": 6.0,
        "text": "so um traditional architecture many"
      },
      {
        "start": 4090.319,
        "duration": 6.301,
        "text": "times we see distributed databases they"
      },
      {
        "start": 4093.44,
        "duration": 4.919,
        "text": "they follow this design pattern where"
      },
      {
        "start": 4096.62,
        "duration": 6.54,
        "text": "they have leader and they have have"
      },
      {
        "start": 4098.359,
        "duration": 6.9,
        "text": "followers so essentially they um uh you"
      },
      {
        "start": 4103.16,
        "duration": 8.099,
        "text": "can think about the the leader is going"
      },
      {
        "start": 4105.259,
        "duration": 8.58,
        "text": "to uh always get all the rights and will"
      },
      {
        "start": 4111.259,
        "duration": 4.861,
        "text": "will send those rights to all all the"
      },
      {
        "start": 4113.839,
        "duration": 4.98,
        "text": "followers server servers or you can say"
      },
      {
        "start": 4116.12,
        "duration": 4.32,
        "text": "they are replica servers as well so they"
      },
      {
        "start": 4118.819,
        "duration": 5.101,
        "text": "will will store the data they will"
      },
      {
        "start": 4120.44,
        "duration": 5.94,
        "text": "replicate the data uh but however so"
      },
      {
        "start": 4123.92,
        "duration": 4.439,
        "text": "they when you're doing right in this"
      },
      {
        "start": 4126.38,
        "duration": 3.72,
        "text": "architecture it always has to go through"
      },
      {
        "start": 4128.359,
        "duration": 4.021,
        "text": "through the leader and that's a problem"
      },
      {
        "start": 4130.1,
        "duration": 4.32,
        "text": "this is a single point of failure and"
      },
      {
        "start": 4132.38,
        "duration": 4.919,
        "text": "rights will not scale with this"
      },
      {
        "start": 4134.42,
        "duration": 5.52,
        "text": "architecture so what there are multiple"
      },
      {
        "start": 4137.299,
        "duration": 5.04,
        "text": "solutions that different databases to"
      },
      {
        "start": 4139.94,
        "duration": 7.08,
        "text": "try to improve scalability for rights"
      },
      {
        "start": 4142.339,
        "duration": 8.101,
        "text": "they create multiple leaders they have"
      },
      {
        "start": 4147.02,
        "duration": 5.88,
        "text": "standby leaders so if one fails they"
      },
      {
        "start": 4150.44,
        "duration": 4.56,
        "text": "they come up they bring another one"
      },
      {
        "start": 4152.9,
        "duration": 4.56,
        "text": "quickly and all of that but it's still"
      },
      {
        "start": 4155.0,
        "duration": 4.739,
        "text": "very hard to scale right so if you're"
      },
      {
        "start": 4157.46,
        "duration": 5.46,
        "text": "worried about rights you should look at"
      },
      {
        "start": 4159.739,
        "duration": 4.44,
        "text": "the database that does not follow these"
      },
      {
        "start": 4162.92,
        "duration": 4.02,
        "text": "architecture"
      },
      {
        "start": 4164.179,
        "duration": 4.14,
        "text": "however for reads if we're talking about"
      },
      {
        "start": 4166.94,
        "duration": 2.52,
        "text": "reads"
      },
      {
        "start": 4168.319,
        "duration": 2.48,
        "text": "um"
      },
      {
        "start": 4169.46,
        "duration": 3.739,
        "text": "we"
      },
      {
        "start": 4170.799,
        "duration": 6.04,
        "text": "we can"
      },
      {
        "start": 4173.199,
        "duration": 5.5,
        "text": "process reads using a follower servers"
      },
      {
        "start": 4176.839,
        "duration": 4.86,
        "text": "so reads do not have to go through the"
      },
      {
        "start": 4178.699,
        "duration": 5.16,
        "text": "leader they can go directly to the"
      },
      {
        "start": 4181.699,
        "duration": 4.441,
        "text": "followers and therefore because there"
      },
      {
        "start": 4183.859,
        "duration": 4.86,
        "text": "are many followers we can actually scale"
      },
      {
        "start": 4186.14,
        "duration": 5.94,
        "text": "reads pretty well okay so in those"
      },
      {
        "start": 4188.719,
        "duration": 5.281,
        "text": "databases scaling reads is easy scaling"
      },
      {
        "start": 4192.08,
        "duration": 5.58,
        "text": "writes is hard"
      },
      {
        "start": 4194.0,
        "duration": 5.28,
        "text": "and now the so-called peer-to-peer"
      },
      {
        "start": 4197.66,
        "duration": 2.82,
        "text": "architecture which is Cassandra"
      },
      {
        "start": 4199.28,
        "duration": 3.84,
        "text": "architecture"
      },
      {
        "start": 4200.48,
        "duration": 6.54,
        "text": "and a few other databases use the same"
      },
      {
        "start": 4203.12,
        "duration": 8.28,
        "text": "type of architecture uh here each node"
      },
      {
        "start": 4207.02,
        "duration": 6.96,
        "text": "each server is essentially identical and"
      },
      {
        "start": 4211.4,
        "duration": 7.14,
        "text": "they talk to each other they know which"
      },
      {
        "start": 4213.98,
        "duration": 6.78,
        "text": "server stores which data and and if one"
      },
      {
        "start": 4218.54,
        "duration": 4.56,
        "text": "sir so the the data is also replicated"
      },
      {
        "start": 4220.76,
        "duration": 4.68,
        "text": "if one server fails it's not a big deal"
      },
      {
        "start": 4223.1,
        "duration": 4.639,
        "text": "because there are replicas and and they"
      },
      {
        "start": 4225.44,
        "duration": 3.92,
        "text": "can answer the same exactly the same"
      },
      {
        "start": 4227.739,
        "duration": 4.601,
        "text": "reads"
      },
      {
        "start": 4229.36,
        "duration": 6.28,
        "text": "read requests so they can read this"
      },
      {
        "start": 4232.34,
        "duration": 5.22,
        "text": "retrieve the same data so no single"
      },
      {
        "start": 4235.64,
        "duration": 5.94,
        "text": "point of failure and that means High"
      },
      {
        "start": 4237.56,
        "duration": 7.26,
        "text": "availability but also we can scale reads"
      },
      {
        "start": 4241.58,
        "duration": 6.18,
        "text": "and write very well in this architecture"
      },
      {
        "start": 4244.82,
        "duration": 5.04,
        "text": "now Focus Sandra specifically"
      },
      {
        "start": 4247.76,
        "duration": 6.78,
        "text": "we we had a little bit of discussion"
      },
      {
        "start": 4249.86,
        "duration": 7.68,
        "text": "earlier uh right uh very efficient you"
      },
      {
        "start": 4254.54,
        "duration": 5.94,
        "text": "cannot find a database that would do"
      },
      {
        "start": 4257.54,
        "duration": 5.1,
        "text": "much faster than Cassandra those those"
      },
      {
        "start": 4260.48,
        "duration": 4.62,
        "text": "that do faster will be very simple key"
      },
      {
        "start": 4262.64,
        "duration": 5.039,
        "text": "value restores most likely so because"
      },
      {
        "start": 4265.1,
        "duration": 5.82,
        "text": "because Cassandra simply writes data"
      },
      {
        "start": 4267.679,
        "duration": 5.581,
        "text": "into commit log and it it right is done"
      },
      {
        "start": 4270.92,
        "duration": 5.4,
        "text": "and then it does additional but reads"
      },
      {
        "start": 4273.26,
        "duration": 6.0,
        "text": "can be more expensive in Cassandra so"
      },
      {
        "start": 4276.32,
        "duration": 5.82,
        "text": "um because certain data structures need"
      },
      {
        "start": 4279.26,
        "duration": 4.38,
        "text": "to be processed and data need to be"
      },
      {
        "start": 4282.14,
        "duration": 3.059,
        "text": "retrieved and they can be multiple of"
      },
      {
        "start": 4283.64,
        "duration": 4.5,
        "text": "them we're not going to attach that"
      },
      {
        "start": 4285.199,
        "duration": 4.921,
        "text": "that's mostly internals but what you"
      },
      {
        "start": 4288.14,
        "duration": 4.82,
        "text": "need to remember it's that both reads"
      },
      {
        "start": 4290.12,
        "duration": 5.28,
        "text": "and writes will ski scale grades"
      },
      {
        "start": 4292.96,
        "duration": 6.1,
        "text": "rights will always be super efficient"
      },
      {
        "start": 4295.4,
        "duration": 6.839,
        "text": "reads maybe less efficient but still"
      },
      {
        "start": 4299.06,
        "duration": 5.42,
        "text": "very efficient real time uh performance"
      },
      {
        "start": 4302.239,
        "duration": 4.44,
        "text": "so we're talking about single digit"
      },
      {
        "start": 4304.48,
        "duration": 5.739,
        "text": "millisecond performance"
      },
      {
        "start": 4306.679,
        "duration": 6.901,
        "text": "so also the data is partitioned"
      },
      {
        "start": 4310.219,
        "duration": 6.301,
        "text": "uh data is stored in tables but those"
      },
      {
        "start": 4313.58,
        "duration": 4.079,
        "text": "tables are partitioned and and since we"
      },
      {
        "start": 4316.52,
        "duration": 3.36,
        "text": "already mentioned horizontal"
      },
      {
        "start": 4317.659,
        "duration": 3.901,
        "text": "partitioning indeed we are using"
      },
      {
        "start": 4319.88,
        "duration": 4.02,
        "text": "horizontal partitioning there they are"
      },
      {
        "start": 4321.56,
        "duration": 5.58,
        "text": "partitioned based on"
      },
      {
        "start": 4323.9,
        "duration": 5.339,
        "text": "uh on a partition key so here is an"
      },
      {
        "start": 4327.14,
        "duration": 4.62,
        "text": "example of a table sensors by Network"
      },
      {
        "start": 4329.239,
        "duration": 7.141,
        "text": "and we have three columns here we have"
      },
      {
        "start": 4331.76,
        "duration": 5.76,
        "text": "rows uh so columns Network sensor ID and"
      },
      {
        "start": 4336.38,
        "duration": 4.16,
        "text": "temperature"
      },
      {
        "start": 4337.52,
        "duration": 5.52,
        "text": "so this is how defined pretty similar to"
      },
      {
        "start": 4340.54,
        "duration": 4.6,
        "text": "SQL if I didn't tell you that this is"
      },
      {
        "start": 4343.04,
        "duration": 4.619,
        "text": "Cassandra Queen which you would easily"
      },
      {
        "start": 4345.14,
        "duration": 5.579,
        "text": "think that this is a structured query"
      },
      {
        "start": 4347.659,
        "duration": 6.0,
        "text": "language used in relational databases so"
      },
      {
        "start": 4350.719,
        "duration": 5.881,
        "text": "the difference is to do the partitioning"
      },
      {
        "start": 4353.659,
        "duration": 5.821,
        "text": "we need to assign one"
      },
      {
        "start": 4356.6,
        "duration": 3.98,
        "text": "key one of the columns to be a partition"
      },
      {
        "start": 4359.48,
        "duration": 3.48,
        "text": "key"
      },
      {
        "start": 4360.58,
        "duration": 5.68,
        "text": "so in this case we're assign a network"
      },
      {
        "start": 4362.96,
        "duration": 7.739,
        "text": "as a partition key and that means that"
      },
      {
        "start": 4366.26,
        "duration": 7.02,
        "text": "any rule that has the same value for the"
      },
      {
        "start": 4370.699,
        "duration": 4.741,
        "text": "network will end up in the same group of"
      },
      {
        "start": 4373.28,
        "duration": 3.3,
        "text": "rows called Partition"
      },
      {
        "start": 4375.44,
        "duration": 4.62,
        "text": "thank you"
      },
      {
        "start": 4376.58,
        "duration": 6.119,
        "text": "so and essentially those partitions so"
      },
      {
        "start": 4380.06,
        "duration": 5.22,
        "text": "everything with a network in California"
      },
      {
        "start": 4382.699,
        "duration": 6.48,
        "text": "will end up all those rows in the same"
      },
      {
        "start": 4385.28,
        "duration": 6.66,
        "text": "partition and Alabama the same thing"
      },
      {
        "start": 4389.179,
        "duration": 4.881,
        "text": "Kansas the same thing and then there"
      },
      {
        "start": 4391.94,
        "duration": 4.92,
        "text": "will be distribution data distribution"
      },
      {
        "start": 4394.06,
        "duration": 7.179,
        "text": "uh that each node will be responsible"
      },
      {
        "start": 4396.86,
        "duration": 7.26,
        "text": "for certain partitions so the data will"
      },
      {
        "start": 4401.239,
        "duration": 7.621,
        "text": "ideally be identically distributed"
      },
      {
        "start": 4404.12,
        "duration": 6.96,
        "text": "across modes in the cluster okay"
      },
      {
        "start": 4408.86,
        "duration": 3.72,
        "text": "so we are talking about distributed"
      },
      {
        "start": 4411.08,
        "duration": 3.96,
        "text": "table here"
      },
      {
        "start": 4412.58,
        "duration": 5.76,
        "text": "this is how partition key defined in"
      },
      {
        "start": 4415.04,
        "duration": 5.82,
        "text": "Cassandra query language cql it's a"
      },
      {
        "start": 4418.34,
        "duration": 6.0,
        "text": "network column so you can see the same"
      },
      {
        "start": 4420.86,
        "duration": 7.68,
        "text": "three columns Network sensor temperature"
      },
      {
        "start": 4424.34,
        "duration": 7.92,
        "text": "and network is here defined as part of"
      },
      {
        "start": 4428.54,
        "duration": 6.9,
        "text": "the primary key but it has a special uh"
      },
      {
        "start": 4432.26,
        "duration": 6.18,
        "text": "dedication as a partition key so one way"
      },
      {
        "start": 4435.44,
        "duration": 4.62,
        "text": "to to to dedicate a column as a"
      },
      {
        "start": 4438.44,
        "duration": 4.44,
        "text": "partition key is to add additional"
      },
      {
        "start": 4440.06,
        "duration": 6.24,
        "text": "parenthesis or by default the First"
      },
      {
        "start": 4442.88,
        "duration": 5.64,
        "text": "Column will be the partition key so the"
      },
      {
        "start": 4446.3,
        "duration": 5.399,
        "text": "partitioning of the table will happen"
      },
      {
        "start": 4448.52,
        "duration": 7.62,
        "text": "based on the network column and"
      },
      {
        "start": 4451.699,
        "duration": 6.661,
        "text": "distribution will also have have this"
      },
      {
        "start": 4456.14,
        "duration": 4.62,
        "text": "um on this partition key so you may"
      },
      {
        "start": 4458.36,
        "duration": 5.58,
        "text": "wonder what is this sensor it's part of"
      },
      {
        "start": 4460.76,
        "duration": 5.84,
        "text": "the primary key why do we have it it's"
      },
      {
        "start": 4463.94,
        "duration": 5.94,
        "text": "actually called clustering key because"
      },
      {
        "start": 4466.6,
        "duration": 5.8,
        "text": "within a partition you also want to be"
      },
      {
        "start": 4469.88,
        "duration": 4.44,
        "text": "able to identify different rows what"
      },
      {
        "start": 4472.4,
        "duration": 3.0,
        "text": "what makes those rows within a partition"
      },
      {
        "start": 4474.32,
        "duration": 4.08,
        "text": "unique"
      },
      {
        "start": 4475.4,
        "duration": 6.12,
        "text": "and if you go back so California is a"
      },
      {
        "start": 4478.4,
        "duration": 4.5,
        "text": "partition key so two rows will end up in"
      },
      {
        "start": 4481.52,
        "duration": 3.9,
        "text": "the same partition what makes them"
      },
      {
        "start": 4482.9,
        "duration": 4.38,
        "text": "unique the the sensor ID makes them"
      },
      {
        "start": 4485.42,
        "duration": 4.08,
        "text": "unique so you can distinguish if you"
      },
      {
        "start": 4487.28,
        "duration": 4.08,
        "text": "want to retrieve whole partition you"
      },
      {
        "start": 4489.5,
        "duration": 4.32,
        "text": "specify partition key if you want to"
      },
      {
        "start": 4491.36,
        "duration": 5.1,
        "text": "retrieve one specific row you need to"
      },
      {
        "start": 4493.82,
        "duration": 5.1,
        "text": "specify partition key and clustering key"
      },
      {
        "start": 4496.46,
        "duration": 4.92,
        "text": "so it's like row ID"
      },
      {
        "start": 4498.92,
        "duration": 4.88,
        "text": "inside of a partition"
      },
      {
        "start": 4501.38,
        "duration": 5.7,
        "text": "okay so"
      },
      {
        "start": 4503.8,
        "duration": 6.52,
        "text": "based on the on the partition key the"
      },
      {
        "start": 4507.08,
        "duration": 5.82,
        "text": "valers in the partition key column there"
      },
      {
        "start": 4510.32,
        "duration": 3.54,
        "text": "will be murmurs 3 hash and partitioner"
      },
      {
        "start": 4512.9,
        "duration": 4.5,
        "text": "used"
      },
      {
        "start": 4513.86,
        "duration": 4.879,
        "text": "that will convert those values Alabama"
      },
      {
        "start": 4517.4,
        "duration": 5.279,
        "text": "California"
      },
      {
        "start": 4518.739,
        "duration": 6.101,
        "text": "into numbers those numbers can be will"
      },
      {
        "start": 4522.679,
        "duration": 5.461,
        "text": "will be large numbers we're using small"
      },
      {
        "start": 4524.84,
        "duration": 5.76,
        "text": "numbers just for uh for the sake of"
      },
      {
        "start": 4528.14,
        "duration": 4.92,
        "text": "Simplicity for this example"
      },
      {
        "start": 4530.6,
        "duration": 4.559,
        "text": "and then so they all of them will be"
      },
      {
        "start": 4533.06,
        "duration": 5.28,
        "text": "converted to numbers and then uh"
      },
      {
        "start": 4535.159,
        "duration": 5.461,
        "text": "Cassandra nodes will be assigned ranges"
      },
      {
        "start": 4538.34,
        "duration": 5.339,
        "text": "of those numbers those numbers are"
      },
      {
        "start": 4540.62,
        "duration": 6.059,
        "text": "called tokens so each Cassandra node"
      },
      {
        "start": 4543.679,
        "duration": 6.121,
        "text": "will have a range of tokens that it will"
      },
      {
        "start": 4546.679,
        "duration": 5.101,
        "text": "be responsible for storing and in"
      },
      {
        "start": 4549.8,
        "duration": 3.3,
        "text": "reality there will be multiple ranges"
      },
      {
        "start": 4551.78,
        "duration": 4.5,
        "text": "assigned"
      },
      {
        "start": 4553.1,
        "duration": 5.22,
        "text": "so if we have four focused under nodes"
      },
      {
        "start": 4556.28,
        "duration": 4.26,
        "text": "here then the first one and we have 100"
      },
      {
        "start": 4558.32,
        "duration": 4.62,
        "text": "tokens of course the value is much"
      },
      {
        "start": 4560.54,
        "duration": 4.82,
        "text": "larger but for the simplest you only"
      },
      {
        "start": 4562.94,
        "duration": 6.06,
        "text": "have 100 tokens and the first one store"
      },
      {
        "start": 4565.36,
        "duration": 9.1,
        "text": "one force so it's one"
      },
      {
        "start": 4569.0,
        "duration": 8.6,
        "text": "it but uh one uh to 25 the second one 26"
      },
      {
        "start": 4574.46,
        "duration": 3.14,
        "text": "to 50 and so on"
      },
      {
        "start": 4577.88,
        "duration": 3.12,
        "text": "so"
      },
      {
        "start": 4579.92,
        "duration": 3.42,
        "text": "what's"
      },
      {
        "start": 4581.0,
        "duration": 4.44,
        "text": "what's fishing in"
      },
      {
        "start": 4583.34,
        "duration": 4.92,
        "text": "Alex I can hear a lot of noise on the"
      },
      {
        "start": 4585.44,
        "duration": 5.64,
        "text": "background oh sorry"
      },
      {
        "start": 4588.26,
        "duration": 6.18,
        "text": "uh so why partitioning"
      },
      {
        "start": 4591.08,
        "duration": 5.099,
        "text": "um and how it's related to sharding"
      },
      {
        "start": 4594.44,
        "duration": 4.38,
        "text": "um so because scaling doesn't have to be"
      },
      {
        "start": 4596.179,
        "duration": 5.161,
        "text": "sharp I think I may have t-shirt"
      },
      {
        "start": 4598.82,
        "duration": 5.399,
        "text": "from 10 years ago that says that but"
      },
      {
        "start": 4601.34,
        "duration": 6.48,
        "text": "Chardon went actually a long way it's"
      },
      {
        "start": 4604.219,
        "duration": 7.081,
        "text": "not no longer it's not manual Chardon"
      },
      {
        "start": 4607.82,
        "duration": 5.78,
        "text": "um so the the relationship of these two"
      },
      {
        "start": 4611.3,
        "duration": 7.439,
        "text": "concept is partitioning is more General"
      },
      {
        "start": 4613.6,
        "duration": 7.3,
        "text": "uh notion of dividing a table or data"
      },
      {
        "start": 4618.739,
        "duration": 6.121,
        "text": "set in our case it's a table"
      },
      {
        "start": 4620.9,
        "duration": 6.9,
        "text": "in two chunks and and uh we can divide"
      },
      {
        "start": 4624.86,
        "duration": 5.22,
        "text": "it either vertically so we decide okay"
      },
      {
        "start": 4627.8,
        "duration": 4.379,
        "text": "this part of the table some of the"
      },
      {
        "start": 4630.08,
        "duration": 4.079,
        "text": "columns will go to a different table and"
      },
      {
        "start": 4632.179,
        "duration": 5.101,
        "text": "the other counts will go to another"
      },
      {
        "start": 4634.159,
        "duration": 4.741,
        "text": "table so we get two tables"
      },
      {
        "start": 4637.28,
        "duration": 3.06,
        "text": "um that's vertical partition we are not"
      },
      {
        "start": 4638.9,
        "duration": 3.9,
        "text": "using it here"
      },
      {
        "start": 4640.34,
        "duration": 5.1,
        "text": "and horizontal position is we divide"
      },
      {
        "start": 4642.8,
        "duration": 6.06,
        "text": "table horizontally so chunks of rows"
      },
      {
        "start": 4645.44,
        "duration": 5.52,
        "text": "groups of rows will go to different uh"
      },
      {
        "start": 4648.86,
        "duration": 4.859,
        "text": "different partitions right so that's"
      },
      {
        "start": 4650.96,
        "duration": 4.5,
        "text": "what we're using here and Chardon is"
      },
      {
        "start": 4653.719,
        "duration": 4.821,
        "text": "actually refers to that horizontal"
      },
      {
        "start": 4655.46,
        "duration": 6.68,
        "text": "partitioning so it's one special case of"
      },
      {
        "start": 4658.54,
        "duration": 6.52,
        "text": "partitioning is is horizontal"
      },
      {
        "start": 4662.14,
        "duration": 4.18,
        "text": "one special case of horizontal partition"
      },
      {
        "start": 4665.06,
        "duration": 6.119,
        "text": "here"
      },
      {
        "start": 4666.32,
        "duration": 6.24,
        "text": "okay and um so here is an example with"
      },
      {
        "start": 4671.179,
        "duration": 3.921,
        "text": "uh"
      },
      {
        "start": 4672.56,
        "duration": 5.04,
        "text": "uh um of"
      },
      {
        "start": 4675.1,
        "duration": 5.32,
        "text": "scaling your cluster whatever so if you"
      },
      {
        "start": 4677.6,
        "duration": 5.34,
        "text": "have this uh token ranges if you have"
      },
      {
        "start": 4680.42,
        "duration": 4.86,
        "text": "four nodes in your data center or even"
      },
      {
        "start": 4682.94,
        "duration": 5.64,
        "text": "just in the in the cluster just think"
      },
      {
        "start": 4685.28,
        "duration": 4.02,
        "text": "about it as a cluster uh with one Data"
      },
      {
        "start": 4688.58,
        "duration": 4.079,
        "text": "Center"
      },
      {
        "start": 4689.3,
        "duration": 6.3,
        "text": "if we add another note we basically need"
      },
      {
        "start": 4692.659,
        "duration": 5.881,
        "text": "to redistribute the data right so we are"
      },
      {
        "start": 4695.6,
        "duration": 6.42,
        "text": "going to scale out each node will be"
      },
      {
        "start": 4698.54,
        "duration": 5.699,
        "text": "responsible for smaller token ranges"
      },
      {
        "start": 4702.02,
        "duration": 3.78,
        "text": "okay but there will be more nodes and"
      },
      {
        "start": 4704.239,
        "duration": 4.5,
        "text": "therefore they there's throughput"
      },
      {
        "start": 4705.8,
        "duration": 6.0,
        "text": "increases how much data they can store"
      },
      {
        "start": 4708.739,
        "duration": 5.041,
        "text": "in those ranges increases and all of"
      },
      {
        "start": 4711.8,
        "duration": 3.24,
        "text": "that and this operation is not"
      },
      {
        "start": 4713.78,
        "duration": 4.399,
        "text": "necessarily"
      },
      {
        "start": 4715.04,
        "duration": 6.06,
        "text": "um uh super efficient or"
      },
      {
        "start": 4718.179,
        "duration": 5.201,
        "text": "inexpensive it's it's not an inexpensive"
      },
      {
        "start": 4721.1,
        "duration": 4.2,
        "text": "duration uh because"
      },
      {
        "start": 4723.38,
        "duration": 3.98,
        "text": "um you have to move data between"
      },
      {
        "start": 4725.3,
        "duration": 3.68,
        "text": "different nodes right"
      },
      {
        "start": 4727.36,
        "duration": 5.44,
        "text": "so"
      },
      {
        "start": 4728.98,
        "duration": 6.16,
        "text": "scaling in is when you no longer need"
      },
      {
        "start": 4732.8,
        "duration": 4.62,
        "text": "that many nodes you your throughput is"
      },
      {
        "start": 4735.14,
        "duration": 4.92,
        "text": "lower you you don't need to store that"
      },
      {
        "start": 4737.42,
        "duration": 5.779,
        "text": "much data so you can decrease to three"
      },
      {
        "start": 4740.06,
        "duration": 6.74,
        "text": "nodes and then you basically have to"
      },
      {
        "start": 4743.199,
        "duration": 6.881,
        "text": "repair those nodes to move data around"
      },
      {
        "start": 4746.8,
        "duration": 5.919,
        "text": "uh and repair by by saying repair this"
      },
      {
        "start": 4750.08,
        "duration": 5.7,
        "text": "is the utility that you run in Cassandra"
      },
      {
        "start": 4752.719,
        "duration": 5.821,
        "text": "it's not it's not manual process so this"
      },
      {
        "start": 4755.78,
        "duration": 5.1,
        "text": "is how it can scale out scale in and"
      },
      {
        "start": 4758.54,
        "duration": 5.04,
        "text": "some systems like asterdb do it for you"
      },
      {
        "start": 4760.88,
        "duration": 5.1,
        "text": "automatically so you don't even know how"
      },
      {
        "start": 4763.58,
        "duration": 5.639,
        "text": "many nodes you have in your cluster they"
      },
      {
        "start": 4765.98,
        "duration": 6.14,
        "text": "all basically whatever throughput"
      },
      {
        "start": 4769.219,
        "duration": 5.94,
        "text": "increases we increase the number of"
      },
      {
        "start": 4772.12,
        "duration": 5.74,
        "text": "modes for you freezes and we will"
      },
      {
        "start": 4775.159,
        "duration": 5.641,
        "text": "decrease it and that therefore it's you"
      },
      {
        "start": 4777.86,
        "duration": 5.339,
        "text": "saving on sources and all of that so"
      },
      {
        "start": 4780.8,
        "duration": 5.899,
        "text": "another important notion in Cassandra is"
      },
      {
        "start": 4783.199,
        "duration": 5.641,
        "text": "replication data replication"
      },
      {
        "start": 4786.699,
        "duration": 4.561,
        "text": "uh Alex could you please mute yourself"
      },
      {
        "start": 4788.84,
        "duration": 5.96,
        "text": "oh sorry"
      },
      {
        "start": 4791.26,
        "duration": 6.28,
        "text": "so replication Factor"
      },
      {
        "start": 4794.8,
        "duration": 5.32,
        "text": "uh the duplication is done based on the"
      },
      {
        "start": 4797.54,
        "duration": 4.08,
        "text": "application factor in the cluster or it"
      },
      {
        "start": 4800.12,
        "duration": 4.86,
        "text": "can be if you have multiple data center"
      },
      {
        "start": 4801.62,
        "duration": 5.46,
        "text": "you can specify a replication factor for"
      },
      {
        "start": 4804.98,
        "duration": 4.38,
        "text": "each Data Center"
      },
      {
        "start": 4807.08,
        "duration": 4.7,
        "text": "so the application factor means the"
      },
      {
        "start": 4809.36,
        "duration": 5.76,
        "text": "number of nodes that will store the same"
      },
      {
        "start": 4811.78,
        "duration": 7.36,
        "text": "uh partition so the same position will"
      },
      {
        "start": 4815.12,
        "duration": 7.02,
        "text": "be stored in in multiple replicas"
      },
      {
        "start": 4819.14,
        "duration": 5.76,
        "text": "so if replication so how how replication"
      },
      {
        "start": 4822.14,
        "duration": 5.46,
        "text": "factor is specified is again when you"
      },
      {
        "start": 4824.9,
        "duration": 5.22,
        "text": "create the key space and key space is"
      },
      {
        "start": 4827.6,
        "duration": 6.0,
        "text": "basically represents your database it"
      },
      {
        "start": 4830.12,
        "duration": 6.599,
        "text": "stores it will be a container for tables"
      },
      {
        "start": 4833.6,
        "duration": 5.52,
        "text": "for indexes for user defined types for"
      },
      {
        "start": 4836.719,
        "duration": 6.241,
        "text": "all the schema elements"
      },
      {
        "start": 4839.12,
        "duration": 6.18,
        "text": "so um when you create the key space you"
      },
      {
        "start": 4842.96,
        "duration": 5.04,
        "text": "specify replication strategy in this"
      },
      {
        "start": 4845.3,
        "duration": 5.899,
        "text": "case it's a network topology strategy"
      },
      {
        "start": 4848.0,
        "duration": 6.54,
        "text": "and replication"
      },
      {
        "start": 4851.199,
        "duration": 6.46,
        "text": "uh Define the duplication Factor defined"
      },
      {
        "start": 4854.54,
        "duration": 6.36,
        "text": "for each data center Us West one e and"
      },
      {
        "start": 4857.659,
        "duration": 6.721,
        "text": "EU is two we get three"
      },
      {
        "start": 4860.9,
        "duration": 5.04,
        "text": "and five okay so in the First Data"
      },
      {
        "start": 4864.38,
        "duration": 4.98,
        "text": "Center we're gonna have three replicas"
      },
      {
        "start": 4865.94,
        "duration": 5.4,
        "text": "of the same data and in the second data"
      },
      {
        "start": 4869.36,
        "duration": 5.22,
        "text": "center we'll have five replicas of the"
      },
      {
        "start": 4871.34,
        "duration": 7.08,
        "text": "same data so totally eight replicas"
      },
      {
        "start": 4874.58,
        "duration": 6.96,
        "text": "so we can lose as many as seven nodes"
      },
      {
        "start": 4878.42,
        "duration": 4.259,
        "text": "seven replicas and we still have the"
      },
      {
        "start": 4881.54,
        "duration": 4.92,
        "text": "data"
      },
      {
        "start": 4882.679,
        "duration": 5.641,
        "text": "of course we we never want to wait until"
      },
      {
        "start": 4886.46,
        "duration": 4.46,
        "text": "that situation when we have the last one"
      },
      {
        "start": 4888.32,
        "duration": 2.6,
        "text": "we need to"
      },
      {
        "start": 4894.08,
        "duration": 6.659,
        "text": "because with uh like afford to losing"
      },
      {
        "start": 4897.08,
        "duration": 6.48,
        "text": "seven notes and still get our data uh it"
      },
      {
        "start": 4900.739,
        "duration": 5.46,
        "text": "works it's achievable but it brings some"
      },
      {
        "start": 4903.56,
        "duration": 5.04,
        "text": "implications what we what our term will"
      },
      {
        "start": 4906.199,
        "duration": 4.261,
        "text": "say soon at the fourth part of a"
      },
      {
        "start": 4908.6,
        "duration": 3.9,
        "text": "workshop"
      },
      {
        "start": 4910.46,
        "duration": 4.739,
        "text": "yep"
      },
      {
        "start": 4912.5,
        "duration": 5.46,
        "text": "so with the replication Factor one we"
      },
      {
        "start": 4915.199,
        "duration": 6.601,
        "text": "only store one copy of that partition"
      },
      {
        "start": 4917.96,
        "duration": 6.84,
        "text": "with replication Factor two we store two"
      },
      {
        "start": 4921.8,
        "duration": 5.52,
        "text": "copies that we have two replicas those"
      },
      {
        "start": 4924.8,
        "duration": 4.859,
        "text": "are different nodes and we store two"
      },
      {
        "start": 4927.32,
        "duration": 5.22,
        "text": "copies on different or one copy on each"
      },
      {
        "start": 4929.659,
        "duration": 5.52,
        "text": "node with replication factor of C we"
      },
      {
        "start": 4932.54,
        "duration": 6.3,
        "text": "have three different copies"
      },
      {
        "start": 4935.179,
        "duration": 6.841,
        "text": "and and so on right and what it looks"
      },
      {
        "start": 4938.84,
        "duration": 7.28,
        "text": "like in internally is basically with"
      },
      {
        "start": 4942.02,
        "duration": 7.5,
        "text": "replication factor of two the this node"
      },
      {
        "start": 4946.12,
        "duration": 6.099,
        "text": "is now responsible for two token ranges"
      },
      {
        "start": 4949.52,
        "duration": 4.26,
        "text": "it used to be with the pH Factor one it"
      },
      {
        "start": 4952.219,
        "duration": 3.96,
        "text": "was responsible for one now it's"
      },
      {
        "start": 4953.78,
        "duration": 4.98,
        "text": "responsible for two token ranges"
      },
      {
        "start": 4956.179,
        "duration": 5.941,
        "text": "and and this node is responsible for two"
      },
      {
        "start": 4958.76,
        "duration": 5.7,
        "text": "token ranges as well but it doesn't make"
      },
      {
        "start": 4962.12,
        "duration": 4.92,
        "text": "them special notes they just assign"
      },
      {
        "start": 4964.46,
        "duration": 5.88,
        "text": "different token ranges that's it they"
      },
      {
        "start": 4967.04,
        "duration": 4.92,
        "text": "they kind they function identically and"
      },
      {
        "start": 4970.34,
        "duration": 5.339,
        "text": "all of that"
      },
      {
        "start": 4971.96,
        "duration": 6.0,
        "text": "so with the replication factor of C when"
      },
      {
        "start": 4975.679,
        "duration": 5.221,
        "text": "we combine in partitioning and replicate"
      },
      {
        "start": 4977.96,
        "duration": 5.699,
        "text": "replication what happens so we need to"
      },
      {
        "start": 4980.9,
        "duration": 6.92,
        "text": "store this partition with two rows in"
      },
      {
        "start": 4983.659,
        "duration": 7.201,
        "text": "our cluster this Forest uh partition key"
      },
      {
        "start": 4987.82,
        "duration": 8.44,
        "text": "will be converted to a token let's say"
      },
      {
        "start": 4990.86,
        "duration": 9.12,
        "text": "it's 59 and based on the this 59 token"
      },
      {
        "start": 4996.26,
        "duration": 6.18,
        "text": "so the the the application can send this"
      },
      {
        "start": 4999.98,
        "duration": 5.94,
        "text": "request to any node in the cluster and"
      },
      {
        "start": 5002.44,
        "duration": 7.92,
        "text": "that node becomes a coordinator of the"
      },
      {
        "start": 5005.92,
        "duration": 7.259,
        "text": "request so we get 59 to this node blue"
      },
      {
        "start": 5010.36,
        "duration": 5.879,
        "text": "node and this coordinator knows exactly"
      },
      {
        "start": 5013.179,
        "duration": 6.48,
        "text": "which replicas are responsible for 59"
      },
      {
        "start": 5016.239,
        "duration": 5.221,
        "text": "for token 59 because it knows ranges of"
      },
      {
        "start": 5019.659,
        "duration": 5.941,
        "text": "all the other nodes"
      },
      {
        "start": 5021.46,
        "duration": 7.38,
        "text": "okay so it will take the data and will"
      },
      {
        "start": 5025.6,
        "duration": 6.24,
        "text": "send that data to all three replicas"
      },
      {
        "start": 5028.84,
        "duration": 4.379,
        "text": "because replication factor is three so"
      },
      {
        "start": 5031.84,
        "duration": 5.1,
        "text": "it will send the data to all three"
      },
      {
        "start": 5033.219,
        "duration": 6.96,
        "text": "replicas and in the normal circumstances"
      },
      {
        "start": 5036.94,
        "duration": 4.44,
        "text": "all three nodes will get that data"
      },
      {
        "start": 5040.179,
        "duration": 4.621,
        "text": "stored"
      },
      {
        "start": 5041.38,
        "duration": 7.08,
        "text": "okay and of course"
      },
      {
        "start": 5044.8,
        "duration": 6.3,
        "text": "to optimize it right to optimize it the"
      },
      {
        "start": 5048.46,
        "duration": 5.16,
        "text": "um uh in Cassandra"
      },
      {
        "start": 5051.1,
        "duration": 5.88,
        "text": "when when you write in your application"
      },
      {
        "start": 5053.62,
        "duration": 8.099,
        "text": "with data stack driver and and data API"
      },
      {
        "start": 5056.98,
        "duration": 7.02,
        "text": "the the interfaces I uh token aware"
      },
      {
        "start": 5061.719,
        "duration": 5.221,
        "text": "interfaces so essentially your driver"
      },
      {
        "start": 5064.0,
        "duration": 6.6,
        "text": "will also know which nodes are"
      },
      {
        "start": 5066.94,
        "duration": 6.06,
        "text": "responsible for uh your driver also know"
      },
      {
        "start": 5070.6,
        "duration": 4.8,
        "text": "with which nodes are responsible for for"
      },
      {
        "start": 5073.0,
        "duration": 4.8,
        "text": "the data so it will not just speak any"
      },
      {
        "start": 5075.4,
        "duration": 4.92,
        "text": "coordinator it will pick one of the"
      },
      {
        "start": 5077.8,
        "duration": 5.399,
        "text": "replicas as a coordinator so that it"
      },
      {
        "start": 5080.32,
        "duration": 4.2,
        "text": "speeds up things you have to do less"
      },
      {
        "start": 5083.199,
        "duration": 4.681,
        "text": "work"
      },
      {
        "start": 5084.52,
        "duration": 6.96,
        "text": "uh I want to uh say a word here I don't"
      },
      {
        "start": 5087.88,
        "duration": 6.359,
        "text": "like the word coordinator because it's"
      },
      {
        "start": 5091.48,
        "duration": 5.58,
        "text": "actually misleading I prefer to call it"
      },
      {
        "start": 5094.239,
        "duration": 5.46,
        "text": "query coordinator and whatever node has"
      },
      {
        "start": 5097.06,
        "duration": 4.5,
        "text": "got your query is that query coordinator"
      },
      {
        "start": 5099.699,
        "duration": 5.161,
        "text": "because people often start to think"
      },
      {
        "start": 5101.56,
        "duration": 6.24,
        "text": "about that uh like masternode which is"
      },
      {
        "start": 5104.86,
        "duration": 5.22,
        "text": "wrong yeah every node is query"
      },
      {
        "start": 5107.8,
        "duration": 5.58,
        "text": "coordinator node as soon as it processes"
      },
      {
        "start": 5110.08,
        "duration": 5.7,
        "text": "your query and each query each node may"
      },
      {
        "start": 5113.38,
        "duration": 5.96,
        "text": "get your query depending on how driver"
      },
      {
        "start": 5115.78,
        "duration": 6.419,
        "text": "is behaving no answer to Adriana"
      },
      {
        "start": 5119.34,
        "duration": 4.899,
        "text": "Cassandra driver is a Cassandra driver a"
      },
      {
        "start": 5122.199,
        "duration": 4.741,
        "text": "query coordinator is one of the nodes"
      },
      {
        "start": 5124.239,
        "duration": 5.161,
        "text": "it's decided to conduct in most of the"
      },
      {
        "start": 5126.94,
        "duration": 5.04,
        "text": "cases query coordinator will conduct one"
      },
      {
        "start": 5129.4,
        "duration": 4.86,
        "text": "of the replicas for web partition you"
      },
      {
        "start": 5131.98,
        "duration": 4.739,
        "text": "are trying to work with"
      },
      {
        "start": 5134.26,
        "duration": 4.8,
        "text": "yeah even better term is request"
      },
      {
        "start": 5136.719,
        "duration": 4.801,
        "text": "coordinator right so it's not only query"
      },
      {
        "start": 5139.06,
        "duration": 5.099,
        "text": "it's both reads and writes indeed"
      },
      {
        "start": 5141.52,
        "duration": 5.28,
        "text": "coordinator has nothing to do with with"
      },
      {
        "start": 5144.159,
        "duration": 5.341,
        "text": "a master or leader that we discuss in"
      },
      {
        "start": 5146.8,
        "duration": 5.64,
        "text": "the architecture it's just the temporary"
      },
      {
        "start": 5149.5,
        "duration": 5.94,
        "text": "role that just to perform that request"
      },
      {
        "start": 5152.44,
        "duration": 5.219,
        "text": "just to forward that request to correct"
      },
      {
        "start": 5155.44,
        "duration": 5.04,
        "text": "replicas"
      },
      {
        "start": 5157.659,
        "duration": 5.461,
        "text": "um yeah and Cassandra Cassandra driver"
      },
      {
        "start": 5160.48,
        "duration": 4.44,
        "text": "one of the questions uh is it is it"
      },
      {
        "start": 5163.12,
        "duration": 3.5,
        "text": "coordinator Knox undertale it's just a"
      },
      {
        "start": 5164.92,
        "duration": 5.16,
        "text": "library that allows you to"
      },
      {
        "start": 5166.62,
        "duration": 5.8,
        "text": "connect to Cassandra cluster from your"
      },
      {
        "start": 5170.08,
        "duration": 5.28,
        "text": "application written in Java python"
      },
      {
        "start": 5172.42,
        "duration": 4.62,
        "text": "JavaScript and so on so now we're gonna"
      },
      {
        "start": 5175.36,
        "duration": 4.799,
        "text": "do"
      },
      {
        "start": 5177.04,
        "duration": 6.48,
        "text": "um our first Hands-On with Cassandra but"
      },
      {
        "start": 5180.159,
        "duration": 5.461,
        "text": "we are not gonna use the um local"
      },
      {
        "start": 5183.52,
        "duration": 5.58,
        "text": "installation we we're gonna use instead"
      },
      {
        "start": 5185.62,
        "duration": 6.14,
        "text": "the um cloud-based service that is built"
      },
      {
        "start": 5189.1,
        "duration": 6.119,
        "text": "based on Cassandra it's called astridbe"
      },
      {
        "start": 5191.76,
        "duration": 7.419,
        "text": "so for our purposes what we will use is"
      },
      {
        "start": 5195.219,
        "duration": 6.721,
        "text": "is gonna be a free part of free plan you"
      },
      {
        "start": 5199.179,
        "duration": 5.281,
        "text": "may have to register sign up uh for for"
      },
      {
        "start": 5201.94,
        "duration": 5.4,
        "text": "that plan and you get"
      },
      {
        "start": 5204.46,
        "duration": 5.4,
        "text": "a large number a large amount of storage"
      },
      {
        "start": 5207.34,
        "duration": 4.98,
        "text": "and large number of operations every"
      },
      {
        "start": 5209.86,
        "duration": 4.62,
        "text": "month so um you don't need to worry"
      },
      {
        "start": 5212.32,
        "duration": 3.6,
        "text": "there will be no credit card asked or"
      },
      {
        "start": 5214.48,
        "duration": 4.259,
        "text": "anything else"
      },
      {
        "start": 5215.92,
        "duration": 4.799,
        "text": "why why do we want to use this well for"
      },
      {
        "start": 5218.739,
        "duration": 5.221,
        "text": "Hands-On we are not worrying about"
      },
      {
        "start": 5220.719,
        "duration": 5.221,
        "text": "operations it we we want to start using"
      },
      {
        "start": 5223.96,
        "duration": 5.42,
        "text": "the database without dealing with"
      },
      {
        "start": 5225.94,
        "duration": 6.0,
        "text": "installing uh Cassandra on a note"
      },
      {
        "start": 5229.38,
        "duration": 5.68,
        "text": "installing the second node connecting"
      },
      {
        "start": 5231.94,
        "duration": 6.48,
        "text": "them I I would say about Astra this"
      },
      {
        "start": 5235.06,
        "duration": 7.32,
        "text": "Workshop would be like uh four or five"
      },
      {
        "start": 5238.42,
        "duration": 5.88,
        "text": "hours the duration right not to indeed"
      },
      {
        "start": 5242.38,
        "duration": 5.279,
        "text": "okay we will not feed gender two but two"
      },
      {
        "start": 5244.3,
        "duration": 5.64,
        "text": "and a half let's say yeah so I will so"
      },
      {
        "start": 5247.659,
        "duration": 4.681,
        "text": "there are many good features about this"
      },
      {
        "start": 5249.94,
        "duration": 6.66,
        "text": "cloud service called Astrid B but I will"
      },
      {
        "start": 5252.34,
        "duration": 6.54,
        "text": "just mention too that uh for me it make"
      },
      {
        "start": 5256.6,
        "duration": 3.96,
        "text": "a lot of difference is one no operation"
      },
      {
        "start": 5258.88,
        "duration": 4.68,
        "text": "so you don't need to install anything"
      },
      {
        "start": 5260.56,
        "duration": 5.4,
        "text": "you just click on the buttons and and"
      },
      {
        "start": 5263.56,
        "duration": 5.099,
        "text": "the cluster is running in the cloud for"
      },
      {
        "start": 5265.96,
        "duration": 6.3,
        "text": "you you just start interacting with it"
      },
      {
        "start": 5268.659,
        "duration": 5.881,
        "text": "in our case we will use cql shell to"
      },
      {
        "start": 5272.26,
        "duration": 4.86,
        "text": "interact with that classroom and the"
      },
      {
        "start": 5274.54,
        "duration": 3.84,
        "text": "second one is this serverless feature"
      },
      {
        "start": 5277.12,
        "duration": 3.78,
        "text": "remember"
      },
      {
        "start": 5278.38,
        "duration": 5.64,
        "text": "when we talked about scaling in and"
      },
      {
        "start": 5280.9,
        "duration": 6.2,
        "text": "scaling out so all of this is done for"
      },
      {
        "start": 5284.02,
        "duration": 6.659,
        "text": "you automatically so it's Auto scaling"
      },
      {
        "start": 5287.1,
        "duration": 6.22,
        "text": "that is built in as a feature of this"
      },
      {
        "start": 5290.679,
        "duration": 4.98,
        "text": "database so you don't need to worry"
      },
      {
        "start": 5293.32,
        "duration": 4.98,
        "text": "about adding nodes if if you need to"
      },
      {
        "start": 5295.659,
        "duration": 5.04,
        "text": "store more data or you need to process"
      },
      {
        "start": 5298.3,
        "duration": 5.52,
        "text": "more concurrent requests and you don't"
      },
      {
        "start": 5300.699,
        "duration": 5.46,
        "text": "need to worry about scaling out so in"
      },
      {
        "start": 5303.82,
        "duration": 4.46,
        "text": "case for example you have the during the"
      },
      {
        "start": 5306.159,
        "duration": 4.381,
        "text": "day the usage is higher"
      },
      {
        "start": 5308.28,
        "duration": 4.78,
        "text": "automatically you will get the logic"
      },
      {
        "start": 5310.54,
        "duration": 4.26,
        "text": "Blaster built for you and you don't need"
      },
      {
        "start": 5313.06,
        "duration": 3.9,
        "text": "to you don't worry about it at all you"
      },
      {
        "start": 5314.8,
        "duration": 4.919,
        "text": "don't do anything about it it's just"
      },
      {
        "start": 5316.96,
        "duration": 4.62,
        "text": "automatic if and it denied the usage is"
      },
      {
        "start": 5319.719,
        "duration": 3.841,
        "text": "lower and and the number of nodes"
      },
      {
        "start": 5321.58,
        "duration": 4.68,
        "text": "decreases automatically for you so you"
      },
      {
        "start": 5323.56,
        "duration": 6.56,
        "text": "don't need need to spend extra resources"
      },
      {
        "start": 5326.26,
        "duration": 7.979,
        "text": "so our first lab will be to use this"
      },
      {
        "start": 5330.12,
        "duration": 7.24,
        "text": "Magic database called Astrid B we will"
      },
      {
        "start": 5334.239,
        "duration": 5.101,
        "text": "create and it's it's built on Cassandra"
      },
      {
        "start": 5337.36,
        "duration": 4.08,
        "text": "again we are not going to use any"
      },
      {
        "start": 5339.34,
        "duration": 5.06,
        "text": "features that are not Cassandra features"
      },
      {
        "start": 5341.44,
        "duration": 6.0,
        "text": "as well so we'll create a"
      },
      {
        "start": 5344.4,
        "duration": 9.279,
        "text": "tables we will insert data we will"
      },
      {
        "start": 5347.44,
        "duration": 9.66,
        "text": "create data okay so let me so this is"
      },
      {
        "start": 5353.679,
        "duration": 5.821,
        "text": "the URL that you can use to access the"
      },
      {
        "start": 5357.1,
        "duration": 6.72,
        "text": "Hands-On instructions and the first one"
      },
      {
        "start": 5359.5,
        "duration": 6.48,
        "text": "is it's gonna be really easy"
      },
      {
        "start": 5363.82,
        "duration": 5.839,
        "text": "okay"
      },
      {
        "start": 5365.98,
        "duration": 3.679,
        "text": "so this is the first one"
      },
      {
        "start": 5372.58,
        "duration": 6.659,
        "text": "create your database okay so this is the"
      },
      {
        "start": 5376.179,
        "duration": 5.401,
        "text": "link you can follow to go to astrodb"
      },
      {
        "start": 5379.239,
        "duration": 5.581,
        "text": "website"
      },
      {
        "start": 5381.58,
        "duration": 5.7,
        "text": "okay and there you will"
      },
      {
        "start": 5384.82,
        "duration": 5.04,
        "text": "if you don't have account already you"
      },
      {
        "start": 5387.28,
        "duration": 4.08,
        "text": "can sign up and you can sign up with"
      },
      {
        "start": 5389.86,
        "duration": 3.839,
        "text": "your Google account if you already have"
      },
      {
        "start": 5391.36,
        "duration": 4.02,
        "text": "an account you can sign in what we will"
      },
      {
        "start": 5393.699,
        "duration": 4.621,
        "text": "do there we will simply create a"
      },
      {
        "start": 5395.38,
        "duration": 7.14,
        "text": "database with name workshops"
      },
      {
        "start": 5398.32,
        "duration": 6.66,
        "text": "okay and key space name sensor"
      },
      {
        "start": 5402.52,
        "duration": 4.619,
        "text": "underscore data we will use Google cloud"
      },
      {
        "start": 5404.98,
        "duration": 6.12,
        "text": "provider"
      },
      {
        "start": 5407.139,
        "duration": 6.0,
        "text": "um to deploy our cluster in and you will"
      },
      {
        "start": 5411.1,
        "duration": 4.38,
        "text": "see what happens whether it's difficult"
      },
      {
        "start": 5413.139,
        "duration": 4.201,
        "text": "or not so I'm clicking this create Astra"
      },
      {
        "start": 5415.48,
        "duration": 3.0,
        "text": "DB"
      },
      {
        "start": 5417.34,
        "duration": 4.5,
        "text": "foreign"
      },
      {
        "start": 5418.48,
        "duration": 4.98,
        "text": "okay and I get to this screen so I'm"
      },
      {
        "start": 5421.84,
        "duration": 6.98,
        "text": "going to sign in"
      },
      {
        "start": 5423.46,
        "duration": 5.36,
        "text": "in this case uh with Google account"
      },
      {
        "start": 5431.62,
        "duration": 6.24,
        "text": "okay and I get to this screen"
      },
      {
        "start": 5435.46,
        "duration": 5.16,
        "text": "okay I will wait a little bit"
      },
      {
        "start": 5437.86,
        "duration": 6.359,
        "text": "how many people are already"
      },
      {
        "start": 5440.62,
        "duration": 6.5,
        "text": "signed into Astra"
      },
      {
        "start": 5444.219,
        "duration": 2.901,
        "text": "website"
      },
      {
        "start": 5447.639,
        "duration": 4.981,
        "text": "um can you confirm can"
      },
      {
        "start": 5449.98,
        "duration": 4.98,
        "text": "can you confirm in the chat or do you"
      },
      {
        "start": 5452.62,
        "duration": 5.16,
        "text": "need time to sign up first"
      },
      {
        "start": 5454.96,
        "duration": 4.98,
        "text": "okay so people like it I mean like sign"
      },
      {
        "start": 5457.78,
        "duration": 4.859,
        "text": "up using Google account or GitHub"
      },
      {
        "start": 5459.94,
        "duration": 4.14,
        "text": "account is uh there are just a few extra"
      },
      {
        "start": 5462.639,
        "duration": 4.56,
        "text": "questions there yeah okay we're getting"
      },
      {
        "start": 5464.08,
        "duration": 7.26,
        "text": "the sign in sign in yeah"
      },
      {
        "start": 5467.199,
        "duration": 5.94,
        "text": "so the next step you can go to databases"
      },
      {
        "start": 5471.34,
        "duration": 4.26,
        "text": "and it's"
      },
      {
        "start": 5473.139,
        "duration": 5.221,
        "text": "if you haven't used this database before"
      },
      {
        "start": 5475.6,
        "duration": 4.98,
        "text": "there is nothing here so it says the"
      },
      {
        "start": 5478.36,
        "duration": 7.26,
        "text": "create database in my case I don't have"
      },
      {
        "start": 5480.58,
        "duration": 7.28,
        "text": "any databases so I will create database"
      },
      {
        "start": 5485.62,
        "duration": 4.92,
        "text": "foreign"
      },
      {
        "start": 5487.86,
        "duration": 5.56,
        "text": "we need to specify the name of the"
      },
      {
        "start": 5490.54,
        "duration": 5.699,
        "text": "database and key space name"
      },
      {
        "start": 5493.42,
        "duration": 4.44,
        "text": "so workshops"
      },
      {
        "start": 5496.239,
        "duration": 4.261,
        "text": "is the one"
      },
      {
        "start": 5497.86,
        "duration": 6.08,
        "text": "the name of database and key space name"
      },
      {
        "start": 5500.5,
        "duration": 3.44,
        "text": "is sensor data"
      },
      {
        "start": 5507.28,
        "duration": 6.0,
        "text": "okay pretty simple"
      },
      {
        "start": 5509.139,
        "duration": 6.481,
        "text": "and you can see this is a free plan this"
      },
      {
        "start": 5513.28,
        "duration": 4.859,
        "text": "there are certain restrictions on on on"
      },
      {
        "start": 5515.62,
        "duration": 5.22,
        "text": "where I can deploy my cluster and"
      },
      {
        "start": 5518.139,
        "duration": 5.301,
        "text": "essentially I can deploy it in the"
      },
      {
        "start": 5520.84,
        "duration": 2.6,
        "text": "foreign"
      },
      {
        "start": 5526.0,
        "duration": 5.94,
        "text": "okay and I will use North America I"
      },
      {
        "start": 5530.08,
        "duration": 4.139,
        "text": "don't think any other or there are some"
      },
      {
        "start": 5531.94,
        "duration": 3.08,
        "text": "other agents if you're in Europe you can"
      },
      {
        "start": 5534.219,
        "duration": 3.661,
        "text": "use"
      },
      {
        "start": 5535.02,
        "duration": 5.199,
        "text": "Belgium if you're an AJ you can use"
      },
      {
        "start": 5537.88,
        "duration": 4.98,
        "text": "Mumbai India"
      },
      {
        "start": 5540.219,
        "duration": 6.301,
        "text": "in my case I'm not I'm in North America"
      },
      {
        "start": 5542.86,
        "duration": 6.42,
        "text": "so I will use the South Carolina"
      },
      {
        "start": 5546.52,
        "duration": 6.02,
        "text": "Us East one"
      },
      {
        "start": 5549.28,
        "duration": 3.26,
        "text": "as my"
      },
      {
        "start": 5553.0,
        "duration": 4.32,
        "text": "um"
      },
      {
        "start": 5554.139,
        "duration": 5.52,
        "text": "the region in in Google Cloud to to"
      },
      {
        "start": 5557.32,
        "duration": 5.399,
        "text": "deploy the database so these are three"
      },
      {
        "start": 5559.659,
        "duration": 5.721,
        "text": "steps right or two steps technically"
      },
      {
        "start": 5562.719,
        "duration": 5.161,
        "text": "right the database name key space name"
      },
      {
        "start": 5565.38,
        "duration": 3.58,
        "text": "and the provider"
      },
      {
        "start": 5567.88,
        "duration": 3.54,
        "text": "then"
      },
      {
        "start": 5568.96,
        "duration": 5.58,
        "text": "create database"
      },
      {
        "start": 5571.42,
        "duration": 6.0,
        "text": "and at this point you it may take a"
      },
      {
        "start": 5574.54,
        "duration": 6.54,
        "text": "couple of minutes what happens be behind"
      },
      {
        "start": 5577.42,
        "duration": 6.0,
        "text": "the scenes is you will get um three node"
      },
      {
        "start": 5581.08,
        "duration": 5.22,
        "text": "cluster created for you automatically"
      },
      {
        "start": 5583.42,
        "duration": 5.7,
        "text": "okay and"
      },
      {
        "start": 5586.3,
        "duration": 4.859,
        "text": "you will also get these tokens generated"
      },
      {
        "start": 5589.12,
        "duration": 3.9,
        "text": "these are different tokens that we we"
      },
      {
        "start": 5591.159,
        "duration": 2.941,
        "text": "discussed these are tokens related to"
      },
      {
        "start": 5593.02,
        "duration": 4.56,
        "text": "security"
      },
      {
        "start": 5594.1,
        "duration": 6.599,
        "text": "these are not tokens that produced by"
      },
      {
        "start": 5597.58,
        "duration": 6.72,
        "text": "partitioner right so um and we don't"
      },
      {
        "start": 5600.699,
        "duration": 6.721,
        "text": "need to use them so you just can go to"
      },
      {
        "start": 5604.3,
        "duration": 4.859,
        "text": "so anything here is is uh"
      },
      {
        "start": 5607.42,
        "duration": 3.18,
        "text": "something that you will need when you"
      },
      {
        "start": 5609.159,
        "duration": 3.721,
        "text": "write your application we're not going"
      },
      {
        "start": 5610.6,
        "duration": 3.2,
        "text": "to write an application yet we're gonna"
      },
      {
        "start": 5612.88,
        "duration": 3.359,
        "text": "use"
      },
      {
        "start": 5613.8,
        "duration": 3.58,
        "text": "built-in clients to work with this"
      },
      {
        "start": 5616.239,
        "duration": 3.42,
        "text": "database"
      },
      {
        "start": 5617.38,
        "duration": 4.92,
        "text": "so at this point you can see workshops"
      },
      {
        "start": 5619.659,
        "duration": 6.48,
        "text": "database oh it's already active that's"
      },
      {
        "start": 5622.3,
        "duration": 6.839,
        "text": "really cool and in the next exercise or"
      },
      {
        "start": 5626.139,
        "duration": 5.821,
        "text": "lab we will go to cql console"
      },
      {
        "start": 5629.139,
        "duration": 7.401,
        "text": "to work with this database"
      },
      {
        "start": 5631.96,
        "duration": 9.5,
        "text": "okay and with this Alex"
      },
      {
        "start": 5636.54,
        "duration": 4.92,
        "text": "yes thank you so much"
      },
      {
        "start": 5641.679,
        "duration": 7.46,
        "text": "I think I switched to I think I switch"
      },
      {
        "start": 5646.3,
        "duration": 8.46,
        "text": "us to my screen"
      },
      {
        "start": 5649.139,
        "duration": 7.721,
        "text": "thank you and good okay before we"
      },
      {
        "start": 5654.76,
        "duration": 4.86,
        "text": "proceed I want to answer two questions"
      },
      {
        "start": 5656.86,
        "duration": 6.779,
        "text": "there are two great questions in the"
      },
      {
        "start": 5659.62,
        "duration": 6.599,
        "text": "chat uh one from Mallory telis and thank"
      },
      {
        "start": 5663.639,
        "duration": 5.341,
        "text": "you for asking uh great questions in a"
      },
      {
        "start": 5666.219,
        "duration": 5.94,
        "text": "row how do the Cassandra driver and"
      },
      {
        "start": 5668.98,
        "duration": 4.62,
        "text": "nodes perform service Discovery uh in"
      },
      {
        "start": 5672.159,
        "duration": 4.98,
        "text": "short idea"
      },
      {
        "start": 5673.6,
        "duration": 7.38,
        "text": "uh each node communicates with each node"
      },
      {
        "start": 5677.139,
        "duration": 5.821,
        "text": "then you launch a cluster nodes uh can"
      },
      {
        "start": 5680.98,
        "duration": 4.32,
        "text": "join this cluster and each server"
      },
      {
        "start": 5682.96,
        "duration": 4.8,
        "text": "understands how many nodes are in the"
      },
      {
        "start": 5685.3,
        "duration": 3.359,
        "text": "cluster but that's only half of the"
      },
      {
        "start": 5687.76,
        "duration": 3.479,
        "text": "answer"
      },
      {
        "start": 5688.659,
        "duration": 5.58,
        "text": "the second answer is when you have a"
      },
      {
        "start": 5691.239,
        "duration": 5.221,
        "text": "cluster like a originally consisting of"
      },
      {
        "start": 5694.239,
        "duration": 3.601,
        "text": "one node two nodes like small amount of"
      },
      {
        "start": 5696.46,
        "duration": 4.62,
        "text": "nodes in the beginning"
      },
      {
        "start": 5697.84,
        "duration": 5.76,
        "text": "they share those token ranges what are"
      },
      {
        "start": 5701.08,
        "duration": 4.8,
        "text": "John was talking earlier so each server"
      },
      {
        "start": 5703.6,
        "duration": 5.039,
        "text": "let's say we have free cluster a free"
      },
      {
        "start": 5705.88,
        "duration": 5.759,
        "text": "node cluster each server responsible of"
      },
      {
        "start": 5708.639,
        "duration": 4.741,
        "text": "free uh observed approximately third of"
      },
      {
        "start": 5711.639,
        "duration": 5.161,
        "text": "a token ranges"
      },
      {
        "start": 5713.38,
        "duration": 5.819,
        "text": "you have next server they are being"
      },
      {
        "start": 5716.8,
        "duration": 4.68,
        "text": "recalculated and next server will be"
      },
      {
        "start": 5719.199,
        "duration": 5.341,
        "text": "responsible and the servers will be"
      },
      {
        "start": 5721.48,
        "duration": 7.259,
        "text": "responsible for quarter of them"
      },
      {
        "start": 5724.54,
        "duration": 7.08,
        "text": "uh tokens like work water 25 percent of"
      },
      {
        "start": 5728.739,
        "duration": 4.201,
        "text": "a token range let's say uh it's a little"
      },
      {
        "start": 5731.62,
        "duration": 3.24,
        "text": "bit more complicated because of"
      },
      {
        "start": 5732.94,
        "duration": 3.54,
        "text": "replication but that is a general idea"
      },
      {
        "start": 5734.86,
        "duration": 4.859,
        "text": "now"
      },
      {
        "start": 5736.48,
        "duration": 5.88,
        "text": "each server not only knows a knows which"
      },
      {
        "start": 5739.719,
        "duration": 5.641,
        "text": "token ranges it's responsible for but"
      },
      {
        "start": 5742.36,
        "duration": 4.62,
        "text": "also knows which token ranges are its"
      },
      {
        "start": 5745.36,
        "duration": 4.279,
        "text": "neighbors and other servers in the"
      },
      {
        "start": 5746.98,
        "duration": 6.659,
        "text": "cluster responsible for"
      },
      {
        "start": 5749.639,
        "duration": 6.1,
        "text": "and the same goes to a driver then you"
      },
      {
        "start": 5753.639,
        "duration": 5.941,
        "text": "launch an application you have to"
      },
      {
        "start": 5755.739,
        "duration": 5.061,
        "text": "specify IP address of some nodes that is"
      },
      {
        "start": 5759.58,
        "duration": 4.92,
        "text": "important"
      },
      {
        "start": 5760.8,
        "duration": 5.98,
        "text": "but a traditional approach in a"
      },
      {
        "start": 5764.5,
        "duration": 5.46,
        "text": "relational databases for example use"
      },
      {
        "start": 5766.78,
        "duration": 5.82,
        "text": "petsify IP address of a node in the"
      },
      {
        "start": 5769.96,
        "duration": 5.279,
        "text": "beginning like Master server legal"
      },
      {
        "start": 5772.6,
        "duration": 5.34,
        "text": "server and your um"
      },
      {
        "start": 5775.239,
        "duration": 4.201,
        "text": "application will work with this and this"
      },
      {
        "start": 5777.94,
        "duration": 4.38,
        "text": "only server"
      },
      {
        "start": 5779.44,
        "duration": 4.38,
        "text": "and that is for Cassandra a complete"
      },
      {
        "start": 5782.32,
        "duration": 4.98,
        "text": "misconception"
      },
      {
        "start": 5783.82,
        "duration": 5.819,
        "text": "because you your node your application"
      },
      {
        "start": 5787.3,
        "duration": 5.04,
        "text": "driver your Cassandra driver will use"
      },
      {
        "start": 5789.639,
        "duration": 5.221,
        "text": "EVS IP address in the beginning"
      },
      {
        "start": 5792.34,
        "duration": 4.74,
        "text": "to bootstrap information to load"
      },
      {
        "start": 5794.86,
        "duration": 4.44,
        "text": "information about the cluster then"
      },
      {
        "start": 5797.08,
        "duration": 5.7,
        "text": "driver starts it will go to this IP"
      },
      {
        "start": 5799.3,
        "duration": 5.58,
        "text": "address and ask what is a cluster what"
      },
      {
        "start": 5802.78,
        "duration": 4.919,
        "text": "are the nodes which node is responsible"
      },
      {
        "start": 5804.88,
        "duration": 5.24,
        "text": "for which particular token range"
      },
      {
        "start": 5807.699,
        "duration": 5.701,
        "text": "then you execute a query"
      },
      {
        "start": 5810.12,
        "duration": 6.16,
        "text": "driver calculates the partition token"
      },
      {
        "start": 5813.4,
        "duration": 5.7,
        "text": "from the partition key you gave"
      },
      {
        "start": 5816.28,
        "duration": 6.0,
        "text": "and then makes a query uh do a"
      },
      {
        "start": 5819.1,
        "duration": 5.88,
        "text": "particular server already knowing which"
      },
      {
        "start": 5822.28,
        "duration": 6.78,
        "text": "servers are responsible for which"
      },
      {
        "start": 5824.98,
        "duration": 6.54,
        "text": "partition because it knows nodes and"
      },
      {
        "start": 5829.06,
        "duration": 5.28,
        "text": "token range and allocation which server"
      },
      {
        "start": 5831.52,
        "duration": 4.56,
        "text": "responsible for which partition tokens"
      },
      {
        "start": 5834.34,
        "duration": 3.5,
        "text": "simple as that"
      },
      {
        "start": 5836.08,
        "duration": 4.8,
        "text": "and then"
      },
      {
        "start": 5837.84,
        "duration": 5.799,
        "text": "these actually answers the second"
      },
      {
        "start": 5840.88,
        "duration": 5.58,
        "text": "question by another person Mahmoud"
      },
      {
        "start": 5843.639,
        "duration": 5.221,
        "text": "akhtar asks is the request coordinator"
      },
      {
        "start": 5846.46,
        "duration": 5.34,
        "text": "similar to Lord balancer"
      },
      {
        "start": 5848.86,
        "duration": 6.0,
        "text": "no request coordinator isn't similar to"
      },
      {
        "start": 5851.8,
        "duration": 6.419,
        "text": "Lord balancer because Lord balancer is"
      },
      {
        "start": 5854.86,
        "duration": 5.879,
        "text": "the client the driver for example you"
      },
      {
        "start": 5858.219,
        "duration": 4.701,
        "text": "have replication Factor free that means"
      },
      {
        "start": 5860.739,
        "duration": 4.44,
        "text": "what were a free replicas of your"
      },
      {
        "start": 5862.92,
        "duration": 5.5,
        "text": "partition is stored on three different"
      },
      {
        "start": 5865.179,
        "duration": 4.921,
        "text": "servers there you try to retrieve a data"
      },
      {
        "start": 5868.42,
        "duration": 3.42,
        "text": "from this partition or maybe write"
      },
      {
        "start": 5870.1,
        "duration": 4.44,
        "text": "something to this partition"
      },
      {
        "start": 5871.84,
        "duration": 4.92,
        "text": "you have to give a partition key then"
      },
      {
        "start": 5874.54,
        "duration": 5.099,
        "text": "driver calculates a partition token"
      },
      {
        "start": 5876.76,
        "duration": 5.64,
        "text": "based on the partition key you gave it"
      },
      {
        "start": 5879.639,
        "duration": 5.181,
        "text": "knows which pre-servers store your data"
      },
      {
        "start": 5882.4,
        "duration": 4.799,
        "text": "and then base it on the route Robin"
      },
      {
        "start": 5884.82,
        "duration": 4.839,
        "text": "balancing policy it may change from"
      },
      {
        "start": 5887.199,
        "duration": 6.781,
        "text": "version to version but the general idea"
      },
      {
        "start": 5889.659,
        "duration": 6.601,
        "text": "it tries to ask the least loaded server"
      },
      {
        "start": 5893.98,
        "duration": 5.699,
        "text": "of those three"
      },
      {
        "start": 5896.26,
        "duration": 5.84,
        "text": "to get your data so client-side load"
      },
      {
        "start": 5899.679,
        "duration": 2.421,
        "text": "balancing"
      },
      {
        "start": 5903.06,
        "duration": 6.28,
        "text": "all right it's built in into driver yep"
      },
      {
        "start": 5906.82,
        "duration": 7.08,
        "text": "yeah"
      },
      {
        "start": 5909.34,
        "duration": 6.839,
        "text": "yes a good question melroy uh friend you"
      },
      {
        "start": 5913.9,
        "duration": 5.4,
        "text": "really need to get the Cassandra"
      },
      {
        "start": 5916.179,
        "duration": 4.98,
        "text": "certification like it's free and it"
      },
      {
        "start": 5919.3,
        "duration": 4.919,
        "text": "really helped you to get your LinkedIn"
      },
      {
        "start": 5921.159,
        "duration": 5.461,
        "text": "profile page to look better and make"
      },
      {
        "start": 5924.219,
        "duration": 4.98,
        "text": "more money in the end I'll really like"
      },
      {
        "start": 5926.62,
        "duration": 3.86,
        "text": "your question man uh"
      },
      {
        "start": 5929.199,
        "duration": 4.261,
        "text": "so"
      },
      {
        "start": 5930.48,
        "duration": 5.259,
        "text": "if a node receives a request for a"
      },
      {
        "start": 5933.46,
        "duration": 4.739,
        "text": "partition with a token outside the token"
      },
      {
        "start": 5935.739,
        "duration": 5.521,
        "text": "range it will behave like a query"
      },
      {
        "start": 5938.199,
        "duration": 5.52,
        "text": "coordinator so it sees what I'm not"
      },
      {
        "start": 5941.26,
        "duration": 4.8,
        "text": "responsible for this token but I know"
      },
      {
        "start": 5943.719,
        "duration": 4.98,
        "text": "who is responsible so I become a query"
      },
      {
        "start": 5946.06,
        "duration": 5.24,
        "text": "coordinator or request coordinator and"
      },
      {
        "start": 5948.699,
        "duration": 6.121,
        "text": "root this query to a proper servers"
      },
      {
        "start": 5951.3,
        "duration": 5.14,
        "text": "coordinate their efforts and return the"
      },
      {
        "start": 5954.82,
        "duration": 4.5,
        "text": "result as soon as I have this result"
      },
      {
        "start": 5956.44,
        "duration": 4.86,
        "text": "that's the answer so no request is"
      },
      {
        "start": 5959.32,
        "duration": 4.379,
        "text": "rejected"
      },
      {
        "start": 5961.3,
        "duration": 5.22,
        "text": "okay I have answered all the questions"
      },
      {
        "start": 5963.699,
        "duration": 4.641,
        "text": "now it's my time to ask you some"
      },
      {
        "start": 5966.52,
        "duration": 4.74,
        "text": "questions right"
      },
      {
        "start": 5968.34,
        "duration": 4.48,
        "text": "uh two two questions in a row yes two"
      },
      {
        "start": 5971.26,
        "duration": 4.08,
        "text": "questions in a row actually even three"
      },
      {
        "start": 5972.82,
        "duration": 5.1,
        "text": "questions in a row and question number"
      },
      {
        "start": 5975.34,
        "duration": 6.299,
        "text": "uh one of those three will be how many"
      },
      {
        "start": 5977.92,
        "duration": 5.46,
        "text": "masternodes Cassandra cluster needs"
      },
      {
        "start": 5981.639,
        "duration": 3.781,
        "text": "minimum free"
      },
      {
        "start": 5983.38,
        "duration": 5.1,
        "text": "per Data Center"
      },
      {
        "start": 5985.42,
        "duration": 5.779,
        "text": "follow replica divided by three no"
      },
      {
        "start": 5988.48,
        "duration": 2.719,
        "text": "masternodes"
      },
      {
        "start": 5992.199,
        "duration": 4.161,
        "text": "I'm quite curious about the answers"
      },
      {
        "start": 5997.12,
        "duration": 2.48,
        "text": "people"
      },
      {
        "start": 6001.08,
        "duration": 6.659,
        "text": "okay 23 persons answer it right no"
      },
      {
        "start": 6005.159,
        "duration": 5.401,
        "text": "master notes there are no concept of a"
      },
      {
        "start": 6007.739,
        "duration": 6.601,
        "text": "master node in Cassandra no master notes"
      },
      {
        "start": 6010.56,
        "duration": 7.2,
        "text": "in Cassandra nope okay"
      },
      {
        "start": 6014.34,
        "duration": 6.2,
        "text": "very well let me see how it will go with"
      },
      {
        "start": 6017.76,
        "duration": 2.78,
        "text": "the next question"
      },
      {
        "start": 6021.6,
        "duration": 4.4,
        "text": "how is data for a table distributed"
      },
      {
        "start": 6026.4,
        "duration": 8.6,
        "text": "each server has all data one table on"
      },
      {
        "start": 6029.76,
        "duration": 5.24,
        "text": "one server by partitions by shards"
      },
      {
        "start": 6050.04,
        "duration": 6.9,
        "text": "okay yes right by partitions"
      },
      {
        "start": 6053.46,
        "duration": 7.259,
        "text": "uh we cannot have things like each"
      },
      {
        "start": 6056.94,
        "duration": 6.779,
        "text": "server has all data"
      },
      {
        "start": 6060.719,
        "duration": 5.701,
        "text": "um oh yeah because it will just not feed"
      },
      {
        "start": 6063.719,
        "duration": 4.92,
        "text": "like we speak about 100 terabytes we"
      },
      {
        "start": 6066.42,
        "duration": 4.2,
        "text": "speak about petabytes of data there are"
      },
      {
        "start": 6068.639,
        "duration": 4.801,
        "text": "no server to hold this data and still"
      },
      {
        "start": 6070.62,
        "duration": 4.619,
        "text": "answer within milliseconds"
      },
      {
        "start": 6073.44,
        "duration": 3.779,
        "text": "yeah and there is a question where"
      },
      {
        "start": 6075.239,
        "duration": 4.321,
        "text": "should we answer those questions answer"
      },
      {
        "start": 6077.219,
        "duration": 5.96,
        "text": "is on top of the screen go to"
      },
      {
        "start": 6079.56,
        "duration": 7.56,
        "text": "mention.com and use the code"
      },
      {
        "start": 6083.179,
        "duration": 6.96,
        "text": "6291-8600 or you can just get the link"
      },
      {
        "start": 6087.12,
        "duration": 3.019,
        "text": "in the chat"
      },
      {
        "start": 6090.38,
        "duration": 4.779,
        "text": "I will answer your question after this"
      },
      {
        "start": 6093.48,
        "duration": 4.199,
        "text": "uh quiz"
      },
      {
        "start": 6095.159,
        "duration": 5.221,
        "text": "good"
      },
      {
        "start": 6097.679,
        "duration": 6.241,
        "text": "right transfer is by partitions and then"
      },
      {
        "start": 6100.38,
        "duration": 7.98,
        "text": "finally last question what is the"
      },
      {
        "start": 6103.92,
        "duration": 7.199,
        "text": "biggest problem of replication"
      },
      {
        "start": 6108.36,
        "duration": 5.46,
        "text": "uh we are getting to the next section I"
      },
      {
        "start": 6111.119,
        "duration": 5.281,
        "text": "will be doing and what is the biggest"
      },
      {
        "start": 6113.82,
        "duration": 5.879,
        "text": "problem of replicated data"
      },
      {
        "start": 6116.4,
        "duration": 6.239,
        "text": "increase disk space consumption more"
      },
      {
        "start": 6119.699,
        "duration": 6.0,
        "text": "networks transaction or potential Cruise"
      },
      {
        "start": 6122.639,
        "duration": 5.04,
        "text": "node inconsistency that is a treaty"
      },
      {
        "start": 6125.699,
        "duration": 6.44,
        "text": "question"
      },
      {
        "start": 6127.679,
        "duration": 4.46,
        "text": "I made it intentionally very team"
      },
      {
        "start": 6133.08,
        "duration": 4.94,
        "text": "so I'm very curious of what your answer"
      },
      {
        "start": 6135.48,
        "duration": 2.54,
        "text": "will be"
      },
      {
        "start": 6138.179,
        "duration": 7.5,
        "text": "and time is up yeah nice"
      },
      {
        "start": 6141.78,
        "duration": 6.18,
        "text": "nice so very good very good now it is a"
      },
      {
        "start": 6145.679,
        "duration": 4.621,
        "text": "tricky question so if you gave a kind of"
      },
      {
        "start": 6147.96,
        "duration": 3.779,
        "text": "wrong answer wait for a second I will"
      },
      {
        "start": 6150.3,
        "duration": 3.24,
        "text": "explain"
      },
      {
        "start": 6151.739,
        "duration": 4.321,
        "text": "take a look"
      },
      {
        "start": 6153.54,
        "duration": 6.06,
        "text": "all of those answers are technically"
      },
      {
        "start": 6156.06,
        "duration": 6.36,
        "text": "correct because it all those all are the"
      },
      {
        "start": 6159.6,
        "duration": 4.74,
        "text": "problems of replicated data replicated"
      },
      {
        "start": 6162.42,
        "duration": 4.5,
        "text": "data leads to increased disk space"
      },
      {
        "start": 6164.34,
        "duration": 4.92,
        "text": "consumption replicated data leads to"
      },
      {
        "start": 6166.92,
        "duration": 4.62,
        "text": "more Network transactions and definitely"
      },
      {
        "start": 6169.26,
        "duration": 5.04,
        "text": "replicated data leads to potential gross"
      },
      {
        "start": 6171.54,
        "duration": 5.94,
        "text": "node inconsistency but the question was"
      },
      {
        "start": 6174.3,
        "duration": 5.939,
        "text": "what is the biggest problem of"
      },
      {
        "start": 6177.48,
        "duration": 5.82,
        "text": "replicated data and the biggest problem"
      },
      {
        "start": 6180.239,
        "duration": 4.141,
        "text": "is potential inconsistency let me"
      },
      {
        "start": 6183.3,
        "duration": 3.78,
        "text": "explain"
      },
      {
        "start": 6184.38,
        "duration": 4.92,
        "text": "first two disk space or network"
      },
      {
        "start": 6187.08,
        "duration": 4.559,
        "text": "transactions you know there is a very"
      },
      {
        "start": 6189.3,
        "duration": 4.919,
        "text": "good phrase if you can solve a problem"
      },
      {
        "start": 6191.639,
        "duration": 4.08,
        "text": "with money it's not a problem it's"
      },
      {
        "start": 6194.219,
        "duration": 3.721,
        "text": "expenses"
      },
      {
        "start": 6195.719,
        "duration": 4.261,
        "text": "and that's exactly the same Cassandra is"
      },
      {
        "start": 6197.94,
        "duration": 4.679,
        "text": "used by companies like apple or Netflix"
      },
      {
        "start": 6199.98,
        "duration": 3.719,
        "text": "or Instagram those guys have money for"
      },
      {
        "start": 6202.619,
        "duration": 3.54,
        "text": "disks"
      },
      {
        "start": 6203.699,
        "duration": 5.101,
        "text": "and disk space is cheap what is"
      },
      {
        "start": 6206.159,
        "duration": 5.221,
        "text": "priceless is your reputation and"
      },
      {
        "start": 6208.8,
        "duration": 5.359,
        "text": "reputation for engineers very often"
      },
      {
        "start": 6211.38,
        "duration": 5.4,
        "text": "defined by the uptime of the application"
      },
      {
        "start": 6214.159,
        "duration": 4.841,
        "text": "so yeah replication is not possible"
      },
      {
        "start": 6216.78,
        "duration": 4.62,
        "text": "without some disk space consumption and"
      },
      {
        "start": 6219.0,
        "duration": 4.679,
        "text": "that is expenses not a problem exacting"
      },
      {
        "start": 6221.4,
        "duration": 4.98,
        "text": "okay problem problem but solvable"
      },
      {
        "start": 6223.679,
        "duration": 4.46,
        "text": "Problem solvable by money same with"
      },
      {
        "start": 6226.38,
        "duration": 4.68,
        "text": "network transactions modern"
      },
      {
        "start": 6228.139,
        "duration": 5.141,
        "text": "software-defined networks even sustained"
      },
      {
        "start": 6231.06,
        "duration": 4.92,
        "text": "software-defined networks are extremely"
      },
      {
        "start": 6233.28,
        "duration": 5.04,
        "text": "fast not to say fiber optics blah blah"
      },
      {
        "start": 6235.98,
        "duration": 4.56,
        "text": "blah also very very fast so it is a"
      },
      {
        "start": 6238.32,
        "duration": 4.62,
        "text": "problem yes it's solvable yes"
      },
      {
        "start": 6240.54,
        "duration": 5.22,
        "text": "uh but potential gross node and"
      },
      {
        "start": 6242.94,
        "duration": 6.92,
        "text": "consistency is a real deal breaker"
      },
      {
        "start": 6245.76,
        "duration": 4.1,
        "text": "so let me show you what do I mean"
      },
      {
        "start": 6252.06,
        "duration": 5.46,
        "text": "take a look you have your data"
      },
      {
        "start": 6254.28,
        "duration": 5.82,
        "text": "replicated on multiple servers"
      },
      {
        "start": 6257.52,
        "duration": 3.9,
        "text": "for example price for the goods you are"
      },
      {
        "start": 6260.1,
        "duration": 3.599,
        "text": "selling"
      },
      {
        "start": 6261.42,
        "duration": 5.04,
        "text": "and then there is an update you want to"
      },
      {
        "start": 6263.699,
        "duration": 4.44,
        "text": "update a price sell it more expensive"
      },
      {
        "start": 6266.46,
        "duration": 4.86,
        "text": "for example I don't know inflation or"
      },
      {
        "start": 6268.139,
        "duration": 5.881,
        "text": "whatever but for whatever reason Network"
      },
      {
        "start": 6271.32,
        "duration": 5.819,
        "text": "outage power outage I don't know server"
      },
      {
        "start": 6274.02,
        "duration": 5.82,
        "text": "kidnapped by aliens uh server stolen"
      },
      {
        "start": 6277.139,
        "duration": 5.1,
        "text": "violence uh this update didn't reach"
      },
      {
        "start": 6279.84,
        "duration": 4.74,
        "text": "your one of your servers and as an"
      },
      {
        "start": 6282.239,
        "duration": 3.9,
        "text": "outcome two server have new most"
      },
      {
        "start": 6284.58,
        "duration": 3.9,
        "text": "up-to-date price"
      },
      {
        "start": 6286.139,
        "duration": 5.221,
        "text": "and second server does not a third"
      },
      {
        "start": 6288.48,
        "duration": 5.159,
        "text": "server does not that is called that"
      },
      {
        "start": 6291.36,
        "duration": 3.859,
        "text": "cross node inconsistency when one of the"
      },
      {
        "start": 6293.639,
        "duration": 5.341,
        "text": "servers stole"
      },
      {
        "start": 6295.219,
        "duration": 5.92,
        "text": "serves stale data what happens I mean if"
      },
      {
        "start": 6298.98,
        "duration": 4.739,
        "text": "you ask visor web server for the data"
      },
      {
        "start": 6301.139,
        "duration": 4.681,
        "text": "you get your answer and everyone escapee"
      },
      {
        "start": 6303.719,
        "duration": 5.041,
        "text": "but if you ask this one and this one"
      },
      {
        "start": 6305.82,
        "duration": 5.52,
        "text": "only that may lead to a real problem"
      },
      {
        "start": 6308.76,
        "duration": 5.939,
        "text": "because with even one dollar difference"
      },
      {
        "start": 6311.34,
        "duration": 5.94,
        "text": "over time on a big"
      },
      {
        "start": 6314.699,
        "duration": 5.761,
        "text": "um intensive cell may lead to Big losses"
      },
      {
        "start": 6317.28,
        "duration": 7.379,
        "text": "but we don't want you to have"
      },
      {
        "start": 6320.46,
        "duration": 6.14,
        "text": "um so to protect itself from a potential"
      },
      {
        "start": 6324.659,
        "duration": 6.121,
        "text": "gross node inconsistency"
      },
      {
        "start": 6326.6,
        "duration": 5.86,
        "text": "Cassandra has multiple tools or layered"
      },
      {
        "start": 6330.78,
        "duration": 4.62,
        "text": "defense"
      },
      {
        "start": 6332.46,
        "duration": 5.94,
        "text": "first one we already discussed it"
      },
      {
        "start": 6335.4,
        "duration": 6.06,
        "text": "first one was hinted uh handoffs briefly"
      },
      {
        "start": 6338.4,
        "duration": 6.48,
        "text": "mentioned before uh hinted handoff means"
      },
      {
        "start": 6341.46,
        "duration": 6.719,
        "text": "when for example we process this data"
      },
      {
        "start": 6344.88,
        "duration": 6.72,
        "text": "and this node is a query coordinator but"
      },
      {
        "start": 6348.179,
        "duration": 7.321,
        "text": "not replica who are the replicas because"
      },
      {
        "start": 6351.6,
        "duration": 6.24,
        "text": "this network forest makes token 59 and"
      },
      {
        "start": 6355.5,
        "duration": 4.679,
        "text": "those three servers are responsible for"
      },
      {
        "start": 6357.84,
        "duration": 5.16,
        "text": "this uh token"
      },
      {
        "start": 6360.179,
        "duration": 4.621,
        "text": "then that means what we will send these"
      },
      {
        "start": 6363.0,
        "duration": 4.92,
        "text": "data to those three replicas query"
      },
      {
        "start": 6364.8,
        "duration": 6.0,
        "text": "coordinator sees what one of the servers"
      },
      {
        "start": 6367.92,
        "duration": 7.259,
        "text": "does not return the answer so not"
      },
      {
        "start": 6370.8,
        "duration": 6.3,
        "text": "confirms receivable of this update"
      },
      {
        "start": 6375.179,
        "duration": 6.06,
        "text": "what happens then"
      },
      {
        "start": 6377.1,
        "duration": 6.18,
        "text": "query coordinator stores hind hint it's"
      },
      {
        "start": 6381.239,
        "duration": 4.741,
        "text": "a persistent data basically it's a file"
      },
      {
        "start": 6383.28,
        "duration": 5.64,
        "text": "what keeps this information"
      },
      {
        "start": 6385.98,
        "duration": 4.8,
        "text": "as soon as this server recovers as"
      },
      {
        "start": 6388.92,
        "duration": 5.34,
        "text": "servers are communicating with each"
      },
      {
        "start": 6390.78,
        "duration": 6.3,
        "text": "other this server knows what this server"
      },
      {
        "start": 6394.26,
        "duration": 6.12,
        "text": "has recovered and it dispatches the"
      },
      {
        "start": 6397.08,
        "duration": 6.24,
        "text": "screen to them to do a replica failed"
      },
      {
        "start": 6400.38,
        "duration": 6.239,
        "text": "replica so cross node consistency is"
      },
      {
        "start": 6403.32,
        "duration": 5.839,
        "text": "recovered but this mechanism although"
      },
      {
        "start": 6406.619,
        "duration": 5.281,
        "text": "it's magical it works perfectly"
      },
      {
        "start": 6409.159,
        "duration": 6.701,
        "text": "it has um"
      },
      {
        "start": 6411.9,
        "duration": 6.779,
        "text": "some limitations as well for example you"
      },
      {
        "start": 6415.86,
        "duration": 5.72,
        "text": "don't want to keep your hints for too"
      },
      {
        "start": 6418.679,
        "duration": 6.48,
        "text": "long for example if this server was out"
      },
      {
        "start": 6421.58,
        "duration": 5.559,
        "text": "for a couple of days whatever bad"
      },
      {
        "start": 6425.159,
        "duration": 5.281,
        "text": "happened to it it was not available for"
      },
      {
        "start": 6427.139,
        "duration": 5.941,
        "text": "today's then it will get a real storm of"
      },
      {
        "start": 6430.44,
        "duration": 5.64,
        "text": "hints when it recovers what may bring"
      },
      {
        "start": 6433.08,
        "duration": 5.82,
        "text": "him to down again well not exactly like"
      },
      {
        "start": 6436.08,
        "duration": 5.94,
        "text": "this I'm simplifying but um"
      },
      {
        "start": 6438.9,
        "duration": 5.339,
        "text": "the story is hints usually store it only"
      },
      {
        "start": 6442.02,
        "duration": 3.96,
        "text": "to only about three or four hours"
      },
      {
        "start": 6444.239,
        "duration": 4.861,
        "text": "depends on the version"
      },
      {
        "start": 6445.98,
        "duration": 6.06,
        "text": "and after that we will be discarded if"
      },
      {
        "start": 6449.1,
        "duration": 5.34,
        "text": "node was out less than three or four"
      },
      {
        "start": 6452.04,
        "duration": 4.98,
        "text": "hours it will be recovered automatically"
      },
      {
        "start": 6454.44,
        "duration": 4.86,
        "text": "if it isn't you may want to execute"
      },
      {
        "start": 6457.02,
        "duration": 4.139,
        "text": "repairs or you may want to take it off"
      },
      {
        "start": 6459.3,
        "duration": 3.48,
        "text": "the cluster and bring it again to a"
      },
      {
        "start": 6461.159,
        "duration": 4.401,
        "text": "cluster as new"
      },
      {
        "start": 6462.78,
        "duration": 7.5,
        "text": "uh we will"
      },
      {
        "start": 6465.56,
        "duration": 6.4,
        "text": "C other mechanisms also we will discuss"
      },
      {
        "start": 6470.28,
        "duration": 2.939,
        "text": "some other mechanisms to control"
      },
      {
        "start": 6471.96,
        "duration": 3.96,
        "text": "consistency"
      },
      {
        "start": 6473.219,
        "duration": 4.681,
        "text": "so hinted handoffs we just discussed it"
      },
      {
        "start": 6475.92,
        "duration": 3.84,
        "text": "it's a Cassandra job Cassandra is very"
      },
      {
        "start": 6477.9,
        "duration": 4.62,
        "text": "good with it and it's fully automated"
      },
      {
        "start": 6479.76,
        "duration": 5.1,
        "text": "you don't have to think about it that"
      },
      {
        "start": 6482.52,
        "duration": 4.46,
        "text": "there is a repair on read we will see"
      },
      {
        "start": 6484.86,
        "duration": 6.299,
        "text": "you soon in progress"
      },
      {
        "start": 6486.98,
        "duration": 7.239,
        "text": "good then repairs repairs and his"
      },
      {
        "start": 6491.159,
        "duration": 5.52,
        "text": "administrator's job to configure so it's"
      },
      {
        "start": 6494.219,
        "duration": 4.381,
        "text": "not covered by today Workshop if you are"
      },
      {
        "start": 6496.679,
        "duration": 4.381,
        "text": "interested in operation and maintenance"
      },
      {
        "start": 6498.6,
        "duration": 4.619,
        "text": "for Cassandra clusters we have a free"
      },
      {
        "start": 6501.06,
        "duration": 3.92,
        "text": "course or Cassandra operations available"
      },
      {
        "start": 6503.219,
        "duration": 4.861,
        "text": "on"
      },
      {
        "start": 6504.98,
        "duration": 6.699,
        "text": "academy.datastacks.com for free it's"
      },
      {
        "start": 6508.08,
        "duration": 5.639,
        "text": "called a ds210 ds210"
      },
      {
        "start": 6511.679,
        "duration": 5.48,
        "text": "and you are very welcome to take this"
      },
      {
        "start": 6513.719,
        "duration": 6.42,
        "text": "one and then finally consistency levels"
      },
      {
        "start": 6517.159,
        "duration": 4.96,
        "text": "consistency level is a developer job and"
      },
      {
        "start": 6520.139,
        "duration": 3.781,
        "text": "as this Workshop is for developers we"
      },
      {
        "start": 6522.119,
        "duration": 4.62,
        "text": "will be focusing mostly on the"
      },
      {
        "start": 6523.92,
        "duration": 5.219,
        "text": "consistency levels today"
      },
      {
        "start": 6526.739,
        "duration": 4.821,
        "text": "uh"
      },
      {
        "start": 6529.139,
        "duration": 2.421,
        "text": "before"
      },
      {
        "start": 6531.78,
        "duration": 6.56,
        "text": "two questions"
      },
      {
        "start": 6534.26,
        "duration": 4.08,
        "text": "and they are really related"
      },
      {
        "start": 6538.619,
        "duration": 7.801,
        "text": "okay so uh first question uh from"
      },
      {
        "start": 6542.9,
        "duration": 6.1,
        "text": "the Josh Kumar partitioning key details"
      },
      {
        "start": 6546.42,
        "duration": 5.819,
        "text": "are stored on all nodes means for each"
      },
      {
        "start": 6549.0,
        "duration": 5.46,
        "text": "table index is created on each node yes"
      },
      {
        "start": 6552.239,
        "duration": 4.801,
        "text": "and no I mean it's not index in the"
      },
      {
        "start": 6554.46,
        "duration": 5.52,
        "text": "normal understanding like for indexing"
      },
      {
        "start": 6557.04,
        "duration": 7.5,
        "text": "data for search capabilities no"
      },
      {
        "start": 6559.98,
        "duration": 8.96,
        "text": "um it is we can call it an index but the"
      },
      {
        "start": 6564.54,
        "duration": 7.98,
        "text": "general idea is what each node nodes"
      },
      {
        "start": 6568.94,
        "duration": 6.04,
        "text": "token ranges uh allocation over the"
      },
      {
        "start": 6572.52,
        "duration": 8.04,
        "text": "cluster so each node knows what for"
      },
      {
        "start": 6574.98,
        "duration": 8.28,
        "text": "example token is 14 or 42 and who uh it"
      },
      {
        "start": 6580.56,
        "duration": 7.5,
        "text": "knows token ranges what for tokens from"
      },
      {
        "start": 6583.26,
        "duration": 7.56,
        "text": "40 to 50 server a is responsible so it"
      },
      {
        "start": 6588.06,
        "duration": 4.679,
        "text": "knows which server to ask to take care"
      },
      {
        "start": 6590.82,
        "duration": 4.5,
        "text": "of his data"
      },
      {
        "start": 6592.739,
        "duration": 5.521,
        "text": "and an index but not in the normal"
      },
      {
        "start": 6595.32,
        "duration": 4.68,
        "text": "relational database understanding of the"
      },
      {
        "start": 6598.26,
        "duration": 4.62,
        "text": "index okay"
      },
      {
        "start": 6600.0,
        "duration": 5.659,
        "text": "I hope I answered this one yeah well let"
      },
      {
        "start": 6602.88,
        "duration": 5.04,
        "text": "me add it's it's a very small data that"
      },
      {
        "start": 6605.659,
        "duration": 5.141,
        "text": "metadata that needs to be stored about"
      },
      {
        "start": 6607.92,
        "duration": 3.68,
        "text": "token ranges so there is no need to"
      },
      {
        "start": 6610.8,
        "duration": 4.2,
        "text": "store"
      },
      {
        "start": 6611.6,
        "duration": 6.46,
        "text": "details of each partition key when the"
      },
      {
        "start": 6615.0,
        "duration": 7.5,
        "text": "data comes that value of a partition key"
      },
      {
        "start": 6618.06,
        "duration": 7.44,
        "text": "is run through the uh a partitioner"
      },
      {
        "start": 6622.5,
        "duration": 5.88,
        "text": "murmur Suite partition that generates a"
      },
      {
        "start": 6625.5,
        "duration": 5.94,
        "text": "token so it's just very simple and quick"
      },
      {
        "start": 6628.38,
        "duration": 6.239,
        "text": "operation so whatever text you give or"
      },
      {
        "start": 6631.44,
        "duration": 6.12,
        "text": "integer you give you get one number and"
      },
      {
        "start": 6634.619,
        "duration": 5.401,
        "text": "that number will fall into one of the"
      },
      {
        "start": 6637.56,
        "duration": 5.099,
        "text": "ranges and that's very very easy to find"
      },
      {
        "start": 6640.02,
        "duration": 5.159,
        "text": "which which range it's gonna fall there"
      },
      {
        "start": 6642.659,
        "duration": 3.48,
        "text": "are not millions of those ranges right"
      },
      {
        "start": 6645.179,
        "duration": 3.421,
        "text": "so"
      },
      {
        "start": 6646.139,
        "duration": 5.161,
        "text": "yep"
      },
      {
        "start": 6648.6,
        "duration": 4.559,
        "text": "and that also probably answers the the"
      },
      {
        "start": 6651.3,
        "duration": 5.22,
        "text": "next question that we have how do we"
      },
      {
        "start": 6653.159,
        "duration": 5.301,
        "text": "know something is a replica or not it's"
      },
      {
        "start": 6656.52,
        "duration": 4.56,
        "text": "based on the"
      },
      {
        "start": 6658.46,
        "duration": 4.84,
        "text": "murmurc partitioner converting to the"
      },
      {
        "start": 6661.08,
        "duration": 4.74,
        "text": "token and the token range is assigned to"
      },
      {
        "start": 6663.3,
        "duration": 6.54,
        "text": "the different nodes"
      },
      {
        "start": 6665.82,
        "duration": 6.24,
        "text": "a question from a CGR do you have visual"
      },
      {
        "start": 6669.84,
        "duration": 4.02,
        "text": "slide which shows the overall right or"
      },
      {
        "start": 6672.06,
        "duration": 4.5,
        "text": "read process from a series of steps"
      },
      {
        "start": 6673.86,
        "duration": 6.72,
        "text": "answer is yes but it's not the part of"
      },
      {
        "start": 6676.56,
        "duration": 6.24,
        "text": "this Workshop it's a part of a deeper uh"
      },
      {
        "start": 6680.58,
        "duration": 3.98,
        "text": "Apache Cassandra fundamental scores at"
      },
      {
        "start": 6682.8,
        "duration": 5.819,
        "text": "the data Stacks Academy"
      },
      {
        "start": 6684.56,
        "duration": 5.74,
        "text": "and this this is a read pass write pass"
      },
      {
        "start": 6688.619,
        "duration": 4.5,
        "text": "they are not necessarily super simple"
      },
      {
        "start": 6690.3,
        "duration": 5.819,
        "text": "there are many different things involved"
      },
      {
        "start": 6693.119,
        "duration": 6.661,
        "text": "there like memory data structure some"
      },
      {
        "start": 6696.119,
        "duration": 7.08,
        "text": "indexes uh something on multiple files"
      },
      {
        "start": 6699.78,
        "duration": 5.76,
        "text": "on this so these are internals to be"
      },
      {
        "start": 6703.199,
        "duration": 5.52,
        "text": "able to successfully use Cassandra you"
      },
      {
        "start": 6705.54,
        "duration": 6.119,
        "text": "don't really need to know that much in"
      },
      {
        "start": 6708.719,
        "duration": 5.341,
        "text": "terms of uh the the all of those data"
      },
      {
        "start": 6711.659,
        "duration": 6.121,
        "text": "structures and how they interact yeah"
      },
      {
        "start": 6714.06,
        "duration": 5.88,
        "text": "and now to answer a question by Adriana"
      },
      {
        "start": 6717.78,
        "duration": 5.16,
        "text": "um how do we know something is a replica"
      },
      {
        "start": 6719.94,
        "duration": 5.94,
        "text": "or not uh short answer is"
      },
      {
        "start": 6722.94,
        "duration": 5.58,
        "text": "each node is a replica for some"
      },
      {
        "start": 6725.88,
        "duration": 5.04,
        "text": "partitions right"
      },
      {
        "start": 6728.52,
        "duration": 5.88,
        "text": "um each node stores data each node is a"
      },
      {
        "start": 6730.92,
        "duration": 5.759,
        "text": "replica the real question is what will"
      },
      {
        "start": 6734.4,
        "duration": 4.259,
        "text": "be the replica for the partition we are"
      },
      {
        "start": 6736.679,
        "duration": 4.621,
        "text": "currently working with"
      },
      {
        "start": 6738.659,
        "duration": 6.781,
        "text": "we working with Partition like we work"
      },
      {
        "start": 6741.3,
        "duration": 8.399,
        "text": "with these temperature data of Texas for"
      },
      {
        "start": 6745.44,
        "duration": 7.02,
        "text": "example and uh partition as a partition"
      },
      {
        "start": 6749.699,
        "duration": 5.101,
        "text": "key Texas we know what will be the token"
      },
      {
        "start": 6752.46,
        "duration": 5.1,
        "text": "of this partition as we give it to more"
      },
      {
        "start": 6754.8,
        "duration": 5.339,
        "text": "more free partitioner hashing algorithm"
      },
      {
        "start": 6757.56,
        "duration": 5.34,
        "text": "it gives us some integer and we know"
      },
      {
        "start": 6760.139,
        "duration": 5.641,
        "text": "what each server in our cluster for"
      },
      {
        "start": 6762.9,
        "duration": 8.7,
        "text": "example we have six servers it's"
      },
      {
        "start": 6765.78,
        "duration": 6.859,
        "text": "responsible for uh like 18 persons of"
      },
      {
        "start": 6771.6,
        "duration": 4.92,
        "text": "um"
      },
      {
        "start": 6772.639,
        "duration": 5.98,
        "text": "of the potential tokens"
      },
      {
        "start": 6776.52,
        "duration": 5.099,
        "text": "and we know what replication factor is"
      },
      {
        "start": 6778.619,
        "duration": 5.221,
        "text": "free we already know these uh token"
      },
      {
        "start": 6781.619,
        "duration": 4.201,
        "text": "ranges are location over the cluster so"
      },
      {
        "start": 6783.84,
        "duration": 4.799,
        "text": "when we just make this quick quick"
      },
      {
        "start": 6785.82,
        "duration": 4.919,
        "text": "comparison over the data what uh RTO"
      },
      {
        "start": 6788.639,
        "duration": 4.921,
        "text": "mentioned already and then we know which"
      },
      {
        "start": 6790.739,
        "duration": 4.98,
        "text": "node is a replica for this data"
      },
      {
        "start": 6793.56,
        "duration": 4.02,
        "text": "it's better explain it in more details"
      },
      {
        "start": 6795.719,
        "duration": 5.42,
        "text": "let's explain it in our Cassandra"
      },
      {
        "start": 6797.58,
        "duration": 3.559,
        "text": "fundamental scores at the Academy"
      },
      {
        "start": 6801.92,
        "duration": 6.699,
        "text": "yeah and again your application can"
      },
      {
        "start": 6805.32,
        "duration": 5.64,
        "text": "connect to any node and and Magic"
      },
      {
        "start": 6808.619,
        "duration": 4.681,
        "text": "happens for you you don't really need to"
      },
      {
        "start": 6810.96,
        "duration": 3.96,
        "text": "you you you you don't need to deal with"
      },
      {
        "start": 6813.3,
        "duration": 4.319,
        "text": "tokens directly"
      },
      {
        "start": 6814.92,
        "duration": 7.16,
        "text": "you just deal with your data and and"
      },
      {
        "start": 6817.619,
        "duration": 4.461,
        "text": "tables schema that you create"
      },
      {
        "start": 6823.619,
        "duration": 2.54,
        "text": "so"
      },
      {
        "start": 6827.1,
        "duration": 3.9,
        "text": "so then we switch to your part number"
      },
      {
        "start": 6829.8,
        "duration": 3.72,
        "text": "four right"
      },
      {
        "start": 6831.0,
        "duration": 6.06,
        "text": "uh yes"
      },
      {
        "start": 6833.52,
        "duration": 8.219,
        "text": "so in this section uh we're gonna talk"
      },
      {
        "start": 6837.06,
        "duration": 8.48,
        "text": "about cap cerium and"
      },
      {
        "start": 6841.739,
        "duration": 3.801,
        "text": "the this Serum is"
      },
      {
        "start": 6845.94,
        "duration": 7.52,
        "text": "is very fundamental to not only do"
      },
      {
        "start": 6849.06,
        "duration": 4.4,
        "text": "Cassandra but to any distributed system"
      },
      {
        "start": 6853.5,
        "duration": 8.58,
        "text": "okay any distributed system so"
      },
      {
        "start": 6858.739,
        "duration": 6.281,
        "text": "it operates with these three"
      },
      {
        "start": 6862.08,
        "duration": 5.579,
        "text": "um features or three properties"
      },
      {
        "start": 6865.02,
        "duration": 6.06,
        "text": "availability consistency partition"
      },
      {
        "start": 6867.659,
        "duration": 5.58,
        "text": "tolerance and the ethereum essentially"
      },
      {
        "start": 6871.08,
        "duration": 3.24,
        "text": "says that"
      },
      {
        "start": 6873.239,
        "duration": 4.621,
        "text": "um"
      },
      {
        "start": 6874.32,
        "duration": 6.06,
        "text": "the the in a in any distributed system"
      },
      {
        "start": 6877.86,
        "duration": 4.279,
        "text": "in any distributed"
      },
      {
        "start": 6880.38,
        "duration": 3.9,
        "text": "data store"
      },
      {
        "start": 6882.139,
        "duration": 4.48,
        "text": "you can only"
      },
      {
        "start": 6884.28,
        "duration": 4.8,
        "text": "choose two of this system you can only"
      },
      {
        "start": 6886.619,
        "duration": 5.52,
        "text": "guarantee two of these two of these"
      },
      {
        "start": 6889.08,
        "duration": 4.74,
        "text": "properties availability consistency or"
      },
      {
        "start": 6892.139,
        "duration": 4.681,
        "text": "petition tolerance so pick two you"
      },
      {
        "start": 6893.82,
        "duration": 6.299,
        "text": "cannot have all three so let's look more"
      },
      {
        "start": 6896.82,
        "duration": 6.0,
        "text": "closely at each one what do they mean"
      },
      {
        "start": 6900.119,
        "duration": 5.1,
        "text": "so the availability again we're talking"
      },
      {
        "start": 6902.82,
        "duration": 3.899,
        "text": "about distributed system multiple nodes"
      },
      {
        "start": 6905.219,
        "duration": 4.381,
        "text": "in a cluster"
      },
      {
        "start": 6906.719,
        "duration": 6.0,
        "text": "and availability means"
      },
      {
        "start": 6909.6,
        "duration": 6.119,
        "text": "uptime but essentially the availability"
      },
      {
        "start": 6912.719,
        "duration": 4.681,
        "text": "means that if you send a request the"
      },
      {
        "start": 6915.719,
        "duration": 2.821,
        "text": "application sends a request to the"
      },
      {
        "start": 6917.4,
        "duration": 4.52,
        "text": "database"
      },
      {
        "start": 6918.54,
        "duration": 5.579,
        "text": "uh you will get a response so database"
      },
      {
        "start": 6921.92,
        "duration": 4.54,
        "text": "was available"
      },
      {
        "start": 6924.119,
        "duration": 6.0,
        "text": "uh it doesn't say notice it doesn't say"
      },
      {
        "start": 6926.46,
        "duration": 6.06,
        "text": "whether response is consistent or not"
      },
      {
        "start": 6930.119,
        "duration": 5.761,
        "text": "whether it's 100 correct or maybe you"
      },
      {
        "start": 6932.52,
        "duration": 6.02,
        "text": "got stale data remember because"
      },
      {
        "start": 6935.88,
        "duration": 5.279,
        "text": "different replicas it it doesn't take"
      },
      {
        "start": 6938.54,
        "duration": 5.079,
        "text": "one replica maybe it takes three"
      },
      {
        "start": 6941.159,
        "duration": 5.58,
        "text": "milliseconds to to get the data another"
      },
      {
        "start": 6943.619,
        "duration": 5.58,
        "text": "one may take seven milliseconds so"
      },
      {
        "start": 6946.739,
        "duration": 5.0,
        "text": "um there is this very short period of"
      },
      {
        "start": 6949.199,
        "duration": 4.801,
        "text": "time where there may be discrepancy"
      },
      {
        "start": 6951.739,
        "duration": 4.721,
        "text": "inconsistency in data so availability"
      },
      {
        "start": 6954.0,
        "duration": 5.58,
        "text": "simply says that the the there will be"
      },
      {
        "start": 6956.46,
        "duration": 5.64,
        "text": "non-error response you will get"
      },
      {
        "start": 6959.58,
        "duration": 5.28,
        "text": "something whether it's empty or there is"
      },
      {
        "start": 6962.1,
        "duration": 5.039,
        "text": "some data but it's not that you will not"
      },
      {
        "start": 6964.86,
        "duration": 4.379,
        "text": "get an error that system is not"
      },
      {
        "start": 6967.139,
        "duration": 3.241,
        "text": "available that's what availability means"
      },
      {
        "start": 6969.239,
        "duration": 3.0,
        "text": "and and"
      },
      {
        "start": 6970.38,
        "duration": 5.22,
        "text": "we usually want to have availability"
      },
      {
        "start": 6972.239,
        "duration": 7.92,
        "text": "right uh the other one uh consistency"
      },
      {
        "start": 6975.6,
        "duration": 6.48,
        "text": "means that you always get the um the you"
      },
      {
        "start": 6980.159,
        "duration": 5.54,
        "text": "always read the data that was most"
      },
      {
        "start": 6982.08,
        "duration": 7.619,
        "text": "recently written so you're not gonna get"
      },
      {
        "start": 6985.699,
        "duration": 7.181,
        "text": "non-stay no you will not get stale data"
      },
      {
        "start": 6989.699,
        "duration": 5.401,
        "text": "okay the the old data so in this case in"
      },
      {
        "start": 6992.88,
        "duration": 4.56,
        "text": "this example we have three replicas one"
      },
      {
        "start": 6995.1,
        "duration": 4.44,
        "text": "of them still has 12 so it didn't finish"
      },
      {
        "start": 6997.44,
        "duration": 6.12,
        "text": "the update for some reason"
      },
      {
        "start": 6999.54,
        "duration": 6.659,
        "text": "so in this case uh this is stale data so"
      },
      {
        "start": 7003.56,
        "duration": 4.86,
        "text": "if we read from only this replica we"
      },
      {
        "start": 7006.199,
        "duration": 5.161,
        "text": "will actually get inconsistent data"
      },
      {
        "start": 7008.42,
        "duration": 5.66,
        "text": "because the most recent value is 13"
      },
      {
        "start": 7011.36,
        "duration": 4.92,
        "text": "right so that what consistency"
      },
      {
        "start": 7014.08,
        "duration": 6.039,
        "text": "inconsistency means"
      },
      {
        "start": 7016.28,
        "duration": 6.06,
        "text": "so you kind of want to get that too"
      },
      {
        "start": 7020.119,
        "duration": 4.641,
        "text": "but remember you cannot get all three"
      },
      {
        "start": 7022.34,
        "duration": 6.359,
        "text": "you need to you need to"
      },
      {
        "start": 7024.76,
        "duration": 6.22,
        "text": "settle on two so it's it's not an easy"
      },
      {
        "start": 7028.699,
        "duration": 4.44,
        "text": "Choice sometimes so the third one is"
      },
      {
        "start": 7030.98,
        "duration": 5.46,
        "text": "partition tolerance because we are"
      },
      {
        "start": 7033.139,
        "duration": 5.52,
        "text": "talking about cluster of nodes"
      },
      {
        "start": 7036.44,
        "duration": 4.739,
        "text": "um things bad things will happen in that"
      },
      {
        "start": 7038.659,
        "duration": 5.821,
        "text": "cluster right so some notes will go down"
      },
      {
        "start": 7041.179,
        "duration": 6.301,
        "text": "and will no longer be in in the uh"
      },
      {
        "start": 7044.48,
        "duration": 5.34,
        "text": "available to respond to anything to"
      },
      {
        "start": 7047.48,
        "duration": 4.92,
        "text": "interact even you can you can have the"
      },
      {
        "start": 7049.82,
        "duration": 6.54,
        "text": "network partitioning like in this"
      },
      {
        "start": 7052.4,
        "duration": 5.759,
        "text": "example when uh these two nodes are no"
      },
      {
        "start": 7056.36,
        "duration": 4.799,
        "text": "longer communicating to these four nodes"
      },
      {
        "start": 7058.159,
        "duration": 5.761,
        "text": "so it's like you you have a brain split"
      },
      {
        "start": 7061.159,
        "duration": 5.821,
        "text": "so-called brain split uh using proper"
      },
      {
        "start": 7063.92,
        "duration": 7.02,
        "text": "technology and you have the group a and"
      },
      {
        "start": 7066.98,
        "duration": 6.239,
        "text": "Group B and they are independent and"
      },
      {
        "start": 7070.94,
        "duration": 4.38,
        "text": "some applications may be interacting"
      },
      {
        "start": 7073.219,
        "duration": 3.721,
        "text": "with these four nodes and other"
      },
      {
        "start": 7075.32,
        "duration": 6.72,
        "text": "applications may be interacting with"
      },
      {
        "start": 7076.94,
        "duration": 5.1,
        "text": "these two two nodes and so"
      },
      {
        "start": 7082.3,
        "duration": 5.5,
        "text": "they they uh long story short so these"
      },
      {
        "start": 7085.82,
        "duration": 4.44,
        "text": "three properties"
      },
      {
        "start": 7087.8,
        "duration": 5.939,
        "text": "the because we are working with"
      },
      {
        "start": 7090.26,
        "duration": 6.3,
        "text": "distributed system and multiple node"
      },
      {
        "start": 7093.739,
        "duration": 5.041,
        "text": "clusters right uh we will things will"
      },
      {
        "start": 7096.56,
        "duration": 4.38,
        "text": "happen notes will go down and and just a"
      },
      {
        "start": 7098.78,
        "duration": 4.16,
        "text": "single node going down it's basically a"
      },
      {
        "start": 7100.94,
        "duration": 5.46,
        "text": "network partitioning already"
      },
      {
        "start": 7102.94,
        "duration": 7.299,
        "text": "but think about those data centers right"
      },
      {
        "start": 7106.4,
        "duration": 7.08,
        "text": "the one in in New York due to snowstorm"
      },
      {
        "start": 7110.239,
        "duration": 5.521,
        "text": "is down right so uh the whole data"
      },
      {
        "start": 7113.48,
        "duration": 5.52,
        "text": "center cannot communicate with data"
      },
      {
        "start": 7115.76,
        "duration": 5.879,
        "text": "center in California right so"
      },
      {
        "start": 7119.0,
        "duration": 5.34,
        "text": "in distribute system everyone always"
      },
      {
        "start": 7121.639,
        "duration": 5.52,
        "text": "chooses partition tolerance so this is"
      },
      {
        "start": 7124.34,
        "duration": 5.399,
        "text": "fixed basically property every database"
      },
      {
        "start": 7127.159,
        "duration": 4.201,
        "text": "wants to be partition tolerant otherwise"
      },
      {
        "start": 7129.739,
        "duration": 4.261,
        "text": "it's very hard to function in"
      },
      {
        "start": 7131.36,
        "duration": 6.48,
        "text": "distributed uh world"
      },
      {
        "start": 7134.0,
        "duration": 4.5,
        "text": "so we only have one more"
      },
      {
        "start": 7137.84,
        "duration": 4.2,
        "text": "um"
      },
      {
        "start": 7138.5,
        "duration": 6.179,
        "text": "Peak so we can use either consistency or"
      },
      {
        "start": 7142.04,
        "duration": 6.119,
        "text": "availability and and therefore those"
      },
      {
        "start": 7144.679,
        "duration": 9.0,
        "text": "systems are usually they they're called"
      },
      {
        "start": 7148.159,
        "duration": 6.781,
        "text": "CP systems or AP systems okay so in case"
      },
      {
        "start": 7153.679,
        "duration": 4.44,
        "text": "of"
      },
      {
        "start": 7154.94,
        "duration": 7.04,
        "text": "uh in case of Cassandra I'm gonna tell"
      },
      {
        "start": 7158.119,
        "duration": 7.52,
        "text": "you right away the um"
      },
      {
        "start": 7161.98,
        "duration": 9.219,
        "text": "the Cassandra is known as an AP system"
      },
      {
        "start": 7165.639,
        "duration": 8.621,
        "text": "even so we can tune it and make it a CPE"
      },
      {
        "start": 7171.199,
        "duration": 6.601,
        "text": "system but that's not necessary"
      },
      {
        "start": 7174.26,
        "duration": 7.1,
        "text": "um the best choice or the best way to"
      },
      {
        "start": 7177.8,
        "duration": 7.62,
        "text": "use Cassandra so Cassandra can um"
      },
      {
        "start": 7181.36,
        "duration": 7.42,
        "text": "use consistency levels to configure"
      },
      {
        "start": 7185.42,
        "duration": 5.759,
        "text": "consistency or or it's so-called tunable"
      },
      {
        "start": 7188.78,
        "duration": 5.78,
        "text": "consistency it has tunable consists you"
      },
      {
        "start": 7191.179,
        "duration": 5.701,
        "text": "can tune it you can change it to"
      },
      {
        "start": 7194.56,
        "duration": 3.94,
        "text": "a different you can you can use"
      },
      {
        "start": 7196.88,
        "duration": 4.02,
        "text": "different consistency levels for"
      },
      {
        "start": 7198.5,
        "duration": 6.0,
        "text": "different requests and essentially each"
      },
      {
        "start": 7200.9,
        "duration": 6.54,
        "text": "request each insert each delete each"
      },
      {
        "start": 7204.5,
        "duration": 6.599,
        "text": "update each select that you will use in"
      },
      {
        "start": 7207.44,
        "duration": 5.699,
        "text": "Cassandra has Associated consistency"
      },
      {
        "start": 7211.099,
        "duration": 5.161,
        "text": "level they can be different for"
      },
      {
        "start": 7213.139,
        "duration": 6.241,
        "text": "different requests but they can also be"
      },
      {
        "start": 7216.26,
        "duration": 6.32,
        "text": "the same so it all depends on your it so"
      },
      {
        "start": 7219.38,
        "duration": 6.9,
        "text": "you tune your consistency based on"
      },
      {
        "start": 7222.58,
        "duration": 6.46,
        "text": "based on your needs so it you may"
      },
      {
        "start": 7226.28,
        "duration": 4.62,
        "text": "um right with one consistency and read"
      },
      {
        "start": 7229.04,
        "duration": 3.0,
        "text": "with different consistency which is"
      },
      {
        "start": 7230.9,
        "duration": 3.48,
        "text": "pretty common"
      },
      {
        "start": 7232.04,
        "duration": 3.599,
        "text": "okay so here is an example consistency"
      },
      {
        "start": 7234.38,
        "duration": 3.66,
        "text": "level"
      },
      {
        "start": 7235.639,
        "duration": 4.621,
        "text": "consistency level used in Java"
      },
      {
        "start": 7238.04,
        "duration": 5.72,
        "text": "application this is how it's set for"
      },
      {
        "start": 7240.26,
        "duration": 8.58,
        "text": "statement and this is how it's used in"
      },
      {
        "start": 7243.76,
        "duration": 7.479,
        "text": "SQL sh SQL shell where you can read what"
      },
      {
        "start": 7248.84,
        "duration": 4.98,
        "text": "what is current consistency level by"
      },
      {
        "start": 7251.239,
        "duration": 3.781,
        "text": "executing consistency command or"
      },
      {
        "start": 7253.82,
        "duration": 5.16,
        "text": "statement"
      },
      {
        "start": 7255.02,
        "duration": 6.179,
        "text": "or you can change sorry you can change"
      },
      {
        "start": 7258.98,
        "duration": 4.5,
        "text": "the consistency by saying consistency"
      },
      {
        "start": 7261.199,
        "duration": 5.04,
        "text": "and then specify level in this case it's"
      },
      {
        "start": 7263.48,
        "duration": 3.719,
        "text": "consistency level all"
      },
      {
        "start": 7266.239,
        "duration": 3.36,
        "text": "um so"
      },
      {
        "start": 7267.199,
        "duration": 4.381,
        "text": "what it means what consistency level"
      },
      {
        "start": 7269.599,
        "duration": 5.58,
        "text": "means is uh"
      },
      {
        "start": 7271.58,
        "duration": 6.539,
        "text": "how many replicas how many replicas will"
      },
      {
        "start": 7275.179,
        "duration": 6.42,
        "text": "have to acknowledge that the operation"
      },
      {
        "start": 7278.119,
        "duration": 6.421,
        "text": "or request was executed"
      },
      {
        "start": 7281.599,
        "duration": 5.04,
        "text": "uh for the for the client"
      },
      {
        "start": 7284.54,
        "duration": 6.059,
        "text": "um uh"
      },
      {
        "start": 7286.639,
        "duration": 6.54,
        "text": "to get the successful response right so"
      },
      {
        "start": 7290.599,
        "duration": 4.801,
        "text": "we will talk about consistency levels"
      },
      {
        "start": 7293.179,
        "duration": 5.161,
        "text": "um based on some examples for so here is"
      },
      {
        "start": 7295.4,
        "duration": 5.1,
        "text": "an example of we are writing with"
      },
      {
        "start": 7298.34,
        "duration": 5.279,
        "text": "consistency level one"
      },
      {
        "start": 7300.5,
        "duration": 5.82,
        "text": "okay and replication factor is V so"
      },
      {
        "start": 7303.619,
        "duration": 3.841,
        "text": "client sends the request to write"
      },
      {
        "start": 7306.32,
        "duration": 3.839,
        "text": "something"
      },
      {
        "start": 7307.46,
        "duration": 5.04,
        "text": "and that requires is always transferred"
      },
      {
        "start": 7310.159,
        "duration": 4.921,
        "text": "to all replicas in this case three"
      },
      {
        "start": 7312.5,
        "duration": 5.159,
        "text": "replicas but we only science consists"
      },
      {
        "start": 7315.08,
        "duration": 4.68,
        "text": "level is one we only need acknowledgment"
      },
      {
        "start": 7317.659,
        "duration": 5.401,
        "text": "from one replica"
      },
      {
        "start": 7319.76,
        "duration": 5.64,
        "text": "that request was successful"
      },
      {
        "start": 7323.06,
        "duration": 5.82,
        "text": "so out of three replicas the first one"
      },
      {
        "start": 7325.4,
        "duration": 5.94,
        "text": "that says I'm done the coordinator will"
      },
      {
        "start": 7328.88,
        "duration": 5.88,
        "text": "re respond to client the operation"
      },
      {
        "start": 7331.34,
        "duration": 6.299,
        "text": "request was successful it succeeded the"
      },
      {
        "start": 7334.76,
        "duration": 5.1,
        "text": "right succeeded Okay so"
      },
      {
        "start": 7337.639,
        "duration": 4.98,
        "text": "no matter what happens with the other"
      },
      {
        "start": 7339.86,
        "duration": 4.56,
        "text": "two maybe they will fail but most likely"
      },
      {
        "start": 7342.619,
        "duration": 3.421,
        "text": "in normal operations all of them will"
      },
      {
        "start": 7344.42,
        "duration": 3.179,
        "text": "succeed but we are waiting for the"
      },
      {
        "start": 7346.04,
        "duration": 5.4,
        "text": "fastest one to respond"
      },
      {
        "start": 7347.599,
        "duration": 5.881,
        "text": "if you need stronger guarantee then you"
      },
      {
        "start": 7351.44,
        "duration": 4.56,
        "text": "may use something like Quorum majority"
      },
      {
        "start": 7353.48,
        "duration": 5.52,
        "text": "of the replicas so in case of three"
      },
      {
        "start": 7356.0,
        "duration": 5.88,
        "text": "replicas the majority will be two"
      },
      {
        "start": 7359.0,
        "duration": 6.06,
        "text": "and we will wait the the coordinator is"
      },
      {
        "start": 7361.88,
        "duration": 6.359,
        "text": "going to wait for two replicas to"
      },
      {
        "start": 7365.06,
        "duration": 5.46,
        "text": "confirm that they wrote the data for"
      },
      {
        "start": 7368.239,
        "duration": 5.4,
        "text": "telling the client that operation"
      },
      {
        "start": 7370.52,
        "duration": 4.98,
        "text": "succeeded okay this is Quorum consistent"
      },
      {
        "start": 7373.639,
        "duration": 4.02,
        "text": "as well so and you can change it for"
      },
      {
        "start": 7375.5,
        "duration": 5.699,
        "text": "each ride something that is maybe less"
      },
      {
        "start": 7377.659,
        "duration": 5.701,
        "text": "important consistency level one or there"
      },
      {
        "start": 7381.199,
        "duration": 3.181,
        "text": "are others like local one something more"
      },
      {
        "start": 7383.36,
        "duration": 3.66,
        "text": "important"
      },
      {
        "start": 7384.38,
        "duration": 6.0,
        "text": "uh maybe quorum"
      },
      {
        "start": 7387.02,
        "duration": 6.24,
        "text": "and consistency level all will require"
      },
      {
        "start": 7390.38,
        "duration": 6.6,
        "text": "all replicas to confirm that they read"
      },
      {
        "start": 7393.26,
        "duration": 7.08,
        "text": "in the data and consistency level all is"
      },
      {
        "start": 7396.98,
        "duration": 6.42,
        "text": "a bad one so we don't don't ever want to"
      },
      {
        "start": 7400.34,
        "duration": 5.04,
        "text": "use it why because"
      },
      {
        "start": 7403.4,
        "duration": 5.46,
        "text": "if you're gonna wait for all replicas"
      },
      {
        "start": 7405.38,
        "duration": 5.58,
        "text": "essentially we are going to enforce"
      },
      {
        "start": 7408.86,
        "duration": 4.859,
        "text": "consistent right"
      },
      {
        "start": 7410.96,
        "duration": 6.0,
        "text": "but we are going to um"
      },
      {
        "start": 7413.719,
        "duration": 5.281,
        "text": "uh make our system unavailable we are"
      },
      {
        "start": 7416.96,
        "duration": 4.38,
        "text": "going to lose sacrifice availability"
      },
      {
        "start": 7419.0,
        "duration": 3.06,
        "text": "because if one of those replicas goes"
      },
      {
        "start": 7421.34,
        "duration": 2.879,
        "text": "down"
      },
      {
        "start": 7422.06,
        "duration": 4.02,
        "text": "we will not be able to perform"
      },
      {
        "start": 7424.219,
        "duration": 4.5,
        "text": "completely right because there are only"
      },
      {
        "start": 7426.08,
        "duration": 7.079,
        "text": "three replicas if one of them is done"
      },
      {
        "start": 7428.719,
        "duration": 6.241,
        "text": "down then consistency level all cannot"
      },
      {
        "start": 7433.159,
        "duration": 4.681,
        "text": "be satisfied"
      },
      {
        "start": 7434.96,
        "duration": 6.12,
        "text": "Quorum can be satisfied right because"
      },
      {
        "start": 7437.84,
        "duration": 5.7,
        "text": "two out of three is still available one"
      },
      {
        "start": 7441.08,
        "duration": 6.059,
        "text": "can be satisfied one out of three still"
      },
      {
        "start": 7443.54,
        "duration": 5.699,
        "text": "available but just one failure in your"
      },
      {
        "start": 7447.139,
        "duration": 4.5,
        "text": "system is not available so that's not a"
      },
      {
        "start": 7449.239,
        "duration": 5.301,
        "text": "good situation essentially this is"
      },
      {
        "start": 7451.639,
        "duration": 6.841,
        "text": "example of when we sacrifice in"
      },
      {
        "start": 7454.54,
        "duration": 6.639,
        "text": "availability and and using Cassandra as"
      },
      {
        "start": 7458.48,
        "duration": 5.639,
        "text": "CP system which is not recommended don't"
      },
      {
        "start": 7461.179,
        "duration": 4.44,
        "text": "don't use consistency level"
      },
      {
        "start": 7464.119,
        "duration": 3.901,
        "text": "okay"
      },
      {
        "start": 7465.619,
        "duration": 5.701,
        "text": "uh but then you may ask well I don't"
      },
      {
        "start": 7468.02,
        "duration": 6.36,
        "text": "want to ever read stale data I want to"
      },
      {
        "start": 7471.32,
        "duration": 4.44,
        "text": "have consistency it it doesn't matter I"
      },
      {
        "start": 7474.38,
        "duration": 4.279,
        "text": "want availability I want some"
      },
      {
        "start": 7475.76,
        "duration": 6.32,
        "text": "consistency and we can do that as well"
      },
      {
        "start": 7478.659,
        "duration": 6.221,
        "text": "we can still sacrifice some availability"
      },
      {
        "start": 7482.08,
        "duration": 4.84,
        "text": "but make sure we have a better"
      },
      {
        "start": 7484.88,
        "duration": 5.339,
        "text": "consistency and that better consistency"
      },
      {
        "start": 7486.92,
        "duration": 6.12,
        "text": "essentially is called the uh immediate"
      },
      {
        "start": 7490.219,
        "duration": 5.4,
        "text": "consistency or strong consistency so"
      },
      {
        "start": 7493.04,
        "duration": 3.3,
        "text": "let's see let's see how it works"
      },
      {
        "start": 7495.619,
        "duration": 3.661,
        "text": "um"
      },
      {
        "start": 7496.34,
        "duration": 4.68,
        "text": "essentially the the formula for so you"
      },
      {
        "start": 7499.28,
        "duration": 3.6,
        "text": "need to if you want to make sure that"
      },
      {
        "start": 7501.02,
        "duration": 4.26,
        "text": "you write something and then you"
      },
      {
        "start": 7502.88,
        "duration": 5.339,
        "text": "immediately read and you use you read"
      },
      {
        "start": 7505.28,
        "duration": 4.62,
        "text": "most recent data no stale data then you"
      },
      {
        "start": 7508.219,
        "duration": 5.161,
        "text": "need to make sure that your consistency"
      },
      {
        "start": 7509.9,
        "duration": 6.06,
        "text": "level for rights plus consistency level"
      },
      {
        "start": 7513.38,
        "duration": 3.779,
        "text": "for each is greater than replication"
      },
      {
        "start": 7515.96,
        "duration": 3.48,
        "text": "Factor"
      },
      {
        "start": 7517.159,
        "duration": 4.621,
        "text": "so the in this example this is the case"
      },
      {
        "start": 7519.44,
        "duration": 4.98,
        "text": "so replication factor is three and"
      },
      {
        "start": 7521.78,
        "duration": 5.22,
        "text": "consistency level Quorum majority of"
      },
      {
        "start": 7524.42,
        "duration": 5.1,
        "text": "three is two so we're leading with two"
      },
      {
        "start": 7527.0,
        "duration": 4.139,
        "text": "we're writing we're writing these two"
      },
      {
        "start": 7529.52,
        "duration": 4.079,
        "text": "and we're leaving with Quorum which is"
      },
      {
        "start": 7531.139,
        "duration": 5.46,
        "text": "two as well so two plus two is four is"
      },
      {
        "start": 7533.599,
        "duration": 5.941,
        "text": "greater than three right so we are gonna"
      },
      {
        "start": 7536.599,
        "duration": 6.301,
        "text": "get immediate or strong consistency in"
      },
      {
        "start": 7539.54,
        "duration": 6.0,
        "text": "this case so this client writes the data"
      },
      {
        "start": 7542.9,
        "duration": 5.58,
        "text": "it writes into three replicas"
      },
      {
        "start": 7545.54,
        "duration": 5.22,
        "text": "and waits for two confirmations so these"
      },
      {
        "start": 7548.48,
        "duration": 6.239,
        "text": "two confirm this one may be slow it"
      },
      {
        "start": 7550.76,
        "duration": 5.64,
        "text": "maybe it's gonna take uh 10 milliseconds"
      },
      {
        "start": 7554.719,
        "duration": 4.081,
        "text": "and these two did it in three"
      },
      {
        "start": 7556.4,
        "duration": 5.04,
        "text": "milliseconds immediately we have a"
      },
      {
        "start": 7558.8,
        "duration": 4.68,
        "text": "client that is reading the same data and"
      },
      {
        "start": 7561.44,
        "duration": 5.82,
        "text": "doing it for us so less than 10"
      },
      {
        "start": 7563.48,
        "duration": 6.119,
        "text": "milliseconds passed and it's in in case"
      },
      {
        "start": 7567.26,
        "duration": 5.04,
        "text": "of reading because we didn't we score"
      },
      {
        "start": 7569.599,
        "duration": 4.441,
        "text": "them we don't have to contact all the"
      },
      {
        "start": 7572.3,
        "duration": 3.54,
        "text": "replicas we are going to contact only"
      },
      {
        "start": 7574.04,
        "duration": 2.88,
        "text": "two"
      },
      {
        "start": 7575.84,
        "duration": 3.68,
        "text": "um so"
      },
      {
        "start": 7576.92,
        "duration": 5.58,
        "text": "let's say we contacting these two"
      },
      {
        "start": 7579.52,
        "duration": 5.079,
        "text": "this one actually has the most"
      },
      {
        "start": 7582.5,
        "duration": 4.92,
        "text": "up-to-date data and this one still has"
      },
      {
        "start": 7584.599,
        "duration": 4.801,
        "text": "stale data because it the right didn't"
      },
      {
        "start": 7587.42,
        "duration": 4.14,
        "text": "complete so what happens"
      },
      {
        "start": 7589.4,
        "duration": 5.4,
        "text": "we get both of them"
      },
      {
        "start": 7591.56,
        "duration": 5.579,
        "text": "on the coordinator node uh the request"
      },
      {
        "start": 7594.8,
        "duration": 5.22,
        "text": "coordinator nodes and based on the"
      },
      {
        "start": 7597.139,
        "duration": 5.701,
        "text": "timestamp every every piece of data in"
      },
      {
        "start": 7600.02,
        "duration": 4.139,
        "text": "Cassandra has a timestamp that is there"
      },
      {
        "start": 7602.84,
        "duration": 3.839,
        "text": "automatically"
      },
      {
        "start": 7604.159,
        "duration": 5.46,
        "text": "So based on the timestamp the the most"
      },
      {
        "start": 7606.679,
        "duration": 6.96,
        "text": "recent data is going to be identified"
      },
      {
        "start": 7609.619,
        "duration": 6.721,
        "text": "and returned to the client and besides"
      },
      {
        "start": 7613.639,
        "duration": 4.621,
        "text": "that even there is a chance that the"
      },
      {
        "start": 7616.34,
        "duration": 4.74,
        "text": "coordinator will send the most recent"
      },
      {
        "start": 7618.26,
        "duration": 6.419,
        "text": "data to this node to make sure it's"
      },
      {
        "start": 7621.08,
        "duration": 7.139,
        "text": "gonna have it next time it talks to it"
      },
      {
        "start": 7624.679,
        "duration": 6.48,
        "text": "so this is essentially allows you to"
      },
      {
        "start": 7628.219,
        "duration": 5.821,
        "text": "always be consistent and allows you for"
      },
      {
        "start": 7631.159,
        "duration": 6.06,
        "text": "availability if one node fails"
      },
      {
        "start": 7634.04,
        "duration": 5.34,
        "text": "in in with replication factor of C your"
      },
      {
        "start": 7637.219,
        "duration": 4.081,
        "text": "system still functions"
      },
      {
        "start": 7639.38,
        "duration": 4.819,
        "text": "um you will basically not notice your"
      },
      {
        "start": 7641.3,
        "duration": 5.04,
        "text": "application will continue to"
      },
      {
        "start": 7644.199,
        "duration": 4.301,
        "text": "serve the requests"
      },
      {
        "start": 7646.34,
        "duration": 4.5,
        "text": "now there are many consistency levels"
      },
      {
        "start": 7648.5,
        "duration": 5.639,
        "text": "this is not the complete list"
      },
      {
        "start": 7650.84,
        "duration": 6.299,
        "text": "so the edge cases any and all it's"
      },
      {
        "start": 7654.139,
        "duration": 6.361,
        "text": "something you should not use so any is"
      },
      {
        "start": 7657.139,
        "duration": 6.241,
        "text": "only used for rights and it's when no"
      },
      {
        "start": 7660.5,
        "duration": 5.099,
        "text": "replicas available available so the the"
      },
      {
        "start": 7663.38,
        "duration": 4.68,
        "text": "coordinator note is going to store the"
      },
      {
        "start": 7665.599,
        "duration": 4.741,
        "text": "data as a hint so this is something that"
      },
      {
        "start": 7668.06,
        "duration": 5.099,
        "text": "you you don't want to use and all you"
      },
      {
        "start": 7670.34,
        "duration": 5.819,
        "text": "know well it very depends on the use"
      },
      {
        "start": 7673.159,
        "duration": 4.921,
        "text": "case I mean like in general case yes you"
      },
      {
        "start": 7676.159,
        "duration": 4.741,
        "text": "don't want to use any you don't want to"
      },
      {
        "start": 7678.08,
        "duration": 5.88,
        "text": "use all but don't forget what"
      },
      {
        "start": 7680.9,
        "duration": 5.94,
        "text": "consistency level is configurable per"
      },
      {
        "start": 7683.96,
        "duration": 5.159,
        "text": "query and it also may depend on the what"
      },
      {
        "start": 7686.84,
        "duration": 5.339,
        "text": "kind of a data you are storing there are"
      },
      {
        "start": 7689.119,
        "duration": 6.421,
        "text": "plenty of scenarios uh when you when any"
      },
      {
        "start": 7692.179,
        "duration": 5.94,
        "text": "will be fine for you but it's not as a"
      },
      {
        "start": 7695.54,
        "duration": 4.619,
        "text": "general rule not as a rule of thumb only"
      },
      {
        "start": 7698.119,
        "duration": 5.361,
        "text": "when you work with the data you can"
      },
      {
        "start": 7700.159,
        "duration": 6.601,
        "text": "afford to lose but you have really"
      },
      {
        "start": 7703.48,
        "duration": 7.06,
        "text": "intensive right uh performance for"
      },
      {
        "start": 7706.76,
        "duration": 8.16,
        "text": "example for locks for the data which is"
      },
      {
        "start": 7710.54,
        "duration": 6.9,
        "text": "being outdated within a few seconds for"
      },
      {
        "start": 7714.92,
        "duration": 5.699,
        "text": "so there are some scenarios when Annie"
      },
      {
        "start": 7717.44,
        "duration": 6.6,
        "text": "is a good thing I don't want uh like to"
      },
      {
        "start": 7720.619,
        "duration": 5.881,
        "text": "say never use any but definitely as a"
      },
      {
        "start": 7724.04,
        "duration": 4.32,
        "text": "rule of a thumb we don't use it and you"
      },
      {
        "start": 7726.5,
        "duration": 3.719,
        "text": "have to be very careful it may"
      },
      {
        "start": 7728.36,
        "duration": 4.44,
        "text": "potentially lead to the inconsistency"
      },
      {
        "start": 7730.219,
        "duration": 4.561,
        "text": "the story is various of scenarios you"
      },
      {
        "start": 7732.8,
        "duration": 4.799,
        "text": "can afford some consistency"
      },
      {
        "start": 7734.78,
        "duration": 6.3,
        "text": "well they yeah I've never heard anyone"
      },
      {
        "start": 7737.599,
        "duration": 5.821,
        "text": "using any in production and you that the"
      },
      {
        "start": 7741.08,
        "duration": 5.28,
        "text": "cluster will be in a very bad condition"
      },
      {
        "start": 7743.42,
        "duration": 7.799,
        "text": "if you have to use any essential biggest"
      },
      {
        "start": 7746.36,
        "duration": 6.6,
        "text": "all replicas are down and they it's uh"
      },
      {
        "start": 7751.219,
        "duration": 4.5,
        "text": "the data is not going to be stored"
      },
      {
        "start": 7752.96,
        "duration": 4.32,
        "text": "properly it's going to be stored on on"
      },
      {
        "start": 7755.719,
        "duration": 3.661,
        "text": "the other node but it's not going to be"
      },
      {
        "start": 7757.28,
        "duration": 5.339,
        "text": "in proper data structures and all that"
      },
      {
        "start": 7759.38,
        "duration": 4.02,
        "text": "anyway the the most important ones will"
      },
      {
        "start": 7762.619,
        "duration": 3.181,
        "text": "be"
      },
      {
        "start": 7763.4,
        "duration": 5.819,
        "text": "one local one"
      },
      {
        "start": 7765.8,
        "duration": 5.819,
        "text": "some two three is okay but uh most of"
      },
      {
        "start": 7769.219,
        "duration": 4.02,
        "text": "the most important ones will be one"
      },
      {
        "start": 7771.619,
        "duration": 3.721,
        "text": "local one"
      },
      {
        "start": 7773.239,
        "duration": 4.321,
        "text": "um Quorum local Quorum each Quorum so"
      },
      {
        "start": 7775.34,
        "duration": 4.98,
        "text": "what one means if you have these three"
      },
      {
        "start": 7777.56,
        "duration": 5.579,
        "text": "three data centers but one cluster they"
      },
      {
        "start": 7780.32,
        "duration": 7.08,
        "text": "all in one cluster so one means that any"
      },
      {
        "start": 7783.139,
        "duration": 7.741,
        "text": "no any any replica in this whole cluster"
      },
      {
        "start": 7787.4,
        "duration": 5.4,
        "text": "can respond can acknowledge okay your"
      },
      {
        "start": 7790.88,
        "duration": 4.859,
        "text": "write or read"
      },
      {
        "start": 7792.8,
        "duration": 5.28,
        "text": "um local one means that if you your"
      },
      {
        "start": 7795.739,
        "duration": 3.801,
        "text": "client connects to this left Data Center"
      },
      {
        "start": 7798.08,
        "duration": 4.5,
        "text": "leftmost"
      },
      {
        "start": 7799.54,
        "duration": 5.44,
        "text": "then the replica in this data center"
      },
      {
        "start": 7802.58,
        "duration": 4.86,
        "text": "must respond and that brings us the the"
      },
      {
        "start": 7804.98,
        "duration": 5.699,
        "text": "the question we had earlier will"
      },
      {
        "start": 7807.44,
        "duration": 5.279,
        "text": "multiple data centers affect latency so"
      },
      {
        "start": 7810.679,
        "duration": 3.96,
        "text": "if you're using local one it will not"
      },
      {
        "start": 7812.719,
        "duration": 4.321,
        "text": "because you're only going to get"
      },
      {
        "start": 7814.639,
        "duration": 4.621,
        "text": "response from replica in the same data"
      },
      {
        "start": 7817.04,
        "duration": 4.44,
        "text": "center that you connect it to so you"
      },
      {
        "start": 7819.26,
        "duration": 4.32,
        "text": "don't need to you if you connect it to"
      },
      {
        "start": 7821.48,
        "duration": 5.179,
        "text": "one in New York you don't need to to get"
      },
      {
        "start": 7823.58,
        "duration": 7.5,
        "text": "the response from Tokyo data center okay"
      },
      {
        "start": 7826.659,
        "duration": 6.58,
        "text": "uh the two three two nodes or three two"
      },
      {
        "start": 7831.08,
        "duration": 3.96,
        "text": "replicas or three replicas in the whole"
      },
      {
        "start": 7833.239,
        "duration": 5.581,
        "text": "cluster so that's not super useful"
      },
      {
        "start": 7835.04,
        "duration": 6.0,
        "text": "actually uh Quorum means majority of the"
      },
      {
        "start": 7838.82,
        "duration": 4.62,
        "text": "replicas in the whole cluster so we have"
      },
      {
        "start": 7841.04,
        "duration": 5.52,
        "text": "three replicas in each one so we have"
      },
      {
        "start": 7843.44,
        "duration": 5.94,
        "text": "nine replicas in the cluster we need to"
      },
      {
        "start": 7846.56,
        "duration": 6.659,
        "text": "get response from five of them"
      },
      {
        "start": 7849.38,
        "duration": 5.58,
        "text": "okay so again if you're using multi data"
      },
      {
        "start": 7853.219,
        "duration": 6.061,
        "text": "center environment then you probably"
      },
      {
        "start": 7854.96,
        "duration": 7.44,
        "text": "like to use a local Quorum because it's"
      },
      {
        "start": 7859.28,
        "duration": 6.839,
        "text": "gonna be Quorum of the replicas in local"
      },
      {
        "start": 7862.4,
        "duration": 6.239,
        "text": "data center if I'm connected to leftmost"
      },
      {
        "start": 7866.119,
        "duration": 4.201,
        "text": "I'm gonna and there are three replicas"
      },
      {
        "start": 7868.639,
        "duration": 4.201,
        "text": "local Quorum means I want to get"
      },
      {
        "start": 7870.32,
        "duration": 6.299,
        "text": "response from two I don't need a game to"
      },
      {
        "start": 7872.84,
        "duration": 7.62,
        "text": "go to Tokyo or go to um"
      },
      {
        "start": 7876.619,
        "duration": 6.361,
        "text": "New Zealand to get the uh my answers"
      },
      {
        "start": 7880.46,
        "duration": 6.42,
        "text": "right because I'm in California I want"
      },
      {
        "start": 7882.98,
        "duration": 5.759,
        "text": "the data to that is stored here locally"
      },
      {
        "start": 7886.88,
        "duration": 5.04,
        "text": "it's going to be more efficient and each"
      },
      {
        "start": 7888.739,
        "duration": 5.641,
        "text": "Quorum is a quorum in each data center"
      },
      {
        "start": 7891.92,
        "duration": 4.739,
        "text": "so if we have replication Factory in all"
      },
      {
        "start": 7894.38,
        "duration": 5.58,
        "text": "three of them we need to get a response"
      },
      {
        "start": 7896.659,
        "duration": 6.241,
        "text": "from two two and two so totally six"
      },
      {
        "start": 7899.96,
        "duration": 4.62,
        "text": "notes six note notes need to be respond"
      },
      {
        "start": 7902.9,
        "duration": 3.96,
        "text": "uh need to respond"
      },
      {
        "start": 7904.58,
        "duration": 4.38,
        "text": "pretty geographically distributed nodes"
      },
      {
        "start": 7906.86,
        "duration": 4.739,
        "text": "it's not going to be fast"
      },
      {
        "start": 7908.96,
        "duration": 4.8,
        "text": "it's not going to be it's fast yes it's"
      },
      {
        "start": 7911.599,
        "duration": 4.14,
        "text": "it's gonna it's it's the most expensive"
      },
      {
        "start": 7913.76,
        "duration": 4.26,
        "text": "out of uh"
      },
      {
        "start": 7915.739,
        "duration": 4.681,
        "text": "all of this except of all of course so"
      },
      {
        "start": 7918.02,
        "duration": 3.84,
        "text": "all is gonna require nine replica"
      },
      {
        "start": 7920.42,
        "duration": 4.56,
        "text": "respond"
      },
      {
        "start": 7921.86,
        "duration": 5.94,
        "text": "so you get the idea each request write"
      },
      {
        "start": 7924.98,
        "duration": 7.08,
        "text": "or read will have to use some"
      },
      {
        "start": 7927.8,
        "duration": 6.06,
        "text": "consistency level and and you may easily"
      },
      {
        "start": 7932.06,
        "duration": 5.28,
        "text": "write so when you for example if you"
      },
      {
        "start": 7933.86,
        "duration": 5.22,
        "text": "write with local one the data will get"
      },
      {
        "start": 7937.34,
        "duration": 3.18,
        "text": "you'll get information the the"
      },
      {
        "start": 7939.08,
        "duration": 4.68,
        "text": "application will get confirmation from"
      },
      {
        "start": 7940.52,
        "duration": 4.74,
        "text": "only one right the one replica it"
      },
      {
        "start": 7943.76,
        "duration": 3.12,
        "text": "doesn't mean that the others are not"
      },
      {
        "start": 7945.26,
        "duration": 4.8,
        "text": "writing they are writing at that time"
      },
      {
        "start": 7946.88,
        "duration": 5.58,
        "text": "and one of them becomes the coordinator"
      },
      {
        "start": 7950.06,
        "duration": 5.42,
        "text": "for replication with another Data Center"
      },
      {
        "start": 7952.46,
        "duration": 5.82,
        "text": "and and they these two coordinators"
      },
      {
        "start": 7955.48,
        "duration": 5.139,
        "text": "communicate and write into these"
      },
      {
        "start": 7958.28,
        "duration": 4.08,
        "text": "replicas all of this happens for you but"
      },
      {
        "start": 7960.619,
        "duration": 4.381,
        "text": "you are not waiting for this process to"
      },
      {
        "start": 7962.36,
        "duration": 5.64,
        "text": "complete you just wait wait in one local"
      },
      {
        "start": 7965.0,
        "duration": 5.639,
        "text": "node acknowledgment so that's gonna be"
      },
      {
        "start": 7968.0,
        "duration": 4.26,
        "text": "very fast then you may decide reads are"
      },
      {
        "start": 7970.639,
        "duration": 3.741,
        "text": "more important I'm gonna read with local"
      },
      {
        "start": 7972.26,
        "duration": 8.339,
        "text": "forum or something like that"
      },
      {
        "start": 7974.38,
        "duration": 8.5,
        "text": "okay and with this set we can proceed"
      },
      {
        "start": 7980.599,
        "duration": 3.721,
        "text": "to the second lab"
      },
      {
        "start": 7982.88,
        "duration": 4.319,
        "text": "okay"
      },
      {
        "start": 7984.32,
        "duration": 4.68,
        "text": "so again I'm going back to our GitHub"
      },
      {
        "start": 7987.199,
        "duration": 3.42,
        "text": "repo"
      },
      {
        "start": 7989.0,
        "duration": 4.079,
        "text": "and"
      },
      {
        "start": 7990.619,
        "duration": 6.0,
        "text": "we are going to create tables those"
      },
      {
        "start": 7993.079,
        "duration": 7.62,
        "text": "tables will look very much like"
      },
      {
        "start": 7996.619,
        "duration": 7.08,
        "text": "um cql tables very much like SQL tables"
      },
      {
        "start": 8000.699,
        "duration": 5.341,
        "text": "right and even so the Ezekiel Cassandra"
      },
      {
        "start": 8003.699,
        "duration": 4.44,
        "text": "query language the Central Language so"
      },
      {
        "start": 8006.04,
        "duration": 5.579,
        "text": "let's take a look what we need to do we"
      },
      {
        "start": 8008.139,
        "duration": 5.821,
        "text": "can describe key spaces this command so"
      },
      {
        "start": 8011.619,
        "duration": 4.56,
        "text": "we will basically see what can spaces"
      },
      {
        "start": 8013.96,
        "duration": 4.619,
        "text": "will have in our system I will do that"
      },
      {
        "start": 8016.179,
        "duration": 5.821,
        "text": "for you you will you will take take a"
      },
      {
        "start": 8018.579,
        "duration": 6.66,
        "text": "look at that we will then choose to use"
      },
      {
        "start": 8022.0,
        "duration": 6.599,
        "text": "sensor data as a key space"
      },
      {
        "start": 8025.239,
        "duration": 6.241,
        "text": "and then we will create three tables"
      },
      {
        "start": 8028.599,
        "duration": 5.701,
        "text": "one is Network stable"
      },
      {
        "start": 8031.48,
        "duration": 4.98,
        "text": "which is a table with name"
      },
      {
        "start": 8034.3,
        "duration": 4.2,
        "text": "so it stores sensor and network"
      },
      {
        "start": 8036.46,
        "duration": 4.8,
        "text": "information about set sensor Network's"
      },
      {
        "start": 8038.5,
        "duration": 5.4,
        "text": "name description and region so name will"
      },
      {
        "start": 8041.26,
        "duration": 6.0,
        "text": "be partition key"
      },
      {
        "start": 8043.9,
        "duration": 6.12,
        "text": "and we can later check that we we did"
      },
      {
        "start": 8047.26,
        "duration": 7.02,
        "text": "create this table and then we create two"
      },
      {
        "start": 8050.02,
        "duration": 5.82,
        "text": "more two more tables one is sensors by"
      },
      {
        "start": 8054.28,
        "duration": 3.54,
        "text": "Network and the other one is"
      },
      {
        "start": 8055.84,
        "duration": 4.56,
        "text": "temperatures by Network bad so this is"
      },
      {
        "start": 8057.82,
        "duration": 8.16,
        "text": "going to be a bad table"
      },
      {
        "start": 8060.4,
        "duration": 6.44,
        "text": "um and the reason it's bad is because"
      },
      {
        "start": 8065.98,
        "duration": 2.82,
        "text": "um"
      },
      {
        "start": 8066.84,
        "duration": 3.879,
        "text": "partitions that's something that Alex"
      },
      {
        "start": 8068.8,
        "duration": 4.14,
        "text": "will talk in the next section but"
      },
      {
        "start": 8070.719,
        "duration": 4.92,
        "text": "essentially the"
      },
      {
        "start": 8072.94,
        "duration": 5.4,
        "text": "um the the partition key is sensor and"
      },
      {
        "start": 8075.639,
        "duration": 4.98,
        "text": "and all the temperatures measured by"
      },
      {
        "start": 8078.34,
        "duration": 5.46,
        "text": "that sensor will be stored in that"
      },
      {
        "start": 8080.619,
        "duration": 6.6,
        "text": "partition but you can think that"
      },
      {
        "start": 8083.8,
        "duration": 5.04,
        "text": "if we that sensor is working for many"
      },
      {
        "start": 8087.219,
        "duration": 4.801,
        "text": "years it's going to collect data for"
      },
      {
        "start": 8088.84,
        "duration": 5.52,
        "text": "many years and collect data regularly"
      },
      {
        "start": 8092.02,
        "duration": 5.34,
        "text": "every second every five seconds every"
      },
      {
        "start": 8094.36,
        "duration": 5.819,
        "text": "minute and so on then that partition"
      },
      {
        "start": 8097.36,
        "duration": 4.68,
        "text": "will grow it's gonna have many many rows"
      },
      {
        "start": 8100.179,
        "duration": 3.781,
        "text": "over time and we don't want that to"
      },
      {
        "start": 8102.04,
        "duration": 5.34,
        "text": "happen we want to put a limit on the"
      },
      {
        "start": 8103.96,
        "duration": 4.8,
        "text": "size and therefore later we will drop"
      },
      {
        "start": 8107.38,
        "duration": 4.319,
        "text": "this table"
      },
      {
        "start": 8108.76,
        "duration": 6.419,
        "text": "drop table and create table temperatures"
      },
      {
        "start": 8111.699,
        "duration": 6.241,
        "text": "by sensors where we will add date"
      },
      {
        "start": 8115.179,
        "duration": 6.0,
        "text": "as part of the partition key in this"
      },
      {
        "start": 8117.94,
        "duration": 6.84,
        "text": "case we collecting the measurements of"
      },
      {
        "start": 8121.179,
        "duration": 5.821,
        "text": "each sensor on a specific date okay on a"
      },
      {
        "start": 8124.78,
        "duration": 4.68,
        "text": "specific date so this allows us to limit"
      },
      {
        "start": 8127.0,
        "duration": 3.78,
        "text": "the size whatever data is collected on"
      },
      {
        "start": 8129.46,
        "duration": 3.96,
        "text": "that date"
      },
      {
        "start": 8130.78,
        "duration": 5.04,
        "text": "the partition stops right then the next"
      },
      {
        "start": 8133.42,
        "duration": 5.759,
        "text": "partition is created tomorrow"
      },
      {
        "start": 8135.82,
        "duration": 5.58,
        "text": "and so on and so on so only three tables"
      },
      {
        "start": 8139.179,
        "duration": 5.101,
        "text": "at the end Let's uh"
      },
      {
        "start": 8141.4,
        "duration": 5.12,
        "text": "see what we can do let me copy the first"
      },
      {
        "start": 8144.28,
        "duration": 2.24,
        "text": "table"
      },
      {
        "start": 8146.8,
        "duration": 2.359,
        "text": "okay"
      },
      {
        "start": 8160.659,
        "duration": 4.52,
        "text": "okay and I was logged out"
      },
      {
        "start": 8167.199,
        "duration": 5.221,
        "text": "I will log in again"
      },
      {
        "start": 8169.42,
        "duration": 5.819,
        "text": "go to databases"
      },
      {
        "start": 8172.42,
        "duration": 5.699,
        "text": "okay I have my workshop database I will"
      },
      {
        "start": 8175.239,
        "duration": 4.801,
        "text": "click on it you have the same workshops"
      },
      {
        "start": 8178.119,
        "duration": 5.161,
        "text": "database"
      },
      {
        "start": 8180.04,
        "duration": 4.559,
        "text": "and we will use built-in client to"
      },
      {
        "start": 8183.28,
        "duration": 3.66,
        "text": "interact"
      },
      {
        "start": 8184.599,
        "duration": 5.401,
        "text": "okay so essentially it's the client"
      },
      {
        "start": 8186.94,
        "duration": 5.82,
        "text": "someone reading for us"
      },
      {
        "start": 8190.0,
        "duration": 5.82,
        "text": "in Python and we are going to use it to"
      },
      {
        "start": 8192.76,
        "duration": 5.719,
        "text": "interact with our database so first uh"
      },
      {
        "start": 8195.82,
        "duration": 2.659,
        "text": "describe"
      },
      {
        "start": 8198.54,
        "duration": 3.54,
        "text": "key spaces"
      },
      {
        "start": 8204.16,
        "duration": 3.899,
        "text": "okay"
      },
      {
        "start": 8205.42,
        "duration": 6.12,
        "text": "so the key space that we are interested"
      },
      {
        "start": 8208.059,
        "duration": 8.361,
        "text": "in is this sensor data other key spaces"
      },
      {
        "start": 8211.54,
        "duration": 9.42,
        "text": "here are key spaces that are related to"
      },
      {
        "start": 8216.42,
        "duration": 6.099,
        "text": "the database metadata functioning uh and"
      },
      {
        "start": 8220.96,
        "duration": 4.38,
        "text": "so on and so on so these are basically"
      },
      {
        "start": 8222.519,
        "duration": 7.5,
        "text": "internal key spaces that you should not"
      },
      {
        "start": 8225.34,
        "duration": 5.879,
        "text": "work with the one we created is sensor"
      },
      {
        "start": 8230.019,
        "duration": 3.481,
        "text": "data"
      },
      {
        "start": 8231.219,
        "duration": 3.901,
        "text": "and we are going to use it so we're"
      },
      {
        "start": 8233.5,
        "duration": 3.96,
        "text": "going to select it as a default key"
      },
      {
        "start": 8235.12,
        "duration": 6.599,
        "text": "space all our statements will be"
      },
      {
        "start": 8237.46,
        "duration": 7.7,
        "text": "executed within this key space okay okay"
      },
      {
        "start": 8241.719,
        "duration": 3.441,
        "text": "now let me copy again"
      },
      {
        "start": 8246.399,
        "duration": 2.901,
        "text": "okay"
      },
      {
        "start": 8250.719,
        "duration": 5.061,
        "text": "so I'm going to create this table"
      },
      {
        "start": 8253.479,
        "duration": 4.08,
        "text": "done"
      },
      {
        "start": 8255.78,
        "duration": 4.68,
        "text": "describe"
      },
      {
        "start": 8257.559,
        "duration": 2.901,
        "text": "tables"
      },
      {
        "start": 8260.8,
        "duration": 6.179,
        "text": "okay I only have one describe this table"
      },
      {
        "start": 8264.76,
        "duration": 5.639,
        "text": "Networks"
      },
      {
        "start": 8266.979,
        "duration": 6.061,
        "text": "oh you can see the same code create"
      },
      {
        "start": 8270.399,
        "duration": 4.981,
        "text": "table but there are a bunch of other"
      },
      {
        "start": 8273.04,
        "duration": 4.08,
        "text": "properties that you can actually change"
      },
      {
        "start": 8275.38,
        "duration": 4.32,
        "text": "for the table We're not gonna talk about"
      },
      {
        "start": 8277.12,
        "duration": 6.439,
        "text": "them today"
      },
      {
        "start": 8279.7,
        "duration": 3.859,
        "text": "um so the other two tables"
      },
      {
        "start": 8289.3,
        "duration": 3.66,
        "text": "okay sensors"
      },
      {
        "start": 8293.859,
        "duration": 6.2,
        "text": "by Network and temperatures by sensor"
      },
      {
        "start": 8297.04,
        "duration": 3.019,
        "text": "bad okay"
      },
      {
        "start": 8302.859,
        "duration": 6.24,
        "text": "and the last command that we need here"
      },
      {
        "start": 8305.08,
        "duration": 6.24,
        "text": "is to drop that I explain why the why"
      },
      {
        "start": 8309.099,
        "duration": 3.84,
        "text": "that table schema was not great the"
      },
      {
        "start": 8311.32,
        "duration": 4.02,
        "text": "selection of primary key was not great"
      },
      {
        "start": 8312.939,
        "duration": 3.66,
        "text": "so we added date so we will drop the"
      },
      {
        "start": 8315.34,
        "duration": 4.82,
        "text": "table"
      },
      {
        "start": 8316.599,
        "duration": 3.561,
        "text": "and create a new one"
      },
      {
        "start": 8325.54,
        "duration": 6.059,
        "text": "okay now let's describe our"
      },
      {
        "start": 8328.599,
        "duration": 3.0,
        "text": "tables"
      },
      {
        "start": 8332.5,
        "duration": 5.28,
        "text": "and we have"
      },
      {
        "start": 8335.74,
        "duration": 3.18,
        "text": "we have three tables"
      },
      {
        "start": 8337.78,
        "duration": 5.76,
        "text": "right"
      },
      {
        "start": 8338.92,
        "duration": 7.259,
        "text": "and now in the next exercise we will be"
      },
      {
        "start": 8343.54,
        "duration": 5.16,
        "text": "able to populate those tables"
      },
      {
        "start": 8346.179,
        "duration": 4.201,
        "text": "okay so we'll be able to insert delete"
      },
      {
        "start": 8348.7,
        "duration": 4.739,
        "text": "update so if you're familiar with"
      },
      {
        "start": 8350.38,
        "duration": 6.74,
        "text": "relational databases with SQL"
      },
      {
        "start": 8353.439,
        "duration": 6.301,
        "text": "then you probably feel comfortable using"
      },
      {
        "start": 8357.12,
        "duration": 6.279,
        "text": "cql Cassandra queue language create"
      },
      {
        "start": 8359.74,
        "duration": 5.52,
        "text": "table insert delete update select all"
      },
      {
        "start": 8363.399,
        "duration": 3.421,
        "text": "similar statements all similar"
      },
      {
        "start": 8365.26,
        "duration": 4.259,
        "text": "statements but there are some"
      },
      {
        "start": 8366.82,
        "duration": 4.5,
        "text": "differences we've seen already like the"
      },
      {
        "start": 8369.519,
        "duration": 5.401,
        "text": "partition key"
      },
      {
        "start": 8371.32,
        "duration": 7.039,
        "text": "and this clustering order by is"
      },
      {
        "start": 8374.92,
        "duration": 6.599,
        "text": "something new what it does is basically"
      },
      {
        "start": 8378.359,
        "duration": 5.08,
        "text": "specify specifies how you're gonna how"
      },
      {
        "start": 8381.519,
        "duration": 4.801,
        "text": "the data will be sort within each"
      },
      {
        "start": 8383.439,
        "duration": 5.761,
        "text": "partition within each partition the data"
      },
      {
        "start": 8386.32,
        "duration": 4.74,
        "text": "is sorted based on clustering key in"
      },
      {
        "start": 8389.2,
        "duration": 4.32,
        "text": "this case timestamp and we're saying"
      },
      {
        "start": 8391.06,
        "duration": 4.98,
        "text": "let's sort them in descending order so"
      },
      {
        "start": 8393.52,
        "duration": 3.72,
        "text": "the the most recent data is going to be"
      },
      {
        "start": 8396.04,
        "duration": 4.8,
        "text": "first"
      },
      {
        "start": 8397.24,
        "duration": 5.82,
        "text": "and this is kind of optimization that"
      },
      {
        "start": 8400.84,
        "duration": 5.639,
        "text": "that allows you to efficiently retrieve"
      },
      {
        "start": 8403.06,
        "duration": 5.82,
        "text": "the data and do some specific queries"
      },
      {
        "start": 8406.479,
        "duration": 5.041,
        "text": "um that that clustering"
      },
      {
        "start": 8408.88,
        "duration": 5.7,
        "text": "clustering order helps in in that case"
      },
      {
        "start": 8411.52,
        "duration": 4.26,
        "text": "but that's out of scope for today Alex"
      },
      {
        "start": 8414.58,
        "duration": 6.06,
        "text": "back to you"
      },
      {
        "start": 8415.78,
        "duration": 9.3,
        "text": "yep good oh"
      },
      {
        "start": 8420.64,
        "duration": 8.96,
        "text": "so questions are answering shot"
      },
      {
        "start": 8425.08,
        "duration": 4.52,
        "text": "and let me switch to my screen"
      },
      {
        "start": 8431.56,
        "duration": 6.36,
        "text": "yes good"
      },
      {
        "start": 8433.8,
        "duration": 7.24,
        "text": "so with that say it and done uh let me"
      },
      {
        "start": 8437.92,
        "duration": 7.68,
        "text": "ask you a couple of questions"
      },
      {
        "start": 8441.04,
        "duration": 7.02,
        "text": "uh to be basically very very last"
      },
      {
        "start": 8445.6,
        "duration": 6.48,
        "text": "questions of"
      },
      {
        "start": 8448.06,
        "duration": 8.64,
        "text": "ah okay almost the last question"
      },
      {
        "start": 8452.08,
        "duration": 8.46,
        "text": "cep theorem says what a failure"
      },
      {
        "start": 8456.7,
        "duration": 6.96,
        "text": "C A and P are guaranteed if C fails so"
      },
      {
        "start": 8460.54,
        "duration": 5.72,
        "text": "do A and B only CA or CP can be"
      },
      {
        "start": 8463.66,
        "duration": 2.6,
        "text": "guaranteed"
      },
      {
        "start": 8469.359,
        "duration": 2.601,
        "text": "foreign"
      },
      {
        "start": 8480.12,
        "duration": 6.64,
        "text": "yes CA or CP can be guaranteed you"
      },
      {
        "start": 8484.24,
        "duration": 6.84,
        "text": "cannot that would be great to have C A"
      },
      {
        "start": 8486.76,
        "duration": 7.02,
        "text": "and B on failure magically somehow but"
      },
      {
        "start": 8491.08,
        "duration": 6.899,
        "text": "there are no unicorns I'm sorry"
      },
      {
        "start": 8493.78,
        "duration": 9.18,
        "text": "uh also that would be great yeah and if"
      },
      {
        "start": 8497.979,
        "duration": 11.161,
        "text": "C fails A and B still can be feasible"
      },
      {
        "start": 8502.96,
        "duration": 6.18,
        "text": "good then second question"
      },
      {
        "start": 8510.479,
        "duration": 6.041,
        "text": "uh recommended consistency level for the"
      },
      {
        "start": 8513.52,
        "duration": 6.6,
        "text": "immediate consistency"
      },
      {
        "start": 8516.52,
        "duration": 7.339,
        "text": "read write one one read write one all"
      },
      {
        "start": 8520.12,
        "duration": 3.739,
        "text": "read write Warren quorum"
      },
      {
        "start": 8538.26,
        "duration": 4.059,
        "text": "yeah read write Forum Quorum is"
      },
      {
        "start": 8540.819,
        "duration": 4.08,
        "text": "recommended level for immediate"
      },
      {
        "start": 8542.319,
        "duration": 5.101,
        "text": "consistency those four persons who"
      },
      {
        "start": 8544.899,
        "duration": 5.401,
        "text": "answer it one all technically you are"
      },
      {
        "start": 8547.42,
        "duration": 4.92,
        "text": "right one all also read let you reach"
      },
      {
        "start": 8550.3,
        "duration": 4.019,
        "text": "immediate consistency"
      },
      {
        "start": 8552.34,
        "duration": 5.94,
        "text": "but it's not recommended way because"
      },
      {
        "start": 8554.319,
        "duration": 7.141,
        "text": "this way you are in a trap of"
      },
      {
        "start": 8558.28,
        "duration": 5.76,
        "text": "all consistency level which require all"
      },
      {
        "start": 8561.46,
        "duration": 3.54,
        "text": "nodes to be available and the slowest"
      },
      {
        "start": 8564.04,
        "duration": 2.279,
        "text": "one"
      },
      {
        "start": 8565.0,
        "duration": 4.1,
        "text": "good"
      },
      {
        "start": 8566.319,
        "duration": 5.941,
        "text": "so we are getting to the very end"
      },
      {
        "start": 8569.1,
        "duration": 6.339,
        "text": "uh final part"
      },
      {
        "start": 8572.26,
        "duration": 6.179,
        "text": "and let me uh go let me lead you for a"
      },
      {
        "start": 8575.439,
        "duration": 4.861,
        "text": "bit so data structure in Cassandra"
      },
      {
        "start": 8578.439,
        "duration": 3.42,
        "text": "starts with a cell a seller's"
      },
      {
        "start": 8580.3,
        "duration": 4.44,
        "text": "intersection of a Rowan column that"
      },
      {
        "start": 8581.859,
        "duration": 5.281,
        "text": "stores data then row is a single"
      },
      {
        "start": 8584.74,
        "duration": 4.44,
        "text": "structured data item in a table that"
      },
      {
        "start": 8587.14,
        "duration": 5.52,
        "text": "must be familiar to you already"
      },
      {
        "start": 8589.18,
        "duration": 5.7,
        "text": "then partition is a group of rows having"
      },
      {
        "start": 8592.66,
        "duration": 4.98,
        "text": "the same partition token it's a base"
      },
      {
        "start": 8594.88,
        "duration": 5.46,
        "text": "unit of access in Cassandra it's"
      },
      {
        "start": 8597.64,
        "duration": 4.56,
        "text": "important what all rows of the same"
      },
      {
        "start": 8600.34,
        "duration": 3.9,
        "text": "partition will be stored together on the"
      },
      {
        "start": 8602.2,
        "duration": 4.8,
        "text": "same server close to each hour it's"
      },
      {
        "start": 8604.24,
        "duration": 4.02,
        "text": "important for the smooth retrieval of"
      },
      {
        "start": 8607.0,
        "duration": 4.319,
        "text": "this data"
      },
      {
        "start": 8608.26,
        "duration": 5.46,
        "text": "then finally table is a group of columns"
      },
      {
        "start": 8611.319,
        "duration": 5.101,
        "text": "or rows storing the partition"
      },
      {
        "start": 8613.72,
        "duration": 5.88,
        "text": "in Cassandra data is organized as"
      },
      {
        "start": 8616.42,
        "duration": 5.22,
        "text": "distributed tables so tables are present"
      },
      {
        "start": 8619.6,
        "duration": 4.32,
        "text": "but parts of them are spreaded over"
      },
      {
        "start": 8621.64,
        "duration": 5.16,
        "text": "multiple nodes"
      },
      {
        "start": 8623.92,
        "duration": 5.399,
        "text": "and then responsible for that is a"
      },
      {
        "start": 8626.8,
        "duration": 5.82,
        "text": "partition key then you create a table"
      },
      {
        "start": 8629.319,
        "duration": 6.54,
        "text": "you must Define primary key and primary"
      },
      {
        "start": 8632.62,
        "duration": 5.699,
        "text": "key consists of two parts first part is"
      },
      {
        "start": 8635.859,
        "duration": 5.341,
        "text": "a partition key first argument in a"
      },
      {
        "start": 8638.319,
        "duration": 6.12,
        "text": "primary key definition it may consist or"
      },
      {
        "start": 8641.2,
        "duration": 4.92,
        "text": "one or multiple columns but must present"
      },
      {
        "start": 8644.439,
        "duration": 4.981,
        "text": "and must have at least one column"
      },
      {
        "start": 8646.12,
        "duration": 6.239,
        "text": "otherwise we cannot calculate the token"
      },
      {
        "start": 8649.42,
        "duration": 6.979,
        "text": "uh there are different ways but the"
      },
      {
        "start": 8652.359,
        "duration": 6.601,
        "text": "general idea is all the fields of the"
      },
      {
        "start": 8656.399,
        "duration": 5.621,
        "text": "partition key in this case for example"
      },
      {
        "start": 8658.96,
        "duration": 6.42,
        "text": "only sensor we will have as many"
      },
      {
        "start": 8662.02,
        "duration": 5.22,
        "text": "partitions as many sensors we have is it"
      },
      {
        "start": 8665.38,
        "duration": 3.9,
        "text": "good or bad well it depends on your"
      },
      {
        "start": 8667.24,
        "duration": 5.22,
        "text": "situation might be good or bad depending"
      },
      {
        "start": 8669.28,
        "duration": 5.28,
        "text": "on how many sensors do you have well you"
      },
      {
        "start": 8672.46,
        "duration": 4.979,
        "text": "can have many partitions it's totally"
      },
      {
        "start": 8674.56,
        "duration": 4.98,
        "text": "fine but maybe you want to improve"
      },
      {
        "start": 8677.439,
        "duration": 5.161,
        "text": "something on that in this case you see"
      },
      {
        "start": 8679.54,
        "duration": 6.18,
        "text": "sensor and timestamp partition token"
      },
      {
        "start": 8682.6,
        "duration": 5.94,
        "text": "will be generated based on sensor ID and"
      },
      {
        "start": 8685.72,
        "duration": 5.88,
        "text": "timestamp of a temperature record that"
      },
      {
        "start": 8688.54,
        "duration": 5.58,
        "text": "means we will have as many partitions as"
      },
      {
        "start": 8691.6,
        "duration": 5.94,
        "text": "many records we have per sensor"
      },
      {
        "start": 8694.12,
        "duration": 6.12,
        "text": "and that might be good on the right time"
      },
      {
        "start": 8697.54,
        "duration": 4.74,
        "text": "but it might be bad on the read time"
      },
      {
        "start": 8700.24,
        "duration": 4.619,
        "text": "there is important thing to understand"
      },
      {
        "start": 8702.28,
        "duration": 5.34,
        "text": "when we're thinking about uh creating"
      },
      {
        "start": 8704.859,
        "duration": 4.861,
        "text": "partitions we speak more about that uh"
      },
      {
        "start": 8707.62,
        "duration": 4.22,
        "text": "next Workshop but briefly I want to"
      },
      {
        "start": 8709.72,
        "duration": 4.98,
        "text": "introduce it"
      },
      {
        "start": 8711.84,
        "duration": 6.639,
        "text": "when thinking of partitions we need to"
      },
      {
        "start": 8714.7,
        "duration": 6.9,
        "text": "remember two operations right and read"
      },
      {
        "start": 8718.479,
        "duration": 5.821,
        "text": "what is important during all the"
      },
      {
        "start": 8721.6,
        "duration": 5.339,
        "text": "operations when we write data when we"
      },
      {
        "start": 8724.3,
        "duration": 5.88,
        "text": "retrieve data we need to know all the"
      },
      {
        "start": 8726.939,
        "duration": 6.841,
        "text": "parts of the partition key"
      },
      {
        "start": 8730.18,
        "duration": 6.36,
        "text": "can we write data with this partition"
      },
      {
        "start": 8733.78,
        "duration": 5.52,
        "text": "key for example temperature sensor"
      },
      {
        "start": 8736.54,
        "duration": 5.3,
        "text": "reports its temperature to be I don't"
      },
      {
        "start": 8739.3,
        "duration": 5.76,
        "text": "know 30 degrees Celsius"
      },
      {
        "start": 8741.84,
        "duration": 5.74,
        "text": "can be right with data yes we can we"
      },
      {
        "start": 8745.06,
        "duration": 5.22,
        "text": "know sensor ID we know timestamp then"
      },
      {
        "start": 8747.58,
        "duration": 4.62,
        "text": "this recording was done when we can just"
      },
      {
        "start": 8750.28,
        "duration": 3.96,
        "text": "go through it to the database and we"
      },
      {
        "start": 8752.2,
        "duration": 4.02,
        "text": "will be happy new Partition will be"
      },
      {
        "start": 8754.24,
        "duration": 4.14,
        "text": "created this partition will have only"
      },
      {
        "start": 8756.22,
        "duration": 3.78,
        "text": "one record and all of this is totally"
      },
      {
        "start": 8758.38,
        "duration": 4.5,
        "text": "fine and good"
      },
      {
        "start": 8760.0,
        "duration": 6.3,
        "text": "but you should not forget about the"
      },
      {
        "start": 8762.88,
        "duration": 5.34,
        "text": "second operation which is a read and in"
      },
      {
        "start": 8766.3,
        "duration": 5.16,
        "text": "this case we might run into trouble"
      },
      {
        "start": 8768.22,
        "duration": 4.56,
        "text": "because to retrieve this data again we"
      },
      {
        "start": 8771.46,
        "duration": 3.84,
        "text": "need to know"
      },
      {
        "start": 8772.78,
        "duration": 4.38,
        "text": "all the parts of a partition key and"
      },
      {
        "start": 8775.3,
        "duration": 4.62,
        "text": "then take a look if you're going to"
      },
      {
        "start": 8777.16,
        "duration": 6.8,
        "text": "retrieve data about the sensor I think"
      },
      {
        "start": 8779.92,
        "duration": 7.559,
        "text": "we might have we may have its ID okay"
      },
      {
        "start": 8783.96,
        "duration": 5.979,
        "text": "but also to retrieve data safely in the"
      },
      {
        "start": 8787.479,
        "duration": 4.681,
        "text": "right way we will need to know all the"
      },
      {
        "start": 8789.939,
        "duration": 6.38,
        "text": "time steps when these recordings were"
      },
      {
        "start": 8792.16,
        "duration": 7.5,
        "text": "done and that sounds already not so easy"
      },
      {
        "start": 8796.319,
        "duration": 5.921,
        "text": "so this partition key might be optimal"
      },
      {
        "start": 8799.66,
        "duration": 4.98,
        "text": "for right but not so optimal for read so"
      },
      {
        "start": 8802.24,
        "duration": 4.26,
        "text": "we could think of something better"
      },
      {
        "start": 8804.64,
        "duration": 3.42,
        "text": "in the future"
      },
      {
        "start": 8806.5,
        "duration": 4.859,
        "text": "then"
      },
      {
        "start": 8808.06,
        "duration": 5.879,
        "text": "second part of a primary key are the"
      },
      {
        "start": 8811.359,
        "duration": 5.281,
        "text": "clustering columns what is a clustering"
      },
      {
        "start": 8813.939,
        "duration": 4.741,
        "text": "column it's a special column a part of"
      },
      {
        "start": 8816.64,
        "duration": 5.0,
        "text": "your table definition in this case for"
      },
      {
        "start": 8818.68,
        "duration": 2.96,
        "text": "example timestamp"
      },
      {
        "start": 8822.0,
        "duration": 8.02,
        "text": "what has two purposes"
      },
      {
        "start": 8826.12,
        "duration": 6.12,
        "text": "it's a user to ensure uniqueness and its"
      },
      {
        "start": 8830.02,
        "duration": 5.64,
        "text": "second duty is to ensure sorting order"
      },
      {
        "start": 8832.24,
        "duration": 6.84,
        "text": "first let's think about uniqueness why"
      },
      {
        "start": 8835.66,
        "duration": 6.779,
        "text": "do we use uh or why do we use clustering"
      },
      {
        "start": 8839.08,
        "duration": 5.64,
        "text": "column imagine primary key like that we"
      },
      {
        "start": 8842.439,
        "duration": 4.441,
        "text": "don't have clustering columns at all we"
      },
      {
        "start": 8844.72,
        "duration": 6.24,
        "text": "have only partition key and partition"
      },
      {
        "start": 8846.88,
        "duration": 7.559,
        "text": "key is sensor so sensor ID with this"
      },
      {
        "start": 8850.96,
        "duration": 6.899,
        "text": "design we will have one recording per"
      },
      {
        "start": 8854.439,
        "duration": 6.241,
        "text": "sensor because primary key will be"
      },
      {
        "start": 8857.859,
        "duration": 7.08,
        "text": "always matching Cassandra follows the"
      },
      {
        "start": 8860.68,
        "duration": 6.299,
        "text": "logic of absurd or update or insert are"
      },
      {
        "start": 8864.939,
        "duration": 5.761,
        "text": "exactly the same operations"
      },
      {
        "start": 8866.979,
        "duration": 5.941,
        "text": "so with that if you use a primary key"
      },
      {
        "start": 8870.7,
        "duration": 5.04,
        "text": "like that every next temperature"
      },
      {
        "start": 8872.92,
        "duration": 6.72,
        "text": "recording will overwrite the previous"
      },
      {
        "start": 8875.74,
        "duration": 5.579,
        "text": "recording is it good or bad it depends"
      },
      {
        "start": 8879.64,
        "duration": 4.38,
        "text": "on your it depends on what do you want"
      },
      {
        "start": 8881.319,
        "duration": 5.58,
        "text": "to have if you are fine saving only the"
      },
      {
        "start": 8884.02,
        "duration": 5.94,
        "text": "last recording then maybe it's totally"
      },
      {
        "start": 8886.899,
        "duration": 6.121,
        "text": "fine as designed but if you are going to"
      },
      {
        "start": 8889.96,
        "duration": 5.46,
        "text": "uh see like how temperature changes over"
      },
      {
        "start": 8893.02,
        "duration": 5.22,
        "text": "time that's obviously not going to be"
      },
      {
        "start": 8895.42,
        "duration": 4.62,
        "text": "the good idea so short answer is not an"
      },
      {
        "start": 8898.24,
        "duration": 5.22,
        "text": "eager"
      },
      {
        "start": 8900.04,
        "duration": 8.16,
        "text": "then uh for example second duty of it is"
      },
      {
        "start": 8903.46,
        "duration": 7.56,
        "text": "to have sorted uh sorted defaults this"
      },
      {
        "start": 8908.2,
        "duration": 6.06,
        "text": "idea is much better sensor as a"
      },
      {
        "start": 8911.02,
        "duration": 5.82,
        "text": "partition key timestamp as a as a"
      },
      {
        "start": 8914.26,
        "duration": 4.74,
        "text": "clustering column this way because they"
      },
      {
        "start": 8916.84,
        "duration": 5.22,
        "text": "both build together the same primary key"
      },
      {
        "start": 8919.0,
        "duration": 6.66,
        "text": "each new recording will be unique and"
      },
      {
        "start": 8922.06,
        "duration": 6.299,
        "text": "available for sensor for timestamp"
      },
      {
        "start": 8925.66,
        "duration": 5.699,
        "text": "and that is the first thing so data is"
      },
      {
        "start": 8928.359,
        "duration": 4.681,
        "text": "unique uh and next there are timestamp"
      },
      {
        "start": 8931.359,
        "duration": 3.661,
        "text": "recording will next temperature"
      },
      {
        "start": 8933.04,
        "duration": 3.18,
        "text": "recording will not overwrite the"
      },
      {
        "start": 8935.02,
        "duration": 4.379,
        "text": "previous one"
      },
      {
        "start": 8936.22,
        "duration": 6.54,
        "text": "uh and in this case we will be able to"
      },
      {
        "start": 8939.399,
        "duration": 6.121,
        "text": "sort by time and that is already pretty"
      },
      {
        "start": 8942.76,
        "duration": 4.98,
        "text": "good for us because for example we want"
      },
      {
        "start": 8945.52,
        "duration": 6.419,
        "text": "to so we want to sort"
      },
      {
        "start": 8947.74,
        "duration": 6.42,
        "text": "our temperatures by time to see how it"
      },
      {
        "start": 8951.939,
        "duration": 4.321,
        "text": "changes over time"
      },
      {
        "start": 8954.16,
        "duration": 4.62,
        "text": "um in this case"
      },
      {
        "start": 8956.26,
        "duration": 5.04,
        "text": "it's a pretty good example how timestamp"
      },
      {
        "start": 8958.78,
        "duration": 5.48,
        "text": "is used for both uniqueness of the"
      },
      {
        "start": 8961.3,
        "duration": 6.72,
        "text": "record and for sorting"
      },
      {
        "start": 8964.26,
        "duration": 6.82,
        "text": "and uh that is a pretty good example"
      },
      {
        "start": 8968.02,
        "duration": 5.879,
        "text": "let's move on"
      },
      {
        "start": 8971.08,
        "duration": 5.46,
        "text": "then primary key is partition key and"
      },
      {
        "start": 8973.899,
        "duration": 4.701,
        "text": "clustering column all together you"
      },
      {
        "start": 8976.54,
        "duration": 6.96,
        "text": "already seen how we're working"
      },
      {
        "start": 8978.6,
        "duration": 7.36,
        "text": "uh partitioning so partition key is used"
      },
      {
        "start": 8983.5,
        "duration": 4.92,
        "text": "to define partitions clustering column"
      },
      {
        "start": 8985.96,
        "duration": 6.479,
        "text": "is used for uniqueness and core sorting"
      },
      {
        "start": 8988.42,
        "duration": 7.14,
        "text": "order and this V clustering order by is"
      },
      {
        "start": 8992.439,
        "duration": 5.581,
        "text": "used to explain in which sorting order"
      },
      {
        "start": 8995.56,
        "duration": 5.4,
        "text": "we need to have it ascending or"
      },
      {
        "start": 8998.02,
        "duration": 5.459,
        "text": "descending uh so those are typical"
      },
      {
        "start": 9000.96,
        "duration": 6.06,
        "text": "examples of a primary key for example"
      },
      {
        "start": 9003.479,
        "duration": 6.781,
        "text": "for these kind of datum"
      },
      {
        "start": 9007.02,
        "duration": 7.919,
        "text": "can we mention clustering order out of a"
      },
      {
        "start": 9010.26,
        "duration": 7.559,
        "text": "primary key columns and ah"
      },
      {
        "start": 9014.939,
        "duration": 4.081,
        "text": "so I'm not sure if I can get the"
      },
      {
        "start": 9017.819,
        "duration": 3.261,
        "text": "question"
      },
      {
        "start": 9019.02,
        "duration": 2.06,
        "text": "um"
      },
      {
        "start": 9021.38,
        "duration": 5.559,
        "text": "non-primary keycombs"
      },
      {
        "start": 9024.54,
        "duration": 5.399,
        "text": "can we use non-primary key columns too"
      },
      {
        "start": 9026.939,
        "duration": 6.661,
        "text": "for sorting yeah"
      },
      {
        "start": 9029.939,
        "duration": 4.861,
        "text": "yes uh maybe so the story is in"
      },
      {
        "start": 9033.6,
        "duration": 5.52,
        "text": "Cassandra"
      },
      {
        "start": 9034.8,
        "duration": 8.42,
        "text": "uh uh clustering or okay so the story is"
      },
      {
        "start": 9039.12,
        "duration": 8.699,
        "text": "we have three uh kinds of columns"
      },
      {
        "start": 9043.22,
        "duration": 6.78,
        "text": "uh prior partition columns"
      },
      {
        "start": 9047.819,
        "duration": 4.741,
        "text": "so censoring date in this example"
      },
      {
        "start": 9050.0,
        "duration": 6.04,
        "text": "clustering columns timestamp in this"
      },
      {
        "start": 9052.56,
        "duration": 6.54,
        "text": "example and data columns value in this"
      },
      {
        "start": 9056.04,
        "duration": 5.399,
        "text": "case y value is a data column because"
      },
      {
        "start": 9059.1,
        "duration": 3.6,
        "text": "it's not mentioned in primary key"
      },
      {
        "start": 9061.439,
        "duration": 4.821,
        "text": "nowhere"
      },
      {
        "start": 9062.7,
        "duration": 7.38,
        "text": "and in Cassandra"
      },
      {
        "start": 9066.26,
        "duration": 6.88,
        "text": "partition key clustering columns work as"
      },
      {
        "start": 9070.08,
        "duration": 5.34,
        "text": "primary indexes so you can use them for"
      },
      {
        "start": 9073.14,
        "duration": 4.92,
        "text": "search and clustering columns for"
      },
      {
        "start": 9075.42,
        "duration": 6.54,
        "text": "filtering for sorting"
      },
      {
        "start": 9078.06,
        "duration": 7.56,
        "text": "data columns cannot be used for search"
      },
      {
        "start": 9081.96,
        "duration": 6.899,
        "text": "for filtering for sorting and so on they"
      },
      {
        "start": 9085.62,
        "duration": 6.54,
        "text": "are just to store data there are tools"
      },
      {
        "start": 9088.859,
        "duration": 5.58,
        "text": "to enable it like secondary indexes but"
      },
      {
        "start": 9092.16,
        "duration": 4.98,
        "text": "secondary indexes Cassandra is a pretty"
      },
      {
        "start": 9094.439,
        "duration": 5.161,
        "text": "complex topic they have their own issues"
      },
      {
        "start": 9097.14,
        "duration": 5.339,
        "text": "they um"
      },
      {
        "start": 9099.6,
        "duration": 5.879,
        "text": "uh partition based and there are like"
      },
      {
        "start": 9102.479,
        "duration": 6.121,
        "text": "plenty of issues with that so uh short"
      },
      {
        "start": 9105.479,
        "duration": 5.821,
        "text": "answer is for sorting"
      },
      {
        "start": 9108.6,
        "duration": 5.52,
        "text": "uh"
      },
      {
        "start": 9111.3,
        "duration": 4.86,
        "text": "only clustering accounts yeah for"
      },
      {
        "start": 9114.12,
        "duration": 4.56,
        "text": "sorting for only inequality operations"
      },
      {
        "start": 9116.16,
        "duration": 4.68,
        "text": "only clustering columns I told you in"
      },
      {
        "start": 9118.68,
        "duration": 4.28,
        "text": "the very beginning Cassandra is a real"
      },
      {
        "start": 9120.84,
        "duration": 4.5,
        "text": "Firepower on the database Market"
      },
      {
        "start": 9122.96,
        "duration": 4.54,
        "text": "extremely fast extremely powerful"
      },
      {
        "start": 9125.34,
        "duration": 3.32,
        "text": "scalable and high availability and"
      },
      {
        "start": 9127.5,
        "duration": 3.84,
        "text": "everything"
      },
      {
        "start": 9128.66,
        "duration": 6.04,
        "text": "but there are plenty of limitations too"
      },
      {
        "start": 9131.34,
        "duration": 6.599,
        "text": "there is a price to pay and inability to"
      },
      {
        "start": 9134.7,
        "duration": 6.659,
        "text": "search by data columns or inability to"
      },
      {
        "start": 9137.939,
        "duration": 6.0,
        "text": "use inequalities on a partition Keys is"
      },
      {
        "start": 9141.359,
        "duration": 5.161,
        "text": "part of this price"
      },
      {
        "start": 9143.939,
        "duration": 3.96,
        "text": "uh we will discuss it more I believe in"
      },
      {
        "start": 9146.52,
        "duration": 5.459,
        "text": "the next Workshop"
      },
      {
        "start": 9147.899,
        "duration": 5.281,
        "text": "good now very important thing"
      },
      {
        "start": 9151.979,
        "duration": 3.84,
        "text": "now"
      },
      {
        "start": 9153.18,
        "duration": 4.38,
        "text": "please Focus they are getting to the end"
      },
      {
        "start": 9155.819,
        "duration": 4.861,
        "text": "and this part is important partition"
      },
      {
        "start": 9157.56,
        "duration": 4.32,
        "text": "keys Define data distribution over"
      },
      {
        "start": 9160.68,
        "duration": 3.78,
        "text": "cluster"
      },
      {
        "start": 9161.88,
        "duration": 4.939,
        "text": "all right a different partition key and"
      },
      {
        "start": 9164.46,
        "duration": 6.18,
        "text": "your data goes to in our server"
      },
      {
        "start": 9166.819,
        "duration": 6.701,
        "text": "clustering columns Define how data is"
      },
      {
        "start": 9170.64,
        "duration": 5.88,
        "text": "physically stored how it's physically"
      },
      {
        "start": 9173.52,
        "duration": 4.379,
        "text": "written on disk"
      },
      {
        "start": 9176.52,
        "duration": 4.74,
        "text": "so"
      },
      {
        "start": 9177.899,
        "duration": 5.701,
        "text": "there is a a very important thing you"
      },
      {
        "start": 9181.26,
        "duration": 5.7,
        "text": "need to understand because of it once"
      },
      {
        "start": 9183.6,
        "duration": 5.52,
        "text": "created data model cannot be changed you"
      },
      {
        "start": 9186.96,
        "duration": 4.74,
        "text": "will need if you find what your data"
      },
      {
        "start": 9189.12,
        "duration": 5.1,
        "text": "model is not right if you have something"
      },
      {
        "start": 9191.7,
        "duration": 4.44,
        "text": "maybe it was right before but now it's"
      },
      {
        "start": 9194.22,
        "duration": 4.139,
        "text": "changed now your application has new"
      },
      {
        "start": 9196.14,
        "duration": 5.58,
        "text": "business requirements you may need to"
      },
      {
        "start": 9198.359,
        "duration": 6.361,
        "text": "create new tables and migrate your data"
      },
      {
        "start": 9201.72,
        "duration": 6.3,
        "text": "and there is no things like alter table"
      },
      {
        "start": 9204.72,
        "duration": 5.58,
        "text": "change primary key it's not possible for"
      },
      {
        "start": 9208.02,
        "duration": 4.5,
        "text": "a simple reason schema is immutable"
      },
      {
        "start": 9210.3,
        "duration": 4.86,
        "text": "because changing any kind of a partition"
      },
      {
        "start": 9212.52,
        "duration": 6.24,
        "text": "key will lead to changing partition"
      },
      {
        "start": 9215.16,
        "duration": 7.02,
        "text": "tokens will lead to moving all data all"
      },
      {
        "start": 9218.76,
        "duration": 5.58,
        "text": "the cluster and basically web can take"
      },
      {
        "start": 9222.18,
        "duration": 4.98,
        "text": "weeks and your cluster will be busy"
      },
      {
        "start": 9224.34,
        "duration": 5.639,
        "text": "moving data not answering customers"
      },
      {
        "start": 9227.16,
        "duration": 5.34,
        "text": "same with clustering columns change of"
      },
      {
        "start": 9229.979,
        "duration": 5.701,
        "text": "the clustering column will lead to a"
      },
      {
        "start": 9232.5,
        "duration": 5.7,
        "text": "need to rewrite all data on your cluster"
      },
      {
        "start": 9235.68,
        "duration": 5.16,
        "text": "which again will take weeks of cluster"
      },
      {
        "start": 9238.2,
        "duration": 5.46,
        "text": "being busy or rewriting your data so"
      },
      {
        "start": 9240.84,
        "duration": 6.66,
        "text": "it's again not possible you can change"
      },
      {
        "start": 9243.66,
        "duration": 9.06,
        "text": "only data columns you cannot change"
      },
      {
        "start": 9247.5,
        "duration": 8.04,
        "text": "anything what is or was a part or is a"
      },
      {
        "start": 9252.72,
        "duration": 5.219,
        "text": "part of a primary key nothing schema is"
      },
      {
        "start": 9255.54,
        "duration": 7.7,
        "text": "immutable"
      },
      {
        "start": 9257.939,
        "duration": 5.301,
        "text": "good and that uh last few slides"
      },
      {
        "start": 9263.359,
        "duration": 4.481,
        "text": "partitioning as you can understand is"
      },
      {
        "start": 9265.8,
        "duration": 3.599,
        "text": "the key to success if you do your"
      },
      {
        "start": 9267.84,
        "duration": 3.479,
        "text": "partitioning right your application"
      },
      {
        "start": 9269.399,
        "duration": 4.621,
        "text": "you'll work very fast and it will be"
      },
      {
        "start": 9271.319,
        "duration": 4.861,
        "text": "very scalable do your partitioning wrong"
      },
      {
        "start": 9274.02,
        "duration": 4.32,
        "text": "and you will have a lot of fun later I"
      },
      {
        "start": 9276.18,
        "duration": 3.6,
        "text": "mean fun in the very bad meaning of this"
      },
      {
        "start": 9278.34,
        "duration": 5.099,
        "text": "world"
      },
      {
        "start": 9279.78,
        "duration": 6.539,
        "text": "so no fun at all uh very free simple"
      },
      {
        "start": 9283.439,
        "duration": 5.281,
        "text": "rules of a good partition first"
      },
      {
        "start": 9286.319,
        "duration": 5.401,
        "text": "store together what you retrieve"
      },
      {
        "start": 9288.72,
        "duration": 5.58,
        "text": "together that means think about how you"
      },
      {
        "start": 9291.72,
        "duration": 6.3,
        "text": "are going to load the data select read"
      },
      {
        "start": 9294.3,
        "duration": 5.639,
        "text": "these data the data makes sense to group"
      },
      {
        "start": 9298.02,
        "duration": 5.04,
        "text": "together what we are going to retrieve"
      },
      {
        "start": 9299.939,
        "duration": 4.861,
        "text": "together we have to try to group our"
      },
      {
        "start": 9303.06,
        "duration": 3.24,
        "text": "data away"
      },
      {
        "start": 9304.8,
        "duration": 5.099,
        "text": "so everything"
      },
      {
        "start": 9306.3,
        "duration": 5.58,
        "text": "will be retrieved from one single server"
      },
      {
        "start": 9309.899,
        "duration": 5.04,
        "text": "so it will belong to one single"
      },
      {
        "start": 9311.88,
        "duration": 4.8,
        "text": "partition because data is isolated on"
      },
      {
        "start": 9314.939,
        "duration": 4.861,
        "text": "the partition level"
      },
      {
        "start": 9316.68,
        "duration": 5.7,
        "text": "that's it second rule avoid big"
      },
      {
        "start": 9319.8,
        "duration": 5.22,
        "text": "partitions don't forget we introduce"
      },
      {
        "start": 9322.38,
        "duration": 4.019,
        "text": "partitions to avoid having too much data"
      },
      {
        "start": 9325.02,
        "duration": 4.26,
        "text": "per server"
      },
      {
        "start": 9326.399,
        "duration": 5.121,
        "text": "and introducing two peak partitions you"
      },
      {
        "start": 9329.28,
        "duration": 5.82,
        "text": "get to exactly the same problem"
      },
      {
        "start": 9331.52,
        "duration": 6.1,
        "text": "you just get too much data on the server"
      },
      {
        "start": 9335.1,
        "duration": 4.86,
        "text": "your server will need to spend a lot of"
      },
      {
        "start": 9337.62,
        "duration": 4.319,
        "text": "time trying to retrieve your data it"
      },
      {
        "start": 9339.96,
        "duration": 5.88,
        "text": "will be unmaintainable and very many"
      },
      {
        "start": 9341.939,
        "duration": 6.901,
        "text": "other problems uh for example"
      },
      {
        "start": 9345.84,
        "duration": 6.059,
        "text": "we do not recommend you to have more"
      },
      {
        "start": 9348.84,
        "duration": 6.36,
        "text": "than 100 000 rows in a partition"
      },
      {
        "start": 9351.899,
        "duration": 5.341,
        "text": "or more than 100 megabytes of data in a"
      },
      {
        "start": 9355.2,
        "duration": 4.68,
        "text": "partition those are recommendations but"
      },
      {
        "start": 9357.24,
        "duration": 5.46,
        "text": "the hard limit you cannot have more than"
      },
      {
        "start": 9359.88,
        "duration": 5.76,
        "text": "2 billion sales per partition but my"
      },
      {
        "start": 9362.7,
        "duration": 5.64,
        "text": "advice is not to try to get any close to"
      },
      {
        "start": 9365.64,
        "duration": 6.48,
        "text": "this number because it's going to be a"
      },
      {
        "start": 9368.34,
        "duration": 4.559,
        "text": "very very very very very very bad idea"
      },
      {
        "start": 9372.12,
        "duration": 2.16,
        "text": "um"
      },
      {
        "start": 9372.899,
        "duration": 4.561,
        "text": "for example"
      },
      {
        "start": 9374.28,
        "duration": 7.199,
        "text": "here we can say what writing comments"
      },
      {
        "start": 9377.46,
        "duration": 7.26,
        "text": "per video on YouTube for example"
      },
      {
        "start": 9381.479,
        "duration": 5.641,
        "text": "um there's a small entity so sometimes"
      },
      {
        "start": 9384.72,
        "duration": 4.38,
        "text": "there can be more than 100 000 rows in a"
      },
      {
        "start": 9387.12,
        "duration": 4.98,
        "text": "partition but at least they are small"
      },
      {
        "start": 9389.1,
        "duration": 6.0,
        "text": "there is a text comment ID out already"
      },
      {
        "start": 9392.1,
        "duration": 4.62,
        "text": "outer name timestamp and text and"
      },
      {
        "start": 9395.1,
        "duration": 3.719,
        "text": "usually comments on YouTube is pretty"
      },
      {
        "start": 9396.72,
        "duration": 4.139,
        "text": "small pretty small so in this case"
      },
      {
        "start": 9398.819,
        "duration": 5.521,
        "text": "partition per video for most of the"
      },
      {
        "start": 9400.859,
        "duration": 6.661,
        "text": "cases will be reopen reasonable size"
      },
      {
        "start": 9404.34,
        "duration": 6.18,
        "text": "but if you group your data"
      },
      {
        "start": 9407.52,
        "duration": 5.459,
        "text": "of customer data your users based on the"
      },
      {
        "start": 9410.52,
        "duration": 5.28,
        "text": "country there are countries like Vatican"
      },
      {
        "start": 9412.979,
        "duration": 4.681,
        "text": "or San Marino there's like a couple of"
      },
      {
        "start": 9415.8,
        "duration": 4.86,
        "text": "thousands of people and there are"
      },
      {
        "start": 9417.66,
        "duration": 6.48,
        "text": "countries like China India and with"
      },
      {
        "start": 9420.66,
        "duration": 6.42,
        "text": "hundreds Millions uh maybe billions of"
      },
      {
        "start": 9424.14,
        "duration": 5.04,
        "text": "people and this case your first"
      },
      {
        "start": 9427.08,
        "duration": 4.62,
        "text": "introduced Big partitions which is bad"
      },
      {
        "start": 9429.18,
        "duration": 5.34,
        "text": "and second you introduce uneven"
      },
      {
        "start": 9431.7,
        "duration": 5.279,
        "text": "partitions which is even worse you see"
      },
      {
        "start": 9434.52,
        "duration": 5.959,
        "text": "Cassandra scalability works best then"
      },
      {
        "start": 9436.979,
        "duration": 8.721,
        "text": "your partitions of a similar size"
      },
      {
        "start": 9440.479,
        "duration": 8.621,
        "text": "or rare more or less even than spreading"
      },
      {
        "start": 9445.7,
        "duration": 6.04,
        "text": "uh things uh like that based on the"
      },
      {
        "start": 9449.1,
        "duration": 4.2,
        "text": "country is basically obviously a wrong"
      },
      {
        "start": 9451.74,
        "duration": 4.619,
        "text": "idea"
      },
      {
        "start": 9453.3,
        "duration": 5.16,
        "text": "and then uh another Point what is very"
      },
      {
        "start": 9456.359,
        "duration": 5.101,
        "text": "often forgotten designing partitioning"
      },
      {
        "start": 9458.46,
        "duration": 6.6,
        "text": "for these tables people forget what size"
      },
      {
        "start": 9461.46,
        "duration": 6.0,
        "text": "may change over time for example if you"
      },
      {
        "start": 9465.06,
        "duration": 5.94,
        "text": "write these temperature sensor and you"
      },
      {
        "start": 9467.46,
        "duration": 5.519,
        "text": "do it like that sensor ID times temp the"
      },
      {
        "start": 9471.0,
        "duration": 5.22,
        "text": "example we are speaking over day today"
      },
      {
        "start": 9472.979,
        "duration": 6.121,
        "text": "with temperature recordings"
      },
      {
        "start": 9476.22,
        "duration": 5.639,
        "text": "if these sensors report they stayed"
      },
      {
        "start": 9479.1,
        "duration": 8.42,
        "text": "frequently like every few seconds if you"
      },
      {
        "start": 9481.859,
        "duration": 8.281,
        "text": "speak not about uh like nature uh"
      },
      {
        "start": 9487.52,
        "duration": 4.66,
        "text": "research but we speak about internet of"
      },
      {
        "start": 9490.14,
        "duration": 4.92,
        "text": "things temperature of an engine"
      },
      {
        "start": 9492.18,
        "duration": 4.679,
        "text": "temperature of oil in the engine then"
      },
      {
        "start": 9495.06,
        "duration": 3.6,
        "text": "this temperature can be recorded every"
      },
      {
        "start": 9496.859,
        "duration": 4.5,
        "text": "few seconds"
      },
      {
        "start": 9498.66,
        "duration": 5.1,
        "text": "and then over time if the beginning this"
      },
      {
        "start": 9501.359,
        "duration": 5.221,
        "text": "model will work partitioning based on"
      },
      {
        "start": 9503.76,
        "duration": 6.02,
        "text": "the sensor rating then over months the"
      },
      {
        "start": 9506.58,
        "duration": 5.819,
        "text": "partitions will start to become too big"
      },
      {
        "start": 9509.78,
        "duration": 4.92,
        "text": "and obviously that's getting dangerous"
      },
      {
        "start": 9512.399,
        "duration": 5.46,
        "text": "our partitions are too big"
      },
      {
        "start": 9514.7,
        "duration": 5.26,
        "text": "another one of the solutions possible in"
      },
      {
        "start": 9517.859,
        "duration": 5.821,
        "text": "this scenario would be introduce some"
      },
      {
        "start": 9519.96,
        "duration": 7.5,
        "text": "sort of bucketing uh where we have these"
      },
      {
        "start": 9523.68,
        "duration": 6.06,
        "text": "uh where we add one more field"
      },
      {
        "start": 9527.46,
        "duration": 5.04,
        "text": "to a partition key to be the month and"
      },
      {
        "start": 9529.74,
        "duration": 5.88,
        "text": "the year of when this recording was done"
      },
      {
        "start": 9532.5,
        "duration": 6.84,
        "text": "so that is the January of 2023 and then"
      },
      {
        "start": 9535.62,
        "duration": 6.359,
        "text": "this value will be 2023.01."
      },
      {
        "start": 9539.34,
        "duration": 6.44,
        "text": "then what happens then this month is"
      },
      {
        "start": 9541.979,
        "duration": 6.781,
        "text": "over and February starts so it will be"
      },
      {
        "start": 9545.78,
        "duration": 5.579,
        "text": "2023-02 that means what for the very"
      },
      {
        "start": 9548.76,
        "duration": 6.24,
        "text": "same sensor this value will be different"
      },
      {
        "start": 9551.359,
        "duration": 6.46,
        "text": "which brings us a new token and very for"
      },
      {
        "start": 9555.0,
        "duration": 4.859,
        "text": "a new Partition is created automatically"
      },
      {
        "start": 9557.819,
        "duration": 4.08,
        "text": "you don't have to think about it but"
      },
      {
        "start": 9559.859,
        "duration": 5.221,
        "text": "then just you have new Partition and it"
      },
      {
        "start": 9561.899,
        "duration": 5.101,
        "text": "all works uh on the new node and it's"
      },
      {
        "start": 9565.08,
        "duration": 3.96,
        "text": "scalable very forward when you will add"
      },
      {
        "start": 9567.0,
        "duration": 4.56,
        "text": "more servers will partition will move to"
      },
      {
        "start": 9569.04,
        "duration": 4.2,
        "text": "different places uh to different service"
      },
      {
        "start": 9571.56,
        "duration": 4.759,
        "text": "very well"
      },
      {
        "start": 9573.24,
        "duration": 7.26,
        "text": "sometimes people ask me why not to put"
      },
      {
        "start": 9576.319,
        "duration": 6.761,
        "text": "timestamp in the partition key or not"
      },
      {
        "start": 9580.5,
        "duration": 4.56,
        "text": "build your base it on month but pay"
      },
      {
        "start": 9583.08,
        "duration": 3.48,
        "text": "build it based on"
      },
      {
        "start": 9585.06,
        "duration": 3.54,
        "text": "um week"
      },
      {
        "start": 9586.56,
        "duration": 4.5,
        "text": "maybe day"
      },
      {
        "start": 9588.6,
        "duration": 6.24,
        "text": "maybe hour things like that don't forget"
      },
      {
        "start": 9591.06,
        "duration": 7.56,
        "text": "two access buttons write and read can I"
      },
      {
        "start": 9594.84,
        "duration": 6.599,
        "text": "write sensor ID month here yes I can can"
      },
      {
        "start": 9598.62,
        "duration": 6.12,
        "text": "I write sensor ID timestamp yes I can"
      },
      {
        "start": 9601.439,
        "duration": 7.021,
        "text": "but then second access pattern read"
      },
      {
        "start": 9604.74,
        "duration": 6.6,
        "text": "can I read sensor ID in month year if"
      },
      {
        "start": 9608.46,
        "duration": 5.64,
        "text": "customer asks me to show data values of"
      },
      {
        "start": 9611.34,
        "duration": 7.019,
        "text": "the sensor for last three months it will"
      },
      {
        "start": 9614.1,
        "duration": 5.879,
        "text": "be January December November so plus the"
      },
      {
        "start": 9618.359,
        "duration": 4.08,
        "text": "same sense already I will hit three"
      },
      {
        "start": 9619.979,
        "duration": 3.96,
        "text": "different partitions not a big deal it's"
      },
      {
        "start": 9622.439,
        "duration": 4.321,
        "text": "okay"
      },
      {
        "start": 9623.939,
        "duration": 6.601,
        "text": "but if I have my partitioning based on a"
      },
      {
        "start": 9626.76,
        "duration": 6.96,
        "text": "week or a day for free last months I"
      },
      {
        "start": 9630.54,
        "duration": 6.899,
        "text": "will need to hit like 90 plus partitions"
      },
      {
        "start": 9633.72,
        "duration": 6.719,
        "text": "that is obviously a bad idea foreign"
      },
      {
        "start": 9637.439,
        "duration": 3.0,
        "text": "partitions"
      },
      {
        "start": 9640.62,
        "duration": 6.84,
        "text": "imagine for our temperature recordings"
      },
      {
        "start": 9644.58,
        "duration": 5.52,
        "text": "we do partitioning like that date and"
      },
      {
        "start": 9647.46,
        "duration": 4.56,
        "text": "sensor with partitioning based on the"
      },
      {
        "start": 9650.1,
        "duration": 4.56,
        "text": "date current date"
      },
      {
        "start": 9652.02,
        "duration": 3.78,
        "text": "then take a look I have a cluster of 10"
      },
      {
        "start": 9654.66,
        "duration": 4.02,
        "text": "servers"
      },
      {
        "start": 9655.8,
        "duration": 4.98,
        "text": "and replication Factor free"
      },
      {
        "start": 9658.68,
        "duration": 6.299,
        "text": "so today"
      },
      {
        "start": 9660.78,
        "duration": 6.72,
        "text": "all sensors write to those free servers"
      },
      {
        "start": 9664.979,
        "duration": 4.441,
        "text": "servers are very busy because I have a"
      },
      {
        "start": 9667.5,
        "duration": 5.28,
        "text": "lot of sensors maybe billion of them"
      },
      {
        "start": 9669.42,
        "duration": 5.76,
        "text": "maybe multiple billions a lot of Rights"
      },
      {
        "start": 9672.78,
        "duration": 4.56,
        "text": "and servers are basically dying because"
      },
      {
        "start": 9675.18,
        "duration": 4.5,
        "text": "there's too much pressure on them they"
      },
      {
        "start": 9677.34,
        "duration": 4.5,
        "text": "cannot process all the queries and that"
      },
      {
        "start": 9679.68,
        "duration": 3.9,
        "text": "is a bad and then I think okay I work"
      },
      {
        "start": 9681.84,
        "duration": 5.04,
        "text": "for a big company we have a lot of money"
      },
      {
        "start": 9683.58,
        "duration": 6.18,
        "text": "we will buy 10 more servers so my"
      },
      {
        "start": 9686.88,
        "duration": 5.88,
        "text": "cluster will be 20 servers"
      },
      {
        "start": 9689.76,
        "duration": 5.639,
        "text": "and we do will that work"
      },
      {
        "start": 9692.76,
        "duration": 5.16,
        "text": "no that will not because despite now I"
      },
      {
        "start": 9695.399,
        "duration": 4.741,
        "text": "have 20 servers very same partitions"
      },
      {
        "start": 9697.92,
        "duration": 4.32,
        "text": "allocated on the very same server or"
      },
      {
        "start": 9700.14,
        "duration": 5.339,
        "text": "maybe new servers but it's still the"
      },
      {
        "start": 9702.24,
        "duration": 5.94,
        "text": "same free servers are overloaded because"
      },
      {
        "start": 9705.479,
        "duration": 4.981,
        "text": "of replication Factor free partition is"
      },
      {
        "start": 9708.18,
        "duration": 4.92,
        "text": "hot it's being accessed all the time"
      },
      {
        "start": 9710.46,
        "duration": 6.2,
        "text": "while all the other partitions are not"
      },
      {
        "start": 9713.1,
        "duration": 6.06,
        "text": "being accessed at all or only for reads"
      },
      {
        "start": 9716.66,
        "duration": 5.319,
        "text": "that means we need to think about the"
      },
      {
        "start": 9719.16,
        "duration": 5.4,
        "text": "size of a partition about how often"
      },
      {
        "start": 9721.979,
        "duration": 5.701,
        "text": "those partitions are being accessed in"
      },
      {
        "start": 9724.56,
        "duration": 5.52,
        "text": "the terms of Rights and reads avoid what"
      },
      {
        "start": 9727.68,
        "duration": 4.74,
        "text": "partitions partitions being accessed all"
      },
      {
        "start": 9730.08,
        "duration": 4.02,
        "text": "the time while others"
      },
      {
        "start": 9732.42,
        "duration": 4.32,
        "text": "are hiding"
      },
      {
        "start": 9734.1,
        "duration": 5.759,
        "text": "so this approach is much better because"
      },
      {
        "start": 9736.74,
        "duration": 5.94,
        "text": "when I need to scale I add more servers"
      },
      {
        "start": 9739.859,
        "duration": 5.161,
        "text": "and those workloads being distributed"
      },
      {
        "start": 9742.68,
        "duration": 6.139,
        "text": "across multiple servers each server has"
      },
      {
        "start": 9745.02,
        "duration": 3.799,
        "text": "less amount of queries per second"
      },
      {
        "start": 9748.92,
        "duration": 3.74,
        "text": "basically last question"
      },
      {
        "start": 9754.1,
        "duration": 5.14,
        "text": "uh all right"
      },
      {
        "start": 9757.38,
        "duration": 3.66,
        "text": "all right two last questions question"
      },
      {
        "start": 9759.24,
        "duration": 5.72,
        "text": "number eight"
      },
      {
        "start": 9761.04,
        "duration": 3.92,
        "text": "select without partition key"
      },
      {
        "start": 9765.62,
        "duration": 8.739,
        "text": "syntax error okay to get all data very"
      },
      {
        "start": 9769.859,
        "duration": 8.101,
        "text": "bad illegal and punishable by law"
      },
      {
        "start": 9774.359,
        "duration": 5.58,
        "text": "now as an officer of nosql police I have"
      },
      {
        "start": 9777.96,
        "duration": 5.76,
        "text": "to say what transfer number four is"
      },
      {
        "start": 9779.939,
        "duration": 5.161,
        "text": "right I will get to you in a resume if"
      },
      {
        "start": 9783.72,
        "duration": 4.759,
        "text": "you are trying to do select remote"
      },
      {
        "start": 9785.1,
        "duration": 3.379,
        "text": "partition key in Cassandra"
      },
      {
        "start": 9788.52,
        "duration": 5.94,
        "text": "yeah so now it's not a syntax server you"
      },
      {
        "start": 9791.88,
        "duration": 4.62,
        "text": "can do select without partition key you"
      },
      {
        "start": 9794.46,
        "duration": 5.22,
        "text": "will get a new role by default but it's"
      },
      {
        "start": 9796.5,
        "duration": 5.16,
        "text": "not a syntax error uh"
      },
      {
        "start": 9799.68,
        "duration": 4.32,
        "text": "and you can make select without"
      },
      {
        "start": 9801.66,
        "duration": 5.159,
        "text": "partition key working with a low"
      },
      {
        "start": 9804.0,
        "duration": 5.7,
        "text": "filtering uh statement but it's a bad"
      },
      {
        "start": 9806.819,
        "duration": 5.641,
        "text": "idea second it's okay to get all data no"
      },
      {
        "start": 9809.7,
        "duration": 6.119,
        "text": "it's not okay to get all data"
      },
      {
        "start": 9812.46,
        "duration": 5.34,
        "text": "uh it is indeed very bad its own"
      },
      {
        "start": 9815.819,
        "duration": 5.04,
        "text": "scenarios it might work if you use a low"
      },
      {
        "start": 9817.8,
        "duration": 5.22,
        "text": "filtering and last one uh whatever you"
      },
      {
        "start": 9820.859,
        "duration": 4.561,
        "text": "are whoever you are who said illegal and"
      },
      {
        "start": 9823.02,
        "duration": 5.6,
        "text": "punishable by law thank you so much like"
      },
      {
        "start": 9825.42,
        "duration": 3.2,
        "text": "and I'm all with you"
      },
      {
        "start": 9828.78,
        "duration": 4.8,
        "text": "uh good"
      },
      {
        "start": 9831.0,
        "duration": 4.92,
        "text": "and the last question for today question"
      },
      {
        "start": 9833.58,
        "duration": 4.38,
        "text": "number nine"
      },
      {
        "start": 9835.92,
        "duration": 4.439,
        "text": "is"
      },
      {
        "start": 9837.96,
        "duration": 5.16,
        "text": "what is the most important rule of"
      },
      {
        "start": 9840.359,
        "duration": 4.861,
        "text": "partition data"
      },
      {
        "start": 9843.12,
        "duration": 3.12,
        "text": "try to have as many partitions as"
      },
      {
        "start": 9845.22,
        "duration": 4.08,
        "text": "possible"
      },
      {
        "start": 9846.24,
        "duration": 5.88,
        "text": "in Partition size under control keep"
      },
      {
        "start": 9849.3,
        "duration": 7.74,
        "text": "together what you retrieve together and"
      },
      {
        "start": 9852.12,
        "duration": 4.92,
        "text": "last one make partitions bigger"
      },
      {
        "start": 9861.92,
        "duration": 5.08,
        "text": "okay don't make me angry don't pick"
      },
      {
        "start": 9865.26,
        "duration": 2.82,
        "text": "before okay thank you thank you thank"
      },
      {
        "start": 9867.0,
        "duration": 3.12,
        "text": "you yes"
      },
      {
        "start": 9868.08,
        "duration": 4.08,
        "text": "so no"
      },
      {
        "start": 9870.12,
        "duration": 4.68,
        "text": "came together what you retrieve together"
      },
      {
        "start": 9872.16,
        "duration": 5.58,
        "text": "is a question of convenience it's"
      },
      {
        "start": 9874.8,
        "duration": 5.48,
        "text": "important rule it may be very helpful on"
      },
      {
        "start": 9877.74,
        "duration": 5.64,
        "text": "the read time that is a very good group"
      },
      {
        "start": 9880.28,
        "duration": 7.3,
        "text": "but uh when your cluster is operational"
      },
      {
        "start": 9883.38,
        "duration": 6.66,
        "text": "you can remodel it you can create"
      },
      {
        "start": 9887.58,
        "duration": 5.279,
        "text": "um new tables you can migrate your data"
      },
      {
        "start": 9890.04,
        "duration": 6.72,
        "text": "but when your partitions went crazy size"
      },
      {
        "start": 9892.859,
        "duration": 5.701,
        "text": "and you your nodes just irresponsive and"
      },
      {
        "start": 9896.76,
        "duration": 4.139,
        "text": "you cannot do anything that is a really"
      },
      {
        "start": 9898.56,
        "duration": 5.16,
        "text": "bad situation so the most important rule"
      },
      {
        "start": 9900.899,
        "duration": 5.58,
        "text": "is key partition size or under control"
      },
      {
        "start": 9903.72,
        "duration": 4.8,
        "text": "don't make the big card partitions or"
      },
      {
        "start": 9906.479,
        "duration": 4.681,
        "text": "avoid big partitions avoid hold"
      },
      {
        "start": 9908.52,
        "duration": 5.16,
        "text": "partitions that brings us to the last"
      },
      {
        "start": 9911.16,
        "duration": 4.52,
        "text": "slide of the quiz who made the best work"
      },
      {
        "start": 9913.68,
        "duration": 6.24,
        "text": "answering questions"
      },
      {
        "start": 9915.68,
        "duration": 7.36,
        "text": "and like each question uh worth 9 000"
      },
      {
        "start": 9919.92,
        "duration": 6.979,
        "text": "points so many thanks to the judge Kumar"
      },
      {
        "start": 9923.04,
        "duration": 8.16,
        "text": "with uh seven right answers then James"
      },
      {
        "start": 9926.899,
        "duration": 6.58,
        "text": "melroy Natalia Sultan Bell evil ranji"
      },
      {
        "start": 9931.2,
        "duration": 6.0,
        "text": "Twitter and JD thank you so much for"
      },
      {
        "start": 9933.479,
        "duration": 6.42,
        "text": "making it and uh Tejas Kumar that was"
      },
      {
        "start": 9937.2,
        "duration": 4.279,
        "text": "incredible job"
      },
      {
        "start": 9939.899,
        "duration": 4.741,
        "text": "perfect"
      },
      {
        "start": 9941.479,
        "duration": 5.92,
        "text": "uh V that"
      },
      {
        "start": 9944.64,
        "duration": 3.719,
        "text": "thank you for participating you are the"
      },
      {
        "start": 9947.399,
        "duration": 5.161,
        "text": "best"
      },
      {
        "start": 9948.359,
        "duration": 6.96,
        "text": "uh I think uh what do you think if we"
      },
      {
        "start": 9952.56,
        "duration": 5.04,
        "text": "keep a last step of the homework to be"
      },
      {
        "start": 9955.319,
        "duration": 3.841,
        "text": "the homework that is the first step of"
      },
      {
        "start": 9957.6,
        "duration": 2.94,
        "text": "the homework it's assigned to be"
      },
      {
        "start": 9959.16,
        "duration": 3.84,
        "text": "homework"
      },
      {
        "start": 9960.54,
        "duration": 5.58,
        "text": "yeah I I don't mind because it's it's"
      },
      {
        "start": 9963.0,
        "duration": 6.479,
        "text": "very easy and and the instructions are"
      },
      {
        "start": 9966.12,
        "duration": 4.699,
        "text": "quite comprehensive so"
      },
      {
        "start": 9969.479,
        "duration": 4.741,
        "text": "yeah"
      },
      {
        "start": 9970.819,
        "duration": 6.0,
        "text": "updates deletes and and selects"
      },
      {
        "start": 9974.22,
        "duration": 2.599,
        "text": "yeah"
      },
      {
        "start": 9976.939,
        "duration": 4.661,
        "text": "uh there is a good question from James"
      },
      {
        "start": 9979.26,
        "duration": 5.099,
        "text": "Wong do we need to constantly archive"
      },
      {
        "start": 9981.6,
        "duration": 5.879,
        "text": "all data to keep database clean I guess"
      },
      {
        "start": 9984.359,
        "duration": 7.141,
        "text": "so James uh first of all Cassandra has"
      },
      {
        "start": 9987.479,
        "duration": 6.541,
        "text": "native uh Tool uh to uh wipe out old"
      },
      {
        "start": 9991.5,
        "duration": 6.06,
        "text": "data if you don't need it so for example"
      },
      {
        "start": 9994.02,
        "duration": 6.48,
        "text": "if you define what you're not going to"
      },
      {
        "start": 9997.56,
        "duration": 6.66,
        "text": "need temperature recordings for longer"
      },
      {
        "start": 10000.5,
        "duration": 7.319,
        "text": "than uh for uh for one year or more"
      },
      {
        "start": 10004.22,
        "duration": 6.9,
        "text": "uh you can creating or writing data you"
      },
      {
        "start": 10007.819,
        "duration": 5.881,
        "text": "can specify GTL time to leave so this"
      },
      {
        "start": 10011.12,
        "duration": 5.4,
        "text": "data will be automatically deleted then"
      },
      {
        "start": 10013.7,
        "duration": 3.659,
        "text": "this time is expired which is pretty"
      },
      {
        "start": 10016.52,
        "duration": 4.08,
        "text": "cool"
      },
      {
        "start": 10017.359,
        "duration": 4.561,
        "text": "uh and uh but in some scenarios you do"
      },
      {
        "start": 10020.6,
        "duration": 4.379,
        "text": "need"
      },
      {
        "start": 10021.92,
        "duration": 6.059,
        "text": "to keep data for longer times and you do"
      },
      {
        "start": 10024.979,
        "duration": 5.521,
        "text": "want to keep it still under control in"
      },
      {
        "start": 10027.979,
        "duration": 6.781,
        "text": "some scenarios you indeed may want to"
      },
      {
        "start": 10030.5,
        "duration": 6.6,
        "text": "unload some old data put it on AWS S3 or"
      },
      {
        "start": 10034.76,
        "duration": 4.86,
        "text": "some another kind of a cold storage if"
      },
      {
        "start": 10037.1,
        "duration": 4.68,
        "text": "you are not going to access it often and"
      },
      {
        "start": 10039.62,
        "duration": 5.22,
        "text": "you will be fine with that but the story"
      },
      {
        "start": 10041.78,
        "duration": 5.1,
        "text": "is you don't necessarily have to like if"
      },
      {
        "start": 10044.84,
        "duration": 3.96,
        "text": "you're going to really read this data"
      },
      {
        "start": 10046.88,
        "duration": 3.72,
        "text": "from time to time and access this data"
      },
      {
        "start": 10048.8,
        "duration": 3.679,
        "text": "from time to time then it may be"
      },
      {
        "start": 10050.6,
        "duration": 5.219,
        "text": "perfectly fine to"
      },
      {
        "start": 10052.479,
        "duration": 6.101,
        "text": "just uh keep it better as long as your"
      },
      {
        "start": 10055.819,
        "duration": 5.16,
        "text": "partitions are designed it well and you"
      },
      {
        "start": 10058.58,
        "duration": 4.56,
        "text": "need to store more data don't forget you"
      },
      {
        "start": 10060.979,
        "duration": 5.34,
        "text": "want to store more data add more nodes"
      },
      {
        "start": 10063.14,
        "duration": 6.48,
        "text": "and it will be scaled automatically that"
      },
      {
        "start": 10066.319,
        "duration": 5.701,
        "text": "is uh like very typical thing good"
      },
      {
        "start": 10069.62,
        "duration": 5.04,
        "text": "question from Andrei there is a tool for"
      },
      {
        "start": 10072.02,
        "duration": 3.24,
        "text": "archiving gesture so"
      },
      {
        "start": 10074.66,
        "duration": 6.0,
        "text": "um"
      },
      {
        "start": 10075.26,
        "duration": 7.26,
        "text": "two recently uh our published well cow"
      },
      {
        "start": 10080.66,
        "duration": 4.98,
        "text": "recently some years ago were published"
      },
      {
        "start": 10082.52,
        "duration": 6.14,
        "text": "by data Stacks call it DS bulk"
      },
      {
        "start": 10085.64,
        "duration": 6.42,
        "text": "uh Diaz bulk"
      },
      {
        "start": 10088.66,
        "duration": 6.76,
        "text": "for some scenarios you might want to use"
      },
      {
        "start": 10092.06,
        "duration": 6.0,
        "text": "a patch spark to get some more advanced"
      },
      {
        "start": 10095.42,
        "duration": 4.979,
        "text": "access to data"
      },
      {
        "start": 10098.06,
        "duration": 5.16,
        "text": "um yeah and things like that"
      },
      {
        "start": 10100.399,
        "duration": 5.341,
        "text": "uh thank you so much for uh thank you so"
      },
      {
        "start": 10103.22,
        "duration": 5.16,
        "text": "much to Jeff Kumar for your kind words"
      },
      {
        "start": 10105.74,
        "duration": 4.8,
        "text": "yeah Billy do we do have all the"
      },
      {
        "start": 10108.38,
        "duration": 6.0,
        "text": "recordings for this and other workshops"
      },
      {
        "start": 10110.54,
        "duration": 6.54,
        "text": "same link so coming in"
      },
      {
        "start": 10114.38,
        "duration": 5.7,
        "text": "after some data is deleted how is that"
      },
      {
        "start": 10117.08,
        "duration": 6.359,
        "text": "reordered on the physical level oh great"
      },
      {
        "start": 10120.08,
        "duration": 6.3,
        "text": "question Evo rumbaldem"
      },
      {
        "start": 10123.439,
        "duration": 5.821,
        "text": "a very good question that's completely"
      },
      {
        "start": 10126.38,
        "duration": 5.58,
        "text": "out of scope for today's Workshop but in"
      },
      {
        "start": 10129.26,
        "duration": 5.76,
        "text": "short there is a process similar to"
      },
      {
        "start": 10131.96,
        "duration": 4.26,
        "text": "vacuuming in relational databases uh"
      },
      {
        "start": 10135.02,
        "duration": 6.18,
        "text": "call it"
      },
      {
        "start": 10136.22,
        "duration": 8.4,
        "text": "um compassion compaction comes in order"
      },
      {
        "start": 10141.2,
        "duration": 5.159,
        "text": "um regularly to clean up deleted data to"
      },
      {
        "start": 10144.62,
        "duration": 4.44,
        "text": "clean up um"
      },
      {
        "start": 10146.359,
        "duration": 6.601,
        "text": "updated information what is not in the"
      },
      {
        "start": 10149.06,
        "duration": 6.36,
        "text": "previous version the story is like a U.S"
      },
      {
        "start": 10152.96,
        "duration": 5.1,
        "text": "state do you you are here every past you"
      },
      {
        "start": 10155.42,
        "duration": 5.76,
        "text": "have a very very end even out even over"
      },
      {
        "start": 10158.06,
        "duration": 4.74,
        "text": "time so I want to open some secrets"
      },
      {
        "start": 10161.18,
        "duration": 4.86,
        "text": "story is"
      },
      {
        "start": 10162.8,
        "duration": 6.3,
        "text": "Cassandra is extremely fast for rights"
      },
      {
        "start": 10166.04,
        "duration": 6.3,
        "text": "but it requires requires some very"
      },
      {
        "start": 10169.1,
        "duration": 5.82,
        "text": "Advanced optimizations on right buff"
      },
      {
        "start": 10172.34,
        "duration": 4.68,
        "text": "then you write data some very Advanced"
      },
      {
        "start": 10174.92,
        "duration": 5.0,
        "text": "temporary optimizations"
      },
      {
        "start": 10177.02,
        "duration": 2.9,
        "text": "one of them"
      },
      {
        "start": 10180.859,
        "duration": 3.061,
        "text": "um"
      },
      {
        "start": 10181.52,
        "duration": 5.04,
        "text": "very interesting take a look in"
      },
      {
        "start": 10183.92,
        "duration": 5.42,
        "text": "Cassandra insert"
      },
      {
        "start": 10186.56,
        "duration": 6.72,
        "text": "update and delete"
      },
      {
        "start": 10189.34,
        "duration": 7.36,
        "text": "exactly the same operation internally"
      },
      {
        "start": 10193.28,
        "duration": 5.4,
        "text": "now you might be surprised insert or"
      },
      {
        "start": 10196.7,
        "duration": 5.159,
        "text": "update our same operation okay that's"
      },
      {
        "start": 10198.68,
        "duration": 6.299,
        "text": "understandable but how come Delete is"
      },
      {
        "start": 10201.859,
        "duration": 6.061,
        "text": "the same operation the story is when we"
      },
      {
        "start": 10204.979,
        "duration": 4.641,
        "text": "write data what is the slowest operation"
      },
      {
        "start": 10207.92,
        "duration": 4.86,
        "text": "in"
      },
      {
        "start": 10209.62,
        "duration": 6.34,
        "text": "software development in software uh"
      },
      {
        "start": 10212.78,
        "duration": 6.18,
        "text": "operations in general it's changing data"
      },
      {
        "start": 10215.96,
        "duration": 6.0,
        "text": "on disk any kind of disk operations"
      },
      {
        "start": 10218.96,
        "duration": 5.6,
        "text": "but especially changing something so you"
      },
      {
        "start": 10221.96,
        "duration": 6.2,
        "text": "need to find you need to update"
      },
      {
        "start": 10224.56,
        "duration": 6.46,
        "text": "you need to move like a lot of things"
      },
      {
        "start": 10228.16,
        "duration": 5.26,
        "text": "it's slow Cassandra designed it to be"
      },
      {
        "start": 10231.02,
        "duration": 5.58,
        "text": "very fast so every time you do anything"
      },
      {
        "start": 10233.42,
        "duration": 7.019,
        "text": "any mutation with your data it's always"
      },
      {
        "start": 10236.6,
        "duration": 6.36,
        "text": "append only operation what goes on the"
      },
      {
        "start": 10240.439,
        "duration": 7.981,
        "text": "bottom let's say of things"
      },
      {
        "start": 10242.96,
        "duration": 8.34,
        "text": "and uh over time you get info formation"
      },
      {
        "start": 10248.42,
        "duration": 5.7,
        "text": "uh like uh being stored too much time"
      },
      {
        "start": 10251.3,
        "duration": 4.92,
        "text": "first value update for the same value"
      },
      {
        "start": 10254.12,
        "duration": 4.38,
        "text": "update for the same value and then"
      },
      {
        "start": 10256.22,
        "duration": 4.679,
        "text": "finally it's deleted you don't sell"
      },
      {
        "start": 10258.5,
        "duration": 4.8,
        "text": "these uh think anymore and you don't"
      },
      {
        "start": 10260.899,
        "duration": 4.861,
        "text": "want to store its data and you want to"
      },
      {
        "start": 10263.3,
        "duration": 4.559,
        "text": "retrieve some disk space"
      },
      {
        "start": 10265.76,
        "duration": 5.46,
        "text": "that as a result it will be original"
      },
      {
        "start": 10267.859,
        "duration": 5.701,
        "text": "value new value next value and dump"
      },
      {
        "start": 10271.22,
        "duration": 4.86,
        "text": "Stone dump stone is a special marker"
      },
      {
        "start": 10273.56,
        "duration": 5.1,
        "text": "what this data has been deleted"
      },
      {
        "start": 10276.08,
        "duration": 4.5,
        "text": "so you have basically poor entries for"
      },
      {
        "start": 10278.66,
        "duration": 4.319,
        "text": "the same data although technically it's"
      },
      {
        "start": 10280.58,
        "duration": 4.92,
        "text": "kind of deleted compaction is the"
      },
      {
        "start": 10282.979,
        "duration": 6.301,
        "text": "process what takes these immutable files"
      },
      {
        "start": 10285.5,
        "duration": 6.96,
        "text": "those files are called SS tables"
      },
      {
        "start": 10289.28,
        "duration": 5.699,
        "text": "um sorted string table files and then it"
      },
      {
        "start": 10292.46,
        "duration": 4.8,
        "text": "makes compaction on them removing all"
      },
      {
        "start": 10294.979,
        "duration": 5.161,
        "text": "the old values removing all the dumb"
      },
      {
        "start": 10297.26,
        "duration": 5.94,
        "text": "Stones deleting all data and writing a"
      },
      {
        "start": 10300.14,
        "duration": 5.42,
        "text": "new file on disk which now will be it"
      },
      {
        "start": 10303.2,
        "duration": 6.0,
        "text": "alone and the old files will be deleted"
      },
      {
        "start": 10305.56,
        "duration": 7.299,
        "text": "this process happens in background"
      },
      {
        "start": 10309.2,
        "duration": 5.94,
        "text": "uh so uh you don't encounter it when you"
      },
      {
        "start": 10312.859,
        "duration": 4.5,
        "text": "originally write on read date it happens"
      },
      {
        "start": 10315.14,
        "duration": 4.62,
        "text": "in background"
      },
      {
        "start": 10317.359,
        "duration": 4.62,
        "text": "um and that is a story how insert update"
      },
      {
        "start": 10319.76,
        "duration": 5.46,
        "text": "and delete are the same operation"
      },
      {
        "start": 10321.979,
        "duration": 7.321,
        "text": "internally and that is just one of the"
      },
      {
        "start": 10325.22,
        "duration": 6.679,
        "text": "many cool uh optimizations inside the"
      },
      {
        "start": 10329.3,
        "duration": 2.599,
        "text": "Cassandra"
      },
      {
        "start": 10332.42,
        "duration": 4.1,
        "text": "I hope I answered this question evil"
      },
      {
        "start": 10336.56,
        "duration": 5.219,
        "text": "what happened if there is a Mis"
      },
      {
        "start": 10339.26,
        "duration": 4.32,
        "text": "inconsistent data read is there a way to"
      },
      {
        "start": 10341.779,
        "duration": 4.62,
        "text": "acknowledge or recover"
      },
      {
        "start": 10343.58,
        "duration": 4.56,
        "text": "so when we read data so it depends on"
      },
      {
        "start": 10346.399,
        "duration": 5.101,
        "text": "your consistency level"
      },
      {
        "start": 10348.14,
        "duration": 6.24,
        "text": "if you read datum"
      },
      {
        "start": 10351.5,
        "duration": 5.819,
        "text": "and then you require consistency level"
      },
      {
        "start": 10354.38,
        "duration": 5.82,
        "text": "Quorum or all or can see any consistency"
      },
      {
        "start": 10357.319,
        "duration": 6.241,
        "text": "level high enough and then"
      },
      {
        "start": 10360.2,
        "duration": 5.88,
        "text": "node sees query coordinator sees what"
      },
      {
        "start": 10363.56,
        "duration": 5.94,
        "text": "someone is outdated then query"
      },
      {
        "start": 10366.08,
        "duration": 5.399,
        "text": "coordinator will initiate repair and"
      },
      {
        "start": 10369.5,
        "duration": 5.399,
        "text": "consistency will be recovered it happens"
      },
      {
        "start": 10371.479,
        "duration": 5.521,
        "text": "in background it's automated"
      },
      {
        "start": 10374.899,
        "duration": 4.261,
        "text": "um but if you read with consistency"
      },
      {
        "start": 10377.0,
        "duration": 6.18,
        "text": "level low if you read with consistency"
      },
      {
        "start": 10379.16,
        "duration": 6.54,
        "text": "level 1 for example and your node stores"
      },
      {
        "start": 10383.18,
        "duration": 4.86,
        "text": "in consistent information then you will"
      },
      {
        "start": 10385.7,
        "duration": 5.34,
        "text": "get inconsistent information and that"
      },
      {
        "start": 10388.04,
        "duration": 6.66,
        "text": "might happen if you use two upgrades of"
      },
      {
        "start": 10391.04,
        "duration": 7.76,
        "text": "consistency levels like one for example"
      },
      {
        "start": 10394.7,
        "duration": 4.1,
        "text": "so you have to be careful with that"
      },
      {
        "start": 10399.5,
        "duration": 4.26,
        "text": "um does this method not preserve a meant"
      },
      {
        "start": 10402.5,
        "duration": 3.96,
        "text": "order"
      },
      {
        "start": 10403.76,
        "duration": 5.639,
        "text": "um so this method compaction indeed"
      },
      {
        "start": 10406.46,
        "duration": 7.34,
        "text": "preserves cement order it preserves the"
      },
      {
        "start": 10409.399,
        "duration": 7.261,
        "text": "order defined by clustering columns"
      },
      {
        "start": 10413.8,
        "duration": 6.04,
        "text": "does Cassandra support updating multiple"
      },
      {
        "start": 10416.66,
        "duration": 5.58,
        "text": "roles in a single query a short answer"
      },
      {
        "start": 10419.84,
        "duration": 6.78,
        "text": "is"
      },
      {
        "start": 10422.24,
        "duration": 7.44,
        "text": "it's complicated because you see if"
      },
      {
        "start": 10426.62,
        "duration": 7.02,
        "text": "roads are in different partitions they"
      },
      {
        "start": 10429.68,
        "duration": 5.759,
        "text": "will belong to different servers and"
      },
      {
        "start": 10433.64,
        "duration": 3.32,
        "text": "that is going to be a totally different"
      },
      {
        "start": 10435.439,
        "duration": 3.84,
        "text": "story"
      },
      {
        "start": 10436.96,
        "duration": 4.479,
        "text": "so you"
      },
      {
        "start": 10439.279,
        "duration": 6.361,
        "text": "can actually"
      },
      {
        "start": 10441.439,
        "duration": 6.601,
        "text": "Arjun if I'm trying to make an update I"
      },
      {
        "start": 10445.64,
        "duration": 5.52,
        "text": "have to specify partition key"
      },
      {
        "start": 10448.04,
        "duration": 5.46,
        "text": "yeah well so yes answer is yes yes well"
      },
      {
        "start": 10451.16,
        "duration": 5.46,
        "text": "well uh okay so"
      },
      {
        "start": 10453.5,
        "duration": 5.52,
        "text": "it's not gonna be in One update"
      },
      {
        "start": 10456.62,
        "duration": 5.12,
        "text": "statement so you you will have to issue"
      },
      {
        "start": 10459.02,
        "duration": 6.419,
        "text": "multiple updates state state statements"
      },
      {
        "start": 10461.74,
        "duration": 6.22,
        "text": "but uh the internally"
      },
      {
        "start": 10465.439,
        "duration": 4.201,
        "text": "if those update or insert statements"
      },
      {
        "start": 10467.96,
        "duration": 4.62,
        "text": "belong to the same partition internal"
      },
      {
        "start": 10469.64,
        "duration": 6.42,
        "text": "optimization will do that update as as"
      },
      {
        "start": 10472.58,
        "duration": 6.66,
        "text": "one single single update even so you"
      },
      {
        "start": 10476.06,
        "duration": 6.419,
        "text": "issued multiple update statements and"
      },
      {
        "start": 10479.24,
        "duration": 6.48,
        "text": "there is a corner case uh static columns"
      },
      {
        "start": 10482.479,
        "duration": 6.661,
        "text": "if you update a static column in in in"
      },
      {
        "start": 10485.72,
        "duration": 4.92,
        "text": "the partition all rows will be affected"
      },
      {
        "start": 10489.14,
        "duration": 5.06,
        "text": "yeah"
      },
      {
        "start": 10490.64,
        "duration": 3.56,
        "text": "so short answer is yes"
      },
      {
        "start": 10494.479,
        "duration": 3.8,
        "text": "uh good so it looks like there are no"
      },
      {
        "start": 10497.12,
        "duration": 5.04,
        "text": "more questions"
      },
      {
        "start": 10498.279,
        "duration": 7.481,
        "text": "then I proceed to the very last slide"
      },
      {
        "start": 10502.16,
        "duration": 7.5,
        "text": "what's next homework is to finish the"
      },
      {
        "start": 10505.76,
        "duration": 7.74,
        "text": "Hands-On lab and submit your uh homework"
      },
      {
        "start": 10509.66,
        "duration": 7.86,
        "text": "for this Workshop using the link which"
      },
      {
        "start": 10513.5,
        "duration": 6.54,
        "text": "is mentioned in the GitHub repo you will"
      },
      {
        "start": 10517.52,
        "duration": 5.82,
        "text": "find it in the homework part"
      },
      {
        "start": 10520.04,
        "duration": 6.3,
        "text": "uh links you might want to have our"
      },
      {
        "start": 10523.34,
        "duration": 5.16,
        "text": "Discord server to talk to us and to have"
      },
      {
        "start": 10526.34,
        "duration": 8.599,
        "text": "us answering your questions in between"
      },
      {
        "start": 10528.5,
        "duration": 6.439,
        "text": "of workshops esport I'm showing it https"
      },
      {
        "start": 10534.979,
        "duration": 6.0,
        "text": "um yep Academy so if you decide what yes"
      },
      {
        "start": 10538.819,
        "duration": 4.561,
        "text": "you want to work with Cassandra it's"
      },
      {
        "start": 10540.979,
        "duration": 4.081,
        "text": "powerful it probably going to make me"
      },
      {
        "start": 10543.38,
        "duration": 3.899,
        "text": "some money and very interesting"
      },
      {
        "start": 10545.06,
        "duration": 4.379,
        "text": "technology to work with then you can"
      },
      {
        "start": 10547.279,
        "duration": 4.561,
        "text": "proceed at the academy.dentastacks.com"
      },
      {
        "start": 10549.439,
        "duration": 4.741,
        "text": "to get your developer path or"
      },
      {
        "start": 10551.84,
        "duration": 5.46,
        "text": "administrator path and get certified for"
      },
      {
        "start": 10554.18,
        "duration": 5.42,
        "text": "free link for the workshops is on the"
      },
      {
        "start": 10557.3,
        "duration": 6.84,
        "text": "screen see you next week"
      },
      {
        "start": 10559.6,
        "duration": 7.24,
        "text": "uh one more time if okay in case you"
      },
      {
        "start": 10564.14,
        "duration": 5.46,
        "text": "missed that I posted already links to"
      },
      {
        "start": 10566.84,
        "duration": 6.12,
        "text": "our LinkedIn so if you aren't in then"
      },
      {
        "start": 10569.6,
        "duration": 6.32,
        "text": "please jump in and add us on LinkedIn"
      },
      {
        "start": 10572.96,
        "duration": 7.68,
        "text": "always pleasure to answer your questions"
      },
      {
        "start": 10575.92,
        "duration": 6.04,
        "text": "uh with that that was our job and Alex"
      },
      {
        "start": 10580.64,
        "duration": 3.36,
        "text": "wolship"
      },
      {
        "start": 10581.96,
        "duration": 4.74,
        "text": "thank you thank you for being with us"
      },
      {
        "start": 10584.0,
        "duration": 4.8,
        "text": "and see you next week then it will be a"
      },
      {
        "start": 10586.7,
        "duration": 4.88,
        "text": "comment uh who will be with you tomorrow"
      },
      {
        "start": 10588.8,
        "duration": 2.78,
        "text": "or next week"
      },
      {
        "start": 10591.7,
        "duration": 7.6,
        "text": "we won the chat today yes yeah and uh a"
      },
      {
        "start": 10595.88,
        "duration": 7.979,
        "text": "great expert book author or like one of"
      },
      {
        "start": 10599.3,
        "duration": 6.72,
        "text": "the best experts in the Cassandra field"
      },
      {
        "start": 10603.859,
        "duration": 5.281,
        "text": "so you are like him"
      },
      {
        "start": 10606.02,
        "duration": 4.799,
        "text": "then uh good luck so don't forget to"
      },
      {
        "start": 10609.14,
        "duration": 5.9,
        "text": "submit your homework and see you next"
      },
      {
        "start": 10610.819,
        "duration": 4.221,
        "text": "week see you next week thank you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T18:20:58.843657+00:00"
}