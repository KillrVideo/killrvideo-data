{
  "video_id": "kbLvKiT9ITE",
  "title": "DS320.46 Spark SQL: Querying Cassandra with SQL | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.46 Spark SQL: Querying Cassandra with SQL\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:34:33Z",
  "thumbnail": "https://i.ytimg.com/vi/kbLvKiT9ITE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "query",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=kbLvKiT9ITE",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] let's take a look at a few more useful tools in the data frame api that are going to come in handy when we're executing sql queries against spark some of these we've touched on before some of them we haven't let's just walk through and see what kind of things we can learn on the cassandra sql context object if you don't want to keep specifying the key space you can set that explicitly you can call set key space and kind of pin that to a particular key space for all subsequent operations on that object of course there's the sql method that we've been looking at it has an alias cassandra sql those are equivalent you pass either one of those a spark sql query that's going to run against cassandra tables or potentially other data frames that you've created about that idea of another data frame participating in a sql query we get that done with the register temp table method now imagine through some process you've got a data frame you probably started by querying a cassandra table you did some other stuff to it maybe you manipulated it through the data frame api any of those things is an option but you've got this data frame and you've got another spark sql query you want to execute that operates partially on that data frame well you can register that as a temporary table and then it participates as a table in future sql queries it doesn't exist in cassandra it's not persisted anywhere but in spark but this is super handy if you've got a data frame lying around that you want to be able to act like a real table going forward the explain method is going to print out to the console the plan that spark is going to execute to actually compute that data frame when computation is forced by an action this is a lot like the familiar explain plan from the relational world it's a key step in optimizing a spark sql query and of course you will have to understand enough about sparks internal architecture and how it distributes computational work throughout a cluster to make sense of what explain tells you but of course we cover that in other sections and you should be pretty well equipped if you've gone over that stuff to understand the output of explain here's set key space in action you can see it's pretty simple we call it on the cassandra sql context object and then in the subsequent sql query we don't need to indicate the key space we can just kind of go on our way with that key space having been set but this example isn't trivial take a look at the query we're executing we're looking for a list of actors and the highest rating they've obtained in any film they've been in that's that's what this query is going to give us and the data frame is called max df in our shell that's important because in our next example we register this as a temp table we call it max rating and in the query that we go on to execute that's a slightly complex query but let's see we're selecting actor title release here rating from max rating inner joined to movies by actor see the join takes place there and we rename the tables in the join we join on the common actor what we want here is all of the films in the movies table that have a rating within 1.0 of the max rating that that actor has obtained this is easy since we had that max readings data frame lying around we get to treat it like a table it's a normal sql join and as joins go it's really not all that complex so what would have been a difficult computation is made very familiar and very easy by spark sql and now that we have a somewhat interesting query happening it's worthwhile trying and explain and here is what actual output from the explain method would look like you're welcome to pause the video and walk through each one of those steps and get an idea of what spark is doing to get the job done as i said really to understand this you do have to have a decent grasp of the internals and how spark distributes work around the cluster but with a little bit of that in hand you can make sense of this so those are just a few extra tools that are going to come in handy when you're querying cassandra with spark sql you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 7.44,
        "duration": 2.4,
        "text": "let's take a look at a few more useful"
      },
      {
        "start": 9.2,
        "duration": 2.559,
        "text": "tools"
      },
      {
        "start": 9.84,
        "duration": 3.52,
        "text": "in the data frame api that are going to"
      },
      {
        "start": 11.759,
        "duration": 2.161,
        "text": "come in handy when we're executing sql"
      },
      {
        "start": 13.36,
        "duration": 2.08,
        "text": "queries"
      },
      {
        "start": 13.92,
        "duration": 2.96,
        "text": "against spark some of these we've"
      },
      {
        "start": 15.44,
        "duration": 2.72,
        "text": "touched on before some of them we"
      },
      {
        "start": 16.88,
        "duration": 2.96,
        "text": "haven't let's just walk through"
      },
      {
        "start": 18.16,
        "duration": 3.76,
        "text": "and see what kind of things we can learn"
      },
      {
        "start": 19.84,
        "duration": 3.679,
        "text": "on the cassandra sql context"
      },
      {
        "start": 21.92,
        "duration": 3.04,
        "text": "object if you don't want to keep"
      },
      {
        "start": 23.519,
        "duration": 3.121,
        "text": "specifying the key space"
      },
      {
        "start": 24.96,
        "duration": 3.36,
        "text": "you can set that explicitly you can call"
      },
      {
        "start": 26.64,
        "duration": 3.44,
        "text": "set key space and"
      },
      {
        "start": 28.32,
        "duration": 3.6,
        "text": "kind of pin that to a particular key"
      },
      {
        "start": 30.08,
        "duration": 4.319,
        "text": "space for all subsequent operations"
      },
      {
        "start": 31.92,
        "duration": 3.92,
        "text": "on that object of course there's the sql"
      },
      {
        "start": 34.399,
        "duration": 4.0,
        "text": "method that we've been looking at"
      },
      {
        "start": 35.84,
        "duration": 3.12,
        "text": "it has an alias cassandra sql those are"
      },
      {
        "start": 38.399,
        "duration": 2.881,
        "text": "equivalent"
      },
      {
        "start": 38.96,
        "duration": 3.36,
        "text": "you pass either one of those a spark sql"
      },
      {
        "start": 41.28,
        "duration": 3.759,
        "text": "query that's going to run"
      },
      {
        "start": 42.32,
        "duration": 3.759,
        "text": "against cassandra tables or potentially"
      },
      {
        "start": 45.039,
        "duration": 2.961,
        "text": "other data frames"
      },
      {
        "start": 46.079,
        "duration": 3.601,
        "text": "that you've created about that idea of"
      },
      {
        "start": 48.0,
        "duration": 2.559,
        "text": "another data frame participating in a"
      },
      {
        "start": 49.68,
        "duration": 3.199,
        "text": "sql query"
      },
      {
        "start": 50.559,
        "duration": 3.281,
        "text": "we get that done with the register temp"
      },
      {
        "start": 52.879,
        "duration": 2.961,
        "text": "table method"
      },
      {
        "start": 53.84,
        "duration": 3.12,
        "text": "now imagine through some process you've"
      },
      {
        "start": 55.84,
        "duration": 2.559,
        "text": "got a data frame"
      },
      {
        "start": 56.96,
        "duration": 3.439,
        "text": "you probably started by querying a"
      },
      {
        "start": 58.399,
        "duration": 2.8,
        "text": "cassandra table you did some other stuff"
      },
      {
        "start": 60.399,
        "duration": 2.48,
        "text": "to it maybe"
      },
      {
        "start": 61.199,
        "duration": 3.761,
        "text": "you manipulated it through the data"
      },
      {
        "start": 62.879,
        "duration": 2.64,
        "text": "frame api any of those things is an"
      },
      {
        "start": 64.96,
        "duration": 2.24,
        "text": "option"
      },
      {
        "start": 65.519,
        "duration": 3.841,
        "text": "but you've got this data frame and"
      },
      {
        "start": 67.2,
        "duration": 3.04,
        "text": "you've got another spark sql query you"
      },
      {
        "start": 69.36,
        "duration": 3.28,
        "text": "want to execute"
      },
      {
        "start": 70.24,
        "duration": 3.199,
        "text": "that operates partially on that data"
      },
      {
        "start": 72.64,
        "duration": 2.24,
        "text": "frame"
      },
      {
        "start": 73.439,
        "duration": 3.68,
        "text": "well you can register that as a"
      },
      {
        "start": 74.88,
        "duration": 4.48,
        "text": "temporary table and then it participates"
      },
      {
        "start": 77.119,
        "duration": 3.921,
        "text": "as a table in future sql queries"
      },
      {
        "start": 79.36,
        "duration": 3.439,
        "text": "it doesn't exist in cassandra it's not"
      },
      {
        "start": 81.04,
        "duration": 3.28,
        "text": "persisted anywhere but in spark"
      },
      {
        "start": 82.799,
        "duration": 3.281,
        "text": "but this is super handy if you've got a"
      },
      {
        "start": 84.32,
        "duration": 3.92,
        "text": "data frame lying around that you want to"
      },
      {
        "start": 86.08,
        "duration": 3.999,
        "text": "be able to act like a real table"
      },
      {
        "start": 88.24,
        "duration": 3.36,
        "text": "going forward the explain method is"
      },
      {
        "start": 90.079,
        "duration": 4.0,
        "text": "going to print out to the console"
      },
      {
        "start": 91.6,
        "duration": 4.479,
        "text": "the plan that spark is going to execute"
      },
      {
        "start": 94.079,
        "duration": 4.641,
        "text": "to actually compute that data frame"
      },
      {
        "start": 96.079,
        "duration": 4.0,
        "text": "when computation is forced by an action"
      },
      {
        "start": 98.72,
        "duration": 3.759,
        "text": "this is a lot like the familiar"
      },
      {
        "start": 100.079,
        "duration": 4.241,
        "text": "explain plan from the relational world"
      },
      {
        "start": 102.479,
        "duration": 2.64,
        "text": "it's a key step in optimizing a spark"
      },
      {
        "start": 104.32,
        "duration": 1.839,
        "text": "sql query"
      },
      {
        "start": 105.119,
        "duration": 2.881,
        "text": "and of course you will have to"
      },
      {
        "start": 106.159,
        "duration": 2.721,
        "text": "understand enough about sparks internal"
      },
      {
        "start": 108.0,
        "duration": 2.64,
        "text": "architecture"
      },
      {
        "start": 108.88,
        "duration": 3.279,
        "text": "and how it distributes computational"
      },
      {
        "start": 110.64,
        "duration": 4.24,
        "text": "work throughout a cluster"
      },
      {
        "start": 112.159,
        "duration": 4.481,
        "text": "to make sense of what explain tells you"
      },
      {
        "start": 114.88,
        "duration": 2.559,
        "text": "but of course we cover that in other"
      },
      {
        "start": 116.64,
        "duration": 2.32,
        "text": "sections"
      },
      {
        "start": 117.439,
        "duration": 2.801,
        "text": "and you should be pretty well equipped"
      },
      {
        "start": 118.96,
        "duration": 2.88,
        "text": "if you've gone over that stuff to"
      },
      {
        "start": 120.24,
        "duration": 4.239,
        "text": "understand the output of explain"
      },
      {
        "start": 121.84,
        "duration": 4.319,
        "text": "here's set key space in action you can"
      },
      {
        "start": 124.479,
        "duration": 3.76,
        "text": "see it's pretty simple we call it on the"
      },
      {
        "start": 126.159,
        "duration": 3.761,
        "text": "cassandra sql context object and then in"
      },
      {
        "start": 128.239,
        "duration": 3.36,
        "text": "the subsequent sql query"
      },
      {
        "start": 129.92,
        "duration": 3.12,
        "text": "we don't need to indicate the key space"
      },
      {
        "start": 131.599,
        "duration": 3.761,
        "text": "we can just kind of go on our way"
      },
      {
        "start": 133.04,
        "duration": 3.76,
        "text": "with that key space having been set but"
      },
      {
        "start": 135.36,
        "duration": 3.36,
        "text": "this example isn't trivial"
      },
      {
        "start": 136.8,
        "duration": 4.159,
        "text": "take a look at the query we're executing"
      },
      {
        "start": 138.72,
        "duration": 4.32,
        "text": "we're looking for a list of actors and"
      },
      {
        "start": 140.959,
        "duration": 4.321,
        "text": "the highest rating they've obtained"
      },
      {
        "start": 143.04,
        "duration": 3.52,
        "text": "in any film they've been in that's"
      },
      {
        "start": 145.28,
        "duration": 1.679,
        "text": "that's what this query is going to give"
      },
      {
        "start": 146.56,
        "duration": 3.039,
        "text": "us"
      },
      {
        "start": 146.959,
        "duration": 3.36,
        "text": "and the data frame is called max df in"
      },
      {
        "start": 149.599,
        "duration": 2.321,
        "text": "our shell"
      },
      {
        "start": 150.319,
        "duration": 3.521,
        "text": "that's important because in our next"
      },
      {
        "start": 151.92,
        "duration": 4.959,
        "text": "example we register this as"
      },
      {
        "start": 153.84,
        "duration": 5.36,
        "text": "a temp table we call it max rating and"
      },
      {
        "start": 156.879,
        "duration": 4.08,
        "text": "in the query that we go on to execute"
      },
      {
        "start": 159.2,
        "duration": 3.36,
        "text": "that's a slightly complex query but"
      },
      {
        "start": 160.959,
        "duration": 2.801,
        "text": "let's see we're selecting actor title"
      },
      {
        "start": 162.56,
        "duration": 4.24,
        "text": "release here rating"
      },
      {
        "start": 163.76,
        "duration": 5.68,
        "text": "from max rating inner joined"
      },
      {
        "start": 166.8,
        "duration": 4.24,
        "text": "to movies by actor see the join takes"
      },
      {
        "start": 169.44,
        "duration": 2.24,
        "text": "place there and we rename the tables in"
      },
      {
        "start": 171.04,
        "duration": 4.16,
        "text": "the join"
      },
      {
        "start": 171.68,
        "duration": 5.6,
        "text": "we join on the common actor what we want"
      },
      {
        "start": 175.2,
        "duration": 2.64,
        "text": "here is all of the films in the movies"
      },
      {
        "start": 177.28,
        "duration": 3.679,
        "text": "table"
      },
      {
        "start": 177.84,
        "duration": 5.2,
        "text": "that have a rating within 1.0"
      },
      {
        "start": 180.959,
        "duration": 3.041,
        "text": "of the max rating that that actor has"
      },
      {
        "start": 183.04,
        "duration": 2.559,
        "text": "obtained"
      },
      {
        "start": 184.0,
        "duration": 3.12,
        "text": "this is easy since we had that max"
      },
      {
        "start": 185.599,
        "duration": 3.201,
        "text": "readings data frame lying around"
      },
      {
        "start": 187.12,
        "duration": 4.0,
        "text": "we get to treat it like a table it's a"
      },
      {
        "start": 188.8,
        "duration": 4.159,
        "text": "normal sql join and as joins go it's"
      },
      {
        "start": 191.12,
        "duration": 3.52,
        "text": "really not all that complex"
      },
      {
        "start": 192.959,
        "duration": 3.841,
        "text": "so what would have been a difficult"
      },
      {
        "start": 194.64,
        "duration": 4.239,
        "text": "computation is made very familiar and"
      },
      {
        "start": 196.8,
        "duration": 3.439,
        "text": "very easy by spark sql"
      },
      {
        "start": 198.879,
        "duration": 2.72,
        "text": "and now that we have a somewhat"
      },
      {
        "start": 200.239,
        "duration": 3.521,
        "text": "interesting query happening it's"
      },
      {
        "start": 201.599,
        "duration": 4.481,
        "text": "worthwhile trying and explain"
      },
      {
        "start": 203.76,
        "duration": 3.36,
        "text": "and here is what actual output from the"
      },
      {
        "start": 206.08,
        "duration": 2.879,
        "text": "explain method"
      },
      {
        "start": 207.12,
        "duration": 3.6,
        "text": "would look like you're welcome to pause"
      },
      {
        "start": 208.959,
        "duration": 2.481,
        "text": "the video and walk through each one of"
      },
      {
        "start": 210.72,
        "duration": 2.64,
        "text": "those steps"
      },
      {
        "start": 211.44,
        "duration": 3.439,
        "text": "and get an idea of what spark is doing"
      },
      {
        "start": 213.36,
        "duration": 3.36,
        "text": "to get the job done"
      },
      {
        "start": 214.879,
        "duration": 3.92,
        "text": "as i said really to understand this you"
      },
      {
        "start": 216.72,
        "duration": 3.76,
        "text": "do have to have a decent grasp"
      },
      {
        "start": 218.799,
        "duration": 3.601,
        "text": "of the internals and how spark"
      },
      {
        "start": 220.48,
        "duration": 3.679,
        "text": "distributes work around the cluster"
      },
      {
        "start": 222.4,
        "duration": 4.72,
        "text": "but with a little bit of that in hand"
      },
      {
        "start": 224.159,
        "duration": 4.8,
        "text": "you can make sense of this"
      },
      {
        "start": 227.12,
        "duration": 3.28,
        "text": "so those are just a few extra tools that"
      },
      {
        "start": 228.959,
        "duration": 2.801,
        "text": "are going to come in handy when you're"
      },
      {
        "start": 230.4,
        "duration": 9.68,
        "text": "querying cassandra"
      },
      {
        "start": 231.76,
        "duration": 10.399,
        "text": "with spark sql"
      },
      {
        "start": 240.08,
        "duration": 2.079,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:08:20.436747+00:00"
}