{
  "video_id": "bolptfhDni4",
  "title": "Success Segment: Getting Started with DataStax Docker Images",
  "description": "Jeff Carpenter shows you how to download use the official DataStax Enterprise Docker images.\n\nABOUT DATASTAX ENTERPRISE 5.1\nDataStax Enterprise 5.1, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.1 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax Enterprise©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2018-03-12T20:21:08Z",
  "thumbnail": "https://i.ytimg.com/vi/bolptfhDni4/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "getting_started",
    "cassandra",
    "tutorial",
    "database",
    "apache_cassandra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=bolptfhDni4",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "over the past couple of years there's been an explosion of popularity in deploying applications in containers especially docker containers as developers have been working to containerize their applications they've started looking at container izing infrastructure as well including databases while there has been a lot of debate about whether databases are a good fit for containers the fact remains that container izing databases is getting more and more popular especially for development environments data stacks has recently released official docker images for the first time in this video I'd like to give you a quick introduction to deploying data stacks enterprise in docker to do this I'm going to use killer video this is a reference application we've built that helps teach developers how to succeed with our technology killer video actually has a long history with docker before we had official data stacks Enterprise docker images Luke Tillman created unofficial images for data stacks enterprise and data stacks studio and older versions of killer video use this docker image set you can now find our official docker images for data stocks products on the docker websites first of all the data sacks enterprise server you will find in the docker store if you go to the home page for the docker store just search for data sacks enterprise and you will come to this page that will allow you to download the docker image from the command line use the docker pull command to pull the version you require from the docker store the other images that are officially supported by data stacks you can find on the docker hub this includes the ops center and Studio images you can find these by going to the hub docker comm website and searching for data stacks remember that all of these images are only supported for development at this time not production if you're interested in seeing the source that was used to build up these docker images you can go to github - the data stacks org and look at the docker images repo next let's dive in to how killer video makes use of these docker images if you go in github - killer video and look at the killer video DSC docker repo you can see that we are building a custom image it's based off of the official data stacks image for the DSC server the reason that we've built a custom image is so that we can update the startup script that kicks off the execution of this container we've modified this startup script to load up the schema so this would include CQL to define Cassandra tables it also includes the definition of a search index for DSC search as well as the definition of a graph for our DSC graph database all of these three different kinds of schema needs to be loaded up when our data stacks enterprise node first starts up if you'd like to see what this looks like you can look at the bootstrap SH script we also have a separate repo in github that is used to store a common set of docker scripts these can be used to help run the killer video application for example the default docker compose script is document compose amel if you download an implementation of killer video such as the killer video Java implementation you will run this docker compose llamó file with docker compose which will create instances of all of the infrastructure that you need in order to run killer video let's have a look as you can see this docker compose file runs required infrastructure that we need for killer video including at CD which is a registry for services a registrate er which is a helper container that assists us in getting some of our various services registered into a CD and most importantly for this success segment DSC so you can see here that the for this particular version of the docker compose file we are actually running our custom image of the DSC server so that's called killer video and it's called killer video - DSC version 4.0.1 happens to be the latest right now this DSE node is started with search and graph enabled as shown by these flags here which we are passing we then make sure that the ports for CQL search and graph are all exposed we actually name these ports and these ports are actually registered in at CD so if someone wants to look and see where the various capabilities of our data sax enterprise node are available they can actually look up these endpoints in at CD and the very last element here that we have in terms of environment variables that we are passing to our DSC image this last item is required we have to explicitly accept the data sax Enterprise license in order for this container to be able to run the docker common repo also contains a couple of other example compose files that you could use in order to run different configurations of data stacks Enterprise with some of our various tooling enabled for example there's another file that shows you how you can run DSC alongside ops center so that you can monitor what is happening in your cluster another file is provided to help you run data stack studio which is our developer tool that allows you to see create and execute queries in cql and the gremlin query language for graph finally there is an additional docker compose file that demonstrates my favorite feature of our new docker images which is the ability to store the data directories that are used to store data for Cassandra and to realize these externally to the Container this allows you to maintain your data even if you are creating and destroying multiple instances of a container being able to keep your data is a very nice feature I'd like to give you just a little bit more detail about how all of this works we're going to use the killer video Java as an example when I cloned the killer video Java repo onto my desktop part of what is included are the docker compose files that I showed you previously those docker compose files are available under the lib killer video docker common now when we go to start up the environment including all of our docker containers docker compose will look for a dot env file in the local directory in this case you can see that there are several environment variables defined in this dot env file the docker compose will use in order to know information about the environment that we want to create if you look at the second line the compose file that is selected here is actually a list of to compose files there's a docker compose Djamel in the root directory of killer video Java that defines some things that are required for that environment for example it starts a sample data generator that we've created the first entry in that list is the docker compose volume zmo file so that is actually the docker compose file that takes advantage of that feature I told you about a minute ago this allows me to preserve my data directories external to the image so what happens when I run a docker compose - up I'm going to use the dash D option so that the logs will appear in the background once I've started these containers I'll choose to monitor them using the kite Matic which is built into the docker environment as you can see I have multiple containers that have started up here including DSE etsy D generator and so on I can select to view the logs of any of my running containers if I watch closely I can see the schema being loaded in my customized version of the DSC docker image there are several other features of the data stacks Enterprise docker images that you can take advantage of if you go to the docker store page for data sacks enterprise you can see the full set of documentation for all the features that are available and how to best make use of the data stacks Enterprise container thanks for joining me for this quick segment on using data stacks Enterprise docker images with killer video I hope this gives you a head start on using these images in your own applications",
    "segments": [
      {
        "start": 6.58,
        "duration": 4.62,
        "text": "over the past couple of years there's"
      },
      {
        "start": 9.04,
        "duration": 4.05,
        "text": "been an explosion of popularity in"
      },
      {
        "start": 11.2,
        "duration": 4.68,
        "text": "deploying applications in containers"
      },
      {
        "start": 13.09,
        "duration": 4.68,
        "text": "especially docker containers as"
      },
      {
        "start": 15.88,
        "duration": 4.05,
        "text": "developers have been working to"
      },
      {
        "start": 17.77,
        "duration": 3.75,
        "text": "containerize their applications they've"
      },
      {
        "start": 19.93,
        "duration": 4.02,
        "text": "started looking at container izing"
      },
      {
        "start": 21.52,
        "duration": 5.04,
        "text": "infrastructure as well including"
      },
      {
        "start": 23.95,
        "duration": 4.59,
        "text": "databases while there has been a lot of"
      },
      {
        "start": 26.56,
        "duration": 4.8,
        "text": "debate about whether databases are a"
      },
      {
        "start": 28.54,
        "duration": 4.8,
        "text": "good fit for containers the fact remains"
      },
      {
        "start": 31.36,
        "duration": 4.86,
        "text": "that container izing databases is"
      },
      {
        "start": 33.34,
        "duration": 5.37,
        "text": "getting more and more popular especially"
      },
      {
        "start": 36.22,
        "duration": 4.38,
        "text": "for development environments data stacks"
      },
      {
        "start": 38.71,
        "duration": 4.71,
        "text": "has recently released official docker"
      },
      {
        "start": 40.6,
        "duration": 4.47,
        "text": "images for the first time in this video"
      },
      {
        "start": 43.42,
        "duration": 3.659,
        "text": "I'd like to give you a quick"
      },
      {
        "start": 45.07,
        "duration": 4.559,
        "text": "introduction to deploying data stacks"
      },
      {
        "start": 47.079,
        "duration": 5.25,
        "text": "enterprise in docker to do this I'm"
      },
      {
        "start": 49.629,
        "duration": 4.441,
        "text": "going to use killer video this is a"
      },
      {
        "start": 52.329,
        "duration": 4.14,
        "text": "reference application we've built that"
      },
      {
        "start": 54.07,
        "duration": 5.009,
        "text": "helps teach developers how to succeed"
      },
      {
        "start": 56.469,
        "duration": 4.89,
        "text": "with our technology killer video"
      },
      {
        "start": 59.079,
        "duration": 4.8,
        "text": "actually has a long history with docker"
      },
      {
        "start": 61.359,
        "duration": 4.8,
        "text": "before we had official data stacks"
      },
      {
        "start": 63.879,
        "duration": 5.161,
        "text": "Enterprise docker images Luke Tillman"
      },
      {
        "start": 66.159,
        "duration": 5.011,
        "text": "created unofficial images for data"
      },
      {
        "start": 69.04,
        "duration": 5.52,
        "text": "stacks enterprise and data stacks studio"
      },
      {
        "start": 71.17,
        "duration": 6.81,
        "text": "and older versions of killer video use"
      },
      {
        "start": 74.56,
        "duration": 5.73,
        "text": "this docker image set you can now find"
      },
      {
        "start": 77.98,
        "duration": 4.71,
        "text": "our official docker images for data"
      },
      {
        "start": 80.29,
        "duration": 4.74,
        "text": "stocks products on the docker websites"
      },
      {
        "start": 82.69,
        "duration": 5.1,
        "text": "first of all the data sacks enterprise"
      },
      {
        "start": 85.03,
        "duration": 4.26,
        "text": "server you will find in the docker store"
      },
      {
        "start": 87.79,
        "duration": 3.51,
        "text": "if you go to the home page for the"
      },
      {
        "start": 89.29,
        "duration": 3.75,
        "text": "docker store just search for data sacks"
      },
      {
        "start": 91.3,
        "duration": 4.95,
        "text": "enterprise and you will come to this"
      },
      {
        "start": 93.04,
        "duration": 5.58,
        "text": "page that will allow you to download the"
      },
      {
        "start": 96.25,
        "duration": 5.61,
        "text": "docker image from the command line"
      },
      {
        "start": 98.62,
        "duration": 4.92,
        "text": "use the docker pull command to pull the"
      },
      {
        "start": 101.86,
        "duration": 4.1,
        "text": "version you require from the docker"
      },
      {
        "start": 103.54,
        "duration": 2.42,
        "text": "store"
      },
      {
        "start": 109.43,
        "duration": 4.89,
        "text": "the other images that are officially"
      },
      {
        "start": 111.83,
        "duration": 6.48,
        "text": "supported by data stacks you can find on"
      },
      {
        "start": 114.32,
        "duration": 7.02,
        "text": "the docker hub this includes the ops"
      },
      {
        "start": 118.31,
        "duration": 6.48,
        "text": "center and Studio images you can find"
      },
      {
        "start": 121.34,
        "duration": 5.67,
        "text": "these by going to the hub docker comm"
      },
      {
        "start": 124.79,
        "duration": 4.74,
        "text": "website and searching for data stacks"
      },
      {
        "start": 127.01,
        "duration": 5.1,
        "text": "remember that all of these images are"
      },
      {
        "start": 129.53,
        "duration": 6.03,
        "text": "only supported for development at this"
      },
      {
        "start": 132.11,
        "duration": 5.64,
        "text": "time not production if you're interested"
      },
      {
        "start": 135.56,
        "duration": 5.16,
        "text": "in seeing the source that was used to"
      },
      {
        "start": 137.75,
        "duration": 6.54,
        "text": "build up these docker images you can go"
      },
      {
        "start": 140.72,
        "duration": 6.9,
        "text": "to github - the data stacks org and look"
      },
      {
        "start": 144.29,
        "duration": 6.06,
        "text": "at the docker images repo next let's"
      },
      {
        "start": 147.62,
        "duration": 5.96,
        "text": "dive in to how killer video makes use of"
      },
      {
        "start": 150.35,
        "duration": 7.02,
        "text": "these docker images if you go in github"
      },
      {
        "start": 153.58,
        "duration": 7.99,
        "text": "- killer video and look at the killer"
      },
      {
        "start": 157.37,
        "duration": 6.18,
        "text": "video DSC docker repo you can see that"
      },
      {
        "start": 161.57,
        "duration": 3.81,
        "text": "we are building a custom image it's"
      },
      {
        "start": 163.55,
        "duration": 5.43,
        "text": "based off of the official data stacks"
      },
      {
        "start": 165.38,
        "duration": 6.24,
        "text": "image for the DSC server the reason that"
      },
      {
        "start": 168.98,
        "duration": 5.55,
        "text": "we've built a custom image is so that we"
      },
      {
        "start": 171.62,
        "duration": 4.53,
        "text": "can update the startup script that kicks"
      },
      {
        "start": 174.53,
        "duration": 4.26,
        "text": "off the execution of this container"
      },
      {
        "start": 176.15,
        "duration": 5.24,
        "text": "we've modified this startup script to"
      },
      {
        "start": 178.79,
        "duration": 6.12,
        "text": "load up the schema so this would include"
      },
      {
        "start": 181.39,
        "duration": 6.129,
        "text": "CQL to define Cassandra tables it also"
      },
      {
        "start": 184.91,
        "duration": 6.09,
        "text": "includes the definition of a search"
      },
      {
        "start": 187.519,
        "duration": 6.151,
        "text": "index for DSC search as well as the"
      },
      {
        "start": 191.0,
        "duration": 4.65,
        "text": "definition of a graph for our DSC graph"
      },
      {
        "start": 193.67,
        "duration": 3.96,
        "text": "database all of these three different"
      },
      {
        "start": 195.65,
        "duration": 5.16,
        "text": "kinds of schema needs to be loaded up"
      },
      {
        "start": 197.63,
        "duration": 5.37,
        "text": "when our data stacks enterprise node"
      },
      {
        "start": 200.81,
        "duration": 2.97,
        "text": "first starts up if you'd like to see"
      },
      {
        "start": 203.0,
        "duration": 3.989,
        "text": "what this looks like"
      },
      {
        "start": 203.78,
        "duration": 6.48,
        "text": "you can look at the bootstrap SH script"
      },
      {
        "start": 206.989,
        "duration": 5.161,
        "text": "we also have a separate repo in github"
      },
      {
        "start": 210.26,
        "duration": 5.28,
        "text": "that is used to store a common set of"
      },
      {
        "start": 212.15,
        "duration": 6.059,
        "text": "docker scripts these can be used to help"
      },
      {
        "start": 215.54,
        "duration": 5.43,
        "text": "run the killer video application for"
      },
      {
        "start": 218.209,
        "duration": 6.78,
        "text": "example the default docker compose"
      },
      {
        "start": 220.97,
        "duration": 6.6,
        "text": "script is document compose amel if you"
      },
      {
        "start": 224.989,
        "duration": 4.951,
        "text": "download an implementation of killer"
      },
      {
        "start": 227.57,
        "duration": 5.25,
        "text": "video such as the killer video Java"
      },
      {
        "start": 229.94,
        "duration": 5.85,
        "text": "implementation you will run this docker"
      },
      {
        "start": 232.82,
        "duration": 5.34,
        "text": "compose llamó file with docker compose"
      },
      {
        "start": 235.79,
        "duration": 4.5,
        "text": "which will create instances of all of"
      },
      {
        "start": 238.16,
        "duration": 4.29,
        "text": "the infrastructure that you need in"
      },
      {
        "start": 240.29,
        "duration": 2.76,
        "text": "order to run killer video let's have a"
      },
      {
        "start": 242.45,
        "duration": 3.35,
        "text": "look"
      },
      {
        "start": 243.05,
        "duration": 5.64,
        "text": "as you can see this docker compose file"
      },
      {
        "start": 245.8,
        "duration": 5.62,
        "text": "runs required infrastructure that we"
      },
      {
        "start": 248.69,
        "duration": 5.34,
        "text": "need for killer video including at CD"
      },
      {
        "start": 251.42,
        "duration": 5.16,
        "text": "which is a registry for services a"
      },
      {
        "start": 254.03,
        "duration": 5.429,
        "text": "registrate er which is a helper"
      },
      {
        "start": 256.58,
        "duration": 6.69,
        "text": "container that assists us in getting"
      },
      {
        "start": 259.459,
        "duration": 8.041,
        "text": "some of our various services registered"
      },
      {
        "start": 263.27,
        "duration": 8.58,
        "text": "into a CD and most importantly for this"
      },
      {
        "start": 267.5,
        "duration": 7.77,
        "text": "success segment DSC so you can see here"
      },
      {
        "start": 271.85,
        "duration": 5.97,
        "text": "that the for this particular version of"
      },
      {
        "start": 275.27,
        "duration": 6.27,
        "text": "the docker compose file we are actually"
      },
      {
        "start": 277.82,
        "duration": 6.45,
        "text": "running our custom image of the DSC"
      },
      {
        "start": 281.54,
        "duration": 6.18,
        "text": "server so that's called killer video and"
      },
      {
        "start": 284.27,
        "duration": 6.09,
        "text": "it's called killer video - DSC version"
      },
      {
        "start": 287.72,
        "duration": 6.0,
        "text": "4.0.1 happens to be the latest right now"
      },
      {
        "start": 290.36,
        "duration": 6.54,
        "text": "this DSE node is started with search and"
      },
      {
        "start": 293.72,
        "duration": 5.85,
        "text": "graph enabled as shown by these flags"
      },
      {
        "start": 296.9,
        "duration": 7.23,
        "text": "here which we are passing we then make"
      },
      {
        "start": 299.57,
        "duration": 6.66,
        "text": "sure that the ports for CQL search and"
      },
      {
        "start": 304.13,
        "duration": 4.62,
        "text": "graph are all exposed"
      },
      {
        "start": 306.23,
        "duration": 5.46,
        "text": "we actually name these ports and these"
      },
      {
        "start": 308.75,
        "duration": 5.13,
        "text": "ports are actually registered in at CD"
      },
      {
        "start": 311.69,
        "duration": 4.71,
        "text": "so if someone wants to look and see"
      },
      {
        "start": 313.88,
        "duration": 5.13,
        "text": "where the various capabilities of our"
      },
      {
        "start": 316.4,
        "duration": 4.11,
        "text": "data sax enterprise node are available"
      },
      {
        "start": 319.01,
        "duration": 4.02,
        "text": "they can actually look up these"
      },
      {
        "start": 320.51,
        "duration": 4.71,
        "text": "endpoints in at CD and the very last"
      },
      {
        "start": 323.03,
        "duration": 3.69,
        "text": "element here that we have in terms of"
      },
      {
        "start": 325.22,
        "duration": 4.74,
        "text": "environment variables that we are"
      },
      {
        "start": 326.72,
        "duration": 6.63,
        "text": "passing to our DSC image this last item"
      },
      {
        "start": 329.96,
        "duration": 5.49,
        "text": "is required we have to explicitly accept"
      },
      {
        "start": 333.35,
        "duration": 5.22,
        "text": "the data sax Enterprise license in order"
      },
      {
        "start": 335.45,
        "duration": 6.39,
        "text": "for this container to be able to run the"
      },
      {
        "start": 338.57,
        "duration": 5.94,
        "text": "docker common repo also contains a"
      },
      {
        "start": 341.84,
        "duration": 5.07,
        "text": "couple of other example compose files"
      },
      {
        "start": 344.51,
        "duration": 4.38,
        "text": "that you could use in order to run"
      },
      {
        "start": 346.91,
        "duration": 4.44,
        "text": "different configurations of data stacks"
      },
      {
        "start": 348.89,
        "duration": 5.07,
        "text": "Enterprise with some of our various"
      },
      {
        "start": 351.35,
        "duration": 4.65,
        "text": "tooling enabled for example there's"
      },
      {
        "start": 353.96,
        "duration": 6.27,
        "text": "another file that shows you how you can"
      },
      {
        "start": 356.0,
        "duration": 6.09,
        "text": "run DSC alongside ops center so that you"
      },
      {
        "start": 360.23,
        "duration": 4.41,
        "text": "can monitor what is happening in your"
      },
      {
        "start": 362.09,
        "duration": 5.49,
        "text": "cluster another file is provided to help"
      },
      {
        "start": 364.64,
        "duration": 5.58,
        "text": "you run data stack studio which is our"
      },
      {
        "start": 367.58,
        "duration": 7.02,
        "text": "developer tool that allows you to see"
      },
      {
        "start": 370.22,
        "duration": 6.66,
        "text": "create and execute queries in cql and"
      },
      {
        "start": 374.6,
        "duration": 4.71,
        "text": "the gremlin query language"
      },
      {
        "start": 376.88,
        "duration": 4.83,
        "text": "for graph finally there is an additional"
      },
      {
        "start": 379.31,
        "duration": 4.65,
        "text": "docker compose file that demonstrates my"
      },
      {
        "start": 381.71,
        "duration": 5.52,
        "text": "favorite feature of our new docker"
      },
      {
        "start": 383.96,
        "duration": 5.67,
        "text": "images which is the ability to store the"
      },
      {
        "start": 387.23,
        "duration": 5.45,
        "text": "data directories that are used to store"
      },
      {
        "start": 389.63,
        "duration": 6.21,
        "text": "data for Cassandra and to realize these"
      },
      {
        "start": 392.68,
        "duration": 6.07,
        "text": "externally to the Container this allows"
      },
      {
        "start": 395.84,
        "duration": 4.89,
        "text": "you to maintain your data even if you"
      },
      {
        "start": 398.75,
        "duration": 4.5,
        "text": "are creating and destroying multiple"
      },
      {
        "start": 400.73,
        "duration": 4.89,
        "text": "instances of a container being able to"
      },
      {
        "start": 403.25,
        "duration": 4.59,
        "text": "keep your data is a very nice feature"
      },
      {
        "start": 405.62,
        "duration": 4.32,
        "text": "I'd like to give you just a little bit"
      },
      {
        "start": 407.84,
        "duration": 4.92,
        "text": "more detail about how all of this works"
      },
      {
        "start": 409.94,
        "duration": 5.19,
        "text": "we're going to use the killer video Java"
      },
      {
        "start": 412.76,
        "duration": 5.22,
        "text": "as an example when I cloned the killer"
      },
      {
        "start": 415.13,
        "duration": 4.5,
        "text": "video Java repo onto my desktop part of"
      },
      {
        "start": 417.98,
        "duration": 3.63,
        "text": "what is included are the docker compose"
      },
      {
        "start": 419.63,
        "duration": 4.17,
        "text": "files that I showed you previously"
      },
      {
        "start": 421.61,
        "duration": 5.87,
        "text": "those docker compose files are available"
      },
      {
        "start": 423.8,
        "duration": 6.27,
        "text": "under the lib killer video docker common"
      },
      {
        "start": 427.48,
        "duration": 4.96,
        "text": "now when we go to start up the"
      },
      {
        "start": 430.07,
        "duration": 4.71,
        "text": "environment including all of our docker"
      },
      {
        "start": 432.44,
        "duration": 6.8,
        "text": "containers docker compose will look for"
      },
      {
        "start": 434.78,
        "duration": 4.46,
        "text": "a dot env file in the local directory"
      },
      {
        "start": 439.31,
        "duration": 5.25,
        "text": "in this case you can see that there are"
      },
      {
        "start": 442.07,
        "duration": 4.5,
        "text": "several environment variables defined in"
      },
      {
        "start": 444.56,
        "duration": 4.16,
        "text": "this dot env file the docker compose"
      },
      {
        "start": 446.57,
        "duration": 4.38,
        "text": "will use in order to know information"
      },
      {
        "start": 448.72,
        "duration": 3.91,
        "text": "about the environment that we want to"
      },
      {
        "start": 450.95,
        "duration": 4.2,
        "text": "create if you look at the second line"
      },
      {
        "start": 452.63,
        "duration": 5.37,
        "text": "the compose file that is selected here"
      },
      {
        "start": 455.15,
        "duration": 5.64,
        "text": "is actually a list of to compose files"
      },
      {
        "start": 458.0,
        "duration": 5.25,
        "text": "there's a docker compose Djamel in the"
      },
      {
        "start": 460.79,
        "duration": 4.29,
        "text": "root directory of killer video Java that"
      },
      {
        "start": 463.25,
        "duration": 4.56,
        "text": "defines some things that are required"
      },
      {
        "start": 465.08,
        "duration": 5.13,
        "text": "for that environment for example it"
      },
      {
        "start": 467.81,
        "duration": 4.2,
        "text": "starts a sample data generator that"
      },
      {
        "start": 470.21,
        "duration": 5.64,
        "text": "we've created the first entry in that"
      },
      {
        "start": 472.01,
        "duration": 6.57,
        "text": "list is the docker compose volume zmo"
      },
      {
        "start": 475.85,
        "duration": 5.04,
        "text": "file so that is actually the docker"
      },
      {
        "start": 478.58,
        "duration": 3.72,
        "text": "compose file that takes advantage of"
      },
      {
        "start": 480.89,
        "duration": 3.93,
        "text": "that feature I told you about a minute"
      },
      {
        "start": 482.3,
        "duration": 5.73,
        "text": "ago this allows me to preserve my data"
      },
      {
        "start": 484.82,
        "duration": 5.91,
        "text": "directories external to the image so"
      },
      {
        "start": 488.03,
        "duration": 5.81,
        "text": "what happens when I run a docker compose"
      },
      {
        "start": 490.73,
        "duration": 3.11,
        "text": "- up"
      },
      {
        "start": 494.06,
        "duration": 8.129,
        "text": "I'm going to use the dash D option"
      },
      {
        "start": 499.639,
        "duration": 4.741,
        "text": "so that the logs will appear in the"
      },
      {
        "start": 502.189,
        "duration": 4.471,
        "text": "background"
      },
      {
        "start": 504.38,
        "duration": 5.25,
        "text": "once I've started these containers I'll"
      },
      {
        "start": 506.66,
        "duration": 5.759,
        "text": "choose to monitor them using the kite"
      },
      {
        "start": 509.63,
        "duration": 5.01,
        "text": "Matic which is built into the docker"
      },
      {
        "start": 512.419,
        "duration": 4.561,
        "text": "environment"
      },
      {
        "start": 514.64,
        "duration": 3.78,
        "text": "as you can see I have multiple"
      },
      {
        "start": 516.98,
        "duration": 5.91,
        "text": "containers that have started up here"
      },
      {
        "start": 518.42,
        "duration": 7.17,
        "text": "including DSE etsy D generator and so on"
      },
      {
        "start": 522.89,
        "duration": 5.79,
        "text": "I can select to view the logs of any of"
      },
      {
        "start": 525.59,
        "duration": 5.73,
        "text": "my running containers if I watch closely"
      },
      {
        "start": 528.68,
        "duration": 5.61,
        "text": "I can see the schema being loaded in my"
      },
      {
        "start": 531.32,
        "duration": 4.95,
        "text": "customized version of the DSC docker"
      },
      {
        "start": 534.29,
        "duration": 4.35,
        "text": "image there are several other features"
      },
      {
        "start": 536.27,
        "duration": 4.95,
        "text": "of the data stacks Enterprise docker"
      },
      {
        "start": 538.64,
        "duration": 5.28,
        "text": "images that you can take advantage of if"
      },
      {
        "start": 541.22,
        "duration": 4.77,
        "text": "you go to the docker store page for data"
      },
      {
        "start": 543.92,
        "duration": 4.56,
        "text": "sacks enterprise you can see the full"
      },
      {
        "start": 545.99,
        "duration": 4.47,
        "text": "set of documentation for all the"
      },
      {
        "start": 548.48,
        "duration": 4.56,
        "text": "features that are available and how to"
      },
      {
        "start": 550.46,
        "duration": 4.86,
        "text": "best make use of the data stacks"
      },
      {
        "start": 553.04,
        "duration": 4.5,
        "text": "Enterprise container thanks for joining"
      },
      {
        "start": 555.32,
        "duration": 4.95,
        "text": "me for this quick segment on using data"
      },
      {
        "start": 557.54,
        "duration": 5.04,
        "text": "stacks Enterprise docker images with"
      },
      {
        "start": 560.27,
        "duration": 4.59,
        "text": "killer video I hope this gives you a"
      },
      {
        "start": 562.58,
        "duration": 5.42,
        "text": "head start on using these images in your"
      },
      {
        "start": 564.86,
        "duration": 3.14,
        "text": "own applications"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T06:47:27.176093+00:00"
}