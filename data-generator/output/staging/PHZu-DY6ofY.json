{
  "video_id": "PHZu-DY6ofY",
  "title": "Distributed Data Show Episode 80: Finding Bad Actors with Max Melnick",
  "description": "In this episode Jeff talks with Max Melnick about how he got into analytics consulting with Deloitte (no, he's not an accountant), and how the Mission Graph capability Deloitte has built on top of DataStax Enterprise helps analysts leverage complex networks to detect financial fraud, terrorism, and even supply chain vulnerabilities.\n\nHighlights\n0:15 -You told us you want to hear about use cases, so here we go!\n0:58 - Getting to know Max - Virginia native, TensorFlow committer, Analytics at Deloitte\n2:35 - The problem space for Mission Graph - identifying high-risk actors in networks aka \"bad guys\" to help analysts be more effective\n3:53 - Mission Graph - solving not only the data problem of high volume, but the operational problems of connecting/correlating across data sets\n5:35 - Mission Graph is a self-service platform for interactive network exploration and analysis. With current systems, most analyst time is spent on data engineering tasks. Mission Graph is trying to fix this.\n7:58 - The technology stack includes Cassandra, DataStax Search, DataStax Graph. Lessons learned include: 1) avoiding network-based storage and doing regular health checks.\n9:48 - 2) When onboarding new team members, give them initial tasks that correspond to their skill level.\n11:17 - 3) When using Graph, use the DSE GraphFrames API for large volume data loading. Use Spark GraphFrames to take advantage of algorithms page rank, motif finding, etc.\n13:28 - Wrapping up\n\nABOUT DATASTAX ENTERPRISE 6\nDataStax  powers  the  Right-Now  Enterprise  with  the  always-on,  distributed  cloud  database  built  on  Apache  Cassandraâ„¢  and designed for hybrid cloud. DataStax Enterprise 6 (DSE 6) includes industry-leading performance, self-driving operational simplicity, and robust analytics.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://www.datastax.com/products/datastax-enterprise-6\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1",
  "published_at": "2019-01-08T14:00:03Z",
  "thumbnail": "https://i.ytimg.com/vi/PHZu-DY6ofY/hqdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "search",
    "database",
    "performance",
    "talk",
    "dse",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=PHZu-DY6ofY",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems hey I'm hanging out in our nation's capital well maybe not your nation's capital but my nation's capital Washington DC with max Melnick from Deloitte we're actually hanging out here at data sacks developer day so we've been on tour taking this show around the country helping people get educated on Apache Cassandra and data sacks enterprise and Max was kind enough to join us for our keynote this morning and I want to have more use case conversations and we get these we get input we get reader mail or viewer mail it's like we want to hear about use cases so I want to give the people what they want do you want to help me give the people what they want let's do it okay it's good so tell me a little bit about yourself who are you who is max yes so a little bit about me I am currently engineering lead for one of the analytic product development teams that we have at Deloitte I grew up in the DC area I then went to school at UVA studied systems engineering and then from there went and joined Deloitte and in those nine years that I've been there I've learnt a lot of different hats I've done the traditional consulting roles and then also been more on the technical side whether it be more of an ops position a data scientists software engineer and now technical lead I've also committed to tensorflow and so I really my passion is building analytic capabilities and solutions for clients and so I identify more with the software developer side cool yeah we were joking before that you know people think that if you work for Deloitte you must be an accountant and not so no no we everyone asks that first when you say you work at Deloitte but that is not the part of the light that I work for I don't know that I don't have a CPA part of Deloitte that I'm part of is within our technology consulting practice specifically within analytics part of the product development team cool okay so analytics is your jam and I like that combination of being able to do some consulting you get out and see customers you see what they need and then you're also a work on product so what I know that you work in a project called mission graph which is kind of an EDX platform that we're gonna get into you but what is the problem that you were trying to solve with mission graph yeah so the use case at a high level is how does an analyst whether it be a bishop mission or business analysts identify high risk entities or actors in a network so what are some examples of that so we're finding bad guys that's why I do it yeah finding bad guys okay so some examples of that in the financial space could be identifying fraudulent transactions or fraud rings yep in the national security space it could be identifying terrorists in supply chain it could be identifying high-risk suppliers okay Oh see that's yeah that's not when we think about I know we've had some recent news about illicit either chips or for more depending on whose reports that you believe kind of making their way into the supply chain and product have a lot of devices that we use all the time so this is like this is a top of mind thing right now absolutely okay so what did you guys put together to kind of help solve this problem you're basically like kind of shorten the time frame to insights in order to be able to find and detect bad actors right yeah mountains of data some of the way I like to characterize the problem with that use case is around one the data and then the operational challenges okay so from a data perspective there's the usual analyst have to deal with massive quantities of data data that is coming through it very high frequency but then there's also some of the more data modeling challenges and data integration challenges around okay if I'm an analyst trying to I create a full network to analyze how do I connect all these different types of data across different data sets okay and that also includes specifically things that are not connecting things that are not strongly keyed so how do I know if I'm looking at airline data that one plane ticket for max Melnik is the same as max genomic in another airline system and so how do i connect those or resolve those two entities to create one max Melnik entity ok the analyst yeah right okay so and we've we've had discussions on this show before about entity resolution problems and why graph databases are especially well equipped rather than maybe in a classic sense like writing a massive joint statement that would go and figure some of these things out so am I on the right track is that direction that you guys headed down grab absolutely yeah and so as far as some of those problems inspired us to create a product called mission graph yeah and at the core it's about a self-service platform for analysts to create a real comprehensive network that combines lots of different data from lots of different domains so that they can do analysis like I was talking about before around identifying bad actors in the network okay and what yeah kind of real fast like what what does that usage pattern look like for an analyst and sitting in front of the tool what can I do yeah a lot of it's around interactive network exploration and analysis so some of the key core questions that we enable an analyst to answer our one tell me everything about this entity it be a person so that they can see okay is there any kind of risky information that they have but also more powerfully and getting kind of to the graph side of things what bad actors might this entity related to and so that's part of the solution that we help analysts and so that's and other pieces of that are also more on the graph analysis side around how are these two entities whether it's organizations or people related yeah so that's kind of like a graph shortest path problem okay cool okay so it sounds like what you mention there is a little bit of a search problem just locating entities in this in this you know treasure trove of data that we have and then a graph problem of navigating relationships between them I love the visual that you kind of showed in your talk this morning where there was a particular entity of interest that you zeroed in on you search for it you found it in the graph and then began kind of traversing relationships and the visualization was such that we could very clearly see like three suspicious entities that were two hops away from that node which made us kind of like oh we should dig in and really investigate I can imagine an analyst saying okay this is something I need to pay attention to you yeah right now they spend so much time with the data collection accessing the data integrating the data we want them to spend more time with the analysis so that they can identify bad guys and whether if you're law enforcement for example put people in jail gotcha okay so we're not gonna go through your whole technology stack here I know that like you know some people are like hey let me show you pictures of my kids that I've got here on my phone I feel like Architects are like yeah you want to see my technology stack this is what I'm using we live to trade stories so I mean I know that you built a solution that's on Cassandra at the core I'm using data sex search and graph what is some advice that you have like lessons learned that you would share with people that are adopting this technology you can help of things so the first lesson learned and I like to remind people about is no the data stacks and Cassandra anti-patterns and best practices that goes for really any tool that you're using so one example at one implementation we ended up having the infrastructure team and the servers on storage back I'm sorry Network back story oh wait a minute okay as we all know that is one of the big anti patterns for running Cassandra on some kind of sand and no sands people know yeah it created a lot of heartburn for the ops team and the the developers who are trying to get these massive data loads integrated into our application right so you can see why it would be attractive but there's some caveats there yeah and I I love the documentation on the data stacks site that has explicitly or some of the anti patterns and best practices and how to make your platform production ready so definitely recommend people going in looking at those even if you've been running data stacks for a while it probably pays to revisit them do a health check yeah okay that's good that's a good one what else you got the next thing as far as onboarding new team members this is something we deal with a lot is we've been growing and that is start simple relative to that team members experience level and so for example with junior practitioners a lot of times if we say ok go into the actual application code whether it's the data pipeline code and start modifying it it can get a lot it can get very overwhelming and so what I like to do is start a little bit more simple and for example I know a lot of the data stacks Academy videos they have this reference application killer video that's a little bit more simple and I know that we head around so starting with things that are a little bit more simple and straightforward to help people ramp up is one thing that I recommend ok good that makes a lot of sense I mean I I definitely I'm sympathetic because I've thrown myself into situations and thrown on with other people into situations where you're trying to learn new technology and it's not just one new technology learning curve it's like hey can you go use this distributed database and by the way you also need to learn how to deploy in the cloud and here's the CLI for the clap for our cloud that we're using and oh you know your head begins to explode so that's that's good measured advice about how to just kind of take your time find some resources that can really work you through it alright we'll keep them coming you have more you're more of these absolutely okay so one thing more specific to graph yeah is I recommend if you're trying to load or modify lots of data in DAC graph to use the DSC graph frames library that is built into DSC sparc okay and we had a lot of challenges originally we had were programming trying to load a bunch of data into graph using some of the lower-level spark api's like Rd B's and trying to use the DSC Java driver we're going to load massive amounts of data using parameterised gremlin statements which was very performant but it was very difficult to understand from a developer's right if it was very fragile it was hard to debug and then DSC graph graph frames came out and it made developers lives a lot easier or not that code a lot cleaner and also some of the other benefits that you get out of that or it integrates nicely with the higher-level spark api's and then also you can easily take any data that you've persisted in DSC graph and export it to a spark graph frame and start doing some of the more awesome analytics that you can do out of the spark graph frames library like running PageRank on your data and graph doing some of the community detection algorithms that they have doing motif finding so real powerful graph analytics very quickly right that's cool that means the tools in this area are getting more powerful time and spark api's are changing and maturing we're responding to that in data stacks Enterprise with what we're doing with that and continuing to kind of push the envelope in this area so I think it's good maybe to come back every once in a while and just really look and see what's available and how the api's are changing and there may be some you can get some lines of code it's a good day for me as a developer when my net lines of co-production is negative this is a good day I like to simplify things clean things up exactly thanks for joining us max this has been a really great episode and I love having people to talk out about use cases I'm so glad that you came and did a keynote for us a developer day that was amazing and we're actually gonna share out the footage of that keynote kind of a long side we'll release it alongside with this episode so look for that and you know to everyone out there we're trying to get to you with our developer days we're trying to get one in a city near you I hear you Denver I hear you Seattle it's it's coming your way and maybe this could be you sitting here talking to me for a distributed data show episode where we talk about your use case we would love that we would love to have you on the show and hear more about how people are using Cassandra and do sex Enterprise so until next time thank you thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data stacks Academy and tell us what you think you can also find us on the data stacks Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.05,
        "duration": 4.15,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.399,
        "duration": 4.201,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.6,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.04,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.4,
        "text": "large-scale distributed systems hey I'm"
      },
      {
        "start": 16.5,
        "duration": 4.23,
        "text": "hanging out in our nation's capital well"
      },
      {
        "start": 19.05,
        "duration": 4.59,
        "text": "maybe not your nation's capital but my"
      },
      {
        "start": 20.73,
        "duration": 5.76,
        "text": "nation's capital Washington DC with max"
      },
      {
        "start": 23.64,
        "duration": 4.799,
        "text": "Melnick from Deloitte we're actually"
      },
      {
        "start": 26.49,
        "duration": 5.4,
        "text": "hanging out here at data sacks developer"
      },
      {
        "start": 28.439,
        "duration": 5.251,
        "text": "day so we've been on tour taking this"
      },
      {
        "start": 31.89,
        "duration": 4.349,
        "text": "show around the country helping people"
      },
      {
        "start": 33.69,
        "duration": 5.13,
        "text": "get educated on Apache Cassandra and"
      },
      {
        "start": 36.239,
        "duration": 4.021,
        "text": "data sacks enterprise and Max was kind"
      },
      {
        "start": 38.82,
        "duration": 5.16,
        "text": "enough to join us for our keynote this"
      },
      {
        "start": 40.26,
        "duration": 6.479,
        "text": "morning and I want to have more use case"
      },
      {
        "start": 43.98,
        "duration": 4.95,
        "text": "conversations and we get these we get"
      },
      {
        "start": 46.739,
        "duration": 4.951,
        "text": "input we get reader mail or viewer mail"
      },
      {
        "start": 48.93,
        "duration": 5.58,
        "text": "it's like we want to hear about use"
      },
      {
        "start": 51.69,
        "duration": 4.32,
        "text": "cases so I want to give the people what"
      },
      {
        "start": 54.51,
        "duration": 3.0,
        "text": "they want do you want to help me give"
      },
      {
        "start": 56.01,
        "duration": 3.27,
        "text": "the people what they want let's do it"
      },
      {
        "start": 57.51,
        "duration": 3.33,
        "text": "okay it's good so tell me a little bit"
      },
      {
        "start": 59.28,
        "duration": 5.43,
        "text": "about yourself who are you who is max"
      },
      {
        "start": 60.84,
        "duration": 7.62,
        "text": "yes so a little bit about me I am"
      },
      {
        "start": 64.71,
        "duration": 5.67,
        "text": "currently engineering lead for one of"
      },
      {
        "start": 68.46,
        "duration": 4.769,
        "text": "the analytic product development teams"
      },
      {
        "start": 70.38,
        "duration": 7.08,
        "text": "that we have at Deloitte I grew up in"
      },
      {
        "start": 73.229,
        "duration": 6.75,
        "text": "the DC area I then went to school at UVA"
      },
      {
        "start": 77.46,
        "duration": 5.67,
        "text": "studied systems engineering and then"
      },
      {
        "start": 79.979,
        "duration": 5.43,
        "text": "from there went and joined Deloitte and"
      },
      {
        "start": 83.13,
        "duration": 4.98,
        "text": "in those nine years that I've been there"
      },
      {
        "start": 85.409,
        "duration": 5.07,
        "text": "I've learnt a lot of different hats I've"
      },
      {
        "start": 88.11,
        "duration": 5.13,
        "text": "done the traditional consulting roles"
      },
      {
        "start": 90.479,
        "duration": 5.221,
        "text": "and then also been more on the technical"
      },
      {
        "start": 93.24,
        "duration": 6.18,
        "text": "side whether it be more of an ops"
      },
      {
        "start": 95.7,
        "duration": 6.72,
        "text": "position a data scientists software"
      },
      {
        "start": 99.42,
        "duration": 7.37,
        "text": "engineer and now technical lead I've"
      },
      {
        "start": 102.42,
        "duration": 7.519,
        "text": "also committed to tensorflow and so I"
      },
      {
        "start": 106.79,
        "duration": 5.5,
        "text": "really my passion is building analytic"
      },
      {
        "start": 109.939,
        "duration": 5.591,
        "text": "capabilities and solutions for clients"
      },
      {
        "start": 112.29,
        "duration": 5.67,
        "text": "and so I identify more with the software"
      },
      {
        "start": 115.53,
        "duration": 4.71,
        "text": "developer side cool yeah we were joking"
      },
      {
        "start": 117.96,
        "duration": 4.17,
        "text": "before that you know people think that"
      },
      {
        "start": 120.24,
        "duration": 6.69,
        "text": "if you work for Deloitte you must be an"
      },
      {
        "start": 122.13,
        "duration": 7.019,
        "text": "accountant and not so no no we everyone"
      },
      {
        "start": 126.93,
        "duration": 4.5,
        "text": "asks that first when you say you work at"
      },
      {
        "start": 129.149,
        "duration": 3.261,
        "text": "Deloitte but that is not the part of the"
      },
      {
        "start": 131.43,
        "duration": 5.32,
        "text": "light that I work for"
      },
      {
        "start": 132.41,
        "duration": 8.39,
        "text": "I don't know that I don't have a CPA"
      },
      {
        "start": 136.75,
        "duration": 6.25,
        "text": "part of Deloitte that I'm part of is"
      },
      {
        "start": 140.8,
        "duration": 5.01,
        "text": "within our technology consulting"
      },
      {
        "start": 143.0,
        "duration": 5.76,
        "text": "practice specifically within analytics"
      },
      {
        "start": 145.81,
        "duration": 4.03,
        "text": "part of the product development team"
      },
      {
        "start": 148.76,
        "duration": 6.21,
        "text": "cool"
      },
      {
        "start": 149.84,
        "duration": 6.63,
        "text": "okay so analytics is your jam and I like"
      },
      {
        "start": 154.97,
        "duration": 2.97,
        "text": "that combination of being able to do"
      },
      {
        "start": 156.47,
        "duration": 2.97,
        "text": "some consulting you get out and see"
      },
      {
        "start": 157.94,
        "duration": 4.14,
        "text": "customers you see what they need and"
      },
      {
        "start": 159.44,
        "duration": 4.98,
        "text": "then you're also a work on product so"
      },
      {
        "start": 162.08,
        "duration": 5.1,
        "text": "what I know that you work in a project"
      },
      {
        "start": 164.42,
        "duration": 4.23,
        "text": "called mission graph which is kind of an"
      },
      {
        "start": 167.18,
        "duration": 3.66,
        "text": "EDX platform that we're gonna get into"
      },
      {
        "start": 168.65,
        "duration": 4.41,
        "text": "you but what is the problem that you"
      },
      {
        "start": 170.84,
        "duration": 5.96,
        "text": "were trying to solve with mission graph"
      },
      {
        "start": 173.06,
        "duration": 6.12,
        "text": "yeah so the use case at a high level is"
      },
      {
        "start": 176.8,
        "duration": 5.22,
        "text": "how does an analyst whether it be a"
      },
      {
        "start": 179.18,
        "duration": 6.36,
        "text": "bishop mission or business analysts"
      },
      {
        "start": 182.02,
        "duration": 5.92,
        "text": "identify high risk entities or actors in"
      },
      {
        "start": 185.54,
        "duration": 5.01,
        "text": "a network so what are some examples of"
      },
      {
        "start": 187.94,
        "duration": 3.03,
        "text": "that so we're finding bad guys that's"
      },
      {
        "start": 190.55,
        "duration": 3.42,
        "text": "why I do it"
      },
      {
        "start": 190.97,
        "duration": 4.92,
        "text": "yeah finding bad guys okay so some"
      },
      {
        "start": 193.97,
        "duration": 5.07,
        "text": "examples of that in the financial space"
      },
      {
        "start": 195.89,
        "duration": 7.17,
        "text": "could be identifying fraudulent"
      },
      {
        "start": 199.04,
        "duration": 5.91,
        "text": "transactions or fraud rings yep in the"
      },
      {
        "start": 203.06,
        "duration": 4.95,
        "text": "national security space it could be"
      },
      {
        "start": 204.95,
        "duration": 4.92,
        "text": "identifying terrorists in supply chain"
      },
      {
        "start": 208.01,
        "duration": 5.55,
        "text": "it could be identifying high-risk"
      },
      {
        "start": 209.87,
        "duration": 5.04,
        "text": "suppliers okay Oh see that's yeah that's"
      },
      {
        "start": 213.56,
        "duration": 4.74,
        "text": "not when we think about I know we've had"
      },
      {
        "start": 214.91,
        "duration": 5.37,
        "text": "some recent news about illicit either"
      },
      {
        "start": 218.3,
        "duration": 3.36,
        "text": "chips or for more depending on whose"
      },
      {
        "start": 220.28,
        "duration": 3.0,
        "text": "reports that you believe kind of making"
      },
      {
        "start": 221.66,
        "duration": 3.27,
        "text": "their way into the supply chain and"
      },
      {
        "start": 223.28,
        "duration": 3.3,
        "text": "product have a lot of devices that we"
      },
      {
        "start": 224.93,
        "duration": 3.15,
        "text": "use all the time so this is like this is"
      },
      {
        "start": 226.58,
        "duration": 5.97,
        "text": "a top of mind thing right now"
      },
      {
        "start": 228.08,
        "duration": 5.85,
        "text": "absolutely okay so what did you guys put"
      },
      {
        "start": 232.55,
        "duration": 3.48,
        "text": "together to kind of help solve this"
      },
      {
        "start": 233.93,
        "duration": 5.25,
        "text": "problem you're basically like kind of"
      },
      {
        "start": 236.03,
        "duration": 4.74,
        "text": "shorten the time frame to insights in"
      },
      {
        "start": 239.18,
        "duration": 4.65,
        "text": "order to be able to find and detect bad"
      },
      {
        "start": 240.77,
        "duration": 5.79,
        "text": "actors right yeah mountains of data some"
      },
      {
        "start": 243.83,
        "duration": 5.85,
        "text": "of the way I like to characterize the"
      },
      {
        "start": 246.56,
        "duration": 5.34,
        "text": "problem with that use case is around one"
      },
      {
        "start": 249.68,
        "duration": 4.44,
        "text": "the data and then the operational"
      },
      {
        "start": 251.9,
        "duration": 4.98,
        "text": "challenges okay so from a data"
      },
      {
        "start": 254.12,
        "duration": 4.86,
        "text": "perspective there's the usual analyst"
      },
      {
        "start": 256.88,
        "duration": 5.789,
        "text": "have to deal with massive quantities of"
      },
      {
        "start": 258.98,
        "duration": 5.39,
        "text": "data data that is coming through it very"
      },
      {
        "start": 262.669,
        "duration": 3.861,
        "text": "high frequency"
      },
      {
        "start": 264.37,
        "duration": 4.59,
        "text": "but then there's also some of the more"
      },
      {
        "start": 266.53,
        "duration": 4.77,
        "text": "data modeling challenges and data"
      },
      {
        "start": 268.96,
        "duration": 4.86,
        "text": "integration challenges around okay if"
      },
      {
        "start": 271.3,
        "duration": 5.13,
        "text": "I'm an analyst trying to I create a full"
      },
      {
        "start": 273.82,
        "duration": 5.159,
        "text": "network to analyze how do I connect all"
      },
      {
        "start": 276.43,
        "duration": 6.84,
        "text": "these different types of data across"
      },
      {
        "start": 278.979,
        "duration": 8.071,
        "text": "different data sets okay and that also"
      },
      {
        "start": 283.27,
        "duration": 5.19,
        "text": "includes specifically things that are"
      },
      {
        "start": 287.05,
        "duration": 4.23,
        "text": "not connecting things that are not"
      },
      {
        "start": 288.46,
        "duration": 6.78,
        "text": "strongly keyed so how do I know if I'm"
      },
      {
        "start": 291.28,
        "duration": 6.23,
        "text": "looking at airline data that one plane"
      },
      {
        "start": 295.24,
        "duration": 6.299,
        "text": "ticket for max Melnik is the same as max"
      },
      {
        "start": 297.51,
        "duration": 7.21,
        "text": "genomic in another airline system and so"
      },
      {
        "start": 301.539,
        "duration": 6.571,
        "text": "how do i connect those or resolve those"
      },
      {
        "start": 304.72,
        "duration": 6.0,
        "text": "two entities to create one max Melnik"
      },
      {
        "start": 308.11,
        "duration": 4.71,
        "text": "entity ok the analyst yeah right okay so"
      },
      {
        "start": 310.72,
        "duration": 3.479,
        "text": "and we've we've had discussions on this"
      },
      {
        "start": 312.82,
        "duration": 4.95,
        "text": "show before about entity resolution"
      },
      {
        "start": 314.199,
        "duration": 6.391,
        "text": "problems and why graph databases are"
      },
      {
        "start": 317.77,
        "duration": 5.369,
        "text": "especially well equipped rather than"
      },
      {
        "start": 320.59,
        "duration": 4.26,
        "text": "maybe in a classic sense like writing a"
      },
      {
        "start": 323.139,
        "duration": 3.411,
        "text": "massive joint statement that would go"
      },
      {
        "start": 324.85,
        "duration": 3.749,
        "text": "and figure some of these things out so"
      },
      {
        "start": 326.55,
        "duration": 3.97,
        "text": "am I on the right track is that"
      },
      {
        "start": 328.599,
        "duration": 5.761,
        "text": "direction that you guys headed down grab"
      },
      {
        "start": 330.52,
        "duration": 6.149,
        "text": "absolutely yeah and so as far as some of"
      },
      {
        "start": 334.36,
        "duration": 4.86,
        "text": "those problems inspired us to create a"
      },
      {
        "start": 336.669,
        "duration": 5.131,
        "text": "product called mission graph yeah and at"
      },
      {
        "start": 339.22,
        "duration": 7.259,
        "text": "the core it's about a self-service"
      },
      {
        "start": 341.8,
        "duration": 8.67,
        "text": "platform for analysts to create a real"
      },
      {
        "start": 346.479,
        "duration": 5.701,
        "text": "comprehensive network that combines lots"
      },
      {
        "start": 350.47,
        "duration": 4.11,
        "text": "of different data from lots of different"
      },
      {
        "start": 352.18,
        "duration": 4.2,
        "text": "domains so that they can do analysis"
      },
      {
        "start": 354.58,
        "duration": 4.619,
        "text": "like I was talking about before around"
      },
      {
        "start": 356.38,
        "duration": 6.21,
        "text": "identifying bad actors in the network"
      },
      {
        "start": 359.199,
        "duration": 5.701,
        "text": "okay and what yeah kind of real fast"
      },
      {
        "start": 362.59,
        "duration": 4.049,
        "text": "like what what does that usage pattern"
      },
      {
        "start": 364.9,
        "duration": 5.04,
        "text": "look like for an analyst and sitting in"
      },
      {
        "start": 366.639,
        "duration": 6.861,
        "text": "front of the tool what can I do yeah"
      },
      {
        "start": 369.94,
        "duration": 7.11,
        "text": "a lot of it's around interactive network"
      },
      {
        "start": 373.5,
        "duration": 5.77,
        "text": "exploration and analysis so some of the"
      },
      {
        "start": 377.05,
        "duration": 4.679,
        "text": "key core questions that we enable an"
      },
      {
        "start": 379.27,
        "duration": 5.01,
        "text": "analyst to answer our one tell me"
      },
      {
        "start": 381.729,
        "duration": 4.591,
        "text": "everything about this entity it be a"
      },
      {
        "start": 384.28,
        "duration": 4.08,
        "text": "person so that they can see okay is"
      },
      {
        "start": 386.32,
        "duration": 4.65,
        "text": "there any kind of risky information that"
      },
      {
        "start": 388.36,
        "duration": 4.23,
        "text": "they have but also more powerfully and"
      },
      {
        "start": 390.97,
        "duration": 6.45,
        "text": "getting kind of to the graph side of"
      },
      {
        "start": 392.59,
        "duration": 10.23,
        "text": "things what bad actors might this entity"
      },
      {
        "start": 397.42,
        "duration": 7.5,
        "text": "related to and so that's part of the"
      },
      {
        "start": 402.82,
        "duration": 5.69,
        "text": "solution that we help analysts and so"
      },
      {
        "start": 404.92,
        "duration": 6.3,
        "text": "that's and other pieces of that are also"
      },
      {
        "start": 408.51,
        "duration": 5.8,
        "text": "more on the graph analysis side around"
      },
      {
        "start": 411.22,
        "duration": 6.48,
        "text": "how are these two entities whether it's"
      },
      {
        "start": 414.31,
        "duration": 4.89,
        "text": "organizations or people related yeah so"
      },
      {
        "start": 417.7,
        "duration": 4.74,
        "text": "that's kind of like a graph shortest"
      },
      {
        "start": 419.2,
        "duration": 4.74,
        "text": "path problem okay cool okay so it sounds"
      },
      {
        "start": 422.44,
        "duration": 3.39,
        "text": "like what you mention there is a little"
      },
      {
        "start": 423.94,
        "duration": 4.44,
        "text": "bit of a search problem just locating"
      },
      {
        "start": 425.83,
        "duration": 4.11,
        "text": "entities in this in this you know"
      },
      {
        "start": 428.38,
        "duration": 3.84,
        "text": "treasure trove of data that we have and"
      },
      {
        "start": 429.94,
        "duration": 3.9,
        "text": "then a graph problem of navigating"
      },
      {
        "start": 432.22,
        "duration": 3.3,
        "text": "relationships between them"
      },
      {
        "start": 433.84,
        "duration": 3.95,
        "text": "I love the visual that you kind of"
      },
      {
        "start": 435.52,
        "duration": 4.53,
        "text": "showed in your talk this morning where"
      },
      {
        "start": 437.79,
        "duration": 3.58,
        "text": "there was a particular entity of"
      },
      {
        "start": 440.05,
        "duration": 2.67,
        "text": "interest that you zeroed in on you"
      },
      {
        "start": 441.37,
        "duration": 3.57,
        "text": "search for it you found it in the graph"
      },
      {
        "start": 442.72,
        "duration": 4.17,
        "text": "and then began kind of traversing"
      },
      {
        "start": 444.94,
        "duration": 4.47,
        "text": "relationships and the visualization was"
      },
      {
        "start": 446.89,
        "duration": 4.89,
        "text": "such that we could very clearly see like"
      },
      {
        "start": 449.41,
        "duration": 5.28,
        "text": "three suspicious entities that were two"
      },
      {
        "start": 451.78,
        "duration": 4.62,
        "text": "hops away from that node which made us"
      },
      {
        "start": 454.69,
        "duration": 3.27,
        "text": "kind of like oh we should dig in and"
      },
      {
        "start": 456.4,
        "duration": 3.15,
        "text": "really investigate I can imagine an"
      },
      {
        "start": 457.96,
        "duration": 2.91,
        "text": "analyst saying okay this is something I"
      },
      {
        "start": 459.55,
        "duration": 3.21,
        "text": "need to pay attention to you yeah right"
      },
      {
        "start": 460.87,
        "duration": 3.81,
        "text": "now they spend so much time with the"
      },
      {
        "start": 462.76,
        "duration": 4.56,
        "text": "data collection accessing the data"
      },
      {
        "start": 464.68,
        "duration": 5.01,
        "text": "integrating the data we want them to"
      },
      {
        "start": 467.32,
        "duration": 5.22,
        "text": "spend more time with the analysis so"
      },
      {
        "start": 469.69,
        "duration": 4.71,
        "text": "that they can identify bad guys and"
      },
      {
        "start": 472.54,
        "duration": 5.22,
        "text": "whether if you're law enforcement for"
      },
      {
        "start": 474.4,
        "duration": 5.55,
        "text": "example put people in jail gotcha okay"
      },
      {
        "start": 477.76,
        "duration": 5.46,
        "text": "so we're not gonna go through your whole"
      },
      {
        "start": 479.95,
        "duration": 5.55,
        "text": "technology stack here I know that like"
      },
      {
        "start": 483.22,
        "duration": 3.6,
        "text": "you know some people are like hey let me"
      },
      {
        "start": 485.5,
        "duration": 2.49,
        "text": "show you pictures of my kids that I've"
      },
      {
        "start": 486.82,
        "duration": 3.48,
        "text": "got here on my phone I feel like"
      },
      {
        "start": 487.99,
        "duration": 3.72,
        "text": "Architects are like yeah you want to see"
      },
      {
        "start": 490.3,
        "duration": 2.16,
        "text": "my technology stack this is what I'm"
      },
      {
        "start": 491.71,
        "duration": 2.31,
        "text": "using"
      },
      {
        "start": 492.46,
        "duration": 3.06,
        "text": "we live to trade stories so I mean I"
      },
      {
        "start": 494.02,
        "duration": 4.23,
        "text": "know that you built a solution that's on"
      },
      {
        "start": 495.52,
        "duration": 5.55,
        "text": "Cassandra at the core I'm using data sex"
      },
      {
        "start": 498.25,
        "duration": 4.59,
        "text": "search and graph what is some advice"
      },
      {
        "start": 501.07,
        "duration": 2.94,
        "text": "that you have like lessons learned that"
      },
      {
        "start": 502.84,
        "duration": 3.33,
        "text": "you would share with people that are"
      },
      {
        "start": 504.01,
        "duration": 5.67,
        "text": "adopting this technology you can help of"
      },
      {
        "start": 506.17,
        "duration": 6.059,
        "text": "things so the first lesson learned and I"
      },
      {
        "start": 509.68,
        "duration": 5.28,
        "text": "like to remind people about is no the"
      },
      {
        "start": 512.229,
        "duration": 5.011,
        "text": "data stacks and Cassandra anti-patterns"
      },
      {
        "start": 514.96,
        "duration": 6.12,
        "text": "and best practices that goes for really"
      },
      {
        "start": 517.24,
        "duration": 6.3,
        "text": "any tool that you're using so one"
      },
      {
        "start": 521.08,
        "duration": 7.24,
        "text": "example at one implementation we ended"
      },
      {
        "start": 523.54,
        "duration": 10.21,
        "text": "up having the infrastructure team"
      },
      {
        "start": 528.32,
        "duration": 8.55,
        "text": "and the servers on storage back"
      },
      {
        "start": 533.75,
        "duration": 5.64,
        "text": "I'm sorry Network back story oh wait a"
      },
      {
        "start": 536.87,
        "duration": 4.91,
        "text": "minute okay as we all know that is one"
      },
      {
        "start": 539.39,
        "duration": 5.52,
        "text": "of the big anti patterns for running"
      },
      {
        "start": 541.78,
        "duration": 6.55,
        "text": "Cassandra on some kind of sand and no"
      },
      {
        "start": 544.91,
        "duration": 5.91,
        "text": "sands people know yeah it created a lot"
      },
      {
        "start": 548.33,
        "duration": 4.65,
        "text": "of heartburn for the ops team and the"
      },
      {
        "start": 550.82,
        "duration": 6.12,
        "text": "the developers who are trying to get"
      },
      {
        "start": 552.98,
        "duration": 7.14,
        "text": "these massive data loads integrated into"
      },
      {
        "start": 556.94,
        "duration": 5.13,
        "text": "our application right so you can see why"
      },
      {
        "start": 560.12,
        "duration": 4.65,
        "text": "it would be attractive but there's some"
      },
      {
        "start": 562.07,
        "duration": 4.62,
        "text": "caveats there yeah and I"
      },
      {
        "start": 564.77,
        "duration": 5.76,
        "text": "I love the documentation on the data"
      },
      {
        "start": 566.69,
        "duration": 5.76,
        "text": "stacks site that has explicitly or some"
      },
      {
        "start": 570.53,
        "duration": 5.34,
        "text": "of the anti patterns and best practices"
      },
      {
        "start": 572.45,
        "duration": 5.55,
        "text": "and how to make your platform production"
      },
      {
        "start": 575.87,
        "duration": 4.26,
        "text": "ready so definitely recommend people"
      },
      {
        "start": 578.0,
        "duration": 3.9,
        "text": "going in looking at those even if you've"
      },
      {
        "start": 580.13,
        "duration": 4.65,
        "text": "been running data stacks for a while it"
      },
      {
        "start": 581.9,
        "duration": 5.1,
        "text": "probably pays to revisit them do a"
      },
      {
        "start": 584.78,
        "duration": 4.08,
        "text": "health check yeah okay that's good"
      },
      {
        "start": 587.0,
        "duration": 4.74,
        "text": "that's a good one what else you got the"
      },
      {
        "start": 588.86,
        "duration": 4.98,
        "text": "next thing as far as onboarding new team"
      },
      {
        "start": 591.74,
        "duration": 5.69,
        "text": "members this is something we deal with a"
      },
      {
        "start": 593.84,
        "duration": 6.69,
        "text": "lot is we've been growing and that is"
      },
      {
        "start": 597.43,
        "duration": 6.91,
        "text": "start simple relative to that team"
      },
      {
        "start": 600.53,
        "duration": 5.94,
        "text": "members experience level and so for"
      },
      {
        "start": 604.34,
        "duration": 5.55,
        "text": "example with junior practitioners a lot"
      },
      {
        "start": 606.47,
        "duration": 5.7,
        "text": "of times if we say ok go into the actual"
      },
      {
        "start": 609.89,
        "duration": 5.91,
        "text": "application code whether it's the data"
      },
      {
        "start": 612.17,
        "duration": 5.58,
        "text": "pipeline code and start modifying it it"
      },
      {
        "start": 615.8,
        "duration": 5.01,
        "text": "can get a lot it can get very"
      },
      {
        "start": 617.75,
        "duration": 5.46,
        "text": "overwhelming and so what I like to do is"
      },
      {
        "start": 620.81,
        "duration": 4.05,
        "text": "start a little bit more simple and for"
      },
      {
        "start": 623.21,
        "duration": 5.1,
        "text": "example I know a lot of the data stacks"
      },
      {
        "start": 624.86,
        "duration": 5.61,
        "text": "Academy videos they have this reference"
      },
      {
        "start": 628.31,
        "duration": 4.92,
        "text": "application killer video that's a little"
      },
      {
        "start": 630.47,
        "duration": 4.89,
        "text": "bit more simple and I know that we head"
      },
      {
        "start": 633.23,
        "duration": 3.63,
        "text": "around so starting with things that are"
      },
      {
        "start": 635.36,
        "duration": 4.44,
        "text": "a little bit more simple and"
      },
      {
        "start": 636.86,
        "duration": 5.79,
        "text": "straightforward to help people ramp up"
      },
      {
        "start": 639.8,
        "duration": 4.53,
        "text": "is one thing that I recommend ok good"
      },
      {
        "start": 642.65,
        "duration": 4.19,
        "text": "that makes a lot of sense I mean I I"
      },
      {
        "start": 644.33,
        "duration": 5.16,
        "text": "definitely I'm sympathetic because I've"
      },
      {
        "start": 646.84,
        "duration": 3.85,
        "text": "thrown myself into situations and thrown"
      },
      {
        "start": 649.49,
        "duration": 3.45,
        "text": "on with other people into situations"
      },
      {
        "start": 650.69,
        "duration": 4.44,
        "text": "where you're trying to learn new"
      },
      {
        "start": 652.94,
        "duration": 4.59,
        "text": "technology and it's not just one new"
      },
      {
        "start": 655.13,
        "duration": 4.74,
        "text": "technology learning curve it's like hey"
      },
      {
        "start": 657.53,
        "duration": 4.409,
        "text": "can you go use this distributed database"
      },
      {
        "start": 659.87,
        "duration": 4.109,
        "text": "and by the way you also need to learn"
      },
      {
        "start": 661.939,
        "duration": 4.77,
        "text": "how to deploy in the cloud and here's"
      },
      {
        "start": 663.979,
        "duration": 4.38,
        "text": "the CLI for the clap for our cloud that"
      },
      {
        "start": 666.709,
        "duration": 3.78,
        "text": "we're using and oh you know your head"
      },
      {
        "start": 668.359,
        "duration": 3.78,
        "text": "begins to explode so that's that's good"
      },
      {
        "start": 670.489,
        "duration": 3.3,
        "text": "measured advice about how to just kind"
      },
      {
        "start": 672.139,
        "duration": 3.21,
        "text": "of take your time find some resources"
      },
      {
        "start": 673.789,
        "duration": 3.3,
        "text": "that can really work you through it"
      },
      {
        "start": 675.349,
        "duration": 3.27,
        "text": "alright we'll keep them coming you have"
      },
      {
        "start": 677.089,
        "duration": 4.65,
        "text": "more you're more of these absolutely"
      },
      {
        "start": 678.619,
        "duration": 3.9,
        "text": "okay so one thing more specific to graph"
      },
      {
        "start": 681.739,
        "duration": 4.231,
        "text": "yeah"
      },
      {
        "start": 682.519,
        "duration": 8.19,
        "text": "is I recommend if you're trying to load"
      },
      {
        "start": 685.97,
        "duration": 7.859,
        "text": "or modify lots of data in DAC graph to"
      },
      {
        "start": 690.709,
        "duration": 7.65,
        "text": "use the DSC graph frames library that is"
      },
      {
        "start": 693.829,
        "duration": 7.32,
        "text": "built into DSC sparc okay and we had a"
      },
      {
        "start": 698.359,
        "duration": 5.01,
        "text": "lot of challenges originally we had were"
      },
      {
        "start": 701.149,
        "duration": 4.56,
        "text": "programming trying to load a bunch of"
      },
      {
        "start": 703.369,
        "duration": 6.24,
        "text": "data into graph using some of the"
      },
      {
        "start": 705.709,
        "duration": 6.93,
        "text": "lower-level spark api's like Rd B's and"
      },
      {
        "start": 709.609,
        "duration": 6.03,
        "text": "trying to use the DSC Java driver we're"
      },
      {
        "start": 712.639,
        "duration": 5.85,
        "text": "going to load massive amounts of data"
      },
      {
        "start": 715.639,
        "duration": 6.12,
        "text": "using parameterised gremlin statements"
      },
      {
        "start": 718.489,
        "duration": 5.19,
        "text": "which was very performant but it was"
      },
      {
        "start": 721.759,
        "duration": 4.41,
        "text": "very difficult to understand from a"
      },
      {
        "start": 723.679,
        "duration": 5.46,
        "text": "developer's right if it was very fragile"
      },
      {
        "start": 726.169,
        "duration": 5.76,
        "text": "it was hard to debug and then DSC graph"
      },
      {
        "start": 729.139,
        "duration": 4.8,
        "text": "graph frames came out and it made"
      },
      {
        "start": 731.929,
        "duration": 6.96,
        "text": "developers lives a lot easier or not"
      },
      {
        "start": 733.939,
        "duration": 6.39,
        "text": "that code a lot cleaner and also some of"
      },
      {
        "start": 738.889,
        "duration": 3.75,
        "text": "the other benefits that you get out of"
      },
      {
        "start": 740.329,
        "duration": 5.43,
        "text": "that or it integrates nicely with the"
      },
      {
        "start": 742.639,
        "duration": 6.42,
        "text": "higher-level spark api's and then also"
      },
      {
        "start": 745.759,
        "duration": 6.57,
        "text": "you can easily take any data that you've"
      },
      {
        "start": 749.059,
        "duration": 5.58,
        "text": "persisted in DSC graph and export it to"
      },
      {
        "start": 752.329,
        "duration": 5.04,
        "text": "a spark graph frame and start doing some"
      },
      {
        "start": 754.639,
        "duration": 4.2,
        "text": "of the more awesome analytics that you"
      },
      {
        "start": 757.369,
        "duration": 4.29,
        "text": "can do out of the spark graph frames"
      },
      {
        "start": 758.839,
        "duration": 4.89,
        "text": "library like running PageRank on your"
      },
      {
        "start": 761.659,
        "duration": 4.05,
        "text": "data and graph doing some of the"
      },
      {
        "start": 763.729,
        "duration": 4.59,
        "text": "community detection algorithms that they"
      },
      {
        "start": 765.709,
        "duration": 6.39,
        "text": "have doing motif finding so real"
      },
      {
        "start": 768.319,
        "duration": 6.48,
        "text": "powerful graph analytics very quickly"
      },
      {
        "start": 772.099,
        "duration": 3.84,
        "text": "right that's cool that means the tools"
      },
      {
        "start": 774.799,
        "duration": 4.59,
        "text": "in this area are getting more powerful"
      },
      {
        "start": 775.939,
        "duration": 5.58,
        "text": "time and spark api's are changing and"
      },
      {
        "start": 779.389,
        "duration": 3.93,
        "text": "maturing we're responding to that in"
      },
      {
        "start": 781.519,
        "duration": 4.05,
        "text": "data stacks Enterprise with what we're"
      },
      {
        "start": 783.319,
        "duration": 4.98,
        "text": "doing with that and continuing to kind"
      },
      {
        "start": 785.569,
        "duration": 4.2,
        "text": "of push the envelope in this area so I"
      },
      {
        "start": 788.299,
        "duration": 2.82,
        "text": "think it's good maybe to come back every"
      },
      {
        "start": 789.769,
        "duration": 3.15,
        "text": "once in a while and just really look and"
      },
      {
        "start": 791.119,
        "duration": 4.08,
        "text": "see what's available and how the api's"
      },
      {
        "start": 792.919,
        "duration": 2.651,
        "text": "are changing and there may be some you"
      },
      {
        "start": 795.199,
        "duration": 1.781,
        "text": "can get"
      },
      {
        "start": 795.57,
        "duration": 4.259,
        "text": "some lines of code it's a good day for"
      },
      {
        "start": 796.98,
        "duration": 5.31,
        "text": "me as a developer when my net lines of"
      },
      {
        "start": 799.829,
        "duration": 5.671,
        "text": "co-production is negative this is a good"
      },
      {
        "start": 802.29,
        "duration": 4.02,
        "text": "day I like to simplify things clean"
      },
      {
        "start": 805.5,
        "duration": 3.48,
        "text": "things up"
      },
      {
        "start": 806.31,
        "duration": 4.92,
        "text": "exactly thanks for joining us max this"
      },
      {
        "start": 808.98,
        "duration": 4.02,
        "text": "has been a really great episode and I"
      },
      {
        "start": 811.23,
        "duration": 3.479,
        "text": "love having people to talk out about use"
      },
      {
        "start": 813.0,
        "duration": 4.11,
        "text": "cases I'm so glad that you came and did"
      },
      {
        "start": 814.709,
        "duration": 3.421,
        "text": "a keynote for us a developer day that"
      },
      {
        "start": 817.11,
        "duration": 2.669,
        "text": "was amazing"
      },
      {
        "start": 818.13,
        "duration": 4.41,
        "text": "and we're actually gonna share out the"
      },
      {
        "start": 819.779,
        "duration": 4.23,
        "text": "footage of that keynote kind of a long"
      },
      {
        "start": 822.54,
        "duration": 4.14,
        "text": "side we'll release it alongside with"
      },
      {
        "start": 824.009,
        "duration": 4.741,
        "text": "this episode so look for that and you"
      },
      {
        "start": 826.68,
        "duration": 3.63,
        "text": "know to everyone out there we're trying"
      },
      {
        "start": 828.75,
        "duration": 3.449,
        "text": "to get to you with our developer days"
      },
      {
        "start": 830.31,
        "duration": 3.3,
        "text": "we're trying to get one in a city near"
      },
      {
        "start": 832.199,
        "duration": 3.721,
        "text": "you I hear you Denver"
      },
      {
        "start": 833.61,
        "duration": 4.68,
        "text": "I hear you Seattle it's it's coming your"
      },
      {
        "start": 835.92,
        "duration": 4.38,
        "text": "way and maybe this could be you sitting"
      },
      {
        "start": 838.29,
        "duration": 3.299,
        "text": "here talking to me for a distributed"
      },
      {
        "start": 840.3,
        "duration": 3.45,
        "text": "data show episode where we talk about"
      },
      {
        "start": 841.589,
        "duration": 3.391,
        "text": "your use case we would love that we"
      },
      {
        "start": 843.75,
        "duration": 3.23,
        "text": "would love to have you on the show and"
      },
      {
        "start": 844.98,
        "duration": 5.43,
        "text": "hear more about how people are using"
      },
      {
        "start": 846.98,
        "duration": 5.58,
        "text": "Cassandra and do sex Enterprise so until"
      },
      {
        "start": 850.41,
        "duration": 4.44,
        "text": "next time thank you"
      },
      {
        "start": 852.56,
        "duration": 4.269,
        "text": "thank you for joining us again for the"
      },
      {
        "start": 854.85,
        "duration": 3.69,
        "text": "distributed data show we love your"
      },
      {
        "start": 856.829,
        "duration": 3.51,
        "text": "feedback so go to the distributed data"
      },
      {
        "start": 858.54,
        "duration": 3.63,
        "text": "show page on data stacks Academy and"
      },
      {
        "start": 860.339,
        "duration": 3.511,
        "text": "tell us what you think you can also find"
      },
      {
        "start": 862.17,
        "duration": 4.38,
        "text": "us on the data stacks Academy YouTube"
      },
      {
        "start": 863.85,
        "duration": 4.739,
        "text": "channel or find our podcast on itunes"
      },
      {
        "start": 866.55,
        "duration": 4.5,
        "text": "google play or wherever you get great"
      },
      {
        "start": 868.589,
        "duration": 4.141,
        "text": "podcast while you're there make sure and"
      },
      {
        "start": 871.05,
        "duration": 2.49,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 872.73,
        "duration": 5.0,
        "text": "episode"
      },
      {
        "start": 873.54,
        "duration": 4.19,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T05:31:10.083675+00:00"
}