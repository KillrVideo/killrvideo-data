{
  "video_id": "UsenTP029tM",
  "title": "DS320.28 Spark/Cassandra Connector: Joining Tables | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.28 Spark/Cassandra Connector: Joining Tables\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:30:57Z",
  "thumbnail": "https://i.ytimg.com/vi/UsenTP029tM/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=UsenTP029tM",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] now cassandra itself famously doesn't support joins and one of the great things about bringing spark into the picture is that now we have a joint transformation and we can take two rdds we've created from separate cassandra queries join them together just like we're used to so in this example we can see that being done sub-optimally and just like all of our sub-optimal examples it really seems pretty sensible we get an rdd of actors with a trivial query from the actors table convert it into a pair rdd same thing with movies convert it into a pair rdd by actor and then we join those together take a sample and print it out nothing could be easier but we can do better the sparca sander connector gives us a method called join with cassandra table let's take a look if you're joining on columns to the second table which are in the primary key of that second table you want to use this method if you need to override the default join condition you can use the on method now on still has to pick columns that are in the primary key for this to work as an optimization and to be done by the spark cassandra connector it still has to be something that can be converted into cql so that has to be a valid cql query before we get back to our original sub-optimal query and fixing that up let's take a look at an example of how these methods work in some code we're going to begin with a parallelized collection of actor year just to kind of make life easy for ourselves we'll make some simulated keys with johnny depp in 2014 and bruce willis in 2014 that's an actor in a particular year and with that rdd in hand we will join it with the cassandra table movies by actor and so that join gets done in the spark cassandra connector not by spark again the idea there is that we have work done in the cassandra process that doesn't need to serialize data pull it out and push it into the spark process and have spark do work we'd rather do that work locally to cassandra if we can the second query does the same thing but it makes a little bit of a change to the join condition by calling the on method now by default the first query which uses join with cassandra table is going to join only on the partition key which if you look at the schema here is just the actor column you see the results for that first query we're getting all johnny depp movies irrespective of the year so we get one that's released in 2010. if we want to modify the join condition we use the on method and we're going to add release here to the join condition that's one of the clustering columns so we're allowed to do it and still use this optimization in that case if you look at the results of the second query we see only the 2014 movies it would have been impossible for a 2010 movie to be returned by that query now how does this work inside the spark cassandra connector well it implements the classical index based join algorithm which we can see played out in this diagram so the source rdd that we're starting with is over on the left and that includes just for this example johnny depp and bruce willis what the connector is going to do is iterate through the items in that rdd and for each one of them that participates in the join condition it will create a new cql query on the table being joined to and you can see that there's one a select star from movies by actor where actor equals bruce willis and another one where actor equals johnny depp and we'll get some arbitrary number of columns back depending upon how productive those actors have been and those results will be merged into the result of the join and now we can get back to the original inefficient query that we had we were just innocently trying to join two cassandra tables together let's look at our optimized code we do a query on actors and that's an unconstrained query we're getting all of the actors back from uh that table in the cassandra schema and we're joining that with the movies by actor cassandra table you have to look at the schema over on the right and note that the default join condition which is going to be to match partition keys is going to work because both of those share a partition key they're both using actor as the only column in their partition key so that works out trivially for us we then take a sample and print those results out and you see we get a nice optimized join happening partially in spark partially inside the cassandra connector and running faster this brings up a final question is it faster to join movies by actor to actors or actors to movies by actor now a join is communicative so we're going to get the same results either way but they won't necessarily perform the same way let's take a look at these two examples and see if we can figure out which one's faster we see the top one where we query actors first and then join movies by actor to it the second one we query moves by actor first and join actors to it what you have to know is which table has the higher cardinality and i'm just going to guess we could certainly inspect the data and find out for ourselves but i'm going to make an educated guess and say there are more movies than there are actors since most movies contain more than one actor and actors participate in movies multiple times so that first one is going to be faster we want to do a smaller number of queries and since this is an index based join we'll take all the items in that first table and execute a new query for each one of them so if you know for sure that one of your tables has lower cardinality you want to start with that one it'll always be faster",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.96,
        "duration": 3.759,
        "text": "now cassandra itself"
      },
      {
        "start": 8.24,
        "duration": 3.68,
        "text": "famously doesn't support joins and one"
      },
      {
        "start": 10.719,
        "duration": 3.761,
        "text": "of the great things about bringing"
      },
      {
        "start": 11.92,
        "duration": 4.0,
        "text": "spark into the picture is that now we"
      },
      {
        "start": 14.48,
        "duration": 3.2,
        "text": "have a joint transformation and we can"
      },
      {
        "start": 15.92,
        "duration": 3.68,
        "text": "take two rdds we've created from"
      },
      {
        "start": 17.68,
        "duration": 3.599,
        "text": "separate cassandra queries"
      },
      {
        "start": 19.6,
        "duration": 4.08,
        "text": "join them together just like we're used"
      },
      {
        "start": 21.279,
        "duration": 4.721,
        "text": "to so in this example we can see"
      },
      {
        "start": 23.68,
        "duration": 4.72,
        "text": "that being done sub-optimally and just"
      },
      {
        "start": 26.0,
        "duration": 4.24,
        "text": "like all of our sub-optimal examples it"
      },
      {
        "start": 28.4,
        "duration": 4.64,
        "text": "really seems pretty sensible"
      },
      {
        "start": 30.24,
        "duration": 4.72,
        "text": "we get an rdd of actors with a trivial"
      },
      {
        "start": 33.04,
        "duration": 4.24,
        "text": "query from the actors table"
      },
      {
        "start": 34.96,
        "duration": 3.279,
        "text": "convert it into a pair rdd same thing"
      },
      {
        "start": 37.28,
        "duration": 3.76,
        "text": "with movies"
      },
      {
        "start": 38.239,
        "duration": 3.361,
        "text": "convert it into a pair rdd by actor and"
      },
      {
        "start": 41.04,
        "duration": 3.039,
        "text": "then we"
      },
      {
        "start": 41.6,
        "duration": 3.36,
        "text": "join those together take a sample and"
      },
      {
        "start": 44.079,
        "duration": 2.881,
        "text": "print it out"
      },
      {
        "start": 44.96,
        "duration": 3.759,
        "text": "nothing could be easier but we can do"
      },
      {
        "start": 46.96,
        "duration": 3.2,
        "text": "better the sparca sander connector gives"
      },
      {
        "start": 48.719,
        "duration": 4.241,
        "text": "us a method called join"
      },
      {
        "start": 50.16,
        "duration": 4.079,
        "text": "with cassandra table let's take a look"
      },
      {
        "start": 52.96,
        "duration": 3.279,
        "text": "if you're joining on columns to the"
      },
      {
        "start": 54.239,
        "duration": 2.401,
        "text": "second table which are in the primary"
      },
      {
        "start": 56.239,
        "duration": 2.32,
        "text": "key"
      },
      {
        "start": 56.64,
        "duration": 4.079,
        "text": "of that second table you want to use"
      },
      {
        "start": 58.559,
        "duration": 3.84,
        "text": "this method if you need to override the"
      },
      {
        "start": 60.719,
        "duration": 4.48,
        "text": "default join condition"
      },
      {
        "start": 62.399,
        "duration": 3.601,
        "text": "you can use the on method now on still"
      },
      {
        "start": 65.199,
        "duration": 3.761,
        "text": "has to pick"
      },
      {
        "start": 66.0,
        "duration": 4.88,
        "text": "columns that are in the primary key for"
      },
      {
        "start": 68.96,
        "duration": 2.56,
        "text": "this to work as an optimization and to"
      },
      {
        "start": 70.88,
        "duration": 2.32,
        "text": "be done"
      },
      {
        "start": 71.52,
        "duration": 3.12,
        "text": "by the spark cassandra connector it"
      },
      {
        "start": 73.2,
        "duration": 2.88,
        "text": "still has to be something that can be"
      },
      {
        "start": 74.64,
        "duration": 3.44,
        "text": "converted into cql"
      },
      {
        "start": 76.08,
        "duration": 3.679,
        "text": "so that has to be a valid cql query"
      },
      {
        "start": 78.08,
        "duration": 3.359,
        "text": "before we get back to our original"
      },
      {
        "start": 79.759,
        "duration": 3.281,
        "text": "sub-optimal query and fixing that up"
      },
      {
        "start": 81.439,
        "duration": 2.561,
        "text": "let's take a look at an example of how"
      },
      {
        "start": 83.04,
        "duration": 2.88,
        "text": "these methods work"
      },
      {
        "start": 84.0,
        "duration": 3.52,
        "text": "in some code we're going to begin with a"
      },
      {
        "start": 85.92,
        "duration": 3.839,
        "text": "parallelized collection"
      },
      {
        "start": 87.52,
        "duration": 4.0,
        "text": "of actor year just to kind of make life"
      },
      {
        "start": 89.759,
        "duration": 4.881,
        "text": "easy for ourselves we'll make some"
      },
      {
        "start": 91.52,
        "duration": 5.12,
        "text": "simulated keys with johnny depp in 2014"
      },
      {
        "start": 94.64,
        "duration": 4.72,
        "text": "and bruce willis in 2014"
      },
      {
        "start": 96.64,
        "duration": 3.36,
        "text": "that's an actor in a particular year and"
      },
      {
        "start": 99.36,
        "duration": 3.28,
        "text": "with that"
      },
      {
        "start": 100.0,
        "duration": 4.0,
        "text": "rdd in hand we will join it with the"
      },
      {
        "start": 102.64,
        "duration": 4.799,
        "text": "cassandra table"
      },
      {
        "start": 104.0,
        "duration": 3.759,
        "text": "movies by actor and so that join gets"
      },
      {
        "start": 107.439,
        "duration": 2.561,
        "text": "done"
      },
      {
        "start": 107.759,
        "duration": 4.161,
        "text": "in the spark cassandra connector not by"
      },
      {
        "start": 110.0,
        "duration": 2.799,
        "text": "spark again the idea there is that we"
      },
      {
        "start": 111.92,
        "duration": 3.04,
        "text": "have work done"
      },
      {
        "start": 112.799,
        "duration": 3.761,
        "text": "in the cassandra process that doesn't"
      },
      {
        "start": 114.96,
        "duration": 3.199,
        "text": "need to serialize data pull it out and"
      },
      {
        "start": 116.56,
        "duration": 3.519,
        "text": "push it into the spark process"
      },
      {
        "start": 118.159,
        "duration": 3.441,
        "text": "and have spark do work we'd rather do"
      },
      {
        "start": 120.079,
        "duration": 4.72,
        "text": "that work locally to cassandra"
      },
      {
        "start": 121.6,
        "duration": 4.799,
        "text": "if we can the second query does the same"
      },
      {
        "start": 124.799,
        "duration": 3.281,
        "text": "thing but it makes a little bit of a"
      },
      {
        "start": 126.399,
        "duration": 4.56,
        "text": "change to the join condition by"
      },
      {
        "start": 128.08,
        "duration": 4.0,
        "text": "calling the on method now by default the"
      },
      {
        "start": 130.959,
        "duration": 3.441,
        "text": "first query which uses"
      },
      {
        "start": 132.08,
        "duration": 3.519,
        "text": "join with cassandra table is going to"
      },
      {
        "start": 134.4,
        "duration": 3.68,
        "text": "join only"
      },
      {
        "start": 135.599,
        "duration": 3.521,
        "text": "on the partition key which if you look"
      },
      {
        "start": 138.08,
        "duration": 3.44,
        "text": "at the schema here"
      },
      {
        "start": 139.12,
        "duration": 3.759,
        "text": "is just the actor column you see the"
      },
      {
        "start": 141.52,
        "duration": 2.64,
        "text": "results for that first query we're"
      },
      {
        "start": 142.879,
        "duration": 3.44,
        "text": "getting all johnny depp movies"
      },
      {
        "start": 144.16,
        "duration": 4.64,
        "text": "irrespective of the year so we get one"
      },
      {
        "start": 146.319,
        "duration": 4.64,
        "text": "that's released in 2010. if we want to"
      },
      {
        "start": 148.8,
        "duration": 4.64,
        "text": "modify the join condition we use the"
      },
      {
        "start": 150.959,
        "duration": 3.041,
        "text": "on method and we're going to add release"
      },
      {
        "start": 153.44,
        "duration": 2.24,
        "text": "here"
      },
      {
        "start": 154.0,
        "duration": 3.36,
        "text": "to the join condition that's one of the"
      },
      {
        "start": 155.68,
        "duration": 2.16,
        "text": "clustering columns so we're allowed to"
      },
      {
        "start": 157.36,
        "duration": 3.04,
        "text": "do it"
      },
      {
        "start": 157.84,
        "duration": 3.92,
        "text": "and still use this optimization in that"
      },
      {
        "start": 160.4,
        "duration": 2.24,
        "text": "case if you look at the results of the"
      },
      {
        "start": 161.76,
        "duration": 3.92,
        "text": "second query"
      },
      {
        "start": 162.64,
        "duration": 4.0,
        "text": "we see only the 2014 movies it would"
      },
      {
        "start": 165.68,
        "duration": 3.12,
        "text": "have been impossible"
      },
      {
        "start": 166.64,
        "duration": 3.36,
        "text": "for a 2010 movie to be returned by that"
      },
      {
        "start": 168.8,
        "duration": 2.96,
        "text": "query now how does this work"
      },
      {
        "start": 170.0,
        "duration": 3.2,
        "text": "inside the spark cassandra connector"
      },
      {
        "start": 171.76,
        "duration": 3.92,
        "text": "well it implements the"
      },
      {
        "start": 173.2,
        "duration": 3.92,
        "text": "classical index based join algorithm"
      },
      {
        "start": 175.68,
        "duration": 3.199,
        "text": "which we can see played out in this"
      },
      {
        "start": 177.12,
        "duration": 3.28,
        "text": "diagram so the source rdd that we're"
      },
      {
        "start": 178.879,
        "duration": 2.64,
        "text": "starting with is over on the left and"
      },
      {
        "start": 180.4,
        "duration": 3.04,
        "text": "that includes"
      },
      {
        "start": 181.519,
        "duration": 3.841,
        "text": "just for this example johnny depp and"
      },
      {
        "start": 183.44,
        "duration": 2.64,
        "text": "bruce willis what the connector is going"
      },
      {
        "start": 185.36,
        "duration": 4.4,
        "text": "to do"
      },
      {
        "start": 186.08,
        "duration": 4.879,
        "text": "is iterate through the items in that rdd"
      },
      {
        "start": 189.76,
        "duration": 3.28,
        "text": "and for each one of them that"
      },
      {
        "start": 190.959,
        "duration": 5.041,
        "text": "participates in the join condition"
      },
      {
        "start": 193.04,
        "duration": 4.64,
        "text": "it will create a new cql query on the"
      },
      {
        "start": 196.0,
        "duration": 2.08,
        "text": "table being joined to and you can see"
      },
      {
        "start": 197.68,
        "duration": 2.8,
        "text": "that"
      },
      {
        "start": 198.08,
        "duration": 4.48,
        "text": "there's one a select star from movies by"
      },
      {
        "start": 200.48,
        "duration": 3.6,
        "text": "actor where actor equals bruce willis"
      },
      {
        "start": 202.56,
        "duration": 3.28,
        "text": "and another one where actor equals"
      },
      {
        "start": 204.08,
        "duration": 3.76,
        "text": "johnny depp and we'll get"
      },
      {
        "start": 205.84,
        "duration": 3.759,
        "text": "some arbitrary number of columns back"
      },
      {
        "start": 207.84,
        "duration": 2.88,
        "text": "depending upon how productive those"
      },
      {
        "start": 209.599,
        "duration": 4.161,
        "text": "actors have been"
      },
      {
        "start": 210.72,
        "duration": 4.159,
        "text": "and those results will be merged into"
      },
      {
        "start": 213.76,
        "duration": 2.64,
        "text": "the result of the join"
      },
      {
        "start": 214.879,
        "duration": 3.201,
        "text": "and now we can get back to the original"
      },
      {
        "start": 216.4,
        "duration": 3.199,
        "text": "inefficient query that we had we were"
      },
      {
        "start": 218.08,
        "duration": 3.92,
        "text": "just innocently trying to join"
      },
      {
        "start": 219.599,
        "duration": 4.481,
        "text": "two cassandra tables together let's look"
      },
      {
        "start": 222.0,
        "duration": 4.0,
        "text": "at our optimized code we do a query"
      },
      {
        "start": 224.08,
        "duration": 3.28,
        "text": "on actors and that's an unconstrained"
      },
      {
        "start": 226.0,
        "duration": 1.76,
        "text": "query we're getting all of the actors"
      },
      {
        "start": 227.36,
        "duration": 2.56,
        "text": "back"
      },
      {
        "start": 227.76,
        "duration": 4.08,
        "text": "from uh that table in the cassandra"
      },
      {
        "start": 229.92,
        "duration": 2.72,
        "text": "schema and we're joining that with the"
      },
      {
        "start": 231.84,
        "duration": 3.119,
        "text": "movies by"
      },
      {
        "start": 232.64,
        "duration": 4.0,
        "text": "actor cassandra table you have to look"
      },
      {
        "start": 234.959,
        "duration": 4.64,
        "text": "at the schema over on the right"
      },
      {
        "start": 236.64,
        "duration": 4.239,
        "text": "and note that the default join condition"
      },
      {
        "start": 239.599,
        "duration": 3.681,
        "text": "which is going to be to match"
      },
      {
        "start": 240.879,
        "duration": 3.44,
        "text": "partition keys is going to work because"
      },
      {
        "start": 243.28,
        "duration": 3.679,
        "text": "both of those"
      },
      {
        "start": 244.319,
        "duration": 3.441,
        "text": "share a partition key they're both using"
      },
      {
        "start": 246.959,
        "duration": 2.961,
        "text": "actor"
      },
      {
        "start": 247.76,
        "duration": 4.08,
        "text": "as the only column in their partition"
      },
      {
        "start": 249.92,
        "duration": 3.519,
        "text": "key so that works out trivially for us"
      },
      {
        "start": 251.84,
        "duration": 3.679,
        "text": "we then take a sample and print those"
      },
      {
        "start": 253.439,
        "duration": 5.281,
        "text": "results out and you see we get a nice"
      },
      {
        "start": 255.519,
        "duration": 4.0,
        "text": "optimized join happening partially in"
      },
      {
        "start": 258.72,
        "duration": 3.28,
        "text": "spark"
      },
      {
        "start": 259.519,
        "duration": 3.601,
        "text": "partially inside the cassandra connector"
      },
      {
        "start": 262.0,
        "duration": 3.04,
        "text": "and running faster"
      },
      {
        "start": 263.12,
        "duration": 3.04,
        "text": "this brings up a final question is it"
      },
      {
        "start": 265.04,
        "duration": 4.32,
        "text": "faster to join"
      },
      {
        "start": 266.16,
        "duration": 5.759,
        "text": "movies by actor to actors or actors"
      },
      {
        "start": 269.36,
        "duration": 4.16,
        "text": "to movies by actor now a join is"
      },
      {
        "start": 271.919,
        "duration": 3.121,
        "text": "communicative so we're going to get the"
      },
      {
        "start": 273.52,
        "duration": 4.64,
        "text": "same results either way"
      },
      {
        "start": 275.04,
        "duration": 3.68,
        "text": "but they won't necessarily perform the"
      },
      {
        "start": 278.16,
        "duration": 2.4,
        "text": "same way"
      },
      {
        "start": 278.72,
        "duration": 3.28,
        "text": "let's take a look at these two examples"
      },
      {
        "start": 280.56,
        "duration": 2.0,
        "text": "and see if we can figure out which one's"
      },
      {
        "start": 282.0,
        "duration": 3.28,
        "text": "faster"
      },
      {
        "start": 282.56,
        "duration": 3.359,
        "text": "we see the top one where we query actors"
      },
      {
        "start": 285.28,
        "duration": 2.96,
        "text": "first"
      },
      {
        "start": 285.919,
        "duration": 4.241,
        "text": "and then join movies by actor to it the"
      },
      {
        "start": 288.24,
        "duration": 3.12,
        "text": "second one we query moves by actor first"
      },
      {
        "start": 290.16,
        "duration": 4.56,
        "text": "and join actors to it"
      },
      {
        "start": 291.36,
        "duration": 4.88,
        "text": "what you have to know is which table has"
      },
      {
        "start": 294.72,
        "duration": 2.96,
        "text": "the higher cardinality and i'm just"
      },
      {
        "start": 296.24,
        "duration": 3.28,
        "text": "going to guess we could certainly"
      },
      {
        "start": 297.68,
        "duration": 3.6,
        "text": "inspect the data and find out for"
      },
      {
        "start": 299.52,
        "duration": 3.44,
        "text": "ourselves but i'm going to make an"
      },
      {
        "start": 301.28,
        "duration": 2.479,
        "text": "educated guess and say there are more"
      },
      {
        "start": 302.96,
        "duration": 3.2,
        "text": "movies"
      },
      {
        "start": 303.759,
        "duration": 4.241,
        "text": "than there are actors since most movies"
      },
      {
        "start": 306.16,
        "duration": 3.44,
        "text": "contain more than one actor and actors"
      },
      {
        "start": 308.0,
        "duration": 4.0,
        "text": "participate in movies multiple times"
      },
      {
        "start": 309.6,
        "duration": 4.08,
        "text": "so that first one is going to be faster"
      },
      {
        "start": 312.0,
        "duration": 3.84,
        "text": "we want to do a smaller number of"
      },
      {
        "start": 313.68,
        "duration": 2.64,
        "text": "queries and since this is an index based"
      },
      {
        "start": 315.84,
        "duration": 2.32,
        "text": "join"
      },
      {
        "start": 316.32,
        "duration": 3.36,
        "text": "we'll take all the items in that first"
      },
      {
        "start": 318.16,
        "duration": 3.84,
        "text": "table and execute"
      },
      {
        "start": 319.68,
        "duration": 3.6,
        "text": "a new query for each one of them so if"
      },
      {
        "start": 322.0,
        "duration": 2.0,
        "text": "you know for sure that one of your"
      },
      {
        "start": 323.28,
        "duration": 2.639,
        "text": "tables has lower"
      },
      {
        "start": 324.0,
        "duration": 11.52,
        "text": "cardinality you want to start with that"
      },
      {
        "start": 325.919,
        "duration": 9.601,
        "text": "one it'll always be faster"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:28:27.637403+00:00"
}