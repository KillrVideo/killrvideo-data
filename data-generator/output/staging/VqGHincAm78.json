{
  "video_id": "VqGHincAm78",
  "title": "Distributed Data Show Episode 11: Catching up on Apache Spark with Russ Spitzer",
  "description": "DSE Analytics badass Russ Spitzer brings us up to speed on the latest developments in Apache Spark and the implications for DataStax Enterprise Analytics.\n\nABOUT DATASTAX ENTERPRISE 5\nDataStax Enterprise 5.0, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.0 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax EnterpriseÂ©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-09-06T18:03:16Z",
  "thumbnail": "https://i.ytimg.com/vi/VqGHincAm78/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "dse",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=VqGHincAm78",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems welcome once again to another episode of the distributed data show I'm Jeff carpenter live in the studio with Patrick McFadden how you doing Jeff I'm awesome today yeah yes so you get anything new for me well I would like to talk about spark today spark that's at what's old is new again that's right yeah and we have a special guest only we do joining us remotely is from New Orleans Louisiana NOLA is mr. Russ Spitzer welcome rest a rest howdy I think it's important that we highlight Russ as more than just the data sex employee more than just a developer badass developer on DC analytics you're kind of a rockstar in the spark community I have to say when you give a talk on spark the room is always full because you seem to know a few things did you know that you know it's one of the things I try to know but I definitely think I'm as much a beginner as most folks so that's it's a definitely a process to try to learn new things every day you know yes no Matt there's no magic you know let's save our impostor syndrome for another episode exactly but I mean to be fair the spark project is not static it is moving constantly like any good project any popular project it's constantly evolving constantly moving and that's probably why we need to talk today because if you haven't been paying attention to spark for a while there are some things things have changed right yeah I mean the project's changed a lot since the 100 era I mean a lot of people might think about spark and there's thinking about rdd's and thinking about oh I've gotta learn Scala I've gotta you know figure out how to do these mapping and flat mapping all you know functional concepts well cut it sup man we need we probably need to be caught up because I I know when to dot Oh hit I was like oh they changed everything help me and I wasn't you know I was an RDD guy or already already D I keep saying already's because I back in the day no because our our DS or were what you did for graphing when you you had like cacti remember the graphing product and his are DS behind the scene that did name right right you have to be an old ops guy to get into that anyway RT DS so they changed everything so maybe you can give us a catch-up here yeah so I mean just to say if you knew spark before you're probably learning about rdd's these resilient distributed datasets and you basically could treat them like a giant scholar collection so you just have this giant collection and you did maps and flat maps and filters and all that kind of fun stuff and then spark would do a whole lot of distributed work for you but what to do really emphasizes and starts really focusing on this is a different concept called data sets and data sets you might have heard of them as data frames kind of interchangeable a data set is or a data frame it's just a data set of a specific type of thing but it's basically a new way of talking about things you don't have to know as much Scala so a lot of ways to interact with it that don't require knowing any programming at all you can actually interact with it through SQL and the cool thing about it is unlike that RTD approach that you know we used to be using this is a whole bunch of really common commands you know you've got your group bys and your aggregates and your filters and basically everything you could have done in s well you start being able to do with a set of common commands with spark so the real importance the real reason that this is all all important is that data sets and data frames when you do operations on them you're not actually programming the low-level operation you're not actually saying this is what happens when a couple comes in the top hook comes in we do something to it and something goes out that's what you have to do in rdd's catalyst you don't do that or in data frames data when you do something in data sets or the data frames what it does is it takes the description of what you want to do and it figures out under the hood how would you be doing so you mentioned cattle yeah I wanted to cap on that too you just blew that ride by but catalyst you're like oh and because of catalyst no you can't do that here you have to explain yourself sir so catalyst is basically us take the instructions that we give spark take those instructions that's gonna break them down into components that it knows how to reorganize and to optimize for you so before you were doing like RDD i've got an object in I want to get a member of that I'm going to you know do get something you know I'm writing a bunch of Java code or on the Scala code that's like dealing with these objects in catalyst you say like well there'll be a row and this row is gonna have some elements and I'm going to do something on this element of the row but what catalyst does is it looks at that and says oh you're you're manipulating this row you're filtering on this column I don't actually need to do that right now I can tell that this operation can actually happen either earlier in the pipeline or later in the pipeline and I can move it around it says that we don't have to do things the moment you said to in the API it says we can start reorganizing things to be more efficient so alright so I'm I think back in the day we were familiar with DAGs directed acyclic graph you know cuz I just rolls right off the top but is catalyst a replacement for that or an adjunct to that what we're you DAGs were about getting from point A to point B without doing endless loops of course that's bad but where does catalyst you mentioned the order of things dag did that so so yeah so the catalyst is actually building that dag for you it's just building an optimized ad so there's basically a different a new intermediate layer in between your query and what actually happens so before what you wrote is what happened now what you write gets turned into what they call a logical plan which is a description of actions that need to be done on the data another data SP filter the data needs to be joined the data in has this UDF that's applied to it and then below that it changes that and changes that into well if I'm spark and I'm smart I know how to do things can I reorder this so that maybe the parts that take the least amount of data happen first rather than later so you know maybe doing a joint after I do a filter it's a really good idea because it's better to join less data than it is to join lots of data so it'll reorganize things okay hold on you're getting close to I'm you're probably thinking this to cost-based optimizer this is actually one of the newest additions that has been added in 2.2 is a cost-based optimizer has been added so one of the one of the I guess this is one of the newest kind of developments that's happening at spark right now is that we have all these tools now these frameworks for taking user queries and doing optimization just like I was in a relational DB but one of the problems with Big Data is we often don't have the statistics that you would need to actually make smart cost optimizations right we don't really know allottee of columns we don't know you know exactly how big a dataset is I mean we're getting things off of a stream or reading from a file that doesn't have statistics on this sort of thing so one of the big pushes are in the last 2.2 was to first get in the first set of join cost based optimizations well they'll look at your different joints and try to reorder your joins to do the most efficient set of joints possible I mean this is familiar to anyone who's done a lot of matrix multiplication sort of stock you know there's an order tied it all the time you Jeff under napkin especially yeah we do a lot of matrix math here on the show I'll be the next show yeah it's a meister joseph yeah well matrix revolution was one of our best episodes we're probably not gonna release it sorry yeah well basically you know there are identical there were different ways to get an identical result and there different ways can be more efficient so there's no you use the cost based optimization to try to decide which joins should go first which push second which goes third I mean even before this there were all kinds of things like well I have a filter I have this filter on this column why don't I see if the underlying data source like if you're connecting to Cassandra right can handle that filter before the data ever gets to spark and it will move it so even if you said the very last thing you're going to do is filter on this clustering column you know you have this huge query at the end you're filtering on a clustering column it's going to be like wait a minute let me just kind of push that back through the tree and check whether or not the source can handle because if I can do that at the source before we even get into the spark that's a huge benefit and it can do that automatically for you so you've got me sold here on the upgrade but what do you say to somebody that has an existing application that's built on previous versions of spark so do they they want to rewrite all that Scala code that they have that manipulates rdd's or what's the advice there well I think I mean my main advice I'm a pretty pretty conservative programmer when I think something is working and is stable I keep it that way unless we have considerable reason to change it for business interest or otherwise it is really nice to be in this new paradigm because inside of catalysts every upgrade that happens to this optimization engine is passed on to you you don't have to actually keep updating your code to keep up with like oh there's an optimization here it just will automatically be applied as you go through the versions that said if you got your own program that's running rdd's all you have to do is recompile against the new binaries and with a very few exceptions it will still work on spark - oh how heavy Zoey's braking change then so that's it isn't a really a breaking change or is it just a massive change that is covered or mattie to the end-user so it's definitely a binary incompatible change that's that we clearly you cannot just use your old compile jars against the new spark won't work there are breaking changes in some of the and some of the exposed api's and whatnot six they started like introducing this idea of data frames and data sets and all of this and those are completely incompatible with the api's that are presented in two up so you have to be aware if you were testing out this feature and Lund in the one dot line and now you didn't - now though you'll hit a few compile errors and might have to change a few things around things are in different places but that said a lot of the things are pretty much the same so there are a few things I guess some of the key breaking changes are the way that you are supposed to make a context the way you're supposed to initialize your communication with the cluster and the way that you're supposed to handle sessions within within this so this whole idea of an optimizer comes along with its own idea the catalog of its own idea temporary tables and temporary UDS and all this kind of stuff and that gets locked into a new concept that's called the SPARC session so you might remember in SPARC one if you were using spark 1 something called the SQL context yeah that's just when I got used to it ok it's it's still there but it's kind of hidden now is it's basically you access it and it's a wrapper around the SPARC session concept the SPARC session is there new like an entry point for all of this this great data frame data set goodness um well I'll tell you the SQL context was when I found that it was like like the light shone because that means I don't have to write Scala so I just dropped made an ass of SQL statement in this SQL context and I felt happy so don't make it go away it's yeah I mean it's there it's just another inert I mean this is should tell you something about the direction of the project the item you get now when you start up the spark shell being repple but you get to just pop in and writes barcode with gives you an object called spark and the object called spark is a spark session right so this is this is the target this is the future the spark session has references to a context it has references to this SQL context as well but spark is the main entry point it's what they want everyone to kind of be going through so so if we're de-emphasizing the need for Scala code then and then so is SQL is not the dominant like what is the dominant way that I interact it is with the data frame API or would help me out here that's a great question because this is this is the best part about the whole catalyst scheme quiz that great question then you write your code in scala you write your code in java you write your code in Python you write your code in are they all go into that same machinery so you can end up writing the same kind of query in any API you are most comfortable with and you get the same performance benefits as if you had ridden it natively because you aren't actually writing again the physical operations that are happening you don't write that you just write a description of how the data is manipulated and because of that spark doesn't care what language you wrote that at you know you basically just wrote a description it's like well I'll rewrite that description into the lowest level I can and that actually goes into a really interesting other part of catalysts I don't know if you want to talk about that right now of course I'll you know we go but on the scuba gear yeah the time this is one of the reason that a lot of Python people are super excited about dancing because now they don't have to get the side-eye from the scallop people right same performance you get the same performance if you ride in Python you write in Scala oh that that's a that we could stop the interview right now that just feels so good inside cuz you know scallop people they do have that but you know they're they're like oh we're superior though just reminder we are superior and poor Python people have always been like but it's easy right no this is great what an equaliser what a great day for data I mean yeah I mean you could be an hour user right now right you're you know the same performance in the Scala so so this is really great and the reason that all this works is that when it gets down to that physical layer when it's actually writing the code that's gonna perform your calculations gonna do two awesome things two really awesome things so the first is that it's gonna change it into its own memory format right so you're gonna give it like a row and it's gonna say well that row on the onion sparks view it's just this series of bytes with these offsets and it knows exactly you know where those offsets are so it ends up writing these giant blocks of just binary data you know no Java overhead no objects nothing like that it's just a huge hunk of memory that's the awesome thing one the second thing it knows this layout it then writes custom Java code to do bitwise operations and that sort of stuff on the literal byte arrays you know as they're coming through the system so there is no Java serialization at all when you're working with data within this API so fantastic yeah that is really huge because we know 30 operations are the absolute slowest thing you can possibly do in job they've never fixed that day or we blame Oracle for everything so yeah we should just blame that 30 sucks because it work okay I said sure I mean you just got to think about the amount of optimizations that this brings into play right so instead of having an object that you have to call it get iran and the getter has to be looked up and then we have to figure out where would this be in memory and it's got to be put onto the heap into a brand-new Java object that's nice and safe to deal with it's just gonna go straight to the memory and it says well I'm supposed to compare field X with field Y so I just take those bytes when I take those bytes and I can actually just do a native comparison that oh really interesting so then this this sounds a lot like most of this is memory mapped at this point okay is that what it is yeah so we're yeah we're getting to to this awesome layer where it basically is just offering operating and purely on memory you know it's not it's not giant Java objects that are going around anymore that saved heap that will help a lot yeah cuz I I know that back and when I was doing a lot of spark work just trying to manage all the different heaps because every time the executor fires up you know you get all the different workers going at it and those there's a lot of heap was like managing a herd of cats yeah I mean you're doing a lot of garbage collection tons of tiny objects that are constantly being made and destroyed and all of this you know just doesn't have to happen anymore because inside of this paradigm it's a block of memory and out out of it comes another block of memory so that's that's it so it's it's pretty great so that's that's the awesome thing if you're looking for more information on that this is the the in-memory format is called tungsten at least it was called tungsten I don't know people talk about it by that code name anymore but it's it's basically the in-memory format that happens after you do stuff and another cool thing about that is that since it's got this direct memory format you can start doing vectorized readers for a bunch of other formats that have set memory layouts so if you know that your incoming memory looks like column a column B column C called a comma B comma C and you know where those offsets are it can actually just grab chunks and move them directly over like ten rows at a time and stuff like that you can do all kinds of really cool things you know I mean basically you're getting into like SMS IMD type operations then now optimize all these modern processors pretty well yeah I mean it's basically in the best part of all this again is that us the users we don't have to care about it we don't have to think about it at all this happens for us you know you're you can Python this is happening for you you're using Scala this is happening for you you're writing SQL by a JDBC client it still happened you know so you get these benefits regardless of what API you're using so that's so this is a zero this is all here oh yeah oh yeah shipped done out there excellent well 2.2 is the current right as of recording do 2.2 is current it was only released a few weeks ago maybe three that would be July of 2017 yeah and a new features and that or is a bug fix release so well one that one of the coolest things in 2.2 is that structured streaming got moved into being a production ready library it basically took the experimental tags officer right hot epic right yeah so the reason that structured streaming is Stokes all that stuff I just said about catalyst about all this optimization and these low-level operations and this API that you can use an SQL and using the sky like and using Python using our structured streaming does that for stream it it says that whole API that whole thing that you just learned to do all your batch stuff with we're going to just make it so that you change like two things and now it's a streaming job instead that zone cool yeah I mean it's from streaming let's face it that's the hot topic right now with people working with data data arrest great make it faster make it easier for me to get to but streaming data is our problem to solve and there's a lot of I think there are a lot of projects a lot of people talking about how to solve that problem I think spark can really get there faster based on their foundation what do you think I mean I agree I think that one of the huge benefits is that in spark right you can be you can be working on all of your stuff you can work on your code in batch mode you can be testing out the same pipeline with batch code and then all you do is you'll switch your source that you're reading from to a streaming source and then the same code will work so to make the time to prototype and develop this sort of thing really really quick for a lot of people so a spark streaming does that sorry I'm kind of I'm asking a lot of questions for from asking for a friend no it's discrete events versus micro batch which was spark streaming and in the beginning micro batch was great for a lot of use cases not good for discrete so a single object what is there a change there now - are we doing discrete as well as batch so that's that's the big dream this is something that I really I'm still dreaming Mykel Mykel are burst one of the lead developers on spark data bricks do the demo at spark summit this year and of course everyone dropped out of their seats when they saw this the basically he showed a pert Uppal based streaming using structured stream okay so I was gonna fall out of my seat but I'm gonna if you keep talking so while it's not in there yet the way that the API is designed for this whole structure streaming is you can put in you can decide that maybe this is going to be better off using a protocol maybe you really care about that individual item latency you know once an item goes in you want know about it as soon as possible you don't want to like one batch at all and he basically showed that it was possible to have this implemented inside of spark with the way that the code is set up right now so it does not currently exist so if you're still looking for that you'll have to go to something like like a flank or apex or something like that but it probably will not be too long before the code that you write for a micro batching environment and spark streaming could just be instantly switched over to a tupple based event model so Wow alright so then I can know I no longer have to add the rock apart in my smacks that we're gonna be controversial here [Laughter] hey that's a good I don't know he's shifting nervously wow you finally pinned him down you finally stumped rust he's not stumped no he's just not wanting to say that people should or shouldn't use a crab that's I'll leave that for you you can talk about that okay it just got awkward but I like out Gordon Jeff speaking of awkward I do want to comment just as a note here as we closed on there has been a little bit of what I don't know what I want to call it maybe sticker shaming going on we've gotten some listener feedback from what some viewer feedback and noted that mmm conspicuous lack of stickers yeah certain laptops compared to other laptops sorry and we just want to say that we've noted this and we're taking it into account you may notice if you're watching on YouTube that I've added a couple of things I've got a new spark sticker and I'm rocking on here right now with more to come so look the the sticker space on my laptop is currently available there's some real estate left and if your thing if your tech is worthy let's get it on here yeah so this is this should be a thing so if you have a sticker that you feel like needs to be on Jeff's laptop then let us know in the show notes or in the in the comments you can hit us on twitter at data tax academy we wouldn't if you think it's worthy to be on Jeff's laptop then it's a neat you know trade like I we got them we got a lot of stickers here that we can share out the other direction so now my life is going my laptop is fine i'm i have my twenty six pieces of flair I'm good but yes yeah somebody's let's let's wrap this up with I mean let's just face the past of spark just you're catching us up on what's going on looks really bright I'm gonna have to revisit what the future look like now that you've we've got all these goodies what's finish this up with the the grand vision yeah well I mean so the grand vision is spark right is that you will have these machine learning libraries we love graft libraries you'll have all kinds of different technology that just fits on top of this catalyst optimization engine and you already see a bunch of it coming out you know there's that ml live work there's graph frames right but these kind of things are all going to take advantage of the same optimizer the same thing so people will be writing all kinds of different libraries all building up this giant ecosystem that you can access without having to learn anything new so it's it's all about this huge interoperability I mean we didn't even talk about how the fact that with inspark SQL within this catalyst you can take sources from all kinds of different places like our DBMS is no SQL file formats s3 you can combine them all without having to actually write a new connector for any of them and that's really what's because if you're gonna have to get you back Jeff take a note this may be a thing yeah I think we're just gonna have to have because we get behind and then we lose things so Russ will you come back yes welcome back okay so we got that we got that marked in stone he will come back so I think the things we would love to talk about in the future are things like spark streaming graph frames really some really low-level things if you can demonstrate like here's the code that I'm writing and look at what it's doing now would be great if we could show our viewers some of that she also the code gem that actually is happening under the hood I like that so nerdy things good stuff thanks Russ well thank you our listening audience for joining us for another episode and we'll see you next week thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data Stax Academy and tell us what you think you can also find us on the data Stax Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.37,
        "duration": 4.11,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.48,
        "duration": 4.17,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.819,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.61,
        "text": "large-scale distributed systems welcome"
      },
      {
        "start": 17.279,
        "duration": 3.181,
        "text": "once again to another episode of the"
      },
      {
        "start": 19.26,
        "duration": 3.48,
        "text": "distributed data show"
      },
      {
        "start": 20.46,
        "duration": 5.399,
        "text": "I'm Jeff carpenter live in the studio"
      },
      {
        "start": 22.74,
        "duration": 4.59,
        "text": "with Patrick McFadden how you doing Jeff"
      },
      {
        "start": 25.859,
        "duration": 4.461,
        "text": "I'm awesome today"
      },
      {
        "start": 27.33,
        "duration": 5.58,
        "text": "yeah yes so you get anything new for me"
      },
      {
        "start": 30.32,
        "duration": 5.71,
        "text": "well I would like to talk about spark"
      },
      {
        "start": 32.91,
        "duration": 3.75,
        "text": "today spark that's at what's old is new"
      },
      {
        "start": 36.03,
        "duration": 2.97,
        "text": "again"
      },
      {
        "start": 36.66,
        "duration": 5.6,
        "text": "that's right yeah and we have a special"
      },
      {
        "start": 39.0,
        "duration": 8.579,
        "text": "guest only we do joining us remotely is"
      },
      {
        "start": 42.26,
        "duration": 7.54,
        "text": "from New Orleans Louisiana NOLA is mr."
      },
      {
        "start": 47.579,
        "duration": 6.48,
        "text": "Russ Spitzer welcome rest a rest"
      },
      {
        "start": 49.8,
        "duration": 7.89,
        "text": "howdy I think it's important that we"
      },
      {
        "start": 54.059,
        "duration": 5.881,
        "text": "highlight Russ as more than just the"
      },
      {
        "start": 57.69,
        "duration": 5.04,
        "text": "data sex employee more than just a"
      },
      {
        "start": 59.94,
        "duration": 5.07,
        "text": "developer badass developer on DC"
      },
      {
        "start": 62.73,
        "duration": 5.459,
        "text": "analytics you're kind of a rockstar in"
      },
      {
        "start": 65.01,
        "duration": 5.219,
        "text": "the spark community I have to say when"
      },
      {
        "start": 68.189,
        "duration": 4.171,
        "text": "you give a talk on spark the room is"
      },
      {
        "start": 70.229,
        "duration": 5.131,
        "text": "always full because you seem to know a"
      },
      {
        "start": 72.36,
        "duration": 5.82,
        "text": "few things did you know that you know"
      },
      {
        "start": 75.36,
        "duration": 4.53,
        "text": "it's one of the things I try to know but"
      },
      {
        "start": 78.18,
        "duration": 3.86,
        "text": "I definitely think I'm as much a"
      },
      {
        "start": 79.89,
        "duration": 4.409,
        "text": "beginner as most folks so that's it's a"
      },
      {
        "start": 82.04,
        "duration": 5.31,
        "text": "definitely a process to try to learn new"
      },
      {
        "start": 84.299,
        "duration": 5.491,
        "text": "things every day you know yes no Matt"
      },
      {
        "start": 87.35,
        "duration": 4.979,
        "text": "there's no magic you know let's save our"
      },
      {
        "start": 89.79,
        "duration": 5.789,
        "text": "impostor syndrome for another episode"
      },
      {
        "start": 92.329,
        "duration": 7.211,
        "text": "exactly but I mean to be fair the spark"
      },
      {
        "start": 95.579,
        "duration": 5.821,
        "text": "project is not static it is moving"
      },
      {
        "start": 99.54,
        "duration": 4.439,
        "text": "constantly like any good project any"
      },
      {
        "start": 101.4,
        "duration": 4.44,
        "text": "popular project it's constantly evolving"
      },
      {
        "start": 103.979,
        "duration": 4.32,
        "text": "constantly moving and that's probably"
      },
      {
        "start": 105.84,
        "duration": 4.2,
        "text": "why we need to talk today because if you"
      },
      {
        "start": 108.299,
        "duration": 3.661,
        "text": "haven't been paying attention to spark"
      },
      {
        "start": 110.04,
        "duration": 5.52,
        "text": "for a while there are some things things"
      },
      {
        "start": 111.96,
        "duration": 5.67,
        "text": "have changed right yeah I mean the"
      },
      {
        "start": 115.56,
        "duration": 4.11,
        "text": "project's changed a lot since the 100"
      },
      {
        "start": 117.63,
        "duration": 3.87,
        "text": "era I mean a lot of people might think"
      },
      {
        "start": 119.67,
        "duration": 4.47,
        "text": "about spark and there's thinking about"
      },
      {
        "start": 121.5,
        "duration": 4.469,
        "text": "rdd's and thinking about oh I've gotta"
      },
      {
        "start": 124.14,
        "duration": 3.45,
        "text": "learn Scala I've gotta you know figure"
      },
      {
        "start": 125.969,
        "duration": 3.63,
        "text": "out how to do these mapping and flat"
      },
      {
        "start": 127.59,
        "duration": 4.44,
        "text": "mapping all you know functional concepts"
      },
      {
        "start": 129.599,
        "duration": 4.061,
        "text": "well cut it sup man we need we probably"
      },
      {
        "start": 132.03,
        "duration": 3.82,
        "text": "need to be caught up because I"
      },
      {
        "start": 133.66,
        "duration": 5.04,
        "text": "I know when to dot Oh hit I was like oh"
      },
      {
        "start": 135.85,
        "duration": 4.71,
        "text": "they changed everything help me and I"
      },
      {
        "start": 138.7,
        "duration": 4.14,
        "text": "wasn't you know I was an RDD guy or"
      },
      {
        "start": 140.56,
        "duration": 5.1,
        "text": "already already D I keep saying"
      },
      {
        "start": 142.84,
        "duration": 5.16,
        "text": "already's because I back in the day no"
      },
      {
        "start": 145.66,
        "duration": 4.38,
        "text": "because our our DS or were what you did"
      },
      {
        "start": 148.0,
        "duration": 4.59,
        "text": "for graphing when you you had like cacti"
      },
      {
        "start": 150.04,
        "duration": 4.74,
        "text": "remember the graphing product and his"
      },
      {
        "start": 152.59,
        "duration": 3.78,
        "text": "are DS behind the scene that did name"
      },
      {
        "start": 154.78,
        "duration": 4.38,
        "text": "right right you have to be an old ops"
      },
      {
        "start": 156.37,
        "duration": 4.47,
        "text": "guy to get into that anyway RT DS so"
      },
      {
        "start": 159.16,
        "duration": 5.49,
        "text": "they changed everything so maybe you can"
      },
      {
        "start": 160.84,
        "duration": 6.15,
        "text": "give us a catch-up here yeah so I mean"
      },
      {
        "start": 164.65,
        "duration": 3.66,
        "text": "just to say if you knew spark before"
      },
      {
        "start": 166.99,
        "duration": 3.48,
        "text": "you're probably learning about rdd's"
      },
      {
        "start": 168.31,
        "duration": 3.39,
        "text": "these resilient distributed datasets and"
      },
      {
        "start": 170.47,
        "duration": 3.81,
        "text": "you basically could treat them like a"
      },
      {
        "start": 171.7,
        "duration": 4.5,
        "text": "giant scholar collection so you just"
      },
      {
        "start": 174.28,
        "duration": 4.11,
        "text": "have this giant collection and you did"
      },
      {
        "start": 176.2,
        "duration": 4.38,
        "text": "maps and flat maps and filters and all"
      },
      {
        "start": 178.39,
        "duration": 3.51,
        "text": "that kind of fun stuff and then spark"
      },
      {
        "start": 180.58,
        "duration": 5.13,
        "text": "would do a whole lot of distributed work"
      },
      {
        "start": 181.9,
        "duration": 5.61,
        "text": "for you but what to do really emphasizes"
      },
      {
        "start": 185.71,
        "duration": 4.04,
        "text": "and starts really focusing on this is a"
      },
      {
        "start": 187.51,
        "duration": 4.77,
        "text": "different concept called data sets and"
      },
      {
        "start": 189.75,
        "duration": 5.08,
        "text": "data sets you might have heard of them"
      },
      {
        "start": 192.28,
        "duration": 5.82,
        "text": "as data frames kind of interchangeable a"
      },
      {
        "start": 194.83,
        "duration": 6.57,
        "text": "data set is or a data frame it's just a"
      },
      {
        "start": 198.1,
        "duration": 5.22,
        "text": "data set of a specific type of thing but"
      },
      {
        "start": 201.4,
        "duration": 3.36,
        "text": "it's basically a new way of talking"
      },
      {
        "start": 203.32,
        "duration": 3.72,
        "text": "about things you don't have to know as"
      },
      {
        "start": 204.76,
        "duration": 4.26,
        "text": "much Scala so a lot of ways to interact"
      },
      {
        "start": 207.04,
        "duration": 2.94,
        "text": "with it that don't require knowing any"
      },
      {
        "start": 209.02,
        "duration": 4.68,
        "text": "programming at all you can actually"
      },
      {
        "start": 209.98,
        "duration": 5.729,
        "text": "interact with it through SQL and the"
      },
      {
        "start": 213.7,
        "duration": 3.509,
        "text": "cool thing about it is unlike that RTD"
      },
      {
        "start": 215.709,
        "duration": 3.541,
        "text": "approach that you know we used to be"
      },
      {
        "start": 217.209,
        "duration": 4.291,
        "text": "using this is a whole bunch of really"
      },
      {
        "start": 219.25,
        "duration": 4.05,
        "text": "common commands you know you've got your"
      },
      {
        "start": 221.5,
        "duration": 3.989,
        "text": "group bys and your aggregates and your"
      },
      {
        "start": 223.3,
        "duration": 4.89,
        "text": "filters and basically everything you"
      },
      {
        "start": 225.489,
        "duration": 4.741,
        "text": "could have done in s well you start"
      },
      {
        "start": 228.19,
        "duration": 6.6,
        "text": "being able to do with a set of common"
      },
      {
        "start": 230.23,
        "duration": 6.27,
        "text": "commands with spark so the real"
      },
      {
        "start": 234.79,
        "duration": 5.91,
        "text": "importance the real reason that this is"
      },
      {
        "start": 236.5,
        "duration": 5.94,
        "text": "all all important is that data sets and"
      },
      {
        "start": 240.7,
        "duration": 3.96,
        "text": "data frames when you do operations on"
      },
      {
        "start": 242.44,
        "duration": 4.14,
        "text": "them you're not actually programming the"
      },
      {
        "start": 244.66,
        "duration": 3.48,
        "text": "low-level operation you're not actually"
      },
      {
        "start": 246.58,
        "duration": 3.9,
        "text": "saying this is what happens when a"
      },
      {
        "start": 248.14,
        "duration": 3.81,
        "text": "couple comes in the top hook comes in we"
      },
      {
        "start": 250.48,
        "duration": 3.5,
        "text": "do something to it and something goes"
      },
      {
        "start": 251.95,
        "duration": 4.59,
        "text": "out that's what you have to do in rdd's"
      },
      {
        "start": 253.98,
        "duration": 5.08,
        "text": "catalyst you don't do that or in data"
      },
      {
        "start": 256.54,
        "duration": 4.29,
        "text": "frames data when you do something in"
      },
      {
        "start": 259.06,
        "duration": 3.72,
        "text": "data sets or the data frames what it"
      },
      {
        "start": 260.83,
        "duration": 4.53,
        "text": "does is it takes the description of what"
      },
      {
        "start": 262.78,
        "duration": 3.89,
        "text": "you want to do and it figures out under"
      },
      {
        "start": 265.36,
        "duration": 5.12,
        "text": "the hood how would you"
      },
      {
        "start": 266.67,
        "duration": 5.7,
        "text": "be doing so you mentioned cattle yeah I"
      },
      {
        "start": 270.48,
        "duration": 4.29,
        "text": "wanted to cap on that too you just blew"
      },
      {
        "start": 272.37,
        "duration": 4.11,
        "text": "that ride by but catalyst you're like oh"
      },
      {
        "start": 274.77,
        "duration": 3.48,
        "text": "and because of catalyst no you can't do"
      },
      {
        "start": 276.48,
        "duration": 2.46,
        "text": "that here you have to explain yourself"
      },
      {
        "start": 278.25,
        "duration": 3.51,
        "text": "sir"
      },
      {
        "start": 278.94,
        "duration": 5.46,
        "text": "so catalyst is basically us take the"
      },
      {
        "start": 281.76,
        "duration": 4.11,
        "text": "instructions that we give spark take"
      },
      {
        "start": 284.4,
        "duration": 3.15,
        "text": "those instructions that's gonna break"
      },
      {
        "start": 285.87,
        "duration": 4.29,
        "text": "them down into components that it knows"
      },
      {
        "start": 287.55,
        "duration": 4.89,
        "text": "how to reorganize and to optimize for"
      },
      {
        "start": 290.16,
        "duration": 4.35,
        "text": "you so before you were doing like RDD"
      },
      {
        "start": 292.44,
        "duration": 3.51,
        "text": "i've got an object in I want to get a"
      },
      {
        "start": 294.51,
        "duration": 3.87,
        "text": "member of that I'm going to you know do"
      },
      {
        "start": 295.95,
        "duration": 4.35,
        "text": "get something you know I'm writing a"
      },
      {
        "start": 298.38,
        "duration": 3.63,
        "text": "bunch of Java code or on the Scala code"
      },
      {
        "start": 300.3,
        "duration": 3.96,
        "text": "that's like dealing with these objects"
      },
      {
        "start": 302.01,
        "duration": 4.38,
        "text": "in catalyst you say like well there'll"
      },
      {
        "start": 304.26,
        "duration": 3.39,
        "text": "be a row and this row is gonna have some"
      },
      {
        "start": 306.39,
        "duration": 2.82,
        "text": "elements and I'm going to do something"
      },
      {
        "start": 307.65,
        "duration": 4.26,
        "text": "on this element of the row"
      },
      {
        "start": 309.21,
        "duration": 3.99,
        "text": "but what catalyst does is it looks at"
      },
      {
        "start": 311.91,
        "duration": 2.67,
        "text": "that and says oh you're you're"
      },
      {
        "start": 313.2,
        "duration": 4.23,
        "text": "manipulating this row you're filtering"
      },
      {
        "start": 314.58,
        "duration": 4.14,
        "text": "on this column I don't actually need to"
      },
      {
        "start": 317.43,
        "duration": 3.54,
        "text": "do that right now"
      },
      {
        "start": 318.72,
        "duration": 3.75,
        "text": "I can tell that this operation can"
      },
      {
        "start": 320.97,
        "duration": 3.72,
        "text": "actually happen either earlier in the"
      },
      {
        "start": 322.47,
        "duration": 4.56,
        "text": "pipeline or later in the pipeline and I"
      },
      {
        "start": 324.69,
        "duration": 4.11,
        "text": "can move it around it says that we don't"
      },
      {
        "start": 327.03,
        "duration": 3.42,
        "text": "have to do things the moment you said to"
      },
      {
        "start": 328.8,
        "duration": 3.36,
        "text": "in the API it says we can start"
      },
      {
        "start": 330.45,
        "duration": 4.86,
        "text": "reorganizing things to be more efficient"
      },
      {
        "start": 332.16,
        "duration": 4.86,
        "text": "so alright so I'm I think back in the"
      },
      {
        "start": 335.31,
        "duration": 3.42,
        "text": "day we were familiar with DAGs directed"
      },
      {
        "start": 337.02,
        "duration": 4.77,
        "text": "acyclic graph you know cuz I just rolls"
      },
      {
        "start": 338.73,
        "duration": 6.24,
        "text": "right off the top but is catalyst a"
      },
      {
        "start": 341.79,
        "duration": 5.69,
        "text": "replacement for that or an adjunct to"
      },
      {
        "start": 344.97,
        "duration": 4.53,
        "text": "that what we're you DAGs were about"
      },
      {
        "start": 347.48,
        "duration": 4.36,
        "text": "getting from point A to point B without"
      },
      {
        "start": 349.5,
        "duration": 4.8,
        "text": "doing endless loops of course that's bad"
      },
      {
        "start": 351.84,
        "duration": 3.72,
        "text": "but where does catalyst you mentioned"
      },
      {
        "start": 354.3,
        "duration": 6.21,
        "text": "the order of things"
      },
      {
        "start": 355.56,
        "duration": 6.93,
        "text": "dag did that so so yeah so the catalyst"
      },
      {
        "start": 360.51,
        "duration": 4.17,
        "text": "is actually building that dag for you"
      },
      {
        "start": 362.49,
        "duration": 4.59,
        "text": "it's just building an optimized ad so"
      },
      {
        "start": 364.68,
        "duration": 4.77,
        "text": "there's basically a different a new"
      },
      {
        "start": 367.08,
        "duration": 5.76,
        "text": "intermediate layer in between your query"
      },
      {
        "start": 369.45,
        "duration": 5.55,
        "text": "and what actually happens so before what"
      },
      {
        "start": 372.84,
        "duration": 4.02,
        "text": "you wrote is what happened now what you"
      },
      {
        "start": 375.0,
        "duration": 4.14,
        "text": "write gets turned into what they call a"
      },
      {
        "start": 376.86,
        "duration": 3.96,
        "text": "logical plan which is a description of"
      },
      {
        "start": 379.14,
        "duration": 3.6,
        "text": "actions that need to be done on the data"
      },
      {
        "start": 380.82,
        "duration": 4.32,
        "text": "another data SP filter the data needs to"
      },
      {
        "start": 382.74,
        "duration": 5.22,
        "text": "be joined the data in has this UDF"
      },
      {
        "start": 385.14,
        "duration": 5.01,
        "text": "that's applied to it and then below that"
      },
      {
        "start": 387.96,
        "duration": 5.82,
        "text": "it changes that and changes that into"
      },
      {
        "start": 390.15,
        "duration": 4.5,
        "text": "well if I'm spark and I'm smart I know"
      },
      {
        "start": 393.78,
        "duration": 3.06,
        "text": "how to do things"
      },
      {
        "start": 394.65,
        "duration": 3.66,
        "text": "can I reorder this so that maybe the"
      },
      {
        "start": 396.84,
        "duration": 3.83,
        "text": "parts that take the least amount of data"
      },
      {
        "start": 398.31,
        "duration": 4.19,
        "text": "happen first rather than"
      },
      {
        "start": 400.67,
        "duration": 3.6,
        "text": "later so you know maybe doing a joint"
      },
      {
        "start": 402.5,
        "duration": 3.81,
        "text": "after I do a filter it's a really good"
      },
      {
        "start": 404.27,
        "duration": 3.78,
        "text": "idea because it's better to join less"
      },
      {
        "start": 406.31,
        "duration": 4.41,
        "text": "data than it is to join lots of data"
      },
      {
        "start": 408.05,
        "duration": 4.8,
        "text": "so it'll reorganize things okay hold on"
      },
      {
        "start": 410.72,
        "duration": 4.14,
        "text": "you're getting close to I'm you're"
      },
      {
        "start": 412.85,
        "duration": 4.56,
        "text": "probably thinking this to cost-based"
      },
      {
        "start": 414.86,
        "duration": 4.68,
        "text": "optimizer this is actually one of the"
      },
      {
        "start": 417.41,
        "duration": 5.64,
        "text": "newest additions that has been added in"
      },
      {
        "start": 419.54,
        "duration": 6.33,
        "text": "2.2 is a cost-based optimizer has been"
      },
      {
        "start": 423.05,
        "duration": 4.08,
        "text": "added so one of the one of the I guess"
      },
      {
        "start": 425.87,
        "duration": 2.85,
        "text": "this is one of the newest kind of"
      },
      {
        "start": 427.13,
        "duration": 2.13,
        "text": "developments that's happening at spark"
      },
      {
        "start": 428.72,
        "duration": 2.49,
        "text": "right now"
      },
      {
        "start": 429.26,
        "duration": 4.23,
        "text": "is that we have all these tools now"
      },
      {
        "start": 431.21,
        "duration": 4.08,
        "text": "these frameworks for taking user queries"
      },
      {
        "start": 433.49,
        "duration": 3.96,
        "text": "and doing optimization just like I was"
      },
      {
        "start": 435.29,
        "duration": 4.35,
        "text": "in a relational DB but one of the"
      },
      {
        "start": 437.45,
        "duration": 4.05,
        "text": "problems with Big Data is we often don't"
      },
      {
        "start": 439.64,
        "duration": 3.99,
        "text": "have the statistics that you would need"
      },
      {
        "start": 441.5,
        "duration": 5.01,
        "text": "to actually make smart cost"
      },
      {
        "start": 443.63,
        "duration": 5.64,
        "text": "optimizations right we don't really know"
      },
      {
        "start": 446.51,
        "duration": 5.76,
        "text": "allottee of columns we don't know you"
      },
      {
        "start": 449.27,
        "duration": 4.44,
        "text": "know exactly how big a dataset is I mean"
      },
      {
        "start": 452.27,
        "duration": 3.0,
        "text": "we're getting things off of a stream or"
      },
      {
        "start": 453.71,
        "duration": 5.13,
        "text": "reading from a file that doesn't have"
      },
      {
        "start": 455.27,
        "duration": 5.64,
        "text": "statistics on this sort of thing so one"
      },
      {
        "start": 458.84,
        "duration": 3.57,
        "text": "of the big pushes are in the last 2.2"
      },
      {
        "start": 460.91,
        "duration": 3.54,
        "text": "was to first get in the first set of"
      },
      {
        "start": 462.41,
        "duration": 3.36,
        "text": "join cost based optimizations"
      },
      {
        "start": 464.45,
        "duration": 5.1,
        "text": "well they'll look at your different"
      },
      {
        "start": 465.77,
        "duration": 5.55,
        "text": "joints and try to reorder your joins to"
      },
      {
        "start": 469.55,
        "duration": 3.54,
        "text": "do the most efficient set of joints"
      },
      {
        "start": 471.32,
        "duration": 3.21,
        "text": "possible I mean this is familiar to"
      },
      {
        "start": 473.09,
        "duration": 2.97,
        "text": "anyone who's done a lot of matrix"
      },
      {
        "start": 474.53,
        "duration": 3.33,
        "text": "multiplication sort of stock you know"
      },
      {
        "start": 476.06,
        "duration": 4.71,
        "text": "there's an order tied it all the time"
      },
      {
        "start": 477.86,
        "duration": 4.41,
        "text": "you Jeff under napkin especially yeah we"
      },
      {
        "start": 480.77,
        "duration": 3.69,
        "text": "do a lot of matrix math here on the show"
      },
      {
        "start": 482.27,
        "duration": 3.87,
        "text": "I'll be the next show yeah it's a"
      },
      {
        "start": 484.46,
        "duration": 3.33,
        "text": "meister joseph yeah well matrix"
      },
      {
        "start": 486.14,
        "duration": 2.81,
        "text": "revolution was one of our best episodes"
      },
      {
        "start": 487.79,
        "duration": 4.86,
        "text": "we're probably not gonna release it"
      },
      {
        "start": 488.95,
        "duration": 6.28,
        "text": "sorry yeah well basically you know there"
      },
      {
        "start": 492.65,
        "duration": 5.04,
        "text": "are identical there were different ways"
      },
      {
        "start": 495.23,
        "duration": 4.62,
        "text": "to get an identical result and there"
      },
      {
        "start": 497.69,
        "duration": 4.26,
        "text": "different ways can be more efficient so"
      },
      {
        "start": 499.85,
        "duration": 3.63,
        "text": "there's no you use the cost based"
      },
      {
        "start": 501.95,
        "duration": 3.69,
        "text": "optimization to try to decide which"
      },
      {
        "start": 503.48,
        "duration": 4.17,
        "text": "joins should go first which push second"
      },
      {
        "start": 505.64,
        "duration": 4.23,
        "text": "which goes third"
      },
      {
        "start": 507.65,
        "duration": 3.51,
        "text": "I mean even before this there were all"
      },
      {
        "start": 509.87,
        "duration": 3.54,
        "text": "kinds of things like well I have a"
      },
      {
        "start": 511.16,
        "duration": 4.68,
        "text": "filter I have this filter on this column"
      },
      {
        "start": 513.41,
        "duration": 3.78,
        "text": "why don't I see if the underlying data"
      },
      {
        "start": 515.84,
        "duration": 3.42,
        "text": "source like if you're connecting to"
      },
      {
        "start": 517.19,
        "duration": 4.35,
        "text": "Cassandra right can handle that filter"
      },
      {
        "start": 519.26,
        "duration": 4.5,
        "text": "before the data ever gets to spark and"
      },
      {
        "start": 521.54,
        "duration": 3.45,
        "text": "it will move it so even if you said the"
      },
      {
        "start": 523.76,
        "duration": 4.65,
        "text": "very last thing you're going to do is"
      },
      {
        "start": 524.99,
        "duration": 5.34,
        "text": "filter on this clustering column you"
      },
      {
        "start": 528.41,
        "duration": 3.3,
        "text": "know you have this huge query at the end"
      },
      {
        "start": 530.33,
        "duration": 2.61,
        "text": "you're filtering on a clustering column"
      },
      {
        "start": 531.71,
        "duration": 2.7,
        "text": "it's going to be like wait a minute"
      },
      {
        "start": 532.94,
        "duration": 4.079,
        "text": "let me just kind of push"
      },
      {
        "start": 534.41,
        "duration": 4.14,
        "text": "that back through the tree and check"
      },
      {
        "start": 537.019,
        "duration": 3.24,
        "text": "whether or not the source can handle"
      },
      {
        "start": 538.55,
        "duration": 4.26,
        "text": "because if I can do that at the source"
      },
      {
        "start": 540.259,
        "duration": 4.2,
        "text": "before we even get into the spark that's"
      },
      {
        "start": 542.81,
        "duration": 5.699,
        "text": "a huge benefit and it can do that"
      },
      {
        "start": 544.459,
        "duration": 7.591,
        "text": "automatically for you so you've got me"
      },
      {
        "start": 548.509,
        "duration": 5.37,
        "text": "sold here on the upgrade but what do you"
      },
      {
        "start": 552.05,
        "duration": 3.779,
        "text": "say to somebody that has an existing"
      },
      {
        "start": 553.879,
        "duration": 6.031,
        "text": "application that's built on previous"
      },
      {
        "start": 555.829,
        "duration": 5.671,
        "text": "versions of spark so do they they want"
      },
      {
        "start": 559.91,
        "duration": 4.08,
        "text": "to rewrite all that Scala code that they"
      },
      {
        "start": 561.5,
        "duration": 6.899,
        "text": "have that manipulates rdd's or what's"
      },
      {
        "start": 563.99,
        "duration": 5.76,
        "text": "the advice there well I think I mean my"
      },
      {
        "start": 568.399,
        "duration": 4.081,
        "text": "main advice I'm a pretty pretty"
      },
      {
        "start": 569.75,
        "duration": 5.339,
        "text": "conservative programmer when I think"
      },
      {
        "start": 572.48,
        "duration": 4.409,
        "text": "something is working and is stable I"
      },
      {
        "start": 575.089,
        "duration": 3.87,
        "text": "keep it that way unless we have"
      },
      {
        "start": 576.889,
        "duration": 6.421,
        "text": "considerable reason to change it for"
      },
      {
        "start": 578.959,
        "duration": 5.82,
        "text": "business interest or otherwise it is"
      },
      {
        "start": 583.31,
        "duration": 3.959,
        "text": "really nice to be in this new paradigm"
      },
      {
        "start": 584.779,
        "duration": 3.66,
        "text": "because inside of catalysts every"
      },
      {
        "start": 587.269,
        "duration": 3.57,
        "text": "upgrade that happens to this"
      },
      {
        "start": 588.439,
        "duration": 4.38,
        "text": "optimization engine is passed on to you"
      },
      {
        "start": 590.839,
        "duration": 3.331,
        "text": "you don't have to actually keep updating"
      },
      {
        "start": 592.819,
        "duration": 3.181,
        "text": "your code to keep up with like oh"
      },
      {
        "start": 594.17,
        "duration": 3.659,
        "text": "there's an optimization here it just"
      },
      {
        "start": 596.0,
        "duration": 4.019,
        "text": "will automatically be applied as you go"
      },
      {
        "start": 597.829,
        "duration": 3.721,
        "text": "through the versions that said if you"
      },
      {
        "start": 600.019,
        "duration": 4.26,
        "text": "got your own program that's running"
      },
      {
        "start": 601.55,
        "duration": 4.709,
        "text": "rdd's all you have to do is recompile"
      },
      {
        "start": 604.279,
        "duration": 4.891,
        "text": "against the new binaries and with a very"
      },
      {
        "start": 606.259,
        "duration": 5.52,
        "text": "few exceptions it will still work on"
      },
      {
        "start": 609.17,
        "duration": 4.979,
        "text": "spark - oh how heavy Zoey's braking"
      },
      {
        "start": 611.779,
        "duration": 4.381,
        "text": "change then so that's it isn't a really"
      },
      {
        "start": 614.149,
        "duration": 5.341,
        "text": "a breaking change or is it just a"
      },
      {
        "start": 616.16,
        "duration": 5.669,
        "text": "massive change that is covered or mattie"
      },
      {
        "start": 619.49,
        "duration": 4.92,
        "text": "to the end-user so it's definitely a"
      },
      {
        "start": 621.829,
        "duration": 5.101,
        "text": "binary incompatible change that's that"
      },
      {
        "start": 624.41,
        "duration": 5.07,
        "text": "we clearly you cannot just use your old"
      },
      {
        "start": 626.93,
        "duration": 5.55,
        "text": "compile jars against the new spark won't"
      },
      {
        "start": 629.48,
        "duration": 5.969,
        "text": "work there are breaking changes in some"
      },
      {
        "start": 632.48,
        "duration": 4.469,
        "text": "of the and some of the exposed api's and"
      },
      {
        "start": 635.449,
        "duration": 4.08,
        "text": "whatnot six they started like"
      },
      {
        "start": 636.949,
        "duration": 4.86,
        "text": "introducing this idea of data frames and"
      },
      {
        "start": 639.529,
        "duration": 4.321,
        "text": "data sets and all of this and those are"
      },
      {
        "start": 641.809,
        "duration": 4.14,
        "text": "completely incompatible with the api's"
      },
      {
        "start": 643.85,
        "duration": 4.349,
        "text": "that are presented in two up so you have"
      },
      {
        "start": 645.949,
        "duration": 4.14,
        "text": "to be aware if you were testing out this"
      },
      {
        "start": 648.199,
        "duration": 3.961,
        "text": "feature and Lund in the one dot line and"
      },
      {
        "start": 650.089,
        "duration": 3.631,
        "text": "now you didn't - now though you'll hit a"
      },
      {
        "start": 652.16,
        "duration": 3.149,
        "text": "few compile errors and might have to"
      },
      {
        "start": 653.72,
        "duration": 5.19,
        "text": "change a few things around things are in"
      },
      {
        "start": 655.309,
        "duration": 5.941,
        "text": "different places but that said a lot of"
      },
      {
        "start": 658.91,
        "duration": 4.919,
        "text": "the things are pretty much the same so"
      },
      {
        "start": 661.25,
        "duration": 4.47,
        "text": "there are a few things I guess some of"
      },
      {
        "start": 663.829,
        "duration": 4.45,
        "text": "the key breaking changes are the way"
      },
      {
        "start": 665.72,
        "duration": 3.789,
        "text": "that you are supposed to make a"
      },
      {
        "start": 668.279,
        "duration": 2.881,
        "text": "context the way you're supposed to"
      },
      {
        "start": 669.509,
        "duration": 3.69,
        "text": "initialize your communication with the"
      },
      {
        "start": 671.16,
        "duration": 4.619,
        "text": "cluster and the way that you're supposed"
      },
      {
        "start": 673.199,
        "duration": 4.921,
        "text": "to handle sessions within within this so"
      },
      {
        "start": 675.779,
        "duration": 4.23,
        "text": "this whole idea of an optimizer comes"
      },
      {
        "start": 678.12,
        "duration": 4.86,
        "text": "along with its own idea the catalog of"
      },
      {
        "start": 680.009,
        "duration": 4.711,
        "text": "its own idea temporary tables and"
      },
      {
        "start": 682.98,
        "duration": 3.899,
        "text": "temporary UDS and all this kind of stuff"
      },
      {
        "start": 684.72,
        "duration": 4.65,
        "text": "and that gets locked into a new concept"
      },
      {
        "start": 686.879,
        "duration": 4.14,
        "text": "that's called the SPARC session so you"
      },
      {
        "start": 689.37,
        "duration": 3.54,
        "text": "might remember in SPARC one if you were"
      },
      {
        "start": 691.019,
        "duration": 6.99,
        "text": "using spark 1 something called the SQL"
      },
      {
        "start": 692.91,
        "duration": 8.159,
        "text": "context yeah that's just when I got used"
      },
      {
        "start": 698.009,
        "duration": 5.25,
        "text": "to it ok it's it's still there but it's"
      },
      {
        "start": 701.069,
        "duration": 3.93,
        "text": "kind of hidden now is it's basically you"
      },
      {
        "start": 703.259,
        "duration": 3.75,
        "text": "access it and it's a wrapper around the"
      },
      {
        "start": 704.999,
        "duration": 4.95,
        "text": "SPARC session concept the SPARC session"
      },
      {
        "start": 707.009,
        "duration": 5.13,
        "text": "is there new like an entry point for all"
      },
      {
        "start": 709.949,
        "duration": 5.401,
        "text": "of this this great data frame data set"
      },
      {
        "start": 712.139,
        "duration": 5.281,
        "text": "goodness um well I'll tell you the SQL"
      },
      {
        "start": 715.35,
        "duration": 5.609,
        "text": "context was when I found that it was"
      },
      {
        "start": 717.42,
        "duration": 5.609,
        "text": "like like the light shone because that"
      },
      {
        "start": 720.959,
        "duration": 3.901,
        "text": "means I don't have to write Scala so I"
      },
      {
        "start": 723.029,
        "duration": 3.99,
        "text": "just dropped made an ass of SQL"
      },
      {
        "start": 724.86,
        "duration": 6.959,
        "text": "statement in this SQL context and I felt"
      },
      {
        "start": 727.019,
        "duration": 6.091,
        "text": "happy so don't make it go away it's yeah"
      },
      {
        "start": 731.819,
        "duration": 3.24,
        "text": "I mean it's there it's just another"
      },
      {
        "start": 733.11,
        "duration": 3.12,
        "text": "inert I mean this is should tell you"
      },
      {
        "start": 735.059,
        "duration": 4.14,
        "text": "something about the direction of the"
      },
      {
        "start": 736.23,
        "duration": 5.339,
        "text": "project the item you get now when you"
      },
      {
        "start": 739.199,
        "duration": 4.411,
        "text": "start up the spark shell being repple"
      },
      {
        "start": 741.569,
        "duration": 4.291,
        "text": "but you get to just pop in and writes"
      },
      {
        "start": 743.61,
        "duration": 4.86,
        "text": "barcode with gives you an object called"
      },
      {
        "start": 745.86,
        "duration": 6.539,
        "text": "spark and the object called spark is a"
      },
      {
        "start": 748.47,
        "duration": 5.76,
        "text": "spark session right so this is this is"
      },
      {
        "start": 752.399,
        "duration": 4.321,
        "text": "the target this is the future the spark"
      },
      {
        "start": 754.23,
        "duration": 5.31,
        "text": "session has references to a context it"
      },
      {
        "start": 756.72,
        "duration": 6.179,
        "text": "has references to this SQL context as"
      },
      {
        "start": 759.54,
        "duration": 5.099,
        "text": "well but spark is the main entry point"
      },
      {
        "start": 762.899,
        "duration": 5.031,
        "text": "it's what they want everyone to kind of"
      },
      {
        "start": 764.639,
        "duration": 5.851,
        "text": "be going through so so if we're"
      },
      {
        "start": 767.93,
        "duration": 5.86,
        "text": "de-emphasizing the need for Scala code"
      },
      {
        "start": 770.49,
        "duration": 5.189,
        "text": "then and then so is SQL is not the"
      },
      {
        "start": 773.79,
        "duration": 3.779,
        "text": "dominant like what is the dominant way"
      },
      {
        "start": 775.679,
        "duration": 4.2,
        "text": "that I interact it is with the data"
      },
      {
        "start": 777.569,
        "duration": 3.901,
        "text": "frame API or would help me out here"
      },
      {
        "start": 779.879,
        "duration": 3.69,
        "text": "that's a great question because this is"
      },
      {
        "start": 781.47,
        "duration": 5.219,
        "text": "this is the best part about the whole"
      },
      {
        "start": 783.569,
        "duration": 6.091,
        "text": "catalyst scheme quiz that great question"
      },
      {
        "start": 786.689,
        "duration": 4.681,
        "text": "then you write your code in scala you"
      },
      {
        "start": 789.66,
        "duration": 3.75,
        "text": "write your code in java you write your"
      },
      {
        "start": 791.37,
        "duration": 5.809,
        "text": "code in Python you write your code in"
      },
      {
        "start": 793.41,
        "duration": 6.419,
        "text": "are they all go into that same machinery"
      },
      {
        "start": 797.179,
        "duration": 4.811,
        "text": "so you can end up writing the same kind"
      },
      {
        "start": 799.829,
        "duration": 4.021,
        "text": "of query in any API you are"
      },
      {
        "start": 801.99,
        "duration": 4.11,
        "text": "most comfortable with and you get the"
      },
      {
        "start": 803.85,
        "duration": 4.29,
        "text": "same performance benefits as if you had"
      },
      {
        "start": 806.1,
        "duration": 4.14,
        "text": "ridden it natively because you aren't"
      },
      {
        "start": 808.14,
        "duration": 3.72,
        "text": "actually writing again the physical"
      },
      {
        "start": 810.24,
        "duration": 3.599,
        "text": "operations that are happening you don't"
      },
      {
        "start": 811.86,
        "duration": 3.66,
        "text": "write that you just write a description"
      },
      {
        "start": 813.839,
        "duration": 4.531,
        "text": "of how the data is manipulated and"
      },
      {
        "start": 815.52,
        "duration": 4.319,
        "text": "because of that spark doesn't care what"
      },
      {
        "start": 818.37,
        "duration": 3.12,
        "text": "language you wrote that at you know you"
      },
      {
        "start": 819.839,
        "duration": 3.271,
        "text": "basically just wrote a description it's"
      },
      {
        "start": 821.49,
        "duration": 3.78,
        "text": "like well I'll rewrite that description"
      },
      {
        "start": 823.11,
        "duration": 4.169,
        "text": "into the lowest level I can and that"
      },
      {
        "start": 825.27,
        "duration": 3.84,
        "text": "actually goes into a really interesting"
      },
      {
        "start": 827.279,
        "duration": 3.391,
        "text": "other part of catalysts I don't know if"
      },
      {
        "start": 829.11,
        "duration": 4.38,
        "text": "you want to talk about that right now"
      },
      {
        "start": 830.67,
        "duration": 6.72,
        "text": "of course I'll you know we go but on the"
      },
      {
        "start": 833.49,
        "duration": 5.25,
        "text": "scuba gear yeah the time this is one of"
      },
      {
        "start": 837.39,
        "duration": 5.819,
        "text": "the reason that a lot of Python people"
      },
      {
        "start": 838.74,
        "duration": 5.82,
        "text": "are super excited about dancing because"
      },
      {
        "start": 843.209,
        "duration": 5.25,
        "text": "now they don't have to get the side-eye"
      },
      {
        "start": 844.56,
        "duration": 5.52,
        "text": "from the scallop people right same"
      },
      {
        "start": 848.459,
        "duration": 3.451,
        "text": "performance you get the same performance"
      },
      {
        "start": 850.08,
        "duration": 6.12,
        "text": "if you ride in Python you write in Scala"
      },
      {
        "start": 851.91,
        "duration": 6.39,
        "text": "oh that that's a that we could stop the"
      },
      {
        "start": 856.2,
        "duration": 5.54,
        "text": "interview right now that just feels so"
      },
      {
        "start": 858.3,
        "duration": 7.83,
        "text": "good inside cuz you know scallop people"
      },
      {
        "start": 861.74,
        "duration": 5.86,
        "text": "they do have that but you know they're"
      },
      {
        "start": 866.13,
        "duration": 5.19,
        "text": "they're like oh we're superior though"
      },
      {
        "start": 867.6,
        "duration": 5.88,
        "text": "just reminder we are superior and poor"
      },
      {
        "start": 871.32,
        "duration": 5.19,
        "text": "Python people have always been like but"
      },
      {
        "start": 873.48,
        "duration": 5.4,
        "text": "it's easy right no this is great what an"
      },
      {
        "start": 876.51,
        "duration": 4.38,
        "text": "equaliser what a great day for data I"
      },
      {
        "start": 878.88,
        "duration": 7.26,
        "text": "mean yeah I mean you could be an hour"
      },
      {
        "start": 880.89,
        "duration": 7.17,
        "text": "user right now right you're you know the"
      },
      {
        "start": 886.14,
        "duration": 3.27,
        "text": "same performance in the Scala so so this"
      },
      {
        "start": 888.06,
        "duration": 3.45,
        "text": "is really great and the reason that all"
      },
      {
        "start": 889.41,
        "duration": 3.9,
        "text": "this works is that when it gets down to"
      },
      {
        "start": 891.51,
        "duration": 3.24,
        "text": "that physical layer when it's actually"
      },
      {
        "start": 893.31,
        "duration": 5.04,
        "text": "writing the code that's gonna perform"
      },
      {
        "start": 894.75,
        "duration": 4.079,
        "text": "your calculations gonna do two awesome"
      },
      {
        "start": 898.35,
        "duration": 2.609,
        "text": "things"
      },
      {
        "start": 898.829,
        "duration": 4.681,
        "text": "two really awesome things so the first"
      },
      {
        "start": 900.959,
        "duration": 5.101,
        "text": "is that it's gonna change it into its"
      },
      {
        "start": 903.51,
        "duration": 4.8,
        "text": "own memory format right so you're gonna"
      },
      {
        "start": 906.06,
        "duration": 5.49,
        "text": "give it like a row and it's gonna say"
      },
      {
        "start": 908.31,
        "duration": 5.13,
        "text": "well that row on the onion sparks view"
      },
      {
        "start": 911.55,
        "duration": 4.17,
        "text": "it's just this series of bytes with"
      },
      {
        "start": 913.44,
        "duration": 4.08,
        "text": "these offsets and it knows exactly you"
      },
      {
        "start": 915.72,
        "duration": 4.02,
        "text": "know where those offsets are so it ends"
      },
      {
        "start": 917.52,
        "duration": 5.37,
        "text": "up writing these giant blocks of just"
      },
      {
        "start": 919.74,
        "duration": 5.07,
        "text": "binary data you know no Java overhead no"
      },
      {
        "start": 922.89,
        "duration": 4.08,
        "text": "objects nothing like that it's just a"
      },
      {
        "start": 924.81,
        "duration": 6.09,
        "text": "huge hunk of memory that's the awesome"
      },
      {
        "start": 926.97,
        "duration": 7.05,
        "text": "thing one the second thing it knows this"
      },
      {
        "start": 930.9,
        "duration": 4.89,
        "text": "layout it then writes custom Java code"
      },
      {
        "start": 934.02,
        "duration": 4.35,
        "text": "to do bitwise"
      },
      {
        "start": 935.79,
        "duration": 4.65,
        "text": "operations and that sort of stuff on the"
      },
      {
        "start": 938.37,
        "duration": 4.29,
        "text": "literal byte arrays you know as they're"
      },
      {
        "start": 940.44,
        "duration": 5.04,
        "text": "coming through the system so there is no"
      },
      {
        "start": 942.66,
        "duration": 5.58,
        "text": "Java serialization at all when you're"
      },
      {
        "start": 945.48,
        "duration": 5.22,
        "text": "working with data within this API so"
      },
      {
        "start": 948.24,
        "duration": 5.18,
        "text": "fantastic yeah that is really huge"
      },
      {
        "start": 950.7,
        "duration": 4.89,
        "text": "because we know 30 operations are the"
      },
      {
        "start": 953.42,
        "duration": 3.31,
        "text": "absolute slowest thing you can possibly"
      },
      {
        "start": 955.59,
        "duration": 5.49,
        "text": "do in job"
      },
      {
        "start": 956.73,
        "duration": 7.53,
        "text": "they've never fixed that day or we blame"
      },
      {
        "start": 961.08,
        "duration": 5.13,
        "text": "Oracle for everything so yeah we should"
      },
      {
        "start": 964.26,
        "duration": 5.67,
        "text": "just blame that 30 sucks because it work"
      },
      {
        "start": 966.21,
        "duration": 5.58,
        "text": "okay I said sure I mean you just got to"
      },
      {
        "start": 969.93,
        "duration": 3.3,
        "text": "think about the amount of optimizations"
      },
      {
        "start": 971.79,
        "duration": 3.09,
        "text": "that this brings into play right so"
      },
      {
        "start": 973.23,
        "duration": 3.33,
        "text": "instead of having an object that you"
      },
      {
        "start": 974.88,
        "duration": 3.21,
        "text": "have to call it get iran and the getter"
      },
      {
        "start": 976.56,
        "duration": 3.69,
        "text": "has to be looked up and then we have to"
      },
      {
        "start": 978.09,
        "duration": 3.48,
        "text": "figure out where would this be in memory"
      },
      {
        "start": 980.25,
        "duration": 3.27,
        "text": "and it's got to be put onto the heap"
      },
      {
        "start": 981.57,
        "duration": 4.05,
        "text": "into a brand-new Java object that's nice"
      },
      {
        "start": 983.52,
        "duration": 4.08,
        "text": "and safe to deal with it's just gonna go"
      },
      {
        "start": 985.62,
        "duration": 5.25,
        "text": "straight to the memory and it says well"
      },
      {
        "start": 987.6,
        "duration": 6.39,
        "text": "I'm supposed to compare field X with"
      },
      {
        "start": 990.87,
        "duration": 4.71,
        "text": "field Y so I just take those bytes when"
      },
      {
        "start": 993.99,
        "duration": 4.86,
        "text": "I take those bytes and I can actually"
      },
      {
        "start": 995.58,
        "duration": 5.43,
        "text": "just do a native comparison that oh"
      },
      {
        "start": 998.85,
        "duration": 3.87,
        "text": "really interesting so then this this"
      },
      {
        "start": 1001.01,
        "duration": 4.5,
        "text": "sounds a lot like most of this is memory"
      },
      {
        "start": 1002.72,
        "duration": 4.71,
        "text": "mapped at this point okay is that what"
      },
      {
        "start": 1005.51,
        "duration": 4.74,
        "text": "it is yeah so we're yeah we're getting"
      },
      {
        "start": 1007.43,
        "duration": 4.98,
        "text": "to to this awesome layer where it"
      },
      {
        "start": 1010.25,
        "duration": 5.46,
        "text": "basically is just offering operating and"
      },
      {
        "start": 1012.41,
        "duration": 5.07,
        "text": "purely on memory you know it's not it's"
      },
      {
        "start": 1015.71,
        "duration": 2.49,
        "text": "not giant Java objects that are going"
      },
      {
        "start": 1017.48,
        "duration": 5.51,
        "text": "around anymore"
      },
      {
        "start": 1018.2,
        "duration": 8.04,
        "text": "that saved heap that will help a lot"
      },
      {
        "start": 1022.99,
        "duration": 5.65,
        "text": "yeah cuz I I know that back and when I"
      },
      {
        "start": 1026.24,
        "duration": 3.84,
        "text": "was doing a lot of spark work just"
      },
      {
        "start": 1028.64,
        "duration": 4.68,
        "text": "trying to manage all the different heaps"
      },
      {
        "start": 1030.08,
        "duration": 4.29,
        "text": "because every time the executor fires up"
      },
      {
        "start": 1033.32,
        "duration": 5.13,
        "text": "you know you get all the different"
      },
      {
        "start": 1034.37,
        "duration": 6.54,
        "text": "workers going at it and those there's a"
      },
      {
        "start": 1038.45,
        "duration": 4.98,
        "text": "lot of heap was like managing a herd of"
      },
      {
        "start": 1040.91,
        "duration": 4.74,
        "text": "cats yeah I mean you're doing a lot of"
      },
      {
        "start": 1043.43,
        "duration": 3.36,
        "text": "garbage collection tons of tiny objects"
      },
      {
        "start": 1045.65,
        "duration": 3.6,
        "text": "that are constantly being made and"
      },
      {
        "start": 1046.79,
        "duration": 3.96,
        "text": "destroyed and all of this you know just"
      },
      {
        "start": 1049.25,
        "duration": 4.02,
        "text": "doesn't have to happen anymore because"
      },
      {
        "start": 1050.75,
        "duration": 5.04,
        "text": "inside of this paradigm it's a block of"
      },
      {
        "start": 1053.27,
        "duration": 6.18,
        "text": "memory and out out of it comes another"
      },
      {
        "start": 1055.79,
        "duration": 5.7,
        "text": "block of memory so that's that's it so"
      },
      {
        "start": 1059.45,
        "duration": 4.2,
        "text": "it's it's pretty great so that's that's"
      },
      {
        "start": 1061.49,
        "duration": 3.99,
        "text": "the awesome thing if you're looking for"
      },
      {
        "start": 1063.65,
        "duration": 4.83,
        "text": "more information on that this is the the"
      },
      {
        "start": 1065.48,
        "duration": 4.17,
        "text": "in-memory format is called tungsten at"
      },
      {
        "start": 1068.48,
        "duration": 3.0,
        "text": "least it was called tungsten"
      },
      {
        "start": 1069.65,
        "duration": 4.35,
        "text": "I don't know people talk about it by"
      },
      {
        "start": 1071.48,
        "duration": 4.86,
        "text": "that code name anymore but it's it's"
      },
      {
        "start": 1074.0,
        "duration": 5.61,
        "text": "basically the in-memory format that"
      },
      {
        "start": 1076.34,
        "duration": 5.22,
        "text": "happens after you do stuff and another"
      },
      {
        "start": 1079.61,
        "duration": 3.99,
        "text": "cool thing about that is that since it's"
      },
      {
        "start": 1081.56,
        "duration": 4.11,
        "text": "got this direct memory format you can"
      },
      {
        "start": 1083.6,
        "duration": 3.99,
        "text": "start doing vectorized readers for a"
      },
      {
        "start": 1085.67,
        "duration": 4.29,
        "text": "bunch of other formats that have set"
      },
      {
        "start": 1087.59,
        "duration": 5.4,
        "text": "memory layouts so if you know that your"
      },
      {
        "start": 1089.96,
        "duration": 5.28,
        "text": "incoming memory looks like column a"
      },
      {
        "start": 1092.99,
        "duration": 3.63,
        "text": "column B column C called a comma B comma"
      },
      {
        "start": 1095.24,
        "duration": 3.9,
        "text": "C and you know where those offsets are"
      },
      {
        "start": 1096.62,
        "duration": 4.98,
        "text": "it can actually just grab chunks and"
      },
      {
        "start": 1099.14,
        "duration": 4.5,
        "text": "move them directly over like ten rows at"
      },
      {
        "start": 1101.6,
        "duration": 4.38,
        "text": "a time and stuff like that you can do"
      },
      {
        "start": 1103.64,
        "duration": 4.83,
        "text": "all kinds of really cool things you know"
      },
      {
        "start": 1105.98,
        "duration": 6.6,
        "text": "I mean basically you're getting into"
      },
      {
        "start": 1108.47,
        "duration": 6.0,
        "text": "like SMS IMD type operations then now"
      },
      {
        "start": 1112.58,
        "duration": 4.29,
        "text": "optimize all these modern processors"
      },
      {
        "start": 1114.47,
        "duration": 4.92,
        "text": "pretty well yeah I mean it's basically"
      },
      {
        "start": 1116.87,
        "duration": 5.49,
        "text": "in the best part of all this again is"
      },
      {
        "start": 1119.39,
        "duration": 5.28,
        "text": "that us the users we don't have to care"
      },
      {
        "start": 1122.36,
        "duration": 5.46,
        "text": "about it we don't have to think about it"
      },
      {
        "start": 1124.67,
        "duration": 5.34,
        "text": "at all this happens for us you know"
      },
      {
        "start": 1127.82,
        "duration": 4.59,
        "text": "you're you can Python this is happening"
      },
      {
        "start": 1130.01,
        "duration": 4.86,
        "text": "for you you're using Scala this is"
      },
      {
        "start": 1132.41,
        "duration": 5.91,
        "text": "happening for you you're writing SQL by"
      },
      {
        "start": 1134.87,
        "duration": 5.49,
        "text": "a JDBC client it still happened you know"
      },
      {
        "start": 1138.32,
        "duration": 4.38,
        "text": "so you get these benefits regardless of"
      },
      {
        "start": 1140.36,
        "duration": 6.12,
        "text": "what API you're using so that's so this"
      },
      {
        "start": 1142.7,
        "duration": 4.53,
        "text": "is a zero this is all here oh yeah oh"
      },
      {
        "start": 1146.48,
        "duration": 4.71,
        "text": "yeah"
      },
      {
        "start": 1147.23,
        "duration": 7.34,
        "text": "shipped done out there excellent well"
      },
      {
        "start": 1151.19,
        "duration": 6.54,
        "text": "2.2 is the current right as of recording"
      },
      {
        "start": 1154.57,
        "duration": 6.28,
        "text": "do 2.2 is current it was only released a"
      },
      {
        "start": 1157.73,
        "duration": 7.11,
        "text": "few weeks ago maybe three that would be"
      },
      {
        "start": 1160.85,
        "duration": 7.38,
        "text": "July of 2017 yeah and a new features and"
      },
      {
        "start": 1164.84,
        "duration": 5.13,
        "text": "that or is a bug fix release so well one"
      },
      {
        "start": 1168.23,
        "duration": 4.44,
        "text": "that one of the coolest things in 2.2 is"
      },
      {
        "start": 1169.97,
        "duration": 5.19,
        "text": "that structured streaming got moved into"
      },
      {
        "start": 1172.67,
        "duration": 3.84,
        "text": "being a production ready library it"
      },
      {
        "start": 1175.16,
        "duration": 6.48,
        "text": "basically took the experimental tags"
      },
      {
        "start": 1176.51,
        "duration": 6.33,
        "text": "officer right hot epic right yeah so the"
      },
      {
        "start": 1181.64,
        "duration": 4.11,
        "text": "reason that structured streaming is"
      },
      {
        "start": 1182.84,
        "duration": 5.28,
        "text": "Stokes all that stuff I just said about"
      },
      {
        "start": 1185.75,
        "duration": 4.8,
        "text": "catalyst about all this optimization and"
      },
      {
        "start": 1188.12,
        "duration": 4.62,
        "text": "these low-level operations and this API"
      },
      {
        "start": 1190.55,
        "duration": 4.1,
        "text": "that you can use an SQL and using the"
      },
      {
        "start": 1192.74,
        "duration": 4.17,
        "text": "sky like and using Python using our"
      },
      {
        "start": 1194.65,
        "duration": 5.26,
        "text": "structured streaming does that for"
      },
      {
        "start": 1196.91,
        "duration": 4.35,
        "text": "stream it it says that whole API that"
      },
      {
        "start": 1199.91,
        "duration": 2.95,
        "text": "whole thing that you just learned to do"
      },
      {
        "start": 1201.26,
        "duration": 3.13,
        "text": "all your batch stuff with"
      },
      {
        "start": 1202.86,
        "duration": 3.0,
        "text": "we're going to just make it so that you"
      },
      {
        "start": 1204.39,
        "duration": 5.759,
        "text": "change like two things and now it's a"
      },
      {
        "start": 1205.86,
        "duration": 7.62,
        "text": "streaming job instead that zone cool"
      },
      {
        "start": 1210.149,
        "duration": 4.921,
        "text": "yeah I mean it's from streaming let's"
      },
      {
        "start": 1213.48,
        "duration": 3.809,
        "text": "face it that's the hot topic right now"
      },
      {
        "start": 1215.07,
        "duration": 5.4,
        "text": "with people working with data data"
      },
      {
        "start": 1217.289,
        "duration": 4.681,
        "text": "arrest great make it faster make it"
      },
      {
        "start": 1220.47,
        "duration": 3.36,
        "text": "easier for me to get to but streaming"
      },
      {
        "start": 1221.97,
        "duration": 3.39,
        "text": "data is our problem to solve and there's"
      },
      {
        "start": 1223.83,
        "duration": 3.54,
        "text": "a lot of I think there are a lot of"
      },
      {
        "start": 1225.36,
        "duration": 3.24,
        "text": "projects a lot of people talking about"
      },
      {
        "start": 1227.37,
        "duration": 4.26,
        "text": "how to solve that problem"
      },
      {
        "start": 1228.6,
        "duration": 6.179,
        "text": "I think spark can really get there"
      },
      {
        "start": 1231.63,
        "duration": 6.179,
        "text": "faster based on their foundation what do"
      },
      {
        "start": 1234.779,
        "duration": 5.13,
        "text": "you think I mean I agree I think that"
      },
      {
        "start": 1237.809,
        "duration": 4.921,
        "text": "one of the huge benefits is that in"
      },
      {
        "start": 1239.909,
        "duration": 4.14,
        "text": "spark right you can be you can be"
      },
      {
        "start": 1242.73,
        "duration": 3.689,
        "text": "working on all of your stuff you can"
      },
      {
        "start": 1244.049,
        "duration": 4.62,
        "text": "work on your code in batch mode you can"
      },
      {
        "start": 1246.419,
        "duration": 4.921,
        "text": "be testing out the same pipeline with"
      },
      {
        "start": 1248.669,
        "duration": 4.5,
        "text": "batch code and then all you do is you'll"
      },
      {
        "start": 1251.34,
        "duration": 4.5,
        "text": "switch your source that you're reading"
      },
      {
        "start": 1253.169,
        "duration": 5.431,
        "text": "from to a streaming source and then the"
      },
      {
        "start": 1255.84,
        "duration": 4.319,
        "text": "same code will work so to make the time"
      },
      {
        "start": 1258.6,
        "duration": 3.299,
        "text": "to prototype and develop this sort of"
      },
      {
        "start": 1260.159,
        "duration": 3.75,
        "text": "thing really really quick for a lot of"
      },
      {
        "start": 1261.899,
        "duration": 3.811,
        "text": "people so a spark streaming does that"
      },
      {
        "start": 1263.909,
        "duration": 4.02,
        "text": "sorry I'm kind of I'm asking a lot of"
      },
      {
        "start": 1265.71,
        "duration": 7.26,
        "text": "questions for from asking for a friend"
      },
      {
        "start": 1267.929,
        "duration": 6.781,
        "text": "no it's discrete events versus micro"
      },
      {
        "start": 1272.97,
        "duration": 5.939,
        "text": "batch which was spark streaming and in"
      },
      {
        "start": 1274.71,
        "duration": 6.48,
        "text": "the beginning micro batch was great for"
      },
      {
        "start": 1278.909,
        "duration": 6.061,
        "text": "a lot of use cases not good for discrete"
      },
      {
        "start": 1281.19,
        "duration": 5.64,
        "text": "so a single object what is there a"
      },
      {
        "start": 1284.97,
        "duration": 4.829,
        "text": "change there now - are we doing discrete"
      },
      {
        "start": 1286.83,
        "duration": 4.29,
        "text": "as well as batch so that's that's the"
      },
      {
        "start": 1289.799,
        "duration": 4.37,
        "text": "big dream this is something that I"
      },
      {
        "start": 1291.12,
        "duration": 5.789,
        "text": "really I'm still dreaming"
      },
      {
        "start": 1294.169,
        "duration": 5.74,
        "text": "Mykel Mykel are burst one of the lead"
      },
      {
        "start": 1296.909,
        "duration": 6.541,
        "text": "developers on spark data bricks do the"
      },
      {
        "start": 1299.909,
        "duration": 5.551,
        "text": "demo at spark summit this year and of"
      },
      {
        "start": 1303.45,
        "duration": 3.449,
        "text": "course everyone dropped out of their"
      },
      {
        "start": 1305.46,
        "duration": 4.14,
        "text": "seats when they saw this the basically"
      },
      {
        "start": 1306.899,
        "duration": 5.971,
        "text": "he showed a pert Uppal based streaming"
      },
      {
        "start": 1309.6,
        "duration": 4.77,
        "text": "using structured stream okay so I was"
      },
      {
        "start": 1312.87,
        "duration": 8.58,
        "text": "gonna fall out of my seat but I'm gonna"
      },
      {
        "start": 1314.37,
        "duration": 9.12,
        "text": "if you keep talking so while it's not in"
      },
      {
        "start": 1321.45,
        "duration": 3.719,
        "text": "there yet the way that the API is"
      },
      {
        "start": 1323.49,
        "duration": 3.45,
        "text": "designed for this whole structure"
      },
      {
        "start": 1325.169,
        "duration": 3.571,
        "text": "streaming is you can put in you can"
      },
      {
        "start": 1326.94,
        "duration": 4.229,
        "text": "decide that maybe this is going to be"
      },
      {
        "start": 1328.74,
        "duration": 4.23,
        "text": "better off using a protocol maybe you"
      },
      {
        "start": 1331.169,
        "duration": 4.201,
        "text": "really care about that individual item"
      },
      {
        "start": 1332.97,
        "duration": 2.8,
        "text": "latency you know once an item goes in"
      },
      {
        "start": 1335.37,
        "duration": 2.08,
        "text": "you want"
      },
      {
        "start": 1335.77,
        "duration": 3.15,
        "text": "know about it as soon as possible you"
      },
      {
        "start": 1337.45,
        "duration": 3.18,
        "text": "don't want to like one batch at all"
      },
      {
        "start": 1338.92,
        "duration": 3.78,
        "text": "and he basically showed that it was"
      },
      {
        "start": 1340.63,
        "duration": 5.1,
        "text": "possible to have this implemented inside"
      },
      {
        "start": 1342.7,
        "duration": 5.28,
        "text": "of spark with the way that the code is"
      },
      {
        "start": 1345.73,
        "duration": 4.17,
        "text": "set up right now so it does not"
      },
      {
        "start": 1347.98,
        "duration": 3.24,
        "text": "currently exist so if you're still"
      },
      {
        "start": 1349.9,
        "duration": 4.11,
        "text": "looking for that you'll have to go to"
      },
      {
        "start": 1351.22,
        "duration": 5.28,
        "text": "something like like a flank or apex or"
      },
      {
        "start": 1354.01,
        "duration": 4.5,
        "text": "something like that but it probably will"
      },
      {
        "start": 1356.5,
        "duration": 4.17,
        "text": "not be too long before the code that you"
      },
      {
        "start": 1358.51,
        "duration": 3.57,
        "text": "write for a micro batching environment"
      },
      {
        "start": 1360.67,
        "duration": 4.2,
        "text": "and spark streaming could just be"
      },
      {
        "start": 1362.08,
        "duration": 5.82,
        "text": "instantly switched over to a tupple"
      },
      {
        "start": 1364.87,
        "duration": 6.42,
        "text": "based event model so Wow"
      },
      {
        "start": 1367.9,
        "duration": 6.12,
        "text": "alright so then I can know I no longer"
      },
      {
        "start": 1371.29,
        "duration": 8.03,
        "text": "have to add the rock apart in my smacks"
      },
      {
        "start": 1374.02,
        "duration": 5.3,
        "text": "that we're gonna be controversial here"
      },
      {
        "start": 1381.23,
        "duration": 5.84,
        "text": "[Laughter]"
      },
      {
        "start": 1383.88,
        "duration": 5.41,
        "text": "hey that's a good I don't know he's"
      },
      {
        "start": 1387.07,
        "duration": 4.32,
        "text": "shifting nervously wow you finally"
      },
      {
        "start": 1389.29,
        "duration": 4.32,
        "text": "pinned him down you finally stumped rust"
      },
      {
        "start": 1391.39,
        "duration": 6.0,
        "text": "he's not stumped no he's just not"
      },
      {
        "start": 1393.61,
        "duration": 6.42,
        "text": "wanting to say that people should or"
      },
      {
        "start": 1397.39,
        "duration": 4.88,
        "text": "shouldn't use a crab that's I'll leave"
      },
      {
        "start": 1400.03,
        "duration": 5.34,
        "text": "that for you you can talk about that"
      },
      {
        "start": 1402.27,
        "duration": 10.72,
        "text": "okay it just got awkward but I like out"
      },
      {
        "start": 1405.37,
        "duration": 9.96,
        "text": "Gordon Jeff speaking of awkward I do"
      },
      {
        "start": 1412.99,
        "duration": 5.01,
        "text": "want to comment just as a note here as"
      },
      {
        "start": 1415.33,
        "duration": 5.04,
        "text": "we closed on there has been a little bit"
      },
      {
        "start": 1418.0,
        "duration": 4.47,
        "text": "of what I don't know what I want to call"
      },
      {
        "start": 1420.37,
        "duration": 4.62,
        "text": "it maybe sticker shaming going on we've"
      },
      {
        "start": 1422.47,
        "duration": 5.04,
        "text": "gotten some listener feedback from what"
      },
      {
        "start": 1424.99,
        "duration": 5.16,
        "text": "some viewer feedback and noted that mmm"
      },
      {
        "start": 1427.51,
        "duration": 4.14,
        "text": "conspicuous lack of stickers yeah"
      },
      {
        "start": 1430.15,
        "duration": 4.32,
        "text": "certain laptops compared to other"
      },
      {
        "start": 1431.65,
        "duration": 5.1,
        "text": "laptops sorry and we just want to say"
      },
      {
        "start": 1434.47,
        "duration": 4.709,
        "text": "that we've noted this and we're taking"
      },
      {
        "start": 1436.75,
        "duration": 4.08,
        "text": "it into account you may notice if you're"
      },
      {
        "start": 1439.179,
        "duration": 3.421,
        "text": "watching on YouTube that I've added a"
      },
      {
        "start": 1440.83,
        "duration": 4.41,
        "text": "couple of things I've got a new spark"
      },
      {
        "start": 1442.6,
        "duration": 3.63,
        "text": "sticker and I'm rocking on here right"
      },
      {
        "start": 1445.24,
        "duration": 3.9,
        "text": "now"
      },
      {
        "start": 1446.23,
        "duration": 5.64,
        "text": "with more to come so look the the"
      },
      {
        "start": 1449.14,
        "duration": 4.169,
        "text": "sticker space on my laptop is currently"
      },
      {
        "start": 1451.87,
        "duration": 5.37,
        "text": "available there's some real estate left"
      },
      {
        "start": 1453.309,
        "duration": 5.671,
        "text": "and if your thing if your tech is worthy"
      },
      {
        "start": 1457.24,
        "duration": 3.42,
        "text": "let's get it on here yeah so this is"
      },
      {
        "start": 1458.98,
        "duration": 3.57,
        "text": "this should be a thing so if you have a"
      },
      {
        "start": 1460.66,
        "duration": 4.32,
        "text": "sticker that you feel like needs to be"
      },
      {
        "start": 1462.55,
        "duration": 4.86,
        "text": "on Jeff's laptop then let us know in the"
      },
      {
        "start": 1464.98,
        "duration": 4.169,
        "text": "show notes or in the in the comments you"
      },
      {
        "start": 1467.41,
        "duration": 4.53,
        "text": "can hit us on twitter at data"
      },
      {
        "start": 1469.149,
        "duration": 4.71,
        "text": "tax academy we wouldn't if you think"
      },
      {
        "start": 1471.94,
        "duration": 3.689,
        "text": "it's worthy to be on Jeff's laptop then"
      },
      {
        "start": 1473.859,
        "duration": 3.36,
        "text": "it's a neat you know trade like I we got"
      },
      {
        "start": 1475.629,
        "duration": 3.18,
        "text": "them we got a lot of stickers here that"
      },
      {
        "start": 1477.219,
        "duration": 3.81,
        "text": "we can share out the other direction so"
      },
      {
        "start": 1478.809,
        "duration": 4.47,
        "text": "now my life is going my laptop is fine"
      },
      {
        "start": 1481.029,
        "duration": 3.421,
        "text": "i'm i have my twenty six pieces of flair"
      },
      {
        "start": 1483.279,
        "duration": 6.45,
        "text": "I'm good"
      },
      {
        "start": 1484.45,
        "duration": 9.209,
        "text": "but yes yeah somebody's let's let's wrap"
      },
      {
        "start": 1489.729,
        "duration": 7.11,
        "text": "this up with I mean let's just face the"
      },
      {
        "start": 1493.659,
        "duration": 5.25,
        "text": "past of spark just you're catching us up"
      },
      {
        "start": 1496.839,
        "duration": 6.21,
        "text": "on what's going on looks really bright"
      },
      {
        "start": 1498.909,
        "duration": 6.0,
        "text": "I'm gonna have to revisit what the"
      },
      {
        "start": 1503.049,
        "duration": 4.38,
        "text": "future look like now that you've we've"
      },
      {
        "start": 1504.909,
        "duration": 7.68,
        "text": "got all these goodies what's finish this"
      },
      {
        "start": 1507.429,
        "duration": 7.021,
        "text": "up with the the grand vision yeah well I"
      },
      {
        "start": 1512.589,
        "duration": 3.93,
        "text": "mean so the grand vision is spark right"
      },
      {
        "start": 1514.45,
        "duration": 3.389,
        "text": "is that you will have these machine"
      },
      {
        "start": 1516.519,
        "duration": 3.181,
        "text": "learning libraries we love graft"
      },
      {
        "start": 1517.839,
        "duration": 4.08,
        "text": "libraries you'll have all kinds of"
      },
      {
        "start": 1519.7,
        "duration": 4.62,
        "text": "different technology that just fits on"
      },
      {
        "start": 1521.919,
        "duration": 4.411,
        "text": "top of this catalyst optimization engine"
      },
      {
        "start": 1524.32,
        "duration": 3.719,
        "text": "and you already see a bunch of it coming"
      },
      {
        "start": 1526.33,
        "duration": 4.169,
        "text": "out you know there's that ml live work"
      },
      {
        "start": 1528.039,
        "duration": 3.75,
        "text": "there's graph frames right but these"
      },
      {
        "start": 1530.499,
        "duration": 3.51,
        "text": "kind of things are all going to take"
      },
      {
        "start": 1531.789,
        "duration": 4.47,
        "text": "advantage of the same optimizer the same"
      },
      {
        "start": 1534.009,
        "duration": 3.96,
        "text": "thing so people will be writing all"
      },
      {
        "start": 1536.259,
        "duration": 4.74,
        "text": "kinds of different libraries all"
      },
      {
        "start": 1537.969,
        "duration": 4.71,
        "text": "building up this giant ecosystem that"
      },
      {
        "start": 1540.999,
        "duration": 4.62,
        "text": "you can access without having to learn"
      },
      {
        "start": 1542.679,
        "duration": 5.16,
        "text": "anything new so it's it's all about this"
      },
      {
        "start": 1545.619,
        "duration": 3.93,
        "text": "huge interoperability I mean we didn't"
      },
      {
        "start": 1547.839,
        "duration": 4.71,
        "text": "even talk about how the fact that with"
      },
      {
        "start": 1549.549,
        "duration": 5.1,
        "text": "inspark SQL within this catalyst you can"
      },
      {
        "start": 1552.549,
        "duration": 5.82,
        "text": "take sources from all kinds of different"
      },
      {
        "start": 1554.649,
        "duration": 6.12,
        "text": "places like our DBMS is no SQL file"
      },
      {
        "start": 1558.369,
        "duration": 4.5,
        "text": "formats s3 you can combine them all"
      },
      {
        "start": 1560.769,
        "duration": 3.48,
        "text": "without having to actually write a new"
      },
      {
        "start": 1562.869,
        "duration": 4.35,
        "text": "connector for any of them"
      },
      {
        "start": 1564.249,
        "duration": 5.36,
        "text": "and that's really what's because if"
      },
      {
        "start": 1567.219,
        "duration": 5.04,
        "text": "you're gonna have to get you back Jeff"
      },
      {
        "start": 1569.609,
        "duration": 4.12,
        "text": "take a note this may be a thing yeah I"
      },
      {
        "start": 1572.259,
        "duration": 5.25,
        "text": "think we're just gonna have to have"
      },
      {
        "start": 1573.729,
        "duration": 8.851,
        "text": "because we get behind and then we lose"
      },
      {
        "start": 1577.509,
        "duration": 7.62,
        "text": "things so Russ will you come back yes"
      },
      {
        "start": 1582.58,
        "duration": 5.039,
        "text": "welcome back okay so we got that we got"
      },
      {
        "start": 1585.129,
        "duration": 4.77,
        "text": "that marked in stone he will come back"
      },
      {
        "start": 1587.619,
        "duration": 3.54,
        "text": "so I think the things we would love to"
      },
      {
        "start": 1589.899,
        "duration": 5.34,
        "text": "talk about in the future are things like"
      },
      {
        "start": 1591.159,
        "duration": 6.36,
        "text": "spark streaming graph frames really some"
      },
      {
        "start": 1595.239,
        "duration": 4.53,
        "text": "really low-level things if you can"
      },
      {
        "start": 1597.519,
        "duration": 4.35,
        "text": "demonstrate like here's the code that"
      },
      {
        "start": 1599.769,
        "duration": 2.941,
        "text": "I'm writing and look at what it's doing"
      },
      {
        "start": 1601.869,
        "duration": 2.16,
        "text": "now"
      },
      {
        "start": 1602.71,
        "duration": 4.14,
        "text": "would be great if we could show our"
      },
      {
        "start": 1604.029,
        "duration": 4.38,
        "text": "viewers some of that she also the code"
      },
      {
        "start": 1606.85,
        "duration": 4.74,
        "text": "gem that actually is happening under the"
      },
      {
        "start": 1608.409,
        "duration": 7.88,
        "text": "hood I like that so nerdy things good"
      },
      {
        "start": 1611.59,
        "duration": 6.809,
        "text": "stuff thanks Russ well thank you our"
      },
      {
        "start": 1616.289,
        "duration": 3.821,
        "text": "listening audience for joining us for"
      },
      {
        "start": 1618.399,
        "duration": 4.77,
        "text": "another episode and we'll see you next"
      },
      {
        "start": 1620.11,
        "duration": 5.13,
        "text": "week thank you for joining us again for"
      },
      {
        "start": 1623.169,
        "duration": 3.781,
        "text": "the distributed data show we love your"
      },
      {
        "start": 1625.24,
        "duration": 3.72,
        "text": "feedback so go to the distributed data"
      },
      {
        "start": 1626.95,
        "duration": 3.81,
        "text": "show page on data Stax Academy and tell"
      },
      {
        "start": 1628.96,
        "duration": 3.689,
        "text": "us what you think you can also find us"
      },
      {
        "start": 1630.76,
        "duration": 4.38,
        "text": "on the data Stax Academy YouTube channel"
      },
      {
        "start": 1632.649,
        "duration": 4.831,
        "text": "or find our podcast on itunes google"
      },
      {
        "start": 1635.14,
        "duration": 4.32,
        "text": "play or wherever you get great podcast"
      },
      {
        "start": 1637.48,
        "duration": 3.689,
        "text": "while you're there make sure and"
      },
      {
        "start": 1639.46,
        "duration": 3.58,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 1641.169,
        "duration": 4.981,
        "text": "episode"
      },
      {
        "start": 1643.04,
        "duration": 3.11,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:22:43.172580+00:00"
}