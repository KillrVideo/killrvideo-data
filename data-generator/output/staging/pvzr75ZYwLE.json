{
  "video_id": "pvzr75ZYwLE",
  "title": "Introducing K8ssandra - Apache Cassandra‚Ñ¢ & Kubernetes",
  "description": "üö® Register for DataStax AstraDB: https://dtsx.io/3ckpsMX‚Äã - No credit card required, $25.00 USD credit every month, roughly 30M reads, 5M writes, 40GB storage monthly - sufficient to run small production workloads.\n\nJoin the DataStax Developers as we introduce you to how Cassandra‚Äôs architecture and logical fault domains are complimented by Kubernetes - you‚Äôll take a typical containerized application and deploy it with a fully automated data service backed by Apache Cassandra‚Ñ¢. Come and see how you can move fast with confidence and very few trade-offs. Don‚Äôt miss it!\n\nüì• All Workshop resources \nhttps://github.com/datastaxdevs/k8ssandra-workshop\n\nLearn more about Cassandra at Apache (https://cassandra.apache.org/doc/latest/)  and DataStax (https://docs.datastax.com/en/landing_page/doc/landing_page/cassandra.html) documentation websites.\n\nAbout DataStax: DataStax is the company behind the massively scalable, highly available, cloud-native NoSQL data platform built on Apache Cassandra‚Ñ¢. DataStax gives developers and enterprises the freedom to run data in any cloud, Kubernetes, hybrid or bare metal at global scale with zero downtime and zero lock-in. More than 450 of the world‚Äôs leading enterprises including Capital One, Cisco, Comcast, Delta Airlines, Macy‚Äôs, McDonald‚Äôs, Safeway, Sony, and Walmart use DataStax to build transformational data architectures for real-world outcomes. For more, visit DataStax.com and @DataStax.\n\nüîî Sign up to our event alert:\nhttps://bit.ly/subscribe-datastaxdevs\n\nüí¨ CHAT = DISCORD, ask questions live: \nhttps://bit.ly/cassandra-workshop\n\n‚ùìFORUM = QUESTIONS during the week community.datastax.com : \nhttps://community.datastax.com\n\nüéìCertifications Infos\nhttps://www.datastax.com/dev/certifications\n\nüöÄ üöÄ ENJOY !! üöÄ üöÄ\n\nThis workshop was recorded live. Some live elements have been cut out for your enjoyment. Be sure to make use of the timestamps below. Enjoy!\n\n0:00 Introduction\n8:00 Apache Cassandra Basics\n22:03 Kubernetes Basics\n31:55 Introducing K8ss",
  "published_at": "2020-11-18T19:26:19Z",
  "thumbnail": "https://i.ytimg.com/vi/pvzr75ZYwLE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "scalable",
    "workshop",
    "cassandra",
    "apache_cassandra",
    "nosql",
    "introduction",
    "astra",
    "architecture",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=pvzr75ZYwLE",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "hello everyone and welcome hi Eric hello how you doing today Alex yeah that's a great day you know that's a day of a big release for us so I feel a bit tired but very happy and you I I'm in the same boat very very tired it's long road getting here but we are we are we're here it's great yeah wonderful so uh if you can hear us if you can see us please set the thumbs up in the YouTube chat and let's celebrate together because that's a special day for all the Apache candra community and data stocks of course as well yes all right and it looks like we got Cedric's giving us a thumbs up okay so that's that's already great helping us that doesn't [Laughter] count no but I mean Cedric today is also not only an answer but list ER thank you sh thank you thank you babo and all the other people today with us and that means what we can start yes okay so but uh Eric what makes these days so special for us there is a new open source project in town and it's something you and I have had our hands on for a little while now but we are actually uh bringing it public I think the GitHub repos all went public the Jer went public all this morning so we are going to be talking a little bit about that what it is what it looks like why it's cool and how you can get involved um again it's open source so not a data Stacks only product it's not like dsse data Stacks Enterprise or anything like that this is an an open source project with uh other open source tools um that are around the cassander community built in and we'll get into what that looks like as we progress here throughout the day yeah and manil is perfectly right because today is the official public release of kandra we discussed it a lot before what's the Cassandra is and we talked about kubernetes as well and today is the public release for K Sandra Cassandra we've all required ecosystem for operations built in together into the something you can easily run on kubernetes with just a couple with just a couple of commands and that's really easy to use and you we'll see that today yes and you know the the cool thing is so this is the second time we're actually doing this Workshop sh don't tell anyone but if you were here for your yesterday's uh cubec con Workshop you got a sneak peek and you got to see a little bit this is a lot of the content today is going to be the same but um feel free to stick around and and ask questions and add color where you can so yeah absolutely so what I think we can start already that's a very good time to start and let's take a look about the thing about the things we are going to do today uh so we have to ask you some questions and prepare for a workshop we will cover Cassandra and kubernetes Basics but Basics you see we are speaking about running Cassandra and kubernetes so if you have no idea of both Cassandra and kubernetes work this Workshop isn't going to be easy for you but we will not do take a Too Deep dive don't worry then we will discuss about how do you set up and monitor kandra work with data scale the cluster up and down because well candra is the easiest database for scaling in both directions we will do some anti-entropy fighting with repairs uh and we will switch to resources that may help you and um we will use four different tools uh to cover during these workshops uh for the streams we are doing the main stream now in YouTube and we have a backup stream in twitch for the questions you can use YouTube uh chat but the main place for us is our Discord server which is going to be much better and uh to do the steps that's a workshop so you are going to do your part of for work uh you can use your machine as long as it supports uh Docker and has some Firepower uh but if it doesn't work to you you can uh use our Linux box uh in the cloud delivered by AWS thanks and materials are all completely available on GitHub I kindly ask I'll we have Link in the description of the video now about the Practical steps you have uh two pills to decide which one to take your laptop or Cloud environment so if you do it on your own you will need Docker and kubernetes uh as a kind or mini Cube for example mini Cube should work also as well as far as I know and if you cannot have Docker or your laptop is not so uh strong enough to run the W system you may use our CL Cloud uh infrastructure so uh if you want to grab one our Cloud instance please contact contact jack. fryer dat.com and I see Jack in the chat already so you can write him an email and he will immediately send you back the yeah thank you Jack if you need a cloud instance please send us the things uh send the things to Jack uh and this one is completely prepared so it has kubernetes installed with kind and that's a sento machine yeah I would just throw out there that our our infrastructure is going to be much much easier it's a much much cleaner experience for you to hear today because we're not really going to allow time for you to set up all the docker the kind cluster and all that that that stuff it's not built into the labs here so highly recommend you go with our infrastructure if that's not an option for you you know we we do have the in the GitHub today we'll have instructions to how to set it up yourself but um we do try to provide everything so you can get the labs done yeah absolutely thank you Eric you are very right for a smoother experience we recommend to use cloud cloud in from all right and I have a question in the chat do you recommend any specific course for the certification or one listed on Cassandra Academy is sufficient I recommend learning puff at the Cassandra Academy data academy. dat stacks.com we have learning puff for admins and learning puff for developers yeah and it's a full curated thing so all you got to do is Click there and it will actually line up the correct courses for you um I think all of them take intro to Cassandra and then it kind of um bra branches off a little bit from there but they they both go very very in depth on the content um and you should be able to pass you if you do the exercises you do the learning path and you really absorb this stuff you should be able to pass the exams without too much trouble at all so good now uh request your Cloud instance if you going to do a practical steps with us uh but not following this link uh but contacting jack. fryer dat.com his email I've just pasted into the chat and that would be enough for us to start and we are going to cover Cassandra and kubernetes Basics that's what we need to discuss so apach candra very quickly in apach Cassandra in five minutes apach Cassandra you do that oh yeah that's going to be something special ladies and gentlemen start your engines so uh apach candra is a nosql decentralized distributed database uh and that's not every word in this phrase is very important because it is no squ distributed decentralized so we use it to store data as you do with post gr SQL or MySQL or in other databases but it works in a very different manner it's different to other databases so first of all it's decentralized there are no things like primary uh or secondary notes or like we us it to speak to say master or slave notes that's nothing things like that every note has the same same duties then it's uh distributed so we are going to work with multiple nodes at once we are not putting all our X into the single basket but we are spreading data and spreading responsibilities over multiple nodes and uh that what allows us to handle any kind of um problems and we want and we can grow over the size of a normal database significantly who knows what's the biggest Cassandra deployment in the world um I will not stop for too long of that but we know what biggest Cassandra users not only users but also committers on Netflix and Instagram and out oh no Oliver 10,000 much higher uh the biggest known personally discussed uh by me deployment uh was um done by Apple it was5 6 160,000 notes once again I like how it sounds 160,000 notes apple and now we have heard what uh some Chinese companies like Huawei have even more yeah Netflix Apple Instagram and some others Spotify is another big one all of their infrastructure their their data layer is scand from what I know yep exactly and that's non-relational database so no SQL database nodes are organized in the data centers or rings but uh every node communicate with every node so there is no things like primary node giving orders to secondary noes it doesn't work like that what are the main features of Cassandra we want to cover Cassandra is distributed so we have a lot of nodes working together in a cluster it makes it responsive and scalable we can always add more notes to have higher FR output or volume or whatever we want to have and it's replicated it means what your record your data is replicated to multiple notes and even if one of those not uh notes uh is not available your data will be returned by other noes so you can do right and read operations even if the some notes are in on fire and as say there is no single point of failure because we have a true democracy here there are no primaries and secondaries there are every note is the uh full uh full size citizen of the world cluster and they have the same duties they are absolutely equal Cassandra is distributed and highly available notes organiz it into the groups data centers notes monitor each other's health status using a gossip protocol Cassandra wrotes requests away from notes what are down or slow automatically and that's not for your operations guys uh or girls to take care of that's not the question that's what Cassandra takes care of Cassandra scales very good and we speak not about vertical scaling traditional for the databases when you when you are out of power you want to have something more you buy a new bigger service migrate your data and uh remove the old one that's vertical scaling buying more and more powerful Hardware we prefer another way uh we prefer to go with horizontal scaling and that's a very different way problem of a vertical scaling first it gets expensive very soon but also second as soon as you um you still have the same issue that's one single instance which has one single power of uh source of electricity for example with all the problems related to that and um problem for us uh here uh with horizontal scaling we can do it in a different way uh we prefer to add more nodes and one of the best features of Cassandra uh it scales not only uh horizontally but also linearly it means what we have have very low to zero overhead on adding new nodes and every time you add next next note your claster is getting more and more powerful on from the volume point of view or from the FR output point of view you are slow check your data model and add more nodes you need more capacity add more nodes and that's how it works this picture on the right side we don't want to show what cassandre is faster than our database Bas well it is but that's not your point for now yeah you know what uh on the uh different testing uh infrastructures and with access to the settings and configuration I can set up every database to be quick or slow um what I want to set here I want to highlight what every next note add that uh it scales linearly so we have no overhead and we have more and more power growing over time uh if you know maybe Netflix kind of tiny company streaming some not so popular TV series maybe uh they did a great research it's published it in their Tech blog uh they scaled Cassandra cluster from 30 notes I believe to 300 something like 350 maybe uh and what way the testing how fra put and volume grows and it grows linearly uh so that's not only my words that's Netflix words um what are the main principles for Cassandra first of all everything is distributed data is distributed over clusters those orange circles on the left side are servers and the table on the right side is the table now when we have those seven notes and this table on the right how do you think data will be spread at over so which Note stores which part of data we can say it's going to be stored like that um so every every note is responsible for the part of a table at this point you may ask why I'm working with my POS gra or whatever relational database you are using and it doesn't think like that will it be convenient to use answer is very simple take a look Sandra is Big Data R your relational database may work great till some limit and after this limit it doesn't work great and after some more it doesn't work at all why because it was uh not designed uh to be uh Big Data ready from the as a design concept as a result it works good as long as it's in the conditions it was designed for so some limited amounts of data Maybe gigabytes of data maybe some terabytes but not more and when we start to speak about dozens terabytes or dozens petabytes like Apple Works then you need something like Cassandra Cassandra separates data um to a multiple partitions it's called it partitioning based on the partition key you design uh and then if we need more volume we simply add more nodes and the part ition will be moved over the cluster again very simple then uh what is a partition key partition key is the column in your table you are using uh to identify the partitions like take a look here we have Toronto Paris Berlin Mumbai Berlin Moscow and so on how way will be stored based on your partition key in this case we use the uh partition key we use CT as the partition key so data is grouped together and uh that's how it works that's not only data is distributed but data is replicated compare those two slides this one and that one in short answer every replica every partition is duplicated for a very simple High availability reason when you have you can configure your Cassandra to work like that with replication Factor one it's good for your laptop it's good for your maybe uh test environment but it's bad for your staging and that's bad for your production when you raise the replication factor to two it looks like that but what we recommend to have is replication Factor free uh replication Factor free is important so you can afford losing a note while still being consistent people call Cassandra eventually consistent but that's not perfectly correct because Cassandra is configura consistent and you can move this uh switch to any site you prefer to have right now so every data is replicated to be on multiple times available and finally uh replicated distributed what's next uh distributed globally it means what with Cassandra you can easily have data centers all over the world working as a single cluster so your data is on the United States East and then uh Europe Central one and then Asia central 2 and they are all working together handling the same data why because you want your data to be close to your clients if you have clients everywhere you want your data to be also everywhere it's easy to run application into any part of a world as long as you have data center there but uh with data it's usually not so easy with Cassandra it's easy and finally Cassandra is absolutely platform agnostic so you can run exactly the same cluster different parts of a cluster different data centers or rings in the Google Compu platform Microsoft Azure AWS on your own data center on premises on absolutely the same uh time and it will be still the same cluster Cassandra's platform agnostic you can run it everywhere and they still will be fully operational working together and last point of that so the use cases scalability everything what relates to high for output high volume a lot of writes a lot of reads that's very sounds like aandra use case especially then its changes today you have uh one number of requests and tomorrow going to be Black Friday and you are going to have two times more no need to buy more powerful server just add one more note wait till Black Friday is over decommission this note and you are great you are highly available all the time and your expenses are very well optimized okay then availability everything what relates to Mission critical systems never data loss always available that's absolutely about aacha Cassandra when this distributed whatever we mean about the global presence that's a perfect use case for the Cassandra whatever we speak about the compliance or gdbr if you want to have some of your data available only in Europe and some other parts of your data in both Europe and the United States you can easily do that uh specifying different replication factors for different data centers like I'm located in Germany and there are some gdpr rules and you can for example store course in some cases data of German clients only in Germany no problems you specify replication Factor allow it for the data center in Germany and remove that for this kind of data for all the other data centers boom you have your data only in Germany and then all what goes to Cloud native modern applications um microservices very good feed Cloud native and Cloud deployed very good feed kubernetes perfect Feit that's what this Workshop about all right Alex you said you'd get it done in five minutes you want to know what your time was yes so what that let's see if we can see it on screen here 13 minutes and 41 seconds oh my God you know what uh I would better speak about that for days so it's always very hard to feed into the smaller size I will try TR to improve thank you Eric good so uh kubernetes we have some people with pretty low experience on this field uh but we will not do a deep dive in general the main idea what you have to understand kubernetes is an open- Source system for management ofer containerized applications and that's what it does it helps you to deploy upgrade remove scale uh containerized applications so what does that mean before we that's a kind of famous picture I see literally on every um conference uh regularly uh virtual machines old approach to virtualization well not old but different I would say older approach uh which helps you to have higher isolation using guest operating systems running on the hypervisor or host operating system it works very well it provides a very high level of isolation but also brings a problem a lot of your resources consumed by Gest operation operating system that's sometimes may be good if that's your intention but you know what's the funniest point about the operating systems really no one needs operating system you have operating system on your laptop you don't need that you need you want to watch uh uh kitten photos on the internet and funny videos and learn things at the data Stacks developer workshops uh so basically you use browser most of the time and maybe your integrated development environment but uh what's the operating system then it's just the glue what brings this software together with your Hardware allowing them to work together but per se operating system is not the thing you need you need to do something uh different and containers is a new approach to virtualization which allow you to do this thing easier in the containers uh processes or applications you are running are being executed directly on the host operating system without guests operating systems so what makes things um little bit less isolated maybe in some cases but much more like lightweight so containers usually much more lightweight than virtual machine images and um that makes them much more convenient to use but the containers uh just as they are like Docker containers for example they are great but you still have to work with every particular image and every particular container and you have to say Docker run Docker stop uh and many other operations and then you are trying to do um some signif some more or less complex application even for simple applications I believe some of you were at my four weeks Docker learning puff I hope if you did please write about that in chat so I know there are some people uh from my Docker learning path uh you remember the week two when we tried to run pretty simple application without any orchestration without Docker compost without do swarm without kubernetes it was pretty a lot of things to do just with doer so we consider kubernetes as an advanced doer compost I hope no one will kill me for this comparison because G to say I can see the pitchforks coming out already yeah yeah yeah so you see uh the general idea is the same to orchestrate but of course kubernetes works on much bigger scale when you need something on your own laptop you go for Docker compost because it's easier than kubernetes but when you are going to run over a big data center or maybe many of them and complex applications and hundreds of services you definitely need kubernetes so what kubernetes does it helps you to orchestrate for storage it helps you to manage uh configuration and secrets it helps you with automated roll outs and roll backs if needed it helps with service Discovery and loow balancing horizontal scaling running multiple pods for example it cares of a selfhealing if some pots are broken and many other things uh what's the infrastructure very simple when we speak about the base kubernetes infrastructure you have to think about the following things Master nodes and worker nodes so kubernetes cluster consists of a control plane running on the master nodee and free worker oh not free well as much as you want to have worker machines uh they are usually much more powerful because worker machines have un noes where you're going to run your applications and kubernetes control plane um organizes communication of these machines takes cares of networking sink pods and so on and so forth uh so there is pretty a lot information I don't want to do a deep dive but what we have to do uh what we have to know control plane consists of a API server so what something what answers your queries I want to scale up I want to scale down that's what you ask a kubernetes API to do with API server controller manager helps you uh with everything what relates to operations on the kubernetes Sher Cates of the ports placement I'm to explain port in a moment and htcd is the we can say it's a database for kubernetes well not only for kubernetes but us it by kubernetes in this case so and on the worker note we have something already more interesting so uh Cube proxy kubernetes networking is a long story uh there is a set of software defined networks working together and Cube proxy is the uh service responsible for the networking things and now Port Port is a very important idea when we work with uh pure Docker what's the minimal unit of access for us it's a container and in kubernetes is a little bit different because every poort uh so basically Port is just a container for a container very simply you can ask like why do we need the port we have containers already why don't we use just containers answer is first of all kubernetes doesn't work only with containers it can be a special kind of virtual machines it can be rkt containers not Docker containers and so on and so forth so for the unification uh we use pot and pot uh contains something which is usually Docker container usually but not necessary then to make it kind of agnostic too it it creates you know it doesn't care what what you have in that pod the Pod is going to be able to communicate with the other pods and all of that is kind of abstracted away where you just don't have to deal with it anymore exactly and one more thing uh one container is one single container with Port it's a little bit different because in Port you may have multiple containers of a different kind at once um what does that give us in some situations your containers uh work so close together so they need to share something uh for example inter interprocess communication is not directly uh possible between different pots but possible for containers within single pot and some other options if you want to think if you want to have one container per poort if you want to have port a and Port b or you want to have your container A and B in a single pot think on how do you want to scale them if your containers always scale to to scale together then they make a good pot for example when we run Cassandra in kubernetes uh we have two containers per Cassandra pot one is the Cassandra as it is and second is a Cassandra side car a special application to help with management and metrics of a Cassandra for monitoring and we always scale them together so we make a good pot together but for most of the cases you will see one pot means one container when echosystem for the cuber netes may be really overwhelming because uh kubernetes was originally designed by uh Google to solve Google size problems and that all it comes through but uh don't worry you don't have to know all of that I guess we're are no one to learn all of that and again we speak mostly about the developer things today so for us it's going to be much easier and very simple very simple and here comes Kate Sandra yay so yeah Eric yeah so Kate Sandra is basically taking all the complexity of the distributed systems in in working it all together weaving both kubernetes and Cassandra together into something that is actually very very simple to use and install so um in in the past everyone knows that Cassandra is a distributed system distributed systems are hard kubernetes is a distrib system distributed systems are hard and you try to put two of them together and it's just a ton of work that's been kind of a historical thorn in the side of both kubernetes and Cassandra is integrating these two things so what we did with the Kate Sandra project again not not just data Stacks this is an open source project we went and we basically used um some tools that we'll get into to integrate the two tie them closely together so that instead of having to spend you know weeks hours sometimes months getting all of these components working adequately for production now suddenly we can do it very very quickly and we'll actually do that within the session here today it's I think about the last hour of the session we're going to go through not just set it up but we're going to do a number of operations with it as well yep exactly okay uh sorry and yes oh that's correct that's correct that's correct first quiz of the day first quiz of the day so warm up your hands prepare for the quiz yeah I'm switching to M him and that's the quiz time so set the thumbs up I'll know you are here and that's going to be Cassandra fundamentals I know we have some people with experience today that's something very interesting for us to see but please give some chance chances to novices as well so once again man.com use the code 62450 540 I'm sorry and I know we have code in the chat okay so I think we are good to go jump in right now overwise you will not have time to answer the first question and as a result you will have worse results I see we have almost 100 of people in this uh in this uh live stream so I really want to have more people than we are having right now make me 45 okay and the top three people on this quiz get a prize so there's this one and then you'll have one more opportunity yeah and people ask all the time do you send prizes to my place it's like a remote one we don't care we deliver worldwide as Cassandra does good so 43 people two more and we start good 44 one last 45 here we go let's do it so answer fast to get more points what is a partition key a consecutive number applied to each new record a designated field in your table to partition your data an optional table field for optional partitioning another word for a garage key and we are done time is up and most of you have answered it correctly it's a designated field in your table to partition your data there is no things like consecutive numbers because when you have a distributed system you will have to agree on the consecutive number over multiple noes in a hostile Network environment that's not going to work uh in a fast way and that's not an optional field that's a required field yes so who was the fastest today Carl G Stu gets the first place with 944 points and very close to him Ashley and the Hustler so but that was only the first question so let's take a look what's going on to happen next and that's for question two so answer fast to get more points what is a partition the smallest unit of data distribution a group of rowes a replica note in a Cassandra cluster a je loated grouping of notes a dividing wall what would you pick Eric I'm going to go with option four a dividing wall yeah I mean everyone knows it's a dividing wall That's clear but you know what it looks like they don't agree answer is the smallest unit of data distribution and group of rows and that's the correct answer and no partition is not a replica node and and I want to see the changes so it looks like we have some oh and Carl Gustaf was fastest again that's a good score today yeah and we have Su hakar on the second place and Ana Gupta is on the third one and ravikiran is so close with Five Points difference to a third place that's a very good result yeah so that's a question three and we are getting close to the middle of the first quiz and answer fast to get more points what is the recommended replication Factor free per note fre per cluster fre per data center zero we don't like replication so this one is a little bit trickier for Cassandra novices but well that's pretty fair yeah it was mentioned very briefly there yeah oh that's painful this is going to switch up the scoreboard yeah that will change the scoreboard so correct answer is free per data center because if you have free replica nodes uh per cluster that isn't going to work in the uh quick and fast Manner and reliable manner for you and definitely not free per note so recommended replication factor is free per data center in some cases maybe five and okay hi skus I see some familiar names already and sakar was the fastest one but it was not enough to get to the first place and we have sures sudakar and anania Gupta on the first three places and Charles are very close to the first three but not yet in so let me see and that's a question four and I want to see your answers because we are getting close to a end what happens when a note goes down you lose data cordinator stores a hint over replica serf request there is downtime for the notes to rebalance uh Eric's option note never goes down yeah yeah I mean that's that's you know if you build the system perfectly they will never fail right yeah that would be great but the correct answer is coordinator stores a hint and other replicas serve the request and that's the correct there is no downtime for the notes to rebalance no there is no downtime please I believe I mean you know see that the people with relational databases experience they believe in downtime in Cassandra team we don't believe in downtime if you do everything correct you can go for the full up time and yeah so there is no downtime if a note goes down and you lose a data is also wrong because there are still replica notes keeping your data so what are the changes in the leaderboard after all I see very well so sures was fastest again and sudakar and Ana still holding the top three places very well all right question five and we are getting close to the end how many Master nodes should be in each cluster one master node per fre replica nodes one master node per data uh two Master noes per data center sorry one cluster Master we have at least two data center submasters zero we don't use master notes and the time is up and the correct answer was Zero we do not use Master nodes and when I say we do not use Master nodes that means exactly what it means no master noes in a cluster and therefore any other qu answers are wrong yeah we were got getting a little tricky with that one too so it looks like we made them think take a look yeah and Sak car was the fastest one this time getting to the first place but the top three list still looks the same but there are some people like Charles KV and agent is9 all who also going to fight for the top score today definitely could could switch it up here more question right so last question so don't make a mistake right now now answer fast to get more points is active active replication possible for multiple data centers yes within the same Jo location yes if a replication is coordinated by a cluster primary node yes Cassandra is natively active active you cannot have multiple data centers now if you're paying attention to the last question that should eliminate one of the answers here yeah so it was easy this time candre is natively active active worldwide globally so there is no thing like a replication coordination by a cluster primary node because there are no primary nodes and that's not the not about the same geolocation that's completely possible all across the world so we can now take a final look at the leaderboard and are there any changes so none of the winners made a mistake but will will be the changes because of the points yes on the very last question Charles jumps in into the top three so sakar with 5,580 points gets the first place very well deserved sures get to the second one with a very small Gap to the first place and Charles jumps in with a very very last moment there a great job and an Gupta I'm very sorry but Charles was faster so for the top three of you make sure you take a screenshot of your win and send that to Jack frier at dat stacks.com he's posted in the chats there the address just send it there and he will get you sorted out with your prizes yep uh so make a screenshot don't forget and send it to uh Jack frier uh he is exactly in the YouTube chat right now and if you didn't make it to be in top three this time don't worry too much because you know what what's the what's the Priceless um price of this Workshop it's not the gifts from data stocks although they are great but your knowledge your skills and your higher salary as you are doing your job better and better that what really values I think we all like High salaries right yeah I mean is our boss listening yeah yeah yeah yeah I hope so I've seen Patrick in the chat good okay so well then we have now advancing to Kate Sandra and I bet I'm switching now to Eric that's going to be Wonder well I get to do kind of the coolest part of this presentation it's also the most dangerous I mean that's a correct time to say sorry Alex I'm going to do the coolest part of this presentation yes yes okay okay all right so we've talked about candra wait a second let me switch to you please boom absolutely so okay here we go all right so in the last hour here we talked about Cassandra and kubernetes and we' talked about kind of how they operate what they are what they do now we're going to talk about putting them together and fortunately for you all we're not going to have to put them together ourselves that's already been done for us we're just going to get to consume and use that so pre-work for today um hope you all got the message we got to do some network setup network storage firewall setup we got to install a bunch of nodes which is going to be you know downloading some tars getting those configured as Services um install our Prometheus grafana user agents some you know there's just a lot here we got to okay I'm just kidding we don't have to do any of that that's all done for us liar yes I know I know I couldn't help myself we actually get to do um some very simple stuff so all you need for today is either the cloud instance or you could have set it up on your own following our documentation you need to be willing to learn and having a pulse is also a very good thing of course you know for our our Undead friends we're accepting of them as well all right so Kate Sandra what is it simply put it's Helm plus all the things you would normally need to run and manage your Cassandra cluster all bundled up into one Helm is basically a package management tool for Cassandra sorry not for Cassandra goodness o that's a big oof it's for a package management and templating tool for kubernetes and it allows us to do a lot of really Dynamic things that wouldn't be possible otherwise with our um kubernetes deployments we'll get into that we'll actually start messing with stuff like resizing things on the fly without editing yaml so really really cool stuff all right setting up Kate Sandra is actually very easy now today we're going to be using release candidate this is um as as we mentioned this morning um the project went live this morning so this is the first uh release or candidate that we have for Kate Sandra it's still very very much a a beta product or a beta uh tool I'm not even going to call it a product cuz it's not a product it's open source it's a beta tool but the intention with this project is to take it to something that will be used in production across the globe basically anywhere you have Cassandra and kubernetes together you can just use Kate Sandra and it will work so couple things here today um with Helm uh if you've ever used apt or yum as you know package managers on Linux Helm works very similarly we actually add our repositories just like we would on any of those other tools but then we also get some additional templating capabilities which are really really awesome so you see there we have a on the slide the helm repo ad and then we add our repo and then we update our repo which basically just says okay we added something now make it Go Active and then we actually do just a Helm install just like you do an apt install or yum install um and then we just install Kate Sandra so really really really cool does a lot of just awesome stuff that we would have had to take hours to do before in a single basically a single line now I will point out there for today um if you're watching this you know sometime in the future on YouTube uh all of those set Flags the set Ingress um You probably aren't going to need to run those because that's all going to be worked into the actual Helm install itself but what that basically is doing here for us today is it's setting up an Ingress an Ingress is a way to communicate um from the outside into a kubernetes cluster so we can actually get at the uis that we're going to be dealing with and you know the various pieces of this that we're going to be playing with today so normally you won't need that but just since it is a release candidate early release um we are going to have to do that ourselves instead of it being handled for us all right with that let's get into it so that is all that's required to set up our Cassandra we're gonna also get Cassandra Reaper and Cassandra Medusa now Cassandra Reaper is basically a tool to handle anti-entropy repairs in Cassandra anti-entropy repairs we'll get into a little bit more but for now just understand in a distributed system the laws of physics still apply we still have to deal with entropy you know things being corrupted things getting out of sync things generally tend towards chaos and so repairs help to bring things back into sync we also have Cassandra Medusa which is not 100% implemented today um it is like 9990 well 95% of the way there um we're not not going to get Hands-On with it but it's there and you can play with it and it is also I believe in the docs um currently on the C Kat sandra. uh page if you wanted to read about it maybe try it out yourself it is a Backup Tool it is for backup and restore and it basically handles all of the needs you'd have around you know taking Cassandra is incredibly durable but you can still accidentally truncate a table or or do some you know massive operation that you weren't intending to do it happened um that's what backups are there for okay other side we got grafana and Prometheus grafana is a data visualization tool it doesn't actually collect metrics itself or do anything like that it just consumes them and displays them in a nice dashboard Prometheus is what goes in and actually collects those metrics so we are going to to use Prometheus to collect the metrics from our Cassandra nodes and then grafana is going to consume those metrics and display them in a nice easy to consume dashboard all right and of course Cassandra is the middle of this whole thing without it we would have nothing to show all right features list um this is kind of a wall of text but it covers a lot of what Kate Sandra does currently there's a couple really cool things that I'd like to to point out here um rolling reboots are a thing that are kind of hard to do in kubernetes by default that's one of the things that you'd have to configure by yourself if you were trying to bring Cassandra into kubernetes you'd have to actually manage that and set that up sorry sorry Eric I just have to say you see we have some uh novices as well not so familiar with kubernetes so my work as a developer Advocate to protect them to and just word about the rolling reboot uh normally if you do just uh reboot then it means what you're are going to reboot all your notes and then what you have downtime because all replica notes are going to be restarted at once and that's obviously not what you want to have again with Cassandra you may have zero down time so rolling reboot means what you when you have to apply some changes or do some maintenance works you still have to restart the noes but you can do it one by one restarting the second one only then first one has finished it already and fully operational it's called it rolling reboot or rolling upgrade and Kate Sandra supports yeah and that is really key I think you you touched on the magic word there no downtime right you do not want downtime Cassandra is able to run indefinitely without downtime if you're you know geolocated across the globe across providers you can pretty much guarantee 100% uptime if you construct it for that and Kate Sandra takes advantage of that it respects that and it allows you to actually um actually Implement that so that's really really cool okay um scale up is something that is very very common in Cassandra scale down we're going to get into that's actually something that's a little bit harder in Cassandra um we have a whole Lab today where we're actually going to scale something up and scale it down it's going to be really really awesome uh gets rid of a lot of the complexity there um automated repairs we talked about and of course the uh metrics and monitoring and all of that is built in to Kate Sandra all right first exercise guys right off the bat we're going to get into this so setting up and monitoring Cassandra we're going to go to the repo here today if I can get some links posted in the chats here I'll post some in uh Discord and in YouTube there y'all are go ahead and click that GitHub link that is going to be our GitHub for today the read me there on the homepage has everything we are going to run through it's got step by steps it's got a table of contents so if you get out of sync feel free to just go up the table of contents go down to the step we're on currently and that will bring you there um we are going to go into our Cloud instances here so if you don't have one of those please do request one from Jack frier um his email again jack if you can post in the chats just let everyone know where to request one of those I already have one of those up today we have a list of links here you'll notice that everything after the first line there says install first those are the things we're actually going to fix so all of those links should be broken if they are not then we have a problem um the first link there however is an SSH console in your browser and what that looks like is this now I will actually exit oops so I can log in with everyone here um actually I'm just going to reopen it that's probably the easiest way to do it boom all right this is shell in a box this allows you to connect through your web browser via SSH into our Cloud instances so kind of wow you know a little bit meta there um if if you wanted to connect over your own SSH feel free to copy that URL at the top of your screen go into say if you're on a Mac or a Linux box you can just use SSH via the terminal and uh the username is going to be the same there it's documented in our uh in our repo here the username is ec2 user and your password is data STX all right uh sorry just a second if you don't have too much experience with uh shell uh when you are sing sshing to a new note to set up a custom user you have to go SSH space uh yes to- user at like in the email at um and then your unique address workstation something some numbers katandra DW workshop. Datt training.com yes that's an excellent point Alex thank you all right so we're logged in now now the next thing we're going to do and you'll notice I'm going follow through line by line pretty much of this repo that's so you guys can all follow along and so we can all do this together all right so first thing we got to do is we got to add our repository so Helm is already installed on these instances for us um again if you're using your own box follow our instructions it helps walk you through the helm install process but we already have it here on our instances so go ahead and do the helm repo ad command and you'll notice we are adding Kate Sandra from the Kate sandra. repo going to go ahead and add that and we get a success me message there Perfect all right now we have to do our repo update and this basically just activates the repo we've just added so go ahead and do that and boom happy helming congrats we got there all right next thing we're going to do now this this is not a Kate Sandra repo this is trafic trafic is actually a special Ingress controller that allows us to basically communicate from the outside world into our cluster and we're we're going to do a lot of configuration of it throughout our commands but uh essentially this just allows us to actually talk to what we're working with here today so we're going to go ahead and we're going to add the repo for traic and we're going to need to do another Helm repo update activating the traic repo as usable for us so let's go and do that and again we get a success Perfect all right so now let's do a hel install let's install our Ingress first here this is going to use the yaml file you'll notice the trafic values. yaml so I'm going to go ahead and I'm going to run that and this will take it just a moment here and boom done and I'll actually show you guys in the directory here we have a whole bunch of EML we have our kind config which is what our actual provisioning step of this this cluster um you don't ever have to use it but that's what uh the our the scripts we used uh to provision this cluster used to configure it we have our pet clinic. which we'll get to in a few minutes we have our set our readmes which are basically the instruction sets and then we have this trafic values. and I'm just going to cat that real quick traic values. and we'll see there's just a couple ports specified um just a really simple file it's just basically saying hey we're setting up this Ingress set it up with these particular ports right off the bat and let's go so nothing too complex there yet just still pretty simple stuff next we're going to go and we're going to install our Kate Sandra tools now Kate Sandra tools is the first step here towards getting Kate Sandra running what it is is basically all the individual components you need to actually set up a a Kate Sandra cluster so all of the individual things that are going to be used should be included here and we'll give that just a moment again to complete one thing that's actually interesting to note um when these actually complete you'll notice we have a couple a couple lines here with information first thing to notice is that revision line revision is basically every time you make a change that will increment so every time you do what's called a Helm upgrade command it will increment it by one so as we go and scale stuff we'll actually I'll point it out to you again there but that's going to start incrementing for us we also have the last date that something was deployed the name space which of course today we're using default and of course the status which is deployed in this case all right so it looks like our home install command worked for the Cassandra or Kate Sandra tools goodness that is hard to remember to say Kate Sandra not Cassandra you know what I bet at some point we will stop making any uh differences between when I'm sure we we most likely will okay here we're actually installing the cluster now you'll notice we've done the Ingress configuration in this command again I I'll just say down the road this will be done automatically for you in the actual Helm install commands but today we're not at that point yet so uh we just have to kind of do it ourselves and let it run so I'm going to go ahead and click enter there and we will give you guys a moment to catch up here as that goes and I am just going to go into Cube I'm going to watch Cube CTL so we can watch this come up so get pods and let's let that run and we're going to watch those come up here now it's going to take you know 2 three minutes for those to actually all come online and you're going to notice that there's some errors that pop up don't worry about it it it it is currently Again release candidate stuff some of the stuff hasn't been set up to launch in specific orders so we're actually relying currently on some pod failures um and then they basically redeploy themselves um they're waiting for some of the previous steps to fin y uh sorry but that's a perfect time uh to give some time to our attendees to catch up and follow the steps so uh yeah yeah yeah absolutely we're going to wait here for a minute so definitely get caught up if you can and uh yeah all right see do we have any questions in chat there uh all answer it the main one was can we go a bit slower please can go slower I'm sorry I I'm talking very fast I I realize that I I will work on slowing down call me out on it if I don't uh so take a look while uh we um have time to catch up and do the steps uh people use it to hurry on during the workshop because as soon as Workshop has gone speakers are not available and training instance are not available and nothing work works and workshop is over not for us we are the data Stacks developers and we care so we want this Workshop available for you as long as you want for it to be available so okay we cannot run training instances for too long because we're are counting all together the workshops from yesterday and today and tomorrow we are around 1,000 of them so that's uh pretty expensive to us we have to stop them after 24 hours but um in general we are always here for you answering the questions at our Discord server and also at the community. DAT stacks.com so Workshop lasts as long as you want it to be running okay yeah we had a request to zoom in here um is that large enough I just zoomed in a little bit there answer in chat there if you can hopefully y'all can see it all right and I see a question from pressat cut and paste doesn't work in Cloud instance well if uh if you're going to the repo and copying out of our our little code blocks there um it should work with just the normal copy paste commands I've been using uh I'm on a Mac I've been using command C and command V this whole time but um you can also I believe right click and copy paste a little more manually that way yeah so there were some uh problems I've heard of before personally I recommend you to use a normal terminal or puty iterm if you are on Mac or any another application you prefer to connect because well uh bash in a browser that's only for those who cannot have anything else but in general we recommend to use SSH yeah yeah absolutely and the only reason I'm using the uh what is it the shell in a box here is because um I'm trying to make it as close of a thing to what what you know you guys are are provided with as possible otherwise I would totally be in the command line myself on my own uh SSH console but all right let's see a couple of copy paste wouldn't work either um option yeah interesting I am not sure about the working with windows that I've never had a problem with that in the past um I would try the right click method and uh see if that works if not um there is a tool out there called putty which will allow you to SSH as well um highly recommend having that tool if you're on Windows anyway I think almost every Windows computer I've ever had I have I have installed putty like first or second thing um and that will allow you to actually SSH with the same SSH command there using the URL and uh that should work right now you could focus on what's uh Eric doing and then do the same steps on your own after the uh Workshop uh using party indeed um yeah all right so we've got some things are completing here here looks like we've got our nodes are up we can see the Kate Sandra dc1 default is now two of two which is excellent we have the schema is now completed so you'll notice that is the only zero of one on that list under ready um that is just a step that basically goes through and takes the reaper schema and applies it to the cassander once it comes online so Reaper which is that repair tool we talked about earlier is using Cassandra to store its data so it is actually utilizing the thing it is repairing kind of cool um but it does need to to install the schema once Cassandra is actually up all right let's see a couple more questions here really quick um can we run SQL yes there are ways to do it we're not going to do it here today but yes you can um let's see here all right I think we're good to continue so I am going to go ahead and contrl C out of my Cube c Watch there and let's go over and look at our next step now we are at the the uh uh Point here where we're actually going to go in and start looking at what our monitoring is so let's go to our links list you'll notice this first one or this sorry this second uh line here is for Prometheus let's go in there and take a quick look at that so Prometheus here doesn't actually display anything you know nice and pretty for us to look at but what it will show you is our node and it shows you the uh what being scraped how often it's being scraped how long it's taking to scrape that data basically just shows us that we are in fact getting metrics and we are in fact healthy it's a great troubleshooting step if for some reason we weren't getting any data in our grafana the second thing we're going to here is grafana now for all of you the uh username admin and the password of secret is what you guys will use to log in by default now if you go to dashboards and and you go to manage you will see this default space here obviously in the final release again we're on release candidate in the final release those will be a little more accessible they're kind of buried here in the first release it's it's something where you know they're they are there but they're just not super upfront and we can actually see we're collecting metrics already so we are connected we are actually getting data and we're actually able to monitor our Cassandra cluster via grafana and Prometheus pretty cool I didn't configure any I didn't configure any Prometheus it is basically there for me when I run the commands and I'm I'm sorry I keep using the word RC this is basically a beta um correct term would be a beta so uh just correcting myself there all right I'm going to go ahead and I'm going to uh I'm going to actually leave grafana open but I'm going to close Prometheus and we're going to go back to our GitHub and that brings us to step two now before we get to step two I'm going to show you just a couple more slides just like two or three and then we're going to jump right back into it all right so working with data having a database is great but if we can't do anything with that database it's useless so what are we going to do today we're going to run the pet clinic app now uh Cedric who's one of my Advocate uh counterparts here uh he wrote a spring app called uh pet clinic it is uh fully uh what's the word I'm looking for containerized goodness my brain just blinked there for for a moment it is fully containerized and we'll actually deploy it with kubernetes alongside of our Kate Sandra um so there I said just a couple slides I kept my promise it was actually one slide let's get into it first thing we have to do is we have to retrieve what our Cassandra password is our user password is from the secret now K Sandra sets up a secret for us when it sets up Cassandra so we're actually going to have to go in and we are going to have to run a command to get that and you'll notice here this giant alpha numeric string is our password now normally I'll actually show you something here um so if we LS ER Eric don't run don't run that's not a Marone slowing down again all right what I'll show you here is if we look at that pet clinic. yaml that we saw earlier we're going to go ahead and we're going to cat that so pet clinic. yaml and we'll notice a few things here first I'm going to scroll up towards the top we have this whole Cassandra password field and right now it's just got gibberish that's not actually a valid cassander password we're going to have to put our own in there now we aren't going to do it oursel we're going to use a said command to take advantage of the power of Linux and do it but uh it's gon to it's going to be replaced with that string we just retrieved next thing I'm going to show you is right down here at the bottom we have this Ingress section where we we're setting up a bunch of ports now those ports are going to be applied to our traic Ingress so that thing we set up at the beginning so that we could access our graan Prometheus is also going to be what allows us to get into our pet clinic app and that's both for the back end and the front end of that application so let's go ahead here and I'm going to uh copy the said command and I am going to paste it here and now if I cat that file again so catpet clinic. yaml and let's scroll up and there we go voila we have our password in there now so our app should be able to connect to our Cassandra instance all right now we're going to go ahead and do kind of the Moment of Truth step and we're going to apply our pet clinic. yaml and what that's going to do I'll actually show you Cube CTL here so Cube CTL get actually let me watch on this so we can watch it come up watch Cube CTL get pods and what's going to happen here is you notice we have these container creating on Pet Clinic front end pet clinic back end and they're really really fast boom they're up I almost missed it I was so slow typing that command those pods that just popped up are our application that is the pet clinic application and if I were to go back to my links list and I were to click on the pet clinic demo app we will see it will load up here now I I'll show you one more thing before we actually interact with this because it's kind of interesting that Ingress we've been working with is uh also on your links list and it actually has a web UI that you can go in and next to Services I'm just going to click explore and I can actually see what's set up as ingresses we've got our grafana here we've got Prometheus we've got our our Reaper and we've got our pet all right there in this list and we can just go look at them and see what's configured kind of an interesting troubleshooting tool not really super relevant to us here today but it's just pretty cool all right closing that out and going back to our pet clinic so now that we have an app connected let's actually work with some data first thing we're going to do we're going to go to pet types and we're going to look at the different pet types that are configured now these are stored in Cassandra currently uh we have dog bird all of that those are actually in a cassander table and instead of having to go in and type an actual you know statement to delete or modify or update I am going to just click delete here and just to prove I'm not you know kind of doing some hand wavess and that something actually deleted from the database I'm going to refresh my page just to show you guys that yes it is indeed gone this isn't something that's cached on the web and I can just delete and hahaa it looks cool I actually deleted something from my database now if I wanted to add something what should we add uh let's add we have snake let's add oh we have cat goodness we've added most things let's add Bird right back in then so let's add Bird go ahead and save and we have bird back in the list now again I will refresh my page just to kind of prove that this is in fact happening and it notice it sorted it now the reason it did that is we were using clustering columns which are a way to order your data inside Cassandra they're way to order and provide uniqueness but in this case the important part is that they're ordering it so that when we refresh the page it reordered and boom that's what we had all right so we have now removed and added data to our Cassandra through an app just by copying over a single password the user access password and this is all done through the the driver this is actually the under the hood this is the the spring uh stuff which all runs on the Java driver all right going back here I think that is all for this section let me just verify that really quick so I'm not getting ahead of myself yes okay perfect so next session or section we are going to move on here now this is the cool part this is the part that just makes me so excited uh I'll try to talk slow because I get excited here you can probably tell I get excited about this stuff because of just how uh energized it makes me but okay in Sandra it's very easy to scale up a cluster it's a lot harder to scale down a cluster but it is possible there are ways to do it but it requires a lot of cleanup steps there's a lot of rebalancing stuff that actually happens um and it it is kind of a job to to do it is possible but it's a job there are two ways in Kate Sandra that we can accomplish these steps now the first one is through config files we could actually go in and we could edit some yaml and we could resize things and then we could let Helm take care of the rest gretes and Helm take care of the rest or we can just do it with a Helm upgrade command and that's what we're going to do today is we're going to use Helm upgrade to go through and handle all of those operations that we need to do automatically for us all right so going back to the exercises it's now section three if you uh if you're trailing along uh feel free to or following along feel free to go down to section three and we'll get started here first thing I'm actually going to do I'm going to do a hel get manif now I better edit out of my exit out of my qctl Helm get manifest basically shows me what is currently running in my cluster now you'll notice Let's uh go ahead and control C out of this because that's going to go on for a while you'll notice up there I had a bunch of yaml files and they are for all sorts of things we got a castdc yaml we've got a deployment yaml all of these things are basically where the magic is happening that is is allowing us to deploy these things without needing to set them all up ourselves so all of these amals are are kind of they are what make Kate Sandra Kate Sandra is all this preconfigured stuff now interestingly enough I mentioned Helm is a templating language Helm allows us to make certain parts of these animals dynamic as we need to and that's what we're going to be manipulating here is uh something that was dynamically configured so let's go ahead and let's clear for me to type and talk at the same time all right there we go so now we're starting fresh with the console there we're going to go ahead and we're going to try to find the value that we are looking for which in this case is size size is how many nodes we have in our cluster and you'll see it is configured to one if we want to change this we can go through and we can use the helm upgrade command now you'll notice all of our Ingress set plags are uh in this command the reason for that is anything set this way needs to be included in the command otherwise it gets reset to the default so we would basically lose all of our Ingress from this cluster and we don't want to do that so let's go ahead here and let's apply our Helm upgrade command oh did it not copy I guess it didn't copy and paste all right there we go so going to go ahead and hit enter on that and then you know what I'm going to do is I am going to uh grip that size again oops did we not Helm upgrade requires two arguments did I miss I think I didn't copy the whole thing Helm upgrade cerer there we go all right it applied and you'll notice my revision is now at two actually so I should have noticed that when I hit enter there I just was moving a little too fast um that's because I have now made a change and so it now it automatically increments that revision number all right let's go and retrieve our value there we go there we go you notice we set that to three in our Command up here so K sand Sandra set size right here set size to three and that is what basically went and resized our entire cluster now to prove this is actually resizing I'm going to go into Cube C actually I'm going to watch it again because watching is much more uh much better in my opinion Cube CTL get pods and there we go we see that we have two nodes that are also initializing here now those are going to take a moment and I don't really want to do anything until they're up but those nodes are now full standard nodes they are actually running and if we were to say go into grafana here in a moment which we'll do once they show up we'll actually see metrics being collected from those nodes as well pretty cool all right let's give it a moment here and give you guys a moment to catch up as well any questions there Alex y see here uh so not so much where do those two notes start up very good question by Kevin that's one we should answer um sorry so the question was what where did the notes start uh yes uh if you would simply do uh Cube CTL get ps- W I will explain a couple of things yeah yeah let me do that here so Cube CTL get pods you said slw uh P get ports d o DH o space w w uh yep like that uh oh my god um yeah sorry that's a pretty late uh for me already uh uh yes looks good wait a second while I'm trying to remember uh question how many data centers are here in this cluster that's only one single data center cluster because that's a educational exercise uh there we go uh yeah thank you so good and can you make it a little bit smaller then so it will be uh yes I can let me yeah uh thank you d o white uh that's at my place that's almost 8:00 p.m. and it was a very long day okay so what and do it again yeah and may you push enter sometimes so it will scroll up a bit oh yeah let me uh clear and then I'll I'll run it again okay also works there we go yep perfect so take a look there are some uh things I want to answer first of all uh we run these uh that's a kubernetes cluster but we have only one um machine running that so you have every one of you have one machine when we are going to have multiple workers uh we use kind for wet so technically that's all the kubernetes in a doer cluster uh but even in this case KAS kandra cares of the data allocation and replica allocation over the cluster so you see on the left part K Sandra dc1 stateful default STS Z one and two can you could you please highlight them uh stateful sets stateful sets Services yeah those those free y yep uh so take a look they allocated on kind worker kind worker two and kind worker three and that's not a coincidence every next note uh Kate sandre will try to launch on the next available free note uh so to spread the notes over the cluster and to have higher higher full tolerance in case one of the kubernetes workers fails so we have fre worker notes and uh therefore we have kandra three of them on different kubernetes worker notes that's not a coincidence that's the intention of kidan R uh well then we were one more question by prasat K I'm not seeing 2/2 import listing so if you again watch those um STS kandra default STS 01 and two they okay V I don't know why the third one has one out of two but H it's it's rolling it's rolling ah it's rolling okay yeah so every kfandra Casandra default STS has 2/2 it means what we have two containers uh in one port and one container as I said before is Cassandra and second is a side car yes and and you'll notice there that when I reran that command so I wasn't running watch on that command before um that's why it was static there just so I could uh highlight things for Alex um but you'll notice I ran it again and now that pod is online with two of two so it is complete and that's a great question when upscale what are the seed nodes and that's the lovely thing thank you noo for asking because from now on you don't care about that because Kate Sandra cares about takes care of it for you you don't have to worry yeah uh all poorts would end with STS are Cassandra poorts well uh yes and no uh in all ports with STS are stateful sets and kandra uses stateful sets so in this case yes all the notes with SS in the end are Cassandra notes exactly yeah all right I think we get we're going to move on here we got about 22 minutes which should be enough to get through the rest of this have a quiz oh that's right we do all right so since we saw those were online you know I'll actually go here to grafana quick and we'll notice right down at my node status we've got three nodes Isn't that cool we got three nodes so now we're actually Gathering data from all three nodes which is just awesome we didn't have to configure anything again it handled it all for us it it added them to the metrics and the monitoring and it's done simple as that it was basically a one command uh operation to add two more nodes to the entire thing that's just so cool all right going back to it we're gonna actually size it back down now I said this before sizing a cander cluster down takes a lot of work it's possible it's doable but it takes a lot of work today we're going to do it with one command and literally if you notice in my command here all we're doing is we got set size to one that's it we're just resetting the size to one Helm and kubernetes take care of the rest let's go ahead and do that all right and boom revision three so we notice that that is now on a new revision meaning our upgrade command took and I am going to go ahead and I am going to do our uh get manifest command just so we can see really quick that that change actually took and I can prove it here for you and the size is now set to one now it's going to start spinning those down we're going to see these notes here for a while um those are going to be spinning down it takes a it takes some time so we might not get to them before the the end of the session here uh to take a look but those are in fact starting to spin down and and uh terminate themselves in a graceful manner that is Cassandra safe and that is really key doing it in a Cassandra Safe Way is important to not have downtime and not lose data all right running repairs we're going to get to that in just a moment because we have to talk about what repairs are so we talked about entropy earlier entropy is just you know the fact it's a fact of life it's it's has to do with physics right things tend to Trend towards chaos and we can't break those rules with our distributed systems in fact we tend to notice those problems a lot more in our distributed systems because instead of having you know a single drive that could fail we have potentially hundreds or thousands of drives that could fail we have hundreds or thousands of processors of different Hardware components we're basically increasing the amount of of places where something could end up going wrong anything going wrong causes or can cause what's called entropy in a system which is basically a gradual degradation of the system in data terms in in Cassandra that can cause data degradation and we don't want that to happen so in order for us to combat entropy we run repairs repairs are a tool to reverse entropy over time now the repairs work by constructing meracle trees which are essentially they take a A in the simplest form I'm going to very oversimplify this but they they take a chunk of the data they hash it they get the hash value and they take that same chunk of data over on the other side they hash it and then they compare the hashes if the hashes don't match then they know that some data is out of sync and they'll go and and find smaller and smaller chunks until they can find what data is out of sync and then they stream that data across to bring it back into you know a reconciled state in a in the simplest form that's what a repair is now there are in Cassandra there things called incremental repairs if you've got data STX Enterprise there's a thing called node sync there are a lot of kind of more advanced tools to to accomplish the same thing today we're just going to focus on simple repairs and honestly in kandra and most Cassandra deployments simple repairs are really all you need um you can accomplish what you need with simple repairs the other tools are just there for you know operational streamlining and things like that okay running repairs is done through a UI where we will schedule them and then we will also be able to trigger them there's also some information we can glean about our cluster through this UI and we'll get into that in just a second here because it is now time for the next exercise so in your link list we're going to go down to the line four which is Cassandra repair go ahead and click on that that's going to bring up our repair console now you'll notice here there's there's actually our topology is laid out we've got dc1 which is the name of our data center we have a single node in dc1 and this node actually we can see the IP address um pretty cool what we're going to do here is we're going to go click schedules and from schedules we're going to click add schedule and we're going to go ahead and we're going to start typing in uh spring pet clinic and notice it auto completes it actually knows what key spaces we have on our cluster key space being the bucket that stores tables that's what our app is interacting with is the spring uh pet clinic keyspace okay owner I'm just going to say I'm the owner for now um obviously if you're in a big organization or something where you actually want to keep track of things you should probably be a little more explicit about that but um just for purposes of the demo we're going to do it this way interval in days best practice is to run a repair every seven days so seven should be the number you use here unless you have a really good reason not to um it does allow you to configure that but let's use seven there for now and I'm going to hit add schedule and you'll notice my repair is now set up and we are good to go now if I go back to clusters here nothing is currently running but if I wanted to kick off that repair I could go back to my schedules and I could click run now and you'll notice it says repair will be run shortly we'll start shortly and in moment here we have to give it a second to actually kick off but it'll pop up here with a progress bar saying you know basically repair running um and it'll give us a little progress bar on that we'll give it a couple seconds here let yall catch up uh I got a question here if the number of nodes is limited to one can we still be able to scale up limited to one I'm not sure what you mean by that um so the in in helm what when we ran it the default was was at one node we were starting with a single node and then we were scaling up from there so yes you can scale up by using that set flag the set size equals and then the number of nodes I recommend not scaling up you know like one two three scale up probably two actually three nodes because three is kind of for Cassandra where you start getting Cassandra likee Behavior you start being able to take advantage of the distributed nature of Cassandra um actually best practice if you're trying to actually run something in production I would highly recommend starting with six nodes in 99% of the use cases out there okay if you look here in our UI we actually had this repair kickoff we see the progress bar and it is actually running so we just triggered a repair that's now going to run once every seven days on our cluster and we don't have to think about it it just runs and we can check back if we want to you know get some information check on some health statistics but it just runs simple as that it's it's you know when I explain these things in the past I'd go like 25 minutes of explaining in-depth how this stuff works now with Kate Sandra it's just like I'm done explaining this is incredible this you know I don't have to explain things anymore they just work really really cool okay at the bottom of the repository you'll find um some resource links I'm not going to navigate back there um again so I just want to point that out all right last piece of this backup and restore now I mentioned earlier that that Medusa the backup and restore tool is part of Kate Sandra it is currently in Kate Sandra and it is most of the way implemented but it's not something we're going to deal with today because again we're we're in beta and there are just a couple things that are still being ironed out with it and we just you know wanted to give you guys a good experience as opposed to trying to fight uh something that is still kind of being hashed out so um the the actual implementation if you want to go and try to run this yourself you can run a hel install command and essentially what you're doing is you're installing just a quick running job which will go and create a backup we use the set Flags to configure what that backup will be called we also use set Flags to configure um where that will be so it can be on you know Google storage S3 storage local storage any any of those things we can actually send our backups there and I believe we're expanding that as well uh on the road map I believe the intention is to get a lot more um uh storage providers in there as well okay with that we are not going to do exercise five because of the reasons I just mentioned we're going to get into resources couple things here Kate Sandra iio is the web page for the open source project highly recommend you go check it out um lot of good stuff there there are links to the GitHub to the docs to um basically everything you need to get involved with the project or to use the project um then also the project GitHub is github.com Kat Sandra K Sandra uh highly recommend you check it out there's a lot of work that's been going on there you'll notice John sand in in both of the chats he's one of the engineers who's actually been committing large portions of the code to this project um he was nice enough to come on and help support questions today in our chats so thank you uh John for doing that um but he and many others are there actually contributing to this project okay road map this is always the exciting stuff right what's coming what's next as with any open source project this is determined partly by the users and Community around it so there are certain things on here that are very high priority let your voice be heard get involved and actually help to to prioritize the lists here um but there's a lot here I mean goodness we upgrading your clusters some node life cycle stuff uh data loading that's kind of a big one there's spark connector kofka connector um all of those things are are on the road map and we are actually working actively to get them into the project so definitely get involved if you have opinions on these things let your voice be heard okay learning now this is where we talked about the certifications before um go to data.com uh sdev you can get links to the academy courses there's also uh a whole bunch of curated content on kataka C if you haven't used kakoda yet it's basically O'Reilly released a really cool tool to do um full scenarios uh in terminal in your web browser so kind of a self-service um lab that you can do from your browser with virtual machines and everything all there for you so a lot of scenarios there with different uh different exercises we also have community. data.com which is basically our stack Overflow managed by um data Stacks talk about all things cassander there it's a really good place to hang out um interact with open source interact with DSE interact with Kate Sandra whatever it is you have questions on bring them there tons of people are on there all the time answering questions so please come on by um we have social media data Stacks devs is of course we are all employed by data Stacks but we are here to as Alex said upgrade developers our goal is not to be marketing we are not trying to do anything like that we are trying to provide developers with useful stuff that will help them to as Alex said uh improve their career and get paid more so well well well advantage or social media yes and no you see I'm happy when uh people are getting paid uh better for the job they're doing but that's not my main purpose I would say I'm working in the it infrastructure and it field for a way too long time and I'm tired of uh so many people doing uh architectural mistakes and doing some software development not as good as they could so I'm happy to make the community better better and make people developing better software that's my main point for me yes I would agree with that as well all right let's go on now this is the cool part we're announcing a Cassandra kubernetes certification now we already have two certifications we have our developer and our administrator certifications but we are working on very soon it will be popping up so keep an eye out for it the Cassandra on kubernetes certification and it's going to cover a whole lot of of really deep content on that topic so highly recommend uh you know keep an eye out for it it it will be coming very shortly all right and oh I will bring this up as well if you do want to see uh any information on certifications dat.com deev certifications will get you to basically the page that that uh has all of that information all right um I will bring up here we do have our our our Academy courses um the ds21 ds210 and ds220 which most everyone who's been in the cassander world for you know any length of time has probably heard of or taken those um those are basically fundamentals courses when it comes to working with Cassandra those are all offered at the uh /dev Academy URL there I highly recommend you check them out if you have any interest in pursuing Cassandra uh in pretty much any capacity but they are very very useful courses and there's a lot more courses there as well well yep and I would say we give you the chance to pass a certification exam for free but uh if you are not ready that's just a wasting of of of time uh not money but time at least definitely and time time is very valuable so first get the course it's free then passw certification exam and you have your very well-deserved certification that's how it works yeah absolutely um we also have uh a book that is Cassandra the definitive guide and it really is the definitive guide um this was written by Jeff Carpenter he is a uh uh one of my co-workers here at datax uh he actually was working I think on the uh was it the second edition of this book as well um so he he's been writing this book for a while uh and updating this book fairly consistently it covers all sorts of things from you know the reasons why Cassandra works the way it does to how to make it do things um it's a very very informative book highly recommend you check it out if you have any uh interest at all um uh if you want to attend our next Workshop subscribe at beat. Le d/ subscribe D dat stacks devs and you will be with us with our next events because we run Cassandra Global Meetup program we run data Stacks Monday learning program we have Cassandra workshops every week and we have always have even something more for you so subscribe at bit.ly subscribe Das data Stacks deaths and now open question what do you like the most and what should we [Music] improve now you can type everything you think about us more [Laughter] swag more re the resources made available they actually are going to be available um in the GitHub that you guys all used for the labs today um there are links down at the bottom for everything we talked about pretty much um so the resources should all be there um what should we improve your presentation skills is that what youd like or what we should improve yeah that was my next question uh slow slow down I didn't have time to highlight that but yes I maybe we have to uh slow down a little bit indeed but you know what again first you can watch what Eric is doing and then do it on your own and we are staying with you so don't worry more time to handle the tools they are cool absolutely but the training instances stay with you for 24 hours so you definitely have time to handle the tools that's no worries yeah there was another one on home there yeah on the left hand side at the very [Music] bottom which one this one yes uh uh practical do documentation resources K Sandra helm so Helm actually has all their own documentation which um you know is very available on Google but Kate Sandra we actually have uh the documentation was all in the links we provided in the Kat sandra. highly recommend you check that out and of course Cassandra documentation uh data.com is itds or is it docs. dat.com currently I don't remember the URL for that off the top of my head but we do have a doc site which we can get the links to as well which is very in depth on a number of sard topics mhm yep uh and I'm uh completely agree uh oh so this one I wanted to highlight why and how clients are using Cassandra uh in general Cassandra is the best Feit when you are going to work with a uh some big size data over the world and your SLA requires to be highest possible availability and highest possible performance and for any kind for every situation like that Cassandra is a good feed and that's why companies like apple Netflix Instagram are using using Cassandra too much yeah actually if you pull out your phone and you just look at the apps on your phone pretty much I'd say 80% plus of the apps on your phone probably have Cassandra somewhere in the stack um it's incredibly widely used by modern applications the times you don't see it used so often is if someone's got a very you know Legacy application that hasn't been modernized often times maybe you know Cassandra didn't exist at that time but for most modern applications Cassandra is somewhere in the stack okay uh so I think we are done for today thank you for feedback we cannot answer every feedback right now but we read them after the workshops and we react on them um um good uh too many topics in one presentation I would like to get a more out of deeper dive into Kate Sandra and less on Cassandra kubernetes I agree and we will do that so this Workshop is more uh beginner to intermediate level and next one we will do kandra is one of our favorite topics from now on so we will do a much deeper dive with requirements to attendees to have already some knowledge in kubernetes and Cassandra so we can focus on uh Kat Sandra but you know what that's a day Zero for kandra kid Sandra was just released and you already want to have a fullsize deep dive workshop on that it takes some time to prepare the workshop we did today it took many dozens I don't know maybe hundreds of working hours so we just uh have some time to prepare we will do that but thank you for your opinion we really value that is this recorded can you watch this demo later absolutely same link yep that'll be on YouTube it doesn't go away it's it's on the YouTube channel for as long as YouTube lets us keep it here okay Cassandra is good in all all up nope it isn't Kal Cassandra is an oilp database but if you want to have uh full pledged all up over Cassandra it's absolutely possible for example with Apache Spark spark is very well integrated with Apache Cassandra so you may have uh whatever spark suggests to you machine learning over Cassandra's data very easy uh even SQL spark SQL you can run structured query languages the forign keys over Cassandra VI aach spark it will not be as lightning fast as Cassandra is but it will work so for alop prefer Cassandra plus spark and I think we are over time so it's time for us to stop so I want to say big thank you to everyone who participated in this Workshop we love you we are very happy you were with us awesome thank you Eric so yeah we're out I think not yet but we are going to be out in a moment so see you next time one new now I have more room no more formats to change me on the same page we are ever [Music] this living in the future you and me made for us ser heaven in the future of the cloud [Music]",
    "segments": [
      {
        "start": 0.64,
        "duration": 6.719,
        "text": "hello everyone and"
      },
      {
        "start": 4.12,
        "duration": 5.64,
        "text": "welcome hi Eric hello how you doing"
      },
      {
        "start": 7.359,
        "duration": 4.641,
        "text": "today Alex yeah that's a great day you"
      },
      {
        "start": 9.76,
        "duration": 5.839,
        "text": "know that's a day of a big release for"
      },
      {
        "start": 12.0,
        "duration": 7.039,
        "text": "us so I feel a bit tired but very happy"
      },
      {
        "start": 15.599,
        "duration": 5.881,
        "text": "and you I I'm in the same boat very very"
      },
      {
        "start": 19.039,
        "duration": 6.361,
        "text": "tired it's long road getting here but we"
      },
      {
        "start": 21.48,
        "duration": 7.4,
        "text": "are we are we're here it's great yeah"
      },
      {
        "start": 25.4,
        "duration": 5.719,
        "text": "wonderful so uh if you can hear us if"
      },
      {
        "start": 28.88,
        "duration": 4.8,
        "text": "you can see us please set the thumbs up"
      },
      {
        "start": 31.119,
        "duration": 5.081,
        "text": "in the YouTube chat and let's celebrate"
      },
      {
        "start": 33.68,
        "duration": 5.32,
        "text": "together because that's a special day"
      },
      {
        "start": 36.2,
        "duration": 5.16,
        "text": "for all the Apache candra community and"
      },
      {
        "start": 39.0,
        "duration": 5.76,
        "text": "data stocks of course as"
      },
      {
        "start": 41.36,
        "duration": 6.92,
        "text": "well yes all right and it looks like we"
      },
      {
        "start": 44.76,
        "duration": 6.08,
        "text": "got Cedric's giving us a thumbs up"
      },
      {
        "start": 48.28,
        "duration": 3.81,
        "text": "okay so that's that's already great"
      },
      {
        "start": 50.84,
        "duration": 3.44,
        "text": "helping us that doesn't"
      },
      {
        "start": 52.09,
        "duration": 6.109,
        "text": "[Laughter]"
      },
      {
        "start": 54.28,
        "duration": 6.799,
        "text": "count no but I mean Cedric today is also"
      },
      {
        "start": 58.199,
        "duration": 6.161,
        "text": "not only an answer but list ER thank you"
      },
      {
        "start": 61.079,
        "duration": 7.04,
        "text": "sh thank you thank you babo and all the"
      },
      {
        "start": 64.36,
        "duration": 5.6,
        "text": "other people today with us and that"
      },
      {
        "start": 68.119,
        "duration": 6.841,
        "text": "means what we can"
      },
      {
        "start": 69.96,
        "duration": 8.159,
        "text": "start yes okay so but uh Eric what makes"
      },
      {
        "start": 74.96,
        "duration": 6.0,
        "text": "these days so special for us there is a"
      },
      {
        "start": 78.119,
        "duration": 4.36,
        "text": "new open source project in town and it's"
      },
      {
        "start": 80.96,
        "duration": 4.24,
        "text": "something you and I have had our hands"
      },
      {
        "start": 82.479,
        "duration": 4.881,
        "text": "on for a little while now but we are"
      },
      {
        "start": 85.2,
        "duration": 4.44,
        "text": "actually uh bringing it public I think"
      },
      {
        "start": 87.36,
        "duration": 5.16,
        "text": "the GitHub repos all went public the Jer"
      },
      {
        "start": 89.64,
        "duration": 4.4,
        "text": "went public all this morning so we are"
      },
      {
        "start": 92.52,
        "duration": 3.72,
        "text": "going to be talking a little bit about"
      },
      {
        "start": 94.04,
        "duration": 4.68,
        "text": "that what it is what it looks like why"
      },
      {
        "start": 96.24,
        "duration": 5.28,
        "text": "it's cool and how you can get involved"
      },
      {
        "start": 98.72,
        "duration": 5.0,
        "text": "um again it's open source so not a data"
      },
      {
        "start": 101.52,
        "duration": 3.879,
        "text": "Stacks only product it's not like dsse"
      },
      {
        "start": 103.72,
        "duration": 4.52,
        "text": "data Stacks Enterprise or anything like"
      },
      {
        "start": 105.399,
        "duration": 6.161,
        "text": "that this is an an open source project"
      },
      {
        "start": 108.24,
        "duration": 5.4,
        "text": "with uh other open source tools um that"
      },
      {
        "start": 111.56,
        "duration": 3.559,
        "text": "are around the cassander community built"
      },
      {
        "start": 113.64,
        "duration": 3.04,
        "text": "in and we'll get into what that looks"
      },
      {
        "start": 115.119,
        "duration": 4.161,
        "text": "like as we progress here throughout the"
      },
      {
        "start": 116.68,
        "duration": 4.96,
        "text": "day yeah and manil is perfectly right"
      },
      {
        "start": 119.28,
        "duration": 5.36,
        "text": "because today is the official public"
      },
      {
        "start": 121.64,
        "duration": 5.6,
        "text": "release of kandra we discussed it a lot"
      },
      {
        "start": 124.64,
        "duration": 5.28,
        "text": "before what's the Cassandra is and we"
      },
      {
        "start": 127.24,
        "duration": 6.92,
        "text": "talked about kubernetes as well and"
      },
      {
        "start": 129.92,
        "duration": 7.319,
        "text": "today is the public release for K Sandra"
      },
      {
        "start": 134.16,
        "duration": 6.799,
        "text": "Cassandra we've all required ecosystem"
      },
      {
        "start": 137.239,
        "duration": 5.841,
        "text": "for operations built in together into"
      },
      {
        "start": 140.959,
        "duration": 4.64,
        "text": "the something you can easily run on"
      },
      {
        "start": 143.08,
        "duration": 5.32,
        "text": "kubernetes with just a couple with just"
      },
      {
        "start": 145.599,
        "duration": 6.561,
        "text": "a couple of commands and that's really"
      },
      {
        "start": 148.4,
        "duration": 6.52,
        "text": "easy to use and you we'll see that"
      },
      {
        "start": 152.16,
        "duration": 4.56,
        "text": "today yes and you know the the cool"
      },
      {
        "start": 154.92,
        "duration": 3.679,
        "text": "thing is so this is the second time"
      },
      {
        "start": 156.72,
        "duration": 3.28,
        "text": "we're actually doing this Workshop sh"
      },
      {
        "start": 158.599,
        "duration": 3.801,
        "text": "don't tell anyone but if you were here"
      },
      {
        "start": 160.0,
        "duration": 4.76,
        "text": "for your yesterday's uh cubec con"
      },
      {
        "start": 162.4,
        "duration": 4.4,
        "text": "Workshop you got a sneak peek and you"
      },
      {
        "start": 164.76,
        "duration": 3.36,
        "text": "got to see a little bit this is a lot of"
      },
      {
        "start": 166.8,
        "duration": 4.439,
        "text": "the content today is going to be the"
      },
      {
        "start": 168.12,
        "duration": 4.92,
        "text": "same but um feel free to stick around"
      },
      {
        "start": 171.239,
        "duration": 6.121,
        "text": "and and ask questions and add color"
      },
      {
        "start": 173.04,
        "duration": 9.279,
        "text": "where you can so yeah"
      },
      {
        "start": 177.36,
        "duration": 8.36,
        "text": "absolutely so what I think we can start"
      },
      {
        "start": 182.319,
        "duration": 6.2,
        "text": "already that's a very good time to start"
      },
      {
        "start": 185.72,
        "duration": 5.48,
        "text": "and let's take a look about the thing"
      },
      {
        "start": 188.519,
        "duration": 6.0,
        "text": "about the things we are going to do"
      },
      {
        "start": 191.2,
        "duration": 5.92,
        "text": "today uh so we have to ask you some"
      },
      {
        "start": 194.519,
        "duration": 4.72,
        "text": "questions and prepare for a workshop we"
      },
      {
        "start": 197.12,
        "duration": 4.52,
        "text": "will cover Cassandra and kubernetes"
      },
      {
        "start": 199.239,
        "duration": 4.36,
        "text": "Basics but Basics you see we are"
      },
      {
        "start": 201.64,
        "duration": 4.519,
        "text": "speaking about running Cassandra and"
      },
      {
        "start": 203.599,
        "duration": 5.161,
        "text": "kubernetes so if you have no idea of"
      },
      {
        "start": 206.159,
        "duration": 5.72,
        "text": "both Cassandra and kubernetes work this"
      },
      {
        "start": 208.76,
        "duration": 5.64,
        "text": "Workshop isn't going to be easy for you"
      },
      {
        "start": 211.879,
        "duration": 5.401,
        "text": "but we will not do take a Too Deep dive"
      },
      {
        "start": 214.4,
        "duration": 5.479,
        "text": "don't worry then we will discuss about"
      },
      {
        "start": 217.28,
        "duration": 5.599,
        "text": "how do you set up and monitor kandra"
      },
      {
        "start": 219.879,
        "duration": 5.401,
        "text": "work with data scale the cluster up and"
      },
      {
        "start": 222.879,
        "duration": 5.601,
        "text": "down because well candra is the easiest"
      },
      {
        "start": 225.28,
        "duration": 5.92,
        "text": "database for scaling in both directions"
      },
      {
        "start": 228.48,
        "duration": 5.72,
        "text": "we will do some anti-entropy fighting"
      },
      {
        "start": 231.2,
        "duration": 8.64,
        "text": "with repairs uh and we will switch to"
      },
      {
        "start": 234.2,
        "duration": 8.56,
        "text": "resources that may help you and um we"
      },
      {
        "start": 239.84,
        "duration": 6.959,
        "text": "will use four different"
      },
      {
        "start": 242.76,
        "duration": 6.6,
        "text": "tools uh to cover during these workshops"
      },
      {
        "start": 246.799,
        "duration": 5.201,
        "text": "uh for the streams we are doing the main"
      },
      {
        "start": 249.36,
        "duration": 5.239,
        "text": "stream now in YouTube and we have a"
      },
      {
        "start": 252.0,
        "duration": 6.04,
        "text": "backup stream in twitch for the"
      },
      {
        "start": 254.599,
        "duration": 6.32,
        "text": "questions you can use YouTube uh chat"
      },
      {
        "start": 258.04,
        "duration": 6.64,
        "text": "but the main place for us is our Discord"
      },
      {
        "start": 260.919,
        "duration": 6.921,
        "text": "server which is going to be much better"
      },
      {
        "start": 264.68,
        "duration": 5.359,
        "text": "and uh to do the steps that's a workshop"
      },
      {
        "start": 267.84,
        "duration": 5.48,
        "text": "so you are going to do your part of for"
      },
      {
        "start": 270.039,
        "duration": 7.88,
        "text": "work uh you can use your machine as long"
      },
      {
        "start": 273.32,
        "duration": 7.12,
        "text": "as it supports uh Docker and has some"
      },
      {
        "start": 277.919,
        "duration": 6.681,
        "text": "Firepower uh but if it doesn't work to"
      },
      {
        "start": 280.44,
        "duration": 8.24,
        "text": "you you can uh use our Linux box uh in"
      },
      {
        "start": 284.6,
        "duration": 6.4,
        "text": "the cloud delivered by AWS thanks and"
      },
      {
        "start": 288.68,
        "duration": 3.2,
        "text": "materials are all completely available"
      },
      {
        "start": 291.0,
        "duration": 4.24,
        "text": "on"
      },
      {
        "start": 291.88,
        "duration": 8.24,
        "text": "GitHub I kindly ask I'll we have Link in"
      },
      {
        "start": 295.24,
        "duration": 8.04,
        "text": "the description of the video now about"
      },
      {
        "start": 300.12,
        "duration": 6.04,
        "text": "the Practical steps you have uh two"
      },
      {
        "start": 303.28,
        "duration": 6.759,
        "text": "pills to decide which one to take your"
      },
      {
        "start": 306.16,
        "duration": 7.08,
        "text": "laptop or Cloud environment so if you do"
      },
      {
        "start": 310.039,
        "duration": 6.401,
        "text": "it on your own you will need Docker and"
      },
      {
        "start": 313.24,
        "duration": 6.16,
        "text": "kubernetes uh as a kind or mini Cube for"
      },
      {
        "start": 316.44,
        "duration": 6.039,
        "text": "example mini Cube should work also as"
      },
      {
        "start": 319.4,
        "duration": 6.6,
        "text": "well as far as I know and if you cannot"
      },
      {
        "start": 322.479,
        "duration": 5.921,
        "text": "have Docker or your laptop is not so uh"
      },
      {
        "start": 326.0,
        "duration": 6.12,
        "text": "strong enough to run the W system you"
      },
      {
        "start": 328.4,
        "duration": 8.12,
        "text": "may use our CL Cloud uh infrastructure"
      },
      {
        "start": 332.12,
        "duration": 8.16,
        "text": "so uh if you want to grab one our Cloud"
      },
      {
        "start": 336.52,
        "duration": 7.64,
        "text": "instance please contact contact jack."
      },
      {
        "start": 340.28,
        "duration": 6.68,
        "text": "fryer dat.com and I see Jack in the chat"
      },
      {
        "start": 344.16,
        "duration": 5.56,
        "text": "already so you can write him an email"
      },
      {
        "start": 346.96,
        "duration": 5.48,
        "text": "and he will immediately send you back"
      },
      {
        "start": 349.72,
        "duration": 7.64,
        "text": "the yeah thank you Jack if you need a"
      },
      {
        "start": 352.44,
        "duration": 7.92,
        "text": "cloud instance please send us the things"
      },
      {
        "start": 357.36,
        "duration": 5.64,
        "text": "uh send the things to Jack"
      },
      {
        "start": 360.36,
        "duration": 6.679,
        "text": "uh and this one is completely prepared"
      },
      {
        "start": 363.0,
        "duration": 6.88,
        "text": "so it has kubernetes installed with kind"
      },
      {
        "start": 367.039,
        "duration": 5.361,
        "text": "and that's a sento"
      },
      {
        "start": 369.88,
        "duration": 4.84,
        "text": "machine yeah I would just throw out"
      },
      {
        "start": 372.4,
        "duration": 4.12,
        "text": "there that our our infrastructure is"
      },
      {
        "start": 374.72,
        "duration": 3.28,
        "text": "going to be much much easier it's a much"
      },
      {
        "start": 376.52,
        "duration": 2.799,
        "text": "much cleaner experience for you to hear"
      },
      {
        "start": 378.0,
        "duration": 2.84,
        "text": "today because we're not really going to"
      },
      {
        "start": 379.319,
        "duration": 4.081,
        "text": "allow time for you to set up all the"
      },
      {
        "start": 380.84,
        "duration": 4.56,
        "text": "docker the kind cluster and all that"
      },
      {
        "start": 383.4,
        "duration": 4.32,
        "text": "that that stuff it's not built into the"
      },
      {
        "start": 385.4,
        "duration": 3.96,
        "text": "labs here so highly recommend you go"
      },
      {
        "start": 387.72,
        "duration": 3.72,
        "text": "with our infrastructure if that's not an"
      },
      {
        "start": 389.36,
        "duration": 4.04,
        "text": "option for you you know we we do have"
      },
      {
        "start": 391.44,
        "duration": 3.68,
        "text": "the in the GitHub today we'll have"
      },
      {
        "start": 393.4,
        "duration": 3.919,
        "text": "instructions to how to set it up"
      },
      {
        "start": 395.12,
        "duration": 3.88,
        "text": "yourself but um we do try to provide"
      },
      {
        "start": 397.319,
        "duration": 4.0,
        "text": "everything so you can get the labs done"
      },
      {
        "start": 399.0,
        "duration": 4.759,
        "text": "yeah absolutely thank you Eric you are"
      },
      {
        "start": 401.319,
        "duration": 6.0,
        "text": "very right for a smoother experience we"
      },
      {
        "start": 403.759,
        "duration": 7.241,
        "text": "recommend to use cloud cloud in from all"
      },
      {
        "start": 407.319,
        "duration": 5.72,
        "text": "right and I have a question in the chat"
      },
      {
        "start": 411.0,
        "duration": 4.28,
        "text": "do you recommend any specific course for"
      },
      {
        "start": 413.039,
        "duration": 4.121,
        "text": "the certification or one listed on"
      },
      {
        "start": 415.28,
        "duration": 4.319,
        "text": "Cassandra Academy is sufficient I"
      },
      {
        "start": 417.16,
        "duration": 6.319,
        "text": "recommend learning puff at the Cassandra"
      },
      {
        "start": 419.599,
        "duration": 5.681,
        "text": "Academy data academy. dat stacks.com we"
      },
      {
        "start": 423.479,
        "duration": 4.761,
        "text": "have learning puff for admins and"
      },
      {
        "start": 425.28,
        "duration": 5.08,
        "text": "learning puff for developers yeah and"
      },
      {
        "start": 428.24,
        "duration": 3.32,
        "text": "it's a full curated thing so all you got"
      },
      {
        "start": 430.36,
        "duration": 3.16,
        "text": "to do is Click there and it will"
      },
      {
        "start": 431.56,
        "duration": 4.68,
        "text": "actually line up the correct courses for"
      },
      {
        "start": 433.52,
        "duration": 5.44,
        "text": "you um I think all of them take intro to"
      },
      {
        "start": 436.24,
        "duration": 4.44,
        "text": "Cassandra and then it kind of um bra"
      },
      {
        "start": 438.96,
        "duration": 3.84,
        "text": "branches off a little bit from there but"
      },
      {
        "start": 440.68,
        "duration": 5.76,
        "text": "they they both go very very in depth on"
      },
      {
        "start": 442.8,
        "duration": 5.959,
        "text": "the content um and you should be able to"
      },
      {
        "start": 446.44,
        "duration": 4.159,
        "text": "pass you if you do the exercises you do"
      },
      {
        "start": 448.759,
        "duration": 3.12,
        "text": "the learning path and you really absorb"
      },
      {
        "start": 450.599,
        "duration": 2.841,
        "text": "this stuff you should be able to pass"
      },
      {
        "start": 451.879,
        "duration": 6.681,
        "text": "the exams without too much trouble at"
      },
      {
        "start": 453.44,
        "duration": 7.36,
        "text": "all so good now uh request your Cloud"
      },
      {
        "start": 458.56,
        "duration": 6.199,
        "text": "instance if you going to do a practical"
      },
      {
        "start": 460.8,
        "duration": 8.16,
        "text": "steps with us uh but not following this"
      },
      {
        "start": 464.759,
        "duration": 8.201,
        "text": "link uh but contacting jack. fryer"
      },
      {
        "start": 468.96,
        "duration": 5.32,
        "text": "dat.com his email I've just pasted into"
      },
      {
        "start": 472.96,
        "duration": 3.079,
        "text": "the"
      },
      {
        "start": 474.28,
        "duration": 5.72,
        "text": "chat"
      },
      {
        "start": 476.039,
        "duration": 6.241,
        "text": "and that would be enough for us to start"
      },
      {
        "start": 480.0,
        "duration": 5.84,
        "text": "and we are going to cover Cassandra and"
      },
      {
        "start": 482.28,
        "duration": 7.52,
        "text": "kubernetes Basics that's what we need to"
      },
      {
        "start": 485.84,
        "duration": 6.359,
        "text": "discuss so apach candra very quickly in"
      },
      {
        "start": 489.8,
        "duration": 4.839,
        "text": "apach Cassandra in five minutes apach"
      },
      {
        "start": 492.199,
        "duration": 5.641,
        "text": "Cassandra you do that oh yeah that's"
      },
      {
        "start": 494.639,
        "duration": 7.0,
        "text": "going to be something special ladies and"
      },
      {
        "start": 497.84,
        "duration": 6.319,
        "text": "gentlemen start your engines so uh apach"
      },
      {
        "start": 501.639,
        "duration": 4.24,
        "text": "candra is a nosql decentralized"
      },
      {
        "start": 504.159,
        "duration": 5.521,
        "text": "distributed"
      },
      {
        "start": 505.879,
        "duration": 6.28,
        "text": "database uh and that's not every word in"
      },
      {
        "start": 509.68,
        "duration": 5.68,
        "text": "this phrase is very important because it"
      },
      {
        "start": 512.159,
        "duration": 5.841,
        "text": "is no squ distributed decentralized so"
      },
      {
        "start": 515.36,
        "duration": 5.4,
        "text": "we use it to store data as you do with"
      },
      {
        "start": 518.0,
        "duration": 4.919,
        "text": "post gr SQL or MySQL or in other"
      },
      {
        "start": 520.76,
        "duration": 4.199,
        "text": "databases but it works in a very"
      },
      {
        "start": 522.919,
        "duration": 4.48,
        "text": "different manner it's different to other"
      },
      {
        "start": 524.959,
        "duration": 4.961,
        "text": "databases so first of all it's"
      },
      {
        "start": 527.399,
        "duration": 5.921,
        "text": "decentralized there are no things like"
      },
      {
        "start": 529.92,
        "duration": 5.96,
        "text": "primary uh or secondary notes or like we"
      },
      {
        "start": 533.32,
        "duration": 5.079,
        "text": "us it to speak to say master or slave"
      },
      {
        "start": 535.88,
        "duration": 4.399,
        "text": "notes that's nothing things like that"
      },
      {
        "start": 538.399,
        "duration": 5.321,
        "text": "every note has the same same"
      },
      {
        "start": 540.279,
        "duration": 6.0,
        "text": "duties then it's uh distributed so we"
      },
      {
        "start": 543.72,
        "duration": 6.04,
        "text": "are going to work with multiple nodes at"
      },
      {
        "start": 546.279,
        "duration": 6.56,
        "text": "once we are not putting all our X into"
      },
      {
        "start": 549.76,
        "duration": 5.68,
        "text": "the single basket but we are spreading"
      },
      {
        "start": 552.839,
        "duration": 3.801,
        "text": "data and spreading responsibilities over"
      },
      {
        "start": 555.44,
        "duration": 4.399,
        "text": "multiple"
      },
      {
        "start": 556.64,
        "duration": 8.08,
        "text": "nodes and uh that what allows us to"
      },
      {
        "start": 559.839,
        "duration": 7.601,
        "text": "handle any kind of um problems and we"
      },
      {
        "start": 564.72,
        "duration": 5.559,
        "text": "want and we can grow over the size of a"
      },
      {
        "start": 567.44,
        "duration": 5.16,
        "text": "normal database significantly who knows"
      },
      {
        "start": 570.279,
        "duration": 3.24,
        "text": "what's the biggest Cassandra deployment"
      },
      {
        "start": 572.6,
        "duration": 4.4,
        "text": "in the"
      },
      {
        "start": 573.519,
        "duration": 5.44,
        "text": "world um I will not stop for too long of"
      },
      {
        "start": 577.0,
        "duration": 5.2,
        "text": "that but we know what biggest Cassandra"
      },
      {
        "start": 578.959,
        "duration": 7.361,
        "text": "users not only users but also committers"
      },
      {
        "start": 582.2,
        "duration": 8.36,
        "text": "on Netflix and Instagram and out oh no"
      },
      {
        "start": 586.32,
        "duration": 7.4,
        "text": "Oliver 10,000 much higher uh the biggest"
      },
      {
        "start": 590.56,
        "duration": 7.24,
        "text": "known personally discussed uh by me"
      },
      {
        "start": 593.72,
        "duration": 6.559,
        "text": "deployment uh was um done by Apple it"
      },
      {
        "start": 597.8,
        "duration": 7.52,
        "text": "was5"
      },
      {
        "start": 600.279,
        "duration": 8.921,
        "text": "6 160,000 notes once again I like how it"
      },
      {
        "start": 605.32,
        "duration": 6.079,
        "text": "sounds 160,000 notes apple and now we"
      },
      {
        "start": 609.2,
        "duration": 5.0,
        "text": "have heard what uh some Chinese"
      },
      {
        "start": 611.399,
        "duration": 6.361,
        "text": "companies like Huawei have even"
      },
      {
        "start": 614.2,
        "duration": 7.8,
        "text": "more yeah Netflix Apple Instagram and"
      },
      {
        "start": 617.76,
        "duration": 6.16,
        "text": "some others Spotify is another big one"
      },
      {
        "start": 622.0,
        "duration": 5.0,
        "text": "all of their infrastructure their their"
      },
      {
        "start": 623.92,
        "duration": 5.44,
        "text": "data layer is scand from what I know yep"
      },
      {
        "start": 627.0,
        "duration": 6.6,
        "text": "exactly and that's non-relational"
      },
      {
        "start": 629.36,
        "duration": 7.56,
        "text": "database so no SQL database nodes are"
      },
      {
        "start": 633.6,
        "duration": 6.479,
        "text": "organized in the data centers or rings"
      },
      {
        "start": 636.92,
        "duration": 6.64,
        "text": "but uh every node communicate with every"
      },
      {
        "start": 640.079,
        "duration": 6.2,
        "text": "node so there is no things like primary"
      },
      {
        "start": 643.56,
        "duration": 5.76,
        "text": "node giving orders to secondary noes it"
      },
      {
        "start": 646.279,
        "duration": 5.521,
        "text": "doesn't work like that what are the main"
      },
      {
        "start": 649.32,
        "duration": 6.56,
        "text": "features of Cassandra we want to"
      },
      {
        "start": 651.8,
        "duration": 6.159,
        "text": "cover Cassandra is distributed so we"
      },
      {
        "start": 655.88,
        "duration": 4.8,
        "text": "have a lot of nodes working together in"
      },
      {
        "start": 657.959,
        "duration": 5.761,
        "text": "a cluster it makes it responsive and"
      },
      {
        "start": 660.68,
        "duration": 6.2,
        "text": "scalable we can always add more notes to"
      },
      {
        "start": 663.72,
        "duration": 5.919,
        "text": "have higher FR output or volume or"
      },
      {
        "start": 666.88,
        "duration": 5.44,
        "text": "whatever we want to have and it's"
      },
      {
        "start": 669.639,
        "duration": 4.801,
        "text": "replicated it means what your record"
      },
      {
        "start": 672.32,
        "duration": 4.84,
        "text": "your data is replicated to multiple"
      },
      {
        "start": 674.44,
        "duration": 5.839,
        "text": "notes and even if one of those not uh"
      },
      {
        "start": 677.16,
        "duration": 5.919,
        "text": "notes uh is not available your data will"
      },
      {
        "start": 680.279,
        "duration": 5.401,
        "text": "be returned by other noes so you can do"
      },
      {
        "start": 683.079,
        "duration": 4.801,
        "text": "right and read operations even if the"
      },
      {
        "start": 685.68,
        "duration": 5.719,
        "text": "some notes are in on"
      },
      {
        "start": 687.88,
        "duration": 5.959,
        "text": "fire and as say there is no single point"
      },
      {
        "start": 691.399,
        "duration": 4.801,
        "text": "of failure because we have a true"
      },
      {
        "start": 693.839,
        "duration": 5.56,
        "text": "democracy here there are no primaries"
      },
      {
        "start": 696.2,
        "duration": 7.6,
        "text": "and secondaries there are every note is"
      },
      {
        "start": 699.399,
        "duration": 6.521,
        "text": "the uh full uh full size citizen of the"
      },
      {
        "start": 703.8,
        "duration": 4.479,
        "text": "world cluster and they have the same"
      },
      {
        "start": 705.92,
        "duration": 5.24,
        "text": "duties they are absolutely"
      },
      {
        "start": 708.279,
        "duration": 5.921,
        "text": "equal Cassandra is distributed and"
      },
      {
        "start": 711.16,
        "duration": 6.239,
        "text": "highly available notes organiz it into"
      },
      {
        "start": 714.2,
        "duration": 5.28,
        "text": "the groups data centers notes monitor"
      },
      {
        "start": 717.399,
        "duration": 4.521,
        "text": "each other's health status using a"
      },
      {
        "start": 719.48,
        "duration": 5.159,
        "text": "gossip protocol Cassandra wrotes"
      },
      {
        "start": 721.92,
        "duration": 5.479,
        "text": "requests away from notes what are down"
      },
      {
        "start": 724.639,
        "duration": 6.121,
        "text": "or slow automatically and that's not for"
      },
      {
        "start": 727.399,
        "duration": 5.56,
        "text": "your operations guys uh or girls to take"
      },
      {
        "start": 730.76,
        "duration": 4.4,
        "text": "care of that's not the question that's"
      },
      {
        "start": 732.959,
        "duration": 5.641,
        "text": "what Cassandra takes care"
      },
      {
        "start": 735.16,
        "duration": 5.679,
        "text": "of Cassandra scales very good and we"
      },
      {
        "start": 738.6,
        "duration": 5.32,
        "text": "speak not about vertical scaling"
      },
      {
        "start": 740.839,
        "duration": 5.281,
        "text": "traditional for the databases when you"
      },
      {
        "start": 743.92,
        "duration": 4.88,
        "text": "when you are out of power you want to"
      },
      {
        "start": 746.12,
        "duration": 6.2,
        "text": "have something more you buy a new bigger"
      },
      {
        "start": 748.8,
        "duration": 5.92,
        "text": "service migrate your data and uh remove"
      },
      {
        "start": 752.32,
        "duration": 5.92,
        "text": "the old one that's vertical scaling"
      },
      {
        "start": 754.72,
        "duration": 5.72,
        "text": "buying more and more powerful Hardware"
      },
      {
        "start": 758.24,
        "duration": 5.08,
        "text": "we prefer another"
      },
      {
        "start": 760.44,
        "duration": 6.48,
        "text": "way uh we prefer to go with horizontal"
      },
      {
        "start": 763.32,
        "duration": 5.56,
        "text": "scaling and that's a very different way"
      },
      {
        "start": 766.92,
        "duration": 5.24,
        "text": "problem of a vertical scaling first it"
      },
      {
        "start": 768.88,
        "duration": 5.199,
        "text": "gets expensive very soon but also second"
      },
      {
        "start": 772.16,
        "duration": 4.919,
        "text": "as soon as you"
      },
      {
        "start": 774.079,
        "duration": 5.721,
        "text": "um you still have the same issue that's"
      },
      {
        "start": 777.079,
        "duration": 6.721,
        "text": "one single instance which has one single"
      },
      {
        "start": 779.8,
        "duration": 7.279,
        "text": "power of uh source of electricity for"
      },
      {
        "start": 783.8,
        "duration": 8.399,
        "text": "example with all the problems related to"
      },
      {
        "start": 787.079,
        "duration": 7.161,
        "text": "that and um problem for us uh here uh"
      },
      {
        "start": 792.199,
        "duration": 5.721,
        "text": "with horizontal scaling we can do it in"
      },
      {
        "start": 794.24,
        "duration": 7.76,
        "text": "a different way uh we prefer to add more"
      },
      {
        "start": 797.92,
        "duration": 7.159,
        "text": "nodes and one of the best features of"
      },
      {
        "start": 802.0,
        "duration": 6.639,
        "text": "Cassandra uh it scales not only uh"
      },
      {
        "start": 805.079,
        "duration": 5.841,
        "text": "horizontally but also linearly it means"
      },
      {
        "start": 808.639,
        "duration": 5.64,
        "text": "what we have have very low to zero"
      },
      {
        "start": 810.92,
        "duration": 6.44,
        "text": "overhead on adding new nodes and every"
      },
      {
        "start": 814.279,
        "duration": 6.12,
        "text": "time you add next next note your claster"
      },
      {
        "start": 817.36,
        "duration": 5.0,
        "text": "is getting more and more powerful on"
      },
      {
        "start": 820.399,
        "duration": 5.56,
        "text": "from the volume point of view or from"
      },
      {
        "start": 822.36,
        "duration": 6.8,
        "text": "the FR output point of view you are slow"
      },
      {
        "start": 825.959,
        "duration": 6.201,
        "text": "check your data model and add more nodes"
      },
      {
        "start": 829.16,
        "duration": 5.359,
        "text": "you need more capacity add more nodes"
      },
      {
        "start": 832.16,
        "duration": 4.72,
        "text": "and that's how it works this picture on"
      },
      {
        "start": 834.519,
        "duration": 4.161,
        "text": "the right side we don't want to show"
      },
      {
        "start": 836.88,
        "duration": 4.48,
        "text": "what cassandre is faster than our"
      },
      {
        "start": 838.68,
        "duration": 6.32,
        "text": "database Bas well it is but that's not"
      },
      {
        "start": 841.36,
        "duration": 7.24,
        "text": "your point for now yeah you know what uh"
      },
      {
        "start": 845.0,
        "duration": 7.079,
        "text": "on the uh different testing uh"
      },
      {
        "start": 848.6,
        "duration": 6.12,
        "text": "infrastructures and with access to the"
      },
      {
        "start": 852.079,
        "duration": 5.041,
        "text": "settings and configuration I can set up"
      },
      {
        "start": 854.72,
        "duration": 6.52,
        "text": "every database to be quick or"
      },
      {
        "start": 857.12,
        "duration": 7.279,
        "text": "slow um what I want to set here I want"
      },
      {
        "start": 861.24,
        "duration": 6.719,
        "text": "to highlight what every next note add"
      },
      {
        "start": 864.399,
        "duration": 6.641,
        "text": "that uh it scales linearly so we have no"
      },
      {
        "start": 867.959,
        "duration": 5.721,
        "text": "overhead and we have more and more power"
      },
      {
        "start": 871.04,
        "duration": 5.68,
        "text": "growing over time uh if you know maybe"
      },
      {
        "start": 873.68,
        "duration": 7.079,
        "text": "Netflix kind of tiny company streaming"
      },
      {
        "start": 876.72,
        "duration": 6.359,
        "text": "some not so popular TV series maybe uh"
      },
      {
        "start": 880.759,
        "duration": 6.0,
        "text": "they did a great research it's published"
      },
      {
        "start": 883.079,
        "duration": 6.041,
        "text": "it in their Tech blog uh they scaled"
      },
      {
        "start": 886.759,
        "duration": 7.32,
        "text": "Cassandra cluster from 30 notes I"
      },
      {
        "start": 889.12,
        "duration": 8.04,
        "text": "believe to 300 something like 350 maybe"
      },
      {
        "start": 894.079,
        "duration": 6.601,
        "text": "uh and what way the testing how fra put"
      },
      {
        "start": 897.16,
        "duration": 5.44,
        "text": "and volume grows and it grows linearly"
      },
      {
        "start": 900.68,
        "duration": 3.88,
        "text": "uh so that's not only my words that's"
      },
      {
        "start": 902.6,
        "duration": 4.88,
        "text": "Netflix"
      },
      {
        "start": 904.56,
        "duration": 5.959,
        "text": "words um what are the main principles"
      },
      {
        "start": 907.48,
        "duration": 5.479,
        "text": "for Cassandra first of all everything is"
      },
      {
        "start": 910.519,
        "duration": 5.481,
        "text": "distributed data is distributed over"
      },
      {
        "start": 912.959,
        "duration": 6.961,
        "text": "clusters those orange circles on the"
      },
      {
        "start": 916.0,
        "duration": 7.639,
        "text": "left side are servers and the table on"
      },
      {
        "start": 919.92,
        "duration": 6.32,
        "text": "the right side is the table now when we"
      },
      {
        "start": 923.639,
        "duration": 4.841,
        "text": "have those seven notes and this table on"
      },
      {
        "start": 926.24,
        "duration": 5.0,
        "text": "the right how do you think data will be"
      },
      {
        "start": 928.48,
        "duration": 6.08,
        "text": "spread at over so which Note stores"
      },
      {
        "start": 931.24,
        "duration": 5.839,
        "text": "which part of data we can say it's going"
      },
      {
        "start": 934.56,
        "duration": 6.719,
        "text": "to be stored like"
      },
      {
        "start": 937.079,
        "duration": 6.88,
        "text": "that um so every every note is"
      },
      {
        "start": 941.279,
        "duration": 5.401,
        "text": "responsible for the part of a table at"
      },
      {
        "start": 943.959,
        "duration": 5.041,
        "text": "this point you may ask why I'm working"
      },
      {
        "start": 946.68,
        "duration": 5.279,
        "text": "with my POS gra or whatever relational"
      },
      {
        "start": 949.0,
        "duration": 5.839,
        "text": "database you are using and it doesn't"
      },
      {
        "start": 951.959,
        "duration": 7.161,
        "text": "think like that will it be convenient to"
      },
      {
        "start": 954.839,
        "duration": 7.641,
        "text": "use answer is very simple take a look"
      },
      {
        "start": 959.12,
        "duration": 6.32,
        "text": "Sandra is Big Data R your relational"
      },
      {
        "start": 962.48,
        "duration": 5.039,
        "text": "database may work great till some limit"
      },
      {
        "start": 965.44,
        "duration": 4.519,
        "text": "and after this limit it doesn't work"
      },
      {
        "start": 967.519,
        "duration": 6.68,
        "text": "great and after some more it doesn't"
      },
      {
        "start": 969.959,
        "duration": 9.281,
        "text": "work at all why because it was uh not"
      },
      {
        "start": 974.199,
        "duration": 8.521,
        "text": "designed uh to be uh Big Data ready from"
      },
      {
        "start": 979.24,
        "duration": 5.8,
        "text": "the as a design concept as a result it"
      },
      {
        "start": 982.72,
        "duration": 5.039,
        "text": "works good as long as it's in the"
      },
      {
        "start": 985.04,
        "duration": 5.64,
        "text": "conditions it was designed for so some"
      },
      {
        "start": 987.759,
        "duration": 5.601,
        "text": "limited amounts of data"
      },
      {
        "start": 990.68,
        "duration": 5.48,
        "text": "Maybe gigabytes of data maybe some"
      },
      {
        "start": 993.36,
        "duration": 5.159,
        "text": "terabytes but not more and when we start"
      },
      {
        "start": 996.16,
        "duration": 5.72,
        "text": "to speak about dozens terabytes or"
      },
      {
        "start": 998.519,
        "duration": 5.401,
        "text": "dozens petabytes like Apple Works then"
      },
      {
        "start": 1001.88,
        "duration": 4.8,
        "text": "you need something like Cassandra"
      },
      {
        "start": 1003.92,
        "duration": 4.359,
        "text": "Cassandra separates data um to a"
      },
      {
        "start": 1006.68,
        "duration": 5.2,
        "text": "multiple partitions it's called it"
      },
      {
        "start": 1008.279,
        "duration": 7.68,
        "text": "partitioning based on the partition key"
      },
      {
        "start": 1011.88,
        "duration": 6.68,
        "text": "you design uh and then if we need more"
      },
      {
        "start": 1015.959,
        "duration": 4.721,
        "text": "volume we simply add more nodes and the"
      },
      {
        "start": 1018.56,
        "duration": 6.08,
        "text": "part ition will be moved over the"
      },
      {
        "start": 1020.68,
        "duration": 6.2,
        "text": "cluster again very simple then uh what"
      },
      {
        "start": 1024.64,
        "duration": 5.76,
        "text": "is a partition key partition key is the"
      },
      {
        "start": 1026.88,
        "duration": 5.84,
        "text": "column in your table you are using uh to"
      },
      {
        "start": 1030.4,
        "duration": 5.799,
        "text": "identify the partitions like take a look"
      },
      {
        "start": 1032.72,
        "duration": 6.88,
        "text": "here we have Toronto Paris Berlin Mumbai"
      },
      {
        "start": 1036.199,
        "duration": 6.201,
        "text": "Berlin Moscow and so on how way will be"
      },
      {
        "start": 1039.6,
        "duration": 6.64,
        "text": "stored based on your partition key in"
      },
      {
        "start": 1042.4,
        "duration": 6.88,
        "text": "this case we use the uh partition key we"
      },
      {
        "start": 1046.24,
        "duration": 4.76,
        "text": "use CT as the partition key so data is"
      },
      {
        "start": 1049.28,
        "duration": 5.36,
        "text": "grouped"
      },
      {
        "start": 1051.0,
        "duration": 6.36,
        "text": "together and uh that's how it"
      },
      {
        "start": 1054.64,
        "duration": 5.52,
        "text": "works that's not only data is"
      },
      {
        "start": 1057.36,
        "duration": 5.52,
        "text": "distributed but data is replicated"
      },
      {
        "start": 1060.16,
        "duration": 4.44,
        "text": "compare those two"
      },
      {
        "start": 1062.88,
        "duration": 6.32,
        "text": "slides this"
      },
      {
        "start": 1064.6,
        "duration": 6.88,
        "text": "one and that one in short answer every"
      },
      {
        "start": 1069.2,
        "duration": 4.839,
        "text": "replica every partition is"
      },
      {
        "start": 1071.48,
        "duration": 4.84,
        "text": "duplicated for a very simple High"
      },
      {
        "start": 1074.039,
        "duration": 4.201,
        "text": "availability reason when you have you"
      },
      {
        "start": 1076.32,
        "duration": 4.4,
        "text": "can configure your Cassandra to work"
      },
      {
        "start": 1078.24,
        "duration": 4.52,
        "text": "like that with replication Factor one"
      },
      {
        "start": 1080.72,
        "duration": 4.64,
        "text": "it's good for your laptop it's good for"
      },
      {
        "start": 1082.76,
        "duration": 4.48,
        "text": "your maybe uh test environment but it's"
      },
      {
        "start": 1085.36,
        "duration": 4.72,
        "text": "bad for your staging and that's bad for"
      },
      {
        "start": 1087.24,
        "duration": 6.2,
        "text": "your production when you raise the"
      },
      {
        "start": 1090.08,
        "duration": 6.0,
        "text": "replication factor to two it looks like"
      },
      {
        "start": 1093.44,
        "duration": 6.0,
        "text": "that but what we recommend to have is"
      },
      {
        "start": 1096.08,
        "duration": 5.28,
        "text": "replication Factor free uh replication"
      },
      {
        "start": 1099.44,
        "duration": 5.239,
        "text": "Factor free is important so you can"
      },
      {
        "start": 1101.36,
        "duration": 5.559,
        "text": "afford losing a note while still being"
      },
      {
        "start": 1104.679,
        "duration": 4.24,
        "text": "consistent people call Cassandra"
      },
      {
        "start": 1106.919,
        "duration": 4.76,
        "text": "eventually consistent but that's not"
      },
      {
        "start": 1108.919,
        "duration": 5.88,
        "text": "perfectly correct because Cassandra is"
      },
      {
        "start": 1111.679,
        "duration": 6.721,
        "text": "configura consistent and you can move"
      },
      {
        "start": 1114.799,
        "duration": 6.601,
        "text": "this uh switch to any site you prefer to"
      },
      {
        "start": 1118.4,
        "duration": 5.639,
        "text": "have right now so every data is"
      },
      {
        "start": 1121.4,
        "duration": 4.6,
        "text": "replicated to be on multiple times"
      },
      {
        "start": 1124.039,
        "duration": 5.081,
        "text": "available and"
      },
      {
        "start": 1126.0,
        "duration": 6.44,
        "text": "finally uh replicated distributed what's"
      },
      {
        "start": 1129.12,
        "duration": 5.439,
        "text": "next uh distributed globally it means"
      },
      {
        "start": 1132.44,
        "duration": 5.8,
        "text": "what with Cassandra you can easily have"
      },
      {
        "start": 1134.559,
        "duration": 6.801,
        "text": "data centers all over the world working"
      },
      {
        "start": 1138.24,
        "duration": 6.48,
        "text": "as a single cluster so your data is on"
      },
      {
        "start": 1141.36,
        "duration": 6.6,
        "text": "the United States East and then uh"
      },
      {
        "start": 1144.72,
        "duration": 5.839,
        "text": "Europe Central one and then Asia central"
      },
      {
        "start": 1147.96,
        "duration": 5.599,
        "text": "2 and they are all working together"
      },
      {
        "start": 1150.559,
        "duration": 4.961,
        "text": "handling the same data why because you"
      },
      {
        "start": 1153.559,
        "duration": 4.201,
        "text": "want your data to be close to your"
      },
      {
        "start": 1155.52,
        "duration": 4.6,
        "text": "clients if you have clients everywhere"
      },
      {
        "start": 1157.76,
        "duration": 4.84,
        "text": "you want your data to be also everywhere"
      },
      {
        "start": 1160.12,
        "duration": 4.52,
        "text": "it's easy to run application into any"
      },
      {
        "start": 1162.6,
        "duration": 4.76,
        "text": "part of a world as long as you have data"
      },
      {
        "start": 1164.64,
        "duration": 5.56,
        "text": "center there but uh with data it's"
      },
      {
        "start": 1167.36,
        "duration": 6.12,
        "text": "usually not so easy with Cassandra it's"
      },
      {
        "start": 1170.2,
        "duration": 6.719,
        "text": "easy and finally Cassandra is absolutely"
      },
      {
        "start": 1173.48,
        "duration": 5.76,
        "text": "platform agnostic so you can run exactly"
      },
      {
        "start": 1176.919,
        "duration": 5.0,
        "text": "the same cluster different parts of a"
      },
      {
        "start": 1179.24,
        "duration": 5.0,
        "text": "cluster different data centers or rings"
      },
      {
        "start": 1181.919,
        "duration": 6.12,
        "text": "in the Google Compu platform Microsoft"
      },
      {
        "start": 1184.24,
        "duration": 8.76,
        "text": "Azure AWS on your own data center on"
      },
      {
        "start": 1188.039,
        "duration": 7.52,
        "text": "premises on absolutely the same uh time"
      },
      {
        "start": 1193.0,
        "duration": 4.52,
        "text": "and it will be still the same cluster"
      },
      {
        "start": 1195.559,
        "duration": 3.761,
        "text": "Cassandra's platform agnostic you can"
      },
      {
        "start": 1197.52,
        "duration": 4.279,
        "text": "run it everywhere"
      },
      {
        "start": 1199.32,
        "duration": 5.12,
        "text": "and they still will be fully operational"
      },
      {
        "start": 1201.799,
        "duration": 2.641,
        "text": "working"
      },
      {
        "start": 1204.679,
        "duration": 7.041,
        "text": "together and last point of that so the"
      },
      {
        "start": 1208.039,
        "duration": 7.161,
        "text": "use cases scalability everything what"
      },
      {
        "start": 1211.72,
        "duration": 5.88,
        "text": "relates to high for output high volume a"
      },
      {
        "start": 1215.2,
        "duration": 5.0,
        "text": "lot of writes a lot of reads that's very"
      },
      {
        "start": 1217.6,
        "duration": 5.8,
        "text": "sounds like aandra use case especially"
      },
      {
        "start": 1220.2,
        "duration": 6.8,
        "text": "then its changes today you have uh one"
      },
      {
        "start": 1223.4,
        "duration": 5.8,
        "text": "number of requests and tomorrow going to"
      },
      {
        "start": 1227.0,
        "duration": 4.84,
        "text": "be Black Friday and you are going to"
      },
      {
        "start": 1229.2,
        "duration": 6.44,
        "text": "have two times more no need to buy more"
      },
      {
        "start": 1231.84,
        "duration": 5.88,
        "text": "powerful server just add one more note"
      },
      {
        "start": 1235.64,
        "duration": 4.919,
        "text": "wait till Black Friday is over"
      },
      {
        "start": 1237.72,
        "duration": 5.079,
        "text": "decommission this note and you are great"
      },
      {
        "start": 1240.559,
        "duration": 5.24,
        "text": "you are highly available all the time"
      },
      {
        "start": 1242.799,
        "duration": 5.921,
        "text": "and your expenses are very well"
      },
      {
        "start": 1245.799,
        "duration": 4.841,
        "text": "optimized okay then availability"
      },
      {
        "start": 1248.72,
        "duration": 5.48,
        "text": "everything what relates to Mission"
      },
      {
        "start": 1250.64,
        "duration": 6.56,
        "text": "critical systems never data loss always"
      },
      {
        "start": 1254.2,
        "duration": 5.959,
        "text": "available that's absolutely about aacha"
      },
      {
        "start": 1257.2,
        "duration": 5.479,
        "text": "Cassandra when this distributed whatever"
      },
      {
        "start": 1260.159,
        "duration": 4.921,
        "text": "we mean about the global presence that's"
      },
      {
        "start": 1262.679,
        "duration": 4.281,
        "text": "a perfect use case for the Cassandra"
      },
      {
        "start": 1265.08,
        "duration": 4.68,
        "text": "whatever we speak about the compliance"
      },
      {
        "start": 1266.96,
        "duration": 5.4,
        "text": "or gdbr if you want to have some of your"
      },
      {
        "start": 1269.76,
        "duration": 4.68,
        "text": "data available only in Europe and some"
      },
      {
        "start": 1272.36,
        "duration": 4.88,
        "text": "other parts of your data in both Europe"
      },
      {
        "start": 1274.44,
        "duration": 5.88,
        "text": "and the United States you can easily do"
      },
      {
        "start": 1277.24,
        "duration": 5.84,
        "text": "that uh specifying different replication"
      },
      {
        "start": 1280.32,
        "duration": 5.12,
        "text": "factors for different data centers like"
      },
      {
        "start": 1283.08,
        "duration": 5.079,
        "text": "I'm located in Germany and there are"
      },
      {
        "start": 1285.44,
        "duration": 4.96,
        "text": "some gdpr rules and you can for example"
      },
      {
        "start": 1288.159,
        "duration": 4.76,
        "text": "store course in some cases data of"
      },
      {
        "start": 1290.4,
        "duration": 4.96,
        "text": "German clients only in Germany no"
      },
      {
        "start": 1292.919,
        "duration": 5.081,
        "text": "problems you specify replication Factor"
      },
      {
        "start": 1295.36,
        "duration": 5.16,
        "text": "allow it for the data center in Germany"
      },
      {
        "start": 1298.0,
        "duration": 4.76,
        "text": "and remove that for this kind of data"
      },
      {
        "start": 1300.52,
        "duration": 4.639,
        "text": "for all the other data centers boom you"
      },
      {
        "start": 1302.76,
        "duration": 5.88,
        "text": "have your data only in"
      },
      {
        "start": 1305.159,
        "duration": 5.4,
        "text": "Germany and then all what goes to Cloud"
      },
      {
        "start": 1308.64,
        "duration": 5.24,
        "text": "native modern"
      },
      {
        "start": 1310.559,
        "duration": 6.12,
        "text": "applications um microservices very good"
      },
      {
        "start": 1313.88,
        "duration": 6.279,
        "text": "feed Cloud native and Cloud deployed"
      },
      {
        "start": 1316.679,
        "duration": 6.201,
        "text": "very good feed kubernetes perfect Feit"
      },
      {
        "start": 1320.159,
        "duration": 5.201,
        "text": "that's what this Workshop"
      },
      {
        "start": 1322.88,
        "duration": 3.919,
        "text": "about all right Alex you said you'd get"
      },
      {
        "start": 1325.36,
        "duration": 2.679,
        "text": "it done in five minutes you want to know"
      },
      {
        "start": 1326.799,
        "duration": 4.281,
        "text": "what your time"
      },
      {
        "start": 1328.039,
        "duration": 8.921,
        "text": "was yes so what that let's see if we can"
      },
      {
        "start": 1331.08,
        "duration": 9.199,
        "text": "see it on screen here 13 minutes and 41"
      },
      {
        "start": 1336.96,
        "duration": 6.959,
        "text": "seconds oh my God you know what uh I"
      },
      {
        "start": 1340.279,
        "duration": 6.0,
        "text": "would better speak about that for days"
      },
      {
        "start": 1343.919,
        "duration": 4.921,
        "text": "so it's always very hard to feed into"
      },
      {
        "start": 1346.279,
        "duration": 5.4,
        "text": "the smaller size I will try TR to"
      },
      {
        "start": 1348.84,
        "duration": 2.839,
        "text": "improve thank you"
      },
      {
        "start": 1352.559,
        "duration": 6.36,
        "text": "Eric good"
      },
      {
        "start": 1355.039,
        "duration": 6.12,
        "text": "so uh"
      },
      {
        "start": 1358.919,
        "duration": 4.88,
        "text": "kubernetes we have some people with"
      },
      {
        "start": 1361.159,
        "duration": 4.721,
        "text": "pretty low experience on this field uh"
      },
      {
        "start": 1363.799,
        "duration": 4.36,
        "text": "but we will not do a deep dive in"
      },
      {
        "start": 1365.88,
        "duration": 4.799,
        "text": "general the main idea what you have to"
      },
      {
        "start": 1368.159,
        "duration": 6.52,
        "text": "understand kubernetes is an open- Source"
      },
      {
        "start": 1370.679,
        "duration": 6.561,
        "text": "system for management ofer containerized"
      },
      {
        "start": 1374.679,
        "duration": 4.36,
        "text": "applications and that's what it does it"
      },
      {
        "start": 1377.24,
        "duration": 6.72,
        "text": "helps you to deploy"
      },
      {
        "start": 1379.039,
        "duration": 7.801,
        "text": "upgrade remove scale uh containerized"
      },
      {
        "start": 1383.96,
        "duration": 5.599,
        "text": "applications so what does that mean"
      },
      {
        "start": 1386.84,
        "duration": 6.68,
        "text": "before we that's a kind of famous"
      },
      {
        "start": 1389.559,
        "duration": 6.0,
        "text": "picture I see literally on every um"
      },
      {
        "start": 1393.52,
        "duration": 4.8,
        "text": "conference uh"
      },
      {
        "start": 1395.559,
        "duration": 4.081,
        "text": "regularly uh virtual machines old"
      },
      {
        "start": 1398.32,
        "duration": 3.479,
        "text": "approach to"
      },
      {
        "start": 1399.64,
        "duration": 5.36,
        "text": "virtualization well not old but"
      },
      {
        "start": 1401.799,
        "duration": 5.721,
        "text": "different I would say older approach uh"
      },
      {
        "start": 1405.0,
        "duration": 5.6,
        "text": "which helps you to have higher isolation"
      },
      {
        "start": 1407.52,
        "duration": 6.48,
        "text": "using guest operating systems running on"
      },
      {
        "start": 1410.6,
        "duration": 5.4,
        "text": "the hypervisor or host operating system"
      },
      {
        "start": 1414.0,
        "duration": 4.44,
        "text": "it works very well it provides a very"
      },
      {
        "start": 1416.0,
        "duration": 4.52,
        "text": "high level of isolation but also brings"
      },
      {
        "start": 1418.44,
        "duration": 5.4,
        "text": "a problem a lot of your resources"
      },
      {
        "start": 1420.52,
        "duration": 6.32,
        "text": "consumed by Gest operation operating"
      },
      {
        "start": 1423.84,
        "duration": 4.68,
        "text": "system that's sometimes may be good if"
      },
      {
        "start": 1426.84,
        "duration": 3.88,
        "text": "that's your intention but you know"
      },
      {
        "start": 1428.52,
        "duration": 5.44,
        "text": "what's the funniest point about the"
      },
      {
        "start": 1430.72,
        "duration": 5.4,
        "text": "operating systems really no one needs"
      },
      {
        "start": 1433.96,
        "duration": 4.04,
        "text": "operating system you have operating"
      },
      {
        "start": 1436.12,
        "duration": 5.4,
        "text": "system on your laptop you don't need"
      },
      {
        "start": 1438.0,
        "duration": 5.88,
        "text": "that you need you want to watch uh uh"
      },
      {
        "start": 1441.52,
        "duration": 4.32,
        "text": "kitten photos on the internet and funny"
      },
      {
        "start": 1443.88,
        "duration": 5.08,
        "text": "videos and learn things at the data"
      },
      {
        "start": 1445.84,
        "duration": 5.719,
        "text": "Stacks developer workshops uh so"
      },
      {
        "start": 1448.96,
        "duration": 4.68,
        "text": "basically you use browser most of the"
      },
      {
        "start": 1451.559,
        "duration": 5.0,
        "text": "time and maybe your integrated"
      },
      {
        "start": 1453.64,
        "duration": 5.2,
        "text": "development environment but uh what's"
      },
      {
        "start": 1456.559,
        "duration": 4.961,
        "text": "the operating system then it's just the"
      },
      {
        "start": 1458.84,
        "duration": 5.439,
        "text": "glue what brings this software together"
      },
      {
        "start": 1461.52,
        "duration": 5.68,
        "text": "with your Hardware allowing them to work"
      },
      {
        "start": 1464.279,
        "duration": 5.681,
        "text": "together but per se operating system is"
      },
      {
        "start": 1467.2,
        "duration": 6.28,
        "text": "not the thing you need you need to do"
      },
      {
        "start": 1469.96,
        "duration": 6.04,
        "text": "something uh different and containers is"
      },
      {
        "start": 1473.48,
        "duration": 7.0,
        "text": "a new approach to virtualization which"
      },
      {
        "start": 1476.0,
        "duration": 7.679,
        "text": "allow you to do this thing easier in the"
      },
      {
        "start": 1480.48,
        "duration": 5.559,
        "text": "containers uh processes or applications"
      },
      {
        "start": 1483.679,
        "duration": 4.72,
        "text": "you are running are being executed"
      },
      {
        "start": 1486.039,
        "duration": 5.681,
        "text": "directly on the host operating system"
      },
      {
        "start": 1488.399,
        "duration": 6.961,
        "text": "without guests operating systems so what"
      },
      {
        "start": 1491.72,
        "duration": 6.679,
        "text": "makes things um little bit less isolated"
      },
      {
        "start": 1495.36,
        "duration": 5.72,
        "text": "maybe in some cases but much more like"
      },
      {
        "start": 1498.399,
        "duration": 4.88,
        "text": "lightweight so containers usually much"
      },
      {
        "start": 1501.08,
        "duration": 6.959,
        "text": "more lightweight than virtual machine"
      },
      {
        "start": 1503.279,
        "duration": 8.201,
        "text": "images and um that makes them much more"
      },
      {
        "start": 1508.039,
        "duration": 5.64,
        "text": "convenient to use but the containers uh"
      },
      {
        "start": 1511.48,
        "duration": 5.319,
        "text": "just as they are like Docker containers"
      },
      {
        "start": 1513.679,
        "duration": 5.761,
        "text": "for example they are great but you still"
      },
      {
        "start": 1516.799,
        "duration": 5.0,
        "text": "have to work with every particular image"
      },
      {
        "start": 1519.44,
        "duration": 5.4,
        "text": "and every particular container and you"
      },
      {
        "start": 1521.799,
        "duration": 6.721,
        "text": "have to say Docker run Docker"
      },
      {
        "start": 1524.84,
        "duration": 7.839,
        "text": "stop uh and many other operations and"
      },
      {
        "start": 1528.52,
        "duration": 6.399,
        "text": "then you are trying to do um some signif"
      },
      {
        "start": 1532.679,
        "duration": 4.801,
        "text": "some more or less complex application"
      },
      {
        "start": 1534.919,
        "duration": 5.64,
        "text": "even for simple applications I believe"
      },
      {
        "start": 1537.48,
        "duration": 5.48,
        "text": "some of you were at my four weeks Docker"
      },
      {
        "start": 1540.559,
        "duration": 4.72,
        "text": "learning puff I hope if you did please"
      },
      {
        "start": 1542.96,
        "duration": 4.52,
        "text": "write about that in chat so I know there"
      },
      {
        "start": 1545.279,
        "duration": 4.961,
        "text": "are some people uh from my Docker"
      },
      {
        "start": 1547.48,
        "duration": 5.96,
        "text": "learning path uh you remember the week"
      },
      {
        "start": 1550.24,
        "duration": 5.88,
        "text": "two when we tried to run pretty simple"
      },
      {
        "start": 1553.44,
        "duration": 5.719,
        "text": "application without any orchestration"
      },
      {
        "start": 1556.12,
        "duration": 5.439,
        "text": "without Docker compost without do swarm"
      },
      {
        "start": 1559.159,
        "duration": 5.721,
        "text": "without kubernetes it was pretty a lot"
      },
      {
        "start": 1561.559,
        "duration": 6.201,
        "text": "of things to do just with doer so we"
      },
      {
        "start": 1564.88,
        "duration": 5.36,
        "text": "consider kubernetes as an advanced doer"
      },
      {
        "start": 1567.76,
        "duration": 5.039,
        "text": "compost I hope no one will kill me for"
      },
      {
        "start": 1570.24,
        "duration": 4.88,
        "text": "this comparison because G to say I can"
      },
      {
        "start": 1572.799,
        "duration": 5.36,
        "text": "see the pitchforks coming out already"
      },
      {
        "start": 1575.12,
        "duration": 5.24,
        "text": "yeah yeah yeah so you see uh the general"
      },
      {
        "start": 1578.159,
        "duration": 4.601,
        "text": "idea is the same to orchestrate but of"
      },
      {
        "start": 1580.36,
        "duration": 4.439,
        "text": "course kubernetes works on much bigger"
      },
      {
        "start": 1582.76,
        "duration": 4.6,
        "text": "scale when you need something on your"
      },
      {
        "start": 1584.799,
        "duration": 4.961,
        "text": "own laptop you go for Docker compost"
      },
      {
        "start": 1587.36,
        "duration": 4.84,
        "text": "because it's easier than kubernetes but"
      },
      {
        "start": 1589.76,
        "duration": 4.919,
        "text": "when you are going to run over a big"
      },
      {
        "start": 1592.2,
        "duration": 4.44,
        "text": "data center or maybe many of them and"
      },
      {
        "start": 1594.679,
        "duration": 4.72,
        "text": "complex applications and hundreds of"
      },
      {
        "start": 1596.64,
        "duration": 5.32,
        "text": "services you definitely need kubernetes"
      },
      {
        "start": 1599.399,
        "duration": 5.16,
        "text": "so what kubernetes does it helps you to"
      },
      {
        "start": 1601.96,
        "duration": 5.76,
        "text": "orchestrate for storage it helps you to"
      },
      {
        "start": 1604.559,
        "duration": 5.36,
        "text": "manage uh configuration and secrets it"
      },
      {
        "start": 1607.72,
        "duration": 4.679,
        "text": "helps you with automated roll outs and"
      },
      {
        "start": 1609.919,
        "duration": 5.24,
        "text": "roll backs if needed it helps with"
      },
      {
        "start": 1612.399,
        "duration": 5.321,
        "text": "service Discovery and loow balancing"
      },
      {
        "start": 1615.159,
        "duration": 5.441,
        "text": "horizontal scaling running multiple pods"
      },
      {
        "start": 1617.72,
        "duration": 6.8,
        "text": "for example it cares of a selfhealing if"
      },
      {
        "start": 1620.6,
        "duration": 7.12,
        "text": "some pots are broken and many other"
      },
      {
        "start": 1624.52,
        "duration": 5.279,
        "text": "things uh what's the infrastructure very"
      },
      {
        "start": 1627.72,
        "duration": 4.8,
        "text": "simple when we speak about the base"
      },
      {
        "start": 1629.799,
        "duration": 5.48,
        "text": "kubernetes infrastructure you have to"
      },
      {
        "start": 1632.52,
        "duration": 6.0,
        "text": "think about the following things Master"
      },
      {
        "start": 1635.279,
        "duration": 5.681,
        "text": "nodes and worker nodes so kubernetes"
      },
      {
        "start": 1638.52,
        "duration": 5.44,
        "text": "cluster consists of a control plane"
      },
      {
        "start": 1640.96,
        "duration": 5.52,
        "text": "running on the master nodee and free"
      },
      {
        "start": 1643.96,
        "duration": 5.719,
        "text": "worker oh not free well as much as you"
      },
      {
        "start": 1646.48,
        "duration": 5.199,
        "text": "want to have worker machines uh they are"
      },
      {
        "start": 1649.679,
        "duration": 4.081,
        "text": "usually much more powerful because"
      },
      {
        "start": 1651.679,
        "duration": 4.681,
        "text": "worker machines have un noes where"
      },
      {
        "start": 1653.76,
        "duration": 5.72,
        "text": "you're going to run your applications"
      },
      {
        "start": 1656.36,
        "duration": 5.199,
        "text": "and kubernetes control plane um"
      },
      {
        "start": 1659.48,
        "duration": 5.0,
        "text": "organizes communication of these"
      },
      {
        "start": 1661.559,
        "duration": 5.041,
        "text": "machines takes cares of networking sink"
      },
      {
        "start": 1664.48,
        "duration": 4.64,
        "text": "pods and so on and so"
      },
      {
        "start": 1666.6,
        "duration": 4.679,
        "text": "forth uh so there is pretty a lot"
      },
      {
        "start": 1669.12,
        "duration": 5.08,
        "text": "information I don't want to do a deep"
      },
      {
        "start": 1671.279,
        "duration": 5.12,
        "text": "dive but what we have to do uh what we"
      },
      {
        "start": 1674.2,
        "duration": 4.92,
        "text": "have to know control plane consists of a"
      },
      {
        "start": 1676.399,
        "duration": 5.52,
        "text": "API server so what something what"
      },
      {
        "start": 1679.12,
        "duration": 5.24,
        "text": "answers your queries I want to scale up"
      },
      {
        "start": 1681.919,
        "duration": 5.64,
        "text": "I want to scale down that's what you ask"
      },
      {
        "start": 1684.36,
        "duration": 7.039,
        "text": "a kubernetes API to do with API server"
      },
      {
        "start": 1687.559,
        "duration": 5.801,
        "text": "controller manager helps you uh with"
      },
      {
        "start": 1691.399,
        "duration": 5.88,
        "text": "everything what relates to operations on"
      },
      {
        "start": 1693.36,
        "duration": 6.28,
        "text": "the kubernetes Sher Cates of the ports"
      },
      {
        "start": 1697.279,
        "duration": 7.681,
        "text": "placement I'm to explain port in a"
      },
      {
        "start": 1699.64,
        "duration": 7.68,
        "text": "moment and htcd is the we can say it's a"
      },
      {
        "start": 1704.96,
        "duration": 4.92,
        "text": "database for kubernetes well not only"
      },
      {
        "start": 1707.32,
        "duration": 3.64,
        "text": "for kubernetes but us it by kubernetes"
      },
      {
        "start": 1709.88,
        "duration": 5.6,
        "text": "in this"
      },
      {
        "start": 1710.96,
        "duration": 8.199,
        "text": "case so and on the worker note we have"
      },
      {
        "start": 1715.48,
        "duration": 4.679,
        "text": "something already more interesting so uh"
      },
      {
        "start": 1719.159,
        "duration": 3.76,
        "text": "Cube"
      },
      {
        "start": 1720.159,
        "duration": 5.961,
        "text": "proxy kubernetes networking is a long"
      },
      {
        "start": 1722.919,
        "duration": 5.921,
        "text": "story uh there is a set of software"
      },
      {
        "start": 1726.12,
        "duration": 6.039,
        "text": "defined networks working together and"
      },
      {
        "start": 1728.84,
        "duration": 6.6,
        "text": "Cube proxy is the uh service responsible"
      },
      {
        "start": 1732.159,
        "duration": 6.441,
        "text": "for the networking things and now Port"
      },
      {
        "start": 1735.44,
        "duration": 6.479,
        "text": "Port is a very important idea when we"
      },
      {
        "start": 1738.6,
        "duration": 7.24,
        "text": "work with uh pure Docker what's the"
      },
      {
        "start": 1741.919,
        "duration": 6.561,
        "text": "minimal unit of access for us it's a"
      },
      {
        "start": 1745.84,
        "duration": 5.24,
        "text": "container and in kubernetes is a little"
      },
      {
        "start": 1748.48,
        "duration": 6.199,
        "text": "bit different because every"
      },
      {
        "start": 1751.08,
        "duration": 6.479,
        "text": "poort uh so basically Port is just a"
      },
      {
        "start": 1754.679,
        "duration": 5.441,
        "text": "container for a container very simply"
      },
      {
        "start": 1757.559,
        "duration": 4.96,
        "text": "you can ask like why do we need the port"
      },
      {
        "start": 1760.12,
        "duration": 5.32,
        "text": "we have containers already why don't we"
      },
      {
        "start": 1762.519,
        "duration": 5.121,
        "text": "use just containers answer is first of"
      },
      {
        "start": 1765.44,
        "duration": 3.239,
        "text": "all kubernetes doesn't work only with"
      },
      {
        "start": 1767.64,
        "duration": 3.24,
        "text": "containers"
      },
      {
        "start": 1768.679,
        "duration": 4.961,
        "text": "it can be a special kind of virtual"
      },
      {
        "start": 1770.88,
        "duration": 5.08,
        "text": "machines it can be rkt containers not"
      },
      {
        "start": 1773.64,
        "duration": 5.6,
        "text": "Docker containers and so on and so forth"
      },
      {
        "start": 1775.96,
        "duration": 6.0,
        "text": "so for the unification uh we use pot and"
      },
      {
        "start": 1779.24,
        "duration": 5.84,
        "text": "pot uh contains something which is"
      },
      {
        "start": 1781.96,
        "duration": 5.319,
        "text": "usually Docker container usually but not"
      },
      {
        "start": 1785.08,
        "duration": 4.64,
        "text": "necessary then to make it kind of"
      },
      {
        "start": 1787.279,
        "duration": 4.801,
        "text": "agnostic too it it creates you know it"
      },
      {
        "start": 1789.72,
        "duration": 4.72,
        "text": "doesn't care what what you have in that"
      },
      {
        "start": 1792.08,
        "duration": 3.959,
        "text": "pod the Pod is going to be able to"
      },
      {
        "start": 1794.44,
        "duration": 4.04,
        "text": "communicate with the other pods and all"
      },
      {
        "start": 1796.039,
        "duration": 3.801,
        "text": "of that is kind of abstracted away where"
      },
      {
        "start": 1798.48,
        "duration": 5.28,
        "text": "you just don't have to deal with it"
      },
      {
        "start": 1799.84,
        "duration": 6.88,
        "text": "anymore exactly and one more thing uh"
      },
      {
        "start": 1803.76,
        "duration": 5.639,
        "text": "one container is one single container"
      },
      {
        "start": 1806.72,
        "duration": 4.839,
        "text": "with Port it's a little bit different"
      },
      {
        "start": 1809.399,
        "duration": 5.76,
        "text": "because in Port you may have multiple"
      },
      {
        "start": 1811.559,
        "duration": 6.0,
        "text": "containers of a different kind at once"
      },
      {
        "start": 1815.159,
        "duration": 5.64,
        "text": "um what does that give us in some"
      },
      {
        "start": 1817.559,
        "duration": 5.641,
        "text": "situations your containers uh work so"
      },
      {
        "start": 1820.799,
        "duration": 4.841,
        "text": "close together so they need to share"
      },
      {
        "start": 1823.2,
        "duration": 5.359,
        "text": "something uh for example inter"
      },
      {
        "start": 1825.64,
        "duration": 5.56,
        "text": "interprocess communication is not"
      },
      {
        "start": 1828.559,
        "duration": 5.081,
        "text": "directly uh possible between different"
      },
      {
        "start": 1831.2,
        "duration": 6.719,
        "text": "pots but possible for containers within"
      },
      {
        "start": 1833.64,
        "duration": 6.48,
        "text": "single pot and some other options if you"
      },
      {
        "start": 1837.919,
        "duration": 4.561,
        "text": "want to think if you want to have one"
      },
      {
        "start": 1840.12,
        "duration": 5.0,
        "text": "container per poort if you want to have"
      },
      {
        "start": 1842.48,
        "duration": 5.48,
        "text": "port a and Port b or you want to have"
      },
      {
        "start": 1845.12,
        "duration": 5.72,
        "text": "your container A and B in a single pot"
      },
      {
        "start": 1847.96,
        "duration": 5.559,
        "text": "think on how do you want to scale them"
      },
      {
        "start": 1850.84,
        "duration": 6.24,
        "text": "if your containers always scale to to"
      },
      {
        "start": 1853.519,
        "duration": 6.561,
        "text": "scale together then they make a good pot"
      },
      {
        "start": 1857.08,
        "duration": 6.16,
        "text": "for example when we run Cassandra in"
      },
      {
        "start": 1860.08,
        "duration": 5.68,
        "text": "kubernetes uh we have two containers per"
      },
      {
        "start": 1863.24,
        "duration": 5.679,
        "text": "Cassandra pot one is the Cassandra as it"
      },
      {
        "start": 1865.76,
        "duration": 4.759,
        "text": "is and second is a Cassandra side car a"
      },
      {
        "start": 1868.919,
        "duration": 4.0,
        "text": "special application to help with"
      },
      {
        "start": 1870.519,
        "duration": 5.201,
        "text": "management and metrics of a Cassandra"
      },
      {
        "start": 1872.919,
        "duration": 5.161,
        "text": "for monitoring and we always scale them"
      },
      {
        "start": 1875.72,
        "duration": 4.64,
        "text": "together so we make a good pot together"
      },
      {
        "start": 1878.08,
        "duration": 5.599,
        "text": "but for most of the cases you will see"
      },
      {
        "start": 1880.36,
        "duration": 3.319,
        "text": "one pot means one"
      },
      {
        "start": 1884.0,
        "duration": 5.96,
        "text": "container when echosystem for the cuber"
      },
      {
        "start": 1888.039,
        "duration": 5.24,
        "text": "netes may be really"
      },
      {
        "start": 1889.96,
        "duration": 6.599,
        "text": "overwhelming because uh kubernetes was"
      },
      {
        "start": 1893.279,
        "duration": 7.36,
        "text": "originally designed by uh Google to"
      },
      {
        "start": 1896.559,
        "duration": 7.161,
        "text": "solve Google size problems and that all"
      },
      {
        "start": 1900.639,
        "duration": 5.201,
        "text": "it comes through but uh don't worry you"
      },
      {
        "start": 1903.72,
        "duration": 5.28,
        "text": "don't have to know all of that I guess"
      },
      {
        "start": 1905.84,
        "duration": 5.12,
        "text": "we're are no one to learn all of that"
      },
      {
        "start": 1909.0,
        "duration": 4.24,
        "text": "and again we speak mostly about the"
      },
      {
        "start": 1910.96,
        "duration": 6.48,
        "text": "developer things today so for us it's"
      },
      {
        "start": 1913.24,
        "duration": 9.159,
        "text": "going to be much easier and very simple"
      },
      {
        "start": 1917.44,
        "duration": 10.719,
        "text": "very simple and here comes Kate Sandra"
      },
      {
        "start": 1922.399,
        "duration": 8.28,
        "text": "yay so yeah Eric yeah so Kate Sandra is"
      },
      {
        "start": 1928.159,
        "duration": 5.441,
        "text": "basically taking all the complexity of"
      },
      {
        "start": 1930.679,
        "duration": 5.641,
        "text": "the distributed systems in in working it"
      },
      {
        "start": 1933.6,
        "duration": 4.0,
        "text": "all together weaving both kubernetes and"
      },
      {
        "start": 1936.32,
        "duration": 3.839,
        "text": "Cassandra together into something that"
      },
      {
        "start": 1937.6,
        "duration": 5.76,
        "text": "is actually very very simple to use and"
      },
      {
        "start": 1940.159,
        "duration": 5.12,
        "text": "install so um in in the past everyone"
      },
      {
        "start": 1943.36,
        "duration": 3.52,
        "text": "knows that Cassandra is a distributed"
      },
      {
        "start": 1945.279,
        "duration": 3.4,
        "text": "system distributed systems are hard"
      },
      {
        "start": 1946.88,
        "duration": 3.6,
        "text": "kubernetes is a distrib system"
      },
      {
        "start": 1948.679,
        "duration": 3.441,
        "text": "distributed systems are hard and you try"
      },
      {
        "start": 1950.48,
        "duration": 3.24,
        "text": "to put two of them together and it's"
      },
      {
        "start": 1952.12,
        "duration": 3.039,
        "text": "just a ton of work that's been kind of a"
      },
      {
        "start": 1953.72,
        "duration": 3.959,
        "text": "historical thorn in the side of both"
      },
      {
        "start": 1955.159,
        "duration": 5.721,
        "text": "kubernetes and Cassandra is integrating"
      },
      {
        "start": 1957.679,
        "duration": 5.48,
        "text": "these two things so what we did with the"
      },
      {
        "start": 1960.88,
        "duration": 4.039,
        "text": "Kate Sandra project again not not just"
      },
      {
        "start": 1963.159,
        "duration": 5.36,
        "text": "data Stacks this is an open source"
      },
      {
        "start": 1964.919,
        "duration": 5.36,
        "text": "project we went and we basically used um"
      },
      {
        "start": 1968.519,
        "duration": 3.681,
        "text": "some tools that we'll get into to"
      },
      {
        "start": 1970.279,
        "duration": 4.081,
        "text": "integrate the two tie them closely"
      },
      {
        "start": 1972.2,
        "duration": 4.88,
        "text": "together so that instead of having to"
      },
      {
        "start": 1974.36,
        "duration": 4.64,
        "text": "spend you know weeks hours sometimes"
      },
      {
        "start": 1977.08,
        "duration": 4.8,
        "text": "months getting all of these components"
      },
      {
        "start": 1979.0,
        "duration": 4.679,
        "text": "working adequately for production now"
      },
      {
        "start": 1981.88,
        "duration": 3.44,
        "text": "suddenly we can do it very very quickly"
      },
      {
        "start": 1983.679,
        "duration": 3.921,
        "text": "and we'll actually do that within the"
      },
      {
        "start": 1985.32,
        "duration": 3.599,
        "text": "session here today it's I think about"
      },
      {
        "start": 1987.6,
        "duration": 3.199,
        "text": "the last hour of the session we're going"
      },
      {
        "start": 1988.919,
        "duration": 3.401,
        "text": "to go through not just set it up but"
      },
      {
        "start": 1990.799,
        "duration": 5.0,
        "text": "we're going to do a number of operations"
      },
      {
        "start": 1992.32,
        "duration": 7.719,
        "text": "with it as well yep"
      },
      {
        "start": 1995.799,
        "duration": 4.24,
        "text": "exactly okay uh"
      },
      {
        "start": 2000.88,
        "duration": 4.639,
        "text": "sorry"
      },
      {
        "start": 2002.48,
        "duration": 5.919,
        "text": "and yes oh that's correct that's correct"
      },
      {
        "start": 2005.519,
        "duration": 5.801,
        "text": "that's correct first quiz of the day"
      },
      {
        "start": 2008.399,
        "duration": 5.441,
        "text": "first quiz of the day so warm up your"
      },
      {
        "start": 2011.32,
        "duration": 6.0,
        "text": "hands prepare for the"
      },
      {
        "start": 2013.84,
        "duration": 7.16,
        "text": "quiz yeah I'm switching to M"
      },
      {
        "start": 2017.32,
        "duration": 7.12,
        "text": "him and that's the quiz time so set the"
      },
      {
        "start": 2021.0,
        "duration": 6.559,
        "text": "thumbs up I'll know you are"
      },
      {
        "start": 2024.44,
        "duration": 5.52,
        "text": "here and that's going to be Cassandra"
      },
      {
        "start": 2027.559,
        "duration": 3.84,
        "text": "fundamentals I know we have some people"
      },
      {
        "start": 2029.96,
        "duration": 4.36,
        "text": "with experience"
      },
      {
        "start": 2031.399,
        "duration": 5.88,
        "text": "today"
      },
      {
        "start": 2034.32,
        "duration": 3.92,
        "text": "that's something very interesting for us"
      },
      {
        "start": 2037.279,
        "duration": 3.481,
        "text": "to see"
      },
      {
        "start": 2038.24,
        "duration": 6.399,
        "text": "but please give some chance chances to"
      },
      {
        "start": 2040.76,
        "duration": 6.44,
        "text": "novices as well so once again man.com"
      },
      {
        "start": 2044.639,
        "duration": 6.921,
        "text": "use the code"
      },
      {
        "start": 2047.2,
        "duration": 7.12,
        "text": "62450 540 I'm sorry and I know we have"
      },
      {
        "start": 2051.56,
        "duration": 2.76,
        "text": "code in the"
      },
      {
        "start": 2056.28,
        "duration": 5.399,
        "text": "chat"
      },
      {
        "start": 2057.8,
        "duration": 7.279,
        "text": "okay so I think we are good to"
      },
      {
        "start": 2061.679,
        "duration": 5.2,
        "text": "go jump in right now overwise you will"
      },
      {
        "start": 2065.079,
        "duration": 5.0,
        "text": "not have time to answer the first"
      },
      {
        "start": 2066.879,
        "duration": 6.76,
        "text": "question and as a result you will have"
      },
      {
        "start": 2070.079,
        "duration": 6.8,
        "text": "worse results I see we have almost 100"
      },
      {
        "start": 2073.639,
        "duration": 5.921,
        "text": "of people in this uh in this uh live"
      },
      {
        "start": 2076.879,
        "duration": 5.0,
        "text": "stream so I really want to have more"
      },
      {
        "start": 2079.56,
        "duration": 6.92,
        "text": "people than we are having right now make"
      },
      {
        "start": 2081.879,
        "duration": 7.04,
        "text": "me 45 okay and the top three people on"
      },
      {
        "start": 2086.48,
        "duration": 3.84,
        "text": "this quiz get a prize so there's this"
      },
      {
        "start": 2088.919,
        "duration": 4.16,
        "text": "one and then you'll have one more"
      },
      {
        "start": 2090.32,
        "duration": 6.12,
        "text": "opportunity yeah and people ask all the"
      },
      {
        "start": 2093.079,
        "duration": 6.441,
        "text": "time do you send prizes to my place it's"
      },
      {
        "start": 2096.44,
        "duration": 6.919,
        "text": "like a remote one we don't care we"
      },
      {
        "start": 2099.52,
        "duration": 9.48,
        "text": "deliver worldwide as Cassandra"
      },
      {
        "start": 2103.359,
        "duration": 5.641,
        "text": "does good so 43 people two more and we"
      },
      {
        "start": 2110.44,
        "duration": 7.919,
        "text": "start good 44 one last 45 here we go"
      },
      {
        "start": 2115.88,
        "duration": 2.479,
        "text": "let's do"
      },
      {
        "start": 2124.04,
        "duration": 7.72,
        "text": "it so answer fast to get more points"
      },
      {
        "start": 2128.68,
        "duration": 6.48,
        "text": "what is a partition"
      },
      {
        "start": 2131.76,
        "duration": 6.68,
        "text": "key a consecutive number applied to each"
      },
      {
        "start": 2135.16,
        "duration": 6.4,
        "text": "new record a designated field in your"
      },
      {
        "start": 2138.44,
        "duration": 5.88,
        "text": "table to partition your data an optional"
      },
      {
        "start": 2141.56,
        "duration": 6.48,
        "text": "table field for optional partitioning"
      },
      {
        "start": 2144.32,
        "duration": 3.72,
        "text": "another word for a garage"
      },
      {
        "start": 2148.8,
        "duration": 7.96,
        "text": "key and we are done time is up and most"
      },
      {
        "start": 2153.96,
        "duration": 4.68,
        "text": "of you have answered it correctly it's a"
      },
      {
        "start": 2156.76,
        "duration": 4.319,
        "text": "designated field in your table to"
      },
      {
        "start": 2158.64,
        "duration": 4.64,
        "text": "partition your data there is no things"
      },
      {
        "start": 2161.079,
        "duration": 4.321,
        "text": "like consecutive numbers because when"
      },
      {
        "start": 2163.28,
        "duration": 4.559,
        "text": "you have a distributed system you will"
      },
      {
        "start": 2165.4,
        "duration": 5.04,
        "text": "have to agree on the consecutive number"
      },
      {
        "start": 2167.839,
        "duration": 6.52,
        "text": "over multiple noes in a hostile Network"
      },
      {
        "start": 2170.44,
        "duration": 6.48,
        "text": "environment that's not going to work uh"
      },
      {
        "start": 2174.359,
        "duration": 5.201,
        "text": "in a fast way and that's not an optional"
      },
      {
        "start": 2176.92,
        "duration": 9.919,
        "text": "field that's a required"
      },
      {
        "start": 2179.56,
        "duration": 10.6,
        "text": "field yes so who was the fastest today"
      },
      {
        "start": 2186.839,
        "duration": 7.441,
        "text": "Carl G Stu gets the first place with"
      },
      {
        "start": 2190.16,
        "duration": 7.64,
        "text": "944 points and very close to him Ashley"
      },
      {
        "start": 2194.28,
        "duration": 5.36,
        "text": "and the Hustler so but that was only the"
      },
      {
        "start": 2197.8,
        "duration": 3.799,
        "text": "first question so let's take a look"
      },
      {
        "start": 2199.64,
        "duration": 4.84,
        "text": "what's going on to happen next and"
      },
      {
        "start": 2201.599,
        "duration": 7.0,
        "text": "that's for question two so answer fast"
      },
      {
        "start": 2204.48,
        "duration": 4.119,
        "text": "to get more points what is a"
      },
      {
        "start": 2209.72,
        "duration": 5.44,
        "text": "partition the smallest unit of data"
      },
      {
        "start": 2212.319,
        "duration": 6.121,
        "text": "distribution a group of rowes a replica"
      },
      {
        "start": 2215.16,
        "duration": 4.56,
        "text": "note in a Cassandra cluster a je loated"
      },
      {
        "start": 2218.44,
        "duration": 3.72,
        "text": "grouping of"
      },
      {
        "start": 2219.72,
        "duration": 5.24,
        "text": "notes a dividing"
      },
      {
        "start": 2222.16,
        "duration": 5.36,
        "text": "wall what would you pick"
      },
      {
        "start": 2224.96,
        "duration": 4.399,
        "text": "Eric I'm going to go with option four a"
      },
      {
        "start": 2227.52,
        "duration": 4.04,
        "text": "dividing wall yeah I mean everyone knows"
      },
      {
        "start": 2229.359,
        "duration": 5.521,
        "text": "it's a dividing wall That's clear but"
      },
      {
        "start": 2231.56,
        "duration": 7.0,
        "text": "you know what it looks like they don't"
      },
      {
        "start": 2234.88,
        "duration": 5.84,
        "text": "agree answer is the smallest unit of"
      },
      {
        "start": 2238.56,
        "duration": 5.039,
        "text": "data distribution and group of rows and"
      },
      {
        "start": 2240.72,
        "duration": 5.52,
        "text": "that's the correct answer and no"
      },
      {
        "start": 2243.599,
        "duration": 7.72,
        "text": "partition is not a replica"
      },
      {
        "start": 2246.24,
        "duration": 9.599,
        "text": "node and and I want to see the"
      },
      {
        "start": 2251.319,
        "duration": 7.361,
        "text": "changes so it looks like we have some oh"
      },
      {
        "start": 2255.839,
        "duration": 6.28,
        "text": "and Carl Gustaf was fastest again that's"
      },
      {
        "start": 2258.68,
        "duration": 7.159,
        "text": "a good score today yeah and we have Su"
      },
      {
        "start": 2262.119,
        "duration": 8.521,
        "text": "hakar on the second place and Ana Gupta"
      },
      {
        "start": 2265.839,
        "duration": 7.081,
        "text": "is on the third one and ravikiran is so"
      },
      {
        "start": 2270.64,
        "duration": 5.12,
        "text": "close with Five Points difference to a"
      },
      {
        "start": 2272.92,
        "duration": 5.36,
        "text": "third place that's a very good"
      },
      {
        "start": 2275.76,
        "duration": 4.64,
        "text": "result yeah"
      },
      {
        "start": 2278.28,
        "duration": 4.44,
        "text": "so that's a question three and we are"
      },
      {
        "start": 2280.4,
        "duration": 6.56,
        "text": "getting close to the middle of the first"
      },
      {
        "start": 2282.72,
        "duration": 8.52,
        "text": "quiz and answer fast to get more points"
      },
      {
        "start": 2286.96,
        "duration": 4.28,
        "text": "what is the recommended replication"
      },
      {
        "start": 2291.4,
        "duration": 10.36,
        "text": "Factor free per note fre per cluster fre"
      },
      {
        "start": 2296.599,
        "duration": 5.161,
        "text": "per data center zero we don't like"
      },
      {
        "start": 2303.88,
        "duration": 6.32,
        "text": "replication so this one is a little bit"
      },
      {
        "start": 2306.52,
        "duration": 4.799,
        "text": "trickier for Cassandra novices but well"
      },
      {
        "start": 2310.2,
        "duration": 3.919,
        "text": "that's pretty"
      },
      {
        "start": 2311.319,
        "duration": 3.76,
        "text": "fair yeah it was mentioned very briefly"
      },
      {
        "start": 2314.119,
        "duration": 4.601,
        "text": "there"
      },
      {
        "start": 2315.079,
        "duration": 4.76,
        "text": "yeah oh that's painful this is going to"
      },
      {
        "start": 2318.72,
        "duration": 3.16,
        "text": "switch up the"
      },
      {
        "start": 2319.839,
        "duration": 5.121,
        "text": "scoreboard yeah that will change the"
      },
      {
        "start": 2321.88,
        "duration": 6.28,
        "text": "scoreboard so correct answer is free per"
      },
      {
        "start": 2324.96,
        "duration": 6.2,
        "text": "data center because if you have free"
      },
      {
        "start": 2328.16,
        "duration": 6.28,
        "text": "replica nodes uh per cluster that isn't"
      },
      {
        "start": 2331.16,
        "duration": 5.56,
        "text": "going to work in the uh quick and fast"
      },
      {
        "start": 2334.44,
        "duration": 4.28,
        "text": "Manner and reliable manner for you and"
      },
      {
        "start": 2336.72,
        "duration": 4.8,
        "text": "definitely not free per note so"
      },
      {
        "start": 2338.72,
        "duration": 7.04,
        "text": "recommended replication factor is free"
      },
      {
        "start": 2341.52,
        "duration": 6.76,
        "text": "per data center in some cases maybe"
      },
      {
        "start": 2345.76,
        "duration": 7.0,
        "text": "five"
      },
      {
        "start": 2348.28,
        "duration": 8.24,
        "text": "and okay hi skus I see some familiar"
      },
      {
        "start": 2352.76,
        "duration": 5.72,
        "text": "names already and sakar was the fastest"
      },
      {
        "start": 2356.52,
        "duration": 5.48,
        "text": "one but it was not enough to get to the"
      },
      {
        "start": 2358.48,
        "duration": 6.119,
        "text": "first place and we have sures sudakar"
      },
      {
        "start": 2362.0,
        "duration": 5.76,
        "text": "and anania Gupta on the first three"
      },
      {
        "start": 2364.599,
        "duration": 8.201,
        "text": "places and Charles are very close to the"
      },
      {
        "start": 2367.76,
        "duration": 7.319,
        "text": "first three but not yet in so let me see"
      },
      {
        "start": 2372.8,
        "duration": 3.64,
        "text": "and that's a question four and I want to"
      },
      {
        "start": 2375.079,
        "duration": 3.76,
        "text": "see your"
      },
      {
        "start": 2376.44,
        "duration": 6.2,
        "text": "answers because we are getting close to"
      },
      {
        "start": 2378.839,
        "duration": 7.841,
        "text": "a end what happens when a note goes"
      },
      {
        "start": 2382.64,
        "duration": 7.16,
        "text": "down you lose data cordinator stores a"
      },
      {
        "start": 2386.68,
        "duration": 5.24,
        "text": "hint over replica serf request there is"
      },
      {
        "start": 2389.8,
        "duration": 5.2,
        "text": "downtime for the notes to"
      },
      {
        "start": 2391.92,
        "duration": 4.24,
        "text": "rebalance uh Eric's option note never"
      },
      {
        "start": 2395.0,
        "duration": 4.079,
        "text": "goes"
      },
      {
        "start": 2396.16,
        "duration": 4.8,
        "text": "down yeah yeah I mean that's that's you"
      },
      {
        "start": 2399.079,
        "duration": 3.801,
        "text": "know if you build the system perfectly"
      },
      {
        "start": 2400.96,
        "duration": 4.68,
        "text": "they will never fail right yeah that"
      },
      {
        "start": 2402.88,
        "duration": 4.84,
        "text": "would be great but the correct answer is"
      },
      {
        "start": 2405.64,
        "duration": 4.32,
        "text": "coordinator stores a hint and other"
      },
      {
        "start": 2407.72,
        "duration": 5.639,
        "text": "replicas serve the request and that's"
      },
      {
        "start": 2409.96,
        "duration": 5.52,
        "text": "the correct there is no downtime for the"
      },
      {
        "start": 2413.359,
        "duration": 4.96,
        "text": "notes to rebalance no there is no"
      },
      {
        "start": 2415.48,
        "duration": 5.76,
        "text": "downtime please I believe I mean you"
      },
      {
        "start": 2418.319,
        "duration": 5.401,
        "text": "know see that the people with relational"
      },
      {
        "start": 2421.24,
        "duration": 5.0,
        "text": "databases experience they believe in"
      },
      {
        "start": 2423.72,
        "duration": 4.879,
        "text": "downtime in Cassandra team we don't"
      },
      {
        "start": 2426.24,
        "duration": 5.76,
        "text": "believe in downtime if you do everything"
      },
      {
        "start": 2428.599,
        "duration": 5.841,
        "text": "correct you can go for the full up time"
      },
      {
        "start": 2432.0,
        "duration": 5.56,
        "text": "and yeah so there is no downtime if a"
      },
      {
        "start": 2434.44,
        "duration": 5.159,
        "text": "note goes down and you lose a data is"
      },
      {
        "start": 2437.56,
        "duration": 5.44,
        "text": "also wrong because there are still"
      },
      {
        "start": 2439.599,
        "duration": 6.401,
        "text": "replica notes keeping your"
      },
      {
        "start": 2443.0,
        "duration": 8.56,
        "text": "data so what are the changes in the"
      },
      {
        "start": 2446.0,
        "duration": 8.68,
        "text": "leaderboard after all I see very well so"
      },
      {
        "start": 2451.56,
        "duration": 6.96,
        "text": "sures was fastest again and sudakar and"
      },
      {
        "start": 2454.68,
        "duration": 5.96,
        "text": "Ana still holding the top three places"
      },
      {
        "start": 2458.52,
        "duration": 6.0,
        "text": "very"
      },
      {
        "start": 2460.64,
        "duration": 6.479,
        "text": "well all right question five and we are"
      },
      {
        "start": 2464.52,
        "duration": 5.88,
        "text": "getting close to the"
      },
      {
        "start": 2467.119,
        "duration": 5.281,
        "text": "end how many Master nodes should be in"
      },
      {
        "start": 2470.4,
        "duration": 5.08,
        "text": "each"
      },
      {
        "start": 2472.4,
        "duration": 5.88,
        "text": "cluster one master node per fre replica"
      },
      {
        "start": 2475.48,
        "duration": 5.52,
        "text": "nodes one master node per data uh two"
      },
      {
        "start": 2478.28,
        "duration": 5.319,
        "text": "Master noes per data center sorry one"
      },
      {
        "start": 2481.0,
        "duration": 5.92,
        "text": "cluster Master we have at least two data"
      },
      {
        "start": 2483.599,
        "duration": 5.641,
        "text": "center submasters zero we don't use"
      },
      {
        "start": 2486.92,
        "duration": 2.32,
        "text": "master"
      },
      {
        "start": 2491.16,
        "duration": 7.48,
        "text": "notes and the time is up and the correct"
      },
      {
        "start": 2494.52,
        "duration": 6.839,
        "text": "answer was Zero we do not use Master"
      },
      {
        "start": 2498.64,
        "duration": 5.12,
        "text": "nodes and when I say we do not use"
      },
      {
        "start": 2501.359,
        "duration": 5.561,
        "text": "Master nodes that means exactly what it"
      },
      {
        "start": 2503.76,
        "duration": 8.2,
        "text": "means no master noes in a cluster and"
      },
      {
        "start": 2506.92,
        "duration": 7.399,
        "text": "therefore any other qu answers are"
      },
      {
        "start": 2511.96,
        "duration": 6.24,
        "text": "wrong yeah we were got getting a little"
      },
      {
        "start": 2514.319,
        "duration": 5.921,
        "text": "tricky with that one too"
      },
      {
        "start": 2518.2,
        "duration": 5.76,
        "text": "so it looks like we made them think take"
      },
      {
        "start": 2520.24,
        "duration": 6.68,
        "text": "a look yeah and Sak car was the fastest"
      },
      {
        "start": 2523.96,
        "duration": 5.28,
        "text": "one this time getting to the first place"
      },
      {
        "start": 2526.92,
        "duration": 4.399,
        "text": "but the top three list still looks the"
      },
      {
        "start": 2529.24,
        "duration": 6.04,
        "text": "same but there are some people like"
      },
      {
        "start": 2531.319,
        "duration": 8.321,
        "text": "Charles KV and agent is9 all who also"
      },
      {
        "start": 2535.28,
        "duration": 7.2,
        "text": "going to fight for the top score"
      },
      {
        "start": 2539.64,
        "duration": 5.08,
        "text": "today definitely could could switch it"
      },
      {
        "start": 2542.48,
        "duration": 4.52,
        "text": "up here more question right so last"
      },
      {
        "start": 2544.72,
        "duration": 2.96,
        "text": "question so don't make a mistake right"
      },
      {
        "start": 2547.0,
        "duration": 5.44,
        "text": "now"
      },
      {
        "start": 2547.68,
        "duration": 7.04,
        "text": "now answer fast to get more points is"
      },
      {
        "start": 2552.44,
        "duration": 3.879,
        "text": "active active replication possible for"
      },
      {
        "start": 2554.72,
        "duration": 5.16,
        "text": "multiple data"
      },
      {
        "start": 2556.319,
        "duration": 5.721,
        "text": "centers yes within the same Jo location"
      },
      {
        "start": 2559.88,
        "duration": 4.84,
        "text": "yes if a replication is coordinated by a"
      },
      {
        "start": 2562.04,
        "duration": 5.6,
        "text": "cluster primary node yes Cassandra is"
      },
      {
        "start": 2564.72,
        "duration": 5.76,
        "text": "natively active active you cannot have"
      },
      {
        "start": 2567.64,
        "duration": 2.84,
        "text": "multiple data"
      },
      {
        "start": 2572.52,
        "duration": 3.36,
        "text": "centers now if you're paying attention"
      },
      {
        "start": 2574.44,
        "duration": 3.96,
        "text": "to the last question that should"
      },
      {
        "start": 2575.88,
        "duration": 5.36,
        "text": "eliminate one of the answers here yeah"
      },
      {
        "start": 2578.4,
        "duration": 5.88,
        "text": "so it was easy this time candre is"
      },
      {
        "start": 2581.24,
        "duration": 6.079,
        "text": "natively active active worldwide"
      },
      {
        "start": 2584.28,
        "duration": 5.2,
        "text": "globally so there is no thing like a"
      },
      {
        "start": 2587.319,
        "duration": 4.24,
        "text": "replication coordination by a cluster"
      },
      {
        "start": 2589.48,
        "duration": 6.48,
        "text": "primary node because there are no"
      },
      {
        "start": 2591.559,
        "duration": 6.841,
        "text": "primary nodes and that's not the not"
      },
      {
        "start": 2595.96,
        "duration": 5.72,
        "text": "about the same geolocation that's"
      },
      {
        "start": 2598.4,
        "duration": 7.24,
        "text": "completely possible all across the world"
      },
      {
        "start": 2601.68,
        "duration": 6.84,
        "text": "so we can now take a final look at the"
      },
      {
        "start": 2605.64,
        "duration": 5.6,
        "text": "leaderboard and are there any changes so"
      },
      {
        "start": 2608.52,
        "duration": 5.599,
        "text": "none of the winners made a mistake but"
      },
      {
        "start": 2611.24,
        "duration": 7.119,
        "text": "will will be the changes because of the"
      },
      {
        "start": 2614.119,
        "duration": 8.081,
        "text": "points yes on the very last question"
      },
      {
        "start": 2618.359,
        "duration": 5.841,
        "text": "Charles jumps in into the top three so"
      },
      {
        "start": 2622.2,
        "duration": 5.28,
        "text": "sakar with"
      },
      {
        "start": 2624.2,
        "duration": 6.08,
        "text": "5,580 points gets the first place very"
      },
      {
        "start": 2627.48,
        "duration": 5.8,
        "text": "well deserved sures get to the second"
      },
      {
        "start": 2630.28,
        "duration": 6.92,
        "text": "one with a very small Gap to the first"
      },
      {
        "start": 2633.28,
        "duration": 6.36,
        "text": "place and Charles jumps in with a very"
      },
      {
        "start": 2637.2,
        "duration": 6.28,
        "text": "very last moment there a great job and"
      },
      {
        "start": 2639.64,
        "duration": 6.4,
        "text": "an Gupta I'm very sorry but Charles was"
      },
      {
        "start": 2643.48,
        "duration": 4.879,
        "text": "faster so for the top three of you make"
      },
      {
        "start": 2646.04,
        "duration": 5.16,
        "text": "sure you take a screenshot of your win"
      },
      {
        "start": 2648.359,
        "duration": 5.841,
        "text": "and send that to Jack frier at dat"
      },
      {
        "start": 2651.2,
        "duration": 5.08,
        "text": "stacks.com he's posted in the chats"
      },
      {
        "start": 2654.2,
        "duration": 3.32,
        "text": "there the address just send it there and"
      },
      {
        "start": 2656.28,
        "duration": 4.64,
        "text": "he will get you sorted out with your"
      },
      {
        "start": 2657.52,
        "duration": 7.559,
        "text": "prizes yep uh so make a screenshot don't"
      },
      {
        "start": 2660.92,
        "duration": 6.8,
        "text": "forget and send it to uh Jack frier uh"
      },
      {
        "start": 2665.079,
        "duration": 6.28,
        "text": "he is exactly in the YouTube chat right"
      },
      {
        "start": 2667.72,
        "duration": 6.24,
        "text": "now and if you didn't make it to be in"
      },
      {
        "start": 2671.359,
        "duration": 4.401,
        "text": "top three this time don't worry too much"
      },
      {
        "start": 2673.96,
        "duration": 5.52,
        "text": "because you know what what's the what's"
      },
      {
        "start": 2675.76,
        "duration": 7.319,
        "text": "the Priceless um price of this Workshop"
      },
      {
        "start": 2679.48,
        "duration": 6.04,
        "text": "it's not the gifts from data stocks"
      },
      {
        "start": 2683.079,
        "duration": 4.841,
        "text": "although they are great but your"
      },
      {
        "start": 2685.52,
        "duration": 4.839,
        "text": "knowledge your skills and your higher"
      },
      {
        "start": 2687.92,
        "duration": 6.04,
        "text": "salary as you are doing your job better"
      },
      {
        "start": 2690.359,
        "duration": 3.601,
        "text": "and better that what really"
      },
      {
        "start": 2695.04,
        "duration": 5.24,
        "text": "values I think we all like High salaries"
      },
      {
        "start": 2697.76,
        "duration": 4.88,
        "text": "right yeah I mean is our boss listening"
      },
      {
        "start": 2700.28,
        "duration": 3.799,
        "text": "yeah yeah yeah yeah I hope so I've seen"
      },
      {
        "start": 2702.64,
        "duration": 6.16,
        "text": "Patrick in the"
      },
      {
        "start": 2704.079,
        "duration": 6.76,
        "text": "chat good okay"
      },
      {
        "start": 2708.8,
        "duration": 7.279,
        "text": "so well"
      },
      {
        "start": 2710.839,
        "duration": 10.961,
        "text": "then we have now advancing to Kate"
      },
      {
        "start": 2716.079,
        "duration": 9.641,
        "text": "Sandra and I bet I'm switching now to"
      },
      {
        "start": 2721.8,
        "duration": 5.72,
        "text": "Eric that's going to be Wonder well I"
      },
      {
        "start": 2725.72,
        "duration": 3.48,
        "text": "get to do kind of the coolest part of"
      },
      {
        "start": 2727.52,
        "duration": 3.92,
        "text": "this presentation it's also the most"
      },
      {
        "start": 2729.2,
        "duration": 4.8,
        "text": "dangerous I mean that's a correct time"
      },
      {
        "start": 2731.44,
        "duration": 5.48,
        "text": "to say sorry Alex I'm going to do the"
      },
      {
        "start": 2734.0,
        "duration": 4.88,
        "text": "coolest part of this presentation yes"
      },
      {
        "start": 2736.92,
        "duration": 5.8,
        "text": "yes okay"
      },
      {
        "start": 2738.88,
        "duration": 6.64,
        "text": "okay all right so we've talked"
      },
      {
        "start": 2742.72,
        "duration": 4.119,
        "text": "about candra wait a second let me switch"
      },
      {
        "start": 2745.52,
        "duration": 3.28,
        "text": "to you"
      },
      {
        "start": 2746.839,
        "duration": 3.801,
        "text": "please boom"
      },
      {
        "start": 2748.8,
        "duration": 5.319,
        "text": "absolutely"
      },
      {
        "start": 2750.64,
        "duration": 6.16,
        "text": "so okay here we go all"
      },
      {
        "start": 2754.119,
        "duration": 5.361,
        "text": "right so in the last hour here we talked"
      },
      {
        "start": 2756.8,
        "duration": 4.64,
        "text": "about Cassandra and kubernetes and we'"
      },
      {
        "start": 2759.48,
        "duration": 3.44,
        "text": "talked about kind of how they operate"
      },
      {
        "start": 2761.44,
        "duration": 2.72,
        "text": "what they are what they do now we're"
      },
      {
        "start": 2762.92,
        "duration": 4.0,
        "text": "going to talk about putting them"
      },
      {
        "start": 2764.16,
        "duration": 3.88,
        "text": "together and fortunately for you all"
      },
      {
        "start": 2766.92,
        "duration": 2.32,
        "text": "we're not going to have to put them"
      },
      {
        "start": 2768.04,
        "duration": 2.44,
        "text": "together ourselves that's already been"
      },
      {
        "start": 2769.24,
        "duration": 4.28,
        "text": "done for us we're just going to get to"
      },
      {
        "start": 2770.48,
        "duration": 5.32,
        "text": "consume and use that so pre-work for"
      },
      {
        "start": 2773.52,
        "duration": 3.88,
        "text": "today um hope you all got the message we"
      },
      {
        "start": 2775.8,
        "duration": 3.84,
        "text": "got to do some network setup network"
      },
      {
        "start": 2777.4,
        "duration": 3.64,
        "text": "storage firewall setup we got to install"
      },
      {
        "start": 2779.64,
        "duration": 2.919,
        "text": "a bunch of nodes which is going to be"
      },
      {
        "start": 2781.04,
        "duration": 3.799,
        "text": "you know downloading some tars getting"
      },
      {
        "start": 2782.559,
        "duration": 5.081,
        "text": "those configured as Services um install"
      },
      {
        "start": 2784.839,
        "duration": 4.081,
        "text": "our Prometheus grafana user agents some"
      },
      {
        "start": 2787.64,
        "duration": 3.199,
        "text": "you know there's just a lot here we got"
      },
      {
        "start": 2788.92,
        "duration": 5.52,
        "text": "to okay I'm just kidding we don't have"
      },
      {
        "start": 2790.839,
        "duration": 7.841,
        "text": "to do any of that that's all done for us"
      },
      {
        "start": 2794.44,
        "duration": 7.28,
        "text": "liar yes I know I know I couldn't help"
      },
      {
        "start": 2798.68,
        "duration": 5.2,
        "text": "myself we actually get to do um some"
      },
      {
        "start": 2801.72,
        "duration": 4.52,
        "text": "very simple stuff so all you need for"
      },
      {
        "start": 2803.88,
        "duration": 4.199,
        "text": "today is either the cloud instance or"
      },
      {
        "start": 2806.24,
        "duration": 3.839,
        "text": "you could have set it up on your own"
      },
      {
        "start": 2808.079,
        "duration": 4.121,
        "text": "following our documentation you need to"
      },
      {
        "start": 2810.079,
        "duration": 4.081,
        "text": "be willing to learn and having a pulse"
      },
      {
        "start": 2812.2,
        "duration": 4.04,
        "text": "is also a very good thing of course you"
      },
      {
        "start": 2814.16,
        "duration": 5.28,
        "text": "know for our our Undead friends we're"
      },
      {
        "start": 2816.24,
        "duration": 7.04,
        "text": "accepting of them as well all right so"
      },
      {
        "start": 2819.44,
        "duration": 5.879,
        "text": "Kate Sandra what is it simply put it's"
      },
      {
        "start": 2823.28,
        "duration": 4.64,
        "text": "Helm plus all the things you would"
      },
      {
        "start": 2825.319,
        "duration": 5.04,
        "text": "normally need to run and manage your"
      },
      {
        "start": 2827.92,
        "duration": 4.96,
        "text": "Cassandra cluster all bundled up into"
      },
      {
        "start": 2830.359,
        "duration": 5.0,
        "text": "one Helm is basically a package"
      },
      {
        "start": 2832.88,
        "duration": 4.36,
        "text": "management tool for Cassandra sorry not"
      },
      {
        "start": 2835.359,
        "duration": 4.081,
        "text": "for Cassandra goodness o that's a big"
      },
      {
        "start": 2837.24,
        "duration": 4.76,
        "text": "oof it's for a package management and"
      },
      {
        "start": 2839.44,
        "duration": 4.76,
        "text": "templating tool for kubernetes and it"
      },
      {
        "start": 2842.0,
        "duration": 3.92,
        "text": "allows us to do a lot of really Dynamic"
      },
      {
        "start": 2844.2,
        "duration": 5.04,
        "text": "things that wouldn't be possible"
      },
      {
        "start": 2845.92,
        "duration": 4.919,
        "text": "otherwise with our um kubernetes"
      },
      {
        "start": 2849.24,
        "duration": 3.0,
        "text": "deployments we'll get into that we'll"
      },
      {
        "start": 2850.839,
        "duration": 3.041,
        "text": "actually start messing with stuff like"
      },
      {
        "start": 2852.24,
        "duration": 4.8,
        "text": "resizing things on the fly without"
      },
      {
        "start": 2853.88,
        "duration": 5.479,
        "text": "editing yaml so really really cool stuff"
      },
      {
        "start": 2857.04,
        "duration": 3.799,
        "text": "all right setting up Kate Sandra is"
      },
      {
        "start": 2859.359,
        "duration": 4.0,
        "text": "actually very easy now today we're going"
      },
      {
        "start": 2860.839,
        "duration": 4.801,
        "text": "to be using release candidate this is um"
      },
      {
        "start": 2863.359,
        "duration": 5.441,
        "text": "as as we mentioned this morning um the"
      },
      {
        "start": 2865.64,
        "duration": 6.959,
        "text": "project went live this morning so this"
      },
      {
        "start": 2868.8,
        "duration": 7.759,
        "text": "is the first uh release or candidate"
      },
      {
        "start": 2872.599,
        "duration": 6.681,
        "text": "that we have for Kate Sandra it's still"
      },
      {
        "start": 2876.559,
        "duration": 4.481,
        "text": "very very much a a beta product or a"
      },
      {
        "start": 2879.28,
        "duration": 3.0,
        "text": "beta uh tool I'm not even going to call"
      },
      {
        "start": 2881.04,
        "duration": 4.319,
        "text": "it a product cuz it's not a product it's"
      },
      {
        "start": 2882.28,
        "duration": 5.6,
        "text": "open source it's a beta tool but the"
      },
      {
        "start": 2885.359,
        "duration": 4.2,
        "text": "intention with this project is to take"
      },
      {
        "start": 2887.88,
        "duration": 4.16,
        "text": "it to something that will be used in"
      },
      {
        "start": 2889.559,
        "duration": 4.04,
        "text": "production across the globe basically"
      },
      {
        "start": 2892.04,
        "duration": 3.319,
        "text": "anywhere you have Cassandra and"
      },
      {
        "start": 2893.599,
        "duration": 5.041,
        "text": "kubernetes together you can just use"
      },
      {
        "start": 2895.359,
        "duration": 6.881,
        "text": "Kate Sandra and it will work so couple"
      },
      {
        "start": 2898.64,
        "duration": 6.08,
        "text": "things here today um with Helm uh if"
      },
      {
        "start": 2902.24,
        "duration": 4.72,
        "text": "you've ever used apt or yum as you know"
      },
      {
        "start": 2904.72,
        "duration": 4.359,
        "text": "package managers on Linux Helm works"
      },
      {
        "start": 2906.96,
        "duration": 4.159,
        "text": "very similarly we actually add our"
      },
      {
        "start": 2909.079,
        "duration": 4.24,
        "text": "repositories just like we would on any"
      },
      {
        "start": 2911.119,
        "duration": 4.24,
        "text": "of those other tools but then we also"
      },
      {
        "start": 2913.319,
        "duration": 3.641,
        "text": "get some additional templating"
      },
      {
        "start": 2915.359,
        "duration": 3.921,
        "text": "capabilities which are really really"
      },
      {
        "start": 2916.96,
        "duration": 4.359,
        "text": "awesome so you see there we have a on"
      },
      {
        "start": 2919.28,
        "duration": 4.319,
        "text": "the slide the helm repo ad and then we"
      },
      {
        "start": 2921.319,
        "duration": 4.04,
        "text": "add our repo and then we update our repo"
      },
      {
        "start": 2923.599,
        "duration": 4.121,
        "text": "which basically just says okay we added"
      },
      {
        "start": 2925.359,
        "duration": 4.2,
        "text": "something now make it Go Active and then"
      },
      {
        "start": 2927.72,
        "duration": 4.079,
        "text": "we actually do just a Helm install just"
      },
      {
        "start": 2929.559,
        "duration": 5.361,
        "text": "like you do an apt install or yum"
      },
      {
        "start": 2931.799,
        "duration": 5.8,
        "text": "install um and then we just install Kate"
      },
      {
        "start": 2934.92,
        "duration": 5.08,
        "text": "Sandra so really really really cool does"
      },
      {
        "start": 2937.599,
        "duration": 3.96,
        "text": "a lot of just awesome stuff that we"
      },
      {
        "start": 2940.0,
        "duration": 3.799,
        "text": "would have had to take hours to do"
      },
      {
        "start": 2941.559,
        "duration": 4.921,
        "text": "before in a single basically a single"
      },
      {
        "start": 2943.799,
        "duration": 4.881,
        "text": "line now I will point out there for"
      },
      {
        "start": 2946.48,
        "duration": 4.72,
        "text": "today um if you're watching this you"
      },
      {
        "start": 2948.68,
        "duration": 4.56,
        "text": "know sometime in the future on YouTube"
      },
      {
        "start": 2951.2,
        "duration": 4.08,
        "text": "uh all of those set Flags the set"
      },
      {
        "start": 2953.24,
        "duration": 3.16,
        "text": "Ingress um You probably aren't going to"
      },
      {
        "start": 2955.28,
        "duration": 3.039,
        "text": "need to run those because that's all"
      },
      {
        "start": 2956.4,
        "duration": 4.199,
        "text": "going to be worked into the actual Helm"
      },
      {
        "start": 2958.319,
        "duration": 4.321,
        "text": "install itself but what that basically"
      },
      {
        "start": 2960.599,
        "duration": 4.48,
        "text": "is doing here for us today is it's"
      },
      {
        "start": 2962.64,
        "duration": 5.08,
        "text": "setting up an Ingress an Ingress is a"
      },
      {
        "start": 2965.079,
        "duration": 4.601,
        "text": "way to communicate um from the outside"
      },
      {
        "start": 2967.72,
        "duration": 3.68,
        "text": "into a kubernetes cluster so we can"
      },
      {
        "start": 2969.68,
        "duration": 4.24,
        "text": "actually get at the uis that we're going"
      },
      {
        "start": 2971.4,
        "duration": 3.6,
        "text": "to be dealing with and you know the"
      },
      {
        "start": 2973.92,
        "duration": 3.36,
        "text": "various pieces of this that we're going"
      },
      {
        "start": 2975.0,
        "duration": 3.88,
        "text": "to be playing with today so normally you"
      },
      {
        "start": 2977.28,
        "duration": 3.92,
        "text": "won't need that but just since it is a"
      },
      {
        "start": 2978.88,
        "duration": 3.76,
        "text": "release candidate early release um we"
      },
      {
        "start": 2981.2,
        "duration": 3.52,
        "text": "are going to have to do that ourselves"
      },
      {
        "start": 2982.64,
        "duration": 5.919,
        "text": "instead of it being handled for us all"
      },
      {
        "start": 2984.72,
        "duration": 6.76,
        "text": "right with that let's get into it so"
      },
      {
        "start": 2988.559,
        "duration": 4.641,
        "text": "that is all that's required to set up"
      },
      {
        "start": 2991.48,
        "duration": 3.8,
        "text": "our Cassandra we're gonna also get"
      },
      {
        "start": 2993.2,
        "duration": 4.0,
        "text": "Cassandra Reaper and Cassandra Medusa"
      },
      {
        "start": 2995.28,
        "duration": 4.12,
        "text": "now Cassandra Reaper"
      },
      {
        "start": 2997.2,
        "duration": 4.68,
        "text": "is basically a tool to handle"
      },
      {
        "start": 2999.4,
        "duration": 4.679,
        "text": "anti-entropy repairs in Cassandra"
      },
      {
        "start": 3001.88,
        "duration": 3.84,
        "text": "anti-entropy repairs we'll get into a"
      },
      {
        "start": 3004.079,
        "duration": 3.601,
        "text": "little bit more but for now just"
      },
      {
        "start": 3005.72,
        "duration": 3.76,
        "text": "understand in a distributed system the"
      },
      {
        "start": 3007.68,
        "duration": 3.96,
        "text": "laws of physics still apply we still"
      },
      {
        "start": 3009.48,
        "duration": 4.079,
        "text": "have to deal with entropy you know"
      },
      {
        "start": 3011.64,
        "duration": 4.0,
        "text": "things being corrupted things getting"
      },
      {
        "start": 3013.559,
        "duration": 5.081,
        "text": "out of sync things generally tend"
      },
      {
        "start": 3015.64,
        "duration": 4.64,
        "text": "towards chaos and so repairs help to"
      },
      {
        "start": 3018.64,
        "duration": 4.479,
        "text": "bring things back into sync we also have"
      },
      {
        "start": 3020.28,
        "duration": 6.64,
        "text": "Cassandra Medusa which is not 100%"
      },
      {
        "start": 3023.119,
        "duration": 7.121,
        "text": "implemented today um it is like 9990"
      },
      {
        "start": 3026.92,
        "duration": 4.639,
        "text": "well 95% of the way there um we're not"
      },
      {
        "start": 3030.24,
        "duration": 2.68,
        "text": "not going to get Hands-On with it but"
      },
      {
        "start": 3031.559,
        "duration": 4.641,
        "text": "it's there and you can play with it and"
      },
      {
        "start": 3032.92,
        "duration": 5.52,
        "text": "it is also I believe in the docs um"
      },
      {
        "start": 3036.2,
        "duration": 4.52,
        "text": "currently on the C Kat"
      },
      {
        "start": 3038.44,
        "duration": 4.44,
        "text": "sandra. uh page if you wanted to read"
      },
      {
        "start": 3040.72,
        "duration": 3.72,
        "text": "about it maybe try it out yourself it is"
      },
      {
        "start": 3042.88,
        "duration": 4.36,
        "text": "a Backup Tool it is for backup and"
      },
      {
        "start": 3044.44,
        "duration": 5.8,
        "text": "restore and it basically handles all of"
      },
      {
        "start": 3047.24,
        "duration": 5.559,
        "text": "the needs you'd have around you know"
      },
      {
        "start": 3050.24,
        "duration": 4.0,
        "text": "taking Cassandra is incredibly durable"
      },
      {
        "start": 3052.799,
        "duration": 4.161,
        "text": "but you can still accidentally truncate"
      },
      {
        "start": 3054.24,
        "duration": 4.24,
        "text": "a table or or do some you know massive"
      },
      {
        "start": 3056.96,
        "duration": 6.159,
        "text": "operation that you weren't intending to"
      },
      {
        "start": 3058.48,
        "duration": 7.0,
        "text": "do it happened um that's what backups"
      },
      {
        "start": 3063.119,
        "duration": 3.401,
        "text": "are there for okay other side we got"
      },
      {
        "start": 3065.48,
        "duration": 3.639,
        "text": "grafana and"
      },
      {
        "start": 3066.52,
        "duration": 5.16,
        "text": "Prometheus grafana is a data"
      },
      {
        "start": 3069.119,
        "duration": 4.361,
        "text": "visualization tool it doesn't actually"
      },
      {
        "start": 3071.68,
        "duration": 3.32,
        "text": "collect metrics itself or do anything"
      },
      {
        "start": 3073.48,
        "duration": 3.16,
        "text": "like that it just consumes them and"
      },
      {
        "start": 3075.0,
        "duration": 3.72,
        "text": "displays them in a nice dashboard"
      },
      {
        "start": 3076.64,
        "duration": 4.24,
        "text": "Prometheus is what goes in and actually"
      },
      {
        "start": 3078.72,
        "duration": 4.839,
        "text": "collects those metrics so we are going"
      },
      {
        "start": 3080.88,
        "duration": 5.36,
        "text": "to to use Prometheus to collect the"
      },
      {
        "start": 3083.559,
        "duration": 5.161,
        "text": "metrics from our Cassandra nodes and"
      },
      {
        "start": 3086.24,
        "duration": 4.599,
        "text": "then grafana is going to consume those"
      },
      {
        "start": 3088.72,
        "duration": 4.68,
        "text": "metrics and display them in a nice easy"
      },
      {
        "start": 3090.839,
        "duration": 4.96,
        "text": "to consume dashboard all right and of"
      },
      {
        "start": 3093.4,
        "duration": 4.04,
        "text": "course Cassandra is the middle of this"
      },
      {
        "start": 3095.799,
        "duration": 2.76,
        "text": "whole thing without it we would have"
      },
      {
        "start": 3097.44,
        "duration": 4.159,
        "text": "nothing to"
      },
      {
        "start": 3098.559,
        "duration": 5.0,
        "text": "show all right features list um this is"
      },
      {
        "start": 3101.599,
        "duration": 4.72,
        "text": "kind of a wall of text but it covers a"
      },
      {
        "start": 3103.559,
        "duration": 4.121,
        "text": "lot of what Kate Sandra does currently"
      },
      {
        "start": 3106.319,
        "duration": 3.921,
        "text": "there's a couple really cool things that"
      },
      {
        "start": 3107.68,
        "duration": 5.04,
        "text": "I'd like to to point out here um rolling"
      },
      {
        "start": 3110.24,
        "duration": 5.359,
        "text": "reboots are a thing that are kind of"
      },
      {
        "start": 3112.72,
        "duration": 4.28,
        "text": "hard to do in kubernetes by default"
      },
      {
        "start": 3115.599,
        "duration": 2.96,
        "text": "that's one of the things that you'd have"
      },
      {
        "start": 3117.0,
        "duration": 3.0,
        "text": "to configure by yourself if you were"
      },
      {
        "start": 3118.559,
        "duration": 3.481,
        "text": "trying to bring Cassandra into"
      },
      {
        "start": 3120.0,
        "duration": 4.799,
        "text": "kubernetes you'd have to actually manage"
      },
      {
        "start": 3122.04,
        "duration": 5.2,
        "text": "that and set that up sorry sorry Eric I"
      },
      {
        "start": 3124.799,
        "duration": 5.0,
        "text": "just have to say you see we have some uh"
      },
      {
        "start": 3127.24,
        "duration": 5.04,
        "text": "novices as well not so familiar with"
      },
      {
        "start": 3129.799,
        "duration": 5.28,
        "text": "kubernetes so my work as a developer"
      },
      {
        "start": 3132.28,
        "duration": 5.96,
        "text": "Advocate to protect them to and just"
      },
      {
        "start": 3135.079,
        "duration": 6.561,
        "text": "word about the rolling reboot uh"
      },
      {
        "start": 3138.24,
        "duration": 5.319,
        "text": "normally if you do just uh reboot then"
      },
      {
        "start": 3141.64,
        "duration": 4.24,
        "text": "it means what you're are going to reboot"
      },
      {
        "start": 3143.559,
        "duration": 4.841,
        "text": "all your notes and then what you have"
      },
      {
        "start": 3145.88,
        "duration": 4.84,
        "text": "downtime because all replica notes are"
      },
      {
        "start": 3148.4,
        "duration": 4.439,
        "text": "going to be restarted at once and that's"
      },
      {
        "start": 3150.72,
        "duration": 4.16,
        "text": "obviously not what you want to have"
      },
      {
        "start": 3152.839,
        "duration": 4.801,
        "text": "again with Cassandra you may have zero"
      },
      {
        "start": 3154.88,
        "duration": 5.04,
        "text": "down time so rolling reboot means what"
      },
      {
        "start": 3157.64,
        "duration": 4.919,
        "text": "you when you have to apply some changes"
      },
      {
        "start": 3159.92,
        "duration": 4.639,
        "text": "or do some maintenance works you still"
      },
      {
        "start": 3162.559,
        "duration": 4.961,
        "text": "have to restart the noes but you can do"
      },
      {
        "start": 3164.559,
        "duration": 5.161,
        "text": "it one by one restarting the second one"
      },
      {
        "start": 3167.52,
        "duration": 4.44,
        "text": "only then first one has finished it"
      },
      {
        "start": 3169.72,
        "duration": 4.119,
        "text": "already and fully operational it's"
      },
      {
        "start": 3171.96,
        "duration": 6.48,
        "text": "called it rolling reboot or rolling"
      },
      {
        "start": 3173.839,
        "duration": 4.601,
        "text": "upgrade and Kate Sandra supports"
      },
      {
        "start": 3179.119,
        "duration": 4.361,
        "text": "yeah and that is really key I think you"
      },
      {
        "start": 3181.119,
        "duration": 5.081,
        "text": "you touched on the magic word there no"
      },
      {
        "start": 3183.48,
        "duration": 5.48,
        "text": "downtime right you do not want downtime"
      },
      {
        "start": 3186.2,
        "duration": 4.399,
        "text": "Cassandra is able to run indefinitely"
      },
      {
        "start": 3188.96,
        "duration": 3.839,
        "text": "without downtime if you're you know"
      },
      {
        "start": 3190.599,
        "duration": 4.0,
        "text": "geolocated across the globe across"
      },
      {
        "start": 3192.799,
        "duration": 5.04,
        "text": "providers you can pretty much guarantee"
      },
      {
        "start": 3194.599,
        "duration": 6.2,
        "text": "100% uptime if you construct it for that"
      },
      {
        "start": 3197.839,
        "duration": 4.96,
        "text": "and Kate Sandra takes advantage of that"
      },
      {
        "start": 3200.799,
        "duration": 4.681,
        "text": "it respects that and it allows you to"
      },
      {
        "start": 3202.799,
        "duration": 4.361,
        "text": "actually um actually Implement that so"
      },
      {
        "start": 3205.48,
        "duration": 5.359,
        "text": "that's really really cool"
      },
      {
        "start": 3207.16,
        "duration": 6.08,
        "text": "okay um scale up is something that is"
      },
      {
        "start": 3210.839,
        "duration": 3.921,
        "text": "very very common in Cassandra scale down"
      },
      {
        "start": 3213.24,
        "duration": 2.68,
        "text": "we're going to get into that's actually"
      },
      {
        "start": 3214.76,
        "duration": 3.599,
        "text": "something that's a little bit harder in"
      },
      {
        "start": 3215.92,
        "duration": 3.24,
        "text": "Cassandra um we have a whole Lab today"
      },
      {
        "start": 3218.359,
        "duration": 1.801,
        "text": "where we're actually going to scale"
      },
      {
        "start": 3219.16,
        "duration": 3.6,
        "text": "something up and scale it down it's"
      },
      {
        "start": 3220.16,
        "duration": 4.32,
        "text": "going to be really really awesome uh"
      },
      {
        "start": 3222.76,
        "duration": 4.079,
        "text": "gets rid of a lot of the complexity"
      },
      {
        "start": 3224.48,
        "duration": 5.8,
        "text": "there um automated repairs we talked"
      },
      {
        "start": 3226.839,
        "duration": 6.641,
        "text": "about and of course the uh metrics and"
      },
      {
        "start": 3230.28,
        "duration": 6.24,
        "text": "monitoring and all of that is built in"
      },
      {
        "start": 3233.48,
        "duration": 4.639,
        "text": "to Kate Sandra all right first exercise"
      },
      {
        "start": 3236.52,
        "duration": 3.64,
        "text": "guys right off the bat we're going to"
      },
      {
        "start": 3238.119,
        "duration": 4.641,
        "text": "get into this so setting up and"
      },
      {
        "start": 3240.16,
        "duration": 4.36,
        "text": "monitoring Cassandra we're going to go"
      },
      {
        "start": 3242.76,
        "duration": 3.839,
        "text": "to the repo here today if I can get some"
      },
      {
        "start": 3244.52,
        "duration": 7.599,
        "text": "links posted in the chats here I'll post"
      },
      {
        "start": 3246.599,
        "duration": 7.24,
        "text": "some in uh Discord and in YouTube there"
      },
      {
        "start": 3252.119,
        "duration": 3.281,
        "text": "y'all are go ahead and click that GitHub"
      },
      {
        "start": 3253.839,
        "duration": 4.201,
        "text": "link that is going to be our GitHub for"
      },
      {
        "start": 3255.4,
        "duration": 4.719,
        "text": "today the read me there on the homepage"
      },
      {
        "start": 3258.04,
        "duration": 3.88,
        "text": "has everything we are going to run"
      },
      {
        "start": 3260.119,
        "duration": 3.561,
        "text": "through it's got step by steps it's got"
      },
      {
        "start": 3261.92,
        "duration": 3.6,
        "text": "a table of contents so if you get out of"
      },
      {
        "start": 3263.68,
        "duration": 4.36,
        "text": "sync feel free to just go up the table"
      },
      {
        "start": 3265.52,
        "duration": 5.0,
        "text": "of contents go down to the step we're on"
      },
      {
        "start": 3268.04,
        "duration": 4.519,
        "text": "currently and that will bring you there"
      },
      {
        "start": 3270.52,
        "duration": 4.0,
        "text": "um we are going to go into our Cloud"
      },
      {
        "start": 3272.559,
        "duration": 3.8,
        "text": "instances here so if you don't have one"
      },
      {
        "start": 3274.52,
        "duration": 4.44,
        "text": "of those please do request one from Jack"
      },
      {
        "start": 3276.359,
        "duration": 5.44,
        "text": "frier um his email again jack if you can"
      },
      {
        "start": 3278.96,
        "duration": 5.24,
        "text": "post in the chats just let everyone know"
      },
      {
        "start": 3281.799,
        "duration": 4.04,
        "text": "where to request one of those I already"
      },
      {
        "start": 3284.2,
        "duration": 4.04,
        "text": "have one of those up today we have a"
      },
      {
        "start": 3285.839,
        "duration": 4.161,
        "text": "list of links here you'll notice that"
      },
      {
        "start": 3288.24,
        "duration": 3.559,
        "text": "everything after the first line there"
      },
      {
        "start": 3290.0,
        "duration": 3.28,
        "text": "says install first those are the things"
      },
      {
        "start": 3291.799,
        "duration": 3.481,
        "text": "we're actually going to fix so all of"
      },
      {
        "start": 3293.28,
        "duration": 4.16,
        "text": "those links should be broken if they are"
      },
      {
        "start": 3295.28,
        "duration": 5.4,
        "text": "not then we have a problem"
      },
      {
        "start": 3297.44,
        "duration": 5.56,
        "text": "um the first link there however is an"
      },
      {
        "start": 3300.68,
        "duration": 5.2,
        "text": "SSH console in your browser and what"
      },
      {
        "start": 3303.0,
        "duration": 4.079,
        "text": "that looks like is this now I will"
      },
      {
        "start": 3305.88,
        "duration": 5.08,
        "text": "actually"
      },
      {
        "start": 3307.079,
        "duration": 5.641,
        "text": "exit oops so I can log in with everyone"
      },
      {
        "start": 3310.96,
        "duration": 3.0,
        "text": "here um actually I'm just going to"
      },
      {
        "start": 3312.72,
        "duration": 3.0,
        "text": "reopen it that's probably the easiest"
      },
      {
        "start": 3313.96,
        "duration": 4.72,
        "text": "way to do it boom all right this is"
      },
      {
        "start": 3315.72,
        "duration": 5.839,
        "text": "shell in a box this allows you to"
      },
      {
        "start": 3318.68,
        "duration": 5.439,
        "text": "connect through your web browser via SSH"
      },
      {
        "start": 3321.559,
        "duration": 4.76,
        "text": "into our Cloud instances so kind of wow"
      },
      {
        "start": 3324.119,
        "duration": 4.121,
        "text": "you know a little bit meta there um if"
      },
      {
        "start": 3326.319,
        "duration": 4.401,
        "text": "if you wanted to connect over your own"
      },
      {
        "start": 3328.24,
        "duration": 4.72,
        "text": "SSH feel free to copy that URL at the"
      },
      {
        "start": 3330.72,
        "duration": 4.839,
        "text": "top of your screen go into say if you're"
      },
      {
        "start": 3332.96,
        "duration": 6.68,
        "text": "on a Mac or a Linux box you can just use"
      },
      {
        "start": 3335.559,
        "duration": 5.48,
        "text": "SSH via the terminal and uh the username"
      },
      {
        "start": 3339.64,
        "duration": 5.08,
        "text": "is going to be the same there it's"
      },
      {
        "start": 3341.039,
        "duration": 6.76,
        "text": "documented in our uh in our repo here"
      },
      {
        "start": 3344.72,
        "duration": 7.2,
        "text": "the username is ec2 user and your"
      },
      {
        "start": 3347.799,
        "duration": 5.8,
        "text": "password is data STX all right uh sorry"
      },
      {
        "start": 3351.92,
        "duration": 4.36,
        "text": "just a second if you don't have too much"
      },
      {
        "start": 3353.599,
        "duration": 5.921,
        "text": "experience with uh shell uh when you are"
      },
      {
        "start": 3356.28,
        "duration": 7.279,
        "text": "sing sshing to a new note to set up a"
      },
      {
        "start": 3359.52,
        "duration": 10.079,
        "text": "custom user you have to go SSH space uh"
      },
      {
        "start": 3363.559,
        "duration": 9.56,
        "text": "yes to- user at like in the email at um"
      },
      {
        "start": 3369.599,
        "duration": 6.401,
        "text": "and then your unique address workstation"
      },
      {
        "start": 3373.119,
        "duration": 6.24,
        "text": "something some numbers katandra DW"
      },
      {
        "start": 3376.0,
        "duration": 6.0,
        "text": "workshop. Datt training.com"
      },
      {
        "start": 3379.359,
        "duration": 5.2,
        "text": "yes that's an excellent point Alex thank"
      },
      {
        "start": 3382.0,
        "duration": 3.64,
        "text": "you all right so we're logged in now now"
      },
      {
        "start": 3384.559,
        "duration": 2.48,
        "text": "the next thing we're going to do and"
      },
      {
        "start": 3385.64,
        "duration": 3.159,
        "text": "you'll notice I'm going"
      },
      {
        "start": 3387.039,
        "duration": 3.721,
        "text": "follow through line by line pretty much"
      },
      {
        "start": 3388.799,
        "duration": 3.56,
        "text": "of this repo that's so you guys can all"
      },
      {
        "start": 3390.76,
        "duration": 3.64,
        "text": "follow along and so we can all do this"
      },
      {
        "start": 3392.359,
        "duration": 4.081,
        "text": "together all right so first thing we got"
      },
      {
        "start": 3394.4,
        "duration": 3.919,
        "text": "to do is we got to add our repository so"
      },
      {
        "start": 3396.44,
        "duration": 3.8,
        "text": "Helm is already installed on these"
      },
      {
        "start": 3398.319,
        "duration": 3.201,
        "text": "instances for us um again if you're"
      },
      {
        "start": 3400.24,
        "duration": 2.76,
        "text": "using your own box follow our"
      },
      {
        "start": 3401.52,
        "duration": 3.079,
        "text": "instructions it helps walk you through"
      },
      {
        "start": 3403.0,
        "duration": 3.76,
        "text": "the helm install process but we already"
      },
      {
        "start": 3404.599,
        "duration": 5.681,
        "text": "have it here on our instances so go"
      },
      {
        "start": 3406.76,
        "duration": 6.0,
        "text": "ahead and do the helm repo ad command"
      },
      {
        "start": 3410.28,
        "duration": 6.2,
        "text": "and you'll notice we are adding Kate"
      },
      {
        "start": 3412.76,
        "duration": 6.24,
        "text": "Sandra from the Kate sandra."
      },
      {
        "start": 3416.48,
        "duration": 5.48,
        "text": "repo going to go ahead and add that and"
      },
      {
        "start": 3419.0,
        "duration": 5.039,
        "text": "we get a success me message there"
      },
      {
        "start": 3421.96,
        "duration": 3.92,
        "text": "Perfect all right now we have to do our"
      },
      {
        "start": 3424.039,
        "duration": 4.401,
        "text": "repo update and this basically just"
      },
      {
        "start": 3425.88,
        "duration": 4.88,
        "text": "activates the repo we've just added so"
      },
      {
        "start": 3428.44,
        "duration": 5.399,
        "text": "go ahead and do that and boom happy"
      },
      {
        "start": 3430.76,
        "duration": 4.559,
        "text": "helming congrats we got there all right"
      },
      {
        "start": 3433.839,
        "duration": 3.881,
        "text": "next thing we're going to do now this"
      },
      {
        "start": 3435.319,
        "duration": 4.361,
        "text": "this is not a Kate Sandra repo this is"
      },
      {
        "start": 3437.72,
        "duration": 5.04,
        "text": "trafic trafic is actually a special"
      },
      {
        "start": 3439.68,
        "duration": 4.84,
        "text": "Ingress controller that allows us to"
      },
      {
        "start": 3442.76,
        "duration": 4.319,
        "text": "basically communicate from the outside"
      },
      {
        "start": 3444.52,
        "duration": 4.48,
        "text": "world into our cluster and we're we're"
      },
      {
        "start": 3447.079,
        "duration": 4.0,
        "text": "going to do a lot of configuration of it"
      },
      {
        "start": 3449.0,
        "duration": 4.039,
        "text": "throughout our commands but uh"
      },
      {
        "start": 3451.079,
        "duration": 3.601,
        "text": "essentially this just allows us to"
      },
      {
        "start": 3453.039,
        "duration": 3.601,
        "text": "actually talk to what we're working with"
      },
      {
        "start": 3454.68,
        "duration": 3.84,
        "text": "here today so we're going to go ahead"
      },
      {
        "start": 3456.64,
        "duration": 5.04,
        "text": "and we're going to add the repo for"
      },
      {
        "start": 3458.52,
        "duration": 6.48,
        "text": "traic and we're going to need to do"
      },
      {
        "start": 3461.68,
        "duration": 6.08,
        "text": "another Helm repo update activating the"
      },
      {
        "start": 3465.0,
        "duration": 6.24,
        "text": "traic repo as usable for us so let's go"
      },
      {
        "start": 3467.76,
        "duration": 6.16,
        "text": "and do that and again we get a success"
      },
      {
        "start": 3471.24,
        "duration": 4.68,
        "text": "Perfect all right so now let's do a hel"
      },
      {
        "start": 3473.92,
        "duration": 2.76,
        "text": "install let's install our Ingress first"
      },
      {
        "start": 3475.92,
        "duration": 3.0,
        "text": "here"
      },
      {
        "start": 3476.68,
        "duration": 5.359,
        "text": "this is going to use the yaml file"
      },
      {
        "start": 3478.92,
        "duration": 5.24,
        "text": "you'll notice the trafic values. yaml so"
      },
      {
        "start": 3482.039,
        "duration": 3.881,
        "text": "I'm going to go ahead and I'm going to"
      },
      {
        "start": 3484.16,
        "duration": 4.08,
        "text": "run that and this will take it just a"
      },
      {
        "start": 3485.92,
        "duration": 3.96,
        "text": "moment here and boom done and I'll"
      },
      {
        "start": 3488.24,
        "duration": 4.52,
        "text": "actually show you guys in the directory"
      },
      {
        "start": 3489.88,
        "duration": 4.64,
        "text": "here we have a whole bunch of EML we"
      },
      {
        "start": 3492.76,
        "duration": 4.12,
        "text": "have our kind config which is what our"
      },
      {
        "start": 3494.52,
        "duration": 4.24,
        "text": "actual provisioning step of this this"
      },
      {
        "start": 3496.88,
        "duration": 3.959,
        "text": "cluster um you don't ever have to use it"
      },
      {
        "start": 3498.76,
        "duration": 4.279,
        "text": "but that's what uh the our the scripts"
      },
      {
        "start": 3500.839,
        "duration": 5.28,
        "text": "we used uh to provision this cluster"
      },
      {
        "start": 3503.039,
        "duration": 4.601,
        "text": "used to configure it we have our pet"
      },
      {
        "start": 3506.119,
        "duration": 4.2,
        "text": "clinic. which we'll get to in a few"
      },
      {
        "start": 3507.64,
        "duration": 4.439,
        "text": "minutes we have our set our readmes"
      },
      {
        "start": 3510.319,
        "duration": 3.561,
        "text": "which are basically the instruction sets"
      },
      {
        "start": 3512.079,
        "duration": 4.321,
        "text": "and then we have this trafic values. and"
      },
      {
        "start": 3513.88,
        "duration": 5.32,
        "text": "I'm just going to cat that real quick"
      },
      {
        "start": 3516.4,
        "duration": 5.76,
        "text": "traic values. and we'll see there's just"
      },
      {
        "start": 3519.2,
        "duration": 4.44,
        "text": "a couple ports specified um just a"
      },
      {
        "start": 3522.16,
        "duration": 3.8,
        "text": "really simple file it's just basically"
      },
      {
        "start": 3523.64,
        "duration": 3.88,
        "text": "saying hey we're setting up this Ingress"
      },
      {
        "start": 3525.96,
        "duration": 4.32,
        "text": "set it up with these particular ports"
      },
      {
        "start": 3527.52,
        "duration": 5.12,
        "text": "right off the bat and let's go so"
      },
      {
        "start": 3530.28,
        "duration": 4.6,
        "text": "nothing too complex there yet just still"
      },
      {
        "start": 3532.64,
        "duration": 4.56,
        "text": "pretty simple stuff next we're going to"
      },
      {
        "start": 3534.88,
        "duration": 5.04,
        "text": "go and we're going to install our Kate"
      },
      {
        "start": 3537.2,
        "duration": 5.28,
        "text": "Sandra tools now Kate Sandra tools is"
      },
      {
        "start": 3539.92,
        "duration": 4.48,
        "text": "the first step here towards getting Kate"
      },
      {
        "start": 3542.48,
        "duration": 3.96,
        "text": "Sandra running what it is is basically"
      },
      {
        "start": 3544.4,
        "duration": 4.76,
        "text": "all the individual components you need"
      },
      {
        "start": 3546.44,
        "duration": 5.04,
        "text": "to actually set up a a Kate Sandra"
      },
      {
        "start": 3549.16,
        "duration": 4.12,
        "text": "cluster so all of the individual things"
      },
      {
        "start": 3551.48,
        "duration": 3.359,
        "text": "that are going to be used should be"
      },
      {
        "start": 3553.28,
        "duration": 4.16,
        "text": "included here and we'll give that just a"
      },
      {
        "start": 3554.839,
        "duration": 5.161,
        "text": "moment again to complete one thing"
      },
      {
        "start": 3557.44,
        "duration": 3.76,
        "text": "that's actually interesting to note um"
      },
      {
        "start": 3560.0,
        "duration": 3.039,
        "text": "when these actually complete you'll"
      },
      {
        "start": 3561.2,
        "duration": 3.56,
        "text": "notice we have a couple a couple lines"
      },
      {
        "start": 3563.039,
        "duration": 3.76,
        "text": "here with information first thing to"
      },
      {
        "start": 3564.76,
        "duration": 4.279,
        "text": "notice is that revision line"
      },
      {
        "start": 3566.799,
        "duration": 4.921,
        "text": "revision is basically every time you"
      },
      {
        "start": 3569.039,
        "duration": 4.04,
        "text": "make a change that will increment so"
      },
      {
        "start": 3571.72,
        "duration": 3.48,
        "text": "every time you do what's called a Helm"
      },
      {
        "start": 3573.079,
        "duration": 4.201,
        "text": "upgrade command it will increment it by"
      },
      {
        "start": 3575.2,
        "duration": 3.56,
        "text": "one so as we go and scale stuff we'll"
      },
      {
        "start": 3577.28,
        "duration": 2.519,
        "text": "actually I'll point it out to you again"
      },
      {
        "start": 3578.76,
        "duration": 3.12,
        "text": "there but that's going to start"
      },
      {
        "start": 3579.799,
        "duration": 4.04,
        "text": "incrementing for us we also have the"
      },
      {
        "start": 3581.88,
        "duration": 3.36,
        "text": "last date that something was deployed"
      },
      {
        "start": 3583.839,
        "duration": 4.601,
        "text": "the name space which of course today"
      },
      {
        "start": 3585.24,
        "duration": 6.0,
        "text": "we're using default and of course the"
      },
      {
        "start": 3588.44,
        "duration": 5.32,
        "text": "status which is deployed in this case"
      },
      {
        "start": 3591.24,
        "duration": 4.52,
        "text": "all right so it looks like our home"
      },
      {
        "start": 3593.76,
        "duration": 3.72,
        "text": "install command worked for the Cassandra"
      },
      {
        "start": 3595.76,
        "duration": 3.559,
        "text": "or Kate Sandra tools goodness that is"
      },
      {
        "start": 3597.48,
        "duration": 4.839,
        "text": "hard to remember to say Kate Sandra not"
      },
      {
        "start": 3599.319,
        "duration": 5.961,
        "text": "Cassandra you know what I bet at some"
      },
      {
        "start": 3602.319,
        "duration": 6.841,
        "text": "point we will stop making any uh"
      },
      {
        "start": 3605.28,
        "duration": 6.48,
        "text": "differences between when I'm sure we we"
      },
      {
        "start": 3609.16,
        "duration": 4.12,
        "text": "most likely will okay here we're"
      },
      {
        "start": 3611.76,
        "duration": 3.0,
        "text": "actually installing the cluster now"
      },
      {
        "start": 3613.28,
        "duration": 4.44,
        "text": "you'll notice we've done the Ingress"
      },
      {
        "start": 3614.76,
        "duration": 5.76,
        "text": "configuration in this command again I"
      },
      {
        "start": 3617.72,
        "duration": 5.76,
        "text": "I'll just say down the road this will be"
      },
      {
        "start": 3620.52,
        "duration": 5.519,
        "text": "done automatically for you in the actual"
      },
      {
        "start": 3623.48,
        "duration": 5.24,
        "text": "Helm install commands but today we're"
      },
      {
        "start": 3626.039,
        "duration": 4.401,
        "text": "not at that point yet so uh we just have"
      },
      {
        "start": 3628.72,
        "duration": 3.28,
        "text": "to kind of do it ourselves and let it"
      },
      {
        "start": 3630.44,
        "duration": 2.84,
        "text": "run so I'm going to go ahead and click"
      },
      {
        "start": 3632.0,
        "duration": 3.92,
        "text": "enter"
      },
      {
        "start": 3633.28,
        "duration": 5.6,
        "text": "there and we will give you guys a moment"
      },
      {
        "start": 3635.92,
        "duration": 4.96,
        "text": "to catch up here as that goes and I am"
      },
      {
        "start": 3638.88,
        "duration": 4.36,
        "text": "just going to go into Cube I'm going to"
      },
      {
        "start": 3640.88,
        "duration": 4.64,
        "text": "watch Cube CTL so we can watch this come"
      },
      {
        "start": 3643.24,
        "duration": 2.28,
        "text": "up"
      },
      {
        "start": 3646.4,
        "duration": 6.76,
        "text": "so get pods and let's let that run and"
      },
      {
        "start": 3651.559,
        "duration": 3.601,
        "text": "we're going to watch those come up here"
      },
      {
        "start": 3653.16,
        "duration": 3.679,
        "text": "now it's going to take you know 2 three"
      },
      {
        "start": 3655.16,
        "duration": 3.6,
        "text": "minutes for those to actually all come"
      },
      {
        "start": 3656.839,
        "duration": 4.121,
        "text": "online and you're going to notice that"
      },
      {
        "start": 3658.76,
        "duration": 4.44,
        "text": "there's some errors that pop up don't"
      },
      {
        "start": 3660.96,
        "duration": 4.2,
        "text": "worry about it it it it is currently"
      },
      {
        "start": 3663.2,
        "duration": 3.56,
        "text": "Again release candidate stuff some of"
      },
      {
        "start": 3665.16,
        "duration": 3.48,
        "text": "the stuff hasn't been set up to launch"
      },
      {
        "start": 3666.76,
        "duration": 5.079,
        "text": "in specific orders so we're actually"
      },
      {
        "start": 3668.64,
        "duration": 5.64,
        "text": "relying currently on some pod"
      },
      {
        "start": 3671.839,
        "duration": 4.601,
        "text": "failures um and then they basically"
      },
      {
        "start": 3674.28,
        "duration": 4.48,
        "text": "redeploy themselves um they're waiting"
      },
      {
        "start": 3676.44,
        "duration": 5.2,
        "text": "for some of the previous steps to fin y"
      },
      {
        "start": 3678.76,
        "duration": 5.4,
        "text": "uh sorry but that's a perfect time uh to"
      },
      {
        "start": 3681.64,
        "duration": 6.52,
        "text": "give some time to our attendees to catch"
      },
      {
        "start": 3684.16,
        "duration": 6.08,
        "text": "up and follow the steps so uh"
      },
      {
        "start": 3688.16,
        "duration": 3.72,
        "text": "yeah yeah yeah absolutely we're going to"
      },
      {
        "start": 3690.24,
        "duration": 7.119,
        "text": "wait here for a minute so definitely get"
      },
      {
        "start": 3691.88,
        "duration": 5.479,
        "text": "caught up if you can and uh"
      },
      {
        "start": 3697.52,
        "duration": 6.24,
        "text": "yeah all right see do we have any"
      },
      {
        "start": 3700.559,
        "duration": 5.401,
        "text": "questions in chat there uh all answer it"
      },
      {
        "start": 3703.76,
        "duration": 4.4,
        "text": "the main one was can we go a bit slower"
      },
      {
        "start": 3705.96,
        "duration": 4.72,
        "text": "please can go slower I'm sorry I I'm"
      },
      {
        "start": 3708.16,
        "duration": 4.28,
        "text": "talking very fast I I realize that I I"
      },
      {
        "start": 3710.68,
        "duration": 4.84,
        "text": "will work on slowing down call me out on"
      },
      {
        "start": 3712.44,
        "duration": 3.96,
        "text": "it if I don't uh so take a look while uh"
      },
      {
        "start": 3715.52,
        "duration": 3.2,
        "text": "we"
      },
      {
        "start": 3716.4,
        "duration": 4.959,
        "text": "um have time to catch up and do the"
      },
      {
        "start": 3718.72,
        "duration": 5.24,
        "text": "steps uh people use it to hurry on"
      },
      {
        "start": 3721.359,
        "duration": 4.841,
        "text": "during the workshop because as soon as"
      },
      {
        "start": 3723.96,
        "duration": 4.599,
        "text": "Workshop has gone speakers are not"
      },
      {
        "start": 3726.2,
        "duration": 4.8,
        "text": "available and training instance are not"
      },
      {
        "start": 3728.559,
        "duration": 6.681,
        "text": "available and nothing work works and"
      },
      {
        "start": 3731.0,
        "duration": 7.2,
        "text": "workshop is over not for us we are the"
      },
      {
        "start": 3735.24,
        "duration": 6.079,
        "text": "data Stacks developers and we care so we"
      },
      {
        "start": 3738.2,
        "duration": 6.32,
        "text": "want this Workshop available for you as"
      },
      {
        "start": 3741.319,
        "duration": 6.441,
        "text": "long as you want for it to be available"
      },
      {
        "start": 3744.52,
        "duration": 6.36,
        "text": "so okay we cannot run training instances"
      },
      {
        "start": 3747.76,
        "duration": 5.4,
        "text": "for too long because we're are counting"
      },
      {
        "start": 3750.88,
        "duration": 4.64,
        "text": "all together the workshops from"
      },
      {
        "start": 3753.16,
        "duration": 6.439,
        "text": "yesterday and today and tomorrow we are"
      },
      {
        "start": 3755.52,
        "duration": 6.559,
        "text": "around 1,000 of them so that's uh pretty"
      },
      {
        "start": 3759.599,
        "duration": 6.841,
        "text": "expensive to us we have to stop them"
      },
      {
        "start": 3762.079,
        "duration": 6.921,
        "text": "after 24 hours but um in general we are"
      },
      {
        "start": 3766.44,
        "duration": 5.679,
        "text": "always here for you answering the"
      },
      {
        "start": 3769.0,
        "duration": 6.039,
        "text": "questions at our Discord server and also"
      },
      {
        "start": 3772.119,
        "duration": 5.96,
        "text": "at the community. DAT stacks.com so"
      },
      {
        "start": 3775.039,
        "duration": 4.601,
        "text": "Workshop lasts as long as you want it to"
      },
      {
        "start": 3778.079,
        "duration": 4.161,
        "text": "be running"
      },
      {
        "start": 3779.64,
        "duration": 4.76,
        "text": "okay yeah we had a request to zoom in"
      },
      {
        "start": 3782.24,
        "duration": 3.92,
        "text": "here um is that large enough I just"
      },
      {
        "start": 3784.4,
        "duration": 4.679,
        "text": "zoomed in a little bit"
      },
      {
        "start": 3786.16,
        "duration": 5.24,
        "text": "there answer in chat there if you can"
      },
      {
        "start": 3789.079,
        "duration": 4.801,
        "text": "hopefully y'all can see it all right and"
      },
      {
        "start": 3791.4,
        "duration": 6.84,
        "text": "I see a question from pressat cut and"
      },
      {
        "start": 3793.88,
        "duration": 9.199,
        "text": "paste doesn't work in Cloud instance"
      },
      {
        "start": 3798.24,
        "duration": 6.76,
        "text": "well if uh if you're going to the repo"
      },
      {
        "start": 3803.079,
        "duration": 3.361,
        "text": "and copying out of our our little code"
      },
      {
        "start": 3805.0,
        "duration": 3.64,
        "text": "blocks there"
      },
      {
        "start": 3806.44,
        "duration": 4.2,
        "text": "um it should work with just the normal"
      },
      {
        "start": 3808.64,
        "duration": 3.639,
        "text": "copy paste commands I've been using uh"
      },
      {
        "start": 3810.64,
        "duration": 3.959,
        "text": "I'm on a Mac I've been using command C"
      },
      {
        "start": 3812.279,
        "duration": 4.32,
        "text": "and command V this whole time but um you"
      },
      {
        "start": 3814.599,
        "duration": 3.76,
        "text": "can also I believe right click and copy"
      },
      {
        "start": 3816.599,
        "duration": 4.161,
        "text": "paste a little more manually that way"
      },
      {
        "start": 3818.359,
        "duration": 5.321,
        "text": "yeah so there were some uh problems I've"
      },
      {
        "start": 3820.76,
        "duration": 5.96,
        "text": "heard of before personally I recommend"
      },
      {
        "start": 3823.68,
        "duration": 6.399,
        "text": "you to use a normal terminal or puty"
      },
      {
        "start": 3826.72,
        "duration": 5.599,
        "text": "iterm if you are on Mac or any another"
      },
      {
        "start": 3830.079,
        "duration": 6.681,
        "text": "application you prefer to connect"
      },
      {
        "start": 3832.319,
        "duration": 7.04,
        "text": "because well uh bash in a browser"
      },
      {
        "start": 3836.76,
        "duration": 4.68,
        "text": "that's only for those who cannot have"
      },
      {
        "start": 3839.359,
        "duration": 3.801,
        "text": "anything else but in general we"
      },
      {
        "start": 3841.44,
        "duration": 4.72,
        "text": "recommend to use"
      },
      {
        "start": 3843.16,
        "duration": 4.8,
        "text": "SSH yeah yeah absolutely and the only"
      },
      {
        "start": 3846.16,
        "duration": 4.959,
        "text": "reason I'm using the uh what is it the"
      },
      {
        "start": 3847.96,
        "duration": 4.92,
        "text": "shell in a box here is because um I'm"
      },
      {
        "start": 3851.119,
        "duration": 4.041,
        "text": "trying to make it as close of a thing to"
      },
      {
        "start": 3852.88,
        "duration": 4.0,
        "text": "what what you know you guys are are"
      },
      {
        "start": 3855.16,
        "duration": 3.439,
        "text": "provided with as possible otherwise I"
      },
      {
        "start": 3856.88,
        "duration": 6.479,
        "text": "would totally be in the command line"
      },
      {
        "start": 3858.599,
        "duration": 7.68,
        "text": "myself on my own uh SSH console but all"
      },
      {
        "start": 3863.359,
        "duration": 5.72,
        "text": "right let's see a couple of copy paste"
      },
      {
        "start": 3866.279,
        "duration": 5.121,
        "text": "wouldn't work either"
      },
      {
        "start": 3869.079,
        "duration": 6.881,
        "text": "um"
      },
      {
        "start": 3871.4,
        "duration": 6.56,
        "text": "option yeah interesting I am not sure"
      },
      {
        "start": 3875.96,
        "duration": 3.319,
        "text": "about the working with windows that I've"
      },
      {
        "start": 3877.96,
        "duration": 4.159,
        "text": "never had a problem with that in the"
      },
      {
        "start": 3879.279,
        "duration": 6.76,
        "text": "past um I would try the right click"
      },
      {
        "start": 3882.119,
        "duration": 5.44,
        "text": "method and uh see if that works if not"
      },
      {
        "start": 3886.039,
        "duration": 4.161,
        "text": "um there is a tool out there called"
      },
      {
        "start": 3887.559,
        "duration": 4.48,
        "text": "putty which will allow you to SSH as"
      },
      {
        "start": 3890.2,
        "duration": 3.32,
        "text": "well um highly recommend having that"
      },
      {
        "start": 3892.039,
        "duration": 3.32,
        "text": "tool if you're on Windows anyway I think"
      },
      {
        "start": 3893.52,
        "duration": 3.96,
        "text": "almost every Windows computer I've ever"
      },
      {
        "start": 3895.359,
        "duration": 4.281,
        "text": "had I have I have installed putty like"
      },
      {
        "start": 3897.48,
        "duration": 4.799,
        "text": "first or second thing um and that will"
      },
      {
        "start": 3899.64,
        "duration": 6.12,
        "text": "allow you to actually SSH with the same"
      },
      {
        "start": 3902.279,
        "duration": 5.241,
        "text": "SSH command there using the URL and uh"
      },
      {
        "start": 3905.76,
        "duration": 4.839,
        "text": "that should work right now you could"
      },
      {
        "start": 3907.52,
        "duration": 6.039,
        "text": "focus on what's uh Eric doing and then"
      },
      {
        "start": 3910.599,
        "duration": 6.561,
        "text": "do the same steps on your own after the"
      },
      {
        "start": 3913.559,
        "duration": 7.04,
        "text": "uh Workshop uh using party"
      },
      {
        "start": 3917.16,
        "duration": 7.48,
        "text": "indeed um"
      },
      {
        "start": 3920.599,
        "duration": 6.041,
        "text": "yeah all right so we've got some things"
      },
      {
        "start": 3924.64,
        "duration": 4.199,
        "text": "are completing here here looks like"
      },
      {
        "start": 3926.64,
        "duration": 5.36,
        "text": "we've got our nodes are up we can see"
      },
      {
        "start": 3928.839,
        "duration": 5.801,
        "text": "the Kate Sandra dc1 default is now two"
      },
      {
        "start": 3932.0,
        "duration": 4.68,
        "text": "of two which is excellent we have the"
      },
      {
        "start": 3934.64,
        "duration": 4.12,
        "text": "schema is now completed so you'll notice"
      },
      {
        "start": 3936.68,
        "duration": 5.08,
        "text": "that is the only zero of one on that"
      },
      {
        "start": 3938.76,
        "duration": 5.24,
        "text": "list under ready um that is just a step"
      },
      {
        "start": 3941.76,
        "duration": 4.76,
        "text": "that basically goes through and takes"
      },
      {
        "start": 3944.0,
        "duration": 5.039,
        "text": "the reaper schema and applies it to the"
      },
      {
        "start": 3946.52,
        "duration": 3.88,
        "text": "cassander once it comes online so Reaper"
      },
      {
        "start": 3949.039,
        "duration": 5.32,
        "text": "which is that repair tool we talked"
      },
      {
        "start": 3950.4,
        "duration": 6.12,
        "text": "about earlier is using Cassandra to"
      },
      {
        "start": 3954.359,
        "duration": 4.081,
        "text": "store its data so it is actually"
      },
      {
        "start": 3956.52,
        "duration": 4.48,
        "text": "utilizing the thing it is repairing kind"
      },
      {
        "start": 3958.44,
        "duration": 4.159,
        "text": "of cool um but it does need to to"
      },
      {
        "start": 3961.0,
        "duration": 4.16,
        "text": "install the schema once Cassandra is"
      },
      {
        "start": 3962.599,
        "duration": 5.081,
        "text": "actually up all right let's see a couple"
      },
      {
        "start": 3965.16,
        "duration": 5.24,
        "text": "more questions here really quick um can"
      },
      {
        "start": 3967.68,
        "duration": 4.119,
        "text": "we run SQL yes there are ways to do it"
      },
      {
        "start": 3970.4,
        "duration": 6.159,
        "text": "we're not going to do it here today but"
      },
      {
        "start": 3971.799,
        "duration": 6.841,
        "text": "yes you can um let's see here all right"
      },
      {
        "start": 3976.559,
        "duration": 4.28,
        "text": "I think we're good to continue so I am"
      },
      {
        "start": 3978.64,
        "duration": 6.439,
        "text": "going to go ahead and contrl C out of my"
      },
      {
        "start": 3980.839,
        "duration": 6.401,
        "text": "Cube c Watch there and let's go over and"
      },
      {
        "start": 3985.079,
        "duration": 6.601,
        "text": "look at our next step"
      },
      {
        "start": 3987.24,
        "duration": 5.76,
        "text": "now we are at the the uh uh Point here"
      },
      {
        "start": 3991.68,
        "duration": 4.28,
        "text": "where we're actually going to go in and"
      },
      {
        "start": 3993.0,
        "duration": 5.559,
        "text": "start looking at what our monitoring is"
      },
      {
        "start": 3995.96,
        "duration": 4.599,
        "text": "so let's go to our links list you'll"
      },
      {
        "start": 3998.559,
        "duration": 4.24,
        "text": "notice this first one or this sorry this"
      },
      {
        "start": 4000.559,
        "duration": 3.601,
        "text": "second uh line here is for Prometheus"
      },
      {
        "start": 4002.799,
        "duration": 4.681,
        "text": "let's go in there and take a quick look"
      },
      {
        "start": 4004.16,
        "duration": 5.48,
        "text": "at that so Prometheus here doesn't"
      },
      {
        "start": 4007.48,
        "duration": 3.839,
        "text": "actually display anything you know nice"
      },
      {
        "start": 4009.64,
        "duration": 4.0,
        "text": "and pretty for us to look at but what it"
      },
      {
        "start": 4011.319,
        "duration": 6.04,
        "text": "will show you is our node and it shows"
      },
      {
        "start": 4013.64,
        "duration": 5.56,
        "text": "you the uh what being scraped how often"
      },
      {
        "start": 4017.359,
        "duration": 4.121,
        "text": "it's being scraped how long it's taking"
      },
      {
        "start": 4019.2,
        "duration": 4.0,
        "text": "to scrape that data basically just shows"
      },
      {
        "start": 4021.48,
        "duration": 3.28,
        "text": "us that we are in fact getting metrics"
      },
      {
        "start": 4023.2,
        "duration": 3.32,
        "text": "and we are in fact healthy it's a great"
      },
      {
        "start": 4024.76,
        "duration": 3.72,
        "text": "troubleshooting step if for some reason"
      },
      {
        "start": 4026.52,
        "duration": 4.36,
        "text": "we weren't getting any data in our"
      },
      {
        "start": 4028.48,
        "duration": 6.76,
        "text": "grafana the second thing we're going to"
      },
      {
        "start": 4030.88,
        "duration": 8.399,
        "text": "here is grafana now for all of you the"
      },
      {
        "start": 4035.24,
        "duration": 6.839,
        "text": "uh username admin and the password of"
      },
      {
        "start": 4039.279,
        "duration": 5.241,
        "text": "secret is what you guys will use to log"
      },
      {
        "start": 4042.079,
        "duration": 5.601,
        "text": "in by default now if you go to"
      },
      {
        "start": 4044.52,
        "duration": 6.2,
        "text": "dashboards and and you go to manage you"
      },
      {
        "start": 4047.68,
        "duration": 5.119,
        "text": "will see this default space here"
      },
      {
        "start": 4050.72,
        "duration": 3.52,
        "text": "obviously in the final release again"
      },
      {
        "start": 4052.799,
        "duration": 2.8,
        "text": "we're on release candidate in the final"
      },
      {
        "start": 4054.24,
        "duration": 2.92,
        "text": "release those will be a little more"
      },
      {
        "start": 4055.599,
        "duration": 3.76,
        "text": "accessible they're kind of buried here"
      },
      {
        "start": 4057.16,
        "duration": 4.32,
        "text": "in the first release it's it's something"
      },
      {
        "start": 4059.359,
        "duration": 4.041,
        "text": "where you know they're they are there"
      },
      {
        "start": 4061.48,
        "duration": 3.079,
        "text": "but they're just not super upfront and"
      },
      {
        "start": 4063.4,
        "duration": 3.439,
        "text": "we can actually see we're collecting"
      },
      {
        "start": 4064.559,
        "duration": 4.121,
        "text": "metrics already so we are connected we"
      },
      {
        "start": 4066.839,
        "duration": 3.881,
        "text": "are actually getting data and we're"
      },
      {
        "start": 4068.68,
        "duration": 5.08,
        "text": "actually able to monitor our Cassandra"
      },
      {
        "start": 4070.72,
        "duration": 5.24,
        "text": "cluster via grafana and Prometheus"
      },
      {
        "start": 4073.76,
        "duration": 5.48,
        "text": "pretty cool I didn't configure any"
      },
      {
        "start": 4075.96,
        "duration": 5.56,
        "text": "I didn't configure any Prometheus it is"
      },
      {
        "start": 4079.24,
        "duration": 4.079,
        "text": "basically there for me when I run the"
      },
      {
        "start": 4081.52,
        "duration": 4.319,
        "text": "commands and I'm I'm sorry I keep using"
      },
      {
        "start": 4083.319,
        "duration": 4.841,
        "text": "the word RC this is basically a beta um"
      },
      {
        "start": 4085.839,
        "duration": 4.76,
        "text": "correct term would be a beta so uh just"
      },
      {
        "start": 4088.16,
        "duration": 4.399,
        "text": "correcting myself there all right I'm"
      },
      {
        "start": 4090.599,
        "duration": 3.96,
        "text": "going to go ahead and I'm going to uh"
      },
      {
        "start": 4092.559,
        "duration": 4.24,
        "text": "I'm going to actually leave grafana open"
      },
      {
        "start": 4094.559,
        "duration": 5.961,
        "text": "but I'm going to close Prometheus and"
      },
      {
        "start": 4096.799,
        "duration": 5.44,
        "text": "we're going to go back to our GitHub and"
      },
      {
        "start": 4100.52,
        "duration": 2.88,
        "text": "that brings us to step two now before we"
      },
      {
        "start": 4102.239,
        "duration": 2.681,
        "text": "get to step two I'm going to show you"
      },
      {
        "start": 4103.4,
        "duration": 2.68,
        "text": "just a couple more slides just like two"
      },
      {
        "start": 4104.92,
        "duration": 3.759,
        "text": "or three and then we're going to jump"
      },
      {
        "start": 4106.08,
        "duration": 5.8,
        "text": "right back into it all right so working"
      },
      {
        "start": 4108.679,
        "duration": 4.361,
        "text": "with data having a database is great but"
      },
      {
        "start": 4111.88,
        "duration": 3.2,
        "text": "if we can't do anything with that"
      },
      {
        "start": 4113.04,
        "duration": 3.799,
        "text": "database it's useless so what are we"
      },
      {
        "start": 4115.08,
        "duration": 4.159,
        "text": "going to do today we're going to run the"
      },
      {
        "start": 4116.839,
        "duration": 6.161,
        "text": "pet clinic app now uh Cedric who's one"
      },
      {
        "start": 4119.239,
        "duration": 6.92,
        "text": "of my Advocate uh counterparts here uh"
      },
      {
        "start": 4123.0,
        "duration": 6.279,
        "text": "he wrote a spring app called uh pet"
      },
      {
        "start": 4126.159,
        "duration": 6.0,
        "text": "clinic it is uh"
      },
      {
        "start": 4129.279,
        "duration": 5.4,
        "text": "fully uh what's the word I'm looking for"
      },
      {
        "start": 4132.159,
        "duration": 4.16,
        "text": "containerized goodness my brain just"
      },
      {
        "start": 4134.679,
        "duration": 3.281,
        "text": "blinked there for for a moment it is"
      },
      {
        "start": 4136.319,
        "duration": 4.561,
        "text": "fully containerized and we'll actually"
      },
      {
        "start": 4137.96,
        "duration": 4.359,
        "text": "deploy it with kubernetes alongside of"
      },
      {
        "start": 4140.88,
        "duration": 4.399,
        "text": "our Kate"
      },
      {
        "start": 4142.319,
        "duration": 4.641,
        "text": "Sandra um so there I said just a couple"
      },
      {
        "start": 4145.279,
        "duration": 4.4,
        "text": "slides I kept my promise it was actually"
      },
      {
        "start": 4146.96,
        "duration": 5.44,
        "text": "one slide let's get into it first thing"
      },
      {
        "start": 4149.679,
        "duration": 5.321,
        "text": "we have to do is we have to retrieve"
      },
      {
        "start": 4152.4,
        "duration": 5.6,
        "text": "what our Cassandra password is our user"
      },
      {
        "start": 4155.0,
        "duration": 5.44,
        "text": "password is from the secret now K Sandra"
      },
      {
        "start": 4158.0,
        "duration": 3.759,
        "text": "sets up a secret for us when it sets up"
      },
      {
        "start": 4160.44,
        "duration": 3.6,
        "text": "Cassandra so we're actually going to"
      },
      {
        "start": 4161.759,
        "duration": 5.361,
        "text": "have to go in and we are going to have"
      },
      {
        "start": 4164.04,
        "duration": 6.679,
        "text": "to run a command to get that and you'll"
      },
      {
        "start": 4167.12,
        "duration": 8.079,
        "text": "notice here this giant alpha numeric"
      },
      {
        "start": 4170.719,
        "duration": 6.04,
        "text": "string is our password now normally I'll"
      },
      {
        "start": 4175.199,
        "duration": 5.56,
        "text": "actually show you something here um so"
      },
      {
        "start": 4176.759,
        "duration": 5.92,
        "text": "if we LS ER Eric don't run don't run"
      },
      {
        "start": 4180.759,
        "duration": 4.721,
        "text": "that's not a"
      },
      {
        "start": 4182.679,
        "duration": 5.881,
        "text": "Marone slowing down"
      },
      {
        "start": 4185.48,
        "duration": 6.16,
        "text": "again all right what I'll show you here"
      },
      {
        "start": 4188.56,
        "duration": 5.36,
        "text": "is if we look at that pet clinic. yaml"
      },
      {
        "start": 4191.64,
        "duration": 4.36,
        "text": "that we saw earlier we're going to go"
      },
      {
        "start": 4193.92,
        "duration": 5.2,
        "text": "ahead and we're going to cat that so pet"
      },
      {
        "start": 4196.0,
        "duration": 5.12,
        "text": "clinic. yaml and we'll notice a few"
      },
      {
        "start": 4199.12,
        "duration": 3.76,
        "text": "things here first I'm going to scroll up"
      },
      {
        "start": 4201.12,
        "duration": 3.52,
        "text": "towards the top we have this whole"
      },
      {
        "start": 4202.88,
        "duration": 3.76,
        "text": "Cassandra password field and right now"
      },
      {
        "start": 4204.64,
        "duration": 3.599,
        "text": "it's just got gibberish that's not"
      },
      {
        "start": 4206.64,
        "duration": 2.8,
        "text": "actually a valid cassander password"
      },
      {
        "start": 4208.239,
        "duration": 2.601,
        "text": "we're going to have to put our own in"
      },
      {
        "start": 4209.44,
        "duration": 3.4,
        "text": "there now we aren't going to do it"
      },
      {
        "start": 4210.84,
        "duration": 4.24,
        "text": "oursel we're going to use a said command"
      },
      {
        "start": 4212.84,
        "duration": 5.68,
        "text": "to take advantage of the power of Linux"
      },
      {
        "start": 4215.08,
        "duration": 5.04,
        "text": "and do it but uh it's gon to it's going"
      },
      {
        "start": 4218.52,
        "duration": 3.719,
        "text": "to be replaced with that string we just"
      },
      {
        "start": 4220.12,
        "duration": 4.68,
        "text": "retrieved next thing I'm going to show"
      },
      {
        "start": 4222.239,
        "duration": 5.081,
        "text": "you is right down here at the bottom we"
      },
      {
        "start": 4224.8,
        "duration": 5.64,
        "text": "have this Ingress section where we we're"
      },
      {
        "start": 4227.32,
        "duration": 6.16,
        "text": "setting up a bunch of ports now those"
      },
      {
        "start": 4230.44,
        "duration": 5.759,
        "text": "ports are going to be applied to our"
      },
      {
        "start": 4233.48,
        "duration": 4.04,
        "text": "traic Ingress so that thing we set up at"
      },
      {
        "start": 4236.199,
        "duration": 3.361,
        "text": "the beginning so that we could access"
      },
      {
        "start": 4237.52,
        "duration": 4.0,
        "text": "our graan Prometheus is also going to be"
      },
      {
        "start": 4239.56,
        "duration": 3.84,
        "text": "what allows us to get into our pet"
      },
      {
        "start": 4241.52,
        "duration": 3.679,
        "text": "clinic app and that's both for the back"
      },
      {
        "start": 4243.4,
        "duration": 4.799,
        "text": "end and the front end of that"
      },
      {
        "start": 4245.199,
        "duration": 6.681,
        "text": "application so let's go ahead here and"
      },
      {
        "start": 4248.199,
        "duration": 8.48,
        "text": "I'm going to uh copy the said"
      },
      {
        "start": 4251.88,
        "duration": 8.52,
        "text": "command and I am going to paste it here"
      },
      {
        "start": 4256.679,
        "duration": 7.801,
        "text": "and now if I cat that file again so"
      },
      {
        "start": 4260.4,
        "duration": 6.759,
        "text": "catpet clinic. yaml and let's scroll up"
      },
      {
        "start": 4264.48,
        "duration": 5.16,
        "text": "and there we go voila we have our"
      },
      {
        "start": 4267.159,
        "duration": 5.801,
        "text": "password in there now so our app should"
      },
      {
        "start": 4269.64,
        "duration": 6.0,
        "text": "be able to connect to our Cassandra"
      },
      {
        "start": 4272.96,
        "duration": 4.84,
        "text": "instance all right now we're going to go"
      },
      {
        "start": 4275.64,
        "duration": 4.519,
        "text": "ahead and do kind of the Moment of Truth"
      },
      {
        "start": 4277.8,
        "duration": 4.68,
        "text": "step and we're going to apply our pet"
      },
      {
        "start": 4280.159,
        "duration": 4.641,
        "text": "clinic. yaml and what that's going to do"
      },
      {
        "start": 4282.48,
        "duration": 4.12,
        "text": "I'll actually show you Cube CTL here so"
      },
      {
        "start": 4284.8,
        "duration": 4.6,
        "text": "Cube"
      },
      {
        "start": 4286.6,
        "duration": 6.72,
        "text": "CTL get actually let me watch on this so"
      },
      {
        "start": 4289.4,
        "duration": 5.2,
        "text": "we can watch it come up watch Cube CTL"
      },
      {
        "start": 4293.32,
        "duration": 3.44,
        "text": "get"
      },
      {
        "start": 4294.6,
        "duration": 4.36,
        "text": "pods and what's going to happen here is"
      },
      {
        "start": 4296.76,
        "duration": 4.84,
        "text": "you notice we have these container"
      },
      {
        "start": 4298.96,
        "duration": 4.04,
        "text": "creating on Pet Clinic front end pet"
      },
      {
        "start": 4301.6,
        "duration": 3.52,
        "text": "clinic back end and they're really"
      },
      {
        "start": 4303.0,
        "duration": 3.719,
        "text": "really fast boom they're up I almost"
      },
      {
        "start": 4305.12,
        "duration": 5.4,
        "text": "missed it I was so slow typing that"
      },
      {
        "start": 4306.719,
        "duration": 5.761,
        "text": "command those pods that just popped up"
      },
      {
        "start": 4310.52,
        "duration": 4.159,
        "text": "are our application that is the pet"
      },
      {
        "start": 4312.48,
        "duration": 4.64,
        "text": "clinic application and if I were to go"
      },
      {
        "start": 4314.679,
        "duration": 4.96,
        "text": "back to my links list and I were to"
      },
      {
        "start": 4317.12,
        "duration": 5.599,
        "text": "click on the pet clinic demo"
      },
      {
        "start": 4319.639,
        "duration": 4.681,
        "text": "app we will see it will load up here now"
      },
      {
        "start": 4322.719,
        "duration": 3.041,
        "text": "I I'll show you one more thing before we"
      },
      {
        "start": 4324.32,
        "duration": 3.56,
        "text": "actually interact with this because it's"
      },
      {
        "start": 4325.76,
        "duration": 5.28,
        "text": "kind of interesting that Ingress we've"
      },
      {
        "start": 4327.88,
        "duration": 5.0,
        "text": "been working with is uh also on your"
      },
      {
        "start": 4331.04,
        "duration": 3.679,
        "text": "links list and it actually has a web UI"
      },
      {
        "start": 4332.88,
        "duration": 3.92,
        "text": "that you can go in and next to Services"
      },
      {
        "start": 4334.719,
        "duration": 4.48,
        "text": "I'm just going to click explore and I"
      },
      {
        "start": 4336.8,
        "duration": 4.48,
        "text": "can actually see what's set up as"
      },
      {
        "start": 4339.199,
        "duration": 4.401,
        "text": "ingresses we've got our grafana here"
      },
      {
        "start": 4341.28,
        "duration": 4.439,
        "text": "we've got Prometheus we've got our our"
      },
      {
        "start": 4343.6,
        "duration": 3.76,
        "text": "Reaper and we've got our pet"
      },
      {
        "start": 4345.719,
        "duration": 3.401,
        "text": "all right there in this list and we can"
      },
      {
        "start": 4347.36,
        "duration": 3.08,
        "text": "just go look at them and see what's"
      },
      {
        "start": 4349.12,
        "duration": 3.32,
        "text": "configured kind of an interesting"
      },
      {
        "start": 4350.44,
        "duration": 3.6,
        "text": "troubleshooting tool not really super"
      },
      {
        "start": 4352.44,
        "duration": 3.96,
        "text": "relevant to us here today but it's just"
      },
      {
        "start": 4354.04,
        "duration": 5.96,
        "text": "pretty cool all right closing that out"
      },
      {
        "start": 4356.4,
        "duration": 5.96,
        "text": "and going back to our pet clinic so now"
      },
      {
        "start": 4360.0,
        "duration": 4.639,
        "text": "that we have an app connected let's"
      },
      {
        "start": 4362.36,
        "duration": 3.96,
        "text": "actually work with some data first thing"
      },
      {
        "start": 4364.639,
        "duration": 3.641,
        "text": "we're going to do we're going to go to"
      },
      {
        "start": 4366.32,
        "duration": 3.839,
        "text": "pet types and we're going to look at the"
      },
      {
        "start": 4368.28,
        "duration": 4.68,
        "text": "different pet types that are configured"
      },
      {
        "start": 4370.159,
        "duration": 5.52,
        "text": "now these are stored in Cassandra"
      },
      {
        "start": 4372.96,
        "duration": 4.52,
        "text": "currently uh we have dog bird all of"
      },
      {
        "start": 4375.679,
        "duration": 4.841,
        "text": "that those are actually in a cassander"
      },
      {
        "start": 4377.48,
        "duration": 6.12,
        "text": "table and instead of having to go in and"
      },
      {
        "start": 4380.52,
        "duration": 6.36,
        "text": "type an actual you know statement to"
      },
      {
        "start": 4383.6,
        "duration": 6.88,
        "text": "delete or modify or update I am going to"
      },
      {
        "start": 4386.88,
        "duration": 5.88,
        "text": "just click delete here and just to prove"
      },
      {
        "start": 4390.48,
        "duration": 3.64,
        "text": "I'm not you know kind of doing some hand"
      },
      {
        "start": 4392.76,
        "duration": 2.479,
        "text": "wavess and that something actually"
      },
      {
        "start": 4394.12,
        "duration": 3.079,
        "text": "deleted from the database I'm going to"
      },
      {
        "start": 4395.239,
        "duration": 4.0,
        "text": "refresh my page just to show you guys"
      },
      {
        "start": 4397.199,
        "duration": 3.761,
        "text": "that yes it is indeed gone this isn't"
      },
      {
        "start": 4399.239,
        "duration": 4.081,
        "text": "something that's cached on the web and I"
      },
      {
        "start": 4400.96,
        "duration": 3.6,
        "text": "can just delete and hahaa it looks cool"
      },
      {
        "start": 4403.32,
        "duration": 3.319,
        "text": "I actually deleted something from my"
      },
      {
        "start": 4404.56,
        "duration": 5.079,
        "text": "database now if I wanted to add"
      },
      {
        "start": 4406.639,
        "duration": 5.841,
        "text": "something what should we add uh let's"
      },
      {
        "start": 4409.639,
        "duration": 4.481,
        "text": "add we have snake let's add oh we have"
      },
      {
        "start": 4412.48,
        "duration": 4.0,
        "text": "cat goodness we've added most things"
      },
      {
        "start": 4414.12,
        "duration": 6.039,
        "text": "let's add Bird right back in then so"
      },
      {
        "start": 4416.48,
        "duration": 8.52,
        "text": "let's add Bird go ahead and save and we"
      },
      {
        "start": 4420.159,
        "duration": 6.48,
        "text": "have bird back in the list now again I"
      },
      {
        "start": 4425.0,
        "duration": 3.88,
        "text": "will refresh my page just to kind of"
      },
      {
        "start": 4426.639,
        "duration": 4.481,
        "text": "prove that this is in fact happening and"
      },
      {
        "start": 4428.88,
        "duration": 4.12,
        "text": "it notice it sorted it now the reason it"
      },
      {
        "start": 4431.12,
        "duration": 3.4,
        "text": "did that is we were using clustering"
      },
      {
        "start": 4433.0,
        "duration": 3.639,
        "text": "columns which are a way to order your"
      },
      {
        "start": 4434.52,
        "duration": 3.76,
        "text": "data inside Cassandra they're way to"
      },
      {
        "start": 4436.639,
        "duration": 2.801,
        "text": "order and provide uniqueness but in this"
      },
      {
        "start": 4438.28,
        "duration": 3.359,
        "text": "case the important part is that they're"
      },
      {
        "start": 4439.44,
        "duration": 5.04,
        "text": "ordering it so that when we refresh the"
      },
      {
        "start": 4441.639,
        "duration": 7.56,
        "text": "page it reordered and boom that's what"
      },
      {
        "start": 4444.48,
        "duration": 7.4,
        "text": "we had all right so we have now removed"
      },
      {
        "start": 4449.199,
        "duration": 6.44,
        "text": "and added data to our Cassandra through"
      },
      {
        "start": 4451.88,
        "duration": 5.799,
        "text": "an app just by copying over a single"
      },
      {
        "start": 4455.639,
        "duration": 4.201,
        "text": "password the user access password and"
      },
      {
        "start": 4457.679,
        "duration": 4.0,
        "text": "this is all done through the the driver"
      },
      {
        "start": 4459.84,
        "duration": 4.359,
        "text": "this is actually the under the hood this"
      },
      {
        "start": 4461.679,
        "duration": 5.56,
        "text": "is the the spring uh stuff which all"
      },
      {
        "start": 4464.199,
        "duration": 5.801,
        "text": "runs on the Java driver all"
      },
      {
        "start": 4467.239,
        "duration": 5.4,
        "text": "right going back here I think that is"
      },
      {
        "start": 4470.0,
        "duration": 3.84,
        "text": "all for this section let me just verify"
      },
      {
        "start": 4472.639,
        "duration": 4.801,
        "text": "that really quick so I'm not getting"
      },
      {
        "start": 4473.84,
        "duration": 6.319,
        "text": "ahead of myself yes okay perfect so next"
      },
      {
        "start": 4477.44,
        "duration": 5.4,
        "text": "session or section we are going to move"
      },
      {
        "start": 4480.159,
        "duration": 4.04,
        "text": "on here now this is the cool part this"
      },
      {
        "start": 4482.84,
        "duration": 4.12,
        "text": "is the part that just makes me so"
      },
      {
        "start": 4484.199,
        "duration": 5.0,
        "text": "excited uh I'll try to talk slow because"
      },
      {
        "start": 4486.96,
        "duration": 3.56,
        "text": "I get excited here you can probably tell"
      },
      {
        "start": 4489.199,
        "duration": 4.361,
        "text": "I get excited about this stuff because"
      },
      {
        "start": 4490.52,
        "duration": 6.52,
        "text": "of just how uh energized it makes me but"
      },
      {
        "start": 4493.56,
        "duration": 5.36,
        "text": "okay in Sandra it's very easy to scale"
      },
      {
        "start": 4497.04,
        "duration": 3.84,
        "text": "up a cluster it's a lot harder to scale"
      },
      {
        "start": 4498.92,
        "duration": 3.92,
        "text": "down a cluster but it is possible there"
      },
      {
        "start": 4500.88,
        "duration": 3.319,
        "text": "are ways to do it but it requires a lot"
      },
      {
        "start": 4502.84,
        "duration": 3.64,
        "text": "of cleanup steps there's a lot of"
      },
      {
        "start": 4504.199,
        "duration": 5.04,
        "text": "rebalancing stuff that actually happens"
      },
      {
        "start": 4506.48,
        "duration": 5.28,
        "text": "um and it it is kind of a job to to do"
      },
      {
        "start": 4509.239,
        "duration": 5.4,
        "text": "it is possible but it's a job there are"
      },
      {
        "start": 4511.76,
        "duration": 5.76,
        "text": "two ways in Kate Sandra that we can"
      },
      {
        "start": 4514.639,
        "duration": 4.201,
        "text": "accomplish these steps now the first one"
      },
      {
        "start": 4517.52,
        "duration": 2.639,
        "text": "is through config files we could"
      },
      {
        "start": 4518.84,
        "duration": 4.359,
        "text": "actually go in and we could edit some"
      },
      {
        "start": 4520.159,
        "duration": 4.801,
        "text": "yaml and we could resize things and then"
      },
      {
        "start": 4523.199,
        "duration": 4.361,
        "text": "we could let Helm take care of the rest"
      },
      {
        "start": 4524.96,
        "duration": 4.239,
        "text": "gretes and Helm take care of the rest or"
      },
      {
        "start": 4527.56,
        "duration": 2.639,
        "text": "we can just do it with a Helm upgrade"
      },
      {
        "start": 4529.199,
        "duration": 2.641,
        "text": "command and that's what we're going to"
      },
      {
        "start": 4530.199,
        "duration": 5.0,
        "text": "do today is we're going to use Helm"
      },
      {
        "start": 4531.84,
        "duration": 5.56,
        "text": "upgrade to go through and handle all of"
      },
      {
        "start": 4535.199,
        "duration": 6.48,
        "text": "those operations that we need to do"
      },
      {
        "start": 4537.4,
        "duration": 6.92,
        "text": "automatically for us all right so going"
      },
      {
        "start": 4541.679,
        "duration": 5.361,
        "text": "back to the exercises it's now section"
      },
      {
        "start": 4544.32,
        "duration": 4.72,
        "text": "three if you uh if you're trailing along"
      },
      {
        "start": 4547.04,
        "duration": 3.4,
        "text": "uh feel free to or following along feel"
      },
      {
        "start": 4549.04,
        "duration": 3.32,
        "text": "free to go down to section three and"
      },
      {
        "start": 4550.44,
        "duration": 3.719,
        "text": "we'll get started here first thing I'm"
      },
      {
        "start": 4552.36,
        "duration": 3.359,
        "text": "actually going to do I'm going to do a"
      },
      {
        "start": 4554.159,
        "duration": 3.881,
        "text": "hel get manif"
      },
      {
        "start": 4555.719,
        "duration": 5.48,
        "text": "now I better edit out of my exit out of"
      },
      {
        "start": 4558.04,
        "duration": 6.28,
        "text": "my qctl Helm get manifest basically"
      },
      {
        "start": 4561.199,
        "duration": 5.641,
        "text": "shows me what is currently running in my"
      },
      {
        "start": 4564.32,
        "duration": 4.52,
        "text": "cluster now you'll notice Let's uh go"
      },
      {
        "start": 4566.84,
        "duration": 4.48,
        "text": "ahead and control C out of this because"
      },
      {
        "start": 4568.84,
        "duration": 5.08,
        "text": "that's going to go on for a while you'll"
      },
      {
        "start": 4571.32,
        "duration": 4.839,
        "text": "notice up there I had a bunch of yaml"
      },
      {
        "start": 4573.92,
        "duration": 5.16,
        "text": "files and they are for all sorts of"
      },
      {
        "start": 4576.159,
        "duration": 5.801,
        "text": "things we got a castdc yaml we've got a"
      },
      {
        "start": 4579.08,
        "duration": 5.52,
        "text": "deployment yaml all of these things are"
      },
      {
        "start": 4581.96,
        "duration": 4.4,
        "text": "basically where the magic is happening"
      },
      {
        "start": 4584.6,
        "duration": 4.32,
        "text": "that is is allowing us to deploy these"
      },
      {
        "start": 4586.36,
        "duration": 5.68,
        "text": "things without needing to set them all"
      },
      {
        "start": 4588.92,
        "duration": 5.799,
        "text": "up ourselves so all of these amals are"
      },
      {
        "start": 4592.04,
        "duration": 4.44,
        "text": "are kind of they are what make Kate"
      },
      {
        "start": 4594.719,
        "duration": 3.681,
        "text": "Sandra Kate Sandra is all this"
      },
      {
        "start": 4596.48,
        "duration": 4.12,
        "text": "preconfigured stuff now interestingly"
      },
      {
        "start": 4598.4,
        "duration": 6.0,
        "text": "enough I mentioned Helm is a templating"
      },
      {
        "start": 4600.6,
        "duration": 5.639,
        "text": "language Helm allows us to make certain"
      },
      {
        "start": 4604.4,
        "duration": 2.88,
        "text": "parts of these animals dynamic as we"
      },
      {
        "start": 4606.239,
        "duration": 3.281,
        "text": "need to and that's what we're going to"
      },
      {
        "start": 4607.28,
        "duration": 5.16,
        "text": "be manipulating here is uh something"
      },
      {
        "start": 4609.52,
        "duration": 5.44,
        "text": "that was dynamically configured so let's"
      },
      {
        "start": 4612.44,
        "duration": 3.92,
        "text": "go ahead and let's clear"
      },
      {
        "start": 4614.96,
        "duration": 3.52,
        "text": "for me to type and talk at the same time"
      },
      {
        "start": 4616.36,
        "duration": 4.24,
        "text": "all right there we go so now we're"
      },
      {
        "start": 4618.48,
        "duration": 3.8,
        "text": "starting fresh with the console there"
      },
      {
        "start": 4620.6,
        "duration": 4.16,
        "text": "we're going to go ahead and we're going"
      },
      {
        "start": 4622.28,
        "duration": 5.08,
        "text": "to try to find the value that we are"
      },
      {
        "start": 4624.76,
        "duration": 4.8,
        "text": "looking for which in this case is size"
      },
      {
        "start": 4627.36,
        "duration": 4.08,
        "text": "size is how many nodes we have in our"
      },
      {
        "start": 4629.56,
        "duration": 5.04,
        "text": "cluster and you'll see it is configured"
      },
      {
        "start": 4631.44,
        "duration": 5.4,
        "text": "to one if we want to change this we can"
      },
      {
        "start": 4634.6,
        "duration": 4.119,
        "text": "go through and we can use the helm"
      },
      {
        "start": 4636.84,
        "duration": 5.64,
        "text": "upgrade command now you'll notice all of"
      },
      {
        "start": 4638.719,
        "duration": 6.361,
        "text": "our Ingress set plags are uh in this"
      },
      {
        "start": 4642.48,
        "duration": 4.88,
        "text": "command the reason for that is anything"
      },
      {
        "start": 4645.08,
        "duration": 4.36,
        "text": "set this way needs to be included in the"
      },
      {
        "start": 4647.36,
        "duration": 4.2,
        "text": "command otherwise it gets reset to the"
      },
      {
        "start": 4649.44,
        "duration": 4.4,
        "text": "default so we would basically lose all"
      },
      {
        "start": 4651.56,
        "duration": 4.24,
        "text": "of our Ingress from this cluster and we"
      },
      {
        "start": 4653.84,
        "duration": 5.319,
        "text": "don't want to do that so let's go ahead"
      },
      {
        "start": 4655.8,
        "duration": 5.8,
        "text": "here and let's apply our Helm upgrade"
      },
      {
        "start": 4659.159,
        "duration": 3.921,
        "text": "command oh did it not copy I guess it"
      },
      {
        "start": 4661.6,
        "duration": 5.16,
        "text": "didn't"
      },
      {
        "start": 4663.08,
        "duration": 5.639,
        "text": "copy and paste all right there we go so"
      },
      {
        "start": 4666.76,
        "duration": 3.439,
        "text": "going to go ahead and hit enter on that"
      },
      {
        "start": 4668.719,
        "duration": 4.92,
        "text": "and then you know what I'm going to do"
      },
      {
        "start": 4670.199,
        "duration": 5.161,
        "text": "is I am going to uh grip that size again"
      },
      {
        "start": 4673.639,
        "duration": 3.721,
        "text": "oops did we not"
      },
      {
        "start": 4675.36,
        "duration": 3.839,
        "text": "Helm upgrade requires two arguments did"
      },
      {
        "start": 4677.36,
        "duration": 3.839,
        "text": "I"
      },
      {
        "start": 4679.199,
        "duration": 4.241,
        "text": "miss I think I didn't copy the whole"
      },
      {
        "start": 4681.199,
        "duration": 5.121,
        "text": "thing Helm upgrade"
      },
      {
        "start": 4683.44,
        "duration": 4.239,
        "text": "cerer there we go all right it applied"
      },
      {
        "start": 4686.32,
        "duration": 3.2,
        "text": "and you'll notice my revision is now at"
      },
      {
        "start": 4687.679,
        "duration": 3.121,
        "text": "two actually so I should have noticed"
      },
      {
        "start": 4689.52,
        "duration": 3.679,
        "text": "that when I hit enter there I just was"
      },
      {
        "start": 4690.8,
        "duration": 4.28,
        "text": "moving a little too fast um that's"
      },
      {
        "start": 4693.199,
        "duration": 4.081,
        "text": "because I have now made a change and so"
      },
      {
        "start": 4695.08,
        "duration": 6.159,
        "text": "it now it automatically increments that"
      },
      {
        "start": 4697.28,
        "duration": 6.399,
        "text": "revision number all right let's go and"
      },
      {
        "start": 4701.239,
        "duration": 4.081,
        "text": "retrieve our value there we go there we"
      },
      {
        "start": 4703.679,
        "duration": 5.161,
        "text": "go you notice we set that to three in"
      },
      {
        "start": 4705.32,
        "duration": 6.0,
        "text": "our Command up here so K sand Sandra set"
      },
      {
        "start": 4708.84,
        "duration": 7.399,
        "text": "size right here set size"
      },
      {
        "start": 4711.32,
        "duration": 7.44,
        "text": "to three and that is what basically went"
      },
      {
        "start": 4716.239,
        "duration": 4.601,
        "text": "and resized our entire cluster now to"
      },
      {
        "start": 4718.76,
        "duration": 3.399,
        "text": "prove this is actually resizing I'm"
      },
      {
        "start": 4720.84,
        "duration": 3.56,
        "text": "going to go into Cube"
      },
      {
        "start": 4722.159,
        "duration": 6.641,
        "text": "C actually I'm going to watch it again"
      },
      {
        "start": 4724.4,
        "duration": 11.4,
        "text": "because watching is much more uh much"
      },
      {
        "start": 4728.8,
        "duration": 8.96,
        "text": "better in my opinion Cube CTL get pods"
      },
      {
        "start": 4735.8,
        "duration": 4.72,
        "text": "and there we go we see that we have two"
      },
      {
        "start": 4737.76,
        "duration": 4.68,
        "text": "nodes that are also initializing here"
      },
      {
        "start": 4740.52,
        "duration": 3.159,
        "text": "now those are going to take a moment and"
      },
      {
        "start": 4742.44,
        "duration": 4.239,
        "text": "I don't really want to do anything until"
      },
      {
        "start": 4743.679,
        "duration": 4.681,
        "text": "they're up but those nodes are now full"
      },
      {
        "start": 4746.679,
        "duration": 3.52,
        "text": "standard nodes they are actually running"
      },
      {
        "start": 4748.36,
        "duration": 3.279,
        "text": "and if we were to say go into grafana"
      },
      {
        "start": 4750.199,
        "duration": 4.241,
        "text": "here in a moment which we'll do once"
      },
      {
        "start": 4751.639,
        "duration": 5.281,
        "text": "they show up we'll actually see metrics"
      },
      {
        "start": 4754.44,
        "duration": 4.64,
        "text": "being collected from those nodes as well"
      },
      {
        "start": 4756.92,
        "duration": 3.56,
        "text": "pretty cool all right let's give it a"
      },
      {
        "start": 4759.08,
        "duration": 4.32,
        "text": "moment here and give you guys a moment"
      },
      {
        "start": 4760.48,
        "duration": 5.92,
        "text": "to catch up as well any questions there"
      },
      {
        "start": 4763.4,
        "duration": 3.0,
        "text": "Alex"
      },
      {
        "start": 4767.199,
        "duration": 6.761,
        "text": "y see here uh so not so much where do"
      },
      {
        "start": 4771.52,
        "duration": 6.199,
        "text": "those two notes start up very good"
      },
      {
        "start": 4773.96,
        "duration": 6.84,
        "text": "question by Kevin that's one we should"
      },
      {
        "start": 4777.719,
        "duration": 4.681,
        "text": "answer um sorry so the question was what"
      },
      {
        "start": 4780.8,
        "duration": 7.64,
        "text": "where did the notes start uh yes uh if"
      },
      {
        "start": 4782.4,
        "duration": 10.08,
        "text": "you would simply do uh Cube CTL get ps-"
      },
      {
        "start": 4788.44,
        "duration": 8.36,
        "text": "W I will explain a couple of things yeah"
      },
      {
        "start": 4792.48,
        "duration": 7.4,
        "text": "yeah let me do that here so Cube"
      },
      {
        "start": 4796.8,
        "duration": 9.0,
        "text": "CTL get"
      },
      {
        "start": 4799.88,
        "duration": 10.04,
        "text": "pods you said slw uh P get ports d"
      },
      {
        "start": 4805.8,
        "duration": 12.76,
        "text": "o DH o space"
      },
      {
        "start": 4809.92,
        "duration": 12.48,
        "text": "w w uh yep like that uh oh my god"
      },
      {
        "start": 4818.56,
        "duration": 4.92,
        "text": "um yeah sorry that's a pretty late uh"
      },
      {
        "start": 4822.4,
        "duration": 4.6,
        "text": "for me"
      },
      {
        "start": 4823.48,
        "duration": 8.32,
        "text": "already uh uh"
      },
      {
        "start": 4827.0,
        "duration": 4.8,
        "text": "yes looks good wait a"
      },
      {
        "start": 4832.6,
        "duration": 5.96,
        "text": "second while I'm trying to remember uh"
      },
      {
        "start": 4836.12,
        "duration": 5.039,
        "text": "question how many data centers are here"
      },
      {
        "start": 4838.56,
        "duration": 5.32,
        "text": "in this cluster that's only one single"
      },
      {
        "start": 4841.159,
        "duration": 4.401,
        "text": "data center cluster because that's a"
      },
      {
        "start": 4843.88,
        "duration": 5.839,
        "text": "educational"
      },
      {
        "start": 4845.56,
        "duration": 7.0,
        "text": "exercise uh there we go uh yeah thank"
      },
      {
        "start": 4849.719,
        "duration": 6.801,
        "text": "you so good and can you make it a little"
      },
      {
        "start": 4852.56,
        "duration": 6.0,
        "text": "bit smaller then so it will be uh yes I"
      },
      {
        "start": 4856.52,
        "duration": 6.84,
        "text": "can let"
      },
      {
        "start": 4858.56,
        "duration": 8.28,
        "text": "me yeah uh thank you d o white"
      },
      {
        "start": 4863.36,
        "duration": 7.52,
        "text": "uh that's at my place that's almost 8:00"
      },
      {
        "start": 4866.84,
        "duration": 6.96,
        "text": "p.m. and it was a very long day okay so"
      },
      {
        "start": 4870.88,
        "duration": 5.799,
        "text": "what and do it again yeah and may you"
      },
      {
        "start": 4873.8,
        "duration": 6.28,
        "text": "push enter sometimes so it will scroll"
      },
      {
        "start": 4876.679,
        "duration": 6.161,
        "text": "up a bit oh yeah let me uh clear and"
      },
      {
        "start": 4880.08,
        "duration": 6.44,
        "text": "then I'll I'll run it again okay also"
      },
      {
        "start": 4882.84,
        "duration": 6.839,
        "text": "works there we go yep perfect so take a"
      },
      {
        "start": 4886.52,
        "duration": 7.44,
        "text": "look there are some uh things I want to"
      },
      {
        "start": 4889.679,
        "duration": 7.241,
        "text": "answer first of all uh we run these uh"
      },
      {
        "start": 4893.96,
        "duration": 6.8,
        "text": "that's a kubernetes cluster but we have"
      },
      {
        "start": 4896.92,
        "duration": 6.319,
        "text": "only one um machine running that so you"
      },
      {
        "start": 4900.76,
        "duration": 5.16,
        "text": "have every one of you have one machine"
      },
      {
        "start": 4903.239,
        "duration": 6.081,
        "text": "when we are going to have multiple"
      },
      {
        "start": 4905.92,
        "duration": 5.52,
        "text": "workers uh we use kind for wet so"
      },
      {
        "start": 4909.32,
        "duration": 5.96,
        "text": "technically that's all the kubernetes in"
      },
      {
        "start": 4911.44,
        "duration": 7.92,
        "text": "a doer cluster uh but even in this case"
      },
      {
        "start": 4915.28,
        "duration": 6.84,
        "text": "KAS kandra cares of the data allocation"
      },
      {
        "start": 4919.36,
        "duration": 6.52,
        "text": "and replica allocation over the cluster"
      },
      {
        "start": 4922.12,
        "duration": 7.8,
        "text": "so you see on the left part K Sandra dc1"
      },
      {
        "start": 4925.88,
        "duration": 6.96,
        "text": "stateful default STS Z one and two can"
      },
      {
        "start": 4929.92,
        "duration": 6.319,
        "text": "you could you please highlight them uh"
      },
      {
        "start": 4932.84,
        "duration": 7.6,
        "text": "stateful sets stateful sets Services"
      },
      {
        "start": 4936.239,
        "duration": 8.44,
        "text": "yeah those those free y yep uh so take a"
      },
      {
        "start": 4940.44,
        "duration": 7.279,
        "text": "look they allocated on kind worker kind"
      },
      {
        "start": 4944.679,
        "duration": 6.921,
        "text": "worker two and kind worker three and"
      },
      {
        "start": 4947.719,
        "duration": 6.401,
        "text": "that's not a coincidence every next note"
      },
      {
        "start": 4951.6,
        "duration": 7.4,
        "text": "uh Kate sandre will try to launch on the"
      },
      {
        "start": 4954.12,
        "duration": 10.119,
        "text": "next available free note uh so to spread"
      },
      {
        "start": 4959.0,
        "duration": 5.239,
        "text": "the notes over the cluster and to have"
      },
      {
        "start": 4964.4,
        "duration": 6.88,
        "text": "higher higher full tolerance in case one"
      },
      {
        "start": 4967.84,
        "duration": 7.48,
        "text": "of the kubernetes workers fails so we"
      },
      {
        "start": 4971.28,
        "duration": 7.12,
        "text": "have fre worker notes and uh therefore"
      },
      {
        "start": 4975.32,
        "duration": 5.8,
        "text": "we have kandra three of them on"
      },
      {
        "start": 4978.4,
        "duration": 5.08,
        "text": "different kubernetes worker notes that's"
      },
      {
        "start": 4981.12,
        "duration": 3.8,
        "text": "not a coincidence that's the intention"
      },
      {
        "start": 4983.48,
        "duration": 6.199,
        "text": "of kidan"
      },
      {
        "start": 4984.92,
        "duration": 9.319,
        "text": "R uh well then we were one more question"
      },
      {
        "start": 4989.679,
        "duration": 9.361,
        "text": "by prasat K I'm not seeing 2/2 import"
      },
      {
        "start": 4994.239,
        "duration": 9.561,
        "text": "listing so if you again watch those um"
      },
      {
        "start": 4999.04,
        "duration": 7.159,
        "text": "STS kandra default STS 01 and two they"
      },
      {
        "start": 5003.8,
        "duration": 5.56,
        "text": "okay V I don't know why the third one"
      },
      {
        "start": 5006.199,
        "duration": 5.201,
        "text": "has one out of two but H it's it's"
      },
      {
        "start": 5009.36,
        "duration": 5.879,
        "text": "rolling it's rolling ah it's rolling"
      },
      {
        "start": 5011.4,
        "duration": 7.64,
        "text": "okay yeah so every kfandra Casandra"
      },
      {
        "start": 5015.239,
        "duration": 5.601,
        "text": "default STS has 2/2 it means what we"
      },
      {
        "start": 5019.04,
        "duration": 5.199,
        "text": "have two"
      },
      {
        "start": 5020.84,
        "duration": 5.879,
        "text": "containers uh in one port and one"
      },
      {
        "start": 5024.239,
        "duration": 4.281,
        "text": "container as I said before is Cassandra"
      },
      {
        "start": 5026.719,
        "duration": 4.681,
        "text": "and second is a side"
      },
      {
        "start": 5028.52,
        "duration": 4.52,
        "text": "car yes and and you'll notice there that"
      },
      {
        "start": 5031.4,
        "duration": 3.88,
        "text": "when I reran that command so I wasn't"
      },
      {
        "start": 5033.04,
        "duration": 3.92,
        "text": "running watch on that command before um"
      },
      {
        "start": 5035.28,
        "duration": 4.68,
        "text": "that's why it was static there just so I"
      },
      {
        "start": 5036.96,
        "duration": 5.08,
        "text": "could uh highlight things for Alex um"
      },
      {
        "start": 5039.96,
        "duration": 5.199,
        "text": "but you'll notice I ran it again and now"
      },
      {
        "start": 5042.04,
        "duration": 4.159,
        "text": "that pod is online with two of two so it"
      },
      {
        "start": 5045.159,
        "duration": 3.961,
        "text": "is"
      },
      {
        "start": 5046.199,
        "duration": 6.121,
        "text": "complete and that's a great question"
      },
      {
        "start": 5049.12,
        "duration": 5.96,
        "text": "when upscale what are the seed nodes and"
      },
      {
        "start": 5052.32,
        "duration": 5.64,
        "text": "that's the lovely thing thank you noo"
      },
      {
        "start": 5055.08,
        "duration": 5.599,
        "text": "for asking because from now on you don't"
      },
      {
        "start": 5057.96,
        "duration": 6.0,
        "text": "care about that because Kate Sandra"
      },
      {
        "start": 5060.679,
        "duration": 4.641,
        "text": "cares about takes care of it for you you"
      },
      {
        "start": 5063.96,
        "duration": 5.32,
        "text": "don't have to"
      },
      {
        "start": 5065.32,
        "duration": 7.24,
        "text": "worry yeah uh all poorts would end with"
      },
      {
        "start": 5069.28,
        "duration": 6.8,
        "text": "STS are Cassandra poorts well uh yes and"
      },
      {
        "start": 5072.56,
        "duration": 7.36,
        "text": "no uh in all ports with STS are stateful"
      },
      {
        "start": 5076.08,
        "duration": 7.079,
        "text": "sets and kandra uses stateful sets so in"
      },
      {
        "start": 5079.92,
        "duration": 5.96,
        "text": "this case yes all the notes with SS in"
      },
      {
        "start": 5083.159,
        "duration": 6.52,
        "text": "the end are Cassandra notes"
      },
      {
        "start": 5085.88,
        "duration": 5.48,
        "text": "exactly yeah all right I think we get"
      },
      {
        "start": 5089.679,
        "duration": 3.401,
        "text": "we're going to move on here we got about"
      },
      {
        "start": 5091.36,
        "duration": 4.04,
        "text": "22 minutes which should be enough to get"
      },
      {
        "start": 5093.08,
        "duration": 5.639,
        "text": "through the rest of this have a"
      },
      {
        "start": 5095.4,
        "duration": 5.36,
        "text": "quiz oh that's right we do all right so"
      },
      {
        "start": 5098.719,
        "duration": 5.241,
        "text": "since we saw those were online you know"
      },
      {
        "start": 5100.76,
        "duration": 6.56,
        "text": "I'll actually go here to grafana quick"
      },
      {
        "start": 5103.96,
        "duration": 6.6,
        "text": "and we'll notice right down at my node"
      },
      {
        "start": 5107.32,
        "duration": 6.24,
        "text": "status we've got three nodes Isn't that"
      },
      {
        "start": 5110.56,
        "duration": 5.04,
        "text": "cool we got three nodes so now we're"
      },
      {
        "start": 5113.56,
        "duration": 4.44,
        "text": "actually Gathering data from all three"
      },
      {
        "start": 5115.6,
        "duration": 4.32,
        "text": "nodes which is just awesome we didn't"
      },
      {
        "start": 5118.0,
        "duration": 4.239,
        "text": "have to configure anything again it"
      },
      {
        "start": 5119.92,
        "duration": 4.56,
        "text": "handled it all for us it it added them"
      },
      {
        "start": 5122.239,
        "duration": 4.601,
        "text": "to the metrics and the monitoring and"
      },
      {
        "start": 5124.48,
        "duration": 6.04,
        "text": "it's done simple as that it was"
      },
      {
        "start": 5126.84,
        "duration": 6.52,
        "text": "basically a one command uh operation to"
      },
      {
        "start": 5130.52,
        "duration": 5.96,
        "text": "add two more nodes to the entire thing"
      },
      {
        "start": 5133.36,
        "duration": 4.72,
        "text": "that's just so cool all right going back"
      },
      {
        "start": 5136.48,
        "duration": 5.4,
        "text": "to it we're gonna actually size it back"
      },
      {
        "start": 5138.08,
        "duration": 6.079,
        "text": "down now I said this before sizing a"
      },
      {
        "start": 5141.88,
        "duration": 4.16,
        "text": "cander cluster down takes a lot of work"
      },
      {
        "start": 5144.159,
        "duration": 4.241,
        "text": "it's possible it's doable but it takes a"
      },
      {
        "start": 5146.04,
        "duration": 4.72,
        "text": "lot of work today we're going to do it"
      },
      {
        "start": 5148.4,
        "duration": 4.04,
        "text": "with one command and literally if you"
      },
      {
        "start": 5150.76,
        "duration": 5.08,
        "text": "notice in my command here all we're"
      },
      {
        "start": 5152.44,
        "duration": 6.12,
        "text": "doing is we got set size to"
      },
      {
        "start": 5155.84,
        "duration": 5.56,
        "text": "one that's it we're just resetting the"
      },
      {
        "start": 5158.56,
        "duration": 4.84,
        "text": "size to one Helm and kubernetes take"
      },
      {
        "start": 5161.4,
        "duration": 6.279,
        "text": "care of the rest let's go ahead and do"
      },
      {
        "start": 5163.4,
        "duration": 5.799,
        "text": "that all right and boom revision three"
      },
      {
        "start": 5167.679,
        "duration": 3.56,
        "text": "so we notice that that is now on a new"
      },
      {
        "start": 5169.199,
        "duration": 4.761,
        "text": "revision meaning our upgrade command"
      },
      {
        "start": 5171.239,
        "duration": 6.241,
        "text": "took and I am going to go ahead and I am"
      },
      {
        "start": 5173.96,
        "duration": 5.36,
        "text": "going to do our uh get manifest command"
      },
      {
        "start": 5177.48,
        "duration": 3.48,
        "text": "just so we can see really quick that"
      },
      {
        "start": 5179.32,
        "duration": 4.08,
        "text": "that change actually took and I can"
      },
      {
        "start": 5180.96,
        "duration": 4.64,
        "text": "prove it here for you and the size is"
      },
      {
        "start": 5183.4,
        "duration": 3.52,
        "text": "now set to one now it's going to start"
      },
      {
        "start": 5185.6,
        "duration": 3.28,
        "text": "spinning those down we're going to see"
      },
      {
        "start": 5186.92,
        "duration": 3.68,
        "text": "these notes here for a while um those"
      },
      {
        "start": 5188.88,
        "duration": 3.72,
        "text": "are going to be spinning down it takes a"
      },
      {
        "start": 5190.6,
        "duration": 3.92,
        "text": "it takes some time so we might not get"
      },
      {
        "start": 5192.6,
        "duration": 4.599,
        "text": "to them before the the end of the"
      },
      {
        "start": 5194.52,
        "duration": 4.96,
        "text": "session here uh to take a look but those"
      },
      {
        "start": 5197.199,
        "duration": 4.081,
        "text": "are in fact starting to spin down and"
      },
      {
        "start": 5199.48,
        "duration": 4.239,
        "text": "and uh terminate themselves in a"
      },
      {
        "start": 5201.28,
        "duration": 4.879,
        "text": "graceful manner that is Cassandra safe"
      },
      {
        "start": 5203.719,
        "duration": 5.201,
        "text": "and that is really key doing it in a"
      },
      {
        "start": 5206.159,
        "duration": 6.161,
        "text": "Cassandra Safe Way is important to not"
      },
      {
        "start": 5208.92,
        "duration": 6.04,
        "text": "have downtime and not lose data all"
      },
      {
        "start": 5212.32,
        "duration": 4.28,
        "text": "right running repairs we're going to get"
      },
      {
        "start": 5214.96,
        "duration": 5.48,
        "text": "to that in just a moment because we have"
      },
      {
        "start": 5216.6,
        "duration": 6.4,
        "text": "to talk about what repairs are so we"
      },
      {
        "start": 5220.44,
        "duration": 4.64,
        "text": "talked about entropy earlier entropy is"
      },
      {
        "start": 5223.0,
        "duration": 4.04,
        "text": "just you know the fact it's a fact of"
      },
      {
        "start": 5225.08,
        "duration": 5.32,
        "text": "life it's it's has to do with physics"
      },
      {
        "start": 5227.04,
        "duration": 6.079,
        "text": "right things tend to Trend towards chaos"
      },
      {
        "start": 5230.4,
        "duration": 4.96,
        "text": "and we can't break those rules with our"
      },
      {
        "start": 5233.119,
        "duration": 4.241,
        "text": "distributed systems in fact we tend to"
      },
      {
        "start": 5235.36,
        "duration": 3.6,
        "text": "notice those problems a lot more in our"
      },
      {
        "start": 5237.36,
        "duration": 2.96,
        "text": "distributed systems because instead of"
      },
      {
        "start": 5238.96,
        "duration": 4.04,
        "text": "having you know a single drive that"
      },
      {
        "start": 5240.32,
        "duration": 4.56,
        "text": "could fail we have potentially hundreds"
      },
      {
        "start": 5243.0,
        "duration": 3.639,
        "text": "or thousands of drives that could fail"
      },
      {
        "start": 5244.88,
        "duration": 3.6,
        "text": "we have hundreds or thousands of"
      },
      {
        "start": 5246.639,
        "duration": 4.201,
        "text": "processors of different Hardware"
      },
      {
        "start": 5248.48,
        "duration": 4.48,
        "text": "components we're basically increasing"
      },
      {
        "start": 5250.84,
        "duration": 4.839,
        "text": "the amount of of places where something"
      },
      {
        "start": 5252.96,
        "duration": 5.12,
        "text": "could end up going wrong anything going"
      },
      {
        "start": 5255.679,
        "duration": 4.721,
        "text": "wrong causes or can cause what's called"
      },
      {
        "start": 5258.08,
        "duration": 5.36,
        "text": "entropy in a system which is basically a"
      },
      {
        "start": 5260.4,
        "duration": 6.44,
        "text": "gradual degradation of the system in"
      },
      {
        "start": 5263.44,
        "duration": 6.16,
        "text": "data terms in in Cassandra that can"
      },
      {
        "start": 5266.84,
        "duration": 5.48,
        "text": "cause data degradation and we don't want"
      },
      {
        "start": 5269.6,
        "duration": 6.4,
        "text": "that to happen so in order for us to"
      },
      {
        "start": 5272.32,
        "duration": 8.52,
        "text": "combat entropy we run repairs repairs"
      },
      {
        "start": 5276.0,
        "duration": 6.8,
        "text": "are a tool to reverse entropy over time"
      },
      {
        "start": 5280.84,
        "duration": 4.08,
        "text": "now the repairs work by constructing"
      },
      {
        "start": 5282.8,
        "duration": 4.359,
        "text": "meracle trees which are essentially they"
      },
      {
        "start": 5284.92,
        "duration": 4.44,
        "text": "take a A in the simplest form I'm going"
      },
      {
        "start": 5287.159,
        "duration": 4.681,
        "text": "to very oversimplify this but they they"
      },
      {
        "start": 5289.36,
        "duration": 4.12,
        "text": "take a chunk of the data they hash it"
      },
      {
        "start": 5291.84,
        "duration": 3.08,
        "text": "they get the hash value and they take"
      },
      {
        "start": 5293.48,
        "duration": 3.239,
        "text": "that same chunk of data over on the"
      },
      {
        "start": 5294.92,
        "duration": 4.279,
        "text": "other side they hash it and then they"
      },
      {
        "start": 5296.719,
        "duration": 4.201,
        "text": "compare the hashes if the hashes don't"
      },
      {
        "start": 5299.199,
        "duration": 4.081,
        "text": "match then they know that some data is"
      },
      {
        "start": 5300.92,
        "duration": 3.719,
        "text": "out of sync and they'll go and and find"
      },
      {
        "start": 5303.28,
        "duration": 2.72,
        "text": "smaller and smaller chunks until they"
      },
      {
        "start": 5304.639,
        "duration": 3.0,
        "text": "can find what data is out of sync and"
      },
      {
        "start": 5306.0,
        "duration": 4.159,
        "text": "then they stream that data across to"
      },
      {
        "start": 5307.639,
        "duration": 4.921,
        "text": "bring it back into you know a reconciled"
      },
      {
        "start": 5310.159,
        "duration": 4.121,
        "text": "state in a in the simplest form that's"
      },
      {
        "start": 5312.56,
        "duration": 3.4,
        "text": "what a repair is now there are in"
      },
      {
        "start": 5314.28,
        "duration": 3.76,
        "text": "Cassandra there things called"
      },
      {
        "start": 5315.96,
        "duration": 3.44,
        "text": "incremental repairs if you've got data"
      },
      {
        "start": 5318.04,
        "duration": 3.4,
        "text": "STX Enterprise there's a thing called"
      },
      {
        "start": 5319.4,
        "duration": 4.08,
        "text": "node sync there are a lot of kind of"
      },
      {
        "start": 5321.44,
        "duration": 3.56,
        "text": "more advanced tools to to accomplish the"
      },
      {
        "start": 5323.48,
        "duration": 4.88,
        "text": "same thing today we're just going to"
      },
      {
        "start": 5325.0,
        "duration": 5.96,
        "text": "focus on simple repairs and honestly in"
      },
      {
        "start": 5328.36,
        "duration": 5.279,
        "text": "kandra and most Cassandra deployments"
      },
      {
        "start": 5330.96,
        "duration": 4.8,
        "text": "simple repairs are really all you need"
      },
      {
        "start": 5333.639,
        "duration": 3.761,
        "text": "um you can accomplish what you need with"
      },
      {
        "start": 5335.76,
        "duration": 3.6,
        "text": "simple repairs the other tools are just"
      },
      {
        "start": 5337.4,
        "duration": 5.48,
        "text": "there for you know operational"
      },
      {
        "start": 5339.36,
        "duration": 7.04,
        "text": "streamlining and things like that okay"
      },
      {
        "start": 5342.88,
        "duration": 5.279,
        "text": "running repairs is done through a UI"
      },
      {
        "start": 5346.4,
        "duration": 3.4,
        "text": "where we will schedule them and then we"
      },
      {
        "start": 5348.159,
        "duration": 3.08,
        "text": "will also be able to trigger them"
      },
      {
        "start": 5349.8,
        "duration": 3.399,
        "text": "there's also some information we can"
      },
      {
        "start": 5351.239,
        "duration": 3.4,
        "text": "glean about our cluster through this UI"
      },
      {
        "start": 5353.199,
        "duration": 3.801,
        "text": "and we'll get into that in just a second"
      },
      {
        "start": 5354.639,
        "duration": 5.241,
        "text": "here because it is now time for the next"
      },
      {
        "start": 5357.0,
        "duration": 5.28,
        "text": "exercise so in your link list we're"
      },
      {
        "start": 5359.88,
        "duration": 4.759,
        "text": "going to go down to the line four which"
      },
      {
        "start": 5362.28,
        "duration": 4.399,
        "text": "is Cassandra repair"
      },
      {
        "start": 5364.639,
        "duration": 4.401,
        "text": "go ahead and click on that that's going"
      },
      {
        "start": 5366.679,
        "duration": 4.04,
        "text": "to bring up our repair console now"
      },
      {
        "start": 5369.04,
        "duration": 3.4,
        "text": "you'll notice here there's there's"
      },
      {
        "start": 5370.719,
        "duration": 3.841,
        "text": "actually our topology is laid out we've"
      },
      {
        "start": 5372.44,
        "duration": 6.12,
        "text": "got dc1 which is the name of our data"
      },
      {
        "start": 5374.56,
        "duration": 5.8,
        "text": "center we have a single node in dc1 and"
      },
      {
        "start": 5378.56,
        "duration": 4.84,
        "text": "this node actually we can see the IP"
      },
      {
        "start": 5380.36,
        "duration": 4.839,
        "text": "address um pretty cool what we're going"
      },
      {
        "start": 5383.4,
        "duration": 4.12,
        "text": "to do here is we're going to go click"
      },
      {
        "start": 5385.199,
        "duration": 3.96,
        "text": "schedules and from schedules we're going"
      },
      {
        "start": 5387.52,
        "duration": 3.639,
        "text": "to click add"
      },
      {
        "start": 5389.159,
        "duration": 5.361,
        "text": "schedule and we're going to go ahead and"
      },
      {
        "start": 5391.159,
        "duration": 5.08,
        "text": "we're going to start typing in uh spring"
      },
      {
        "start": 5394.52,
        "duration": 4.599,
        "text": "pet clinic and notice it auto completes"
      },
      {
        "start": 5396.239,
        "duration": 5.521,
        "text": "it actually knows what key spaces we"
      },
      {
        "start": 5399.119,
        "duration": 4.12,
        "text": "have on our cluster key space being the"
      },
      {
        "start": 5401.76,
        "duration": 3.479,
        "text": "bucket that stores tables that's what"
      },
      {
        "start": 5403.239,
        "duration": 6.041,
        "text": "our app is interacting with is the"
      },
      {
        "start": 5405.239,
        "duration": 5.92,
        "text": "spring uh pet clinic keyspace okay owner"
      },
      {
        "start": 5409.28,
        "duration": 3.52,
        "text": "I'm just going to say I'm the owner for"
      },
      {
        "start": 5411.159,
        "duration": 2.841,
        "text": "now um obviously if you're in a big"
      },
      {
        "start": 5412.8,
        "duration": 2.319,
        "text": "organization or something where you"
      },
      {
        "start": 5414.0,
        "duration": 2.08,
        "text": "actually want to keep track of things"
      },
      {
        "start": 5415.119,
        "duration": 3.401,
        "text": "you should probably be a little more"
      },
      {
        "start": 5416.08,
        "duration": 3.84,
        "text": "explicit about that but um just for"
      },
      {
        "start": 5418.52,
        "duration": 3.8,
        "text": "purposes of the demo we're going to do"
      },
      {
        "start": 5419.92,
        "duration": 5.239,
        "text": "it this way interval in days best"
      },
      {
        "start": 5422.32,
        "duration": 5.28,
        "text": "practice is to run a repair every seven"
      },
      {
        "start": 5425.159,
        "duration": 3.96,
        "text": "days so seven should be the number you"
      },
      {
        "start": 5427.6,
        "duration": 3.8,
        "text": "use here unless you have a really good"
      },
      {
        "start": 5429.119,
        "duration": 3.761,
        "text": "reason not to um it does allow you to"
      },
      {
        "start": 5431.4,
        "duration": 3.0,
        "text": "configure that but let's use seven there"
      },
      {
        "start": 5432.88,
        "duration": 4.759,
        "text": "for now and I'm going to hit add"
      },
      {
        "start": 5434.4,
        "duration": 5.96,
        "text": "schedule and you'll notice my repair is"
      },
      {
        "start": 5437.639,
        "duration": 5.761,
        "text": "now set up and we are good to go now if"
      },
      {
        "start": 5440.36,
        "duration": 4.68,
        "text": "I go back to clusters here nothing is"
      },
      {
        "start": 5443.4,
        "duration": 3.12,
        "text": "currently running but if I wanted to"
      },
      {
        "start": 5445.04,
        "duration": 4.4,
        "text": "kick off that repair I could go back to"
      },
      {
        "start": 5446.52,
        "duration": 5.08,
        "text": "my schedules and I could click run now"
      },
      {
        "start": 5449.44,
        "duration": 4.64,
        "text": "and you'll notice it says repair will be"
      },
      {
        "start": 5451.6,
        "duration": 5.2,
        "text": "run shortly we'll start shortly and in"
      },
      {
        "start": 5454.08,
        "duration": 4.639,
        "text": "moment here we have to give it a second"
      },
      {
        "start": 5456.8,
        "duration": 3.839,
        "text": "to actually kick off but it'll pop up"
      },
      {
        "start": 5458.719,
        "duration": 4.281,
        "text": "here with a progress bar saying you know"
      },
      {
        "start": 5460.639,
        "duration": 4.0,
        "text": "basically repair running um and it'll"
      },
      {
        "start": 5463.0,
        "duration": 4.04,
        "text": "give us a little progress bar on that"
      },
      {
        "start": 5464.639,
        "duration": 4.08,
        "text": "we'll give it a couple seconds here let"
      },
      {
        "start": 5467.04,
        "duration": 5.119,
        "text": "yall catch"
      },
      {
        "start": 5468.719,
        "duration": 5.161,
        "text": "up uh I got a question here if the"
      },
      {
        "start": 5472.159,
        "duration": 5.601,
        "text": "number of nodes is limited to one can we"
      },
      {
        "start": 5473.88,
        "duration": 6.6,
        "text": "still be able to scale up limited to one"
      },
      {
        "start": 5477.76,
        "duration": 7.52,
        "text": "I'm not sure what you mean by that"
      },
      {
        "start": 5480.48,
        "duration": 7.36,
        "text": "um so the in in helm what when we ran it"
      },
      {
        "start": 5485.28,
        "duration": 3.8,
        "text": "the default was was at one node we were"
      },
      {
        "start": 5487.84,
        "duration": 3.279,
        "text": "starting with a single node and then we"
      },
      {
        "start": 5489.08,
        "duration": 4.52,
        "text": "were scaling up from there so yes you"
      },
      {
        "start": 5491.119,
        "duration": 4.681,
        "text": "can scale up by using that set flag the"
      },
      {
        "start": 5493.6,
        "duration": 4.559,
        "text": "set size equals and then the number of"
      },
      {
        "start": 5495.8,
        "duration": 4.28,
        "text": "nodes I recommend not scaling up you"
      },
      {
        "start": 5498.159,
        "duration": 5.48,
        "text": "know like one two three scale up"
      },
      {
        "start": 5500.08,
        "duration": 5.88,
        "text": "probably two actually three nodes"
      },
      {
        "start": 5503.639,
        "duration": 3.961,
        "text": "because three is kind of for Cassandra"
      },
      {
        "start": 5505.96,
        "duration": 3.36,
        "text": "where you start getting Cassandra likee"
      },
      {
        "start": 5507.6,
        "duration": 3.639,
        "text": "Behavior you start being able to take"
      },
      {
        "start": 5509.32,
        "duration": 4.68,
        "text": "advantage of the distributed nature of"
      },
      {
        "start": 5511.239,
        "duration": 3.88,
        "text": "Cassandra um actually best practice if"
      },
      {
        "start": 5514.0,
        "duration": 3.08,
        "text": "you're trying to actually run something"
      },
      {
        "start": 5515.119,
        "duration": 4.6,
        "text": "in production I would highly recommend"
      },
      {
        "start": 5517.08,
        "duration": 4.88,
        "text": "starting with six nodes in 99% of the"
      },
      {
        "start": 5519.719,
        "duration": 4.241,
        "text": "use cases out there okay if you look"
      },
      {
        "start": 5521.96,
        "duration": 4.4,
        "text": "here in our UI we actually had this"
      },
      {
        "start": 5523.96,
        "duration": 4.08,
        "text": "repair kickoff we see the progress bar"
      },
      {
        "start": 5526.36,
        "duration": 3.319,
        "text": "and it is actually running so we just"
      },
      {
        "start": 5528.04,
        "duration": 4.96,
        "text": "triggered a repair that's now going to"
      },
      {
        "start": 5529.679,
        "duration": 4.801,
        "text": "run once every seven days on our cluster"
      },
      {
        "start": 5533.0,
        "duration": 3.159,
        "text": "and we don't have to think about it it"
      },
      {
        "start": 5534.48,
        "duration": 3.159,
        "text": "just runs and we can check back if we"
      },
      {
        "start": 5536.159,
        "duration": 3.401,
        "text": "want to you know get some information"
      },
      {
        "start": 5537.639,
        "duration": 5.08,
        "text": "check on some health statistics but it"
      },
      {
        "start": 5539.56,
        "duration": 4.76,
        "text": "just runs simple as that it's it's you"
      },
      {
        "start": 5542.719,
        "duration": 3.96,
        "text": "know when I explain these things in the"
      },
      {
        "start": 5544.32,
        "duration": 4.56,
        "text": "past I'd go like 25 minutes of"
      },
      {
        "start": 5546.679,
        "duration": 4.56,
        "text": "explaining in-depth how this stuff works"
      },
      {
        "start": 5548.88,
        "duration": 5.0,
        "text": "now with Kate Sandra it's just like I'm"
      },
      {
        "start": 5551.239,
        "duration": 3.96,
        "text": "done explaining this is incredible this"
      },
      {
        "start": 5553.88,
        "duration": 3.72,
        "text": "you know I don't have to explain things"
      },
      {
        "start": 5555.199,
        "duration": 3.561,
        "text": "anymore they just work really really"
      },
      {
        "start": 5557.6,
        "duration": 3.72,
        "text": "cool"
      },
      {
        "start": 5558.76,
        "duration": 4.28,
        "text": "okay at the bottom of the repository"
      },
      {
        "start": 5561.32,
        "duration": 4.0,
        "text": "you'll find um some resource links I'm"
      },
      {
        "start": 5563.04,
        "duration": 4.56,
        "text": "not going to navigate back there um"
      },
      {
        "start": 5565.32,
        "duration": 5.64,
        "text": "again so I just want to point that out"
      },
      {
        "start": 5567.6,
        "duration": 6.32,
        "text": "all right last piece of this backup and"
      },
      {
        "start": 5570.96,
        "duration": 5.64,
        "text": "restore now I mentioned earlier that"
      },
      {
        "start": 5573.92,
        "duration": 5.239,
        "text": "that Medusa the backup and restore tool"
      },
      {
        "start": 5576.6,
        "duration": 4.8,
        "text": "is part of Kate Sandra it is currently"
      },
      {
        "start": 5579.159,
        "duration": 4.08,
        "text": "in Kate Sandra and it is most of the way"
      },
      {
        "start": 5581.4,
        "duration": 3.239,
        "text": "implemented but it's not something we're"
      },
      {
        "start": 5583.239,
        "duration": 3.48,
        "text": "going to deal with today because again"
      },
      {
        "start": 5584.639,
        "duration": 3.04,
        "text": "we're we're in beta and there are just a"
      },
      {
        "start": 5586.719,
        "duration": 2.841,
        "text": "couple things that are still being"
      },
      {
        "start": 5587.679,
        "duration": 2.96,
        "text": "ironed out with it and we just you know"
      },
      {
        "start": 5589.56,
        "duration": 3.119,
        "text": "wanted to give you guys a good"
      },
      {
        "start": 5590.639,
        "duration": 3.361,
        "text": "experience as opposed to trying to fight"
      },
      {
        "start": 5592.679,
        "duration": 3.921,
        "text": "uh something that is still kind of being"
      },
      {
        "start": 5594.0,
        "duration": 3.92,
        "text": "hashed out so um the the actual"
      },
      {
        "start": 5596.6,
        "duration": 3.519,
        "text": "implementation if you want to go and try"
      },
      {
        "start": 5597.92,
        "duration": 4.239,
        "text": "to run this yourself you can run a hel"
      },
      {
        "start": 5600.119,
        "duration": 4.08,
        "text": "install command and essentially what"
      },
      {
        "start": 5602.159,
        "duration": 4.56,
        "text": "you're doing is you're installing just a"
      },
      {
        "start": 5604.199,
        "duration": 4.601,
        "text": "quick running job which will go and"
      },
      {
        "start": 5606.719,
        "duration": 3.4,
        "text": "create a backup we use the set Flags to"
      },
      {
        "start": 5608.8,
        "duration": 3.359,
        "text": "configure what that backup will be"
      },
      {
        "start": 5610.119,
        "duration": 4.441,
        "text": "called we also use set Flags to"
      },
      {
        "start": 5612.159,
        "duration": 4.921,
        "text": "configure um where that will be so it"
      },
      {
        "start": 5614.56,
        "duration": 4.76,
        "text": "can be on you know Google storage S3"
      },
      {
        "start": 5617.08,
        "duration": 4.8,
        "text": "storage local storage any any of those"
      },
      {
        "start": 5619.32,
        "duration": 4.0,
        "text": "things we can actually send our backups"
      },
      {
        "start": 5621.88,
        "duration": 3.88,
        "text": "there and I believe we're expanding that"
      },
      {
        "start": 5623.32,
        "duration": 5.2,
        "text": "as well uh on the road map I believe the"
      },
      {
        "start": 5625.76,
        "duration": 7.28,
        "text": "intention is to get a lot more um uh"
      },
      {
        "start": 5628.52,
        "duration": 6.24,
        "text": "storage providers in there as well okay"
      },
      {
        "start": 5633.04,
        "duration": 4.159,
        "text": "with that we are not going to do"
      },
      {
        "start": 5634.76,
        "duration": 3.879,
        "text": "exercise five because of the reasons I"
      },
      {
        "start": 5637.199,
        "duration": 4.601,
        "text": "just mentioned we're going to get into"
      },
      {
        "start": 5638.639,
        "duration": 5.48,
        "text": "resources couple things here Kate Sandra"
      },
      {
        "start": 5641.8,
        "duration": 4.28,
        "text": "iio is the web page for the open source"
      },
      {
        "start": 5644.119,
        "duration": 4.401,
        "text": "project highly recommend you go check it"
      },
      {
        "start": 5646.08,
        "duration": 5.36,
        "text": "out um lot of good stuff there there are"
      },
      {
        "start": 5648.52,
        "duration": 4.159,
        "text": "links to the GitHub to the docs to um"
      },
      {
        "start": 5651.44,
        "duration": 3.12,
        "text": "basically everything you need to get"
      },
      {
        "start": 5652.679,
        "duration": 4.761,
        "text": "involved with the project or to use the"
      },
      {
        "start": 5654.56,
        "duration": 5.8,
        "text": "project um then also the project GitHub"
      },
      {
        "start": 5657.44,
        "duration": 4.12,
        "text": "is github.com Kat Sandra K Sandra uh"
      },
      {
        "start": 5660.36,
        "duration": 2.56,
        "text": "highly recommend you check it out"
      },
      {
        "start": 5661.56,
        "duration": 3.76,
        "text": "there's a lot of work that's been going"
      },
      {
        "start": 5662.92,
        "duration": 3.68,
        "text": "on there you'll notice John sand in in"
      },
      {
        "start": 5665.32,
        "duration": 3.879,
        "text": "both of the chats he's one of the"
      },
      {
        "start": 5666.6,
        "duration": 4.16,
        "text": "engineers who's actually been committing"
      },
      {
        "start": 5669.199,
        "duration": 3.721,
        "text": "large portions of the code to this"
      },
      {
        "start": 5670.76,
        "duration": 4.08,
        "text": "project um he was nice enough to come on"
      },
      {
        "start": 5672.92,
        "duration": 4.44,
        "text": "and help support questions today in our"
      },
      {
        "start": 5674.84,
        "duration": 5.6,
        "text": "chats so thank you uh John for doing"
      },
      {
        "start": 5677.36,
        "duration": 5.6,
        "text": "that um but he and many others are there"
      },
      {
        "start": 5680.44,
        "duration": 4.36,
        "text": "actually contributing to this project"
      },
      {
        "start": 5682.96,
        "duration": 3.4,
        "text": "okay road map this is always the"
      },
      {
        "start": 5684.8,
        "duration": 4.16,
        "text": "exciting stuff right what's coming"
      },
      {
        "start": 5686.36,
        "duration": 5.2,
        "text": "what's next as with any open source"
      },
      {
        "start": 5688.96,
        "duration": 4.92,
        "text": "project this is determined partly by the"
      },
      {
        "start": 5691.56,
        "duration": 4.24,
        "text": "users and Community around it so there"
      },
      {
        "start": 5693.88,
        "duration": 4.16,
        "text": "are certain things on here that are very"
      },
      {
        "start": 5695.8,
        "duration": 4.64,
        "text": "high priority let your voice be heard"
      },
      {
        "start": 5698.04,
        "duration": 4.92,
        "text": "get involved and actually help to to"
      },
      {
        "start": 5700.44,
        "duration": 4.48,
        "text": "prioritize the lists here um but there's"
      },
      {
        "start": 5702.96,
        "duration": 4.88,
        "text": "a lot here I mean goodness we upgrading"
      },
      {
        "start": 5704.92,
        "duration": 4.799,
        "text": "your clusters some node life cycle stuff"
      },
      {
        "start": 5707.84,
        "duration": 4.68,
        "text": "uh data loading that's kind of a big one"
      },
      {
        "start": 5709.719,
        "duration": 5.48,
        "text": "there's spark connector kofka connector"
      },
      {
        "start": 5712.52,
        "duration": 5.36,
        "text": "um all of those things are are on the"
      },
      {
        "start": 5715.199,
        "duration": 5.92,
        "text": "road map and we are actually working"
      },
      {
        "start": 5717.88,
        "duration": 4.88,
        "text": "actively to get them into the project so"
      },
      {
        "start": 5721.119,
        "duration": 3.6,
        "text": "definitely get involved if you have"
      },
      {
        "start": 5722.76,
        "duration": 4.2,
        "text": "opinions on these things let your voice"
      },
      {
        "start": 5724.719,
        "duration": 4.96,
        "text": "be heard"
      },
      {
        "start": 5726.96,
        "duration": 4.92,
        "text": "okay learning now this is where we"
      },
      {
        "start": 5729.679,
        "duration": 4.081,
        "text": "talked about the certifications before"
      },
      {
        "start": 5731.88,
        "duration": 4.799,
        "text": "um go to"
      },
      {
        "start": 5733.76,
        "duration": 6.0,
        "text": "data.com uh sdev you can get links to"
      },
      {
        "start": 5736.679,
        "duration": 5.681,
        "text": "the academy courses there's also uh a"
      },
      {
        "start": 5739.76,
        "duration": 4.399,
        "text": "whole bunch of curated content on kataka"
      },
      {
        "start": 5742.36,
        "duration": 4.279,
        "text": "C if you haven't used kakoda yet it's"
      },
      {
        "start": 5744.159,
        "duration": 6.441,
        "text": "basically O'Reilly released a really"
      },
      {
        "start": 5746.639,
        "duration": 7.48,
        "text": "cool tool to do um full scenarios uh in"
      },
      {
        "start": 5750.6,
        "duration": 5.119,
        "text": "terminal in your web browser so kind of"
      },
      {
        "start": 5754.119,
        "duration": 4.161,
        "text": "a"
      },
      {
        "start": 5755.719,
        "duration": 4.721,
        "text": "self-service um lab that you can do from"
      },
      {
        "start": 5758.28,
        "duration": 4.64,
        "text": "your browser with virtual machines and"
      },
      {
        "start": 5760.44,
        "duration": 4.48,
        "text": "everything all there for you so a lot of"
      },
      {
        "start": 5762.92,
        "duration": 4.44,
        "text": "scenarios there with different uh"
      },
      {
        "start": 5764.92,
        "duration": 5.04,
        "text": "different exercises we also have"
      },
      {
        "start": 5767.36,
        "duration": 5.68,
        "text": "community. data.com which is basically"
      },
      {
        "start": 5769.96,
        "duration": 5.279,
        "text": "our stack Overflow managed by um data"
      },
      {
        "start": 5773.04,
        "duration": 3.639,
        "text": "Stacks talk about all things cassander"
      },
      {
        "start": 5775.239,
        "duration": 3.92,
        "text": "there it's a really good place to hang"
      },
      {
        "start": 5776.679,
        "duration": 4.081,
        "text": "out um interact with open source"
      },
      {
        "start": 5779.159,
        "duration": 3.441,
        "text": "interact with DSE interact with Kate"
      },
      {
        "start": 5780.76,
        "duration": 4.68,
        "text": "Sandra whatever it is you have questions"
      },
      {
        "start": 5782.6,
        "duration": 4.32,
        "text": "on bring them there tons of people are"
      },
      {
        "start": 5785.44,
        "duration": 4.64,
        "text": "on there all the time answering"
      },
      {
        "start": 5786.92,
        "duration": 5.84,
        "text": "questions so please come on by um we"
      },
      {
        "start": 5790.08,
        "duration": 4.44,
        "text": "have social media data Stacks devs is of"
      },
      {
        "start": 5792.76,
        "duration": 4.439,
        "text": "course we are all employed by data"
      },
      {
        "start": 5794.52,
        "duration": 5.119,
        "text": "Stacks but we are here to as Alex said"
      },
      {
        "start": 5797.199,
        "duration": 3.801,
        "text": "upgrade developers our goal is not to be"
      },
      {
        "start": 5799.639,
        "duration": 2.841,
        "text": "marketing we are not trying to do"
      },
      {
        "start": 5801.0,
        "duration": 3.159,
        "text": "anything like that we are trying to"
      },
      {
        "start": 5802.48,
        "duration": 4.199,
        "text": "provide developers with useful stuff"
      },
      {
        "start": 5804.159,
        "duration": 4.881,
        "text": "that will help them to as Alex said uh"
      },
      {
        "start": 5806.679,
        "duration": 4.881,
        "text": "improve their career and get paid more"
      },
      {
        "start": 5809.04,
        "duration": 5.199,
        "text": "so well well well advantage or social"
      },
      {
        "start": 5811.56,
        "duration": 6.0,
        "text": "media yes and no you see I'm happy when"
      },
      {
        "start": 5814.239,
        "duration": 5.521,
        "text": "uh people are getting paid uh better for"
      },
      {
        "start": 5817.56,
        "duration": 4.92,
        "text": "the job they're doing but that's not my"
      },
      {
        "start": 5819.76,
        "duration": 5.64,
        "text": "main purpose I would say I'm working in"
      },
      {
        "start": 5822.48,
        "duration": 7.719,
        "text": "the it infrastructure and it field for a"
      },
      {
        "start": 5825.4,
        "duration": 8.279,
        "text": "way too long time and I'm tired of uh so"
      },
      {
        "start": 5830.199,
        "duration": 6.881,
        "text": "many people doing uh architectural"
      },
      {
        "start": 5833.679,
        "duration": 6.641,
        "text": "mistakes and doing some software"
      },
      {
        "start": 5837.08,
        "duration": 6.48,
        "text": "development not as good as they could so"
      },
      {
        "start": 5840.32,
        "duration": 6.16,
        "text": "I'm happy to make the community better"
      },
      {
        "start": 5843.56,
        "duration": 6.2,
        "text": "better and make people developing better"
      },
      {
        "start": 5846.48,
        "duration": 6.44,
        "text": "software that's my main point for"
      },
      {
        "start": 5849.76,
        "duration": 5.32,
        "text": "me yes I would agree with that as"
      },
      {
        "start": 5852.92,
        "duration": 4.88,
        "text": "well all"
      },
      {
        "start": 5855.08,
        "duration": 4.88,
        "text": "right let's go on now this is the cool"
      },
      {
        "start": 5857.8,
        "duration": 4.08,
        "text": "part we're announcing a Cassandra"
      },
      {
        "start": 5859.96,
        "duration": 3.4,
        "text": "kubernetes certification now we already"
      },
      {
        "start": 5861.88,
        "duration": 3.279,
        "text": "have two certifications we have our"
      },
      {
        "start": 5863.36,
        "duration": 3.92,
        "text": "developer and our administrator"
      },
      {
        "start": 5865.159,
        "duration": 4.361,
        "text": "certifications but we are working on"
      },
      {
        "start": 5867.28,
        "duration": 4.8,
        "text": "very soon it will be popping up so keep"
      },
      {
        "start": 5869.52,
        "duration": 4.32,
        "text": "an eye out for it the Cassandra on"
      },
      {
        "start": 5872.08,
        "duration": 4.88,
        "text": "kubernetes certification and it's going"
      },
      {
        "start": 5873.84,
        "duration": 5.319,
        "text": "to cover a whole lot of of really deep"
      },
      {
        "start": 5876.96,
        "duration": 4.159,
        "text": "content on that topic so highly"
      },
      {
        "start": 5879.159,
        "duration": 5.52,
        "text": "recommend uh you know keep an eye out"
      },
      {
        "start": 5881.119,
        "duration": 5.321,
        "text": "for it it it will be coming very shortly"
      },
      {
        "start": 5884.679,
        "duration": 3.48,
        "text": "all right and oh I will bring this up as"
      },
      {
        "start": 5886.44,
        "duration": 4.0,
        "text": "well if you do want to see uh any"
      },
      {
        "start": 5888.159,
        "duration": 5.281,
        "text": "information on certifications dat.com"
      },
      {
        "start": 5890.44,
        "duration": 5.52,
        "text": "deev certifications will get you to"
      },
      {
        "start": 5893.44,
        "duration": 6.239,
        "text": "basically the page that that uh has all"
      },
      {
        "start": 5895.96,
        "duration": 7.0,
        "text": "of that information all right um I will"
      },
      {
        "start": 5899.679,
        "duration": 6.841,
        "text": "bring up here we do have our our our"
      },
      {
        "start": 5902.96,
        "duration": 6.36,
        "text": "Academy courses um the ds21 ds210 and"
      },
      {
        "start": 5906.52,
        "duration": 4.56,
        "text": "ds220 which most everyone who's been in"
      },
      {
        "start": 5909.32,
        "duration": 3.6,
        "text": "the cassander world for you know any"
      },
      {
        "start": 5911.08,
        "duration": 5.24,
        "text": "length of time has probably heard of or"
      },
      {
        "start": 5912.92,
        "duration": 5.319,
        "text": "taken those um those are basically"
      },
      {
        "start": 5916.32,
        "duration": 4.279,
        "text": "fundamentals courses when it comes to"
      },
      {
        "start": 5918.239,
        "duration": 6.241,
        "text": "working with Cassandra those are all"
      },
      {
        "start": 5920.599,
        "duration": 5.281,
        "text": "offered at the uh /dev Academy URL there"
      },
      {
        "start": 5924.48,
        "duration": 2.88,
        "text": "I highly recommend you check them out if"
      },
      {
        "start": 5925.88,
        "duration": 4.319,
        "text": "you have any interest in pursuing"
      },
      {
        "start": 5927.36,
        "duration": 4.56,
        "text": "Cassandra uh in pretty much any capacity"
      },
      {
        "start": 5930.199,
        "duration": 3.121,
        "text": "but they are very very useful courses"
      },
      {
        "start": 5931.92,
        "duration": 4.04,
        "text": "and there's a lot more courses there as"
      },
      {
        "start": 5933.32,
        "duration": 5.12,
        "text": "well well yep and I would say we give"
      },
      {
        "start": 5935.96,
        "duration": 5.96,
        "text": "you the chance to pass a certification"
      },
      {
        "start": 5938.44,
        "duration": 6.44,
        "text": "exam for free but uh if you are not"
      },
      {
        "start": 5941.92,
        "duration": 5.6,
        "text": "ready that's just a wasting of of of"
      },
      {
        "start": 5944.88,
        "duration": 4.44,
        "text": "time uh not money but time at least"
      },
      {
        "start": 5947.52,
        "duration": 4.48,
        "text": "definitely and time time is very"
      },
      {
        "start": 5949.32,
        "duration": 5.839,
        "text": "valuable so first get the course it's"
      },
      {
        "start": 5952.0,
        "duration": 5.199,
        "text": "free then passw certification exam and"
      },
      {
        "start": 5955.159,
        "duration": 4.44,
        "text": "you have your very well-deserved"
      },
      {
        "start": 5957.199,
        "duration": 6.841,
        "text": "certification that's how it"
      },
      {
        "start": 5959.599,
        "duration": 6.841,
        "text": "works yeah absolutely um we also have uh"
      },
      {
        "start": 5964.04,
        "duration": 4.24,
        "text": "a book that is Cassandra the definitive"
      },
      {
        "start": 5966.44,
        "duration": 3.36,
        "text": "guide and it really is the definitive"
      },
      {
        "start": 5968.28,
        "duration": 4.64,
        "text": "guide um this was written by Jeff"
      },
      {
        "start": 5969.8,
        "duration": 6.359,
        "text": "Carpenter he is a uh uh one of my"
      },
      {
        "start": 5972.92,
        "duration": 5.96,
        "text": "co-workers here at datax uh he actually"
      },
      {
        "start": 5976.159,
        "duration": 5.401,
        "text": "was working I think on the uh was it the"
      },
      {
        "start": 5978.88,
        "duration": 4.92,
        "text": "second edition of this book as well um"
      },
      {
        "start": 5981.56,
        "duration": 4.44,
        "text": "so he he's been writing this book for a"
      },
      {
        "start": 5983.8,
        "duration": 5.12,
        "text": "while uh and updating this book fairly"
      },
      {
        "start": 5986.0,
        "duration": 5.28,
        "text": "consistently it covers all sorts of"
      },
      {
        "start": 5988.92,
        "duration": 3.88,
        "text": "things from you know the reasons why"
      },
      {
        "start": 5991.28,
        "duration": 4.24,
        "text": "Cassandra works the way it does to how"
      },
      {
        "start": 5992.8,
        "duration": 4.359,
        "text": "to make it do things um it's a very very"
      },
      {
        "start": 5995.52,
        "duration": 3.8,
        "text": "informative book highly recommend you"
      },
      {
        "start": 5997.159,
        "duration": 6.201,
        "text": "check it out if you have any uh interest"
      },
      {
        "start": 5999.32,
        "duration": 9.399,
        "text": "at all um uh if you want to attend our"
      },
      {
        "start": 6003.36,
        "duration": 8.6,
        "text": "next Workshop subscribe at beat. Le d/"
      },
      {
        "start": 6008.719,
        "duration": 6.161,
        "text": "subscribe D dat stacks devs and you will"
      },
      {
        "start": 6011.96,
        "duration": 5.639,
        "text": "be with us with our next events because"
      },
      {
        "start": 6014.88,
        "duration": 4.68,
        "text": "we run Cassandra Global Meetup program"
      },
      {
        "start": 6017.599,
        "duration": 4.761,
        "text": "we run data Stacks Monday learning"
      },
      {
        "start": 6019.56,
        "duration": 4.48,
        "text": "program we have Cassandra workshops"
      },
      {
        "start": 6022.36,
        "duration": 4.319,
        "text": "every week"
      },
      {
        "start": 6024.04,
        "duration": 6.599,
        "text": "and we have always have even something"
      },
      {
        "start": 6026.679,
        "duration": 6.601,
        "text": "more for you so subscribe at bit.ly"
      },
      {
        "start": 6030.639,
        "duration": 6.121,
        "text": "subscribe Das data Stacks"
      },
      {
        "start": 6033.28,
        "duration": 6.23,
        "text": "deaths and now open question what do you"
      },
      {
        "start": 6036.76,
        "duration": 5.819,
        "text": "like the most and what should we"
      },
      {
        "start": 6039.51,
        "duration": 3.069,
        "text": "[Music]"
      },
      {
        "start": 6043.36,
        "duration": 8.879,
        "text": "improve now you can type everything you"
      },
      {
        "start": 6047.8,
        "duration": 4.439,
        "text": "think about us"
      },
      {
        "start": 6053.76,
        "duration": 5.71,
        "text": "more"
      },
      {
        "start": 6054.64,
        "duration": 4.83,
        "text": "[Laughter]"
      },
      {
        "start": 6063.56,
        "duration": 4.039,
        "text": "swag more re the resources made"
      },
      {
        "start": 6066.08,
        "duration": 4.44,
        "text": "available they actually are going to be"
      },
      {
        "start": 6067.599,
        "duration": 6.681,
        "text": "available um in the GitHub that you guys"
      },
      {
        "start": 6070.52,
        "duration": 5.84,
        "text": "all used for the labs today um there are"
      },
      {
        "start": 6074.28,
        "duration": 4.48,
        "text": "links down at the bottom for everything"
      },
      {
        "start": 6076.36,
        "duration": 4.96,
        "text": "we talked about pretty much um so the"
      },
      {
        "start": 6078.76,
        "duration": 6.68,
        "text": "resources should all be"
      },
      {
        "start": 6081.32,
        "duration": 6.879,
        "text": "there um what should we"
      },
      {
        "start": 6085.44,
        "duration": 4.48,
        "text": "improve your presentation skills is that"
      },
      {
        "start": 6088.199,
        "duration": 5.161,
        "text": "what youd like or what we should"
      },
      {
        "start": 6089.92,
        "duration": 7.12,
        "text": "improve yeah that was my next question"
      },
      {
        "start": 6093.36,
        "duration": 7.16,
        "text": "uh slow slow down I didn't have time to"
      },
      {
        "start": 6097.04,
        "duration": 7.119,
        "text": "highlight that but yes I maybe we have"
      },
      {
        "start": 6100.52,
        "duration": 7.0,
        "text": "to uh slow down a little bit indeed but"
      },
      {
        "start": 6104.159,
        "duration": 5.401,
        "text": "you know what again first you can watch"
      },
      {
        "start": 6107.52,
        "duration": 4.639,
        "text": "what Eric is doing and then do it on"
      },
      {
        "start": 6109.56,
        "duration": 5.039,
        "text": "your own and we are staying with you so"
      },
      {
        "start": 6112.159,
        "duration": 5.321,
        "text": "don't worry more time to handle the"
      },
      {
        "start": 6114.599,
        "duration": 5.801,
        "text": "tools they are cool absolutely but the"
      },
      {
        "start": 6117.48,
        "duration": 5.32,
        "text": "training instances stay with you for 24"
      },
      {
        "start": 6120.4,
        "duration": 5.68,
        "text": "hours so you definitely have time to"
      },
      {
        "start": 6122.8,
        "duration": 6.16,
        "text": "handle the tools that's no"
      },
      {
        "start": 6126.08,
        "duration": 6.559,
        "text": "worries yeah there was another one on"
      },
      {
        "start": 6128.96,
        "duration": 4.18,
        "text": "home there yeah on the left hand side at"
      },
      {
        "start": 6132.639,
        "duration": 1.721,
        "text": "the very"
      },
      {
        "start": 6133.14,
        "duration": 5.42,
        "text": "[Music]"
      },
      {
        "start": 6134.36,
        "duration": 7.08,
        "text": "bottom which one this one yes"
      },
      {
        "start": 6138.56,
        "duration": 5.96,
        "text": "uh uh practical do documentation"
      },
      {
        "start": 6141.44,
        "duration": 5.239,
        "text": "resources K Sandra helm so Helm actually"
      },
      {
        "start": 6144.52,
        "duration": 4.24,
        "text": "has all their own documentation which um"
      },
      {
        "start": 6146.679,
        "duration": 5.241,
        "text": "you know is very available on Google but"
      },
      {
        "start": 6148.76,
        "duration": 4.64,
        "text": "Kate Sandra we actually have uh the"
      },
      {
        "start": 6151.92,
        "duration": 3.199,
        "text": "documentation was all in the links we"
      },
      {
        "start": 6153.4,
        "duration": 3.719,
        "text": "provided in the Kat"
      },
      {
        "start": 6155.119,
        "duration": 3.881,
        "text": "sandra. highly recommend you check that"
      },
      {
        "start": 6157.119,
        "duration": 3.56,
        "text": "out and of course Cassandra"
      },
      {
        "start": 6159.0,
        "duration": 6.159,
        "text": "documentation uh"
      },
      {
        "start": 6160.679,
        "duration": 6.201,
        "text": "data.com is itds or is it docs. dat.com"
      },
      {
        "start": 6165.159,
        "duration": 3.52,
        "text": "currently I don't remember the URL for"
      },
      {
        "start": 6166.88,
        "duration": 3.799,
        "text": "that off the top of my head but we do"
      },
      {
        "start": 6168.679,
        "duration": 4.241,
        "text": "have a doc site which we can get the"
      },
      {
        "start": 6170.679,
        "duration": 6.281,
        "text": "links to as well which is very in depth"
      },
      {
        "start": 6172.92,
        "duration": 6.799,
        "text": "on a number of sard topics mhm yep uh"
      },
      {
        "start": 6176.96,
        "duration": 6.36,
        "text": "and I'm uh completely"
      },
      {
        "start": 6179.719,
        "duration": 6.0,
        "text": "agree uh oh so this one I wanted to"
      },
      {
        "start": 6183.32,
        "duration": 5.359,
        "text": "highlight why and how clients are using"
      },
      {
        "start": 6185.719,
        "duration": 5.201,
        "text": "Cassandra uh in general Cassandra is the"
      },
      {
        "start": 6188.679,
        "duration": 6.201,
        "text": "best Feit when you are going to work"
      },
      {
        "start": 6190.92,
        "duration": 7.16,
        "text": "with a uh some big size data over the"
      },
      {
        "start": 6194.88,
        "duration": 5.52,
        "text": "world and your SLA requires to be"
      },
      {
        "start": 6198.08,
        "duration": 3.76,
        "text": "highest possible availability and"
      },
      {
        "start": 6200.4,
        "duration": 4.839,
        "text": "highest possible"
      },
      {
        "start": 6201.84,
        "duration": 6.56,
        "text": "performance and for any kind for every"
      },
      {
        "start": 6205.239,
        "duration": 6.0,
        "text": "situation like that Cassandra is a good"
      },
      {
        "start": 6208.4,
        "duration": 6.12,
        "text": "feed and that's why companies like apple"
      },
      {
        "start": 6211.239,
        "duration": 4.96,
        "text": "Netflix Instagram are using using"
      },
      {
        "start": 6214.52,
        "duration": 3.92,
        "text": "Cassandra too"
      },
      {
        "start": 6216.199,
        "duration": 4.121,
        "text": "much yeah actually if you pull out your"
      },
      {
        "start": 6218.44,
        "duration": 5.679,
        "text": "phone and you just look at the apps on"
      },
      {
        "start": 6220.32,
        "duration": 6.16,
        "text": "your phone pretty much I'd say 80% plus"
      },
      {
        "start": 6224.119,
        "duration": 5.761,
        "text": "of the apps on your phone probably have"
      },
      {
        "start": 6226.48,
        "duration": 6.0,
        "text": "Cassandra somewhere in the stack um it's"
      },
      {
        "start": 6229.88,
        "duration": 4.48,
        "text": "incredibly widely used by modern"
      },
      {
        "start": 6232.48,
        "duration": 3.8,
        "text": "applications the times you don't see it"
      },
      {
        "start": 6234.36,
        "duration": 3.72,
        "text": "used so often is if someone's got a very"
      },
      {
        "start": 6236.28,
        "duration": 4.319,
        "text": "you know Legacy application that hasn't"
      },
      {
        "start": 6238.08,
        "duration": 4.28,
        "text": "been modernized often times maybe you"
      },
      {
        "start": 6240.599,
        "duration": 4.241,
        "text": "know Cassandra didn't exist at that time"
      },
      {
        "start": 6242.36,
        "duration": 6.08,
        "text": "but for most modern applications"
      },
      {
        "start": 6244.84,
        "duration": 8.64,
        "text": "Cassandra is somewhere in the"
      },
      {
        "start": 6248.44,
        "duration": 7.6,
        "text": "stack okay uh so I think we are done for"
      },
      {
        "start": 6253.48,
        "duration": 5.239,
        "text": "today thank you for feedback we cannot"
      },
      {
        "start": 6256.04,
        "duration": 4.88,
        "text": "answer every feedback right now but we"
      },
      {
        "start": 6258.719,
        "duration": 5.601,
        "text": "read them after the workshops and we"
      },
      {
        "start": 6260.92,
        "duration": 6.52,
        "text": "react on them um"
      },
      {
        "start": 6264.32,
        "duration": 5.16,
        "text": "um good uh too many topics in one"
      },
      {
        "start": 6267.44,
        "duration": 4.239,
        "text": "presentation I would like to get a more"
      },
      {
        "start": 6269.48,
        "duration": 5.679,
        "text": "out of deeper dive into Kate Sandra and"
      },
      {
        "start": 6271.679,
        "duration": 7.56,
        "text": "less on Cassandra kubernetes I agree and"
      },
      {
        "start": 6275.159,
        "duration": 7.56,
        "text": "we will do that so this Workshop is more"
      },
      {
        "start": 6279.239,
        "duration": 6.241,
        "text": "uh beginner to intermediate level and"
      },
      {
        "start": 6282.719,
        "duration": 5.201,
        "text": "next one we will do kandra is one of our"
      },
      {
        "start": 6285.48,
        "duration": 5.4,
        "text": "favorite topics from now on so we will"
      },
      {
        "start": 6287.92,
        "duration": 5.36,
        "text": "do a much deeper dive with requirements"
      },
      {
        "start": 6290.88,
        "duration": 4.759,
        "text": "to attendees to have already some"
      },
      {
        "start": 6293.28,
        "duration": 5.52,
        "text": "knowledge in kubernetes and Cassandra so"
      },
      {
        "start": 6295.639,
        "duration": 5.96,
        "text": "we can focus on uh Kat Sandra but you"
      },
      {
        "start": 6298.8,
        "duration": 4.919,
        "text": "know what that's a day Zero for kandra"
      },
      {
        "start": 6301.599,
        "duration": 4.921,
        "text": "kid Sandra was just released and you"
      },
      {
        "start": 6303.719,
        "duration": 5.44,
        "text": "already want to have a fullsize deep"
      },
      {
        "start": 6306.52,
        "duration": 5.36,
        "text": "dive workshop on that it takes some time"
      },
      {
        "start": 6309.159,
        "duration": 4.96,
        "text": "to prepare the workshop we did today it"
      },
      {
        "start": 6311.88,
        "duration": 5.6,
        "text": "took many dozens I don't know maybe"
      },
      {
        "start": 6314.119,
        "duration": 5.52,
        "text": "hundreds of working hours so we just uh"
      },
      {
        "start": 6317.48,
        "duration": 4.28,
        "text": "have some time to prepare we will do"
      },
      {
        "start": 6319.639,
        "duration": 5.08,
        "text": "that but thank you for your opinion we"
      },
      {
        "start": 6321.76,
        "duration": 5.839,
        "text": "really value that is this recorded can"
      },
      {
        "start": 6324.719,
        "duration": 3.96,
        "text": "you watch this demo later absolutely"
      },
      {
        "start": 6327.599,
        "duration": 3.56,
        "text": "same"
      },
      {
        "start": 6328.679,
        "duration": 5.0,
        "text": "link yep that'll be on YouTube it"
      },
      {
        "start": 6331.159,
        "duration": 4.401,
        "text": "doesn't go away it's it's on the YouTube"
      },
      {
        "start": 6333.679,
        "duration": 4.48,
        "text": "channel for as long as YouTube lets us"
      },
      {
        "start": 6335.56,
        "duration": 6.52,
        "text": "keep it here okay Cassandra is good in"
      },
      {
        "start": 6338.159,
        "duration": 6.921,
        "text": "all all up nope it isn't Kal Cassandra"
      },
      {
        "start": 6342.08,
        "duration": 6.639,
        "text": "is an oilp database but if you want to"
      },
      {
        "start": 6345.08,
        "duration": 5.96,
        "text": "have uh full pledged all up over"
      },
      {
        "start": 6348.719,
        "duration": 5.041,
        "text": "Cassandra it's absolutely possible for"
      },
      {
        "start": 6351.04,
        "duration": 5.559,
        "text": "example with Apache Spark spark is very"
      },
      {
        "start": 6353.76,
        "duration": 5.919,
        "text": "well integrated with Apache Cassandra so"
      },
      {
        "start": 6356.599,
        "duration": 5.64,
        "text": "you may have uh whatever spark suggests"
      },
      {
        "start": 6359.679,
        "duration": 7.161,
        "text": "to you machine learning over Cassandra's"
      },
      {
        "start": 6362.239,
        "duration": 7.4,
        "text": "data very easy uh even SQL spark SQL you"
      },
      {
        "start": 6366.84,
        "duration": 6.56,
        "text": "can run structured query languages the"
      },
      {
        "start": 6369.639,
        "duration": 5.841,
        "text": "forign keys over Cassandra VI aach spark"
      },
      {
        "start": 6373.4,
        "duration": 4.88,
        "text": "it will not be as lightning fast as"
      },
      {
        "start": 6375.48,
        "duration": 6.36,
        "text": "Cassandra is but it will work so for"
      },
      {
        "start": 6378.28,
        "duration": 5.879,
        "text": "alop prefer Cassandra plus spark and I"
      },
      {
        "start": 6381.84,
        "duration": 6.08,
        "text": "think we are over time so it's time for"
      },
      {
        "start": 6384.159,
        "duration": 6.48,
        "text": "us to stop so I want to say big thank"
      },
      {
        "start": 6387.92,
        "duration": 5.239,
        "text": "you to everyone who participated in this"
      },
      {
        "start": 6390.639,
        "duration": 5.441,
        "text": "Workshop we love you we are very happy"
      },
      {
        "start": 6393.159,
        "duration": 2.921,
        "text": "you were with"
      },
      {
        "start": 6397.08,
        "duration": 8.039,
        "text": "us awesome thank you Eric so yeah we're"
      },
      {
        "start": 6401.679,
        "duration": 9.241,
        "text": "out I think not yet but we are going to"
      },
      {
        "start": 6405.119,
        "duration": 5.801,
        "text": "be out in a moment so see you next time"
      },
      {
        "start": 6413.0,
        "duration": 11.199,
        "text": "one new now I have more room no more"
      },
      {
        "start": 6418.52,
        "duration": 9.3,
        "text": "formats to change me on the same page we"
      },
      {
        "start": 6424.199,
        "duration": 6.241,
        "text": "are ever"
      },
      {
        "start": 6427.82,
        "duration": 5.94,
        "text": "[Music]"
      },
      {
        "start": 6430.44,
        "duration": 6.56,
        "text": "this living in the"
      },
      {
        "start": 6433.76,
        "duration": 6.2,
        "text": "future you and"
      },
      {
        "start": 6437.0,
        "duration": 6.96,
        "text": "me made for"
      },
      {
        "start": 6439.96,
        "duration": 4.0,
        "text": "us ser"
      },
      {
        "start": 6444.36,
        "duration": 6.799,
        "text": "heaven in the"
      },
      {
        "start": 6446.48,
        "duration": 4.679,
        "text": "future of the cloud"
      },
      {
        "start": 6459.32,
        "duration": 25.9,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T21:28:14.507824+00:00"
}