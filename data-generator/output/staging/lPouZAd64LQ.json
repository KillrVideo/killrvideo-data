{
  "video_id": "lPouZAd64LQ",
  "title": "DS320.37 Spark Streaming: Checkpointing and Recovery | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.37 Spark Streaming: Checkpointing and Recovery\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:32:42Z",
  "thumbnail": "https://i.ytimg.com/vi/lPouZAd64LQ/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=lPouZAd64LQ",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] checkpointing is a fault tolerance mechanism used by spark streaming now recall we've got some kind of streaming data coming into the system and we're chunking it off every say four seconds and making a little discrete rdd that becomes a part of our d stream but in general there's these events there's this data coming at us all the time we're doing some kind of computation on that and aggregating some kind of result that we want to look at that's in some sense a summary of the stream now if our application dies or a node goes down or something breaks then to recover all that conceptually we'd have to go back to the beginning of time with respect to that stream and recompute all that data that would be a bummer because we probably haven't stored that data and it would take a long time so checkpointing is a mechanism where every so often spark will persist data and metadata into the file system now file system data metadata let me define what i mean by those things first of all by file system i mean cfs the cassandra file system or the cassandra implementation of hdfs so spark streaming persists its snapshots into cfs which is provided for you by dse by default now metadata remember as we're defining our spark application we create streams we create rdds we apply transformations to those things we apply output operations on d streams and actions on rdds maybe we've got spark sql queries defined there's all these things happening and there's this graph of computations that spark maintains as a result of that application code that's the metadata pretty lightweight even if it's a very complex set of computations a big spark application you're not going to be talking about a huge amount of data for it to persist into the file system but checkpointing also persists some stream data into cfs and that potentially can be a lot of data this is necessary again in the event of failure we have to rewind to the previous checkpoint and replay the data that we've persisted there from the stream checkpointing is optional in the case of some transformations but required in the case of these if you've got update state by key count by window count by value in window reduce by window or reduce by key and window then you're going to have to enable checkpointing otherwise it's an option and we'll talk about the trade-offs that would influence that decision happily it's not difficult to enable on the spark streaming context we call that checkpoint method and pass it the directory or the path in cfs where we'd like the stuff to be persisted then start the application and get on with the computations that you've got to do checkpointing is a periodic thing it's going to happen every so often and determining that period is a key engineering decision we've got to make more frequent checkpointing means recovering from a failure is going to be quicker there's less checkpoint stuff to go through when you come back up after having died however that's more overhead each checkpoint that we do is going to cause more file io there's more overhead in general so we'd rather not do it too often so that pushes us to infrequent checkpointing which means less runtime overhead faster performance of the spark cluster but when we do come back up from a failure it will take us longer so that's a decision you're going to have to make in the context of your application and its failure recovery requirements if you're looking for a rule of thumb you should go for 5 to 10 times the slide interval now remember the slide interval is the number of seconds the window moves along each time the transformation runs in our example we've been using 4 seconds for the slide interval because four seconds is our batch interval that's just a decision we've made for the examples we're using to illustrate things here in your case look at what your slide interval is and you can use that 5 to 10x as a rule of thumb to get started in order to recover from a checkpoint our driver initialization code has to look slightly different when we're creating a streaming context we don't just get it we get or create the streaming context and we pass it the checkpoint dir so it'll be able to go look at that path in cfs and say are there files persisted here am i coming up for the first time or am i waking up after having died and do i have some recovery to do now that create streaming context function is a little non-standard let me show you the code we have in mind for that a lot of this is completely standard just creating the spark conf object and getting it all configured creating the streaming context setting the batch window then on the stream we do set the checkpoint interval at this case 20 seconds which is five times our batch interval so that's inside our rule of thumb and we also on the streaming context set the checkpoint directory to turn check pointing on so this is an example of a little bit of initialization code that is going to use checkpointing it's pretty simple to get it set up [Music] you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 7.6,
        "duration": 2.48,
        "text": "checkpointing is a fault tolerance"
      },
      {
        "start": 9.2,
        "duration": 2.88,
        "text": "mechanism"
      },
      {
        "start": 10.08,
        "duration": 3.519,
        "text": "used by spark streaming now recall we've"
      },
      {
        "start": 12.08,
        "duration": 2.4,
        "text": "got some kind of streaming data coming"
      },
      {
        "start": 13.599,
        "duration": 2.561,
        "text": "into the system"
      },
      {
        "start": 14.48,
        "duration": 3.6,
        "text": "and we're chunking it off every say four"
      },
      {
        "start": 16.16,
        "duration": 3.52,
        "text": "seconds and making a little discrete rdd"
      },
      {
        "start": 18.08,
        "duration": 3.039,
        "text": "that becomes a part of our d stream but"
      },
      {
        "start": 19.68,
        "duration": 3.359,
        "text": "in general there's these events there's"
      },
      {
        "start": 21.119,
        "duration": 3.761,
        "text": "this data coming at us all the time"
      },
      {
        "start": 23.039,
        "duration": 4.16,
        "text": "we're doing some kind of computation on"
      },
      {
        "start": 24.88,
        "duration": 3.84,
        "text": "that and aggregating some kind of result"
      },
      {
        "start": 27.199,
        "duration": 3.201,
        "text": "that we want to look at that's in some"
      },
      {
        "start": 28.72,
        "duration": 4.48,
        "text": "sense a summary of the stream"
      },
      {
        "start": 30.4,
        "duration": 4.8,
        "text": "now if our application dies or a node"
      },
      {
        "start": 33.2,
        "duration": 4.08,
        "text": "goes down or something breaks"
      },
      {
        "start": 35.2,
        "duration": 3.679,
        "text": "then to recover all that conceptually"
      },
      {
        "start": 37.28,
        "duration": 2.24,
        "text": "we'd have to go back to the beginning of"
      },
      {
        "start": 38.879,
        "duration": 2.161,
        "text": "time"
      },
      {
        "start": 39.52,
        "duration": 3.039,
        "text": "with respect to that stream and"
      },
      {
        "start": 41.04,
        "duration": 2.88,
        "text": "recompute all that data"
      },
      {
        "start": 42.559,
        "duration": 2.801,
        "text": "that would be a bummer because we"
      },
      {
        "start": 43.92,
        "duration": 3.119,
        "text": "probably haven't stored that data and it"
      },
      {
        "start": 45.36,
        "duration": 3.679,
        "text": "would take a long time so checkpointing"
      },
      {
        "start": 47.039,
        "duration": 5.04,
        "text": "is a mechanism where every so often"
      },
      {
        "start": 49.039,
        "duration": 5.601,
        "text": "spark will persist data and metadata"
      },
      {
        "start": 52.079,
        "duration": 3.521,
        "text": "into the file system now file system"
      },
      {
        "start": 54.64,
        "duration": 2.16,
        "text": "data metadata"
      },
      {
        "start": 55.6,
        "duration": 3.2,
        "text": "let me define what i mean by those"
      },
      {
        "start": 56.8,
        "duration": 2.32,
        "text": "things first of all by file system i"
      },
      {
        "start": 58.8,
        "duration": 3.279,
        "text": "mean"
      },
      {
        "start": 59.12,
        "duration": 4.64,
        "text": "cfs the cassandra file system or the"
      },
      {
        "start": 62.079,
        "duration": 4.481,
        "text": "cassandra implementation of"
      },
      {
        "start": 63.76,
        "duration": 3.84,
        "text": "hdfs so spark streaming persists its"
      },
      {
        "start": 66.56,
        "duration": 3.52,
        "text": "snapshots"
      },
      {
        "start": 67.6,
        "duration": 3.28,
        "text": "into cfs which is provided for you by"
      },
      {
        "start": 70.08,
        "duration": 3.52,
        "text": "dse"
      },
      {
        "start": 70.88,
        "duration": 4.72,
        "text": "by default now metadata remember as"
      },
      {
        "start": 73.6,
        "duration": 4.159,
        "text": "we're defining our spark application we"
      },
      {
        "start": 75.6,
        "duration": 4.879,
        "text": "create streams we create rdds"
      },
      {
        "start": 77.759,
        "duration": 3.121,
        "text": "we apply transformations to those things"
      },
      {
        "start": 80.479,
        "duration": 2.881,
        "text": "we"
      },
      {
        "start": 80.88,
        "duration": 3.84,
        "text": "apply output operations on d streams and"
      },
      {
        "start": 83.36,
        "duration": 3.119,
        "text": "actions on rdds"
      },
      {
        "start": 84.72,
        "duration": 3.039,
        "text": "maybe we've got spark sql queries"
      },
      {
        "start": 86.479,
        "duration": 1.921,
        "text": "defined there's all these things"
      },
      {
        "start": 87.759,
        "duration": 3.281,
        "text": "happening"
      },
      {
        "start": 88.4,
        "duration": 5.2,
        "text": "and there's this graph of computations"
      },
      {
        "start": 91.04,
        "duration": 3.92,
        "text": "that spark maintains as a result of that"
      },
      {
        "start": 93.6,
        "duration": 3.519,
        "text": "application code"
      },
      {
        "start": 94.96,
        "duration": 3.76,
        "text": "that's the metadata pretty lightweight"
      },
      {
        "start": 97.119,
        "duration": 3.281,
        "text": "even if it's a very complex"
      },
      {
        "start": 98.72,
        "duration": 3.039,
        "text": "set of computations a big spark"
      },
      {
        "start": 100.4,
        "duration": 3.2,
        "text": "application you're not going to be"
      },
      {
        "start": 101.759,
        "duration": 3.68,
        "text": "talking about a huge amount of data"
      },
      {
        "start": 103.6,
        "duration": 3.12,
        "text": "for it to persist into the file system"
      },
      {
        "start": 105.439,
        "duration": 5.281,
        "text": "but checkpointing"
      },
      {
        "start": 106.72,
        "duration": 5.92,
        "text": "also persists some stream data into cfs"
      },
      {
        "start": 110.72,
        "duration": 3.759,
        "text": "and that potentially can be a lot of"
      },
      {
        "start": 112.64,
        "duration": 3.519,
        "text": "data this is necessary again in the"
      },
      {
        "start": 114.479,
        "duration": 2.96,
        "text": "event of failure we have to rewind to"
      },
      {
        "start": 116.159,
        "duration": 4.401,
        "text": "the previous checkpoint"
      },
      {
        "start": 117.439,
        "duration": 3.761,
        "text": "and replay the data that we've persisted"
      },
      {
        "start": 120.56,
        "duration": 2.32,
        "text": "there"
      },
      {
        "start": 121.2,
        "duration": 2.8,
        "text": "from the stream checkpointing is"
      },
      {
        "start": 122.88,
        "duration": 3.199,
        "text": "optional in the case of some"
      },
      {
        "start": 124.0,
        "duration": 3.52,
        "text": "transformations but required"
      },
      {
        "start": 126.079,
        "duration": 3.6,
        "text": "in the case of these if you've got"
      },
      {
        "start": 127.52,
        "duration": 4.16,
        "text": "update state by key count by window"
      },
      {
        "start": 129.679,
        "duration": 3.92,
        "text": "count by value in window reduce by"
      },
      {
        "start": 131.68,
        "duration": 3.36,
        "text": "window or reduce by key and window"
      },
      {
        "start": 133.599,
        "duration": 3.681,
        "text": "then you're going to have to enable"
      },
      {
        "start": 135.04,
        "duration": 3.44,
        "text": "checkpointing otherwise it's an option"
      },
      {
        "start": 137.28,
        "duration": 2.88,
        "text": "and we'll talk about the trade-offs that"
      },
      {
        "start": 138.48,
        "duration": 3.6,
        "text": "would influence that decision happily"
      },
      {
        "start": 140.16,
        "duration": 3.52,
        "text": "it's not difficult to enable"
      },
      {
        "start": 142.08,
        "duration": 3.12,
        "text": "on the spark streaming context we call"
      },
      {
        "start": 143.68,
        "duration": 4.24,
        "text": "that checkpoint method and"
      },
      {
        "start": 145.2,
        "duration": 4.16,
        "text": "pass it the directory or the path in cfs"
      },
      {
        "start": 147.92,
        "duration": 2.16,
        "text": "where we'd like the stuff to be"
      },
      {
        "start": 149.36,
        "duration": 2.879,
        "text": "persisted"
      },
      {
        "start": 150.08,
        "duration": 3.68,
        "text": "then start the application and get on"
      },
      {
        "start": 152.239,
        "duration": 3.28,
        "text": "with the computations that you've got to"
      },
      {
        "start": 153.76,
        "duration": 3.44,
        "text": "do checkpointing is a periodic thing"
      },
      {
        "start": 155.519,
        "duration": 4.72,
        "text": "it's going to happen every so often"
      },
      {
        "start": 157.2,
        "duration": 4.8,
        "text": "and determining that period is a key"
      },
      {
        "start": 160.239,
        "duration": 3.841,
        "text": "engineering decision we've got to make"
      },
      {
        "start": 162.0,
        "duration": 3.599,
        "text": "more frequent checkpointing means"
      },
      {
        "start": 164.08,
        "duration": 3.439,
        "text": "recovering from a failure"
      },
      {
        "start": 165.599,
        "duration": 3.601,
        "text": "is going to be quicker there's less"
      },
      {
        "start": 167.519,
        "duration": 4.321,
        "text": "checkpoint stuff to go through"
      },
      {
        "start": 169.2,
        "duration": 3.36,
        "text": "when you come back up after having died"
      },
      {
        "start": 171.84,
        "duration": 2.8,
        "text": "however"
      },
      {
        "start": 172.56,
        "duration": 3.039,
        "text": "that's more overhead each checkpoint"
      },
      {
        "start": 174.64,
        "duration": 3.04,
        "text": "that we do"
      },
      {
        "start": 175.599,
        "duration": 3.841,
        "text": "is going to cause more file io there's"
      },
      {
        "start": 177.68,
        "duration": 2.4,
        "text": "more overhead in general so we'd rather"
      },
      {
        "start": 179.44,
        "duration": 2.799,
        "text": "not do it"
      },
      {
        "start": 180.08,
        "duration": 4.159,
        "text": "too often so that pushes us to"
      },
      {
        "start": 182.239,
        "duration": 4.241,
        "text": "infrequent checkpointing which means"
      },
      {
        "start": 184.239,
        "duration": 3.681,
        "text": "less runtime overhead faster performance"
      },
      {
        "start": 186.48,
        "duration": 2.96,
        "text": "of the spark cluster"
      },
      {
        "start": 187.92,
        "duration": 3.039,
        "text": "but when we do come back up from a"
      },
      {
        "start": 189.44,
        "duration": 3.36,
        "text": "failure it will take us"
      },
      {
        "start": 190.959,
        "duration": 3.2,
        "text": "longer so that's a decision you're going"
      },
      {
        "start": 192.8,
        "duration": 2.24,
        "text": "to have to make in the context of your"
      },
      {
        "start": 194.159,
        "duration": 3.201,
        "text": "application"
      },
      {
        "start": 195.04,
        "duration": 3.76,
        "text": "and its failure recovery requirements if"
      },
      {
        "start": 197.36,
        "duration": 3.519,
        "text": "you're looking for a rule of thumb"
      },
      {
        "start": 198.8,
        "duration": 3.2,
        "text": "you should go for 5 to 10 times the"
      },
      {
        "start": 200.879,
        "duration": 2.881,
        "text": "slide interval"
      },
      {
        "start": 202.0,
        "duration": 4.56,
        "text": "now remember the slide interval is the"
      },
      {
        "start": 203.76,
        "duration": 5.039,
        "text": "number of seconds the window moves along"
      },
      {
        "start": 206.56,
        "duration": 3.599,
        "text": "each time the transformation runs in our"
      },
      {
        "start": 208.799,
        "duration": 3.281,
        "text": "example we've been using"
      },
      {
        "start": 210.159,
        "duration": 3.841,
        "text": "4 seconds for the slide interval because"
      },
      {
        "start": 212.08,
        "duration": 3.84,
        "text": "four seconds is our batch interval"
      },
      {
        "start": 214.0,
        "duration": 3.44,
        "text": "that's just a decision we've made for"
      },
      {
        "start": 215.92,
        "duration": 2.48,
        "text": "the examples we're using to illustrate"
      },
      {
        "start": 217.44,
        "duration": 2.719,
        "text": "things here"
      },
      {
        "start": 218.4,
        "duration": 3.44,
        "text": "in your case look at what your slide"
      },
      {
        "start": 220.159,
        "duration": 3.761,
        "text": "interval is and you can use that 5 to"
      },
      {
        "start": 221.84,
        "duration": 4.08,
        "text": "10x as a rule of thumb to get started"
      },
      {
        "start": 223.92,
        "duration": 4.16,
        "text": "in order to recover from a checkpoint"
      },
      {
        "start": 225.92,
        "duration": 2.64,
        "text": "our driver initialization code has to"
      },
      {
        "start": 228.08,
        "duration": 2.159,
        "text": "look"
      },
      {
        "start": 228.56,
        "duration": 3.28,
        "text": "slightly different when we're creating a"
      },
      {
        "start": 230.239,
        "duration": 4.321,
        "text": "streaming context we don't just get it"
      },
      {
        "start": 231.84,
        "duration": 4.72,
        "text": "we get or create the streaming context"
      },
      {
        "start": 234.56,
        "duration": 3.92,
        "text": "and we pass it the checkpoint dir so"
      },
      {
        "start": 236.56,
        "duration": 2.56,
        "text": "it'll be able to go look at that path in"
      },
      {
        "start": 238.48,
        "duration": 2.88,
        "text": "cfs"
      },
      {
        "start": 239.12,
        "duration": 3.679,
        "text": "and say are there files persisted here"
      },
      {
        "start": 241.36,
        "duration": 3.439,
        "text": "am i coming up for the first time"
      },
      {
        "start": 242.799,
        "duration": 3.52,
        "text": "or am i waking up after having died and"
      },
      {
        "start": 244.799,
        "duration": 3.601,
        "text": "do i have some recovery to do"
      },
      {
        "start": 246.319,
        "duration": 3.92,
        "text": "now that create streaming context"
      },
      {
        "start": 248.4,
        "duration": 3.44,
        "text": "function is a little non-standard"
      },
      {
        "start": 250.239,
        "duration": 3.2,
        "text": "let me show you the code we have in mind"
      },
      {
        "start": 251.84,
        "duration": 3.119,
        "text": "for that a lot of this is completely"
      },
      {
        "start": 253.439,
        "duration": 2.8,
        "text": "standard just creating the spark conf"
      },
      {
        "start": 254.959,
        "duration": 2.881,
        "text": "object and getting it all"
      },
      {
        "start": 256.239,
        "duration": 3.601,
        "text": "configured creating the streaming"
      },
      {
        "start": 257.84,
        "duration": 3.519,
        "text": "context setting the batch window"
      },
      {
        "start": 259.84,
        "duration": 3.04,
        "text": "then on the stream we do set the"
      },
      {
        "start": 261.359,
        "duration": 2.641,
        "text": "checkpoint interval at this case 20"
      },
      {
        "start": 262.88,
        "duration": 3.52,
        "text": "seconds which is"
      },
      {
        "start": 264.0,
        "duration": 4.56,
        "text": "five times our batch interval so that's"
      },
      {
        "start": 266.4,
        "duration": 4.0,
        "text": "inside our rule of thumb and we also on"
      },
      {
        "start": 268.56,
        "duration": 2.56,
        "text": "the streaming context set the checkpoint"
      },
      {
        "start": 270.4,
        "duration": 2.64,
        "text": "directory"
      },
      {
        "start": 271.12,
        "duration": 2.799,
        "text": "to turn check pointing on so this is an"
      },
      {
        "start": 273.04,
        "duration": 2.0,
        "text": "example of a little bit of"
      },
      {
        "start": 273.919,
        "duration": 3.361,
        "text": "initialization code"
      },
      {
        "start": 275.04,
        "duration": 7.11,
        "text": "that is going to use checkpointing it's"
      },
      {
        "start": 277.28,
        "duration": 8.08,
        "text": "pretty simple to get it set up"
      },
      {
        "start": 282.15,
        "duration": 5.29,
        "text": "[Music]"
      },
      {
        "start": 285.36,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:19:23.753842+00:00"
}