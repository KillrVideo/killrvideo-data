{
  "video_id": "t0SDniI98n8",
  "title": "DS320.38 Spark Streaming: Persistence | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.38 Spark Streaming: Persistence\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:32:53Z",
  "thumbnail": "https://i.ytimg.com/vi/t0SDniI98n8/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=t0SDniI98n8",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] when you're just getting started with spark and the apis are really starting to click it can be really exciting and rewarding as you get a lot of computational work done in just a little bit of code but it's not exactly difficult to write sub-optimal code by not paying attention to persistence now we've covered elsewhere the idea of persisting or caching rdds this is also an important topic when it comes to streaming if you look at this code here you've got some kind of click stream data coming in on movies this is tracking user activity on particular movies shown on the killer video website and we're using the reduce by key streaming transformation to count those things up easy enough what do we do with that though at that point then we save it to cassandra and for good measure we print it now that print is a little bit contrived but think about it save to cassandra and print they're both output operations that means they're going to trigger computation twice and if you actually ran this code the way you see it here you'd do the reducing twice too and that would be a huge waste d stream persistence is a way of giving spark hints that it should persist particular d streams either to memory or to disk this way a persistent d stream can be reused by multiple output operations without having to recompute it so if you're going to call an output operation on the same d stream more than once persistence is definitely something that should be on your mind the api looks hauntingly like the caching api for rdds we've got a persist method that lets us specify a storage level which really is a way of saying do i want this to be persisted to disk or memory and the cache method which is what you're going to see most of the time which is another way of saying that you want to call the persist method specifying the memory only serialized option now when you're using a memory persistence level and something doesn't fit into memory those partitions will get kicked they will not be cached and they will be recomputed on the fly when needed so in the broader context of optimizing a spark application you want to make sure that the nodes actually have the memory to do the persisting of the partitions you're asking them to persist so this will affect the way you provision hardware how much memory you pick for nodes and the number of partitions you select for a given d stream or rdd again most commonly you'll call cache which is the equivalent of persisting with the memory only serialized option now memory only serialized uses memory a little more efficiently than memory only but at the cost of higher cpu utilization if i say memory and disk then those partitions that don't fit in memory will spill to disk rather than being discarded altogether and of course i can opt to persist a d stream only to disk now some kinds of d streams are automatically persisted and you don't even have to call cache like any update state by key transformation is going to get cached any window transformations those will be automatically persisted in memory remember that sub-optimal code we saw at the beginning the fix is really easy all we have to do is call cache at the end of our window transformation then that d stream will be persisted to memory and those two output operations that we call save to cassandra and print are going to be called on the persisted in memory version and the computation won't have to be run twice [Music] you",
    "segments": [
      {
        "start": 0.28,
        "duration": 6.489,
        "text": "[Music]"
      },
      {
        "start": 6.799,
        "duration": 2.8,
        "text": "when you're just getting started with"
      },
      {
        "start": 7.839,
        "duration": 2.481,
        "text": "spark and the apis are really starting"
      },
      {
        "start": 9.599,
        "duration": 2.401,
        "text": "to click"
      },
      {
        "start": 10.32,
        "duration": 3.52,
        "text": "it can be really exciting and rewarding"
      },
      {
        "start": 12.0,
        "duration": 3.519,
        "text": "as you get a lot of computational work"
      },
      {
        "start": 13.84,
        "duration": 3.279,
        "text": "done in just a little bit of code but"
      },
      {
        "start": 15.519,
        "duration": 4.001,
        "text": "it's not exactly difficult"
      },
      {
        "start": 17.119,
        "duration": 4.16,
        "text": "to write sub-optimal code by not paying"
      },
      {
        "start": 19.52,
        "duration": 3.999,
        "text": "attention to persistence"
      },
      {
        "start": 21.279,
        "duration": 3.521,
        "text": "now we've covered elsewhere the idea of"
      },
      {
        "start": 23.519,
        "duration": 3.84,
        "text": "persisting or caching"
      },
      {
        "start": 24.8,
        "duration": 3.84,
        "text": "rdds this is also an important topic"
      },
      {
        "start": 27.359,
        "duration": 2.801,
        "text": "when it comes to streaming"
      },
      {
        "start": 28.64,
        "duration": 4.0,
        "text": "if you look at this code here you've got"
      },
      {
        "start": 30.16,
        "duration": 5.44,
        "text": "some kind of click stream data coming in"
      },
      {
        "start": 32.64,
        "duration": 3.28,
        "text": "on movies this is tracking user activity"
      },
      {
        "start": 35.6,
        "duration": 2.72,
        "text": "on"
      },
      {
        "start": 35.92,
        "duration": 4.24,
        "text": "particular movies shown on the killer"
      },
      {
        "start": 38.32,
        "duration": 3.44,
        "text": "video website and we're using the reduce"
      },
      {
        "start": 40.16,
        "duration": 4.079,
        "text": "by key streaming transformation"
      },
      {
        "start": 41.76,
        "duration": 3.92,
        "text": "to count those things up easy enough"
      },
      {
        "start": 44.239,
        "duration": 2.961,
        "text": "what do we do with that though"
      },
      {
        "start": 45.68,
        "duration": 3.52,
        "text": "at that point then we save it to"
      },
      {
        "start": 47.2,
        "duration": 3.76,
        "text": "cassandra and for good measure"
      },
      {
        "start": 49.2,
        "duration": 3.679,
        "text": "we print it now that print is a little"
      },
      {
        "start": 50.96,
        "duration": 3.04,
        "text": "bit contrived but think about it save to"
      },
      {
        "start": 52.879,
        "duration": 2.801,
        "text": "cassandra and print"
      },
      {
        "start": 54.0,
        "duration": 2.48,
        "text": "they're both output operations that"
      },
      {
        "start": 55.68,
        "duration": 1.6,
        "text": "means they're going to trigger"
      },
      {
        "start": 56.48,
        "duration": 2.719,
        "text": "computation"
      },
      {
        "start": 57.28,
        "duration": 3.36,
        "text": "twice and if you actually ran this code"
      },
      {
        "start": 59.199,
        "duration": 2.801,
        "text": "the way you see it here you'd do the"
      },
      {
        "start": 60.64,
        "duration": 3.519,
        "text": "reducing twice too"
      },
      {
        "start": 62.0,
        "duration": 4.08,
        "text": "and that would be a huge waste d stream"
      },
      {
        "start": 64.159,
        "duration": 3.441,
        "text": "persistence is a way of giving spark"
      },
      {
        "start": 66.08,
        "duration": 4.16,
        "text": "hints that it should persist"
      },
      {
        "start": 67.6,
        "duration": 3.519,
        "text": "particular d streams either to memory or"
      },
      {
        "start": 70.24,
        "duration": 2.64,
        "text": "to disk"
      },
      {
        "start": 71.119,
        "duration": 3.841,
        "text": "this way a persistent d stream can be"
      },
      {
        "start": 72.88,
        "duration": 3.68,
        "text": "reused by multiple output operations"
      },
      {
        "start": 74.96,
        "duration": 3.04,
        "text": "without having to recompute it"
      },
      {
        "start": 76.56,
        "duration": 3.44,
        "text": "so if you're going to call an output"
      },
      {
        "start": 78.0,
        "duration": 4.0,
        "text": "operation on the same d stream"
      },
      {
        "start": 80.0,
        "duration": 3.52,
        "text": "more than once persistence is definitely"
      },
      {
        "start": 82.0,
        "duration": 4.24,
        "text": "something that should be on your mind"
      },
      {
        "start": 83.52,
        "duration": 4.48,
        "text": "the api looks hauntingly like the"
      },
      {
        "start": 86.24,
        "duration": 3.68,
        "text": "caching api for rdds"
      },
      {
        "start": 88.0,
        "duration": 4.64,
        "text": "we've got a persist method that lets us"
      },
      {
        "start": 89.92,
        "duration": 3.6,
        "text": "specify a storage level which really is"
      },
      {
        "start": 92.64,
        "duration": 2.64,
        "text": "a way of saying"
      },
      {
        "start": 93.52,
        "duration": 3.599,
        "text": "do i want this to be persisted to disk"
      },
      {
        "start": 95.28,
        "duration": 2.879,
        "text": "or memory and the cache method which is"
      },
      {
        "start": 97.119,
        "duration": 1.521,
        "text": "what you're going to see most of the"
      },
      {
        "start": 98.159,
        "duration": 2.721,
        "text": "time"
      },
      {
        "start": 98.64,
        "duration": 3.68,
        "text": "which is another way of saying that you"
      },
      {
        "start": 100.88,
        "duration": 4.239,
        "text": "want to call the persist method"
      },
      {
        "start": 102.32,
        "duration": 3.2,
        "text": "specifying the memory only serialized"
      },
      {
        "start": 105.119,
        "duration": 2.401,
        "text": "option"
      },
      {
        "start": 105.52,
        "duration": 4.0,
        "text": "now when you're using a memory"
      },
      {
        "start": 107.52,
        "duration": 3.04,
        "text": "persistence level and something doesn't"
      },
      {
        "start": 109.52,
        "duration": 2.8,
        "text": "fit into memory"
      },
      {
        "start": 110.56,
        "duration": 3.44,
        "text": "those partitions will get kicked they"
      },
      {
        "start": 112.32,
        "duration": 3.2,
        "text": "will not be cached and they will be"
      },
      {
        "start": 114.0,
        "duration": 3.84,
        "text": "recomputed on the fly"
      },
      {
        "start": 115.52,
        "duration": 4.0,
        "text": "when needed so in the broader context of"
      },
      {
        "start": 117.84,
        "duration": 3.52,
        "text": "optimizing a spark application"
      },
      {
        "start": 119.52,
        "duration": 3.52,
        "text": "you want to make sure that the nodes"
      },
      {
        "start": 121.36,
        "duration": 2.48,
        "text": "actually have the memory to do the"
      },
      {
        "start": 123.04,
        "duration": 3.439,
        "text": "persisting"
      },
      {
        "start": 123.84,
        "duration": 3.36,
        "text": "of the partitions you're asking them to"
      },
      {
        "start": 126.479,
        "duration": 1.84,
        "text": "persist"
      },
      {
        "start": 127.2,
        "duration": 2.88,
        "text": "so this will affect the way you"
      },
      {
        "start": 128.319,
        "duration": 2.401,
        "text": "provision hardware how much memory you"
      },
      {
        "start": 130.08,
        "duration": 3.519,
        "text": "pick for"
      },
      {
        "start": 130.72,
        "duration": 3.76,
        "text": "nodes and the number of partitions you"
      },
      {
        "start": 133.599,
        "duration": 3.601,
        "text": "select"
      },
      {
        "start": 134.48,
        "duration": 3.68,
        "text": "for a given d stream or rdd again most"
      },
      {
        "start": 137.2,
        "duration": 2.64,
        "text": "commonly you'll call"
      },
      {
        "start": 138.16,
        "duration": 3.52,
        "text": "cache which is the equivalent of"
      },
      {
        "start": 139.84,
        "duration": 3.2,
        "text": "persisting with the memory only"
      },
      {
        "start": 141.68,
        "duration": 4.24,
        "text": "serialized option"
      },
      {
        "start": 143.04,
        "duration": 4.16,
        "text": "now memory only serialized uses memory a"
      },
      {
        "start": 145.92,
        "duration": 3.2,
        "text": "little more efficiently"
      },
      {
        "start": 147.2,
        "duration": 3.6,
        "text": "than memory only but at the cost of"
      },
      {
        "start": 149.12,
        "duration": 4.08,
        "text": "higher cpu utilization"
      },
      {
        "start": 150.8,
        "duration": 4.48,
        "text": "if i say memory and disk then those"
      },
      {
        "start": 153.2,
        "duration": 3.119,
        "text": "partitions that don't fit in memory will"
      },
      {
        "start": 155.28,
        "duration": 2.959,
        "text": "spill to disk"
      },
      {
        "start": 156.319,
        "duration": 3.601,
        "text": "rather than being discarded altogether"
      },
      {
        "start": 158.239,
        "duration": 2.08,
        "text": "and of course i can opt to persist a d"
      },
      {
        "start": 159.92,
        "duration": 2.88,
        "text": "stream"
      },
      {
        "start": 160.319,
        "duration": 3.681,
        "text": "only to disk now some kinds of d streams"
      },
      {
        "start": 162.8,
        "duration": 2.719,
        "text": "are automatically"
      },
      {
        "start": 164.0,
        "duration": 3.44,
        "text": "persisted and you don't even have to"
      },
      {
        "start": 165.519,
        "duration": 4.321,
        "text": "call cache like any"
      },
      {
        "start": 167.44,
        "duration": 3.36,
        "text": "update state by key transformation is"
      },
      {
        "start": 169.84,
        "duration": 2.88,
        "text": "going to get cached"
      },
      {
        "start": 170.8,
        "duration": 3.12,
        "text": "any window transformations those will be"
      },
      {
        "start": 172.72,
        "duration": 3.28,
        "text": "automatically persisted"
      },
      {
        "start": 173.92,
        "duration": 3.52,
        "text": "in memory remember that sub-optimal code"
      },
      {
        "start": 176.0,
        "duration": 2.239,
        "text": "we saw at the beginning the fix is"
      },
      {
        "start": 177.44,
        "duration": 3.2,
        "text": "really easy"
      },
      {
        "start": 178.239,
        "duration": 4.801,
        "text": "all we have to do is call cache at the"
      },
      {
        "start": 180.64,
        "duration": 5.44,
        "text": "end of our window transformation"
      },
      {
        "start": 183.04,
        "duration": 4.8,
        "text": "then that d stream will be persisted to"
      },
      {
        "start": 186.08,
        "duration": 2.48,
        "text": "memory and those two output operations"
      },
      {
        "start": 187.84,
        "duration": 2.479,
        "text": "that we call"
      },
      {
        "start": 188.56,
        "duration": 3.44,
        "text": "save to cassandra and print are going to"
      },
      {
        "start": 190.319,
        "duration": 2.241,
        "text": "be called on the persisted in memory"
      },
      {
        "start": 192.0,
        "duration": 4.08,
        "text": "version"
      },
      {
        "start": 192.56,
        "duration": 3.52,
        "text": "and the computation won't have to be run"
      },
      {
        "start": 196.84,
        "duration": 5.16,
        "text": "twice"
      },
      {
        "start": 198.89,
        "duration": 5.19,
        "text": "[Music]"
      },
      {
        "start": 202.0,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:18:23.392923+00:00"
}