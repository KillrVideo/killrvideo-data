{
  "video_id": "Pt3auUZXCqE",
  "title": "Distributed Data Show Episode 21: Debugging Gremlin Queries with Duy Hai Doan",
  "description": "DuyHai Doan shares his advice on debugging graph traversals using the Gremlin query language, including how to identify and fix performance bottlenecks and his thoughts on the “supernode” challenge.\n\nABOUT DATASTAX ENTERPRISE 5.1\nDataStax Enterprise 5.1, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.1 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax Enterprise©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-11-14T16:00:04Z",
  "thumbnail": "https://i.ytimg.com/vi/Pt3auUZXCqE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "query",
    "database",
    "apache_cassandra",
    "tutorial",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=Pt3auUZXCqE",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems man I love our walk-up music you know in the studio we listen to the theme music that kicks off our show before we start the episode just to get us in the mood this is Jeff carpenter I'm here with do we hi John hello Jeff - technical advocate here at data stacks and you're out of Paris yeah excellent and today we want to talk about debugging gremlin traversals and the first thing I want to say is wait a minute I know you as the deep dive expert on all things Apache Cassandra and digging into things like secondary indexes and materialized views and understanding what's going on under the hood so I don't know what's what's going on here like what's the sudden interesting graph yeah very good question so I used to tell people that that want to make a career in as a software developer try to learn a new language programming language I mean every two years the reason is you need to keep your mind flexible you need to learn new paradigm right and in fact graph is a new paradigm it's a new way to model your data so when is it useful when is it relevant to use graph tomorrow Loretta the key point is if you have a lot of connected data and if you have a lot of value in relationships which in your data graph is a good fit and in fact I really like a gremlin query language because again it's a new way to query data it's not a declarative way it's not an imperative way so it's a what I would say I would define it as a descriptive way of query your reader what I what I mean by descriptive is it is very visual you have the graph schema you have one vertex connected to another vertex by some edges right and with gremlin you would say I will start from this vertex going out because each Edge has a direction going out using this edge to another vertex going back going out to another vertex so it is completely a descriptive query language awesome so yeah and I think that you described that very well like you can really visualize the relationships between the different pieces of the graph I really like a description that i heard from martin Clubman from his designing data intensive applications book which it's in a riley book it's a really i highly recommend it it's I found it pretty enjoyable and one of the things that he describes about graph databases is that they're very good at capturing those many-to-many relationships which is exactly that highly connected data so we we've had some previous episodes on the distributed data show where we've talked about graph technology in particular we had Sebastian Aceves on and talked about optimizing some of our gremlin queries and then we've also had Bob Bridey on and we had him talk about data stack studio and some of the power features that are in there for working with graphs so we want to take a little bit different angle with you today and really talk about this this debugging aspect of working with gremlin queries so what are the techniques that we have that you recommend for doing that so personally the the first time I learn gremlin travel sauce and the syntax it was very weird for me like I have this because medium sized travel sauce and at the time I didn't when I click on execute sometimes I don't get the resort I expected I said why I expect it to have some vortices or some value scholar value why don't I have it right why do I have something different and my approach to any technology is to try to understand the underlying layer so my approach to understand gremlin step and reversal is you should know what you are dealing with what is the data type at each step for example G dot V V means vertices so you have you have vertices in fact each step in remnant will produce an iterator of something right right some distant thing can be a vertex on edge so G dot V is an eater of the text and then out I don't know some relationship connected to we move you to another iterator of vertex and so on and so on and of course vertex is a very generic description what you want to know is what kind of vertex what is the vertex label of these things and there is a very simple way to know the data type at each step is to use the you know the iterator interface in Java has exposes the method next he made the next element in my iterator so G dot V dot plus something dot next you will fetch the element at just a single one and then not get class that get class we tell you it is a vertex it is an edge or sometime it is a scalar value or maybe some map because when you are doing when you are using the group step if we produce a map of key value right so the key things is to use neck dot get class every time you have a doubt and you can put this neck next dot get class in the middle of your Traverse or if you get lost right sometimes you have so huge a traversal spanning so 10 lines that you a completely lost you don't know where where am I and then you can you put that in a like a debug logging statement or how do you get that out you're in the middle of that traversal and then you can you're getting the class and then you want to output that somehow to figure out or are you just running in a debugger - no I just I just comment out the rest of the travelers oh and just put my next dot get class in the middle okay so the advantage of next up get grass is Bureau of just fetching just one element right so the performance impact is very minimal minimal yeah excellent all right so what did some of the other techniques we talked about the gate class what are the techniques you have it that you recommend for debugging so yet class is to understand the data type mm-hmm your traversal now you have you will face also sometimes performance issues like why does it take so long right there is a step a special step increment which is called profile very useful when you put a profiling gremlin will give you for each step the number of traverses that actually travels this step and also the duration the total duration in millisecond so you can just spot ok 99% of my travel some time has been spent on this group count or whatever right so you know ok this one is too expensive maybe I need to optimize this step sorry giving you a trace exactly hold right out I will say that performance steps profile is very equivalent to you know explain explain plan in square right so not to be confused with there's another useful step for debugging which is explain so explain is a little bit different explain will just show you all the strategies used by the actual traversal and all the step implementation but it didn't give you any information about the performance right so I would prefer most of the time I prefer profile although I explained okay good so we've talked a little bit already about debugging for errors and just trying to understand what's happening in our query and also about debugging for performance now a lot of times it it might be pretty easy to determine that okay here's the step that I'm losing all my time on that's the non performance step but then you kind of need that next level of understanding about what's really going on why is that part of my traversal slow so what do we need to pay attention to in order to really understand what's going on and what's making our queries perform poorly like what do we need to understand about what's going on under the hood and the thing to understand we've gremlin is you have two execution mode so by default Kremlin is using an OLTP mode which we call lazy evaluation if you are familiar with Java 8's the stream API it should know that the stream API is used lazy evaluation so you can define mainly filtering step or map step as you wish as as long as you don't have a final step nothing is executed so it's very similar with lazy evaluation in Kremlin and in Greenland you have two execution mode as I said when TP and Ola so LTP means real-time real-time query that consume few resources my resources I mean memory CPU the success usually when you are using LG p-mod you are accessing a single vertex a small set of the vertices using either primary key access rows or indices for example give me all the users living in this state or in the city so necessarily you have to define Sakharine to be able to access them and usually in oil GP mode the query duration is between millisecond up to a few seconds for very complex turbos so now the the other execution mode is Allah this execution mode or lab is more suited for batch processing and it will consume a lot of resources the main reason is the pattern of OLAP is when you perform a fool's almost a full table scan food crafts can get let me give you an example say you have a graph schema of social network vertex user knows all the users very simple schema but you have millions of vertex but it is and billions of edges right now if you issue a query like ok G dot V that group counts something like this a group by oh I want to group all the user by their number of outgoing the number of friends first-degree friends and then do an order by descending order and just like the top 10 this query this traversal is typically an OLAP why because to be able to do a grouping you need two full scan your graph right and necessarily necessarily full scanning a graph we spend a lot of time right usually when you you are in a batch mode that the time it takes for the traversal to complete is between minutes maybe some time hours if you have a huge graph and very complex travels there's another thing to pay attention to is the what I call the combinatorial explosion even though you have a real-time query you say let's say you start from one user and you expand to its friends out nose right gee that vid has user ID from something else no so give me all the first-degree friends of this this person this can turn quickly into an OLAP query if you are unlucky and if you have this special user has a lots of friends so that's what we call come combinatorial explosion and imagine that your your traversal is a little bit more involved than just this so from one user you you fetch all of his friends and you want to get all the move the science-fiction movies they like right so very simple query when you describe it in English but in terms of processing environment one user 1,000 friends already one level of explosion each friends likes I don't know 10 to 20 science-fiction movies you just do the mass right it adds up very fast so it sounds like you can sort of accidentally without really thinking about it go from a fairly small reasonable size traversal to this combinatorial explosion which then turns it really into an OLAP kind of problem so how what can we do to limit those combinatorial explosions because sometimes we may not really intend to walk the entire graph so what can we do so that several solution mmm this is it there isn't any which is perfect so let me just list all of them first you can use the limit steps okay okay okay give me all friends of this user limit for example 210 now 21 of them whatever but the problem of limit is it's very restrictive right you if you want to know a little bit about this user even limit will restrict your your space right you can use also a very useful step in Grameen which it's called time limit so time limit is a little bit special it doesn't put a hard limit on the number of vertices or edges you want to fetch for the next step it will just start a kind of counter a time countdown mm-hm okay to say okay I want to time limit this step to maximum I don't know one second so Grambling can fire many traverser to explore all the branches but as soon as the countdown reaches one second trembling will stop exploring so it's very nice because you put a very strict control on the timing of your toggle so so I'm gonna get the best answer I can in this amount of time one second yeah so but but the drawback is you don't you don't control what kind of ends on you because the only thing you control is the time the timing be careful when you are using again a repeat step I just to forget to mention earlier the repeat step can explode pretty fast because people use repeat for looping yes on a social network graph just looking two times you start from single vertex and just looping two times you can finish with 10000 vertex recursion is the recursion right we might have learned that in our first programming class are not a funny step I call it funny is the sample so the the sample step the idea is instead of fetching all the friends of my user I will just take some of them so you can say sample 100 sample 15 and this step will just randomly pick 100 of 15 the the difference between sample and limit is limit will just follow of the order right okay I stopped with the first friend second fan the ordering is given by the storage engine underneath sample just introduce some kind of random randomness into the process right so it's nice if you don't care about the honouring you just want to fetch some of the data to have to visualize them to have an idea about your data so some sample can be nice in this context and another technique is also to to restrict to have a very restrictive interring on your travel so so for example I would say okay start from this user and give me all of instead of instead of giving all his first-degree friends I would say give me all have his first-degree friends whose age is between 20 and 25 living in this city so you had so many criteria for filtering that in the end the result set is quite small but even this is not warranted right it depends on the criteria for example living in San Francisco oh my god how many people are living the city if you are living in San Francisco you may have many friends all right right so even restrictive enduring is not perfect solution gotcha okay so a minute ago I want to I want to pull you back to something we were talking about a minute ago this problem of the super node and in the classic example is in that social network graph you have the Justin Bieber node that everyone likes maybe not everyone but a large number of likes into that one node so it seems like any traversal that's kind of kind of walked through that node has the potential to really be a performance bottleneck so what can we do so I would say that this scenario should this kind of problem the super node problem in my opinion should be solved at the storage engine layer I mean should be solved at the customer layer and how how can we solve it by supporting huge partitions in kasama okay we know that we used to tell people okay be careful about the size of your partition try to control it and if you know that your partition is going to grow very very huge try to sub partition by introducing a date in your partition key right right a big break instead large particular again the problem with this kind of design because I have faced this situation many times when I'm doing a data modelling for customer is because of some special case in your dataset imagine you have a data set where 99.9 percent of the time people have a normal cardinality like small to medium partition size and for some odd years values they have huge partition some one to ten huge partition because of this one percent we need to accommodate all of our data model and you know that when you are bucket icing and you are doing sub partitioning you put a constraint on your query because now your partition key contain a bucket column right and so now you end up doing these multi partition queries whereas you would not have had to do that exactly and so I think that if we can support huge partition natively in in kasama it will be the best answer and for people who are worried about hotspot because of course when we talk about huge partition which concern only one percent of our data set people who raised their hand and say oh but it means that some not which are hosting those huge partition will contain more data right so we have but distribution of data not really if we think about the the amount the total amount of data if you have some Justin Bieber's among your users mm-hmm let's say a dozen of Justin Bieber but on the other side you have millions tens of millions of normal user right in fact the the difference in size will be averaged out completely you not see that huge difference in term of data between the different nodes gotcha well you haven't disappointed me do we high I in the end we did come back to Cassandra yeah we did end up talking about the storage layer so your your super node at the graph layer becomes the the very large partition down at the at the Cassandra layer for the storage layer for graph so okay so I do we have time for one bonus question do you think yeah so well one bonus announcement idea so yeah stay tuned because we this a stack we are working very hard to try to solve this huge partition problem and in future release of DSC we will try to address this problem so wait and see what so more to come maybe a good future episode of the distributed data show yeah thanks for watching thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data Stax Academy and tell us what you think you can also find us on the data Stax Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.37,
        "duration": 4.11,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.48,
        "duration": 4.17,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.25,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.789,
        "text": "large-scale distributed systems man I"
      },
      {
        "start": 16.71,
        "duration": 5.19,
        "text": "love our walk-up music you know in the"
      },
      {
        "start": 19.439,
        "duration": 4.471,
        "text": "studio we listen to the theme music that"
      },
      {
        "start": 21.9,
        "duration": 4.619,
        "text": "kicks off our show before we start the"
      },
      {
        "start": 23.91,
        "duration": 3.51,
        "text": "episode just to get us in the mood this"
      },
      {
        "start": 26.519,
        "duration": 4.02,
        "text": "is Jeff carpenter"
      },
      {
        "start": 27.42,
        "duration": 5.43,
        "text": "I'm here with do we hi John hello Jeff -"
      },
      {
        "start": 30.539,
        "duration": 7.231,
        "text": "technical advocate here at data stacks"
      },
      {
        "start": 32.85,
        "duration": 7.5,
        "text": "and you're out of Paris yeah excellent"
      },
      {
        "start": 37.77,
        "duration": 5.43,
        "text": "and today we want to talk about"
      },
      {
        "start": 40.35,
        "duration": 5.7,
        "text": "debugging gremlin traversals and the"
      },
      {
        "start": 43.2,
        "duration": 6.21,
        "text": "first thing I want to say is wait a"
      },
      {
        "start": 46.05,
        "duration": 5.91,
        "text": "minute I know you as the deep dive"
      },
      {
        "start": 49.41,
        "duration": 5.219,
        "text": "expert on all things Apache Cassandra"
      },
      {
        "start": 51.96,
        "duration": 4.919,
        "text": "and digging into things like secondary"
      },
      {
        "start": 54.629,
        "duration": 4.2,
        "text": "indexes and materialized views and"
      },
      {
        "start": 56.879,
        "duration": 5.791,
        "text": "understanding what's going on under the"
      },
      {
        "start": 58.829,
        "duration": 5.37,
        "text": "hood so I don't know what's what's going"
      },
      {
        "start": 62.67,
        "duration": 4.5,
        "text": "on here like what's the sudden"
      },
      {
        "start": 64.199,
        "duration": 8.061,
        "text": "interesting graph yeah very good"
      },
      {
        "start": 67.17,
        "duration": 9.39,
        "text": "question so I used to tell people that"
      },
      {
        "start": 72.26,
        "duration": 6.31,
        "text": "that want to make a career in as a"
      },
      {
        "start": 76.56,
        "duration": 3.93,
        "text": "software developer try to learn a new"
      },
      {
        "start": 78.57,
        "duration": 7.35,
        "text": "language programming language I mean"
      },
      {
        "start": 80.49,
        "duration": 8.19,
        "text": "every two years the reason is you need"
      },
      {
        "start": 85.92,
        "duration": 6.36,
        "text": "to keep your mind flexible you need to"
      },
      {
        "start": 88.68,
        "duration": 7.5,
        "text": "learn new paradigm right and in fact"
      },
      {
        "start": 92.28,
        "duration": 7.699,
        "text": "graph is a new paradigm it's a new way"
      },
      {
        "start": 96.18,
        "duration": 6.24,
        "text": "to model your data so when is it useful"
      },
      {
        "start": 99.979,
        "duration": 6.971,
        "text": "when is it relevant to use graph"
      },
      {
        "start": 102.42,
        "duration": 7.979,
        "text": "tomorrow Loretta the key point is if you"
      },
      {
        "start": 106.95,
        "duration": 6.36,
        "text": "have a lot of connected data and if you"
      },
      {
        "start": 110.399,
        "duration": 5.79,
        "text": "have a lot of value in relationships"
      },
      {
        "start": 113.31,
        "duration": 8.059,
        "text": "which in your data graph is a good fit"
      },
      {
        "start": 116.189,
        "duration": 9.93,
        "text": "and in fact I really like a gremlin"
      },
      {
        "start": 121.369,
        "duration": 7.731,
        "text": "query language because again it's a new"
      },
      {
        "start": 126.119,
        "duration": 6.731,
        "text": "way to query data it's not"
      },
      {
        "start": 129.1,
        "duration": 8.55,
        "text": "a declarative way it's not an imperative"
      },
      {
        "start": 132.85,
        "duration": 8.16,
        "text": "way so it's a what I would say I would"
      },
      {
        "start": 137.65,
        "duration": 6.93,
        "text": "define it as a descriptive way of query"
      },
      {
        "start": 141.01,
        "duration": 7.65,
        "text": "your reader what I what I mean by"
      },
      {
        "start": 144.58,
        "duration": 5.94,
        "text": "descriptive is it is very visual you"
      },
      {
        "start": 148.66,
        "duration": 4.29,
        "text": "have the graph schema you have one"
      },
      {
        "start": 150.52,
        "duration": 5.58,
        "text": "vertex connected to another vertex by"
      },
      {
        "start": 152.95,
        "duration": 6.78,
        "text": "some edges right and with gremlin you"
      },
      {
        "start": 156.1,
        "duration": 7.08,
        "text": "would say I will start from this vertex"
      },
      {
        "start": 159.73,
        "duration": 7.11,
        "text": "going out because each Edge has a"
      },
      {
        "start": 163.18,
        "duration": 7.29,
        "text": "direction going out using this edge to"
      },
      {
        "start": 166.84,
        "duration": 6.86,
        "text": "another vertex going back going out to"
      },
      {
        "start": 170.47,
        "duration": 6.9,
        "text": "another vertex so it is completely a"
      },
      {
        "start": 173.7,
        "duration": 5.92,
        "text": "descriptive query language awesome so"
      },
      {
        "start": 177.37,
        "duration": 3.78,
        "text": "yeah and I think that you described that"
      },
      {
        "start": 179.62,
        "duration": 3.6,
        "text": "very well like you can really visualize"
      },
      {
        "start": 181.15,
        "duration": 4.35,
        "text": "the relationships between the different"
      },
      {
        "start": 183.22,
        "duration": 4.59,
        "text": "pieces of the graph I really like a"
      },
      {
        "start": 185.5,
        "duration": 4.08,
        "text": "description that i heard from martin"
      },
      {
        "start": 187.81,
        "duration": 4.29,
        "text": "Clubman from his designing data"
      },
      {
        "start": 189.58,
        "duration": 4.59,
        "text": "intensive applications book which it's"
      },
      {
        "start": 192.1,
        "duration": 5.31,
        "text": "in a riley book it's a really i highly"
      },
      {
        "start": 194.17,
        "duration": 4.74,
        "text": "recommend it it's I found it pretty"
      },
      {
        "start": 197.41,
        "duration": 3.15,
        "text": "enjoyable and one of the things that he"
      },
      {
        "start": 198.91,
        "duration": 3.12,
        "text": "describes about graph databases is that"
      },
      {
        "start": 200.56,
        "duration": 3.75,
        "text": "they're very good at capturing those"
      },
      {
        "start": 202.03,
        "duration": 5.96,
        "text": "many-to-many relationships which is"
      },
      {
        "start": 204.31,
        "duration": 6.63,
        "text": "exactly that highly connected data so we"
      },
      {
        "start": 207.99,
        "duration": 4.51,
        "text": "we've had some previous episodes on the"
      },
      {
        "start": 210.94,
        "duration": 4.35,
        "text": "distributed data show where we've talked"
      },
      {
        "start": 212.5,
        "duration": 5.96,
        "text": "about graph technology in particular we"
      },
      {
        "start": 215.29,
        "duration": 5.76,
        "text": "had Sebastian Aceves on and talked about"
      },
      {
        "start": 218.46,
        "duration": 4.72,
        "text": "optimizing some of our gremlin queries"
      },
      {
        "start": 221.05,
        "duration": 4.56,
        "text": "and then we've also had Bob Bridey on"
      },
      {
        "start": 223.18,
        "duration": 3.87,
        "text": "and we had him talk about data stack"
      },
      {
        "start": 225.61,
        "duration": 2.91,
        "text": "studio and some of the power features"
      },
      {
        "start": 227.05,
        "duration": 3.63,
        "text": "that are in there for working with"
      },
      {
        "start": 228.52,
        "duration": 4.14,
        "text": "graphs so we want to take a little bit"
      },
      {
        "start": 230.68,
        "duration": 4.59,
        "text": "different angle with you today and"
      },
      {
        "start": 232.66,
        "duration": 5.49,
        "text": "really talk about this this debugging"
      },
      {
        "start": 235.27,
        "duration": 4.68,
        "text": "aspect of working with gremlin queries"
      },
      {
        "start": 238.15,
        "duration": 4.44,
        "text": "so what are the techniques that we have"
      },
      {
        "start": 239.95,
        "duration": 6.14,
        "text": "that you recommend for doing that so"
      },
      {
        "start": 242.59,
        "duration": 7.38,
        "text": "personally the the first time I learn"
      },
      {
        "start": 246.09,
        "duration": 7.15,
        "text": "gremlin travel sauce and the syntax it"
      },
      {
        "start": 249.97,
        "duration": 7.62,
        "text": "was very weird for me like I have this"
      },
      {
        "start": 253.24,
        "duration": 6.059,
        "text": "because medium sized travel sauce and at"
      },
      {
        "start": 257.59,
        "duration": 4.71,
        "text": "the time I didn't when I click on"
      },
      {
        "start": 259.299,
        "duration": 8.041,
        "text": "execute sometimes I don't get the resort"
      },
      {
        "start": 262.3,
        "duration": 7.859,
        "text": "I expected I said why I expect it to"
      },
      {
        "start": 267.34,
        "duration": 5.52,
        "text": "have some vortices or some value scholar"
      },
      {
        "start": 270.159,
        "duration": 5.461,
        "text": "value why don't I have it right why do I"
      },
      {
        "start": 272.86,
        "duration": 5.1,
        "text": "have something different and my approach"
      },
      {
        "start": 275.62,
        "duration": 7.35,
        "text": "to any technology is to try to"
      },
      {
        "start": 277.96,
        "duration": 8.4,
        "text": "understand the underlying layer so my"
      },
      {
        "start": 282.97,
        "duration": 6.87,
        "text": "approach to understand gremlin step and"
      },
      {
        "start": 286.36,
        "duration": 6.119,
        "text": "reversal is you should know what you are"
      },
      {
        "start": 289.84,
        "duration": 6.87,
        "text": "dealing with what is the data type at"
      },
      {
        "start": 292.479,
        "duration": 7.111,
        "text": "each step for example G dot V V means"
      },
      {
        "start": 296.71,
        "duration": 7.049,
        "text": "vertices so you have you have vertices"
      },
      {
        "start": 299.59,
        "duration": 6.6,
        "text": "in fact each step in remnant will"
      },
      {
        "start": 303.759,
        "duration": 5.97,
        "text": "produce an iterator of something right"
      },
      {
        "start": 306.19,
        "duration": 7.14,
        "text": "right some distant thing can be a vertex"
      },
      {
        "start": 309.729,
        "duration": 7.171,
        "text": "on edge so G dot V is an eater of the"
      },
      {
        "start": 313.33,
        "duration": 8.76,
        "text": "text and then out I don't know some"
      },
      {
        "start": 316.9,
        "duration": 9.18,
        "text": "relationship connected to we move you to"
      },
      {
        "start": 322.09,
        "duration": 8.189,
        "text": "another iterator of vertex and so on and"
      },
      {
        "start": 326.08,
        "duration": 7.32,
        "text": "so on and of course vertex is a very"
      },
      {
        "start": 330.279,
        "duration": 5.971,
        "text": "generic description what you want to"
      },
      {
        "start": 333.4,
        "duration": 6.12,
        "text": "know is what kind of vertex what is the"
      },
      {
        "start": 336.25,
        "duration": 6.569,
        "text": "vertex label of these things and there"
      },
      {
        "start": 339.52,
        "duration": 8.63,
        "text": "is a very simple way to know the data"
      },
      {
        "start": 342.819,
        "duration": 8.931,
        "text": "type at each step is to use the you know"
      },
      {
        "start": 348.15,
        "duration": 7.06,
        "text": "the iterator interface in Java has"
      },
      {
        "start": 351.75,
        "duration": 7.27,
        "text": "exposes the method next he made the next"
      },
      {
        "start": 355.21,
        "duration": 6.69,
        "text": "element in my iterator so G dot V dot"
      },
      {
        "start": 359.02,
        "duration": 5.67,
        "text": "plus something dot next you will fetch"
      },
      {
        "start": 361.9,
        "duration": 5.28,
        "text": "the element at just a single one and"
      },
      {
        "start": 364.69,
        "duration": 5.069,
        "text": "then not get class that get class we"
      },
      {
        "start": 367.18,
        "duration": 5.609,
        "text": "tell you it is a vertex it is an edge or"
      },
      {
        "start": 369.759,
        "duration": 5.791,
        "text": "sometime it is a scalar value or maybe"
      },
      {
        "start": 372.789,
        "duration": 6.0,
        "text": "some map because when you are doing when"
      },
      {
        "start": 375.55,
        "duration": 6.03,
        "text": "you are using the group step if we"
      },
      {
        "start": 378.789,
        "duration": 5.19,
        "text": "produce a map of key value right so the"
      },
      {
        "start": 381.58,
        "duration": 5.369,
        "text": "key things is to use neck dot get class"
      },
      {
        "start": 383.979,
        "duration": 6.0,
        "text": "every time you have a doubt and you can"
      },
      {
        "start": 386.949,
        "duration": 5.791,
        "text": "put this neck next dot get class in the"
      },
      {
        "start": 389.979,
        "duration": 6.041,
        "text": "middle of your Traverse or if you get"
      },
      {
        "start": 392.74,
        "duration": 6.549,
        "text": "lost right sometimes you have so huge"
      },
      {
        "start": 396.02,
        "duration": 4.799,
        "text": "a traversal spanning so 10 lines that"
      },
      {
        "start": 399.289,
        "duration": 3.391,
        "text": "you a completely lost you don't know"
      },
      {
        "start": 400.819,
        "duration": 4.021,
        "text": "where where am I"
      },
      {
        "start": 402.68,
        "duration": 4.38,
        "text": "and then you can you put that in a like"
      },
      {
        "start": 404.84,
        "duration": 3.63,
        "text": "a debug logging statement or how do you"
      },
      {
        "start": 407.06,
        "duration": 2.88,
        "text": "get that out you're in the middle of"
      },
      {
        "start": 408.47,
        "duration": 3.06,
        "text": "that traversal and then you can you're"
      },
      {
        "start": 409.94,
        "duration": 3.39,
        "text": "getting the class and then you want to"
      },
      {
        "start": 411.53,
        "duration": 3.449,
        "text": "output that somehow to figure out or are"
      },
      {
        "start": 413.33,
        "duration": 4.53,
        "text": "you just running in a debugger - no I"
      },
      {
        "start": 414.979,
        "duration": 5.34,
        "text": "just I just comment out the rest of the"
      },
      {
        "start": 417.86,
        "duration": 5.13,
        "text": "travelers oh and just put my next dot"
      },
      {
        "start": 420.319,
        "duration": 4.771,
        "text": "get class in the middle okay so the"
      },
      {
        "start": 422.99,
        "duration": 5.28,
        "text": "advantage of next up get grass is Bureau"
      },
      {
        "start": 425.09,
        "duration": 4.979,
        "text": "of just fetching just one element right"
      },
      {
        "start": 428.27,
        "duration": 6.57,
        "text": "so the performance impact is very"
      },
      {
        "start": 430.069,
        "duration": 6.061,
        "text": "minimal minimal yeah excellent all right"
      },
      {
        "start": 434.84,
        "duration": 5.34,
        "text": "so what did some of the other techniques"
      },
      {
        "start": 436.13,
        "duration": 5.34,
        "text": "we talked about the gate class what are"
      },
      {
        "start": 440.18,
        "duration": 5.459,
        "text": "the techniques you have it that you"
      },
      {
        "start": 441.47,
        "duration": 7.05,
        "text": "recommend for debugging so yet class is"
      },
      {
        "start": 445.639,
        "duration": 6.721,
        "text": "to understand the data type mm-hmm your"
      },
      {
        "start": 448.52,
        "duration": 6.03,
        "text": "traversal now you have you will face"
      },
      {
        "start": 452.36,
        "duration": 6.989,
        "text": "also sometimes performance issues like"
      },
      {
        "start": 454.55,
        "duration": 7.41,
        "text": "why does it take so long right there is"
      },
      {
        "start": 459.349,
        "duration": 6.54,
        "text": "a step a special step increment which is"
      },
      {
        "start": 461.96,
        "duration": 9.209,
        "text": "called profile very useful when you put"
      },
      {
        "start": 465.889,
        "duration": 9.9,
        "text": "a profiling gremlin will give you for"
      },
      {
        "start": 471.169,
        "duration": 7.68,
        "text": "each step the number of traverses that"
      },
      {
        "start": 475.789,
        "duration": 5.791,
        "text": "actually travels this step and also the"
      },
      {
        "start": 478.849,
        "duration": 7.171,
        "text": "duration the total duration in"
      },
      {
        "start": 481.58,
        "duration": 7.32,
        "text": "millisecond so you can just spot ok 99%"
      },
      {
        "start": 486.02,
        "duration": 5.639,
        "text": "of my travel some time has been spent on"
      },
      {
        "start": 488.9,
        "duration": 4.71,
        "text": "this group count or whatever right so"
      },
      {
        "start": 491.659,
        "duration": 5.01,
        "text": "you know ok this one is too expensive"
      },
      {
        "start": 493.61,
        "duration": 5.549,
        "text": "maybe I need to optimize this step sorry"
      },
      {
        "start": 496.669,
        "duration": 4.86,
        "text": "giving you a trace exactly hold right"
      },
      {
        "start": 499.159,
        "duration": 5.1,
        "text": "out I will say that performance steps"
      },
      {
        "start": 501.529,
        "duration": 9.181,
        "text": "profile is very equivalent to you know"
      },
      {
        "start": 504.259,
        "duration": 9.32,
        "text": "explain explain plan in square right so"
      },
      {
        "start": 510.71,
        "duration": 6.03,
        "text": "not to be confused with there's another"
      },
      {
        "start": 513.579,
        "duration": 6.07,
        "text": "useful step for debugging which is"
      },
      {
        "start": 516.74,
        "duration": 6.299,
        "text": "explain so explain is a little bit"
      },
      {
        "start": 519.649,
        "duration": 7.5,
        "text": "different explain will just show you all"
      },
      {
        "start": 523.039,
        "duration": 5.881,
        "text": "the strategies used by the actual"
      },
      {
        "start": 527.149,
        "duration": 3.231,
        "text": "traversal and all the step"
      },
      {
        "start": 528.92,
        "duration": 4.29,
        "text": "implementation"
      },
      {
        "start": 530.38,
        "duration": 6.31,
        "text": "but it didn't give you any information"
      },
      {
        "start": 533.21,
        "duration": 5.82,
        "text": "about the performance right so I would"
      },
      {
        "start": 536.69,
        "duration": 5.97,
        "text": "prefer most of the time I prefer profile"
      },
      {
        "start": 539.03,
        "duration": 5.18,
        "text": "although I explained okay good so we've"
      },
      {
        "start": 542.66,
        "duration": 4.26,
        "text": "talked a little bit already about"
      },
      {
        "start": 544.21,
        "duration": 4.54,
        "text": "debugging for errors and just trying to"
      },
      {
        "start": 546.92,
        "duration": 5.55,
        "text": "understand what's happening in our query"
      },
      {
        "start": 548.75,
        "duration": 6.48,
        "text": "and also about debugging for performance"
      },
      {
        "start": 552.47,
        "duration": 5.43,
        "text": "now a lot of times it it might be pretty"
      },
      {
        "start": 555.23,
        "duration": 5.28,
        "text": "easy to determine that okay here's the"
      },
      {
        "start": 557.9,
        "duration": 5.96,
        "text": "step that I'm losing all my time on"
      },
      {
        "start": 560.51,
        "duration": 6.06,
        "text": "that's the non performance step but then"
      },
      {
        "start": 563.86,
        "duration": 4.36,
        "text": "you kind of need that next level of"
      },
      {
        "start": 566.57,
        "duration": 5.22,
        "text": "understanding about what's really going"
      },
      {
        "start": 568.22,
        "duration": 5.94,
        "text": "on why is that part of my traversal slow"
      },
      {
        "start": 571.79,
        "duration": 4.38,
        "text": "so what do we need to pay attention to"
      },
      {
        "start": 574.16,
        "duration": 3.45,
        "text": "in order to really understand what's"
      },
      {
        "start": 576.17,
        "duration": 3.24,
        "text": "going on and what's making our queries"
      },
      {
        "start": 577.61,
        "duration": 3.48,
        "text": "perform poorly like what do we need to"
      },
      {
        "start": 579.41,
        "duration": 4.02,
        "text": "understand about what's going on under"
      },
      {
        "start": 581.09,
        "duration": 5.16,
        "text": "the hood and the thing to understand"
      },
      {
        "start": 583.43,
        "duration": 7.11,
        "text": "we've gremlin is you have two execution"
      },
      {
        "start": 586.25,
        "duration": 7.62,
        "text": "mode so by default Kremlin is using an"
      },
      {
        "start": 590.54,
        "duration": 7.05,
        "text": "OLTP mode which we call lazy evaluation"
      },
      {
        "start": 593.87,
        "duration": 5.85,
        "text": "if you are familiar with Java 8's the"
      },
      {
        "start": 597.59,
        "duration": 6.09,
        "text": "stream API it should know that the"
      },
      {
        "start": 599.72,
        "duration": 5.85,
        "text": "stream API is used lazy evaluation so"
      },
      {
        "start": 603.68,
        "duration": 5.1,
        "text": "you can define mainly filtering step or"
      },
      {
        "start": 605.57,
        "duration": 5.19,
        "text": "map step as you wish as as long as you"
      },
      {
        "start": 608.78,
        "duration": 5.16,
        "text": "don't have a final step nothing is"
      },
      {
        "start": 610.76,
        "duration": 6.18,
        "text": "executed so it's very similar with lazy"
      },
      {
        "start": 613.94,
        "duration": 5.91,
        "text": "evaluation in Kremlin and in Greenland"
      },
      {
        "start": 616.94,
        "duration": 7.64,
        "text": "you have two execution mode as I said"
      },
      {
        "start": 619.85,
        "duration": 9.09,
        "text": "when TP and Ola so LTP means real-time"
      },
      {
        "start": 624.58,
        "duration": 8.08,
        "text": "real-time query that consume few"
      },
      {
        "start": 628.94,
        "duration": 8.37,
        "text": "resources my resources I mean memory CPU"
      },
      {
        "start": 632.66,
        "duration": 8.58,
        "text": "the success usually when you are using"
      },
      {
        "start": 637.31,
        "duration": 8.67,
        "text": "LG p-mod you are accessing a single"
      },
      {
        "start": 641.24,
        "duration": 8.4,
        "text": "vertex a small set of the vertices using"
      },
      {
        "start": 645.98,
        "duration": 7.95,
        "text": "either primary key access rows or"
      },
      {
        "start": 649.64,
        "duration": 7.53,
        "text": "indices for example give me all the"
      },
      {
        "start": 653.93,
        "duration": 7.02,
        "text": "users living in this state or in the"
      },
      {
        "start": 657.17,
        "duration": 5.05,
        "text": "city so necessarily you have to define"
      },
      {
        "start": 660.95,
        "duration": 5.08,
        "text": "Sakharine"
      },
      {
        "start": 662.22,
        "duration": 8.07,
        "text": "to be able to access them and usually in"
      },
      {
        "start": 666.03,
        "duration": 7.68,
        "text": "oil GP mode the query duration is"
      },
      {
        "start": 670.29,
        "duration": 8.46,
        "text": "between millisecond up to a few seconds"
      },
      {
        "start": 673.71,
        "duration": 7.95,
        "text": "for very complex turbos so now the the"
      },
      {
        "start": 678.75,
        "duration": 6.03,
        "text": "other execution mode is Allah this"
      },
      {
        "start": 681.66,
        "duration": 8.43,
        "text": "execution mode or lab is more suited for"
      },
      {
        "start": 684.78,
        "duration": 8.07,
        "text": "batch processing and it will consume a"
      },
      {
        "start": 690.09,
        "duration": 7.05,
        "text": "lot of resources the main reason is the"
      },
      {
        "start": 692.85,
        "duration": 6.66,
        "text": "pattern of OLAP is when you perform a"
      },
      {
        "start": 697.14,
        "duration": 4.71,
        "text": "fool's almost a full table scan food"
      },
      {
        "start": 699.51,
        "duration": 5.97,
        "text": "crafts can get let me give you an"
      },
      {
        "start": 701.85,
        "duration": 7.98,
        "text": "example say you have a graph schema of"
      },
      {
        "start": 705.48,
        "duration": 7.92,
        "text": "social network vertex user knows all the"
      },
      {
        "start": 709.83,
        "duration": 6.2,
        "text": "users very simple schema but you have"
      },
      {
        "start": 713.4,
        "duration": 7.35,
        "text": "millions of vertex but it is and"
      },
      {
        "start": 716.03,
        "duration": 8.35,
        "text": "billions of edges right now if you issue"
      },
      {
        "start": 720.75,
        "duration": 5.85,
        "text": "a query like ok G dot V that group"
      },
      {
        "start": 724.38,
        "duration": 5.04,
        "text": "counts something like this a group by oh"
      },
      {
        "start": 726.6,
        "duration": 6.93,
        "text": "I want to group all the user by their"
      },
      {
        "start": 729.42,
        "duration": 7.02,
        "text": "number of outgoing the number of friends"
      },
      {
        "start": 733.53,
        "duration": 7.08,
        "text": "first-degree friends and then do an"
      },
      {
        "start": 736.44,
        "duration": 9.66,
        "text": "order by descending order and just like"
      },
      {
        "start": 740.61,
        "duration": 8.73,
        "text": "the top 10 this query this traversal is"
      },
      {
        "start": 746.1,
        "duration": 6.66,
        "text": "typically an OLAP why because to be able"
      },
      {
        "start": 749.34,
        "duration": 7.22,
        "text": "to do a grouping you need two full scan"
      },
      {
        "start": 752.76,
        "duration": 8.19,
        "text": "your graph right and necessarily"
      },
      {
        "start": 756.56,
        "duration": 8.08,
        "text": "necessarily full scanning a graph we"
      },
      {
        "start": 760.95,
        "duration": 7.139,
        "text": "spend a lot of time right usually when"
      },
      {
        "start": 764.64,
        "duration": 6.39,
        "text": "you you are in a batch mode that the"
      },
      {
        "start": 768.089,
        "duration": 7.921,
        "text": "time it takes for the traversal to"
      },
      {
        "start": 771.03,
        "duration": 7.59,
        "text": "complete is between minutes maybe some"
      },
      {
        "start": 776.01,
        "duration": 5.97,
        "text": "time hours if you have a huge graph and"
      },
      {
        "start": 778.62,
        "duration": 8.1,
        "text": "very complex travels there's another"
      },
      {
        "start": 781.98,
        "duration": 8.4,
        "text": "thing to pay attention to is the what I"
      },
      {
        "start": 786.72,
        "duration": 6.03,
        "text": "call the combinatorial explosion even"
      },
      {
        "start": 790.38,
        "duration": 5.38,
        "text": "though you have a real-time query you"
      },
      {
        "start": 792.75,
        "duration": 7.03,
        "text": "say let's say you start from one user"
      },
      {
        "start": 795.76,
        "duration": 7.05,
        "text": "and you expand to its friends out nose"
      },
      {
        "start": 799.78,
        "duration": 5.46,
        "text": "right gee that vid has user ID from"
      },
      {
        "start": 802.81,
        "duration": 5.84,
        "text": "something else no so give me all the"
      },
      {
        "start": 805.24,
        "duration": 7.83,
        "text": "first-degree friends of this this person"
      },
      {
        "start": 808.65,
        "duration": 9.31,
        "text": "this can turn quickly into an OLAP query"
      },
      {
        "start": 813.07,
        "duration": 10.11,
        "text": "if you are unlucky and if you have this"
      },
      {
        "start": 817.96,
        "duration": 7.74,
        "text": "special user has a lots of friends so"
      },
      {
        "start": 823.18,
        "duration": 4.59,
        "text": "that's what we call come combinatorial"
      },
      {
        "start": 825.7,
        "duration": 4.65,
        "text": "explosion and imagine that your your"
      },
      {
        "start": 827.77,
        "duration": 6.18,
        "text": "traversal is a little bit more involved"
      },
      {
        "start": 830.35,
        "duration": 6.36,
        "text": "than just this so from one user you you"
      },
      {
        "start": 833.95,
        "duration": 5.88,
        "text": "fetch all of his friends and you want to"
      },
      {
        "start": 836.71,
        "duration": 8.31,
        "text": "get all the move the science-fiction"
      },
      {
        "start": 839.83,
        "duration": 7.5,
        "text": "movies they like right so very simple"
      },
      {
        "start": 845.02,
        "duration": 5.79,
        "text": "query when you describe it in English"
      },
      {
        "start": 847.33,
        "duration": 8.13,
        "text": "but in terms of processing environment"
      },
      {
        "start": 850.81,
        "duration": 9.33,
        "text": "one user 1,000 friends already one level"
      },
      {
        "start": 855.46,
        "duration": 8.19,
        "text": "of explosion each friends likes I don't"
      },
      {
        "start": 860.14,
        "duration": 5.88,
        "text": "know 10 to 20 science-fiction movies you"
      },
      {
        "start": 863.65,
        "duration": 6.0,
        "text": "just do the mass right it adds up very"
      },
      {
        "start": 866.02,
        "duration": 5.28,
        "text": "fast so it sounds like you can sort of"
      },
      {
        "start": 869.65,
        "duration": 4.38,
        "text": "accidentally without really thinking"
      },
      {
        "start": 871.3,
        "duration": 5.1,
        "text": "about it go from a fairly small"
      },
      {
        "start": 874.03,
        "duration": 6.03,
        "text": "reasonable size traversal to this"
      },
      {
        "start": 876.4,
        "duration": 6.12,
        "text": "combinatorial explosion which then turns"
      },
      {
        "start": 880.06,
        "duration": 5.79,
        "text": "it really into an OLAP kind of problem"
      },
      {
        "start": 882.52,
        "duration": 5.04,
        "text": "so how what can we do to limit those"
      },
      {
        "start": 885.85,
        "duration": 4.44,
        "text": "combinatorial explosions because"
      },
      {
        "start": 887.56,
        "duration": 5.55,
        "text": "sometimes we may not really intend to"
      },
      {
        "start": 890.29,
        "duration": 9.21,
        "text": "walk the entire graph so what can we do"
      },
      {
        "start": 893.11,
        "duration": 8.64,
        "text": "so that several solution mmm this is it"
      },
      {
        "start": 899.5,
        "duration": 5.37,
        "text": "there isn't any which is perfect so let"
      },
      {
        "start": 901.75,
        "duration": 6.45,
        "text": "me just list all of them first you can"
      },
      {
        "start": 904.87,
        "duration": 7.02,
        "text": "use the limit steps okay okay okay give"
      },
      {
        "start": 908.2,
        "duration": 7.8,
        "text": "me all friends of this user limit for"
      },
      {
        "start": 911.89,
        "duration": 6.54,
        "text": "example 210 now 21 of them whatever but"
      },
      {
        "start": 916.0,
        "duration": 4.92,
        "text": "the problem of limit is it's very"
      },
      {
        "start": 918.43,
        "duration": 5.7,
        "text": "restrictive right you if you want to"
      },
      {
        "start": 920.92,
        "duration": 7.45,
        "text": "know a little bit about this user even"
      },
      {
        "start": 924.13,
        "duration": 6.79,
        "text": "limit will restrict your your space"
      },
      {
        "start": 928.37,
        "duration": 4.62,
        "text": "right you can use also a very useful"
      },
      {
        "start": 930.92,
        "duration": 4.919,
        "text": "step in Grameen which it's called time"
      },
      {
        "start": 932.99,
        "duration": 5.07,
        "text": "limit so time limit is a little bit"
      },
      {
        "start": 935.839,
        "duration": 5.221,
        "text": "special it doesn't put a hard limit on"
      },
      {
        "start": 938.06,
        "duration": 6.71,
        "text": "the number of vertices or edges you want"
      },
      {
        "start": 941.06,
        "duration": 8.46,
        "text": "to fetch for the next step it will just"
      },
      {
        "start": 944.77,
        "duration": 7.09,
        "text": "start a kind of counter a time countdown"
      },
      {
        "start": 949.52,
        "duration": 6.9,
        "text": "mm-hm okay to say okay I want to time"
      },
      {
        "start": 951.86,
        "duration": 5.72,
        "text": "limit this step to maximum I don't know"
      },
      {
        "start": 956.42,
        "duration": 6.51,
        "text": "one second"
      },
      {
        "start": 957.58,
        "duration": 8.56,
        "text": "so Grambling can fire many traverser to"
      },
      {
        "start": 962.93,
        "duration": 5.25,
        "text": "explore all the branches but as soon as"
      },
      {
        "start": 966.14,
        "duration": 5.94,
        "text": "the countdown reaches one second"
      },
      {
        "start": 968.18,
        "duration": 8.72,
        "text": "trembling will stop exploring so it's"
      },
      {
        "start": 972.08,
        "duration": 7.92,
        "text": "very nice because you put a very strict"
      },
      {
        "start": 976.9,
        "duration": 5.08,
        "text": "control on the timing of your toggle so"
      },
      {
        "start": 980.0,
        "duration": 5.07,
        "text": "so I'm gonna get the best answer I can"
      },
      {
        "start": 981.98,
        "duration": 6.99,
        "text": "in this amount of time one second yeah"
      },
      {
        "start": 985.07,
        "duration": 7.37,
        "text": "so but but the drawback is you don't you"
      },
      {
        "start": 988.97,
        "duration": 6.03,
        "text": "don't control what kind of ends on you"
      },
      {
        "start": 992.44,
        "duration": 6.79,
        "text": "because the only thing you control is"
      },
      {
        "start": 995.0,
        "duration": 8.73,
        "text": "the time the timing be careful when you"
      },
      {
        "start": 999.23,
        "duration": 7.17,
        "text": "are using again a repeat step I just to"
      },
      {
        "start": 1003.73,
        "duration": 5.6,
        "text": "forget to mention earlier the repeat"
      },
      {
        "start": 1006.4,
        "duration": 10.26,
        "text": "step can explode pretty fast because"
      },
      {
        "start": 1009.33,
        "duration": 10.48,
        "text": "people use repeat for looping yes on a"
      },
      {
        "start": 1016.66,
        "duration": 5.929,
        "text": "social network graph just looking two"
      },
      {
        "start": 1019.81,
        "duration": 5.399,
        "text": "times you start from single vertex and"
      },
      {
        "start": 1022.589,
        "duration": 4.061,
        "text": "just looping two times you can finish"
      },
      {
        "start": 1025.209,
        "duration": 3.99,
        "text": "with 10000 vertex"
      },
      {
        "start": 1026.65,
        "duration": 3.75,
        "text": "recursion is the recursion right we"
      },
      {
        "start": 1029.199,
        "duration": 5.101,
        "text": "might have learned that in our first"
      },
      {
        "start": 1030.4,
        "duration": 7.799,
        "text": "programming class are not a funny step I"
      },
      {
        "start": 1034.3,
        "duration": 6.48,
        "text": "call it funny is the sample so the the"
      },
      {
        "start": 1038.199,
        "duration": 6.571,
        "text": "sample step the idea is instead of"
      },
      {
        "start": 1040.78,
        "duration": 6.72,
        "text": "fetching all the friends of my user I"
      },
      {
        "start": 1044.77,
        "duration": 7.02,
        "text": "will just take some of them so you can"
      },
      {
        "start": 1047.5,
        "duration": 8.25,
        "text": "say sample 100 sample 15 and this step"
      },
      {
        "start": 1051.79,
        "duration": 6.12,
        "text": "will just randomly pick 100 of 15 the"
      },
      {
        "start": 1055.75,
        "duration": 5.32,
        "text": "the difference between sample and limit"
      },
      {
        "start": 1057.91,
        "duration": 5.32,
        "text": "is limit will just follow of the order"
      },
      {
        "start": 1061.07,
        "duration": 6.0,
        "text": "right okay I stopped with the first"
      },
      {
        "start": 1063.23,
        "duration": 7.02,
        "text": "friend second fan the ordering is given"
      },
      {
        "start": 1067.07,
        "duration": 5.72,
        "text": "by the storage engine underneath sample"
      },
      {
        "start": 1070.25,
        "duration": 5.34,
        "text": "just introduce some kind of random"
      },
      {
        "start": 1072.79,
        "duration": 5.98,
        "text": "randomness into the process right so"
      },
      {
        "start": 1075.59,
        "duration": 7.11,
        "text": "it's nice if you don't care about the"
      },
      {
        "start": 1078.77,
        "duration": 6.9,
        "text": "honouring you just want to fetch some of"
      },
      {
        "start": 1082.7,
        "duration": 5.16,
        "text": "the data to have to visualize them to"
      },
      {
        "start": 1085.67,
        "duration": 5.24,
        "text": "have an idea about your data so some"
      },
      {
        "start": 1087.86,
        "duration": 7.64,
        "text": "sample can be nice in this context and"
      },
      {
        "start": 1090.91,
        "duration": 7.99,
        "text": "another technique is also to to restrict"
      },
      {
        "start": 1095.5,
        "duration": 6.1,
        "text": "to have a very restrictive interring on"
      },
      {
        "start": 1098.9,
        "duration": 5.25,
        "text": "your travel so so for example I would"
      },
      {
        "start": 1101.6,
        "duration": 5.19,
        "text": "say okay start from this user and give"
      },
      {
        "start": 1104.15,
        "duration": 5.67,
        "text": "me all of instead of instead of giving"
      },
      {
        "start": 1106.79,
        "duration": 5.61,
        "text": "all his first-degree friends I would say"
      },
      {
        "start": 1109.82,
        "duration": 8.69,
        "text": "give me all have his first-degree"
      },
      {
        "start": 1112.4,
        "duration": 10.34,
        "text": "friends whose age is between 20 and 25"
      },
      {
        "start": 1118.51,
        "duration": 8.83,
        "text": "living in this city so you had so many"
      },
      {
        "start": 1122.74,
        "duration": 8.29,
        "text": "criteria for filtering that in the end"
      },
      {
        "start": 1127.34,
        "duration": 6.72,
        "text": "the result set is quite small but even"
      },
      {
        "start": 1131.03,
        "duration": 5.88,
        "text": "this is not warranted right it depends"
      },
      {
        "start": 1134.06,
        "duration": 5.49,
        "text": "on the criteria for example living in"
      },
      {
        "start": 1136.91,
        "duration": 5.01,
        "text": "San Francisco oh my god how many people"
      },
      {
        "start": 1139.55,
        "duration": 4.59,
        "text": "are living the city if you are living in"
      },
      {
        "start": 1141.92,
        "duration": 3.33,
        "text": "San Francisco you may have many friends"
      },
      {
        "start": 1144.14,
        "duration": 4.14,
        "text": "all right right"
      },
      {
        "start": 1145.25,
        "duration": 6.71,
        "text": "so even restrictive enduring is not"
      },
      {
        "start": 1148.28,
        "duration": 6.93,
        "text": "perfect solution gotcha"
      },
      {
        "start": 1151.96,
        "duration": 4.36,
        "text": "okay so a minute ago I want to I want to"
      },
      {
        "start": 1155.21,
        "duration": 3.03,
        "text": "pull you back to something we were"
      },
      {
        "start": 1156.32,
        "duration": 3.9,
        "text": "talking about a minute ago this problem"
      },
      {
        "start": 1158.24,
        "duration": 4.5,
        "text": "of the super node and in the classic"
      },
      {
        "start": 1160.22,
        "duration": 4.79,
        "text": "example is in that social network graph"
      },
      {
        "start": 1162.74,
        "duration": 6.84,
        "text": "you have the Justin Bieber node that"
      },
      {
        "start": 1165.01,
        "duration": 7.36,
        "text": "everyone likes maybe not everyone but a"
      },
      {
        "start": 1169.58,
        "duration": 6.36,
        "text": "large number of likes into that one node"
      },
      {
        "start": 1172.37,
        "duration": 5.31,
        "text": "so it seems like any traversal that's"
      },
      {
        "start": 1175.94,
        "duration": 4.29,
        "text": "kind of kind of walked through that node"
      },
      {
        "start": 1177.68,
        "duration": 4.8,
        "text": "has the potential to really be a"
      },
      {
        "start": 1180.23,
        "duration": 6.99,
        "text": "performance bottleneck so what can we do"
      },
      {
        "start": 1182.48,
        "duration": 7.74,
        "text": "so I would say that this scenario should"
      },
      {
        "start": 1187.22,
        "duration": 5.85,
        "text": "this kind of problem the super node"
      },
      {
        "start": 1190.22,
        "duration": 5.7,
        "text": "problem in my opinion"
      },
      {
        "start": 1193.07,
        "duration": 4.859,
        "text": "should be solved at the storage engine"
      },
      {
        "start": 1195.92,
        "duration": 6.12,
        "text": "layer I mean should be solved at the"
      },
      {
        "start": 1197.929,
        "duration": 8.191,
        "text": "customer layer and how how can we solve"
      },
      {
        "start": 1202.04,
        "duration": 7.259,
        "text": "it by supporting huge partitions in"
      },
      {
        "start": 1206.12,
        "duration": 4.92,
        "text": "kasama okay we know that we used to tell"
      },
      {
        "start": 1209.299,
        "duration": 4.951,
        "text": "people okay be careful"
      },
      {
        "start": 1211.04,
        "duration": 6.12,
        "text": "about the size of your partition try to"
      },
      {
        "start": 1214.25,
        "duration": 5.48,
        "text": "control it and if you know that your"
      },
      {
        "start": 1217.16,
        "duration": 6.389,
        "text": "partition is going to grow very very"
      },
      {
        "start": 1219.73,
        "duration": 7.9,
        "text": "huge try to sub partition by introducing"
      },
      {
        "start": 1223.549,
        "duration": 6.481,
        "text": "a date in your partition key right right"
      },
      {
        "start": 1227.63,
        "duration": 6.0,
        "text": "a big break instead large particular"
      },
      {
        "start": 1230.03,
        "duration": 7.44,
        "text": "again the problem with this kind of"
      },
      {
        "start": 1233.63,
        "duration": 5.85,
        "text": "design because I have faced this"
      },
      {
        "start": 1237.47,
        "duration": 6.959,
        "text": "situation many times when I'm doing a"
      },
      {
        "start": 1239.48,
        "duration": 7.35,
        "text": "data modelling for customer is because"
      },
      {
        "start": 1244.429,
        "duration": 6.0,
        "text": "of some special case in your dataset"
      },
      {
        "start": 1246.83,
        "duration": 6.63,
        "text": "imagine you have a data set where 99.9"
      },
      {
        "start": 1250.429,
        "duration": 6.681,
        "text": "percent of the time people have a normal"
      },
      {
        "start": 1253.46,
        "duration": 6.69,
        "text": "cardinality like small to medium"
      },
      {
        "start": 1257.11,
        "duration": 8.83,
        "text": "partition size and for some odd years"
      },
      {
        "start": 1260.15,
        "duration": 8.46,
        "text": "values they have huge partition some one"
      },
      {
        "start": 1265.94,
        "duration": 5.58,
        "text": "to ten huge partition because of this"
      },
      {
        "start": 1268.61,
        "duration": 6.0,
        "text": "one percent we need to accommodate all"
      },
      {
        "start": 1271.52,
        "duration": 5.46,
        "text": "of our data model and you know that when"
      },
      {
        "start": 1274.61,
        "duration": 5.069,
        "text": "you are bucket icing and you are doing"
      },
      {
        "start": 1276.98,
        "duration": 5.699,
        "text": "sub partitioning you put a constraint on"
      },
      {
        "start": 1279.679,
        "duration": 5.941,
        "text": "your query because now your partition"
      },
      {
        "start": 1282.679,
        "duration": 5.671,
        "text": "key contain a bucket column right and so"
      },
      {
        "start": 1285.62,
        "duration": 4.62,
        "text": "now you end up doing these multi"
      },
      {
        "start": 1288.35,
        "duration": 5.16,
        "text": "partition queries whereas you would not"
      },
      {
        "start": 1290.24,
        "duration": 6.48,
        "text": "have had to do that exactly and so I"
      },
      {
        "start": 1293.51,
        "duration": 8.549,
        "text": "think that if we can support huge"
      },
      {
        "start": 1296.72,
        "duration": 7.829,
        "text": "partition natively in in kasama it will"
      },
      {
        "start": 1302.059,
        "duration": 5.521,
        "text": "be the best answer and for people who"
      },
      {
        "start": 1304.549,
        "duration": 5.691,
        "text": "are worried about hotspot because of"
      },
      {
        "start": 1307.58,
        "duration": 5.55,
        "text": "course when we talk about huge partition"
      },
      {
        "start": 1310.24,
        "duration": 5.59,
        "text": "which concern only one percent of our"
      },
      {
        "start": 1313.13,
        "duration": 4.89,
        "text": "data set people who raised their hand"
      },
      {
        "start": 1315.83,
        "duration": 4.92,
        "text": "and say oh but it means that some not"
      },
      {
        "start": 1318.02,
        "duration": 6.729,
        "text": "which are hosting those huge partition"
      },
      {
        "start": 1320.75,
        "duration": 8.32,
        "text": "will contain more data right so we have"
      },
      {
        "start": 1324.749,
        "duration": 7.111,
        "text": "but distribution of data not really if"
      },
      {
        "start": 1329.07,
        "duration": 5.76,
        "text": "we think about the the amount the total"
      },
      {
        "start": 1331.86,
        "duration": 6.809,
        "text": "amount of data if you have some Justin"
      },
      {
        "start": 1334.83,
        "duration": 7.049,
        "text": "Bieber's among your users mm-hmm let's"
      },
      {
        "start": 1338.669,
        "duration": 6.271,
        "text": "say a dozen of Justin Bieber but on the"
      },
      {
        "start": 1341.879,
        "duration": 5.37,
        "text": "other side you have millions tens of"
      },
      {
        "start": 1344.94,
        "duration": 4.699,
        "text": "millions of normal user right in fact"
      },
      {
        "start": 1347.249,
        "duration": 5.971,
        "text": "the the difference in size will be"
      },
      {
        "start": 1349.639,
        "duration": 6.61,
        "text": "averaged out completely you not see that"
      },
      {
        "start": 1353.22,
        "duration": 6.059,
        "text": "huge difference in term of data between"
      },
      {
        "start": 1356.249,
        "duration": 5.88,
        "text": "the different nodes gotcha"
      },
      {
        "start": 1359.279,
        "duration": 5.22,
        "text": "well you haven't disappointed me do we"
      },
      {
        "start": 1362.129,
        "duration": 5.01,
        "text": "high I in the end we did come back to"
      },
      {
        "start": 1364.499,
        "duration": 5.13,
        "text": "Cassandra yeah we did end up talking"
      },
      {
        "start": 1367.139,
        "duration": 5.961,
        "text": "about the storage layer so your your"
      },
      {
        "start": 1369.629,
        "duration": 7.05,
        "text": "super node at the graph layer becomes"
      },
      {
        "start": 1373.1,
        "duration": 5.23,
        "text": "the the very large partition down at the"
      },
      {
        "start": 1376.679,
        "duration": 5.22,
        "text": "at the Cassandra layer for the storage"
      },
      {
        "start": 1378.33,
        "duration": 5.87,
        "text": "layer for graph so okay so I do we have"
      },
      {
        "start": 1381.899,
        "duration": 8.071,
        "text": "time for one bonus question do you think"
      },
      {
        "start": 1384.2,
        "duration": 11.109,
        "text": "yeah so well one bonus announcement idea"
      },
      {
        "start": 1389.97,
        "duration": 8.49,
        "text": "so yeah stay tuned because we this a"
      },
      {
        "start": 1395.309,
        "duration": 6.901,
        "text": "stack we are working very hard to try to"
      },
      {
        "start": 1398.46,
        "duration": 7.62,
        "text": "solve this huge partition problem and in"
      },
      {
        "start": 1402.21,
        "duration": 7.52,
        "text": "future release of DSC we will try to"
      },
      {
        "start": 1406.08,
        "duration": 8.339,
        "text": "address this problem so wait and see"
      },
      {
        "start": 1409.73,
        "duration": 6.46,
        "text": "what so more to come maybe a good future"
      },
      {
        "start": 1414.419,
        "duration": 6.751,
        "text": "episode of the distributed data show"
      },
      {
        "start": 1416.19,
        "duration": 6.99,
        "text": "yeah thanks for watching"
      },
      {
        "start": 1421.17,
        "duration": 4.05,
        "text": "thank you for joining us again for the"
      },
      {
        "start": 1423.18,
        "duration": 3.75,
        "text": "distributed data show we love your"
      },
      {
        "start": 1425.22,
        "duration": 3.72,
        "text": "feedback so go to the distributed data"
      },
      {
        "start": 1426.93,
        "duration": 3.84,
        "text": "show page on data Stax Academy and tell"
      },
      {
        "start": 1428.94,
        "duration": 3.66,
        "text": "us what you think you can also find us"
      },
      {
        "start": 1430.77,
        "duration": 4.44,
        "text": "on the data Stax Academy YouTube channel"
      },
      {
        "start": 1432.6,
        "duration": 4.86,
        "text": "or find our podcast on itunes google"
      },
      {
        "start": 1435.21,
        "duration": 4.23,
        "text": "play or wherever you get great podcast"
      },
      {
        "start": 1437.46,
        "duration": 3.66,
        "text": "while you're there make sure and"
      },
      {
        "start": 1439.44,
        "duration": 2.5,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 1441.12,
        "duration": 5.76,
        "text": "episode"
      },
      {
        "start": 1441.94,
        "duration": 4.94,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:07:37.380688+00:00"
}