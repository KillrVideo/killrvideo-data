{
  "video_id": "Z3NXvb2RxNs",
  "title": "Distributed Data Show Episode 26: Partitioning Techniques with DuyHai Doan and Patrick McFadin",
  "description": "DuyHai Doan and Patrick McFadin explain the primary two ways of distributing data used in computer science: hash-based partitioning and range-based partitioning, and the implications of each of these on operations (hint: rebalancing!). \n\nABOUT DATASTAX ENTERPRISE 5.1\nDataStax Enterprise 5.1, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.1 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax EnterpriseÂ©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-12-19T16:00:03Z",
  "thumbnail": "https://i.ytimg.com/vi/Z3NXvb2RxNs/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=Z3NXvb2RxNs",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems hello everyone the distributed data show back in the studio today with three high dome how are you I'm fine had a batch make so we have a little more of a I think a heady topic today we're not going to talk about a specific technology like Cassandra or solar or anything else it's going to be about techniques and the topic is partitioning techniques in distributed systems of course so you and I both we tell people about how to use distributed systems and using them means understanding next acting yeah and when you don't understand them what usually happens compressor free yeah it's bad it's really really bad so partitioning techniques now when we talk about that maybe you can explain what a partitioning technique is why is this important so basically when we talk about distributed system we are talking about multiple machines cluster right if you have single machine you are not a distributed system and when you have multiple machines you need to put data on all of them the question is how do i distribute my data on all those machines and then come the partition or partitioning techniques so I think a lot of folks that come from relational land know about sharding yeah and sharding of course is when you take data you break it into pieces and I've distributed across multiple machines mm-hmm that it's similar but it's not the same topic right it depends on because the shouting is a subset of partitioning techniques okay all right so in more modern distributed data systems all of that's handled automatically correct yeah more or less yes you have some system where you only choose the columns which the algorithm of partitioning is applied to right you don't decide which algorithm the system imposes you the the algorithm you have some system where you are freely it's up to you to choose how you distribute your ATAR so those have pros and cons right right right and in fact we have two distinct families our partitioning scheme yeah so what are they so what are they that's a good place to start is just breaking this into bigger pieces so what are the two largest pieces of how to distribute data in a distributed system so you have two ideas the first ideas is I want to spread all my data evenly so the best way to do that is to introduce randomness and to use hash function you apply a hash function too young to some of your primary keys and then depending on the hash value you know on which machine you should assign your data the second family is range base partitioning so this family is very really a simple trick to explain let's say you have a column and it is a text column on an integer value so you would say okay from 0 to 10 for this column I will assign my data to not number one for 20 for 10 to 20 not number 2 and so on right all right let's break let's dig into each one of these and I think we'll leave the hashing 1 for the last yeah that's the most interesting one and there's a lot to that let's talk about one that may be a little more familiar range based partitioning techniques yes so far the key thing is so let's talk about pro and cons right the pro is when you you partition your data by range of values the key thing is you can have range queries of course what does it mean between that first you can access your data by equality so give me for example user where user ID equals to some values a hash of user ID equals to some value o you can say give me all the user user ID is between between 10 and 20 so inequality queries right it is very convenient the the cons is now you risk hotspot because how can you be sure that for each range of data you have you will have the same amount of data yeah so I think that a you know when sharding when you sharding a database which is a ranger based partition and very difficult to get right if for instance if you use letters of a last name yeah yeah then you you're not going to have a statistically even data set no because yeah and then especially when you're in certain geographies where you know names may start with m like mine quite a bit and then none of them are starting with X you know exactly that there's differences even with IDs and I've seen this happen to you where because you're generating sequential IDs that's very difficult to do as well because now you have to find you have seen this before where range based queries would fill up a machine and then get to a certain limit and then they'd start filling up a new machine zactly and also I would like to UM to stress on the point that when you do choose R and bash partitioning you are facing sooner or later hotspot so most of the technology who are choosing range range based partitioning they they have what they call rebalancing by the rebalancing processes okay at some point in time some I realized that some machine has more data than others so I start to move my my range of values to rebalance the register but rebalancing has a huge cost usually people don't realize it what does it mean in practice rebalancing data it means reading data out of disk so this I own cost read them into memory pull them on a network so network will be busy and at the receiving not sir sir realizing them and writing them back to disk yeah there's a lot of activity that has to I mean and moving data is never cheap exactly and in fact you have two choices either you can trigger the rebalancing manually so it is an operator who decide okay okay my traffic right now and my cluster is very low I can just trigger every managing file but he puts a lot of manual work to the operator or you can decide to do it automatically right but then you take the risk in the middle of a heavy traffic to start on rebalancing I would also say that this is where there's the other problem that I've seen and most of the range based algorithms that I've seen are very much in the application the application has to be aware of it and has to guide it now other I have seen some others for instance Cassandra we had byte order petitioner and the byte order partitioner was that it used a range and then it divided the range into how many nodes who had the hotspot problem was the issue there I had a friend used to say this all time use Bop and your ops people will plan your disappearance exactly it's not good and also we even didn't talk about the older issue related to rebalancing because what what are your warranties about consistency when you are moving data right because in the middle of moving data the data has not lived yet the center not and the receiving not have not received all of them yet so in terms of consistency should I query the sender not or should i query the receiver not to get the data right and imagine that the rebalancing fail in the middle what do we do do we roll back or do we just retry so see you open networks Europe your data is immutable that's what you hope for idempotency for the yeah which is another advantage inside Cassandra LAN is that that idempotency of that data inside of a inside of the data model itself really helps whenever you have these kind of problems and that's that's harder to do with the relational databases and actually almost impossible okay well that's range based partitioning about the more interesting one the hash based partitioning so hash based partitioning as it names in Bly we use a hash function a consistent hashing out yeah yes so the idea is not to take any random hash function because if the the idea here is to have a very good distribution of your data so your hash function should be very distributive and right now in the state of the art the most distributive hash function out there is mama tree right we are using in modern Cassandra cluster so the course is that you are guaranteed to have a good distribution of data so I want to warn our all of our watcher the guarantee of good distribution is stas statistical what do i what do I mean imagine you are playing rolling dice right you roll a dice six time what is the grunty you have one two three four five six no guarantee you can have three times the number one three tiny number two and that's all what's a non repeated trial too exactly right so the warranty to have good distribution of data with the hash based partitioning is you should have a lot of distinct value large l yes yeah so the more you have distinct value of the partition keys you have the better the distribution is yeah that's pretty critical and and again with the consistent hashing algorithm and I think this bears some explanation it's it's not just a randomizer it's it's really like a one-way door you put a string into it and it will always give you the same hash yeah our random hash but the same one so if I put int we hi it spits out a huge 64 bit or 120 minute whatever size your from your hash but it'll always spit that out and if you put in a Shakespeare sonnet it'll spit out a 64 bit - but it'll always be that how - and yes and that's it's actually a pretty incredible thing and the the limit on collision at that point is well theoretically there is a potential for collision in the universe but what's such a huge number and yeah the chances are very small extremely small yeah and that that I think that's where a lot of people get hung up wait a minute isn't there gonna be a collision there's gonna have my data overlapping probably not yeah actually no it won't happen and of course now this is those are the pros and the cons and now because you are applying a hash function on your magician key now you can no longer query your partition key by range uh-huh because in fact when you hash a value you lose the ordering right because the hash value are completely like distributed all over the range of possible value so yeah scattered out again if you need any kind of sequence then you're going to be bouncing around all over the place to find that but in fact the trick is there is an ordering but the order is on the hashed value right right not on the original value so in fact for you developer knowing that the hash value of your partition key is order wealth it doesn't help the only moment the only case the only scenario where it's useful is you want to to perform a full scan of your table and you do it by chunk so you can say okay I start with the hash value being -2 blah blah blah and then you move on sequentially and then you can apply the idea that the hash value is order any moment yeah and that's how you know you're getting all of the data for a particular node in a distributed system partition by a consistent hash but it doesn't give you the guarantee that the the data in the partition key that when into the hash is ordered so if it's 1 2 3 and gets hashed different ways that's not the point of that so like Cassandra and cql there's a function get token that shows you the token value for that partition key and that partition key is what we're talking about that's what how it gets distributed throughout the Cassandra cluster but that that get token will give you a number that is on a particular note now and you can range through those those token numbers excitement every bit of data on that note exactly by the way that's kind of the secret how the sparks don't works [Laughter] which is a you know not a secret but I think it's still pretty interesting yeah have you seen I'm kind of loading the question here a little bit but have you seen some newer things in computer science about partitioning techniques or some more modern thinking around what this what a partitioning technique looks like in a large distributed system the idea of so you you can introduce some idea where you have a bit of geo data which is fixed and introduce some hashing part of your data part of your primary keys is hash part of your primary key is right on them you can perform branch query but it is what we are already having customer are right but partition keys clustering columns one part of your primary key is for distribution the other part is for range query right and in fact in those kind of new technique it's very hard to go whenever you touch the hash function you lose all right yeah so it's a mathematic property yeah and and here break math no no you cannot really find a hash function that want to use trick all right no it's not hash function anymore I've seen some interesting ideas around hybridizing it or finding ways to control some order get some order control Google had an interesting paper not too long ago about around load so using an ordered based partitioner but with load shedding in it the you're starting to get into much more advanced much more complicated hashing techniques and that I think that's interesting and it may be something that develops over time but the simplicity of a consistent hashing algorithm or range based partitioner it really is helpful because when you're writing code let's say you're you know you're building an application for some company or for yourself you don't want to have to spend a few days on the math no you don't need to have a PhD no piece of science I just want to write your code yeah right right well this has been really interesting I mean I hope it has been interesting for you too I I could talk about distributed computing for hours and I'm sure you wouldn't want to listen to that and you could too could yeah we have before many many times well thank you very much for joining me today to be thank you press right all right and thanks everyone for joining us on the distributed data show we'll see you next time thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data Stax Academy and tell us what you think you can also find us on the data Stax Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode you",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.37,
        "duration": 4.23,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.6,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.22,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.4,
        "text": "large-scale distributed systems hello"
      },
      {
        "start": 16.68,
        "duration": 4.83,
        "text": "everyone the distributed data show back"
      },
      {
        "start": 19.05,
        "duration": 5.55,
        "text": "in the studio today with three high dome"
      },
      {
        "start": 21.51,
        "duration": 5.97,
        "text": "how are you I'm fine had a batch make so"
      },
      {
        "start": 24.6,
        "duration": 4.499,
        "text": "we have a little more of a I think a"
      },
      {
        "start": 27.48,
        "duration": 4.56,
        "text": "heady topic today we're not going to"
      },
      {
        "start": 29.099,
        "duration": 6.571,
        "text": "talk about a specific technology like"
      },
      {
        "start": 32.04,
        "duration": 5.82,
        "text": "Cassandra or solar or anything else it's"
      },
      {
        "start": 35.67,
        "duration": 5.01,
        "text": "going to be about techniques and the"
      },
      {
        "start": 37.86,
        "duration": 6.39,
        "text": "topic is partitioning techniques in"
      },
      {
        "start": 40.68,
        "duration": 7.16,
        "text": "distributed systems of course so you and"
      },
      {
        "start": 44.25,
        "duration": 6.51,
        "text": "I both we tell people about how to use"
      },
      {
        "start": 47.84,
        "duration": 5.8,
        "text": "distributed systems and using them means"
      },
      {
        "start": 50.76,
        "duration": 4.439,
        "text": "understanding next acting yeah and when"
      },
      {
        "start": 53.64,
        "duration": 4.59,
        "text": "you don't understand them what usually"
      },
      {
        "start": 55.199,
        "duration": 4.171,
        "text": "happens compressor free yeah it's bad"
      },
      {
        "start": 58.23,
        "duration": 4.71,
        "text": "it's really really bad"
      },
      {
        "start": 59.37,
        "duration": 5.189,
        "text": "so partitioning techniques now when we"
      },
      {
        "start": 62.94,
        "duration": 4.05,
        "text": "talk about that maybe you can explain"
      },
      {
        "start": 64.559,
        "duration": 4.92,
        "text": "what a partitioning technique is why is"
      },
      {
        "start": 66.99,
        "duration": 4.59,
        "text": "this important so basically when we talk"
      },
      {
        "start": 69.479,
        "duration": 4.591,
        "text": "about distributed system we are talking"
      },
      {
        "start": 71.58,
        "duration": 4.46,
        "text": "about multiple machines cluster right if"
      },
      {
        "start": 74.07,
        "duration": 4.409,
        "text": "you have single machine you are not a"
      },
      {
        "start": 76.04,
        "duration": 4.81,
        "text": "distributed system and when you have"
      },
      {
        "start": 78.479,
        "duration": 5.851,
        "text": "multiple machines you need to put data"
      },
      {
        "start": 80.85,
        "duration": 6.21,
        "text": "on all of them the question is how do i"
      },
      {
        "start": 84.33,
        "duration": 5.24,
        "text": "distribute my data on all those machines"
      },
      {
        "start": 87.06,
        "duration": 6.51,
        "text": "and then come the partition or"
      },
      {
        "start": 89.57,
        "duration": 5.68,
        "text": "partitioning techniques so I think a lot"
      },
      {
        "start": 93.57,
        "duration": 5.189,
        "text": "of folks that come from relational land"
      },
      {
        "start": 95.25,
        "duration": 6.84,
        "text": "know about sharding yeah and sharding of"
      },
      {
        "start": 98.759,
        "duration": 5.79,
        "text": "course is when you take data you break"
      },
      {
        "start": 102.09,
        "duration": 5.4,
        "text": "it into pieces and I've distributed"
      },
      {
        "start": 104.549,
        "duration": 6.0,
        "text": "across multiple machines mm-hmm that"
      },
      {
        "start": 107.49,
        "duration": 7.769,
        "text": "it's similar but it's not the same topic"
      },
      {
        "start": 110.549,
        "duration": 7.621,
        "text": "right it depends on because the shouting"
      },
      {
        "start": 115.259,
        "duration": 5.371,
        "text": "is a subset of partitioning techniques"
      },
      {
        "start": 118.17,
        "duration": 4.83,
        "text": "okay all right so in more modern"
      },
      {
        "start": 120.63,
        "duration": 5.309,
        "text": "distributed data systems all of that's"
      },
      {
        "start": 123.0,
        "duration": 3.229,
        "text": "handled automatically correct yeah more"
      },
      {
        "start": 125.939,
        "duration": 3.96,
        "text": "or less"
      },
      {
        "start": 126.229,
        "duration": 5.771,
        "text": "yes you have some system where you only"
      },
      {
        "start": 129.899,
        "duration": 4.471,
        "text": "choose the columns"
      },
      {
        "start": 132.0,
        "duration": 5.37,
        "text": "which the algorithm of partitioning is"
      },
      {
        "start": 134.37,
        "duration": 7.35,
        "text": "applied to right you don't decide which"
      },
      {
        "start": 137.37,
        "duration": 6.66,
        "text": "algorithm the system imposes you the the"
      },
      {
        "start": 141.72,
        "duration": 5.07,
        "text": "algorithm you have some system where you"
      },
      {
        "start": 144.03,
        "duration": 6.24,
        "text": "are freely it's up to you to choose how"
      },
      {
        "start": 146.79,
        "duration": 5.94,
        "text": "you distribute your ATAR so those have"
      },
      {
        "start": 150.27,
        "duration": 5.43,
        "text": "pros and cons right right right and in"
      },
      {
        "start": 152.73,
        "duration": 5.28,
        "text": "fact we have two distinct families our"
      },
      {
        "start": 155.7,
        "duration": 3.69,
        "text": "partitioning scheme yeah so what are"
      },
      {
        "start": 158.01,
        "duration": 3.87,
        "text": "they so what are they that's a good"
      },
      {
        "start": 159.39,
        "duration": 4.65,
        "text": "place to start is just breaking this"
      },
      {
        "start": 161.88,
        "duration": 5.34,
        "text": "into bigger pieces so what are the two"
      },
      {
        "start": 164.04,
        "duration": 5.16,
        "text": "largest pieces of how to distribute data"
      },
      {
        "start": 167.22,
        "duration": 5.07,
        "text": "in a distributed system so you have two"
      },
      {
        "start": 169.2,
        "duration": 6.93,
        "text": "ideas the first ideas is I want to"
      },
      {
        "start": 172.29,
        "duration": 5.22,
        "text": "spread all my data evenly so the best"
      },
      {
        "start": 176.13,
        "duration": 4.8,
        "text": "way to do that is to introduce"
      },
      {
        "start": 177.51,
        "duration": 5.58,
        "text": "randomness and to use hash function you"
      },
      {
        "start": 180.93,
        "duration": 6.72,
        "text": "apply a hash function too young to some"
      },
      {
        "start": 183.09,
        "duration": 6.48,
        "text": "of your primary keys and then depending"
      },
      {
        "start": 187.65,
        "duration": 4.83,
        "text": "on the hash value you know on which"
      },
      {
        "start": 189.57,
        "duration": 5.94,
        "text": "machine you should assign your data the"
      },
      {
        "start": 192.48,
        "duration": 5.67,
        "text": "second family is range base partitioning"
      },
      {
        "start": 195.51,
        "duration": 5.94,
        "text": "so this family is very really a simple"
      },
      {
        "start": 198.15,
        "duration": 7.77,
        "text": "trick to explain let's say you have a"
      },
      {
        "start": 201.45,
        "duration": 6.99,
        "text": "column and it is a text column on an"
      },
      {
        "start": 205.92,
        "duration": 7.05,
        "text": "integer value so you would say okay from"
      },
      {
        "start": 208.44,
        "duration": 7.74,
        "text": "0 to 10 for this column I will assign my"
      },
      {
        "start": 212.97,
        "duration": 5.16,
        "text": "data to not number one for 20 for 10 to"
      },
      {
        "start": 216.18,
        "duration": 4.529,
        "text": "20 not number 2 and so on"
      },
      {
        "start": 218.13,
        "duration": 5.52,
        "text": "right all right let's break let's dig"
      },
      {
        "start": 220.709,
        "duration": 5.34,
        "text": "into each one of these and I think we'll"
      },
      {
        "start": 223.65,
        "duration": 3.869,
        "text": "leave the hashing 1 for the last yeah"
      },
      {
        "start": 226.049,
        "duration": 3.451,
        "text": "that's the most interesting one and"
      },
      {
        "start": 227.519,
        "duration": 3.121,
        "text": "there's a lot to that let's talk about"
      },
      {
        "start": 229.5,
        "duration": 4.41,
        "text": "one that may be a little more familiar"
      },
      {
        "start": 230.64,
        "duration": 7.77,
        "text": "range based partitioning techniques yes"
      },
      {
        "start": 233.91,
        "duration": 8.46,
        "text": "so far the key thing is so let's talk"
      },
      {
        "start": 238.41,
        "duration": 6.42,
        "text": "about pro and cons right the pro is when"
      },
      {
        "start": 242.37,
        "duration": 5.79,
        "text": "you you partition your data by range of"
      },
      {
        "start": 244.83,
        "duration": 5.85,
        "text": "values the key thing is you can have"
      },
      {
        "start": 248.16,
        "duration": 4.859,
        "text": "range queries of course what does it"
      },
      {
        "start": 250.68,
        "duration": 4.65,
        "text": "mean between that first you can access"
      },
      {
        "start": 253.019,
        "duration": 4.59,
        "text": "your data by equality so give me for"
      },
      {
        "start": 255.33,
        "duration": 6.209,
        "text": "example user where user ID equals to"
      },
      {
        "start": 257.609,
        "duration": 7.471,
        "text": "some values a hash of user ID equals to"
      },
      {
        "start": 261.539,
        "duration": 4.231,
        "text": "some value o you can say give me all the"
      },
      {
        "start": 265.08,
        "duration": 4.86,
        "text": "user"
      },
      {
        "start": 265.77,
        "duration": 6.72,
        "text": "user ID is between between 10 and 20 so"
      },
      {
        "start": 269.94,
        "duration": 3.42,
        "text": "inequality queries right it is very"
      },
      {
        "start": 272.49,
        "duration": 6.38,
        "text": "convenient"
      },
      {
        "start": 273.36,
        "duration": 9.51,
        "text": "the the cons is now you risk hotspot"
      },
      {
        "start": 278.87,
        "duration": 6.07,
        "text": "because how can you be sure that for"
      },
      {
        "start": 282.87,
        "duration": 4.229,
        "text": "each range of data you have you will"
      },
      {
        "start": 284.94,
        "duration": 4.8,
        "text": "have the same amount of data"
      },
      {
        "start": 287.099,
        "duration": 5.25,
        "text": "yeah so I think that a you know when"
      },
      {
        "start": 289.74,
        "duration": 4.47,
        "text": "sharding when you sharding a database"
      },
      {
        "start": 292.349,
        "duration": 4.741,
        "text": "which is a ranger based partition and"
      },
      {
        "start": 294.21,
        "duration": 5.639,
        "text": "very difficult to get right if for"
      },
      {
        "start": 297.09,
        "duration": 6.78,
        "text": "instance if you use letters of a last"
      },
      {
        "start": 299.849,
        "duration": 7.141,
        "text": "name yeah yeah then you you're not going"
      },
      {
        "start": 303.87,
        "duration": 5.43,
        "text": "to have a statistically even data set"
      },
      {
        "start": 306.99,
        "duration": 4.019,
        "text": "no because yeah and then especially when"
      },
      {
        "start": 309.3,
        "duration": 3.66,
        "text": "you're in certain geographies where you"
      },
      {
        "start": 311.009,
        "duration": 4.261,
        "text": "know names may start with m like mine"
      },
      {
        "start": 312.96,
        "duration": 4.4,
        "text": "quite a bit and then none of them are"
      },
      {
        "start": 315.27,
        "duration": 4.649,
        "text": "starting with X you know exactly that"
      },
      {
        "start": 317.36,
        "duration": 4.29,
        "text": "there's differences even with IDs and"
      },
      {
        "start": 319.919,
        "duration": 4.261,
        "text": "I've seen this happen to you where"
      },
      {
        "start": 321.65,
        "duration": 4.389,
        "text": "because you're generating sequential IDs"
      },
      {
        "start": 324.18,
        "duration": 4.079,
        "text": "that's very difficult to do as well"
      },
      {
        "start": 326.039,
        "duration": 3.6,
        "text": "because now you have to find you have"
      },
      {
        "start": 328.259,
        "duration": 3.09,
        "text": "seen this before where range based"
      },
      {
        "start": 329.639,
        "duration": 3.541,
        "text": "queries would fill up a machine and then"
      },
      {
        "start": 331.349,
        "duration": 3.481,
        "text": "get to a certain limit and then they'd"
      },
      {
        "start": 333.18,
        "duration": 5.76,
        "text": "start filling up a new machine zactly"
      },
      {
        "start": 334.83,
        "duration": 7.05,
        "text": "and also I would like to UM to stress on"
      },
      {
        "start": 338.94,
        "duration": 5.64,
        "text": "the point that when you do choose R and"
      },
      {
        "start": 341.88,
        "duration": 5.49,
        "text": "bash partitioning you are facing"
      },
      {
        "start": 344.58,
        "duration": 5.429,
        "text": "sooner or later hotspot so most of the"
      },
      {
        "start": 347.37,
        "duration": 4.829,
        "text": "technology who are choosing range range"
      },
      {
        "start": 350.009,
        "duration": 4.951,
        "text": "based partitioning they they have what"
      },
      {
        "start": 352.199,
        "duration": 5.37,
        "text": "they call rebalancing by the rebalancing"
      },
      {
        "start": 354.96,
        "duration": 4.949,
        "text": "processes okay at some point in time"
      },
      {
        "start": 357.569,
        "duration": 6.421,
        "text": "some I realized that some machine has"
      },
      {
        "start": 359.909,
        "duration": 7.56,
        "text": "more data than others so I start to move"
      },
      {
        "start": 363.99,
        "duration": 6.41,
        "text": "my my range of values to rebalance the"
      },
      {
        "start": 367.469,
        "duration": 5.67,
        "text": "register but rebalancing has a huge cost"
      },
      {
        "start": 370.4,
        "duration": 5.109,
        "text": "usually people don't realize it what"
      },
      {
        "start": 373.139,
        "duration": 2.701,
        "text": "does it mean in practice rebalancing"
      },
      {
        "start": 375.509,
        "duration": 3.511,
        "text": "data"
      },
      {
        "start": 375.84,
        "duration": 8.17,
        "text": "it means reading data out of disk so"
      },
      {
        "start": 379.02,
        "duration": 9.08,
        "text": "this I own cost read them into memory"
      },
      {
        "start": 384.01,
        "duration": 9.91,
        "text": "pull them on a network so network will"
      },
      {
        "start": 388.1,
        "duration": 8.1,
        "text": "be busy and at the receiving not sir sir"
      },
      {
        "start": 393.92,
        "duration": 4.71,
        "text": "realizing them and writing them back to"
      },
      {
        "start": 396.2,
        "duration": 4.38,
        "text": "disk yeah there's a lot of activity that"
      },
      {
        "start": 398.63,
        "duration": 5.34,
        "text": "has to I mean and moving data is never"
      },
      {
        "start": 400.58,
        "duration": 6.24,
        "text": "cheap exactly and in fact you have two"
      },
      {
        "start": 403.97,
        "duration": 5.49,
        "text": "choices either you can trigger the"
      },
      {
        "start": 406.82,
        "duration": 6.15,
        "text": "rebalancing manually so it is an"
      },
      {
        "start": 409.46,
        "duration": 5.25,
        "text": "operator who decide okay okay my traffic"
      },
      {
        "start": 412.97,
        "duration": 4.23,
        "text": "right now and my cluster is very low I"
      },
      {
        "start": 414.71,
        "duration": 5.19,
        "text": "can just trigger every managing file but"
      },
      {
        "start": 417.2,
        "duration": 5.28,
        "text": "he puts a lot of manual work to the"
      },
      {
        "start": 419.9,
        "duration": 4.71,
        "text": "operator or you can decide to do it"
      },
      {
        "start": 422.48,
        "duration": 3.75,
        "text": "automatically right but then you take"
      },
      {
        "start": 424.61,
        "duration": 4.53,
        "text": "the risk in the middle of a heavy"
      },
      {
        "start": 426.23,
        "duration": 5.91,
        "text": "traffic to start on rebalancing I would"
      },
      {
        "start": 429.14,
        "duration": 5.04,
        "text": "also say that this is where there's the"
      },
      {
        "start": 432.14,
        "duration": 3.33,
        "text": "other problem that I've seen and most of"
      },
      {
        "start": 434.18,
        "duration": 4.2,
        "text": "the range based algorithms that I've"
      },
      {
        "start": 435.47,
        "duration": 5.43,
        "text": "seen are very much in the application"
      },
      {
        "start": 438.38,
        "duration": 7.11,
        "text": "the application has to be aware of it"
      },
      {
        "start": 440.9,
        "duration": 7.11,
        "text": "and has to guide it now other I have"
      },
      {
        "start": 445.49,
        "duration": 5.01,
        "text": "seen some others for instance Cassandra"
      },
      {
        "start": 448.01,
        "duration": 5.01,
        "text": "we had byte order petitioner and the"
      },
      {
        "start": 450.5,
        "duration": 4.92,
        "text": "byte order partitioner was that it used"
      },
      {
        "start": 453.02,
        "duration": 5.94,
        "text": "a range and then it divided the range"
      },
      {
        "start": 455.42,
        "duration": 5.46,
        "text": "into how many nodes who had the hotspot"
      },
      {
        "start": 458.96,
        "duration": 3.69,
        "text": "problem was the issue there"
      },
      {
        "start": 460.88,
        "duration": 3.99,
        "text": "I had a friend used to say this all time"
      },
      {
        "start": 462.65,
        "duration": 4.53,
        "text": "use Bop and your ops people will plan"
      },
      {
        "start": 464.87,
        "duration": 6.84,
        "text": "your disappearance exactly it's not good"
      },
      {
        "start": 467.18,
        "duration": 7.23,
        "text": "and also we even didn't talk about the"
      },
      {
        "start": 471.71,
        "duration": 6.78,
        "text": "older issue related to rebalancing"
      },
      {
        "start": 474.41,
        "duration": 6.72,
        "text": "because what what are your warranties"
      },
      {
        "start": 478.49,
        "duration": 4.83,
        "text": "about consistency when you are moving"
      },
      {
        "start": 481.13,
        "duration": 5.22,
        "text": "data right because in the middle of"
      },
      {
        "start": 483.32,
        "duration": 5.73,
        "text": "moving data the data has not lived yet"
      },
      {
        "start": 486.35,
        "duration": 5.64,
        "text": "the center not and the receiving not"
      },
      {
        "start": 489.05,
        "duration": 5.79,
        "text": "have not received all of them yet so in"
      },
      {
        "start": 491.99,
        "duration": 4.83,
        "text": "terms of consistency should I query the"
      },
      {
        "start": 494.84,
        "duration": 4.43,
        "text": "sender not or should i query the"
      },
      {
        "start": 496.82,
        "duration": 5.01,
        "text": "receiver not to get the data right and"
      },
      {
        "start": 499.27,
        "duration": 5.05,
        "text": "imagine that the rebalancing fail in the"
      },
      {
        "start": 501.83,
        "duration": 6.08,
        "text": "middle what do we do do we roll back or"
      },
      {
        "start": 504.32,
        "duration": 6.18,
        "text": "do we just retry so see you open"
      },
      {
        "start": 507.91,
        "duration": 5.47,
        "text": "networks Europe your data is immutable"
      },
      {
        "start": 510.5,
        "duration": 3.09,
        "text": "that's what you hope for idempotency for"
      },
      {
        "start": 513.38,
        "duration": 3.75,
        "text": "the"
      },
      {
        "start": 513.59,
        "duration": 5.94,
        "text": "yeah which is another advantage inside"
      },
      {
        "start": 517.13,
        "duration": 4.59,
        "text": "Cassandra LAN is that that idempotency"
      },
      {
        "start": 519.53,
        "duration": 4.8,
        "text": "of that data inside of a inside of the"
      },
      {
        "start": 521.72,
        "duration": 3.72,
        "text": "data model itself really helps whenever"
      },
      {
        "start": 524.33,
        "duration": 2.64,
        "text": "you have these kind of problems and"
      },
      {
        "start": 525.44,
        "duration": 3.06,
        "text": "that's that's harder to do with the"
      },
      {
        "start": 526.97,
        "duration": 2.25,
        "text": "relational databases and actually almost"
      },
      {
        "start": 528.5,
        "duration": 2.55,
        "text": "impossible"
      },
      {
        "start": 529.22,
        "duration": 4.86,
        "text": "okay well that's range based"
      },
      {
        "start": 531.05,
        "duration": 5.58,
        "text": "partitioning about the more interesting"
      },
      {
        "start": 534.08,
        "duration": 5.13,
        "text": "one the hash based partitioning so hash"
      },
      {
        "start": 536.63,
        "duration": 4.95,
        "text": "based partitioning as it names in Bly we"
      },
      {
        "start": 539.21,
        "duration": 5.4,
        "text": "use a hash function a consistent hashing"
      },
      {
        "start": 541.58,
        "duration": 6.45,
        "text": "out yeah yes so the idea is not to take"
      },
      {
        "start": 544.61,
        "duration": 5.55,
        "text": "any random hash function because if the"
      },
      {
        "start": 548.03,
        "duration": 5.19,
        "text": "the idea here is to have a very good"
      },
      {
        "start": 550.16,
        "duration": 7.17,
        "text": "distribution of your data so your hash"
      },
      {
        "start": 553.22,
        "duration": 8.25,
        "text": "function should be very distributive and"
      },
      {
        "start": 557.33,
        "duration": 6.03,
        "text": "right now in the state of the art the"
      },
      {
        "start": 561.47,
        "duration": 4.29,
        "text": "most distributive hash function out"
      },
      {
        "start": 563.36,
        "duration": 6.72,
        "text": "there is mama tree right we are using in"
      },
      {
        "start": 565.76,
        "duration": 6.99,
        "text": "modern Cassandra cluster so the course"
      },
      {
        "start": 570.08,
        "duration": 4.71,
        "text": "is that you are guaranteed to have a"
      },
      {
        "start": 572.75,
        "duration": 5.7,
        "text": "good distribution of data so I want to"
      },
      {
        "start": 574.79,
        "duration": 6.06,
        "text": "warn our all of our watcher the"
      },
      {
        "start": 578.45,
        "duration": 4.77,
        "text": "guarantee of good distribution is stas"
      },
      {
        "start": 580.85,
        "duration": 4.86,
        "text": "statistical what do i what do I mean"
      },
      {
        "start": 583.22,
        "duration": 6.93,
        "text": "imagine you are playing rolling dice"
      },
      {
        "start": 585.71,
        "duration": 7.14,
        "text": "right you roll a dice six time what is"
      },
      {
        "start": 590.15,
        "duration": 5.49,
        "text": "the grunty you have one two three four"
      },
      {
        "start": 592.85,
        "duration": 5.13,
        "text": "five six no guarantee you can have three"
      },
      {
        "start": 595.64,
        "duration": 4.14,
        "text": "times the number one three tiny number"
      },
      {
        "start": 597.98,
        "duration": 4.11,
        "text": "two and that's all what's a non repeated"
      },
      {
        "start": 599.78,
        "duration": 4.47,
        "text": "trial too exactly right so the warranty"
      },
      {
        "start": 602.09,
        "duration": 4.98,
        "text": "to have good distribution of data with"
      },
      {
        "start": 604.25,
        "duration": 5.43,
        "text": "the hash based partitioning is you"
      },
      {
        "start": 607.07,
        "duration": 6.12,
        "text": "should have a lot of distinct value"
      },
      {
        "start": 609.68,
        "duration": 6.78,
        "text": "large l yes yeah so the more you have"
      },
      {
        "start": 613.19,
        "duration": 6.93,
        "text": "distinct value of the partition keys you"
      },
      {
        "start": 616.46,
        "duration": 5.28,
        "text": "have the better the distribution is yeah"
      },
      {
        "start": 620.12,
        "duration": 3.33,
        "text": "that's pretty critical and and again"
      },
      {
        "start": 621.74,
        "duration": 4.56,
        "text": "with the consistent hashing algorithm"
      },
      {
        "start": 623.45,
        "duration": 5.04,
        "text": "and I think this bears some explanation"
      },
      {
        "start": 626.3,
        "duration": 5.61,
        "text": "it's it's not just a randomizer it's"
      },
      {
        "start": 628.49,
        "duration": 6.66,
        "text": "it's really like a one-way door you put"
      },
      {
        "start": 631.91,
        "duration": 5.7,
        "text": "a string into it and it will always give"
      },
      {
        "start": 635.15,
        "duration": 4.82,
        "text": "you the same hash yeah our random hash"
      },
      {
        "start": 637.61,
        "duration": 6.99,
        "text": "but the same one so if I put int we hi"
      },
      {
        "start": 639.97,
        "duration": 6.62,
        "text": "it spits out a huge 64 bit or 120 minute"
      },
      {
        "start": 644.6,
        "duration": 3.88,
        "text": "whatever size your"
      },
      {
        "start": 646.59,
        "duration": 4.56,
        "text": "from your hash but it'll always spit"
      },
      {
        "start": 648.48,
        "duration": 6.99,
        "text": "that out and if you put in a Shakespeare"
      },
      {
        "start": 651.15,
        "duration": 6.93,
        "text": "sonnet it'll spit out a 64 bit - but"
      },
      {
        "start": 655.47,
        "duration": 4.559,
        "text": "it'll always be that how - and yes and"
      },
      {
        "start": 658.08,
        "duration": 6.54,
        "text": "that's it's actually a pretty incredible"
      },
      {
        "start": 660.029,
        "duration": 8.071,
        "text": "thing and the the limit on collision at"
      },
      {
        "start": 664.62,
        "duration": 5.219,
        "text": "that point is well theoretically there"
      },
      {
        "start": 668.1,
        "duration": 4.26,
        "text": "is a potential for collision in the"
      },
      {
        "start": 669.839,
        "duration": 5.011,
        "text": "universe but what's such a huge number"
      },
      {
        "start": 672.36,
        "duration": 3.87,
        "text": "and yeah the chances are very small"
      },
      {
        "start": 674.85,
        "duration": 3.51,
        "text": "extremely small"
      },
      {
        "start": 676.23,
        "duration": 3.299,
        "text": "yeah and that that I think that's where"
      },
      {
        "start": 678.36,
        "duration": 2.64,
        "text": "a lot of people get hung up wait a"
      },
      {
        "start": 679.529,
        "duration": 3.621,
        "text": "minute isn't there gonna be a collision"
      },
      {
        "start": 681.0,
        "duration": 5.339,
        "text": "there's gonna have my data overlapping"
      },
      {
        "start": 683.15,
        "duration": 6.37,
        "text": "probably not yeah actually no it won't"
      },
      {
        "start": 686.339,
        "duration": 4.861,
        "text": "happen and of course now this is those"
      },
      {
        "start": 689.52,
        "duration": 4.08,
        "text": "are the pros and the cons and now"
      },
      {
        "start": 691.2,
        "duration": 5.97,
        "text": "because you are applying a hash function"
      },
      {
        "start": 693.6,
        "duration": 5.7,
        "text": "on your magician key now you can no"
      },
      {
        "start": 697.17,
        "duration": 2.97,
        "text": "longer query your partition key by range"
      },
      {
        "start": 699.3,
        "duration": 3.75,
        "text": "uh-huh"
      },
      {
        "start": 700.14,
        "duration": 4.92,
        "text": "because in fact when you hash a value"
      },
      {
        "start": 703.05,
        "duration": 3.479,
        "text": "you lose the ordering right because the"
      },
      {
        "start": 705.06,
        "duration": 3.2,
        "text": "hash value are completely like"
      },
      {
        "start": 706.529,
        "duration": 4.591,
        "text": "distributed all over the range of"
      },
      {
        "start": 708.26,
        "duration": 5.38,
        "text": "possible value so yeah scattered out"
      },
      {
        "start": 711.12,
        "duration": 5.4,
        "text": "again if you need any kind of sequence"
      },
      {
        "start": 713.64,
        "duration": 5.31,
        "text": "then you're going to be bouncing around"
      },
      {
        "start": 716.52,
        "duration": 6.0,
        "text": "all over the place to find that but in"
      },
      {
        "start": 718.95,
        "duration": 6.45,
        "text": "fact the trick is there is an ordering"
      },
      {
        "start": 722.52,
        "duration": 5.88,
        "text": "but the order is on the hashed value"
      },
      {
        "start": 725.4,
        "duration": 5.76,
        "text": "right right not on the original value so"
      },
      {
        "start": 728.4,
        "duration": 4.86,
        "text": "in fact for you developer knowing that"
      },
      {
        "start": 731.16,
        "duration": 6.32,
        "text": "the hash value of your partition key is"
      },
      {
        "start": 733.26,
        "duration": 6.84,
        "text": "order wealth it doesn't help the only"
      },
      {
        "start": 737.48,
        "duration": 5.29,
        "text": "moment the only case the only scenario"
      },
      {
        "start": 740.1,
        "duration": 4.89,
        "text": "where it's useful is you want to to"
      },
      {
        "start": 742.77,
        "duration": 5.52,
        "text": "perform a full scan of your table and"
      },
      {
        "start": 744.99,
        "duration": 6.81,
        "text": "you do it by chunk so you can say okay I"
      },
      {
        "start": 748.29,
        "duration": 5.88,
        "text": "start with the hash value being -2 blah"
      },
      {
        "start": 751.8,
        "duration": 5.159,
        "text": "blah blah and then you move on"
      },
      {
        "start": 754.17,
        "duration": 7.32,
        "text": "sequentially and then you can apply the"
      },
      {
        "start": 756.959,
        "duration": 5.941,
        "text": "idea that the hash value is order any"
      },
      {
        "start": 761.49,
        "duration": 3.27,
        "text": "moment yeah and that's how you know"
      },
      {
        "start": 762.9,
        "duration": 3.84,
        "text": "you're getting all of the data for a"
      },
      {
        "start": 764.76,
        "duration": 5.04,
        "text": "particular node in a distributed system"
      },
      {
        "start": 766.74,
        "duration": 5.67,
        "text": "partition by a consistent hash but it"
      },
      {
        "start": 769.8,
        "duration": 5.31,
        "text": "doesn't give you the guarantee that the"
      },
      {
        "start": 772.41,
        "duration": 6.24,
        "text": "the data in the partition key that when"
      },
      {
        "start": 775.11,
        "duration": 4.73,
        "text": "into the hash is ordered so if it's 1 2"
      },
      {
        "start": 778.65,
        "duration": 3.92,
        "text": "3 and gets hashed"
      },
      {
        "start": 779.84,
        "duration": 5.16,
        "text": "different ways that's not the point of"
      },
      {
        "start": 782.57,
        "duration": 4.44,
        "text": "that so like Cassandra and cql there's a"
      },
      {
        "start": 785.0,
        "duration": 4.14,
        "text": "function get token that shows you the"
      },
      {
        "start": 787.01,
        "duration": 4.02,
        "text": "token value for that partition key and"
      },
      {
        "start": 789.14,
        "duration": 3.0,
        "text": "that partition key is what we're talking"
      },
      {
        "start": 791.03,
        "duration": 2.46,
        "text": "about that's what how it gets"
      },
      {
        "start": 792.14,
        "duration": 3.75,
        "text": "distributed throughout the Cassandra"
      },
      {
        "start": 793.49,
        "duration": 5.22,
        "text": "cluster but that that get token will"
      },
      {
        "start": 795.89,
        "duration": 5.04,
        "text": "give you a number that is on a"
      },
      {
        "start": 798.71,
        "duration": 3.75,
        "text": "particular note now and you can range"
      },
      {
        "start": 800.93,
        "duration": 3.39,
        "text": "through those those token numbers"
      },
      {
        "start": 802.46,
        "duration": 3.78,
        "text": "excitement every bit of data on that"
      },
      {
        "start": 804.32,
        "duration": 3.38,
        "text": "note exactly by the way that's kind of"
      },
      {
        "start": 806.24,
        "duration": 3.08,
        "text": "the secret how the sparks don't works"
      },
      {
        "start": 807.7,
        "duration": 4.48,
        "text": "[Laughter]"
      },
      {
        "start": 809.32,
        "duration": 5.44,
        "text": "which is a you know not a secret but I"
      },
      {
        "start": 812.18,
        "duration": 4.83,
        "text": "think it's still pretty interesting yeah"
      },
      {
        "start": 814.76,
        "duration": 3.33,
        "text": "have you seen I'm kind of loading the"
      },
      {
        "start": 817.01,
        "duration": 4.26,
        "text": "question here a little bit but have you"
      },
      {
        "start": 818.09,
        "duration": 6.08,
        "text": "seen some newer things in computer"
      },
      {
        "start": 821.27,
        "duration": 5.7,
        "text": "science about partitioning techniques or"
      },
      {
        "start": 824.17,
        "duration": 5.08,
        "text": "some more modern thinking around what"
      },
      {
        "start": 826.97,
        "duration": 4.62,
        "text": "this what a partitioning technique looks"
      },
      {
        "start": 829.25,
        "duration": 6.48,
        "text": "like in a large distributed system the"
      },
      {
        "start": 831.59,
        "duration": 6.33,
        "text": "idea of so you you can introduce some"
      },
      {
        "start": 835.73,
        "duration": 5.7,
        "text": "idea where you have a bit of geo data"
      },
      {
        "start": 837.92,
        "duration": 7.59,
        "text": "which is fixed and introduce some"
      },
      {
        "start": 841.43,
        "duration": 7.23,
        "text": "hashing part of your data part of your"
      },
      {
        "start": 845.51,
        "duration": 5.85,
        "text": "primary keys is hash part of your"
      },
      {
        "start": 848.66,
        "duration": 6.09,
        "text": "primary key is right on them you can"
      },
      {
        "start": 851.36,
        "duration": 5.07,
        "text": "perform branch query but it is what we"
      },
      {
        "start": 854.75,
        "duration": 4.23,
        "text": "are already having customer are right"
      },
      {
        "start": 856.43,
        "duration": 5.1,
        "text": "but partition keys clustering columns"
      },
      {
        "start": 858.98,
        "duration": 4.74,
        "text": "one part of your primary key is for"
      },
      {
        "start": 861.53,
        "duration": 5.88,
        "text": "distribution the other part is for range"
      },
      {
        "start": 863.72,
        "duration": 5.16,
        "text": "query right and in fact in those kind of"
      },
      {
        "start": 867.41,
        "duration": 5.04,
        "text": "new technique it's very hard to go"
      },
      {
        "start": 868.88,
        "duration": 7.26,
        "text": "whenever you touch the hash function you"
      },
      {
        "start": 872.45,
        "duration": 7.08,
        "text": "lose all right yeah so it's a mathematic"
      },
      {
        "start": 876.14,
        "duration": 7.44,
        "text": "property yeah and and here break math no"
      },
      {
        "start": 879.53,
        "duration": 5.76,
        "text": "no you cannot really find a hash"
      },
      {
        "start": 883.58,
        "duration": 4.35,
        "text": "function that want to use trick all"
      },
      {
        "start": 885.29,
        "duration": 6.11,
        "text": "right no it's not hash function anymore"
      },
      {
        "start": 887.93,
        "duration": 6.21,
        "text": "I've seen some interesting ideas around"
      },
      {
        "start": 891.4,
        "duration": 4.81,
        "text": "hybridizing it or finding ways to"
      },
      {
        "start": 894.14,
        "duration": 3.84,
        "text": "control some order get some order"
      },
      {
        "start": 896.21,
        "duration": 5.67,
        "text": "control Google had an interesting paper"
      },
      {
        "start": 897.98,
        "duration": 6.75,
        "text": "not too long ago about around load so"
      },
      {
        "start": 901.88,
        "duration": 6.36,
        "text": "using an ordered based partitioner but"
      },
      {
        "start": 904.73,
        "duration": 5.34,
        "text": "with load shedding in it the you're"
      },
      {
        "start": 908.24,
        "duration": 4.74,
        "text": "starting to get into much more advanced"
      },
      {
        "start": 910.07,
        "duration": 5.88,
        "text": "much more complicated hashing techniques"
      },
      {
        "start": 912.98,
        "duration": 5.01,
        "text": "and that I think that's interesting and"
      },
      {
        "start": 915.95,
        "duration": 5.49,
        "text": "it may be something that develops over"
      },
      {
        "start": 917.99,
        "duration": 5.43,
        "text": "time but the simplicity of a consistent"
      },
      {
        "start": 921.44,
        "duration": 4.95,
        "text": "hashing algorithm or range based"
      },
      {
        "start": 923.42,
        "duration": 5.07,
        "text": "partitioner it really is helpful because"
      },
      {
        "start": 926.39,
        "duration": 3.18,
        "text": "when you're writing code let's say"
      },
      {
        "start": 928.49,
        "duration": 3.12,
        "text": "you're you know you're building an"
      },
      {
        "start": 929.57,
        "duration": 5.28,
        "text": "application for some company or for"
      },
      {
        "start": 931.61,
        "duration": 6.3,
        "text": "yourself you don't want to have to spend"
      },
      {
        "start": 934.85,
        "duration": 5.85,
        "text": "a few days on the math no you don't need"
      },
      {
        "start": 937.91,
        "duration": 5.51,
        "text": "to have a PhD no piece of science I just"
      },
      {
        "start": 940.7,
        "duration": 4.89,
        "text": "want to write your code yeah right right"
      },
      {
        "start": 943.42,
        "duration": 3.64,
        "text": "well this has been really interesting I"
      },
      {
        "start": 945.59,
        "duration": 3.36,
        "text": "mean I hope it has been interesting for"
      },
      {
        "start": 947.06,
        "duration": 5.04,
        "text": "you too I I could talk about distributed"
      },
      {
        "start": 948.95,
        "duration": 5.25,
        "text": "computing for hours and I'm sure you"
      },
      {
        "start": 952.1,
        "duration": 5.31,
        "text": "wouldn't want to listen to that and you"
      },
      {
        "start": 954.2,
        "duration": 5.46,
        "text": "could too could yeah we have before many"
      },
      {
        "start": 957.41,
        "duration": 3.57,
        "text": "many times well thank you very much for"
      },
      {
        "start": 959.66,
        "duration": 2.91,
        "text": "joining me today to be thank you press"
      },
      {
        "start": 960.98,
        "duration": 3.36,
        "text": "right all right and thanks everyone for"
      },
      {
        "start": 962.57,
        "duration": 4.74,
        "text": "joining us on the distributed data show"
      },
      {
        "start": 964.34,
        "duration": 4.35,
        "text": "we'll see you next time thank you for"
      },
      {
        "start": 967.31,
        "duration": 3.9,
        "text": "joining us again for the distributed"
      },
      {
        "start": 968.69,
        "duration": 4.35,
        "text": "data show we love your feedback so go to"
      },
      {
        "start": 971.21,
        "duration": 3.42,
        "text": "the distributed data show page on data"
      },
      {
        "start": 973.04,
        "duration": 3.57,
        "text": "Stax Academy and tell us what you think"
      },
      {
        "start": 974.63,
        "duration": 4.38,
        "text": "you can also find us on the data Stax"
      },
      {
        "start": 976.61,
        "duration": 4.26,
        "text": "Academy YouTube channel or find our"
      },
      {
        "start": 979.01,
        "duration": 4.35,
        "text": "podcast on itunes google play or"
      },
      {
        "start": 980.87,
        "duration": 4.44,
        "text": "wherever you get great podcast while"
      },
      {
        "start": 983.36,
        "duration": 5.24,
        "text": "you're there make sure and subscribe so"
      },
      {
        "start": 985.31,
        "duration": 3.29,
        "text": "you don't miss a single episode"
      },
      {
        "start": 989.15,
        "duration": 2.06,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:00:32.326380+00:00"
}