{
  "video_id": "Cx7xGRdl9hU",
  "title": "DS320.29 Spark/Cassandra Connector: Cassandra Aware Partitioning | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.29 Spark/Cassandra Connector: Cassandra Aware Partitioning\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:31:08Z",
  "thumbnail": "https://i.ytimg.com/vi/Cx7xGRdl9hU/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=Cx7xGRdl9hU",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] now the example you see here may look familiar when we introduced cassandra joins this was the result of our optimization process we said hey we were done it's running much faster it turns out though there's actually more we can do let's look quickly through the code again just to get the example in our heads we're going to start with a local statically initialized list containing two actors johnny depp and bruce willis and parallelize that make it into an rdd then we're going to join that with the cassandra table movies by actor and we're using join with cassandra table so the join is being done inside the connector which is great however we might be getting our partitioning wrong let's take a look at a diagram that illustrates what's happening now getting outside of our movie paradigm for a second we see three nodes here now imagine we have three actors bruce willis johnny depp and emma stone and we made a collection out of them we parallelized it made an rdd and that rdd gets partitioned we don't really know anything about how that rdd is partitioned though we'll probably see emma on onenote johnny on another and bruce on another when we join that to the cassandra table those elements in the actor name rdd are likely not going to be on the same nodes as the partitions they're being joined to in the cassandra table we haven't done anything to establish a relationship between that so occasionally we might get lucky and we might see the source rdd being on the right node but usually it won't be so in the optimal solution we see over on the right you'll see the bruce record from the source rdd is on the same node as the partition that has bruce as the key likewise johnny is on the same node that holds that cassandra partition and emma that rdd record in the source rdd is on the same cassandra node that holds the emma partition it's a lot more efficient this way because we don't have to move data across the network and we'd really like to avoid that if we could the trick to getting this done is to use the repartition by cassandra replica transformation this is going to kick off a partition of the rdd that you call it on but it's going to partition it to put the records on the nodes where they belong where if they're going to come in contact with a cassandra table in a future transformation like a join they're already going to be in place and we'll have less network traffic to do down the road so if there are several joins to do with this we've already done the partition and the shuffle we won't have to do it again and here's what the code looks like it's really just a small tweak on that initial collection that we parallelized after we parallelize it we repartition it by cassandra replica of course we have to specify the table because cassandra is going to need to know what's the partition key structure that we're partitioning by but we do that and that shuffle takes place afterward we're able to join that with the cassandra table and that's gonna run faster",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.64,
        "duration": 3.12,
        "text": "now the example you see"
      },
      {
        "start": 7.919,
        "duration": 3.441,
        "text": "here may look familiar when we"
      },
      {
        "start": 9.76,
        "duration": 3.6,
        "text": "introduced cassandra joins"
      },
      {
        "start": 11.36,
        "duration": 3.439,
        "text": "this was the result of our optimization"
      },
      {
        "start": 13.36,
        "duration": 3.52,
        "text": "process we said hey we were done it's"
      },
      {
        "start": 14.799,
        "duration": 4.4,
        "text": "running much faster it turns out though"
      },
      {
        "start": 16.88,
        "duration": 3.76,
        "text": "there's actually more we can do let's"
      },
      {
        "start": 19.199,
        "duration": 2.401,
        "text": "look quickly through the code again just"
      },
      {
        "start": 20.64,
        "duration": 2.799,
        "text": "to get the example"
      },
      {
        "start": 21.6,
        "duration": 3.439,
        "text": "in our heads we're going to start with a"
      },
      {
        "start": 23.439,
        "duration": 3.281,
        "text": "local statically initialized list"
      },
      {
        "start": 25.039,
        "duration": 2.641,
        "text": "containing two actors johnny depp and"
      },
      {
        "start": 26.72,
        "duration": 3.68,
        "text": "bruce willis"
      },
      {
        "start": 27.68,
        "duration": 4.08,
        "text": "and parallelize that make it into an rdd"
      },
      {
        "start": 30.4,
        "duration": 2.319,
        "text": "then we're going to join that with the"
      },
      {
        "start": 31.76,
        "duration": 3.28,
        "text": "cassandra table"
      },
      {
        "start": 32.719,
        "duration": 3.68,
        "text": "movies by actor and we're using join"
      },
      {
        "start": 35.04,
        "duration": 1.92,
        "text": "with cassandra table so the join is"
      },
      {
        "start": 36.399,
        "duration": 2.961,
        "text": "being done"
      },
      {
        "start": 36.96,
        "duration": 3.2,
        "text": "inside the connector which is great"
      },
      {
        "start": 39.36,
        "duration": 2.4,
        "text": "however"
      },
      {
        "start": 40.16,
        "duration": 2.96,
        "text": "we might be getting our partitioning"
      },
      {
        "start": 41.76,
        "duration": 2.72,
        "text": "wrong let's take a look at a diagram"
      },
      {
        "start": 43.12,
        "duration": 2.88,
        "text": "that illustrates what's happening now"
      },
      {
        "start": 44.48,
        "duration": 2.239,
        "text": "getting outside of our movie paradigm"
      },
      {
        "start": 46.0,
        "duration": 3.12,
        "text": "for a second"
      },
      {
        "start": 46.719,
        "duration": 4.16,
        "text": "we see three nodes here now imagine we"
      },
      {
        "start": 49.12,
        "duration": 3.759,
        "text": "have three actors bruce willis johnny"
      },
      {
        "start": 50.879,
        "duration": 3.52,
        "text": "depp and emma stone and we made a"
      },
      {
        "start": 52.879,
        "duration": 1.84,
        "text": "collection out of them we parallelized"
      },
      {
        "start": 54.399,
        "duration": 1.921,
        "text": "it"
      },
      {
        "start": 54.719,
        "duration": 3.201,
        "text": "made an rdd and that rdd gets"
      },
      {
        "start": 56.32,
        "duration": 2.16,
        "text": "partitioned we don't really know"
      },
      {
        "start": 57.92,
        "duration": 2.479,
        "text": "anything"
      },
      {
        "start": 58.48,
        "duration": 3.919,
        "text": "about how that rdd is partitioned though"
      },
      {
        "start": 60.399,
        "duration": 4.321,
        "text": "we'll probably see emma on onenote"
      },
      {
        "start": 62.399,
        "duration": 4.241,
        "text": "johnny on another and bruce on another"
      },
      {
        "start": 64.72,
        "duration": 5.2,
        "text": "when we join that to the cassandra table"
      },
      {
        "start": 66.64,
        "duration": 5.92,
        "text": "those elements in the actor name rdd are"
      },
      {
        "start": 69.92,
        "duration": 4.4,
        "text": "likely not going to be on the same nodes"
      },
      {
        "start": 72.56,
        "duration": 3.199,
        "text": "as the partitions they're being joined"
      },
      {
        "start": 74.32,
        "duration": 3.119,
        "text": "to in the cassandra table"
      },
      {
        "start": 75.759,
        "duration": 3.04,
        "text": "we haven't done anything to establish a"
      },
      {
        "start": 77.439,
        "duration": 2.961,
        "text": "relationship between that so"
      },
      {
        "start": 78.799,
        "duration": 4.241,
        "text": "occasionally we might get lucky"
      },
      {
        "start": 80.4,
        "duration": 3.52,
        "text": "and we might see the source rdd being on"
      },
      {
        "start": 83.04,
        "duration": 2.8,
        "text": "the right node"
      },
      {
        "start": 83.92,
        "duration": 3.519,
        "text": "but usually it won't be so in the"
      },
      {
        "start": 85.84,
        "duration": 2.08,
        "text": "optimal solution we see over on the"
      },
      {
        "start": 87.439,
        "duration": 2.32,
        "text": "right"
      },
      {
        "start": 87.92,
        "duration": 3.12,
        "text": "you'll see the bruce record from the"
      },
      {
        "start": 89.759,
        "duration": 4.161,
        "text": "source rdd"
      },
      {
        "start": 91.04,
        "duration": 4.64,
        "text": "is on the same node as the partition"
      },
      {
        "start": 93.92,
        "duration": 4.879,
        "text": "that has bruce as the key"
      },
      {
        "start": 95.68,
        "duration": 4.96,
        "text": "likewise johnny is on the same node that"
      },
      {
        "start": 98.799,
        "duration": 4.401,
        "text": "holds that cassandra partition"
      },
      {
        "start": 100.64,
        "duration": 3.28,
        "text": "and emma that rdd record in the source"
      },
      {
        "start": 103.2,
        "duration": 3.279,
        "text": "rdd"
      },
      {
        "start": 103.92,
        "duration": 3.839,
        "text": "is on the same cassandra node that holds"
      },
      {
        "start": 106.479,
        "duration": 2.561,
        "text": "the emma partition"
      },
      {
        "start": 107.759,
        "duration": 3.201,
        "text": "it's a lot more efficient this way"
      },
      {
        "start": 109.04,
        "duration": 3.68,
        "text": "because we don't have to move data"
      },
      {
        "start": 110.96,
        "duration": 3.28,
        "text": "across the network and we'd really like"
      },
      {
        "start": 112.72,
        "duration": 2.56,
        "text": "to avoid that if we could the trick to"
      },
      {
        "start": 114.24,
        "duration": 2.96,
        "text": "getting this done is to use the"
      },
      {
        "start": 115.28,
        "duration": 3.6,
        "text": "repartition by cassandra replica"
      },
      {
        "start": 117.2,
        "duration": 3.84,
        "text": "transformation this is going to kick off"
      },
      {
        "start": 118.88,
        "duration": 2.48,
        "text": "a partition of the rdd that you call it"
      },
      {
        "start": 121.04,
        "duration": 1.759,
        "text": "on"
      },
      {
        "start": 121.36,
        "duration": 3.439,
        "text": "but it's going to partition it to put"
      },
      {
        "start": 122.799,
        "duration": 3.521,
        "text": "the records on the nodes where they"
      },
      {
        "start": 124.799,
        "duration": 2.401,
        "text": "belong where if they're going to come in"
      },
      {
        "start": 126.32,
        "duration": 2.639,
        "text": "contact"
      },
      {
        "start": 127.2,
        "duration": 3.44,
        "text": "with a cassandra table in a future"
      },
      {
        "start": 128.959,
        "duration": 3.601,
        "text": "transformation like a join"
      },
      {
        "start": 130.64,
        "duration": 3.76,
        "text": "they're already going to be in place and"
      },
      {
        "start": 132.56,
        "duration": 3.84,
        "text": "we'll have less network traffic"
      },
      {
        "start": 134.4,
        "duration": 3.52,
        "text": "to do down the road so if there are"
      },
      {
        "start": 136.4,
        "duration": 3.36,
        "text": "several joins to do with this"
      },
      {
        "start": 137.92,
        "duration": 4.24,
        "text": "we've already done the partition and the"
      },
      {
        "start": 139.76,
        "duration": 4.32,
        "text": "shuffle we won't have to do it again and"
      },
      {
        "start": 142.16,
        "duration": 3.36,
        "text": "here's what the code looks like it's"
      },
      {
        "start": 144.08,
        "duration": 3.12,
        "text": "really just a small tweak"
      },
      {
        "start": 145.52,
        "duration": 4.16,
        "text": "on that initial collection that we"
      },
      {
        "start": 147.2,
        "duration": 5.039,
        "text": "parallelized after we parallelize it"
      },
      {
        "start": 149.68,
        "duration": 4.16,
        "text": "we repartition it by cassandra replica"
      },
      {
        "start": 152.239,
        "duration": 2.64,
        "text": "of course we have to specify the table"
      },
      {
        "start": 153.84,
        "duration": 2.8,
        "text": "because cassandra is going to need to"
      },
      {
        "start": 154.879,
        "duration": 3.121,
        "text": "know what's the partition key structure"
      },
      {
        "start": 156.64,
        "duration": 3.04,
        "text": "that we're partitioning by"
      },
      {
        "start": 158.0,
        "duration": 3.599,
        "text": "but we do that and that shuffle takes"
      },
      {
        "start": 159.68,
        "duration": 3.12,
        "text": "place afterward we're able to join that"
      },
      {
        "start": 161.599,
        "duration": 10.241,
        "text": "with the cassandra table"
      },
      {
        "start": 162.8,
        "duration": 9.04,
        "text": "and that's gonna run faster"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:27:27.288956+00:00"
}