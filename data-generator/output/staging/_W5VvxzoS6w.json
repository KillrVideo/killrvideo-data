{
  "video_id": "_W5VvxzoS6w",
  "title": "05 | Intro to Cassandra - The Art of Data Modeling",
  "description": "Welcome to the Intro to Cassandra Crash Course! In this video series, we'll go over the basics of how Apache Cassandra works and get hands on with implementing a basic Cassandra Database in the cloud!\n\nðŸ’» Create your Cassandra Database:\nhttps://astra.dev/cassandra-course\n\nðŸ“¥ Workshop Materials:\nhttps://github.com/DataStax-Academy/Intro-to-Cassandra-for-Developers\n\nLearn more about Cassandra at Apache (https://cassandra.apache.org/doc/latest/)  and DataStax (https://docs.datastax.com/en/landing_page/doc/landing_page/cassandra.html) documentation websites.\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastaxdevs?sub_confirmation=1 \nTwitter: https://twitter.com/datastaxdevs\nTwitch: https://www.twitch.tv/datastaxdevs\n\nAbout DataStax:\nDataStax is the company behind the massively scalable, highly available, cloud-native NoSQL data platform built on Apache Cassandraâ„¢. DataStax gives developers and enterprises the freedom to run data in any cloud, Kubernetes, hybrid or bare metal at global scale with zero downtime and zero lock-in. More than 450 of the worldâ€™s leading enterprises including Capital One, Cisco, Comcast, Delta Airlines, Macyâ€™s, McDonaldâ€™s, Safeway, Sony, and Walmart use DataStax to build transformational data architectures for real-world outcomes. For more, visit DataStax.com and @DataStax.\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache CassandraÂ©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2021-04-21T14:43:30Z",
  "thumbnail": "https://i.ytimg.com/vi/_W5VvxzoS6w/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "scalable",
    "workshop",
    "data_modeling",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "nosql",
    "astra",
    "architecture",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=_W5VvxzoS6w",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "hello and welcome back to our intro to cassandra from developers crash course this is video 5 of 7 the art of data modeling so in the previous sections we got into some of the basics of data modeling things like what's a table what's a key space you know what's a primary key so on and so forth and that's great for building up that base set of knowledge but then what happens when you actually want to start data modeling in cassandra what does that look like so that's what we're going to do in this section so the first thing we just want to do is kind of review um some terms so we're all on the same page right um the first one we see here is normalization so if you've done any work with a relational database before a normalization is probably going to feel somewhat familiar this really came from a time where disk space was not cheap and disks were not fast so normalization is really the process of reducing the amount of redundancy setting up data integrity and such like that and so you go through this process of normalization with your data and then you come up with something like kind of what you see here on the right hand side so we've got a very simple example where i've got two tables i have the employees table and the departments table and in the employees table i'm going to find out okay who are my employees and what information do i have with them but let's say that they work in various departments now in a normalization method most likely i'm going to separate the departments out into a separate table and why do i do this right well this comes down to the data redundancy piece i don't want to have a bunch of redundant data i want to have a single instance for everything that exists every type or whatever so i'm only going to have one engineering department one math department and then i'll use these relationships so use what's called a foreign key to then make a relationship between one table and another so if you notice up in the employees table not only do i have a user id per user but i also have a department id so i'm making that connection back to the department's table but again i only have one instance of each type if you will so another thing to kind of point out here is that for normalization um you know there are some pros and cons right the rights are pretty darn simple right if i want to add a new department i just add it right to the department table done right no big deal um data integrity is also a definite pro of the normalization methods and the way we do things with relational databases the cons though really from a scalability standpoint imagine now if you're 20 tables deep right where you have all of these joins between all these tables at runtime right so you have to read and do all these cartesian joins and everything the queries can become very complex as well again as you have all of these different joins and you have to bring all these different pieces of data together so another technique though is called denormalization this is essentially the opposite of normalization right so denormalization is a strategy that is used to increase read performance now this is something that in the relation world is generally not used unless you're talking like data warehousing or if you have a particular need for read performance where you need to flatten out the data in this case this is something where if you notice look at the table now i have a single employees table and i have the same edgar cod engineering you know so on and so forth but notice that the department column is actually part of the table and i'm repeating data right so one of the the strategies here is to you know we're not worrying about redundant data right we're actually saying yes data i can have redundant data and why because in databases like cassandra and more in the nosql world technology was different so cassandra is making it's making a trade-off it's saying i'm going to optimize for read performance at scale and i'm going to use up more disk space to do so and the good thing is that today compared to other commodities other things like you know memory cpu so on and so forth disk is actually the cheapest and you know with solid state drives things have gotten significantly faster from the time that when relational databases were first created so we make this trade-off and this trade-off actually works in this case so yes we're going to go ahead and repeat data here the key difference is this notice there's no joins you don't have joins in cassandra i make one read from one row if i want to get say edgar codd and i read from that partition i have all of my data in one shot right again it is an optimization for read performance at scale now again some of the pros i just mentioned the quick read performance also your queries are much much simpler without having say 20 nested joins or something like that your queries are very simple compared to a lot of the relational counterpart queries now there are some cons though now if you imagine i have multiple writes potentially right depending on where say that department data needs to go i may need to write to multiple tables where in the normalized relational sense i wouldn't i would just write to a single department table and anybody who had um a relationship to that would then get that update in the case of a denormalized data model i now may have potential rights to multiple places and then from the integrity standpoint you don't have the same type of integrity constraints that you do in a relational database here so you do have to keep up on that on your own again though the big the big reason for this though is read performance and cassandra is completely built to be able to maintain its performance at scale that's a key key thing and if you couldn't tell already yes denormalization is the data model pattern that we use in cassandra so let's look at this from the flow of how i apply my normalization techniques my data modeling and then where developers come into play so in relational data model i'm going to start off with my data i'm going to analyze that raw data i'm going to identify all of their relationships their properties and the entities i'm going to use that to generate my data model using my normalization data model patterns my normalization patterns then after that point from the application standpoint from the developer standpoint then we would do what we would take a look at whatever um you know the the er diagram or whatever was you know designed whether that's through your dba your data architect or whatever and you would use that as like the source of truth and you would then determine well what queries do i need for my application and then use that to determine well okay how do i build those up what tables do i need to join that kind of thing in cassandra we're going to flip this on its head watch what happens so in this case we're going to start with our application workflows we're going to start there with the application we're going to use that to generate our data model and our queries and everything and then apply our data now the question some of you might be thinking is does that mean i need to come up with my queries ahead of time yes actually and i'm going to go through a process right now we're going to go through that so before you think i'm crazy we're going to go through that process and show you how this works okay take a look at this diagram this is the flow right so i mentioned a moment ago we're going to start with our application workflow and our entities and relationships this a conceptual data model and our application workflow matter of fact for most of us who have been doing relational work or any kind of application development you're going to recognize a conceptual data model in a heartbeat the application workflows this is really just the workflow that your users go through right as they are working through your app i mean you could literally start drawing out a ui and a napkin and you've already started to determine like some of the application workflow now we're going to take these two things and then we're going to use that to start generating our conceptual you know mapping our conceptual to our logical data model we'll then kind of refine our logical data model a little bit then go through any optimizations if we need to and finally end with our physical data model this will be the data model we actually implement in the database so let's take a look so here is our conceptual diagram so notice in this particular case i have users and videos so imagine that this is for an application that's like youtube right where i have videos and when i go to those videos i have comments on those videos and users can also have comments as well so we see this relationship if you look at users and videos you can see i have this relation between users commenting on videos and video videos being commented on by users not only that notice that both users and videos have a set of attributes right users have an email they have an id um videos have a title a description so on and so forth so it by using my entity relationship diagram i can then start to map out what those relationships are going to look like now let's move into the application workflow so again i have these these two pieces users and videos again it's like a youtube like application so in one case use case one there a user opens a video page right so they're gonna go to some video page and i probably wanna see all the comments for that video so if you look at the workflow one here it says find comments related to target video using its identifier most reason first so all i'm saying is i want to go ahead and get the comments for a target video right so some video i click on i want to see its comments using its identifier meaning probably some key and then most recent first what am i saying there i'm essentially just saying i want the comments in time order because in an application like that for comments if i have comments in a random order they're probably not going to make much sense right so i want to go ahead and see those at most recent first now if we take a look at the second use case a user opens a profile pretty much in any retail e-commerce app whatever the vast majority of us have built and use applications that require us to log in we have some profile that goes with us same deal here so here the user logs in opens their profile and now we want to see all of their comments right across their videos and stuff so in this case you see workflow 2 i want to find comments related to the target user using its identifier again probably some user id or something again get most reason first right again i want to see those in time order so right now those two simple application workflows we're starting to map out what our data model is going to look like so the next thing i want to do is now generate some pseudo queries based off of that so query one here find comments posted for a user with a known id right so by some id i want the comments now if you look in the right hand side you're going to see this little kind of pseudo table comments by user so in cassandra the convention we use for a table name is whatever whatever the payload is by whatever i'm partitioning by so i want comments partitioned by user that's what we're saying comments partitioned by user and query2 there again i want to find comments for a video with a known id same deal comments by video i want comments partitioned by video and both of them if you know to say show most recent first going back to that kind of thing where i want them in time order that's what that means now i can take this and i can start generating my queries check this out so i'm essentially saying get all the columns so select star get all the columns from comments by user where the user id is some id that's it that's uber simple that query alone once you start to see that the the tables we're going to use that will get me all of the comments per a particular user now if you look at the second one there again i want to select all the common all the columns that's what that star is from my comments by video so i want all the comments by video or video id is again some id this is going to be the id of the video that will give me all of the comments for a video so you notice we haven't even applied any data yet we literally just started with our application workflows in our entity relationship diagram and we're just starting to map this out and we can already generate some of the queries that we're going to use okay so let's take a look at what this looks like when you start bringing in to the logical data model so if you notice here i have our two tables again now let's start on the left with comments by user and see that we have user id so user id that k that k means it's a partition key so if you remember from the previous section we talked about some of the components of the primary key are the partition key and or clustering columns k means partition key the c there you see with the arrow means clustering column the arrow means the order so what we're saying here is with user id i want to again this is the comments by user table so i'm partitioning by user so i am partitioning by user id and then i'm ordering on creation date and comment id there you see that notice the arrow for creation date is down i'm saying it's descending right what's that going to do for me well that means it's going to show them in descending order so i'm going to see the most recent first right so if i just select star from this table with no other constraint i'm immediately going to get the very latest comments in descending order and then the rest of the information is just my payload so video id and comment if you take a look on the right hand side comments by video is essentially the same thing the only difference is i'm now partitioning by the video id and in my payload i have the user id and comment instead of the video id and comment now you might notice here i'm repeating some data yes right it's denormalized and again like we said before in cassandra we use a denormalized data model that's why you know we do that again for read we optimize read performance so what this means is in each one of these cases i can then do a single read to get all the data back for the question that i have okay so now this is starting to map out our logical data model let's move over to the physical data model so i want you to see something that just happened here i'm going to go back notice creation date and common id i want you to watch what happens oh i lost a column what happened well now as i start to map out my types and everything as part of the physical data model so you see that user id has a uuid i'll talk about that in a moment what i want you to notice is comment id then got collapsed down to a time uuid what happened there well i used to have two columns creation date and comment id and as part of going into my physical data model there's an optimization that we performed i just encapsulated those down into a single type a single field common id a time uuid is a combination of a time stamp and a uuid that you can put in a single field it's a nice optimized type of field for cassandra now to be sure if i implement my data model like this would there be any problem no right i'm going to use a little bit more space and such but you know it's it's not that big of a deal so it's just an optimization you don't have to do it but i just want to give you a feel for the types of things you might optimize when you're moving from your logical data model into your physical data model so now i've got my user id is a uuid my common id is a time stamp and a uuid so you know combining both created at and common id into one field my video id is also ueid and then comment here being text now the next step is to map this to tables i mean it goes that quick actually once you get used to this pattern it's it's actually pretty it's pretty straightforward so notice here um if you're familiar with sql this should look familiar this is cql cql is a subset of sql um it looks very familiar to it but you'll notice my create table i have create table if not exists my table name comments by user i have a set of my fields there are types and then notice my primary key if you remember we designated a partition key with k so my primary key that first field with the friends again i have user id comma and then my common id is going to be my clustering column and notice that with clustering order that clustering order by comment id descending we're saying i want it descending order that way later on when i read this data out i do not need to do an order by i do not need to pay the cost of an ordering uh an order at read it is actually being saved in order on disk so when i go to retrieve it later not only do i get everything in one partition by that one user id but it's already in time ordered format so this is all optimized for your read performance at scale right and again this is whether it's three nodes or thousands of nodes to ensure that you can maintain your tight slas at any scale with cassandra okay so that's the that's the overall process that's it you can start with your application workflows you work those out you use those to generate your pseudo queries your pseudo tables you start to then just refine and notice because in a denormalized data model we don't have all the joins and everything the queries are actually extremely simple and so you can take that to just generate your queries matter of fact the general idea is query per table right one query per one table um and you'll be off to a good start okay so thanks so much let's go ahead and get into an exercise and kind of reinforce some of what you learned you",
    "segments": [
      {
        "start": 0.719,
        "duration": 4.241,
        "text": "hello and welcome back to"
      },
      {
        "start": 3.28,
        "duration": 3.039,
        "text": "our intro to cassandra from developers"
      },
      {
        "start": 4.96,
        "duration": 5.2,
        "text": "crash course this is"
      },
      {
        "start": 6.319,
        "duration": 5.841,
        "text": "video 5 of 7 the art of data modeling so"
      },
      {
        "start": 10.16,
        "duration": 3.359,
        "text": "in the previous sections we got into"
      },
      {
        "start": 12.16,
        "duration": 2.96,
        "text": "some of the basics of data modeling"
      },
      {
        "start": 13.519,
        "duration": 3.441,
        "text": "things like what's a table what's a"
      },
      {
        "start": 15.12,
        "duration": 3.919,
        "text": "key space you know what's a primary key"
      },
      {
        "start": 16.96,
        "duration": 3.04,
        "text": "so on and so forth and that's great for"
      },
      {
        "start": 19.039,
        "duration": 3.041,
        "text": "building up that base"
      },
      {
        "start": 20.0,
        "duration": 3.039,
        "text": "set of knowledge but then what happens"
      },
      {
        "start": 22.08,
        "duration": 2.8,
        "text": "when you actually want to"
      },
      {
        "start": 23.039,
        "duration": 3.361,
        "text": "start data modeling in cassandra what"
      },
      {
        "start": 24.88,
        "duration": 2.319,
        "text": "does that look like so that's what we're"
      },
      {
        "start": 26.4,
        "duration": 3.279,
        "text": "going to do in"
      },
      {
        "start": 27.199,
        "duration": 3.441,
        "text": "this section so the first thing we just"
      },
      {
        "start": 29.679,
        "duration": 3.681,
        "text": "want to do is kind of"
      },
      {
        "start": 30.64,
        "duration": 3.36,
        "text": "review um some terms so we're all on the"
      },
      {
        "start": 33.36,
        "duration": 2.96,
        "text": "same page"
      },
      {
        "start": 34.0,
        "duration": 4.079,
        "text": "right um the first one we see here is"
      },
      {
        "start": 36.32,
        "duration": 3.36,
        "text": "normalization so if you've done any work"
      },
      {
        "start": 38.079,
        "duration": 3.201,
        "text": "with a relational database before"
      },
      {
        "start": 39.68,
        "duration": 3.52,
        "text": "a normalization is probably going to"
      },
      {
        "start": 41.28,
        "duration": 3.52,
        "text": "feel somewhat familiar this really came"
      },
      {
        "start": 43.2,
        "duration": 5.199,
        "text": "from a time"
      },
      {
        "start": 44.8,
        "duration": 5.759,
        "text": "where disk space was not cheap and disks"
      },
      {
        "start": 48.399,
        "duration": 3.121,
        "text": "were not fast so normalization is really"
      },
      {
        "start": 50.559,
        "duration": 3.761,
        "text": "the process"
      },
      {
        "start": 51.52,
        "duration": 4.48,
        "text": "of reducing the amount of redundancy"
      },
      {
        "start": 54.32,
        "duration": 3.04,
        "text": "setting up data integrity and such like"
      },
      {
        "start": 56.0,
        "duration": 3.28,
        "text": "that and so you go through this process"
      },
      {
        "start": 57.36,
        "duration": 3.6,
        "text": "of normalization with your data"
      },
      {
        "start": 59.28,
        "duration": 3.279,
        "text": "and then you come up with something like"
      },
      {
        "start": 60.96,
        "duration": 2.32,
        "text": "kind of what you see here on the right"
      },
      {
        "start": 62.559,
        "duration": 2.56,
        "text": "hand side"
      },
      {
        "start": 63.28,
        "duration": 3.519,
        "text": "so we've got a very simple example where"
      },
      {
        "start": 65.119,
        "duration": 2.241,
        "text": "i've got two tables i have the employees"
      },
      {
        "start": 66.799,
        "duration": 2.481,
        "text": "table"
      },
      {
        "start": 67.36,
        "duration": 3.52,
        "text": "and the departments table and in the"
      },
      {
        "start": 69.28,
        "duration": 3.199,
        "text": "employees table"
      },
      {
        "start": 70.88,
        "duration": 3.44,
        "text": "i'm going to find out okay who are my"
      },
      {
        "start": 72.479,
        "duration": 2.721,
        "text": "employees and what information do i have"
      },
      {
        "start": 74.32,
        "duration": 2.56,
        "text": "with them"
      },
      {
        "start": 75.2,
        "duration": 3.52,
        "text": "but let's say that they work in various"
      },
      {
        "start": 76.88,
        "duration": 2.4,
        "text": "departments now in a normalization"
      },
      {
        "start": 78.72,
        "duration": 2.719,
        "text": "method"
      },
      {
        "start": 79.28,
        "duration": 4.479,
        "text": "most likely i'm going to separate the"
      },
      {
        "start": 81.439,
        "duration": 4.481,
        "text": "departments out into a separate table"
      },
      {
        "start": 83.759,
        "duration": 4.161,
        "text": "and why do i do this right well this"
      },
      {
        "start": 85.92,
        "duration": 3.12,
        "text": "comes down to the data redundancy piece"
      },
      {
        "start": 87.92,
        "duration": 2.879,
        "text": "i don't want to have a bunch of"
      },
      {
        "start": 89.04,
        "duration": 3.28,
        "text": "redundant data i want to have a single"
      },
      {
        "start": 90.799,
        "duration": 3.68,
        "text": "instance for everything"
      },
      {
        "start": 92.32,
        "duration": 3.04,
        "text": "that exists every type or whatever so"
      },
      {
        "start": 94.479,
        "duration": 2.96,
        "text": "i'm only going to have"
      },
      {
        "start": 95.36,
        "duration": 3.759,
        "text": "one engineering department one math"
      },
      {
        "start": 97.439,
        "duration": 3.04,
        "text": "department and then i'll use these"
      },
      {
        "start": 99.119,
        "duration": 2.161,
        "text": "relationships so use what's called a"
      },
      {
        "start": 100.479,
        "duration": 2.64,
        "text": "foreign key"
      },
      {
        "start": 101.28,
        "duration": 3.76,
        "text": "to then make a relationship between one"
      },
      {
        "start": 103.119,
        "duration": 3.201,
        "text": "table and another so if you notice up in"
      },
      {
        "start": 105.04,
        "duration": 3.28,
        "text": "the employees table"
      },
      {
        "start": 106.32,
        "duration": 3.52,
        "text": "not only do i have a user id per user"
      },
      {
        "start": 108.32,
        "duration": 2.799,
        "text": "but i also have a department id so i'm"
      },
      {
        "start": 109.84,
        "duration": 3.68,
        "text": "making that connection"
      },
      {
        "start": 111.119,
        "duration": 3.121,
        "text": "back to the department's table but again"
      },
      {
        "start": 113.52,
        "duration": 4.8,
        "text": "i only have"
      },
      {
        "start": 114.24,
        "duration": 5.44,
        "text": "one instance of each type if you will so"
      },
      {
        "start": 118.32,
        "duration": 3.2,
        "text": "another thing to kind of point out here"
      },
      {
        "start": 119.68,
        "duration": 3.52,
        "text": "is that for normalization"
      },
      {
        "start": 121.52,
        "duration": 4.08,
        "text": "um you know there are some pros and cons"
      },
      {
        "start": 123.2,
        "duration": 4.0,
        "text": "right the rights are pretty darn simple"
      },
      {
        "start": 125.6,
        "duration": 2.879,
        "text": "right if i want to add a new department"
      },
      {
        "start": 127.2,
        "duration": 1.679,
        "text": "i just add it right to the department"
      },
      {
        "start": 128.479,
        "duration": 2.721,
        "text": "table"
      },
      {
        "start": 128.879,
        "duration": 3.601,
        "text": "done right no big deal um data integrity"
      },
      {
        "start": 131.2,
        "duration": 2.88,
        "text": "is also a definite pro"
      },
      {
        "start": 132.48,
        "duration": 3.759,
        "text": "of the normalization methods and the way"
      },
      {
        "start": 134.08,
        "duration": 4.32,
        "text": "we do things with relational databases"
      },
      {
        "start": 136.239,
        "duration": 3.441,
        "text": "the cons though really from a"
      },
      {
        "start": 138.4,
        "duration": 2.88,
        "text": "scalability standpoint"
      },
      {
        "start": 139.68,
        "duration": 3.6,
        "text": "imagine now if you're 20 tables deep"
      },
      {
        "start": 141.28,
        "duration": 3.52,
        "text": "right where you have all of these joins"
      },
      {
        "start": 143.28,
        "duration": 3.12,
        "text": "between all these tables"
      },
      {
        "start": 144.8,
        "duration": 2.799,
        "text": "at runtime right so you have to read and"
      },
      {
        "start": 146.4,
        "duration": 1.76,
        "text": "do all these cartesian joins and"
      },
      {
        "start": 147.599,
        "duration": 2.801,
        "text": "everything"
      },
      {
        "start": 148.16,
        "duration": 4.32,
        "text": "the queries can become very complex as"
      },
      {
        "start": 150.4,
        "duration": 3.36,
        "text": "well again as you have all of these"
      },
      {
        "start": 152.48,
        "duration": 2.56,
        "text": "different joins and you have to bring"
      },
      {
        "start": 153.76,
        "duration": 2.8,
        "text": "all these different pieces of data"
      },
      {
        "start": 155.04,
        "duration": 3.68,
        "text": "together"
      },
      {
        "start": 156.56,
        "duration": 3.28,
        "text": "so another technique though is called"
      },
      {
        "start": 158.72,
        "duration": 3.04,
        "text": "denormalization"
      },
      {
        "start": 159.84,
        "duration": 3.52,
        "text": "this is essentially the opposite of"
      },
      {
        "start": 161.76,
        "duration": 4.8,
        "text": "normalization right"
      },
      {
        "start": 163.36,
        "duration": 4.8,
        "text": "so denormalization is a strategy"
      },
      {
        "start": 166.56,
        "duration": 3.6,
        "text": "that is used to increase read"
      },
      {
        "start": 168.16,
        "duration": 3.52,
        "text": "performance now"
      },
      {
        "start": 170.16,
        "duration": 3.439,
        "text": "this is something that in the relation"
      },
      {
        "start": 171.68,
        "duration": 3.279,
        "text": "world is generally not"
      },
      {
        "start": 173.599,
        "duration": 3.36,
        "text": "used unless you're talking like data"
      },
      {
        "start": 174.959,
        "duration": 3.521,
        "text": "warehousing or if you have a particular"
      },
      {
        "start": 176.959,
        "duration": 3.441,
        "text": "need for read performance where you need"
      },
      {
        "start": 178.48,
        "duration": 4.32,
        "text": "to flatten out the data"
      },
      {
        "start": 180.4,
        "duration": 3.759,
        "text": "in this case this is something where if"
      },
      {
        "start": 182.8,
        "duration": 3.439,
        "text": "you notice look at the table now i have"
      },
      {
        "start": 184.159,
        "duration": 3.761,
        "text": "a single employees table"
      },
      {
        "start": 186.239,
        "duration": 3.121,
        "text": "and i have the same edgar cod"
      },
      {
        "start": 187.92,
        "duration": 1.92,
        "text": "engineering you know so on and so forth"
      },
      {
        "start": 189.36,
        "duration": 2.239,
        "text": "but"
      },
      {
        "start": 189.84,
        "duration": 3.039,
        "text": "notice that the department column is"
      },
      {
        "start": 191.599,
        "duration": 4.0,
        "text": "actually part of"
      },
      {
        "start": 192.879,
        "duration": 3.44,
        "text": "the table and i'm repeating data right"
      },
      {
        "start": 195.599,
        "duration": 4.161,
        "text": "so"
      },
      {
        "start": 196.319,
        "duration": 5.2,
        "text": "one of the the strategies here is to"
      },
      {
        "start": 199.76,
        "duration": 3.28,
        "text": "you know we're not worrying about"
      },
      {
        "start": 201.519,
        "duration": 3.28,
        "text": "redundant data right we're actually"
      },
      {
        "start": 203.04,
        "duration": 3.279,
        "text": "saying yes data i can have redundant"
      },
      {
        "start": 204.799,
        "duration": 4.641,
        "text": "data and why"
      },
      {
        "start": 206.319,
        "duration": 5.84,
        "text": "because in databases like cassandra and"
      },
      {
        "start": 209.44,
        "duration": 3.439,
        "text": "more in the nosql world technology was"
      },
      {
        "start": 212.159,
        "duration": 2.72,
        "text": "different"
      },
      {
        "start": 212.879,
        "duration": 3.121,
        "text": "so cassandra is making it's making a"
      },
      {
        "start": 214.879,
        "duration": 3.36,
        "text": "trade-off it's saying"
      },
      {
        "start": 216.0,
        "duration": 3.36,
        "text": "i'm going to optimize for read"
      },
      {
        "start": 218.239,
        "duration": 4.401,
        "text": "performance at"
      },
      {
        "start": 219.36,
        "duration": 5.599,
        "text": "scale and i'm going to use up"
      },
      {
        "start": 222.64,
        "duration": 3.84,
        "text": "more disk space to do so and the good"
      },
      {
        "start": 224.959,
        "duration": 2.801,
        "text": "thing is that today compared to other"
      },
      {
        "start": 226.48,
        "duration": 3.92,
        "text": "commodities other things like"
      },
      {
        "start": 227.76,
        "duration": 4.72,
        "text": "you know memory cpu so on and so forth"
      },
      {
        "start": 230.4,
        "duration": 3.52,
        "text": "disk is actually the cheapest and"
      },
      {
        "start": 232.48,
        "duration": 4.0,
        "text": "you know with solid state drives things"
      },
      {
        "start": 233.92,
        "duration": 4.64,
        "text": "have gotten significantly faster"
      },
      {
        "start": 236.48,
        "duration": 3.759,
        "text": "from the time that when relational"
      },
      {
        "start": 238.56,
        "duration": 3.12,
        "text": "databases were first created"
      },
      {
        "start": 240.239,
        "duration": 3.041,
        "text": "so we make this trade-off and this"
      },
      {
        "start": 241.68,
        "duration": 3.04,
        "text": "trade-off actually works in this case"
      },
      {
        "start": 243.28,
        "duration": 3.76,
        "text": "so yes we're going to go ahead and"
      },
      {
        "start": 244.72,
        "duration": 2.799,
        "text": "repeat data here the key difference is"
      },
      {
        "start": 247.04,
        "duration": 2.32,
        "text": "this"
      },
      {
        "start": 247.519,
        "duration": 3.121,
        "text": "notice there's no joins you don't have"
      },
      {
        "start": 249.36,
        "duration": 3.519,
        "text": "joins in cassandra"
      },
      {
        "start": 250.64,
        "duration": 3.519,
        "text": "i make one read from one row if i want"
      },
      {
        "start": 252.879,
        "duration": 2.801,
        "text": "to get say edgar codd"
      },
      {
        "start": 254.159,
        "duration": 3.521,
        "text": "and i read from that partition i have"
      },
      {
        "start": 255.68,
        "duration": 3.679,
        "text": "all of my data in one shot right again"
      },
      {
        "start": 257.68,
        "duration": 4.88,
        "text": "it is an optimization"
      },
      {
        "start": 259.359,
        "duration": 4.081,
        "text": "for read performance at scale now again"
      },
      {
        "start": 262.56,
        "duration": 2.079,
        "text": "some of the pros"
      },
      {
        "start": 263.44,
        "duration": 2.72,
        "text": "i just mentioned the quick read"
      },
      {
        "start": 264.639,
        "duration": 2.56,
        "text": "performance also your queries are much"
      },
      {
        "start": 266.16,
        "duration": 3.2,
        "text": "much simpler"
      },
      {
        "start": 267.199,
        "duration": 3.681,
        "text": "without having say 20 nested joins or"
      },
      {
        "start": 269.36,
        "duration": 2.32,
        "text": "something like that your queries are"
      },
      {
        "start": 270.88,
        "duration": 2.319,
        "text": "very simple"
      },
      {
        "start": 271.68,
        "duration": 3.36,
        "text": "compared to a lot of the relational"
      },
      {
        "start": 273.199,
        "duration": 2.72,
        "text": "counterpart queries now there are some"
      },
      {
        "start": 275.04,
        "duration": 2.64,
        "text": "cons though"
      },
      {
        "start": 275.919,
        "duration": 3.041,
        "text": "now if you imagine i have multiple"
      },
      {
        "start": 277.68,
        "duration": 3.36,
        "text": "writes potentially right"
      },
      {
        "start": 278.96,
        "duration": 3.04,
        "text": "depending on where say that department"
      },
      {
        "start": 281.04,
        "duration": 3.04,
        "text": "data needs to go"
      },
      {
        "start": 282.0,
        "duration": 3.28,
        "text": "i may need to write to multiple tables"
      },
      {
        "start": 284.08,
        "duration": 3.28,
        "text": "where in the"
      },
      {
        "start": 285.28,
        "duration": 3.52,
        "text": "normalized relational sense i wouldn't i"
      },
      {
        "start": 287.36,
        "duration": 3.04,
        "text": "would just write to a single department"
      },
      {
        "start": 288.8,
        "duration": 4.24,
        "text": "table and anybody who had"
      },
      {
        "start": 290.4,
        "duration": 4.4,
        "text": "um a relationship to that would then get"
      },
      {
        "start": 293.04,
        "duration": 4.719,
        "text": "that update in the case of"
      },
      {
        "start": 294.8,
        "duration": 5.36,
        "text": "a denormalized data model i now may have"
      },
      {
        "start": 297.759,
        "duration": 4.16,
        "text": "potential rights to multiple places"
      },
      {
        "start": 300.16,
        "duration": 3.28,
        "text": "and then from the integrity standpoint"
      },
      {
        "start": 301.919,
        "duration": 3.12,
        "text": "you don't have the same type of"
      },
      {
        "start": 303.44,
        "duration": 3.44,
        "text": "integrity constraints that you do in a"
      },
      {
        "start": 305.039,
        "duration": 3.6,
        "text": "relational database here"
      },
      {
        "start": 306.88,
        "duration": 3.599,
        "text": "so you do have to keep up on that on"
      },
      {
        "start": 308.639,
        "duration": 4.321,
        "text": "your own again though the big"
      },
      {
        "start": 310.479,
        "duration": 4.16,
        "text": "the big reason for this though is read"
      },
      {
        "start": 312.96,
        "duration": 3.44,
        "text": "performance and cassandra"
      },
      {
        "start": 314.639,
        "duration": 4.241,
        "text": "is completely built to be able to"
      },
      {
        "start": 316.4,
        "duration": 4.16,
        "text": "maintain its performance at scale that's"
      },
      {
        "start": 318.88,
        "duration": 2.159,
        "text": "a key key thing and if you couldn't tell"
      },
      {
        "start": 320.56,
        "duration": 2.8,
        "text": "already"
      },
      {
        "start": 321.039,
        "duration": 4.88,
        "text": "yes denormalization is the data model"
      },
      {
        "start": 323.36,
        "duration": 6.16,
        "text": "pattern that we use in cassandra"
      },
      {
        "start": 325.919,
        "duration": 6.081,
        "text": "so let's look at this from the flow"
      },
      {
        "start": 329.52,
        "duration": 3.92,
        "text": "of how i apply my normalization"
      },
      {
        "start": 332.0,
        "duration": 3.44,
        "text": "techniques my data modeling and then"
      },
      {
        "start": 333.44,
        "duration": 4.24,
        "text": "where developers come into play"
      },
      {
        "start": 335.44,
        "duration": 3.599,
        "text": "so in relational data model i'm going to"
      },
      {
        "start": 337.68,
        "duration": 3.28,
        "text": "start off with my data i'm going to"
      },
      {
        "start": 339.039,
        "duration": 3.201,
        "text": "analyze that raw data"
      },
      {
        "start": 340.96,
        "duration": 3.2,
        "text": "i'm going to identify all of their"
      },
      {
        "start": 342.24,
        "duration": 2.64,
        "text": "relationships their properties and the"
      },
      {
        "start": 344.16,
        "duration": 3.44,
        "text": "entities"
      },
      {
        "start": 344.88,
        "duration": 3.68,
        "text": "i'm going to use that to generate my"
      },
      {
        "start": 347.6,
        "duration": 4.08,
        "text": "data model"
      },
      {
        "start": 348.56,
        "duration": 5.52,
        "text": "using my normalization data model"
      },
      {
        "start": 351.68,
        "duration": 5.6,
        "text": "patterns my normalization patterns"
      },
      {
        "start": 354.08,
        "duration": 4.399,
        "text": "then after that point from the"
      },
      {
        "start": 357.28,
        "duration": 2.72,
        "text": "application standpoint from the"
      },
      {
        "start": 358.479,
        "duration": 3.44,
        "text": "developer standpoint"
      },
      {
        "start": 360.0,
        "duration": 3.36,
        "text": "then we would do what we would take a"
      },
      {
        "start": 361.919,
        "duration": 4.641,
        "text": "look at whatever"
      },
      {
        "start": 363.36,
        "duration": 5.119,
        "text": "um you know the the er diagram"
      },
      {
        "start": 366.56,
        "duration": 3.359,
        "text": "or whatever was you know designed"
      },
      {
        "start": 368.479,
        "duration": 2.961,
        "text": "whether that's through your dba your"
      },
      {
        "start": 369.919,
        "duration": 2.72,
        "text": "data architect or whatever"
      },
      {
        "start": 371.44,
        "duration": 2.8,
        "text": "and you would use that as like the"
      },
      {
        "start": 372.639,
        "duration": 3.361,
        "text": "source of truth and you would then"
      },
      {
        "start": 374.24,
        "duration": 3.12,
        "text": "determine well what queries do i need"
      },
      {
        "start": 376.0,
        "duration": 3.919,
        "text": "for my application"
      },
      {
        "start": 377.36,
        "duration": 4.08,
        "text": "and then use that to determine well okay"
      },
      {
        "start": 379.919,
        "duration": 2.4,
        "text": "how do i build those up what tables do i"
      },
      {
        "start": 381.44,
        "duration": 3.92,
        "text": "need to join"
      },
      {
        "start": 382.319,
        "duration": 5.041,
        "text": "that kind of thing in cassandra"
      },
      {
        "start": 385.36,
        "duration": 3.2,
        "text": "we're going to flip this on its head"
      },
      {
        "start": 387.36,
        "duration": 3.679,
        "text": "watch what happens"
      },
      {
        "start": 388.56,
        "duration": 4.079,
        "text": "so in this case we're going to start"
      },
      {
        "start": 391.039,
        "duration": 3.201,
        "text": "with our application workflows"
      },
      {
        "start": 392.639,
        "duration": 4.241,
        "text": "we're going to start there with the"
      },
      {
        "start": 394.24,
        "duration": 4.959,
        "text": "application we're going to use that to"
      },
      {
        "start": 396.88,
        "duration": 3.68,
        "text": "generate our data model and our queries"
      },
      {
        "start": 399.199,
        "duration": 3.921,
        "text": "and everything"
      },
      {
        "start": 400.56,
        "duration": 4.72,
        "text": "and then apply our data now the question"
      },
      {
        "start": 403.12,
        "duration": 3.84,
        "text": "some of you might be thinking is"
      },
      {
        "start": 405.28,
        "duration": 3.44,
        "text": "does that mean i need to come up with my"
      },
      {
        "start": 406.96,
        "duration": 3.679,
        "text": "queries ahead of time yes"
      },
      {
        "start": 408.72,
        "duration": 3.039,
        "text": "actually and i'm going to go through a"
      },
      {
        "start": 410.639,
        "duration": 2.4,
        "text": "process right now we're going to go"
      },
      {
        "start": 411.759,
        "duration": 1.84,
        "text": "through that so before you think i'm"
      },
      {
        "start": 413.039,
        "duration": 1.681,
        "text": "crazy"
      },
      {
        "start": 413.599,
        "duration": 3.121,
        "text": "we're going to go through that process"
      },
      {
        "start": 414.72,
        "duration": 5.28,
        "text": "and show you how this works"
      },
      {
        "start": 416.72,
        "duration": 5.84,
        "text": "okay take a look at this diagram"
      },
      {
        "start": 420.0,
        "duration": 3.84,
        "text": "this is the flow right so i mentioned a"
      },
      {
        "start": 422.56,
        "duration": 2.96,
        "text": "moment ago we're going to start with our"
      },
      {
        "start": 423.84,
        "duration": 3.44,
        "text": "application workflow and our"
      },
      {
        "start": 425.52,
        "duration": 2.959,
        "text": "entities and relationships this a"
      },
      {
        "start": 427.28,
        "duration": 2.24,
        "text": "conceptual data model and our"
      },
      {
        "start": 428.479,
        "duration": 2.72,
        "text": "application workflow"
      },
      {
        "start": 429.52,
        "duration": 3.44,
        "text": "matter of fact for most of us who have"
      },
      {
        "start": 431.199,
        "duration": 3.201,
        "text": "been doing relational work or"
      },
      {
        "start": 432.96,
        "duration": 2.72,
        "text": "any kind of application development"
      },
      {
        "start": 434.4,
        "duration": 2.639,
        "text": "you're going to recognize a conceptual"
      },
      {
        "start": 435.68,
        "duration": 2.959,
        "text": "data model in a heartbeat"
      },
      {
        "start": 437.039,
        "duration": 3.44,
        "text": "the application workflows this is really"
      },
      {
        "start": 438.639,
        "duration": 2.481,
        "text": "just the workflow that your users go"
      },
      {
        "start": 440.479,
        "duration": 2.72,
        "text": "through"
      },
      {
        "start": 441.12,
        "duration": 3.84,
        "text": "right as they are working through your"
      },
      {
        "start": 443.199,
        "duration": 4.081,
        "text": "app i mean you could literally start"
      },
      {
        "start": 444.96,
        "duration": 3.76,
        "text": "drawing out a ui and a napkin and you've"
      },
      {
        "start": 447.28,
        "duration": 2.96,
        "text": "already started to determine like some"
      },
      {
        "start": 448.72,
        "duration": 2.879,
        "text": "of the application workflow"
      },
      {
        "start": 450.24,
        "duration": 2.88,
        "text": "now we're going to take these two things"
      },
      {
        "start": 451.599,
        "duration": 1.841,
        "text": "and then we're going to use that to"
      },
      {
        "start": 453.12,
        "duration": 2.32,
        "text": "start"
      },
      {
        "start": 453.44,
        "duration": 3.52,
        "text": "generating our conceptual you know"
      },
      {
        "start": 455.44,
        "duration": 2.479,
        "text": "mapping our conceptual to our logical"
      },
      {
        "start": 456.96,
        "duration": 3.04,
        "text": "data model"
      },
      {
        "start": 457.919,
        "duration": 3.441,
        "text": "we'll then kind of refine our logical"
      },
      {
        "start": 460.0,
        "duration": 3.44,
        "text": "data model a little bit"
      },
      {
        "start": 461.36,
        "duration": 3.2,
        "text": "then go through any optimizations if we"
      },
      {
        "start": 463.44,
        "duration": 3.039,
        "text": "need to and"
      },
      {
        "start": 464.56,
        "duration": 3.6,
        "text": "finally end with our physical data model"
      },
      {
        "start": 466.479,
        "duration": 3.84,
        "text": "this will be the data model we actually"
      },
      {
        "start": 468.16,
        "duration": 4.4,
        "text": "implement in the database"
      },
      {
        "start": 470.319,
        "duration": 3.921,
        "text": "so let's take a look so here is our"
      },
      {
        "start": 472.56,
        "duration": 3.199,
        "text": "conceptual diagram so notice in this"
      },
      {
        "start": 474.24,
        "duration": 3.44,
        "text": "particular case"
      },
      {
        "start": 475.759,
        "duration": 3.28,
        "text": "i have users and videos so imagine that"
      },
      {
        "start": 477.68,
        "duration": 2.0,
        "text": "this is for an application that's like"
      },
      {
        "start": 479.039,
        "duration": 3.361,
        "text": "youtube"
      },
      {
        "start": 479.68,
        "duration": 4.32,
        "text": "right where i have videos and when i go"
      },
      {
        "start": 482.4,
        "duration": 2.479,
        "text": "to those videos i have comments on those"
      },
      {
        "start": 484.0,
        "duration": 3.759,
        "text": "videos"
      },
      {
        "start": 484.879,
        "duration": 4.641,
        "text": "and users can also have comments as well"
      },
      {
        "start": 487.759,
        "duration": 3.201,
        "text": "so we see this relationship if you look"
      },
      {
        "start": 489.52,
        "duration": 3.519,
        "text": "at users and videos"
      },
      {
        "start": 490.96,
        "duration": 4.16,
        "text": "you can see i have this relation between"
      },
      {
        "start": 493.039,
        "duration": 4.801,
        "text": "users commenting on videos"
      },
      {
        "start": 495.12,
        "duration": 3.6,
        "text": "and video videos being commented on by"
      },
      {
        "start": 497.84,
        "duration": 2.88,
        "text": "users"
      },
      {
        "start": 498.72,
        "duration": 3.28,
        "text": "not only that notice that both users and"
      },
      {
        "start": 500.72,
        "duration": 3.52,
        "text": "videos have a set"
      },
      {
        "start": 502.0,
        "duration": 4.0,
        "text": "of attributes right users have an email"
      },
      {
        "start": 504.24,
        "duration": 3.76,
        "text": "they have an id um"
      },
      {
        "start": 506.0,
        "duration": 3.36,
        "text": "videos have a title a description so on"
      },
      {
        "start": 508.0,
        "duration": 4.399,
        "text": "and so forth so it"
      },
      {
        "start": 509.36,
        "duration": 5.52,
        "text": "by using my entity relationship diagram"
      },
      {
        "start": 512.399,
        "duration": 4.961,
        "text": "i can then start to map out what those"
      },
      {
        "start": 514.88,
        "duration": 3.959,
        "text": "relationships are going to look like"
      },
      {
        "start": 517.36,
        "duration": 4.239,
        "text": "now let's move into the application"
      },
      {
        "start": 518.839,
        "duration": 4.521,
        "text": "workflow so again i have these these two"
      },
      {
        "start": 521.599,
        "duration": 3.601,
        "text": "pieces users and videos again it's like"
      },
      {
        "start": 523.36,
        "duration": 4.72,
        "text": "a youtube like application"
      },
      {
        "start": 525.2,
        "duration": 4.319,
        "text": "so in one case use case one there a user"
      },
      {
        "start": 528.08,
        "duration": 2.879,
        "text": "opens a video page"
      },
      {
        "start": 529.519,
        "duration": 3.201,
        "text": "right so they're gonna go to some video"
      },
      {
        "start": 530.959,
        "duration": 4.161,
        "text": "page and i probably wanna see"
      },
      {
        "start": 532.72,
        "duration": 4.32,
        "text": "all the comments for that video so if"
      },
      {
        "start": 535.12,
        "duration": 4.56,
        "text": "you look at the workflow one here"
      },
      {
        "start": 537.04,
        "duration": 3.12,
        "text": "it says find comments related to target"
      },
      {
        "start": 539.68,
        "duration": 3.04,
        "text": "video"
      },
      {
        "start": 540.16,
        "duration": 4.0,
        "text": "using its identifier most reason first"
      },
      {
        "start": 542.72,
        "duration": 3.119,
        "text": "so all i'm saying is"
      },
      {
        "start": 544.16,
        "duration": 3.2,
        "text": "i want to go ahead and get the comments"
      },
      {
        "start": 545.839,
        "duration": 2.961,
        "text": "for a target video"
      },
      {
        "start": 547.36,
        "duration": 3.52,
        "text": "right so some video i click on i want to"
      },
      {
        "start": 548.8,
        "duration": 3.68,
        "text": "see its comments using its identifier"
      },
      {
        "start": 550.88,
        "duration": 3.519,
        "text": "meaning probably some key"
      },
      {
        "start": 552.48,
        "duration": 3.84,
        "text": "and then most recent first what am i"
      },
      {
        "start": 554.399,
        "duration": 3.681,
        "text": "saying there i'm essentially just saying"
      },
      {
        "start": 556.32,
        "duration": 3.68,
        "text": "i want the comments in time order"
      },
      {
        "start": 558.08,
        "duration": 4.4,
        "text": "because in an application like that for"
      },
      {
        "start": 560.0,
        "duration": 3.04,
        "text": "comments if i have comments in a random"
      },
      {
        "start": 562.48,
        "duration": 1.68,
        "text": "order"
      },
      {
        "start": 563.04,
        "duration": 2.799,
        "text": "they're probably not going to make much"
      },
      {
        "start": 564.16,
        "duration": 4.16,
        "text": "sense right so i want to go ahead and"
      },
      {
        "start": 565.839,
        "duration": 3.761,
        "text": "see those at most recent first"
      },
      {
        "start": 568.32,
        "duration": 3.68,
        "text": "now if we take a look at the second use"
      },
      {
        "start": 569.6,
        "duration": 4.799,
        "text": "case a user opens a profile"
      },
      {
        "start": 572.0,
        "duration": 4.16,
        "text": "pretty much in any retail e-commerce app"
      },
      {
        "start": 574.399,
        "duration": 3.361,
        "text": "whatever the vast majority of us have"
      },
      {
        "start": 576.16,
        "duration": 3.6,
        "text": "built and use applications"
      },
      {
        "start": 577.76,
        "duration": 3.28,
        "text": "that require us to log in we have some"
      },
      {
        "start": 579.76,
        "duration": 4.079,
        "text": "profile that goes with us"
      },
      {
        "start": 581.04,
        "duration": 4.08,
        "text": "same deal here so here the user logs in"
      },
      {
        "start": 583.839,
        "duration": 3.361,
        "text": "opens their profile"
      },
      {
        "start": 585.12,
        "duration": 3.92,
        "text": "and now we want to see all of their"
      },
      {
        "start": 587.2,
        "duration": 3.92,
        "text": "comments right across"
      },
      {
        "start": 589.04,
        "duration": 4.08,
        "text": "their videos and stuff so in this case"
      },
      {
        "start": 591.12,
        "duration": 3.76,
        "text": "you see workflow 2"
      },
      {
        "start": 593.12,
        "duration": 4.0,
        "text": "i want to find comments related to the"
      },
      {
        "start": 594.88,
        "duration": 4.32,
        "text": "target user using its identifier again"
      },
      {
        "start": 597.12,
        "duration": 4.24,
        "text": "probably some user id or something"
      },
      {
        "start": 599.2,
        "duration": 4.0,
        "text": "again get most reason first right again"
      },
      {
        "start": 601.36,
        "duration": 3.919,
        "text": "i want to see those in time order"
      },
      {
        "start": 603.2,
        "duration": 3.759,
        "text": "so right now those two simple"
      },
      {
        "start": 605.279,
        "duration": 2.56,
        "text": "application workflows we're starting to"
      },
      {
        "start": 606.959,
        "duration": 2.241,
        "text": "map out"
      },
      {
        "start": 607.839,
        "duration": 3.601,
        "text": "what our data model is going to look"
      },
      {
        "start": 609.2,
        "duration": 3.759,
        "text": "like so the next thing i want to do"
      },
      {
        "start": 611.44,
        "duration": 4.32,
        "text": "is now generate some pseudo queries"
      },
      {
        "start": 612.959,
        "duration": 4.721,
        "text": "based off of that so query one here"
      },
      {
        "start": 615.76,
        "duration": 3.12,
        "text": "find comments posted for a user with a"
      },
      {
        "start": 617.68,
        "duration": 4.24,
        "text": "known id"
      },
      {
        "start": 618.88,
        "duration": 4.56,
        "text": "right so by some id i want the comments"
      },
      {
        "start": 621.92,
        "duration": 2.24,
        "text": "now if you look in the right hand side"
      },
      {
        "start": 623.44,
        "duration": 2.16,
        "text": "you're going to see"
      },
      {
        "start": 624.16,
        "duration": 4.4,
        "text": "this little kind of pseudo table"
      },
      {
        "start": 625.6,
        "duration": 6.16,
        "text": "comments by user so in cassandra"
      },
      {
        "start": 628.56,
        "duration": 6.719,
        "text": "the convention we use for a table name"
      },
      {
        "start": 631.76,
        "duration": 6.079,
        "text": "is whatever whatever the payload is"
      },
      {
        "start": 635.279,
        "duration": 4.321,
        "text": "by whatever i'm partitioning by so i"
      },
      {
        "start": 637.839,
        "duration": 3.521,
        "text": "want comments partitioned by"
      },
      {
        "start": 639.6,
        "duration": 3.28,
        "text": "user that's what we're saying comments"
      },
      {
        "start": 641.36,
        "duration": 4.32,
        "text": "partitioned by user"
      },
      {
        "start": 642.88,
        "duration": 3.6,
        "text": "and query2 there again i want to find"
      },
      {
        "start": 645.68,
        "duration": 4.0,
        "text": "comments for a"
      },
      {
        "start": 646.48,
        "duration": 5.359,
        "text": "video with a known id same deal"
      },
      {
        "start": 649.68,
        "duration": 3.44,
        "text": "comments by video i want comments"
      },
      {
        "start": 651.839,
        "duration": 3.44,
        "text": "partitioned by"
      },
      {
        "start": 653.12,
        "duration": 4.159,
        "text": "video and both of them if you know to"
      },
      {
        "start": 655.279,
        "duration": 3.521,
        "text": "say show most recent first going back to"
      },
      {
        "start": 657.279,
        "duration": 3.841,
        "text": "that kind of thing where i want them in"
      },
      {
        "start": 658.8,
        "duration": 4.96,
        "text": "time order that's what that means"
      },
      {
        "start": 661.12,
        "duration": 4.32,
        "text": "now i can take this and i can start"
      },
      {
        "start": 663.76,
        "duration": 4.56,
        "text": "generating my queries"
      },
      {
        "start": 665.44,
        "duration": 4.0,
        "text": "check this out so i'm essentially saying"
      },
      {
        "start": 668.32,
        "duration": 3.44,
        "text": "get all the columns"
      },
      {
        "start": 669.44,
        "duration": 3.6,
        "text": "so select star get all the columns from"
      },
      {
        "start": 671.76,
        "duration": 4.8,
        "text": "comments by user"
      },
      {
        "start": 673.04,
        "duration": 6.4,
        "text": "where the user id is some id that's it"
      },
      {
        "start": 676.56,
        "duration": 4.16,
        "text": "that's uber simple that query alone once"
      },
      {
        "start": 679.44,
        "duration": 3.6,
        "text": "you start to see that the"
      },
      {
        "start": 680.72,
        "duration": 4.08,
        "text": "the tables we're going to use that will"
      },
      {
        "start": 683.04,
        "duration": 4.479,
        "text": "get me all of the comments per"
      },
      {
        "start": 684.8,
        "duration": 3.52,
        "text": "a particular user now if you look at the"
      },
      {
        "start": 687.519,
        "duration": 2.801,
        "text": "second one there"
      },
      {
        "start": 688.32,
        "duration": 4.079,
        "text": "again i want to select all the common"
      },
      {
        "start": 690.32,
        "duration": 5.12,
        "text": "all the columns that's what that star is"
      },
      {
        "start": 692.399,
        "duration": 4.161,
        "text": "from my comments by video so i want all"
      },
      {
        "start": 695.44,
        "duration": 3.92,
        "text": "the comments by video"
      },
      {
        "start": 696.56,
        "duration": 4.48,
        "text": "or video id is again some id this is"
      },
      {
        "start": 699.36,
        "duration": 4.24,
        "text": "going to be the id of the video"
      },
      {
        "start": 701.04,
        "duration": 4.08,
        "text": "that will give me all of the comments"
      },
      {
        "start": 703.6,
        "duration": 4.239,
        "text": "for a video"
      },
      {
        "start": 705.12,
        "duration": 3.839,
        "text": "so you notice we haven't even applied"
      },
      {
        "start": 707.839,
        "duration": 2.321,
        "text": "any data yet"
      },
      {
        "start": 708.959,
        "duration": 3.281,
        "text": "we literally just started with our"
      },
      {
        "start": 710.16,
        "duration": 3.44,
        "text": "application workflows in our entity"
      },
      {
        "start": 712.24,
        "duration": 3.039,
        "text": "relationship diagram and we're just"
      },
      {
        "start": 713.6,
        "duration": 3.359,
        "text": "starting to map this out and we can"
      },
      {
        "start": 715.279,
        "duration": 3.521,
        "text": "already generate some of the queries"
      },
      {
        "start": 716.959,
        "duration": 3.361,
        "text": "that we're going to use"
      },
      {
        "start": 718.8,
        "duration": 3.52,
        "text": "okay so let's take a look at what this"
      },
      {
        "start": 720.32,
        "duration": 4.4,
        "text": "looks like when you start bringing in"
      },
      {
        "start": 722.32,
        "duration": 5.04,
        "text": "to the logical data model so if you"
      },
      {
        "start": 724.72,
        "duration": 4.16,
        "text": "notice here i have our two tables again"
      },
      {
        "start": 727.36,
        "duration": 3.599,
        "text": "now let's start on the left with"
      },
      {
        "start": 728.88,
        "duration": 3.759,
        "text": "comments by user and see that we have"
      },
      {
        "start": 730.959,
        "duration": 4.081,
        "text": "user id"
      },
      {
        "start": 732.639,
        "duration": 3.521,
        "text": "so user id that k that k means it's a"
      },
      {
        "start": 735.04,
        "duration": 2.32,
        "text": "partition key"
      },
      {
        "start": 736.16,
        "duration": 2.56,
        "text": "so if you remember from the previous"
      },
      {
        "start": 737.36,
        "duration": 3.279,
        "text": "section we talked about some of the"
      },
      {
        "start": 738.72,
        "duration": 4.48,
        "text": "components of the primary key"
      },
      {
        "start": 740.639,
        "duration": 3.841,
        "text": "are the partition key and or clustering"
      },
      {
        "start": 743.2,
        "duration": 4.079,
        "text": "columns k"
      },
      {
        "start": 744.48,
        "duration": 4.56,
        "text": "means partition key the c there you see"
      },
      {
        "start": 747.279,
        "duration": 3.68,
        "text": "with the arrow means clustering column"
      },
      {
        "start": 749.04,
        "duration": 4.08,
        "text": "the arrow means the order"
      },
      {
        "start": 750.959,
        "duration": 3.761,
        "text": "so what we're saying here is with user"
      },
      {
        "start": 753.12,
        "duration": 2.56,
        "text": "id i want to again this is the comments"
      },
      {
        "start": 754.72,
        "duration": 3.919,
        "text": "by user table"
      },
      {
        "start": 755.68,
        "duration": 4.32,
        "text": "so i'm partitioning by user so i am"
      },
      {
        "start": 758.639,
        "duration": 4.241,
        "text": "partitioning by user id"
      },
      {
        "start": 760.0,
        "duration": 4.8,
        "text": "and then i'm ordering on creation date"
      },
      {
        "start": 762.88,
        "duration": 4.24,
        "text": "and comment id there you see that"
      },
      {
        "start": 764.8,
        "duration": 3.279,
        "text": "notice the arrow for creation date is"
      },
      {
        "start": 767.12,
        "duration": 2.959,
        "text": "down i'm saying"
      },
      {
        "start": 768.079,
        "duration": 3.841,
        "text": "it's descending right what's that going"
      },
      {
        "start": 770.079,
        "duration": 3.2,
        "text": "to do for me well that means it's going"
      },
      {
        "start": 771.92,
        "duration": 2.96,
        "text": "to show them in descending order so i'm"
      },
      {
        "start": 773.279,
        "duration": 3.521,
        "text": "going to see the most recent first right"
      },
      {
        "start": 774.88,
        "duration": 3.6,
        "text": "so if i just select star from this table"
      },
      {
        "start": 776.8,
        "duration": 3.2,
        "text": "with no other constraint i'm immediately"
      },
      {
        "start": 778.48,
        "duration": 3.039,
        "text": "going to get the very latest comments in"
      },
      {
        "start": 780.0,
        "duration": 3.04,
        "text": "descending order"
      },
      {
        "start": 781.519,
        "duration": 4.401,
        "text": "and then the rest of the information is"
      },
      {
        "start": 783.04,
        "duration": 4.0,
        "text": "just my payload so video id and comment"
      },
      {
        "start": 785.92,
        "duration": 2.08,
        "text": "if you take a look on the right hand"
      },
      {
        "start": 787.04,
        "duration": 2.799,
        "text": "side"
      },
      {
        "start": 788.0,
        "duration": 3.839,
        "text": "comments by video is essentially the"
      },
      {
        "start": 789.839,
        "duration": 4.161,
        "text": "same thing the only difference is i'm"
      },
      {
        "start": 791.839,
        "duration": 4.401,
        "text": "now partitioning by the video id"
      },
      {
        "start": 794.0,
        "duration": 3.2,
        "text": "and in my payload i have the user id and"
      },
      {
        "start": 796.24,
        "duration": 3.36,
        "text": "comment instead of"
      },
      {
        "start": 797.2,
        "duration": 3.12,
        "text": "the video id and comment now you might"
      },
      {
        "start": 799.6,
        "duration": 3.84,
        "text": "notice here"
      },
      {
        "start": 800.32,
        "duration": 5.36,
        "text": "i'm repeating some data yes right it's"
      },
      {
        "start": 803.44,
        "duration": 3.199,
        "text": "denormalized and again like we said"
      },
      {
        "start": 805.68,
        "duration": 3.92,
        "text": "before"
      },
      {
        "start": 806.639,
        "duration": 4.0,
        "text": "in cassandra we use a denormalized data"
      },
      {
        "start": 809.6,
        "duration": 2.88,
        "text": "model that's why"
      },
      {
        "start": 810.639,
        "duration": 3.681,
        "text": "you know we do that again for read we"
      },
      {
        "start": 812.48,
        "duration": 3.919,
        "text": "optimize read performance so what this"
      },
      {
        "start": 814.32,
        "duration": 4.56,
        "text": "means is in each one of these cases"
      },
      {
        "start": 816.399,
        "duration": 3.361,
        "text": "i can then do a single read to get all"
      },
      {
        "start": 818.88,
        "duration": 4.319,
        "text": "the data back"
      },
      {
        "start": 819.76,
        "duration": 4.8,
        "text": "for the question that i have okay so now"
      },
      {
        "start": 823.199,
        "duration": 3.041,
        "text": "this is starting to map out our logical"
      },
      {
        "start": 824.56,
        "duration": 3.279,
        "text": "data model let's move over to the"
      },
      {
        "start": 826.24,
        "duration": 3.599,
        "text": "physical data model so i want you to see"
      },
      {
        "start": 827.839,
        "duration": 4.081,
        "text": "something that just happened here"
      },
      {
        "start": 829.839,
        "duration": 3.201,
        "text": "i'm going to go back notice creation"
      },
      {
        "start": 831.92,
        "duration": 4.159,
        "text": "date and common id"
      },
      {
        "start": 833.04,
        "duration": 5.919,
        "text": "i want you to watch what happens oh"
      },
      {
        "start": 836.079,
        "duration": 4.721,
        "text": "i lost a column what happened well now"
      },
      {
        "start": 838.959,
        "duration": 3.041,
        "text": "as i start to map out my types and"
      },
      {
        "start": 840.8,
        "duration": 3.039,
        "text": "everything as part of the physical"
      },
      {
        "start": 842.0,
        "duration": 3.6,
        "text": "data model so you see that user id has a"
      },
      {
        "start": 843.839,
        "duration": 4.0,
        "text": "uuid i'll talk about that in a moment"
      },
      {
        "start": 845.6,
        "duration": 4.239,
        "text": "what i want you to notice is comment id"
      },
      {
        "start": 847.839,
        "duration": 5.44,
        "text": "then got collapsed down to a time"
      },
      {
        "start": 849.839,
        "duration": 4.721,
        "text": "uuid what happened there well i used to"
      },
      {
        "start": 853.279,
        "duration": 2.401,
        "text": "have two columns creation date and"
      },
      {
        "start": 854.56,
        "duration": 3.519,
        "text": "comment id"
      },
      {
        "start": 855.68,
        "duration": 4.159,
        "text": "and as part of going into my physical"
      },
      {
        "start": 858.079,
        "duration": 2.801,
        "text": "data model there's an optimization that"
      },
      {
        "start": 859.839,
        "duration": 3.201,
        "text": "we performed"
      },
      {
        "start": 860.88,
        "duration": 3.12,
        "text": "i just encapsulated those down into a"
      },
      {
        "start": 863.04,
        "duration": 3.52,
        "text": "single type"
      },
      {
        "start": 864.0,
        "duration": 4.72,
        "text": "a single field common id a time uuid is"
      },
      {
        "start": 866.56,
        "duration": 3.519,
        "text": "a combination of a time stamp and a uuid"
      },
      {
        "start": 868.72,
        "duration": 2.96,
        "text": "that you can put in a single field it's"
      },
      {
        "start": 870.079,
        "duration": 4.481,
        "text": "a nice optimized type of field"
      },
      {
        "start": 871.68,
        "duration": 4.88,
        "text": "for cassandra now to be sure if i"
      },
      {
        "start": 874.56,
        "duration": 4.48,
        "text": "implement my data model like this"
      },
      {
        "start": 876.56,
        "duration": 3.839,
        "text": "would there be any problem no right i'm"
      },
      {
        "start": 879.04,
        "duration": 1.919,
        "text": "going to use a little bit more space and"
      },
      {
        "start": 880.399,
        "duration": 2.161,
        "text": "such but"
      },
      {
        "start": 880.959,
        "duration": 3.761,
        "text": "you know it's it's not that big of a"
      },
      {
        "start": 882.56,
        "duration": 3.519,
        "text": "deal so it's just an optimization you"
      },
      {
        "start": 884.72,
        "duration": 1.919,
        "text": "don't have to do it but i just want to"
      },
      {
        "start": 886.079,
        "duration": 2.641,
        "text": "give you a"
      },
      {
        "start": 886.639,
        "duration": 3.361,
        "text": "feel for the types of things you might"
      },
      {
        "start": 888.72,
        "duration": 2.96,
        "text": "optimize when you're moving from your"
      },
      {
        "start": 890.0,
        "duration": 2.959,
        "text": "logical data model into your physical"
      },
      {
        "start": 891.68,
        "duration": 4.08,
        "text": "data model"
      },
      {
        "start": 892.959,
        "duration": 3.761,
        "text": "so now i've got my user id is a uuid my"
      },
      {
        "start": 895.76,
        "duration": 3.759,
        "text": "common id"
      },
      {
        "start": 896.72,
        "duration": 3.919,
        "text": "is a time stamp and a uuid so you know"
      },
      {
        "start": 899.519,
        "duration": 3.361,
        "text": "combining both"
      },
      {
        "start": 900.639,
        "duration": 4.64,
        "text": "created at and common id into one field"
      },
      {
        "start": 902.88,
        "duration": 4.48,
        "text": "my video id is also ueid and then"
      },
      {
        "start": 905.279,
        "duration": 4.321,
        "text": "comment here being text"
      },
      {
        "start": 907.36,
        "duration": 3.039,
        "text": "now the next step is to map this to"
      },
      {
        "start": 909.6,
        "duration": 2.479,
        "text": "tables"
      },
      {
        "start": 910.399,
        "duration": 3.201,
        "text": "i mean it goes that quick actually once"
      },
      {
        "start": 912.079,
        "duration": 3.041,
        "text": "you get used to this pattern"
      },
      {
        "start": 913.6,
        "duration": 3.52,
        "text": "it's it's actually pretty it's pretty"
      },
      {
        "start": 915.12,
        "duration": 3.44,
        "text": "straightforward so notice here"
      },
      {
        "start": 917.12,
        "duration": 3.36,
        "text": "um if you're familiar with sql this"
      },
      {
        "start": 918.56,
        "duration": 4.639,
        "text": "should look familiar this is cql"
      },
      {
        "start": 920.48,
        "duration": 3.76,
        "text": "cql is a subset of sql um it looks very"
      },
      {
        "start": 923.199,
        "duration": 2.481,
        "text": "familiar to it"
      },
      {
        "start": 924.24,
        "duration": 3.36,
        "text": "but you'll notice my create table i have"
      },
      {
        "start": 925.68,
        "duration": 4.159,
        "text": "create table if not exists"
      },
      {
        "start": 927.6,
        "duration": 4.4,
        "text": "my table name comments by user i have a"
      },
      {
        "start": 929.839,
        "duration": 4.401,
        "text": "set of my fields there are types"
      },
      {
        "start": 932.0,
        "duration": 3.279,
        "text": "and then notice my primary key if you"
      },
      {
        "start": 934.24,
        "duration": 3.599,
        "text": "remember"
      },
      {
        "start": 935.279,
        "duration": 4.24,
        "text": "we designated a partition key with k so"
      },
      {
        "start": 937.839,
        "duration": 2.641,
        "text": "my primary key that first field with the"
      },
      {
        "start": 939.519,
        "duration": 3.68,
        "text": "friends again"
      },
      {
        "start": 940.48,
        "duration": 4.96,
        "text": "i have user id comma and then my common"
      },
      {
        "start": 943.199,
        "duration": 5.041,
        "text": "id is going to be my clustering column"
      },
      {
        "start": 945.44,
        "duration": 4.399,
        "text": "and notice that with clustering order"
      },
      {
        "start": 948.24,
        "duration": 2.399,
        "text": "that clustering order by comment id"
      },
      {
        "start": 949.839,
        "duration": 2.961,
        "text": "descending we're"
      },
      {
        "start": 950.639,
        "duration": 3.76,
        "text": "saying i want it descending order that"
      },
      {
        "start": 952.8,
        "duration": 4.479,
        "text": "way later on"
      },
      {
        "start": 954.399,
        "duration": 4.721,
        "text": "when i read this data out i do not need"
      },
      {
        "start": 957.279,
        "duration": 3.521,
        "text": "to do an order by i do not need to pay"
      },
      {
        "start": 959.12,
        "duration": 5.279,
        "text": "the cost of an ordering"
      },
      {
        "start": 960.8,
        "duration": 6.719,
        "text": "uh an order at read it is actually being"
      },
      {
        "start": 964.399,
        "duration": 4.321,
        "text": "saved in order on disk so when i go to"
      },
      {
        "start": 967.519,
        "duration": 3.361,
        "text": "retrieve it later not"
      },
      {
        "start": 968.72,
        "duration": 4.479,
        "text": "only do i get everything in one"
      },
      {
        "start": 970.88,
        "duration": 4.639,
        "text": "partition by that one"
      },
      {
        "start": 973.199,
        "duration": 4.721,
        "text": "user id but it's already in time ordered"
      },
      {
        "start": 975.519,
        "duration": 3.521,
        "text": "format so this is all optimized for your"
      },
      {
        "start": 977.92,
        "duration": 3.68,
        "text": "read performance"
      },
      {
        "start": 979.04,
        "duration": 4.719,
        "text": "at scale right and again this is whether"
      },
      {
        "start": 981.6,
        "duration": 3.84,
        "text": "it's three nodes or thousands of nodes"
      },
      {
        "start": 983.759,
        "duration": 3.601,
        "text": "to ensure that you can maintain your"
      },
      {
        "start": 985.44,
        "duration": 4.399,
        "text": "tight slas at any scale"
      },
      {
        "start": 987.36,
        "duration": 4.0,
        "text": "with cassandra okay so that's the that's"
      },
      {
        "start": 989.839,
        "duration": 2.8,
        "text": "the overall process that's it you can"
      },
      {
        "start": 991.36,
        "duration": 2.479,
        "text": "start with your application workflows"
      },
      {
        "start": 992.639,
        "duration": 3.2,
        "text": "you work those out"
      },
      {
        "start": 993.839,
        "duration": 3.761,
        "text": "you use those to generate your pseudo"
      },
      {
        "start": 995.839,
        "duration": 3.12,
        "text": "queries your pseudo tables you start to"
      },
      {
        "start": 997.6,
        "duration": 3.599,
        "text": "then just refine"
      },
      {
        "start": 998.959,
        "duration": 3.761,
        "text": "and notice because in a denormalized"
      },
      {
        "start": 1001.199,
        "duration": 2.961,
        "text": "data model we don't have all the joins"
      },
      {
        "start": 1002.72,
        "duration": 3.76,
        "text": "and everything the queries are actually"
      },
      {
        "start": 1004.16,
        "duration": 3.84,
        "text": "extremely simple and so you can take"
      },
      {
        "start": 1006.48,
        "duration": 3.279,
        "text": "that to just generate your queries"
      },
      {
        "start": 1008.0,
        "duration": 2.56,
        "text": "matter of fact the general idea is query"
      },
      {
        "start": 1009.759,
        "duration": 3.52,
        "text": "per table"
      },
      {
        "start": 1010.56,
        "duration": 4.32,
        "text": "right one query per one table um and"
      },
      {
        "start": 1013.279,
        "duration": 3.761,
        "text": "you'll be off to a good start"
      },
      {
        "start": 1014.88,
        "duration": 3.44,
        "text": "okay so thanks so much let's go ahead"
      },
      {
        "start": 1017.04,
        "duration": 4.96,
        "text": "and get into an exercise"
      },
      {
        "start": 1018.32,
        "duration": 3.68,
        "text": "and kind of reinforce some of what you"
      },
      {
        "start": 1022.839,
        "duration": 4.84,
        "text": "learned"
      },
      {
        "start": 1025.6,
        "duration": 2.079,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T20:43:12.423421+00:00"
}