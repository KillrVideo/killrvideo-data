{
  "video_id": "b8N1f8jdDio",
  "title": "Building an Open Source RAG Application Using LlamaIndex",
  "description": "DataStax and LlamaIndex come together to talk about the challenges of bringing an LLM application to production! We saw from OpenAI Dev Day that Retrieval Augmented Generation has become table stakes in building an AI LLM application.\n\nIn this hands-on workshop hosted by Patrick McFadin, VP of Developer Relations at DataStax and Yi Ding, Head of Typescript and Partnerships at LlamaIndex, we’ll show you how Datastax built a knowledge retrieval chatbot in production using LlamaIndex. \n\nDuring the webinar, you'll discover:\n\n--How to extend code, which is entirely open source, for your needs.\n--Why enterprises would want to build their own RAG pipeline.\n--Hot takes on commercially available RAG in box solutions.\n\nResources featured:\nGithub: https://github.com/datastax/ai-chatbot-starter\nAstra sign up: https://astra.datastax.com/signup\nTalk with us/Samay: https://talkwith.us/samay\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2023-12-01T03:40:38Z",
  "thumbnail": "https://i.ytimg.com/vi/b8N1f8jdDio/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "workshop",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "talk",
    "astra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=b8N1f8jdDio",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "hi ye hi Patrick it's a long time I haven't seen you in so long let's let's get this party started um and uh I should bring up my screen let's do that and here we go oh God I'm gonna I'm gonna share this but I should probably share this instead all right all right Let's uh this is not what I wanted to do present interview hold on there we go there we go I think we're just gonna go with this right now um so welcome everyone uh this is um yeah I want to make sure everyone sees my complete screen right but um ye and I are going to be talking about building an open source rag application using llama index so yeah did you get any sleep ye about four hours last night four hours yeah so yeah we were talking just before this uh ye's got a 15 or 16mon old it at that point you're counting months right and there's just no sleep in your house is there absolutely yeah but thanks for having having me Patrick really looking forward to this absolutely um so we're let's let's do some intros here okay um so I'm y I'm the head of typescript and Partnerships at llama index prior to llama index I worked at Apple um we started a team called um messaging apps and so we actually buil chat bots so we build chat Bots for WeChat and there's this thing called Apple business chat um it's actually on every single iPhone um and prior to that I actually spent some time in algorithmic trading so I had a couple firms uh Geto and cadel I think you know the thing for me about LS right the reason why after uh seven years at Apple I said okay you know I GNA change is because it's like one of only two times in my career where everything I was working on is now obsolete like the chat bot that we had built um you know we had fairly large teams of people we had you know obviously quite talented folks in the ml space we had um you know lots you know years of customer chat data to go through and it was like you know if you look at it now it looks like a it was built by a 10-year-old right it looks like you know now that you've used chat gbt you compare these you know and not just ours right like you know you go on Comcast or you go on Best Buy and you chat talk to their chat bot it feels like literally these things were just completely um completely almost juvenile in how much capability they have compared to chat um the only other time that's happened to me in my career was when the iPhone launched I was at this company called pong and uh sorry I was intern yeah I was an intern and uh I I I talked to my team I'm like oh yeah there's this rumor that Apple's going to come out with a phone and they said oh no don't worry about it there's a rumor every year that Apple's going to come out with a phone and yeah totally obsolete so I think it's really exciting um LMS are really exciting I think all applications are going to use LS in some capacity in the next five years and I'm really glad all of you are here yeah well and yeah it's it's funny we um so I'm Patrick mcfaden um uh some of you probably already know who I am if you you're because you're at a dat sex event but um just so if you don't um my this is my quick like all about me thing and um I'm a Apache cassander committer um I work at data stack um Cal Poly engineer for those out there you know he went to Cal not Cal paully so you didn't finish the job man um also just released a book earlier this year uh running managing Cloud native data on kubernetes um there's a section on there running AI workloads inside of kubernetes if you're um looking for something to read is you know the end of the year it's a great read and so I would recommend it right away and um you can use my LinkedIn I'd love to connect with you on LinkedIn um funny thing between you and I we've had so many intersections throughout the world ye was interning at a company that I was doing contract work with and the original.com boom that's a funny story but we won't tell it now save it for another time oh yeah mistakes were made made um but anyway uh we're really happy you're here ye I'm happy you're here um I don't know about Michelle who's watching us but um but we're gonna have fun today we're gonna learn a lot um and those of you that are out there uh you know the uh if you want to introduce yourself in the in the chat that'd be great you know we're creating a network of people here so let's do this so let's get this party started so we're gonna start with a bit of a setup because this is Workshop it'll be Hands-On uh we're going to do the let's get things going you can see my tabs here we might have some stuff to do so we will um but first and foremost and this is something ye and I talked about yesterday let's make sure everybody is on the same page um I think this is our Safe Harbor statement is we all know that you're stressed out feeling behind and having has a a boss that says we need an AI like yesterday right um it's okay okay you want to add to that I literally started doing this stuff this year so I know exactly what that feels like that's right that's right we're all learning as fast as possible and it's changing as you'll find out in this hilarious Workshop stuff changed like yesterday and we're trying to keep up with it so this is a continuous effort don't stop learning don't stop asking questions don't stop it'll be great but also Share work together um we're all working on this together so let's do this uh so what we're doing today is we're we're going to build uh this it's a it's a chatbot application and it really what it it's actually is used in production at data Stacks um and it has Integrations with intercom if you use that slack and it also has an API base as well um so the the whole idea and what we're trying to accomplish is just giving you the tools to do rag without having to build it from scratch but there's a lot of things that you can and there's a lot of modifications things like that so we're going to walk through the steps so first things first uh we have a GitHub for you to look at so this AI chatbot starter if you want to take a look go go over to that repo right now um and I think we should probably put this in um Michelle can you can you put that in the chat I forgot to copy and paste it um but uh we're gonna I'm going to walk through these real real quick and this is just the getting started and you can start working on that and then um ye's gonna do a bit of a dive on what rag is so you know this is just to kind of get things going because we're doing a workshop this is Hands-On use your hands um and if you're on an iPhone and you're on a bus don't worry about it so let's switch screens here so what I'm going to do is I'm I'm going to switch over to this is the the repo that um you should see now um there's a couple of things you can do um but the one that you really want to probably do now is opening git pod now git pod is if you've never used it before it's pretty sweet because what it does is it creates a cloud a uh a cloud IDE for you and lets you run your code inside the ID it's just like having it on your desktop it's super cool um now if you want to uh clone it to a local directory and run it you know with your own ID that's cool um but this is if you want to get things going so um I have done that oh here's my oh boy you know what I shouldn't have done started working on the Version Control um this is this is what uh git pod looks like now I've done a lot of work it gives you a terminal and there are a few files in here that are pretty important the the one that we're going to do is there's aemv file that needs to be created by you because if you've done anything with Gen you know that you got to start collecting keys right generating and collecting Keys um and there are two that you need to do uh first is you need to have an astb API at point so just kind of give you the setup um astb is going to be providing the vector store for our chatbot and then open AI is going to be providing the embeddings uh support so those are your two pieces here so um and all these keys on here as soon as this Workshop is over I'm going to go and validate all of them so don't think you're gonna go hack my system um yeah ye is that you on my oh man so I'm going to walk you through real quick on getting you signed in here now uh this experience if you have not been on Astra in any like in the last week um things have changed um and I'm gonna thanks Octor um we have this new Vector developer experience when you log in right now uh you should click this button right now and I'm going to do it enable preview what this does is it radically changes the way the interface looks for using a vector database and uh I've already created one you can when you go to create a database it's very simple you give it a name a provider a country um there's only us e one if you're do on the free tier and um if you give us a credit card then you can open up to the whole world there's probably like 38 different places you could put your database but because we're doing this here I I've already created one earlier and as soon as you create this you get a couple of things you're going to need for the for the chatbot first is going to be the AI endpoint and you can just click the copy right here and then you take it over to your environment uh in N file and you copy that right or paste it right here and the second thing you'll need is the token and you can quickly generate a token and you can copy it and when you're done paste it right here done now open AI I like I said you probably have done this 100 times but if not not uh you can create a free account on open AI uh get the open API Keys you can create a new key I have this AI chatbot test again I'll be invalidating that shortly um and when you create it copy it immediately because you can never get it back after that um and when you get it paste it here um you can put in a a name for your table which this is cool it will create it for you in this app so just give it a name without any can't put any hyphens in it I know I've got burned on that a couple of times that's just not a legal thing um then you put your open AI API key this is your setup so we're gonna stop there and get this part done while we're talking um and then later we're going to walk through the actual running and have some fun with actually doing some chat stuff so let's move on to the next piece here so yeah I'm gonna let you go and take it from here okay um so yeah so just quick quick quick inro to to rag um yeah uh we we can go we can just go to the next one so LS are great at communicating and reasoning right um what they're kind of bad at is knowing things especially you know if it's things that are very recent or it's things that are private to your organization and that's really what retrieval augmented generation of it is about um if you go to next slide you know like retrieval argument to generation when I first thought heard that is like you know it's three very long words I kind of know what they mean but I totally had no idea what they meant put together it's really simple actually it's just about searching for the information that you need giving the data to the L and then getting the best response back out from the LM so in fact you can even think about it like you know when you're talking to somebody right like when Patrick and I are having a conversation we're each doing retrieval argument to generation I'm giving him some context and then because he has yeah I mean it's it's it's literally just like a conversation if and the more relevant the context is the um the better the results and that's a very very important thing to remember when you're building a rag system so if we go to the next slide I can show you some examples of um of rag so actually I just saw Sam here he's a college student over at Oregon State and he built this cool thing it's open source um Patrick you can just click on the first one first link oh can I oh I gotta actually click on the link hang here we go yeah so um and you can do talk with what am I open way hopefully open ke still works and yeah we can just do this first thing like tell me about somebody's education J just let's try it oh okay well we could do this okay yeah we're GNA we're going embarrass him if uh if his keys revoked or something but we'll see we'll see what happens okay and then just hit send um that's funny that this is this is what he's asking let's let's find all about semi yeah exactly well we we'll see I the okay it looks like it looks like there's there's an issue with vuum key I'm gonna try it again yeah no I I so so may if you want to fix this in the next two minutes I know you're online so um but you can look at the code what it does is it actually does retrieval augmented generation it takes information from SM and um and uh that he's given the bot and then it finds the most relevant pieces from that information and then it actually goes and uh and answers your question in a more useful manner because you know open AI does not know about this individual um anyways check it out check it it's completely open source um you can build your own version but they done a great job with UI we just got to fix that opening I ke I think okay so so so next next slide we can go um another type of rag that you you all might be familiar with is um called search engine rag right so basically if you use Google bard if you use Bing I think they're raming it the Bing co-pilot now if you use chat gbt with browser the couple startups perplexity metaphor um what they do is they once again get contextual information to hear from the internet right so they're searching for information on the internet they get the most relevant information and then they give it to the model but once again here's the most important thing you have to give it the right context so I tried it right so chat with browsing I think I think it's enable for everybody or you might have to pay for a pro version um let's see let's see what happened we'll go to the next slide there oh yeah this looks familiar yeah so so so so so ask the question what what 2022 movie won the Oscars right it's 20123 now obviously chat gbt doesn't know um what the uh what movie won the Oscars at the time because it had um a knowledge cut off so it says okay I'm going to search for it right right so it says oh the movie Kota won best picture at the Oscars in 2022 which is correct and then I said well you know is Kota a what year did it come out and it says oh it's released in 2021 so is it actually a 2022 movie and then they're like no it's not right and then I say okay well then tell me what 2022 movie came out in uh one of the Oscars and it says well actually I don't have that information which is true it doesn't have that information because to get that information it would have had to retrieve right the search part it would have had to retrieve the information about the 2023 Oscars which had already happened at this time this was this is not a gimmick it actually you know it could have retrieved that through browsing but because of the way it was searching it did not retrieve the right information and therefore it doesn't have it um so when you build your R system this is very very important to think about so if we go to next slide it's really the same principle that we talk about a lot garbage in garbage out right if you you have to make sure that you're retrieving the right information and we'll talk about some techniques later on about how to tune what you're retrieving um final thing next slide you know I think there's um oftentimes a large variety of different um different people you know different skill levels that's totally okay like like I said I I only started using LMS this year right um but one thing that you can try really easily is uh Jerry Built This cool Stream app it's an agent that builds a rag system for you right should you use it in production no you should use what Patrick's going to show you can you use it to can you use it to try it out and to um you know see see how rag Works absolutely so yeah I encourage you guys to try out literally two weeks ago and uh 4,000 get up s so yeah pass it back to you Patrick yeah that's pretty impressive 4,000 GitHub stars um yeah and you know it's interesting I was I kind of have my own thing in there about the rag you know the thing we were talking about yesterday is this I think the interesting part of of llms are that they are you know they compress knowledge into the statistical likelihood of the next answer right so like if you ask it what's four plus 4 statistically the correct answer is eight it's not actually doing math and that's terrifying in some ways because you don't know what I mean you're basically rolling the dice right um might as well go to Vegas and play the tables um yeah that's interesting all right so let's get this chatbot working and um Jameson I heard you we're gonna zoom in here hopefully this doesn't like zoom in everything so we're gonna see how this works okay so I think it's the command plus oh look look all right look at that I gotta resize everything now okay um if I can get a thumbs up on that is this a good good zoom in level or more um so we're gonna get this working and what that means is actually creating uh creating some Vector data and then actually querying it so there's a couple of Parts here now what I I'm happy is the read me is very solid um the getting started portion of this I covered this a little bit u in the beginning where I'm like go collect all your keys um the other thing of course is to run the the PIP install requirements.txt and you'll see it install the library so once you get into that Baseline where you're like okay I have all the libraries installed I have mymv file done the next step is to work on your config file now you don't need to come up with one right away way um there's this example data Stacks config.yml file um and this has a pretty reasonable it's just um going through so what I'll just kind of walk through a little bit um it's using uh various libraries like this example response to De cider these are all parts of this this application um the llm provider open AI um and then it it goes into more of the like the the data this so like um ye was talking about instead of letting the llm tell us what's in the doc so this what this is supposed to do is essentially um act as a document chatbot right and um the the idea is that we need data that is real and not just like compressed into an llm somewhere if you went to go ask an llm about Cassandra it might give you some good answers but what we want is we want the exact answer and this example what it does is it goes through just some example doc pages that we have and the the doc pages are the source of Truth so essentially we're gonna have the um we're gonna have this app read the docs so this is the rtfm doc rtfm app and then it will after it reads the docs it will use the docs to give you a correct answer when you ask a question so um again if you use intercom on our data STX Astra this is actually code that's being used there now so um it's pretty cool and so there's a few things here like first of all it's the custom rules um and this is uh I'm gonna go over to our config.yml um we had fun with it yesterday um so you can copy the the example into the config.yml file create a new one and just use the defaults now later if you want to have fun create your own config gaml maybe on your own docs and that and start exploring your own documentation or use it on your own site this is an open source project go for it um and with incommon slack integration it's really cool so there's some some custom rules so if the user refers to database assume they're assuming Cassandra that's a common that's a common thing if you ask Chad gbt about hey how do I create a data model for Cassandra for this use case it might Veer off and start giving you different kinds of data modeling advice that may not have anything to do with Cass so we're just going to be very specific about this this is that prompting techniques you're a pred engineer after you figure this out um and like the question is not explicit related to cassander data STX or data STX product or migrating you always say I'm sorry I only answer questions related to cassander data sex products so it's it's giving the uh it's the reasoning part of the llm um some sort of instructions about what to do what if it can't find the answer which is great because most times uh chat gbt he will give you a very confident incorrect answer um this in this case it'll just say I don't know that's what you wanted to do um you could read through the rest yourself but this is where you put in those things kind of create boundaries and guard rails around what the question and answer in the chat box going to be and then um ye and I were having fun yesterday and we and oh by the way Talk Like a Pirate um um you know that that you know that could be your use case I don't know um maybe and uh the the other thing that's really critical is this a list of the the HTML pages to to go through so this is just a subset of our docs um like for instance the storage attach indexes uh which are an indexing mechanism have a go do that okay so that is our config gaml file um we should probably double click on this Talk Like a Pirate real quick um that today will not work in the current code am I right e uh that's correct but but I'm gonna have a PR to make that work well I already have a PR so you have a PR yeah yeah yeah and and I think you know just to keep people online um ye will explain why in just a minute so there you go so you better explain why and welcome to the world of LM um okay so what do we do once we have this config file there are two steps that we're going to do um so I'll go back to the readme it's all in the readme so once you get everything set up with the config file there are two steps um that you need to create the embeddings now when I look at my time my database um I need to make this work and so when we when we go through the actual setup there are two parts there there's whenever I look at my documentation when I have this this app look at the documentation what it's doing is it's reading the text and then it creates the vector embeddings and those Vector embeddings need to be stored inside the system inside this Vector database and then that will be used for the chatbot later um and you will show like where this where this comes in and the actual rag portion the the um retrieval augmented so what's the what are we retrieving well this is where we're going to do and by the way this is one of the super cool parts of this new UI you can actually look at the data that's in there and uh whenever I create these embeddings and I'll I'll walk through it real quick um what it's doing is it's creating a vector so here's this massive number and but what it's doing is it's actually creating it on real content and so it's taking the docs that are in these HTML pages chunking chunking it up into usable pieces creating a vector embedding using open AI putting that embedding into the database along with metadata and it's things like here's the file path and here's the actual content so that whenever we're searching um we have all the base information that created this Vector embedding but the vector embedding is used in an approximate nearest neighbor search and that's that's the real Secret Sauce to building a rag application is having it having this data available in a way that is usable by the library so when llama index is like hey the user asked this question what's close to it this is this is how that gets done all right so when you look at this um you see that there's a ton of data in here uh there's 10,088 records how did I create that I'm glad you ask ye um the first thing you have to do is you have to scrape the site so if I if I run this Command right here what it'll do is it'll go through the list in the config gaml file and it will what it'll do is dump the text version of the HTML into the docs directory so if you go into the data uhds you'll see that it is created a ton of this is uh with the HTML stripped out so for instance um like here's about SII uh zero copy of streaming index these are all the words that were in the documentation how to configure it um these are important this is how this is some of that pre-training cleanup that needs to be done um you don't want to have a bunch of useless HTML tags in your embedding data because no one cares if there was a P tag on there um that's that's part of that cleanup so what this process does is it goes out grabs the HTML cleans out the HTML and uh cleans off the HTML and just turns it into the raw data and that gets dumped into a directory so after I'll go back to my read me how's everyone doing so far is there got any questions so far oh interesting will the data Explorer navigate to all PDF files uh no and but you can use uh there's a search mechanisms inside here where you can do some metadata filtering um there's there's a lot to go here this is not meant to be a um a dive into this and it's actually probably a a good reason to do it but we should create some content about just how to use this particular interface but that's a good question there's limited search fun functionality uh but it is not meant to replace a a li a full Library like llama index it's just there to like explore your data and see what's in there um but that's great question uh thanks Wayne um so another question from Albert saying do we need to copy your astv values or create our own tables create your own tables thank you for asking that question um the uh yes the you w to and this is a good point too you when this is something we talked about like that privacy aspect you don't want to just throw your data into chat GPT for instance and expect privacy um it especially in regulated environments uh if you're in finance healthare that sort of thing you want to have your own database with your own key um probably a good time to mention that Astra is uh it's got all the tickets PCI Hippa um all those things that will make your life a lot easier when you're working in regulated environments all right um let's move along I I see more questions but we can pick those up I just want to make sure we get to your part ye and then we can we'll answer questions towards the end as well um these are great though keep them coming we'll get to you all right so uh when I'm when I'm running when I run this file go back to this right here uh when I do the compil documents what what actually I'm gonna just go ahead and run it real quick um actually should I run it probably not um when I run the compil documents um because it'll take a while uh I and I saw a question is like what embeddings do you are we using in this case it's the open AI Ada embedding um you could and this is another topic worth diving into a lot there are a lot of embeddings a lot of folks are talking about E5 is a cool kid um I don't know ye do you what's your favorite embedding [Laughter] ye you're on mute still oh sorry um I was yeah so over open AI I definitely start with open Ai and then um you know coher has put out some cool embeddings um coher V3 it's a little bit different because the query and the and the answer need to be embedded using different settings um and then there's lots of lots of embeddings on the leaderboard um but the reason why I would suggest starting with openi embeddings is because um with opening ey edings like so many people are using them that your behavior is going to be relatively predictable um if you look at the hugging face leaderboard there's actually lots of Open Source models they're great but you really should test them yourself on your own data right yeah so so yeah um but you know open source Community is fantastic and we love them um but you should you should definitely test it yourself because the benchmarks are synthetic so the performance may or may not be what you need for your application yeah that again this is like we're creating we're creating need for new content out of this particular Workshop I mean just picking embeddings is is a somewhat it's a use case dependent almost like a data modeling exercise in a lot of ways um and you got to think about like what are you trying to accomplish with your embedding is it text is it images what mode of data is it multimodal Etc so um we're gonna um if you noticed I started this uh started the thing I'm going to kill it um but right now what it's actually doing is um going through all the text chunking it going to open AI running up my bill right now and um it's creating the embeddings and then dropping those into Astra so I think this takes a second but um you'll start seeing these pop up on here shortly it'll it'll start saying oh yeah here here comes all your here comes all your data uh there's a bit of a lag and like let's see last five minutes there we go um when it shows up we'll go back over there and check it out but um yeah so the the idea right now is it's just creating all the embeddings so I'm gonna go and kill this right now control c ah okay sorry um and I'm gonna start I'm gonna start the UI portion of this now there is a UI that um that is basic is well the UI is using a python script if you don't have intercom or slack um I think one of the things we were talking about is adding an actual like a maybe a react or something nextjs UI to it um slack and intercom were the first use cases but this is gonna grow as we go along if you want to contribute that's an awesome contribution and I would love to promote it um yeah if you build something I will get you in a workshop and we'll talk about it how about that that's that's you too all right so I'm gonna start oh so the what this is this back end is it we'll start up and essentially what it's doing is is it's creating this uh the back end um go away um I'm creating a backend that will allow a front end to interact and do the this is where the rag stuff starts to happen so LL index is really involved in there it's interacting with Astra on the back end Etc now I'm going to create another terminal here and I'm going to try python script so uh this you can just copy and paste this and actually put a real query in here um one of the things I don't like about G pod is you can't use the arrow key uh but that's okay it's like we're terminal from 1999 um so what like what is s because that's the data that I put in there and it should give me an answer back and after you's finished um then it'll say it like a pirate which I think is so much cooler when you're when you're interacting with docs it'll be like Si say m um but yeah this is a it never I mean if I came up to you and say what's SII and you didn't know what it was you may hallucinate but in this case it actually pulled the information from the docs and uh did a pretty good pretty good answer because this is right out of the about and it gave me the exact answer okay uh ye I think we need to move on to the next portion of this oops awesome um yeah and just to answer a couple questions come can you touch on structured versus unstructured data sources we have a whole bunch of different loaders for different types of data in llama index that is definitely one of those things um that's quite important is how you get the data into a format that's optimal for LS um as Patrick has shown you know he's um you know in this example already they have uh some of this processing already and then um limit on how big the knowledge base can be there is no limit but but as you get more data there are more advanced strategies so so that kind of that goes in quite well I think into this sort of like next piece of diving into llama index so so we can start the first slide um this in itself could be an hour right so we going to talk about two two things production Rag and LM quirks right so if you want to use lm's and you're a developer like I'm a developer I'm not scientist right um and this is sort of first time really you want to be thinking about these things like you know like first off like how do I get this thing production this is why I'm so excited about what dat STX is built is because they are they they're using this in production so you can see what the production code looks like um and it's open source um so so we'll talk a little bit about some of the production rack strategies we have in index um if we go to the next slide here so there you go um so this the example I highly recommend you look at it it's open source so you can change it right you can customiz and that is the number one thing when you're building a production rag production rag pipeline a production rag application is thinking about how and tuning how the data your data is working with that system so data STX has done a lot of tuning to make sure that it works well with their system um we we also have an example this is a different type of example it's SEC insights similar idea you know how can we tune it properly for this particular type of document source which in this case is SEC vales so if we go to the next slide I'll show you a couple of things that we have and one is this thing called sub question query engine um this is in in llama index um there there are equivalent things in other um other Frameworks also but the idea is to do question de decomposition so when a question comes in not all questions are created equal right when a question comes in especially when you have large volumes of data you need to think what document do I actually want this um this question to go to so for example right like if you're if you're doing an doing a sec filings application like we were doing what you don't want to do is you don't want to pull the financial data for Microsoft when they're asking about apple right so um if you go to SEC and I don't think we're going to have time today to actually play around with it but if you go you'll see this sub question decomposition in action right if if somebody's asking you to compare two things right like compare the revenue of Microsoft versus Apple then you really want to decompose it into two questions um to say okay um is Microsoft um you know what's the revenue of Microsoft what's the revenue of apple and then combine them together so um this decomposition and the sort of categorization of your question is very very useful um sub question query engine is what we use in SEC insites and um there's actually a whole host of strategies in this area so so this is like sort of like one one production rack strategy I'm going to go try talk about another one in the next slide I think it's the next slide yes okay so the next the other strategy that I would yes some techn no your slides um so the next the next strategy is like small to big right so so let's back up a second real quick right so what are embeddings embeddings are like Patrick was mentioning these lists of numbers that correspond to a specific piece of text so that sounds pretty easy right you just take the text you chunk you chop it up and then you just send it to the embeddings and you're done except except okay opening eyes and beddings are 1,000 536 floating Point numbers right there's really no way it's it's really a black box like there's no way for me to go into the 1,536 and double check their Mark like like oh yeah this this one need to be a little higher that one needs to be a little lower does not work like that right um so what is it actually doing what is the model actually doing um it's a blackbox but if you look at the literature around natural language processing basically you can think of a few different things this doing one is actually keywords so you're like oh well you know ining search it's also called semantic so it's about semantic meeting yes so semantic meeting is the second one but why why would keywords even be involved because if you don't have like useful keywords if like especially rare keywords then you're not going to get good search results like um so so rare keywords are is one of them um semantic mean intention like what's the intention of the text um another one that for sure is in there in that mix is synonyms right so this is this is the place where like embedding search becomes magical this is like why you you know you think okay well I'm not just going to use like you know Google Search right like Google search has been around for 20 years right I'm not going to use like BM 2.5 to you know just do keyword search on my data because when embedding search is working it's like it can find relationships between things that keyword search just can't find or you have to like have a huge synonym table or you have to you know you have to do like a bunch of manual special casing with hortic all which Google does by the way Google and Bing all do this um but embedding search just does that for you in an automatic way um so but now let's think about this a little bit so you have this thing that's trying to capture the meaning right it's trying to capture like like unique keywords it's trying to capture a meaning it's trying to capture like synonyms for those meanings then figuring out what to embed what chunk of text to embed becomes really important because if your chunks of text are not are too big right they're too big then what happens is that meaning becomes sort of diluted right like all your embeddings when when you actually look at the thing they start becoming the same like they're all very very similar because you know you have like this big chunk of text in you know over the entire file um the meaning becomes very diluted if you think about it then the smallest chunks of text have the most concentrated meaning however however there's a limit right so what what is the sort of like the smallest chunk of text that has the most concentrated meaning but still has has a coherent meaning right you don't want to get to the word because the word itself is not a coherent intention um so you think it's a sentence and that's true oh oh sorry no worries it's a sentence right so um and that's where you know the smallest chunk of text is so so we're going to try that so I wrote a couple sentences I I think it's the next slide we'll see I I got we're gonna find out we're gonna find out right so oh no the next slide sorry so small to big embed small retrieve big that's the strategy we're GNA use and here's why okay so so so we'll go to next I'll show you ESRB are you making word I'm calling it small to big on Twitter but I'm like maybe maybe maybe we should call it the esrv strategy yeah I think everyone that's watching should shime in here so yeah we'll just Outsource this right now we'll go to the next slide but if you have an idea throw it in the chat because clearly year needs it ye needs his Workshop yes okay so so here here here's our text right fairly straightforward Patrick mcon is software engineer and VP of development relations he started with d STX in 2012 previously M worked at Hopson as their Chief Architect okay very very simple straightforward three sentences and then we have the query where does Patrick mum work I incourage you to try this out using as okay like literally you know you know Patrick is showing you you have to do like all these embs These are three embeddings like literally three vectors and then you add one more Vector for the qu um so Patrick tell a guess which sentence like if we've eded each sentence which sentence do you think would uh would the embedding model say is the most uh nearest neighbor the the the most relevant uh probably the second one because second right right he he started with with data Stacks in 2012 that makes the most sense that's the one that you we care about I have to say Patrick you're wrong um why I was so close why I had a 5050 chance so so we go I'll show you I'll show you what the actual answer is all right all right here we go the right answer is it's probably it's probably the third one okay and and why why is that um because mcfaden is not a very common word no right and so the second sentence which has the right information in it does not have the word mcfaden in it right so the model even though once again is a black box um it is not um it's not going to prefer that second sentence um in fact it's going to prefer if you go to the next slide it's going to prefer the first and third sentences these are the sentences that's probably going to pick out with the top of two so here this is this is where it becomes very important right so obviously you like okay well we just embed more right we just embed the whole thing right we can embed the whole thing but then once again the the embedding becomes diluted so if you want the most concentrated embeddings but you still want to get the relevant information you have to use this embed small retrieve big strategy and we found in production with other people that it really does work um so we have two built-in modules in L Index this is something that we are actively doing so if we go to next slide you check out one is one is called I was gonna say that's a really interesting I I never thought about like names being triggers for bad a&n searches but that's so true yeah because you're like well why you know this this is stupider than we thought right but it's not because if you think about it like what if it went and you know because he said does this blah blah blah what if it goes and picks up another sentence from like you know somebody else's bio right that you put in your database right doing picking out the ones the sentences of MC feden is actually the safe smart thing to do um but it does not give you the full context that you need so so that's that's where we have the notes on this window window strategy um we have another one if you go to next slide uh similar idea it's called the autom mering Retriever and similar idea is like basically hey you know if you're retrieving a bunch of small chunks and like we see that you're retrieving all of these then we're just going to combine it so you also get the you know if you're retrieving the first second and fourth sentences we're going to give you the third sentence also in the retrieval because it's probably important even though the even though the embedding model doesn't think it's that close so if we go to the next slide here okay so this this is the other thing that you have to be aware of um you know p patj and I are old techies so we remember qus mode right so you have Netscape Navigator here this is iie I think this is I4 right classic classic I4 good old days right and uh and and you know the painful thing of having to make sure to support these browsers for years and years later um so so the web development Community came up with this idea of corks mode right um why because when these browsers came out they were you know very rough right like the the their treatment of HTML of of JavaScript of CSS was all very very rough um similarly right now since we are very very early literally very very early if we go to the next slide um we are in LM quirks mode like literally these things you know open Ai and propic llama 2 like they've come out literally months ago right opening I just announced four turbo like I don't know like less than a month ago and fra came out with quad 2.1 I think like two weeks ago lamu has been around for like four or five months they have a lot of quirks um once again this is a whole presentation but I'm just going to show you a couple quirks real real real simple so qu number one um what does decreasing temperature do in and out okay I'm not going to this shouldn't be too too embarrassing uh what what does decreasing top PE do in LM Patrick do do you know the the first one decreasing temperature what happens if you turn down the temperature uh you get a a less spec well you get less spicy answers you get more generalized answers right you get less spicy answers it becomes less random right I'm using the word spicy in a very technical way yes yeah the technical word spicy decreasing top p in an LM does the same thing it also makes the um it also makes the answers less random and if we go to the third question all right what does decrease in top K do in an L I'm gonna tell you it does exactly the same thing it makes the answers less random so this is how we know we're in quirks mode right because you think you know your software product engineer been doing this for a while why do we have three knobs that do basically the same thing well because it's these things were built by product Engineers they're built by mathematicians right so the mathematicians said well you know each of these things does a different thing mathematically which is true which is true but from from from you know a developer from a software developer who just wants to get something to work it's kind of annoying that we have three knobs that do very very similar things so if we go to next slide um related right so often times when we deal with computers right we want the computer to return the same thing to us every time this is this you know I've been programming as a software developer for 20 years I want to make sure everything's reproducible right you know you don't want to have like these bugs that come in like you know only when the customer is you know in you know on vacation in the Japan or you know like you want things to do the same thing every time and with lm's you want the same result every time so what do we do well the sort of if we go to next Slide the sort of very classic thing is to set the temperature to zero right because like we said we decrease the temperature knob you turn it down um it becomes less random if you turn it down all the way to zero then that's as low as you can turn it right pretty boring yeah so does that work well next slide let's see no it doesn't so um AMJ last year you know was like yeah no even at temperature zero it does not actually give deterministic output okay um so this is this is one of the things that you have to deal with as an engineer as an AI engineer so next slide but wait there's more okay so not only so okay you're like well maybe maybe it's okay because you know temp zero does make it more deterministic it's just not entirely deterministic right you know you might get like four or five different answers instead of you know a million different answers so but there's actually there's actually a bigger problem with temp z um so if we go to next slide temp zero makes the model Dumber um this is well documented and for a long time like even even in the AI hacking Community we weren't sure why um but then I came came grab this paper uh written by this guy hugging face so the next slide um so so he wrote this paper and he basically said look you know what happens when you make temp equals zero is the search becomes a greedy search and it always picks the absolute most probable next token but that inhibits the L's ability to look ahead several tokens and find the token that's like you know the the tokens that are like three tokens deep that are actually more probable than just the absolute next token you and yeah it's interesting because I this particular thing I remember somebody giving me a really good analogy about is like um early chess programs like way back in the day they were as good as how many moves that they tried to do ahead right yeah if you had a chess program that was on your like your old Apple 2 it would do like three or four moves ahead and that's it and you know it wasn't very it wasn't forward-looking but as computers got more powerful it would look hundreds or thousands of moves ahead and predict like create this prediction tree and say oh this is the best path based on all the different permutations and I I thought that was really interesting because it is just like that right that is exactly what the Alum is doing but it also so um it's also doing because there's so many choices right because unlike chess right because chest this tree is relative I mean it's still a very large tree don't get get me wrong but it's relatively narrow in lm's case at every token there's literally tens of thousands hundreds of thousands of choices um LMS can perform their smartness by doing it probabilistically right but when you set temp to zero you take away that probabilistic ability and then it then just says okay well I'm just going to give you the the the absolute most probable one so so they do a sample so so they they they sampled the distribution and temperature so this is where the math comes and temperature technically is is actually cont controlling the shape of that probability distribution um so so yeah so so there are many many many quirks out there for LMS so soort of where I wanted to leave you all at is if we go to the next slide is that one day there will be standards mode right like I said I believe that one day most programs if not all programs are going to use l in some capacity one day they will work um in a very predictable way but next slide that's not today right so one of the questions why do you want to use llama index next slide you can let us deal with the qus instead of having to deal with them yourself so yeah that's that's the end of uh my section I see a couple of questions is here yeah let's let's uh we're we're kind of at the top of the hour actually totally are at the top of the hour um I think now let's just jump into some questions there's some really good ones on here um and SE didn't have a question he he has a bug report for us uh back online yes yes good job yes so try try it out and and more importantly look at the source code because they did a great job oh man I gotta go back find that what was the what was the URL hang on talk with us hang on let me let me talk withs yeah hold on hold on your next job S is to build it with Astro yeah come on S then you'll get the monitoring that will tell you like hey the qu aren coming in what's going on all right here we are we're doing this again we're doing it live sem okay here we [Music] go look at this speeds up retrieval too look at that see well done all right um okay so so Ursa has a good question here says uh how do we assess quality are there are there metrics Pat Patrick I'll let you take that first and we can talk a little bit about some things we we looked at also well with a&n searches you do get a a score for the retrieval and that's something that's really like it's interesting because with Vector search we in database world we we looked we always talk about two things which is latency and um throughput you know those are those are quality metrics of your database transactions but um now it's relevance and is a third thing and the relevance score is really critical because um and what you're doing is you're saying hey I here's a thing find the things that are close to it and the algorithm is able to say an approximate nearest neighbor algorithm is able to say here's how close it is and so um and it'll be a zero to one number so you'll get like a seven well that's like a 70% match right um and it's up to you and so uh Ursula when when I think of quality and what's the metrics you know it's up to you but like maybe you want the highest quality so you want closer to like 85 to 90% or better uh on your retrievals so that you just won't use an answer then this where may this where might come in where you say hey if it's less than a 90% then just say I don't know like that that just straight up say that and that's kind of how most humans work although not all the time Some Humans make up answers but and then Jameson Jameson had had a similar one which is like you know like if you have similar queries that are coming in that are slightly different one of the things I absolutely encourage you to do is check to see look at look at the embeddings you're getting back right and then if the embeddings are not similar ask yourself why right look at the look at what's coming back from the vector DB and look at your embeddings yeah yeah that's those are really critical things um in the Q&A um there is uh harp as ask this question I'm going to I'm going to give it to you um because this is right in your thing so he says ye the example you mentioned regarding Patrick's dat is since the model searching from the Corpus and it will look for the word work so ideally it should give the second sentence but the ideal the IDE ideally it should give the second sent was the ideal first aners how do you fix that yeah I small B small small small to big absolutely because because there's there's or or you just say you know I'm just going to do bigger chunks I I think Patrick yeah everybody's disconnected so uh oh I think we're oh it shut down yeah so wow it cut us off that went by fast Patrick it was fun it did go by fast yeah we're no longer live are we guess so yeah okay so we'll say something yeah Yep looks like looks like our hour is up you want to do you want to put your uh please uh get in touch with us do you want to put your LinkedIn in there and then yeah I will I will wow we just got shut down man the trains got to run on time all right d this is fun I'm I'm glad we did this boy opened up like 800 more doors um yeah the application working which one um yeah okay all right see you later thanks a lot thanks all right bye bye",
    "segments": [
      {
        "start": 3.12,
        "duration": 4.239,
        "text": "hi"
      },
      {
        "start": 4.12,
        "duration": 5.76,
        "text": "ye hi Patrick it's a long time I haven't"
      },
      {
        "start": 7.359,
        "duration": 6.28,
        "text": "seen you in so long let's let's get this"
      },
      {
        "start": 9.88,
        "duration": 8.92,
        "text": "party started um and uh I should bring"
      },
      {
        "start": 13.639,
        "duration": 8.681,
        "text": "up my screen let's do that and here we"
      },
      {
        "start": 18.8,
        "duration": 6.84,
        "text": "go oh God I'm gonna I'm gonna share this"
      },
      {
        "start": 22.32,
        "duration": 3.32,
        "text": "but I should probably share this"
      },
      {
        "start": 25.8,
        "duration": 5.479,
        "text": "instead all right all"
      },
      {
        "start": 28.96,
        "duration": 5.2,
        "text": "right"
      },
      {
        "start": 31.279,
        "duration": 4.001,
        "text": "Let's uh this is not what I wanted to do"
      },
      {
        "start": 34.16,
        "duration": 6.28,
        "text": "present"
      },
      {
        "start": 35.28,
        "duration": 5.16,
        "text": "interview hold on there we go there we"
      },
      {
        "start": 40.719,
        "duration": 6.761,
        "text": "go I think we're just gonna go with this"
      },
      {
        "start": 43.039,
        "duration": 7.52,
        "text": "right now um so welcome everyone uh this"
      },
      {
        "start": 47.48,
        "duration": 5.16,
        "text": "is um yeah I want to make sure everyone"
      },
      {
        "start": 50.559,
        "duration": 5.361,
        "text": "sees my complete screen"
      },
      {
        "start": 52.64,
        "duration": 4.599,
        "text": "right but um ye and I are going to be"
      },
      {
        "start": 55.92,
        "duration": 5.279,
        "text": "talking about building an open source"
      },
      {
        "start": 57.239,
        "duration": 7.081,
        "text": "rag application using llama index so"
      },
      {
        "start": 61.199,
        "duration": 6.24,
        "text": "yeah did you get any sleep"
      },
      {
        "start": 64.32,
        "duration": 5.479,
        "text": "ye about four hours last night four"
      },
      {
        "start": 67.439,
        "duration": 5.281,
        "text": "hours yeah so yeah we were talking just"
      },
      {
        "start": 69.799,
        "duration": 4.761,
        "text": "before this uh ye's got a 15 or 16mon"
      },
      {
        "start": 72.72,
        "duration": 3.84,
        "text": "old it at that point you're counting"
      },
      {
        "start": 74.56,
        "duration": 4.72,
        "text": "months right and there's just no sleep"
      },
      {
        "start": 76.56,
        "duration": 5.64,
        "text": "in your house is there"
      },
      {
        "start": 79.28,
        "duration": 4.28,
        "text": "absolutely yeah but thanks for having"
      },
      {
        "start": 82.2,
        "duration": 4.84,
        "text": "having me"
      },
      {
        "start": 83.56,
        "duration": 6.12,
        "text": "Patrick really looking forward to this"
      },
      {
        "start": 87.04,
        "duration": 5.16,
        "text": "absolutely um so we're let's let's do"
      },
      {
        "start": 89.68,
        "duration": 6.52,
        "text": "some intros"
      },
      {
        "start": 92.2,
        "duration": 6.0,
        "text": "here okay um so I'm y I'm the head of"
      },
      {
        "start": 96.2,
        "duration": 5.36,
        "text": "typescript and Partnerships at llama"
      },
      {
        "start": 98.2,
        "duration": 7.68,
        "text": "index prior to llama index I worked at"
      },
      {
        "start": 101.56,
        "duration": 6.839,
        "text": "Apple um we started a team called um"
      },
      {
        "start": 105.88,
        "duration": 4.68,
        "text": "messaging apps and so we actually buil"
      },
      {
        "start": 108.399,
        "duration": 3.441,
        "text": "chat bots so we build chat Bots for"
      },
      {
        "start": 110.56,
        "duration": 2.519,
        "text": "WeChat and there's this thing called"
      },
      {
        "start": 111.84,
        "duration": 4.319,
        "text": "Apple business"
      },
      {
        "start": 113.079,
        "duration": 5.64,
        "text": "chat um it's actually on every single"
      },
      {
        "start": 116.159,
        "duration": 4.56,
        "text": "iPhone um and prior to that I actually"
      },
      {
        "start": 118.719,
        "duration": 4.561,
        "text": "spent some time in algorithmic trading"
      },
      {
        "start": 120.719,
        "duration": 6.641,
        "text": "so I had a couple firms uh Geto and"
      },
      {
        "start": 123.28,
        "duration": 8.88,
        "text": "cadel I think you know the thing for me"
      },
      {
        "start": 127.36,
        "duration": 6.599,
        "text": "about LS right the reason why after uh"
      },
      {
        "start": 132.16,
        "duration": 5.159,
        "text": "seven years at Apple I said okay you"
      },
      {
        "start": 133.959,
        "duration": 6.401,
        "text": "know I GNA change is because it's like"
      },
      {
        "start": 137.319,
        "duration": 6.081,
        "text": "one of only two times in my career where"
      },
      {
        "start": 140.36,
        "duration": 5.84,
        "text": "everything I was working on is now"
      },
      {
        "start": 143.4,
        "duration": 7.199,
        "text": "obsolete like the chat bot that we had"
      },
      {
        "start": 146.2,
        "duration": 6.28,
        "text": "built um you know we had fairly large"
      },
      {
        "start": 150.599,
        "duration": 5.561,
        "text": "teams of people we had you know"
      },
      {
        "start": 152.48,
        "duration": 8.16,
        "text": "obviously quite talented folks in the ml"
      },
      {
        "start": 156.16,
        "duration": 7.64,
        "text": "space we had um you know lots you know"
      },
      {
        "start": 160.64,
        "duration": 7.959,
        "text": "years of customer chat data to go"
      },
      {
        "start": 163.8,
        "duration": 7.159,
        "text": "through and it was like you know if you"
      },
      {
        "start": 168.599,
        "duration": 5.481,
        "text": "look at it now it looks like a it was"
      },
      {
        "start": 170.959,
        "duration": 5.441,
        "text": "built by a 10-year-old right it looks"
      },
      {
        "start": 174.08,
        "duration": 4.72,
        "text": "like you know now that you've used chat"
      },
      {
        "start": 176.4,
        "duration": 3.759,
        "text": "gbt you compare these you know and not"
      },
      {
        "start": 178.8,
        "duration": 3.84,
        "text": "just ours right like you know you go on"
      },
      {
        "start": 180.159,
        "duration": 4.481,
        "text": "Comcast or you go on Best Buy and you"
      },
      {
        "start": 182.64,
        "duration": 5.959,
        "text": "chat talk to their chat bot it feels"
      },
      {
        "start": 184.64,
        "duration": 5.519,
        "text": "like literally these things were just"
      },
      {
        "start": 188.599,
        "duration": 5.481,
        "text": "completely"
      },
      {
        "start": 190.159,
        "duration": 6.0,
        "text": "um completely almost juvenile in how"
      },
      {
        "start": 194.08,
        "duration": 4.239,
        "text": "much capability they have compared to"
      },
      {
        "start": 196.159,
        "duration": 4.041,
        "text": "chat um the only other time that's"
      },
      {
        "start": 198.319,
        "duration": 4.2,
        "text": "happened to me in my career was when the"
      },
      {
        "start": 200.2,
        "duration": 4.72,
        "text": "iPhone launched I was at this company"
      },
      {
        "start": 202.519,
        "duration": 6.161,
        "text": "called pong and"
      },
      {
        "start": 204.92,
        "duration": 6.44,
        "text": "uh sorry I was intern yeah I was an"
      },
      {
        "start": 208.68,
        "duration": 3.96,
        "text": "intern and uh I I I talked to my team"
      },
      {
        "start": 211.36,
        "duration": 2.4,
        "text": "I'm like oh yeah there's this rumor that"
      },
      {
        "start": 212.64,
        "duration": 2.679,
        "text": "Apple's going to come out with a phone"
      },
      {
        "start": 213.76,
        "duration": 2.839,
        "text": "and they said oh no don't worry about it"
      },
      {
        "start": 215.319,
        "duration": 3.601,
        "text": "there's a rumor every year that Apple's"
      },
      {
        "start": 216.599,
        "duration": 4.441,
        "text": "going to come out with a phone and yeah"
      },
      {
        "start": 218.92,
        "duration": 4.2,
        "text": "totally obsolete so I think it's really"
      },
      {
        "start": 221.04,
        "duration": 3.759,
        "text": "exciting um LMS are really exciting I"
      },
      {
        "start": 223.12,
        "duration": 3.88,
        "text": "think all applications are going to use"
      },
      {
        "start": 224.799,
        "duration": 4.401,
        "text": "LS in some capacity in the next five"
      },
      {
        "start": 227.0,
        "duration": 5.68,
        "text": "years and I'm really glad all of you are"
      },
      {
        "start": 229.2,
        "duration": 7.759,
        "text": "here yeah well and yeah it's it's funny"
      },
      {
        "start": 232.68,
        "duration": 5.8,
        "text": "we um so I'm Patrick mcfaden um uh some"
      },
      {
        "start": 236.959,
        "duration": 3.321,
        "text": "of you probably already know who I am if"
      },
      {
        "start": 238.48,
        "duration": 5.479,
        "text": "you you're because you're at a dat sex"
      },
      {
        "start": 240.28,
        "duration": 6.239,
        "text": "event but um just so if you don't um my"
      },
      {
        "start": 243.959,
        "duration": 5.761,
        "text": "this is my quick like all about me thing"
      },
      {
        "start": 246.519,
        "duration": 5.36,
        "text": "and um I'm a Apache cassander committer"
      },
      {
        "start": 249.72,
        "duration": 4.439,
        "text": "um I work at data stack um Cal Poly"
      },
      {
        "start": 251.879,
        "duration": 4.801,
        "text": "engineer for those out there you know he"
      },
      {
        "start": 254.159,
        "duration": 3.881,
        "text": "went to Cal not Cal paully so you didn't"
      },
      {
        "start": 256.68,
        "duration": 4.239,
        "text": "finish the job"
      },
      {
        "start": 258.04,
        "duration": 4.56,
        "text": "man um also just released a book earlier"
      },
      {
        "start": 260.919,
        "duration": 3.881,
        "text": "this year uh running managing Cloud"
      },
      {
        "start": 262.6,
        "duration": 4.72,
        "text": "native data on kubernetes um there's a"
      },
      {
        "start": 264.8,
        "duration": 5.119,
        "text": "section on there running AI workloads"
      },
      {
        "start": 267.32,
        "duration": 4.48,
        "text": "inside of kubernetes if you're um"
      },
      {
        "start": 269.919,
        "duration": 3.481,
        "text": "looking for something to read is you"
      },
      {
        "start": 271.8,
        "duration": 4.119,
        "text": "know the end of the year it's a great"
      },
      {
        "start": 273.4,
        "duration": 5.6,
        "text": "read and so I would recommend it right"
      },
      {
        "start": 275.919,
        "duration": 5.601,
        "text": "away and um you can use my LinkedIn I'd"
      },
      {
        "start": 279.0,
        "duration": 4.6,
        "text": "love to connect with you on LinkedIn um"
      },
      {
        "start": 281.52,
        "duration": 4.239,
        "text": "funny thing between you and I we've had"
      },
      {
        "start": 283.6,
        "duration": 4.76,
        "text": "so many intersections throughout the"
      },
      {
        "start": 285.759,
        "duration": 4.521,
        "text": "world ye was interning at a company that"
      },
      {
        "start": 288.36,
        "duration": 5.04,
        "text": "I was doing contract work with and the"
      },
      {
        "start": 290.28,
        "duration": 5.8,
        "text": "original.com boom that's a funny story"
      },
      {
        "start": 293.4,
        "duration": 5.519,
        "text": "but we won't tell it"
      },
      {
        "start": 296.08,
        "duration": 7.0,
        "text": "now save it for another time oh yeah"
      },
      {
        "start": 298.919,
        "duration": 6.361,
        "text": "mistakes were made made um but anyway uh"
      },
      {
        "start": 303.08,
        "duration": 3.959,
        "text": "we're really happy you're here ye I'm"
      },
      {
        "start": 305.28,
        "duration": 4.12,
        "text": "happy you're here um I don't know about"
      },
      {
        "start": 307.039,
        "duration": 3.641,
        "text": "Michelle who's watching us but um but"
      },
      {
        "start": 309.4,
        "duration": 4.239,
        "text": "we're gonna have fun today we're gonna"
      },
      {
        "start": 310.68,
        "duration": 5.84,
        "text": "learn a lot um and those of you that are"
      },
      {
        "start": 313.639,
        "duration": 5.481,
        "text": "out there uh you know"
      },
      {
        "start": 316.52,
        "duration": 4.36,
        "text": "the uh if you want to introduce yourself"
      },
      {
        "start": 319.12,
        "duration": 3.28,
        "text": "in the in the chat that'd be great you"
      },
      {
        "start": 320.88,
        "duration": 4.56,
        "text": "know we're creating a network of people"
      },
      {
        "start": 322.4,
        "duration": 5.68,
        "text": "here so let's do this so let's get this"
      },
      {
        "start": 325.44,
        "duration": 4.28,
        "text": "party started so we're gonna start with"
      },
      {
        "start": 328.08,
        "duration": 3.76,
        "text": "a bit of a setup because this is"
      },
      {
        "start": 329.72,
        "duration": 4.64,
        "text": "Workshop it'll be Hands-On uh we're"
      },
      {
        "start": 331.84,
        "duration": 4.28,
        "text": "going to do the let's get things going"
      },
      {
        "start": 334.36,
        "duration": 4.399,
        "text": "you can see my tabs here we might have"
      },
      {
        "start": 336.12,
        "duration": 4.199,
        "text": "some stuff to do so we will um but first"
      },
      {
        "start": 338.759,
        "duration": 4.16,
        "text": "and foremost and this is something ye"
      },
      {
        "start": 340.319,
        "duration": 7.521,
        "text": "and I talked about yesterday let's make"
      },
      {
        "start": 342.919,
        "duration": 7.081,
        "text": "sure everybody is on the same page um I"
      },
      {
        "start": 347.84,
        "duration": 4.72,
        "text": "think this is our Safe Harbor statement"
      },
      {
        "start": 350.0,
        "duration": 5.08,
        "text": "is we all know that you're stressed out"
      },
      {
        "start": 352.56,
        "duration": 4.6,
        "text": "feeling behind and having has a a boss"
      },
      {
        "start": 355.08,
        "duration": 5.64,
        "text": "that says we need an AI like yesterday"
      },
      {
        "start": 357.16,
        "duration": 6.56,
        "text": "right um it's okay"
      },
      {
        "start": 360.72,
        "duration": 5.479,
        "text": "okay you want to add to"
      },
      {
        "start": 363.72,
        "duration": 5.039,
        "text": "that I literally started doing this"
      },
      {
        "start": 366.199,
        "duration": 4.961,
        "text": "stuff this year so I know exactly what"
      },
      {
        "start": 368.759,
        "duration": 4.401,
        "text": "that feels like that's right that's"
      },
      {
        "start": 371.16,
        "duration": 3.479,
        "text": "right we're all learning as fast as"
      },
      {
        "start": 373.16,
        "duration": 3.599,
        "text": "possible and it's"
      },
      {
        "start": 374.639,
        "duration": 4.56,
        "text": "changing as you'll find out in this"
      },
      {
        "start": 376.759,
        "duration": 4.521,
        "text": "hilarious Workshop stuff changed like"
      },
      {
        "start": 379.199,
        "duration": 5.681,
        "text": "yesterday and we're trying to keep up"
      },
      {
        "start": 381.28,
        "duration": 6.44,
        "text": "with it so this is a continuous effort"
      },
      {
        "start": 384.88,
        "duration": 6.28,
        "text": "don't stop learning don't stop asking"
      },
      {
        "start": 387.72,
        "duration": 6.44,
        "text": "questions don't stop it'll be great but"
      },
      {
        "start": 391.16,
        "duration": 5.52,
        "text": "also Share work together um we're all"
      },
      {
        "start": 394.16,
        "duration": 5.92,
        "text": "working on this together so let's do"
      },
      {
        "start": 396.68,
        "duration": 6.4,
        "text": "this uh so what we're doing today is"
      },
      {
        "start": 400.08,
        "duration": 5.839,
        "text": "we're we're going to build uh this it's"
      },
      {
        "start": 403.08,
        "duration": 4.839,
        "text": "a it's a chatbot application and it"
      },
      {
        "start": 405.919,
        "duration": 4.921,
        "text": "really what it it's actually is used in"
      },
      {
        "start": 407.919,
        "duration": 4.881,
        "text": "production at data Stacks um and it has"
      },
      {
        "start": 410.84,
        "duration": 5.32,
        "text": "Integrations with intercom if you use"
      },
      {
        "start": 412.8,
        "duration": 6.64,
        "text": "that slack and it also has an API base"
      },
      {
        "start": 416.16,
        "duration": 5.0,
        "text": "as well um so the the whole idea and"
      },
      {
        "start": 419.44,
        "duration": 5.64,
        "text": "what we're trying to accomplish is just"
      },
      {
        "start": 421.16,
        "duration": 6.4,
        "text": "giving you the tools to do rag without"
      },
      {
        "start": 425.08,
        "duration": 3.959,
        "text": "having to build it from scratch but"
      },
      {
        "start": 427.56,
        "duration": 3.079,
        "text": "there's a lot of things that you can and"
      },
      {
        "start": 429.039,
        "duration": 2.961,
        "text": "there's a lot of modifications things"
      },
      {
        "start": 430.639,
        "duration": 5.361,
        "text": "like that so we're going to walk through"
      },
      {
        "start": 432.0,
        "duration": 7.56,
        "text": "the steps so first things first uh we"
      },
      {
        "start": 436.0,
        "duration": 6.639,
        "text": "have a GitHub for you to look at so this"
      },
      {
        "start": 439.56,
        "duration": 6.4,
        "text": "AI chatbot starter if you want to take a"
      },
      {
        "start": 442.639,
        "duration": 5.641,
        "text": "look go go over to that repo right now"
      },
      {
        "start": 445.96,
        "duration": 3.959,
        "text": "um and I think we should probably put"
      },
      {
        "start": 448.28,
        "duration": 3.599,
        "text": "this in"
      },
      {
        "start": 449.919,
        "duration": 4.081,
        "text": "um Michelle can you can you put that in"
      },
      {
        "start": 451.879,
        "duration": 4.961,
        "text": "the chat I forgot to copy and paste it"
      },
      {
        "start": 454.0,
        "duration": 4.879,
        "text": "um but uh we're gonna I'm going to walk"
      },
      {
        "start": 456.84,
        "duration": 3.72,
        "text": "through these real real quick and this"
      },
      {
        "start": 458.879,
        "duration": 4.081,
        "text": "is just the getting started and you can"
      },
      {
        "start": 460.56,
        "duration": 4.56,
        "text": "start working on that and then um ye's"
      },
      {
        "start": 462.96,
        "duration": 4.16,
        "text": "gonna do a bit of a dive on what rag is"
      },
      {
        "start": 465.12,
        "duration": 3.24,
        "text": "so you know this is just to kind of get"
      },
      {
        "start": 467.12,
        "duration": 4.44,
        "text": "things going because we're doing a"
      },
      {
        "start": 468.36,
        "duration": 4.72,
        "text": "workshop this is Hands-On use your hands"
      },
      {
        "start": 471.56,
        "duration": 4.96,
        "text": "um and if you're on an iPhone and you're"
      },
      {
        "start": 473.08,
        "duration": 5.6,
        "text": "on a bus don't worry about it so let's"
      },
      {
        "start": 476.52,
        "duration": 4.28,
        "text": "switch screens here so what I'm going to"
      },
      {
        "start": 478.68,
        "duration": 5.0,
        "text": "do is I'm I'm going to switch over to"
      },
      {
        "start": 480.8,
        "duration": 5.399,
        "text": "this is the the repo that um you should"
      },
      {
        "start": 483.68,
        "duration": 5.44,
        "text": "see now um there's a couple of things"
      },
      {
        "start": 486.199,
        "duration": 5.081,
        "text": "you can do um but the one that you"
      },
      {
        "start": 489.12,
        "duration": 5.32,
        "text": "really want to probably do now is"
      },
      {
        "start": 491.28,
        "duration": 5.039,
        "text": "opening git pod now git pod is if you've"
      },
      {
        "start": 494.44,
        "duration": 4.24,
        "text": "never used it before it's pretty sweet"
      },
      {
        "start": 496.319,
        "duration": 7.241,
        "text": "because what it does is it creates a"
      },
      {
        "start": 498.68,
        "duration": 7.12,
        "text": "cloud a uh a cloud IDE for you and lets"
      },
      {
        "start": 503.56,
        "duration": 4.079,
        "text": "you run your code inside the ID it's"
      },
      {
        "start": 505.8,
        "duration": 4.88,
        "text": "just like having it on your desktop it's"
      },
      {
        "start": 507.639,
        "duration": 5.721,
        "text": "super cool um now if you want to uh"
      },
      {
        "start": 510.68,
        "duration": 5.64,
        "text": "clone it to a local directory and run it"
      },
      {
        "start": 513.36,
        "duration": 4.52,
        "text": "you know with your own ID that's cool um"
      },
      {
        "start": 516.32,
        "duration": 5.36,
        "text": "but this is if you want to get things"
      },
      {
        "start": 517.88,
        "duration": 5.519,
        "text": "going so um I have done that oh here's"
      },
      {
        "start": 521.68,
        "duration": 4.2,
        "text": "my oh boy you know what I shouldn't have"
      },
      {
        "start": 523.399,
        "duration": 6.961,
        "text": "done started working on the Version"
      },
      {
        "start": 525.88,
        "duration": 6.8,
        "text": "Control um this is this is what uh git"
      },
      {
        "start": 530.36,
        "duration": 3.56,
        "text": "pod looks like now I've done a lot of"
      },
      {
        "start": 532.68,
        "duration": 3.96,
        "text": "work it gives you a"
      },
      {
        "start": 533.92,
        "duration": 5.0,
        "text": "terminal and there are a few files in"
      },
      {
        "start": 536.64,
        "duration": 4.68,
        "text": "here that are pretty important the the"
      },
      {
        "start": 538.92,
        "duration": 5.52,
        "text": "one that we're going to do is there's"
      },
      {
        "start": 541.32,
        "duration": 6.4,
        "text": "aemv file that needs to be created by"
      },
      {
        "start": 544.44,
        "duration": 5.2,
        "text": "you because if you've done anything with"
      },
      {
        "start": 547.72,
        "duration": 4.6,
        "text": "Gen you know that you got to start"
      },
      {
        "start": 549.64,
        "duration": 6.52,
        "text": "collecting keys"
      },
      {
        "start": 552.32,
        "duration": 7.48,
        "text": "right generating and collecting Keys um"
      },
      {
        "start": 556.16,
        "duration": 7.0,
        "text": "and there are two that you need to do uh"
      },
      {
        "start": 559.8,
        "duration": 6.039,
        "text": "first is you need to have an astb API at"
      },
      {
        "start": 563.16,
        "duration": 4.76,
        "text": "point so just kind of give you the setup"
      },
      {
        "start": 565.839,
        "duration": 5.44,
        "text": "um astb is going to be providing the"
      },
      {
        "start": 567.92,
        "duration": 5.8,
        "text": "vector store for our chatbot and then"
      },
      {
        "start": 571.279,
        "duration": 5.201,
        "text": "open AI is going to be providing the"
      },
      {
        "start": 573.72,
        "duration": 7.08,
        "text": "embeddings uh support so those are your"
      },
      {
        "start": 576.48,
        "duration": 6.44,
        "text": "two pieces here so um and all these keys"
      },
      {
        "start": 580.8,
        "duration": 3.8,
        "text": "on here as soon as this Workshop is over"
      },
      {
        "start": 582.92,
        "duration": 3.28,
        "text": "I'm going to go and validate all of them"
      },
      {
        "start": 584.6,
        "duration": 7.359,
        "text": "so don't think you're gonna go hack my"
      },
      {
        "start": 586.2,
        "duration": 8.759,
        "text": "system um yeah ye is that you on my"
      },
      {
        "start": 591.959,
        "duration": 3.0,
        "text": "oh"
      },
      {
        "start": 595.72,
        "duration": 5.239,
        "text": "man so I'm going to walk you through"
      },
      {
        "start": 598.64,
        "duration": 6.56,
        "text": "real quick on getting you signed in"
      },
      {
        "start": 600.959,
        "duration": 6.921,
        "text": "here now uh this experience if you have"
      },
      {
        "start": 605.2,
        "duration": 3.52,
        "text": "not been on Astra in any like in the"
      },
      {
        "start": 607.88,
        "duration": 4.72,
        "text": "last"
      },
      {
        "start": 608.72,
        "duration": 7.72,
        "text": "week um things have changed um and I'm"
      },
      {
        "start": 612.6,
        "duration": 5.72,
        "text": "gonna thanks Octor um we have this new"
      },
      {
        "start": 616.44,
        "duration": 5.92,
        "text": "Vector developer experience when you log"
      },
      {
        "start": 618.32,
        "duration": 6.84,
        "text": "in right now uh you should click this"
      },
      {
        "start": 622.36,
        "duration": 5.28,
        "text": "button right now and I'm going to do it"
      },
      {
        "start": 625.16,
        "duration": 4.679,
        "text": "enable preview what this does is it"
      },
      {
        "start": 627.64,
        "duration": 4.6,
        "text": "radically changes the way"
      },
      {
        "start": 629.839,
        "duration": 5.401,
        "text": "the interface looks for using a vector"
      },
      {
        "start": 632.24,
        "duration": 4.92,
        "text": "database and uh I've already created one"
      },
      {
        "start": 635.24,
        "duration": 4.12,
        "text": "you can when you go to create a database"
      },
      {
        "start": 637.16,
        "duration": 5.28,
        "text": "it's very simple you give it a name a"
      },
      {
        "start": 639.36,
        "duration": 6.159,
        "text": "provider a country um there's only us e"
      },
      {
        "start": 642.44,
        "duration": 4.519,
        "text": "one if you're do on the free tier and um"
      },
      {
        "start": 645.519,
        "duration": 2.88,
        "text": "if you give us a credit card then you"
      },
      {
        "start": 646.959,
        "duration": 3.201,
        "text": "can open up to the whole world there's"
      },
      {
        "start": 648.399,
        "duration": 2.801,
        "text": "probably like 38 different places you"
      },
      {
        "start": 650.16,
        "duration": 4.479,
        "text": "could put your"
      },
      {
        "start": 651.2,
        "duration": 6.12,
        "text": "database but because we're doing this"
      },
      {
        "start": 654.639,
        "duration": 4.681,
        "text": "here I I've already created one earlier"
      },
      {
        "start": 657.32,
        "duration": 3.16,
        "text": "and as soon as you create this you get a"
      },
      {
        "start": 659.32,
        "duration": 3.6,
        "text": "couple of things you're going to need"
      },
      {
        "start": 660.48,
        "duration": 4.28,
        "text": "for the for the chatbot first is going"
      },
      {
        "start": 662.92,
        "duration": 4.159,
        "text": "to be the AI endpoint and you can just"
      },
      {
        "start": 664.76,
        "duration": 5.16,
        "text": "click the copy right here and then you"
      },
      {
        "start": 667.079,
        "duration": 5.041,
        "text": "take it over to your environment uh in N"
      },
      {
        "start": 669.92,
        "duration": 4.359,
        "text": "file and you copy that right or paste it"
      },
      {
        "start": 672.12,
        "duration": 4.959,
        "text": "right here and the second thing you'll"
      },
      {
        "start": 674.279,
        "duration": 5.8,
        "text": "need is the token and you can quickly"
      },
      {
        "start": 677.079,
        "duration": 4.041,
        "text": "generate a token and you can copy it and"
      },
      {
        "start": 680.079,
        "duration": 5.281,
        "text": "when you're"
      },
      {
        "start": 681.12,
        "duration": 6.6,
        "text": "done paste it right here done now open"
      },
      {
        "start": 685.36,
        "duration": 5.24,
        "text": "AI I like I said you probably have done"
      },
      {
        "start": 687.72,
        "duration": 5.239,
        "text": "this 100 times but if not not uh you can"
      },
      {
        "start": 690.6,
        "duration": 4.64,
        "text": "create a free account on open AI uh get"
      },
      {
        "start": 692.959,
        "duration": 5.0,
        "text": "the open API Keys you can create a new"
      },
      {
        "start": 695.24,
        "duration": 5.839,
        "text": "key I have this AI chatbot test again"
      },
      {
        "start": 697.959,
        "duration": 5.161,
        "text": "I'll be invalidating that shortly um and"
      },
      {
        "start": 701.079,
        "duration": 3.801,
        "text": "when you create it copy it immediately"
      },
      {
        "start": 703.12,
        "duration": 4.719,
        "text": "because you can never get it back after"
      },
      {
        "start": 704.88,
        "duration": 7.24,
        "text": "that um and when you get it paste it"
      },
      {
        "start": 707.839,
        "duration": 7.12,
        "text": "here um you can put in a a name for your"
      },
      {
        "start": 712.12,
        "duration": 5.12,
        "text": "table which this is cool it will create"
      },
      {
        "start": 714.959,
        "duration": 4.601,
        "text": "it for you in this app so just give it a"
      },
      {
        "start": 717.24,
        "duration": 4.039,
        "text": "name without any can't put any hyphens"
      },
      {
        "start": 719.56,
        "duration": 3.279,
        "text": "in it I know I've got burned on that a"
      },
      {
        "start": 721.279,
        "duration": 3.961,
        "text": "couple of times that's just not a legal"
      },
      {
        "start": 722.839,
        "duration": 5.481,
        "text": "thing um then you put your open AI API"
      },
      {
        "start": 725.24,
        "duration": 6.52,
        "text": "key this is your setup so we're gonna"
      },
      {
        "start": 728.32,
        "duration": 6.199,
        "text": "stop there and get this part done while"
      },
      {
        "start": 731.76,
        "duration": 4.879,
        "text": "we're talking um and then later we're"
      },
      {
        "start": 734.519,
        "duration": 4.161,
        "text": "going to walk through the actual running"
      },
      {
        "start": 736.639,
        "duration": 5.961,
        "text": "and have some fun with actually doing"
      },
      {
        "start": 738.68,
        "duration": 6.12,
        "text": "some chat stuff so let's move on to the"
      },
      {
        "start": 742.6,
        "duration": 4.76,
        "text": "next piece"
      },
      {
        "start": 744.8,
        "duration": 4.8,
        "text": "here so yeah I'm gonna let you go and"
      },
      {
        "start": 747.36,
        "duration": 3.8,
        "text": "take it from here"
      },
      {
        "start": 749.6,
        "duration": 4.599,
        "text": "okay"
      },
      {
        "start": 751.16,
        "duration": 6.239,
        "text": "um so yeah so just quick quick quick"
      },
      {
        "start": 754.199,
        "duration": 6.44,
        "text": "inro to to rag um yeah uh we we can go"
      },
      {
        "start": 757.399,
        "duration": 5.0,
        "text": "we can just go to the next one so LS are"
      },
      {
        "start": 760.639,
        "duration": 5.801,
        "text": "great at communicating and reasoning"
      },
      {
        "start": 762.399,
        "duration": 5.761,
        "text": "right um what they're kind of bad at is"
      },
      {
        "start": 766.44,
        "duration": 4.24,
        "text": "knowing things especially you know if"
      },
      {
        "start": 768.16,
        "duration": 4.08,
        "text": "it's things that are very recent or it's"
      },
      {
        "start": 770.68,
        "duration": 3.68,
        "text": "things that are private to your"
      },
      {
        "start": 772.24,
        "duration": 4.399,
        "text": "organization and that's really what"
      },
      {
        "start": 774.36,
        "duration": 4.64,
        "text": "retrieval augmented generation of it is"
      },
      {
        "start": 776.639,
        "duration": 4.721,
        "text": "about um if you go to next slide you"
      },
      {
        "start": 779.0,
        "duration": 3.56,
        "text": "know like retrieval argument to"
      },
      {
        "start": 781.36,
        "duration": 2.839,
        "text": "generation when I first thought heard"
      },
      {
        "start": 782.56,
        "duration": 3.959,
        "text": "that is like you know it's three very"
      },
      {
        "start": 784.199,
        "duration": 4.161,
        "text": "long words I kind of know what they mean"
      },
      {
        "start": 786.519,
        "duration": 3.841,
        "text": "but I totally had no idea what they"
      },
      {
        "start": 788.36,
        "duration": 4.52,
        "text": "meant put together it's really simple"
      },
      {
        "start": 790.36,
        "duration": 5.12,
        "text": "actually it's just about searching for"
      },
      {
        "start": 792.88,
        "duration": 5.0,
        "text": "the information that you need giving the"
      },
      {
        "start": 795.48,
        "duration": 5.24,
        "text": "data to the L and then getting the best"
      },
      {
        "start": 797.88,
        "duration": 3.92,
        "text": "response back out from the LM so in fact"
      },
      {
        "start": 800.72,
        "duration": 3.04,
        "text": "you can even think about it like you"
      },
      {
        "start": 801.8,
        "duration": 3.52,
        "text": "know when you're talking to somebody"
      },
      {
        "start": 803.76,
        "duration": 3.36,
        "text": "right like when Patrick and I are having"
      },
      {
        "start": 805.32,
        "duration": 3.879,
        "text": "a conversation we're each doing"
      },
      {
        "start": 807.12,
        "duration": 5.0,
        "text": "retrieval argument to generation I'm"
      },
      {
        "start": 809.199,
        "duration": 4.521,
        "text": "giving him some context and then because"
      },
      {
        "start": 812.12,
        "duration": 5.0,
        "text": "he"
      },
      {
        "start": 813.72,
        "duration": 5.919,
        "text": "has yeah I mean it's it's it's literally"
      },
      {
        "start": 817.12,
        "duration": 6.12,
        "text": "just like a conversation if and the more"
      },
      {
        "start": 819.639,
        "duration": 5.32,
        "text": "relevant the context is the um the"
      },
      {
        "start": 823.24,
        "duration": 3.159,
        "text": "better the results and that's a very"
      },
      {
        "start": 824.959,
        "duration": 3.721,
        "text": "very important thing to remember when"
      },
      {
        "start": 826.399,
        "duration": 4.081,
        "text": "you're building a rag system so if we go"
      },
      {
        "start": 828.68,
        "duration": 4.04,
        "text": "to the next slide I can show you some"
      },
      {
        "start": 830.48,
        "duration": 5.599,
        "text": "examples of"
      },
      {
        "start": 832.72,
        "duration": 5.479,
        "text": "um of rag so actually I just saw Sam"
      },
      {
        "start": 836.079,
        "duration": 3.281,
        "text": "here he's a college student over at"
      },
      {
        "start": 838.199,
        "duration": 2.841,
        "text": "Oregon State"
      },
      {
        "start": 839.36,
        "duration": 3.2,
        "text": "and he built this cool thing it's open"
      },
      {
        "start": 841.04,
        "duration": 3.88,
        "text": "source"
      },
      {
        "start": 842.56,
        "duration": 5.88,
        "text": "um Patrick you can just click on the"
      },
      {
        "start": 844.92,
        "duration": 5.479,
        "text": "first one first link oh can I oh I gotta"
      },
      {
        "start": 848.44,
        "duration": 6.16,
        "text": "actually click on the link hang here we"
      },
      {
        "start": 850.399,
        "duration": 8.24,
        "text": "go yeah so um and you can do talk"
      },
      {
        "start": 854.6,
        "duration": 6.32,
        "text": "with what am I open way hopefully open"
      },
      {
        "start": 858.639,
        "duration": 3.481,
        "text": "ke still works and yeah we can just do"
      },
      {
        "start": 860.92,
        "duration": 4.2,
        "text": "this first thing like tell me about"
      },
      {
        "start": 862.12,
        "duration": 5.92,
        "text": "somebody's education J just let's try it"
      },
      {
        "start": 865.12,
        "duration": 5.0,
        "text": "oh okay well we could do this okay yeah"
      },
      {
        "start": 868.04,
        "duration": 4.159,
        "text": "we're GNA we're going embarrass him if"
      },
      {
        "start": 870.12,
        "duration": 3.719,
        "text": "uh if his keys revoked or something but"
      },
      {
        "start": 872.199,
        "duration": 3.241,
        "text": "we'll see we'll see what happens okay"
      },
      {
        "start": 873.839,
        "duration": 4.841,
        "text": "and then just hit"
      },
      {
        "start": 875.44,
        "duration": 5.319,
        "text": "send um that's funny that this is this"
      },
      {
        "start": 878.68,
        "duration": 3.04,
        "text": "is what he's asking let's let's find all"
      },
      {
        "start": 880.759,
        "duration": 4.44,
        "text": "about"
      },
      {
        "start": 881.72,
        "duration": 5.919,
        "text": "semi yeah exactly well we we'll see I"
      },
      {
        "start": 885.199,
        "duration": 5.361,
        "text": "the okay it looks like it looks like"
      },
      {
        "start": 887.639,
        "duration": 6.801,
        "text": "there's there's an issue with vuum key"
      },
      {
        "start": 890.56,
        "duration": 5.16,
        "text": "I'm gonna try it again yeah no I I so so"
      },
      {
        "start": 894.44,
        "duration": 3.519,
        "text": "may if you want to fix this in the next"
      },
      {
        "start": 895.72,
        "duration": 4.52,
        "text": "two minutes I know you're online so um"
      },
      {
        "start": 897.959,
        "duration": 3.841,
        "text": "but you can look at the code what it"
      },
      {
        "start": 900.24,
        "duration": 3.599,
        "text": "does is it actually does retrieval"
      },
      {
        "start": 901.8,
        "duration": 4.44,
        "text": "augmented generation it takes"
      },
      {
        "start": 903.839,
        "duration": 5.0,
        "text": "information from"
      },
      {
        "start": 906.24,
        "duration": 6.599,
        "text": "SM and"
      },
      {
        "start": 908.839,
        "duration": 6.56,
        "text": "um and uh that he's given the bot and"
      },
      {
        "start": 912.839,
        "duration": 4.56,
        "text": "then it finds the most relevant pieces"
      },
      {
        "start": 915.399,
        "duration": 5.721,
        "text": "from that information and then it"
      },
      {
        "start": 917.399,
        "duration": 6.0,
        "text": "actually goes and uh and answers your"
      },
      {
        "start": 921.12,
        "duration": 4.92,
        "text": "question in a"
      },
      {
        "start": 923.399,
        "duration": 5.8,
        "text": "more useful manner because you know open"
      },
      {
        "start": 926.04,
        "duration": 4.96,
        "text": "AI does not know about this individual"
      },
      {
        "start": 929.199,
        "duration": 3.76,
        "text": "um anyways check it out check it it's"
      },
      {
        "start": 931.0,
        "duration": 3.56,
        "text": "completely open source um you can build"
      },
      {
        "start": 932.959,
        "duration": 3.921,
        "text": "your own version but they done a great"
      },
      {
        "start": 934.56,
        "duration": 6.16,
        "text": "job with UI we just got to fix that"
      },
      {
        "start": 936.88,
        "duration": 7.12,
        "text": "opening I ke I think okay so so so next"
      },
      {
        "start": 940.72,
        "duration": 5.119,
        "text": "next slide we can go um another type of"
      },
      {
        "start": 944.0,
        "duration": 5.16,
        "text": "rag that you you all might be familiar"
      },
      {
        "start": 945.839,
        "duration": 6.12,
        "text": "with is um called search engine rag"
      },
      {
        "start": 949.16,
        "duration": 5.0,
        "text": "right so basically if you use Google"
      },
      {
        "start": 951.959,
        "duration": 5.161,
        "text": "bard if you use Bing I think they're"
      },
      {
        "start": 954.16,
        "duration": 5.08,
        "text": "raming it the Bing co-pilot now if you"
      },
      {
        "start": 957.12,
        "duration": 4.92,
        "text": "use chat gbt with browser"
      },
      {
        "start": 959.24,
        "duration": 5.839,
        "text": "the couple startups perplexity"
      },
      {
        "start": 962.04,
        "duration": 4.919,
        "text": "metaphor um what they do is they once"
      },
      {
        "start": 965.079,
        "duration": 4.641,
        "text": "again get contextual information to hear"
      },
      {
        "start": 966.959,
        "duration": 4.161,
        "text": "from the internet right so they're"
      },
      {
        "start": 969.72,
        "duration": 2.96,
        "text": "searching for information on the"
      },
      {
        "start": 971.12,
        "duration": 4.6,
        "text": "internet they get the most relevant"
      },
      {
        "start": 972.68,
        "duration": 6.079,
        "text": "information and then they give it to the"
      },
      {
        "start": 975.72,
        "duration": 5.2,
        "text": "model but once again here's the most"
      },
      {
        "start": 978.759,
        "duration": 4.241,
        "text": "important thing you have to give it the"
      },
      {
        "start": 980.92,
        "duration": 3.919,
        "text": "right context so I tried it right so"
      },
      {
        "start": 983.0,
        "duration": 3.279,
        "text": "chat with browsing I think I think it's"
      },
      {
        "start": 984.839,
        "duration": 4.24,
        "text": "enable for everybody or you might have"
      },
      {
        "start": 986.279,
        "duration": 4.281,
        "text": "to pay for a pro version um let's see"
      },
      {
        "start": 989.079,
        "duration": 3.88,
        "text": "let's see what"
      },
      {
        "start": 990.56,
        "duration": 6.959,
        "text": "happened we'll go to the next slide"
      },
      {
        "start": 992.959,
        "duration": 7.8,
        "text": "there oh yeah this looks familiar"
      },
      {
        "start": 997.519,
        "duration": 4.161,
        "text": "yeah so so so so so ask the question"
      },
      {
        "start": 1000.759,
        "duration": 3.52,
        "text": "what what"
      },
      {
        "start": 1001.68,
        "duration": 5.92,
        "text": "2022 movie won the Oscars right it's"
      },
      {
        "start": 1004.279,
        "duration": 7.04,
        "text": "20123 now obviously chat gbt doesn't"
      },
      {
        "start": 1007.6,
        "duration": 6.4,
        "text": "know um what the"
      },
      {
        "start": 1011.319,
        "duration": 5.721,
        "text": "uh what movie won the Oscars at the time"
      },
      {
        "start": 1014.0,
        "duration": 4.36,
        "text": "because it had um a knowledge cut off so"
      },
      {
        "start": 1017.04,
        "duration": 2.919,
        "text": "it says okay I'm going to search for it"
      },
      {
        "start": 1018.36,
        "duration": 4.52,
        "text": "right right so it says oh the movie Kota"
      },
      {
        "start": 1019.959,
        "duration": 5.681,
        "text": "won best picture at the Oscars in 2022"
      },
      {
        "start": 1022.88,
        "duration": 5.52,
        "text": "which is correct and then I said well"
      },
      {
        "start": 1025.64,
        "duration": 4.919,
        "text": "you know is Kota a what year did it come"
      },
      {
        "start": 1028.4,
        "duration": 6.0,
        "text": "out and it says oh it's released in 2021"
      },
      {
        "start": 1030.559,
        "duration": 8.841,
        "text": "so is it actually a 2022 movie and"
      },
      {
        "start": 1034.4,
        "duration": 6.639,
        "text": "then they're like no it's not right and"
      },
      {
        "start": 1039.4,
        "duration": 4.84,
        "text": "then I say okay well then tell me what"
      },
      {
        "start": 1041.039,
        "duration": 5.241,
        "text": "2022 movie came out in uh one of the"
      },
      {
        "start": 1044.24,
        "duration": 3.52,
        "text": "Oscars and it says well actually I don't"
      },
      {
        "start": 1046.28,
        "duration": 3.8,
        "text": "have that information which is true it"
      },
      {
        "start": 1047.76,
        "duration": 3.919,
        "text": "doesn't have that information because to"
      },
      {
        "start": 1050.08,
        "duration": 4.36,
        "text": "get that information it would have had"
      },
      {
        "start": 1051.679,
        "duration": 5.161,
        "text": "to retrieve right the search part it"
      },
      {
        "start": 1054.44,
        "duration": 5.0,
        "text": "would have had to retrieve the"
      },
      {
        "start": 1056.84,
        "duration": 3.88,
        "text": "information about the 2023 Oscars which"
      },
      {
        "start": 1059.44,
        "duration": 3.56,
        "text": "had already happened at this time this"
      },
      {
        "start": 1060.72,
        "duration": 4.0,
        "text": "was this is not a gimmick it actually"
      },
      {
        "start": 1063.0,
        "duration": 3.96,
        "text": "you know it could have retrieved that"
      },
      {
        "start": 1064.72,
        "duration": 3.839,
        "text": "through browsing but because of the way"
      },
      {
        "start": 1066.96,
        "duration": 2.8,
        "text": "it was searching it did not retrieve the"
      },
      {
        "start": 1068.559,
        "duration": 3.641,
        "text": "right information and therefore it"
      },
      {
        "start": 1069.76,
        "duration": 3.799,
        "text": "doesn't have it um so when you build"
      },
      {
        "start": 1072.2,
        "duration": 3.12,
        "text": "your R system this is very very"
      },
      {
        "start": 1073.559,
        "duration": 3.521,
        "text": "important to think about so if we go to"
      },
      {
        "start": 1075.32,
        "duration": 4.0,
        "text": "next slide it's really the same"
      },
      {
        "start": 1077.08,
        "duration": 5.56,
        "text": "principle that we talk about a lot"
      },
      {
        "start": 1079.32,
        "duration": 5.599,
        "text": "garbage in garbage out right if you you"
      },
      {
        "start": 1082.64,
        "duration": 3.8,
        "text": "have to make sure that you're retrieving"
      },
      {
        "start": 1084.919,
        "duration": 4.081,
        "text": "the right information and we'll talk"
      },
      {
        "start": 1086.44,
        "duration": 4.119,
        "text": "about some techniques later on about how"
      },
      {
        "start": 1089.0,
        "duration": 5.679,
        "text": "to tune what you're"
      },
      {
        "start": 1090.559,
        "duration": 5.36,
        "text": "retrieving um final thing next slide you"
      },
      {
        "start": 1094.679,
        "duration": 5.161,
        "text": "know I think"
      },
      {
        "start": 1095.919,
        "duration": 5.441,
        "text": "there's um oftentimes a large variety of"
      },
      {
        "start": 1099.84,
        "duration": 3.839,
        "text": "different"
      },
      {
        "start": 1101.36,
        "duration": 4.36,
        "text": "um different people you know different"
      },
      {
        "start": 1103.679,
        "duration": 4.841,
        "text": "skill levels that's totally okay like"
      },
      {
        "start": 1105.72,
        "duration": 5.4,
        "text": "like I said I I only started using LMS"
      },
      {
        "start": 1108.52,
        "duration": 5.639,
        "text": "this year right um but one thing that"
      },
      {
        "start": 1111.12,
        "duration": 7.52,
        "text": "you can try really easily is uh Jerry"
      },
      {
        "start": 1114.159,
        "duration": 7.201,
        "text": "Built This cool Stream app it's an agent"
      },
      {
        "start": 1118.64,
        "duration": 4.519,
        "text": "that builds a rag system for you right"
      },
      {
        "start": 1121.36,
        "duration": 3.08,
        "text": "should you use it in production no you"
      },
      {
        "start": 1123.159,
        "duration": 4.561,
        "text": "should use what Patrick's going to show"
      },
      {
        "start": 1124.44,
        "duration": 7.0,
        "text": "you can you use it to can you use it to"
      },
      {
        "start": 1127.72,
        "duration": 7.199,
        "text": "try it out and to um you know see see"
      },
      {
        "start": 1131.44,
        "duration": 4.92,
        "text": "how rag Works absolutely so yeah I"
      },
      {
        "start": 1134.919,
        "duration": 5.041,
        "text": "encourage you guys to try out literally"
      },
      {
        "start": 1136.36,
        "duration": 5.88,
        "text": "two weeks ago and uh 4,000 get up s so"
      },
      {
        "start": 1139.96,
        "duration": 3.92,
        "text": "yeah pass it back to you Patrick yeah"
      },
      {
        "start": 1142.24,
        "duration": 5.36,
        "text": "that's pretty impressive 4,000 GitHub"
      },
      {
        "start": 1143.88,
        "duration": 6.159,
        "text": "stars um yeah and you know it's"
      },
      {
        "start": 1147.6,
        "duration": 4.16,
        "text": "interesting I was I kind of have my own"
      },
      {
        "start": 1150.039,
        "duration": 2.681,
        "text": "thing in there about the rag you know"
      },
      {
        "start": 1151.76,
        "duration": 2.32,
        "text": "the thing we were talking about"
      },
      {
        "start": 1152.72,
        "duration": 3.8,
        "text": "yesterday is this I think the"
      },
      {
        "start": 1154.08,
        "duration": 4.44,
        "text": "interesting part of of llms are that"
      },
      {
        "start": 1156.52,
        "duration": 3.72,
        "text": "they are you know they compress"
      },
      {
        "start": 1158.52,
        "duration": 5.12,
        "text": "knowledge into the statistical"
      },
      {
        "start": 1160.24,
        "duration": 6.88,
        "text": "likelihood of the next answer right so"
      },
      {
        "start": 1163.64,
        "duration": 5.159,
        "text": "like if you ask it what's four plus 4"
      },
      {
        "start": 1167.12,
        "duration": 5.72,
        "text": "statistically the correct answer is"
      },
      {
        "start": 1168.799,
        "duration": 5.681,
        "text": "eight it's not actually doing math and"
      },
      {
        "start": 1172.84,
        "duration": 3.199,
        "text": "that's terrifying in some ways because"
      },
      {
        "start": 1174.48,
        "duration": 5.16,
        "text": "you don't know what I mean you're"
      },
      {
        "start": 1176.039,
        "duration": 6.0,
        "text": "basically rolling the dice"
      },
      {
        "start": 1179.64,
        "duration": 3.96,
        "text": "right um might as well go to Vegas and"
      },
      {
        "start": 1182.039,
        "duration": 3.921,
        "text": "play the"
      },
      {
        "start": 1183.6,
        "duration": 6.04,
        "text": "tables um yeah that's"
      },
      {
        "start": 1185.96,
        "duration": 8.64,
        "text": "interesting all right so let's get this"
      },
      {
        "start": 1189.64,
        "duration": 6.76,
        "text": "chatbot working and um Jameson I heard"
      },
      {
        "start": 1194.6,
        "duration": 3.959,
        "text": "you we're gonna zoom in here hopefully"
      },
      {
        "start": 1196.4,
        "duration": 3.88,
        "text": "this doesn't like zoom in everything so"
      },
      {
        "start": 1198.559,
        "duration": 4.921,
        "text": "we're gonna see how this works okay so I"
      },
      {
        "start": 1200.28,
        "duration": 5.04,
        "text": "think it's the command plus oh look look"
      },
      {
        "start": 1203.48,
        "duration": 5.36,
        "text": "all right look at that I gotta resize"
      },
      {
        "start": 1205.32,
        "duration": 5.52,
        "text": "everything now okay um if I can get a"
      },
      {
        "start": 1208.84,
        "duration": 6.92,
        "text": "thumbs up on that is this a good good"
      },
      {
        "start": 1210.84,
        "duration": 7.4,
        "text": "zoom in level or more um so we're gonna"
      },
      {
        "start": 1215.76,
        "duration": 5.36,
        "text": "get this working and what that means is"
      },
      {
        "start": 1218.24,
        "duration": 5.919,
        "text": "actually creating uh creating some"
      },
      {
        "start": 1221.12,
        "duration": 5.32,
        "text": "Vector data and then actually querying"
      },
      {
        "start": 1224.159,
        "duration": 5.64,
        "text": "it so there's a couple of Parts here now"
      },
      {
        "start": 1226.44,
        "duration": 6.16,
        "text": "what I I'm happy is the read me is very"
      },
      {
        "start": 1229.799,
        "duration": 5.641,
        "text": "solid um the getting started portion of"
      },
      {
        "start": 1232.6,
        "duration": 4.64,
        "text": "this I covered this a little bit u in"
      },
      {
        "start": 1235.44,
        "duration": 4.32,
        "text": "the beginning where I'm like go collect"
      },
      {
        "start": 1237.24,
        "duration": 5.04,
        "text": "all your keys um the other thing of"
      },
      {
        "start": 1239.76,
        "duration": 4.96,
        "text": "course is to run the the PIP install"
      },
      {
        "start": 1242.28,
        "duration": 4.32,
        "text": "requirements.txt and you'll see it"
      },
      {
        "start": 1244.72,
        "duration": 3.52,
        "text": "install the library so once you get into"
      },
      {
        "start": 1246.6,
        "duration": 3.72,
        "text": "that Baseline where you're like okay I"
      },
      {
        "start": 1248.24,
        "duration": 5.76,
        "text": "have all the libraries installed I have"
      },
      {
        "start": 1250.32,
        "duration": 6.479,
        "text": "mymv file done the next step is to work"
      },
      {
        "start": 1254.0,
        "duration": 5.2,
        "text": "on your config file now you don't need"
      },
      {
        "start": 1256.799,
        "duration": 4.321,
        "text": "to come up with one right away way um"
      },
      {
        "start": 1259.2,
        "duration": 7.04,
        "text": "there's this example data Stacks"
      },
      {
        "start": 1261.12,
        "duration": 8.52,
        "text": "config.yml file um and this has a pretty"
      },
      {
        "start": 1266.24,
        "duration": 4.679,
        "text": "reasonable it's just um going through so"
      },
      {
        "start": 1269.64,
        "duration": 5.279,
        "text": "what I'll just kind of walk through a"
      },
      {
        "start": 1270.919,
        "duration": 6.76,
        "text": "little bit um it's using uh various"
      },
      {
        "start": 1274.919,
        "duration": 5.041,
        "text": "libraries like this example response to"
      },
      {
        "start": 1277.679,
        "duration": 5.321,
        "text": "De cider these are all parts of this"
      },
      {
        "start": 1279.96,
        "duration": 5.959,
        "text": "this application um the llm provider"
      },
      {
        "start": 1283.0,
        "duration": 6.039,
        "text": "open AI um and then it it goes into more"
      },
      {
        "start": 1285.919,
        "duration": 5.081,
        "text": "of the like the the data this so like um"
      },
      {
        "start": 1289.039,
        "duration": 4.081,
        "text": "ye was talking about instead of letting"
      },
      {
        "start": 1291.0,
        "duration": 5.12,
        "text": "the llm tell us what's in the doc so"
      },
      {
        "start": 1293.12,
        "duration": 6.799,
        "text": "this what this is supposed to do is"
      },
      {
        "start": 1296.12,
        "duration": 7.84,
        "text": "essentially um act as a document chatbot"
      },
      {
        "start": 1299.919,
        "duration": 6.961,
        "text": "right and um the the idea is that we"
      },
      {
        "start": 1303.96,
        "duration": 4.64,
        "text": "need data that is real and not just like"
      },
      {
        "start": 1306.88,
        "duration": 4.96,
        "text": "compressed into an llm somewhere if you"
      },
      {
        "start": 1308.6,
        "duration": 5.12,
        "text": "went to go ask an llm about Cassandra it"
      },
      {
        "start": 1311.84,
        "duration": 4.719,
        "text": "might give you some good answers but"
      },
      {
        "start": 1313.72,
        "duration": 5.48,
        "text": "what we want is we want the exact answer"
      },
      {
        "start": 1316.559,
        "duration": 4.961,
        "text": "and this example what it does is it goes"
      },
      {
        "start": 1319.2,
        "duration": 6.079,
        "text": "through just some example doc pages that"
      },
      {
        "start": 1321.52,
        "duration": 5.48,
        "text": "we have and the the doc pages are the"
      },
      {
        "start": 1325.279,
        "duration": 3.76,
        "text": "source of Truth so essentially we're"
      },
      {
        "start": 1327.0,
        "duration": 4.88,
        "text": "gonna have the um we're gonna have this"
      },
      {
        "start": 1329.039,
        "duration": 6.52,
        "text": "app read the docs so this is the rtfm"
      },
      {
        "start": 1331.88,
        "duration": 6.72,
        "text": "doc rtfm app and then it will after it"
      },
      {
        "start": 1335.559,
        "duration": 4.761,
        "text": "reads the docs it will use the docs to"
      },
      {
        "start": 1338.6,
        "duration": 5.84,
        "text": "give you a correct answer when you ask a"
      },
      {
        "start": 1340.32,
        "duration": 6.479,
        "text": "question so um again if you use intercom"
      },
      {
        "start": 1344.44,
        "duration": 4.8,
        "text": "on our data STX Astra this is actually"
      },
      {
        "start": 1346.799,
        "duration": 4.88,
        "text": "code that's being used there now so um"
      },
      {
        "start": 1349.24,
        "duration": 4.799,
        "text": "it's pretty cool and so there's a few"
      },
      {
        "start": 1351.679,
        "duration": 6.24,
        "text": "things here like first of all it's the"
      },
      {
        "start": 1354.039,
        "duration": 6.601,
        "text": "custom rules um and this is uh I'm gonna"
      },
      {
        "start": 1357.919,
        "duration": 6.521,
        "text": "go over to our config.yml"
      },
      {
        "start": 1360.64,
        "duration": 6.12,
        "text": "um we had fun with it yesterday um so"
      },
      {
        "start": 1364.44,
        "duration": 4.719,
        "text": "you can copy the the example into the"
      },
      {
        "start": 1366.76,
        "duration": 4.68,
        "text": "config.yml file create a new one and"
      },
      {
        "start": 1369.159,
        "duration": 5.041,
        "text": "just use the defaults now later if you"
      },
      {
        "start": 1371.44,
        "duration": 6.68,
        "text": "want to have fun create your own config"
      },
      {
        "start": 1374.2,
        "duration": 5.56,
        "text": "gaml maybe on your own docs and that and"
      },
      {
        "start": 1378.12,
        "duration": 3.4,
        "text": "start exploring your own documentation"
      },
      {
        "start": 1379.76,
        "duration": 4.56,
        "text": "or use it on your own site this is an"
      },
      {
        "start": 1381.52,
        "duration": 4.84,
        "text": "open source project go for it um and"
      },
      {
        "start": 1384.32,
        "duration": 4.76,
        "text": "with incommon slack integration it's"
      },
      {
        "start": 1386.36,
        "duration": 5.36,
        "text": "really cool so there's some some custom"
      },
      {
        "start": 1389.08,
        "duration": 4.56,
        "text": "rules so if the user refers to database"
      },
      {
        "start": 1391.72,
        "duration": 4.04,
        "text": "assume they're assuming Cassandra that's"
      },
      {
        "start": 1393.64,
        "duration": 5.12,
        "text": "a common that's a common thing if you"
      },
      {
        "start": 1395.76,
        "duration": 5.44,
        "text": "ask Chad gbt about hey how do I create a"
      },
      {
        "start": 1398.76,
        "duration": 5.039,
        "text": "data model for Cassandra for this use"
      },
      {
        "start": 1401.2,
        "duration": 4.599,
        "text": "case it might Veer off and start giving"
      },
      {
        "start": 1403.799,
        "duration": 3.721,
        "text": "you different kinds of data modeling"
      },
      {
        "start": 1405.799,
        "duration": 2.641,
        "text": "advice that may not have anything to do"
      },
      {
        "start": 1407.52,
        "duration": 2.56,
        "text": "with Cass"
      },
      {
        "start": 1408.44,
        "duration": 3.2,
        "text": "so we're just going to be very specific"
      },
      {
        "start": 1410.08,
        "duration": 4.0,
        "text": "about this this is that prompting"
      },
      {
        "start": 1411.64,
        "duration": 5.76,
        "text": "techniques you're a pred engineer after"
      },
      {
        "start": 1414.08,
        "duration": 4.719,
        "text": "you figure this out um and like the"
      },
      {
        "start": 1417.4,
        "duration": 3.2,
        "text": "question is not explicit related to"
      },
      {
        "start": 1418.799,
        "duration": 4.561,
        "text": "cassander data STX or data STX product"
      },
      {
        "start": 1420.6,
        "duration": 4.04,
        "text": "or migrating you always say I'm sorry I"
      },
      {
        "start": 1423.36,
        "duration": 3.48,
        "text": "only answer questions related to"
      },
      {
        "start": 1424.64,
        "duration": 5.279,
        "text": "cassander data sex products so it's it's"
      },
      {
        "start": 1426.84,
        "duration": 5.839,
        "text": "giving the uh it's the reasoning part of"
      },
      {
        "start": 1429.919,
        "duration": 4.24,
        "text": "the llm um some sort of instructions"
      },
      {
        "start": 1432.679,
        "duration": 3.841,
        "text": "about what to do what if it can't find"
      },
      {
        "start": 1434.159,
        "duration": 4.441,
        "text": "the answer which is great because most"
      },
      {
        "start": 1436.52,
        "duration": 4.32,
        "text": "times uh chat gbt he will give you a"
      },
      {
        "start": 1438.6,
        "duration": 3.679,
        "text": "very confident incorrect answer um this"
      },
      {
        "start": 1440.84,
        "duration": 3.48,
        "text": "in this case it'll just say I don't know"
      },
      {
        "start": 1442.279,
        "duration": 3.4,
        "text": "that's what you wanted to do um you"
      },
      {
        "start": 1444.32,
        "duration": 2.92,
        "text": "could read through the rest yourself but"
      },
      {
        "start": 1445.679,
        "duration": 4.561,
        "text": "this is where you put in those things"
      },
      {
        "start": 1447.24,
        "duration": 4.64,
        "text": "kind of create boundaries and guard"
      },
      {
        "start": 1450.24,
        "duration": 3.4,
        "text": "rails around what the question and"
      },
      {
        "start": 1451.88,
        "duration": 3.48,
        "text": "answer in the chat box going to be and"
      },
      {
        "start": 1453.64,
        "duration": 3.6,
        "text": "then um ye and I were having fun"
      },
      {
        "start": 1455.36,
        "duration": 4.24,
        "text": "yesterday and we and oh by the way Talk"
      },
      {
        "start": 1457.24,
        "duration": 5.76,
        "text": "Like a Pirate"
      },
      {
        "start": 1459.6,
        "duration": 6.16,
        "text": "um um you know that that you know that"
      },
      {
        "start": 1463.0,
        "duration": 5.32,
        "text": "could be your use case I don't know um"
      },
      {
        "start": 1465.76,
        "duration": 4.159,
        "text": "maybe and uh"
      },
      {
        "start": 1468.32,
        "duration": 4.839,
        "text": "the the other thing that's really"
      },
      {
        "start": 1469.919,
        "duration": 6.24,
        "text": "critical is this a list of the the HTML"
      },
      {
        "start": 1473.159,
        "duration": 5.921,
        "text": "pages to to go through so this is just a"
      },
      {
        "start": 1476.159,
        "duration": 5.841,
        "text": "subset of our docs um like for instance"
      },
      {
        "start": 1479.08,
        "duration": 6.68,
        "text": "the storage attach indexes uh which are"
      },
      {
        "start": 1482.0,
        "duration": 7.559,
        "text": "an indexing mechanism have a go do that"
      },
      {
        "start": 1485.76,
        "duration": 6.039,
        "text": "okay so that is our config gaml file um"
      },
      {
        "start": 1489.559,
        "duration": 5.321,
        "text": "we should probably double click on this"
      },
      {
        "start": 1491.799,
        "duration": 5.641,
        "text": "Talk Like a Pirate real quick um that"
      },
      {
        "start": 1494.88,
        "duration": 3.88,
        "text": "today will not work in the current code"
      },
      {
        "start": 1497.44,
        "duration": 4.2,
        "text": "am I right"
      },
      {
        "start": 1498.76,
        "duration": 4.44,
        "text": "e uh that's correct but but I'm gonna"
      },
      {
        "start": 1501.64,
        "duration": 4.2,
        "text": "have a PR to make that"
      },
      {
        "start": 1503.2,
        "duration": 7.56,
        "text": "work well I already have a PR so you"
      },
      {
        "start": 1505.84,
        "duration": 8.76,
        "text": "have a PR yeah yeah yeah and and I think"
      },
      {
        "start": 1510.76,
        "duration": 8.519,
        "text": "you know just to keep people online"
      },
      {
        "start": 1514.6,
        "duration": 9.04,
        "text": "um ye will explain why in just a minute"
      },
      {
        "start": 1519.279,
        "duration": 4.361,
        "text": "so there you go so you better explain"
      },
      {
        "start": 1524.12,
        "duration": 6.679,
        "text": "why and welcome to the world of LM"
      },
      {
        "start": 1528.2,
        "duration": 5.28,
        "text": "um okay so what do we do once we have"
      },
      {
        "start": 1530.799,
        "duration": 4.641,
        "text": "this config file there are two steps"
      },
      {
        "start": 1533.48,
        "duration": 3.36,
        "text": "that we're going to do um so I'll go"
      },
      {
        "start": 1535.44,
        "duration": 3.56,
        "text": "back to the readme it's all in the"
      },
      {
        "start": 1536.84,
        "duration": 5.319,
        "text": "readme so once you get everything set up"
      },
      {
        "start": 1539.0,
        "duration": 4.6,
        "text": "with the config file there are two steps"
      },
      {
        "start": 1542.159,
        "duration": 5.961,
        "text": "um that you need to create the"
      },
      {
        "start": 1543.6,
        "duration": 8.92,
        "text": "embeddings now when I look at my time my"
      },
      {
        "start": 1548.12,
        "duration": 7.12,
        "text": "database um I need to make this work and"
      },
      {
        "start": 1552.52,
        "duration": 5.72,
        "text": "so when we when we go through the actual"
      },
      {
        "start": 1555.24,
        "duration": 5.439,
        "text": "setup there are two parts there there's"
      },
      {
        "start": 1558.24,
        "duration": 4.12,
        "text": "whenever I look at my documentation when"
      },
      {
        "start": 1560.679,
        "duration": 3.6,
        "text": "I have this this app look at the"
      },
      {
        "start": 1562.36,
        "duration": 5.439,
        "text": "documentation what it's doing is it's"
      },
      {
        "start": 1564.279,
        "duration": 5.52,
        "text": "reading the text and then it creates the"
      },
      {
        "start": 1567.799,
        "duration": 4.801,
        "text": "vector embeddings and those Vector"
      },
      {
        "start": 1569.799,
        "duration": 5.641,
        "text": "embeddings need to be stored inside the"
      },
      {
        "start": 1572.6,
        "duration": 4.799,
        "text": "system inside this Vector database and"
      },
      {
        "start": 1575.44,
        "duration": 4.32,
        "text": "then that will be used for the chatbot"
      },
      {
        "start": 1577.399,
        "duration": 4.441,
        "text": "later um and you will show like where"
      },
      {
        "start": 1579.76,
        "duration": 5.36,
        "text": "this where this comes in and the actual"
      },
      {
        "start": 1581.84,
        "duration": 4.76,
        "text": "rag portion the the um retrieval"
      },
      {
        "start": 1585.12,
        "duration": 3.48,
        "text": "augmented so what's the what are we"
      },
      {
        "start": 1586.6,
        "duration": 5.04,
        "text": "retrieving well this is where we're"
      },
      {
        "start": 1588.6,
        "duration": 5.12,
        "text": "going to do and by the way this is one"
      },
      {
        "start": 1591.64,
        "duration": 3.56,
        "text": "of the super cool parts of this new UI"
      },
      {
        "start": 1593.72,
        "duration": 5.04,
        "text": "you can actually look at the data that's"
      },
      {
        "start": 1595.2,
        "duration": 4.92,
        "text": "in there and uh whenever I create these"
      },
      {
        "start": 1598.76,
        "duration": 4.32,
        "text": "embeddings and I'll I'll walk through it"
      },
      {
        "start": 1600.12,
        "duration": 6.919,
        "text": "real quick um what it's doing is it's"
      },
      {
        "start": 1603.08,
        "duration": 7.04,
        "text": "creating a vector so here's this massive"
      },
      {
        "start": 1607.039,
        "duration": 6.921,
        "text": "number and but what it's doing is it's"
      },
      {
        "start": 1610.12,
        "duration": 6.52,
        "text": "actually creating it on real content and"
      },
      {
        "start": 1613.96,
        "duration": 4.52,
        "text": "so it's taking the docs that are in"
      },
      {
        "start": 1616.64,
        "duration": 4.32,
        "text": "these HTML pages"
      },
      {
        "start": 1618.48,
        "duration": 5.0,
        "text": "chunking chunking it up into usable"
      },
      {
        "start": 1620.96,
        "duration": 6.12,
        "text": "pieces creating a vector embedding using"
      },
      {
        "start": 1623.48,
        "duration": 5.64,
        "text": "open AI putting that embedding into the"
      },
      {
        "start": 1627.08,
        "duration": 4.44,
        "text": "database along with"
      },
      {
        "start": 1629.12,
        "duration": 5.439,
        "text": "metadata and it's things like here's the"
      },
      {
        "start": 1631.52,
        "duration": 5.84,
        "text": "file path and here's the actual content"
      },
      {
        "start": 1634.559,
        "duration": 4.401,
        "text": "so that whenever we're searching um we"
      },
      {
        "start": 1637.36,
        "duration": 3.88,
        "text": "have all the base information that"
      },
      {
        "start": 1638.96,
        "duration": 4.56,
        "text": "created this Vector embedding but the"
      },
      {
        "start": 1641.24,
        "duration": 5.12,
        "text": "vector embedding is used in an"
      },
      {
        "start": 1643.52,
        "duration": 4.68,
        "text": "approximate nearest neighbor search and"
      },
      {
        "start": 1646.36,
        "duration": 4.199,
        "text": "that's that's the real"
      },
      {
        "start": 1648.2,
        "duration": 5.12,
        "text": "Secret Sauce to building a rag"
      },
      {
        "start": 1650.559,
        "duration": 6.161,
        "text": "application is having it having this"
      },
      {
        "start": 1653.32,
        "duration": 5.599,
        "text": "data available in a way that is usable"
      },
      {
        "start": 1656.72,
        "duration": 5.76,
        "text": "by the library so when llama index is"
      },
      {
        "start": 1658.919,
        "duration": 7.441,
        "text": "like hey the user asked this question"
      },
      {
        "start": 1662.48,
        "duration": 7.16,
        "text": "what's close to it this is this is how"
      },
      {
        "start": 1666.36,
        "duration": 5.439,
        "text": "that gets done all right so when you"
      },
      {
        "start": 1669.64,
        "duration": 5.039,
        "text": "look at this um you see that there's a"
      },
      {
        "start": 1671.799,
        "duration": 7.72,
        "text": "ton of data in here uh there's"
      },
      {
        "start": 1674.679,
        "duration": 7.561,
        "text": "10,088 records how did I create that I'm"
      },
      {
        "start": 1679.519,
        "duration": 4.0,
        "text": "glad you ask ye um the first thing you"
      },
      {
        "start": 1682.24,
        "duration": 3.84,
        "text": "have to do is you have to scrape the"
      },
      {
        "start": 1683.519,
        "duration": 4.4,
        "text": "site so if I if I run this Command right"
      },
      {
        "start": 1686.08,
        "duration": 4.959,
        "text": "here what it'll do is it'll go through"
      },
      {
        "start": 1687.919,
        "duration": 5.681,
        "text": "the list in the config gaml file and it"
      },
      {
        "start": 1691.039,
        "duration": 5.24,
        "text": "will what it'll do is dump the text"
      },
      {
        "start": 1693.6,
        "duration": 5.72,
        "text": "version of the HTML into the docs"
      },
      {
        "start": 1696.279,
        "duration": 5.921,
        "text": "directory so if you go into the data"
      },
      {
        "start": 1699.32,
        "duration": 6.0,
        "text": "uhds you'll see that it is created a ton"
      },
      {
        "start": 1702.2,
        "duration": 6.88,
        "text": "of this is uh with the HTML stripped out"
      },
      {
        "start": 1705.32,
        "duration": 5.719,
        "text": "so for instance um like here's about SII"
      },
      {
        "start": 1709.08,
        "duration": 3.4,
        "text": "uh zero copy of streaming index these"
      },
      {
        "start": 1711.039,
        "duration": 5.12,
        "text": "are all the words that were in the"
      },
      {
        "start": 1712.48,
        "duration": 6.0,
        "text": "documentation how to configure it um"
      },
      {
        "start": 1716.159,
        "duration": 3.681,
        "text": "these are important this is how this is"
      },
      {
        "start": 1718.48,
        "duration": 3.4,
        "text": "some of that"
      },
      {
        "start": 1719.84,
        "duration": 4.719,
        "text": "pre-training cleanup that needs to be"
      },
      {
        "start": 1721.88,
        "duration": 5.159,
        "text": "done um you don't want to have a bunch"
      },
      {
        "start": 1724.559,
        "duration": 4.561,
        "text": "of useless HTML tags in your embedding"
      },
      {
        "start": 1727.039,
        "duration": 4.601,
        "text": "data because no one cares if there was a"
      },
      {
        "start": 1729.12,
        "duration": 4.96,
        "text": "P tag on there um that's that's part of"
      },
      {
        "start": 1731.64,
        "duration": 5.84,
        "text": "that cleanup so what this process does"
      },
      {
        "start": 1734.08,
        "duration": 6.56,
        "text": "is it goes out grabs the HTML cleans out"
      },
      {
        "start": 1737.48,
        "duration": 5.4,
        "text": "the HTML and uh cleans off the HTML and"
      },
      {
        "start": 1740.64,
        "duration": 5.12,
        "text": "just turns it into the raw data and that"
      },
      {
        "start": 1742.88,
        "duration": 5.56,
        "text": "gets dumped into a directory so after"
      },
      {
        "start": 1745.76,
        "duration": 4.24,
        "text": "I'll go back to my read me how's"
      },
      {
        "start": 1748.44,
        "duration": 4.16,
        "text": "everyone doing so far is there got any"
      },
      {
        "start": 1750.0,
        "duration": 4.6,
        "text": "questions so"
      },
      {
        "start": 1752.6,
        "duration": 3.88,
        "text": "far oh"
      },
      {
        "start": 1754.6,
        "duration": 6.079,
        "text": "interesting will the data Explorer"
      },
      {
        "start": 1756.48,
        "duration": 7.0,
        "text": "navigate to all PDF files uh no and but"
      },
      {
        "start": 1760.679,
        "duration": 5.12,
        "text": "you can use uh there's a search"
      },
      {
        "start": 1763.48,
        "duration": 5.799,
        "text": "mechanisms inside here where you can do"
      },
      {
        "start": 1765.799,
        "duration": 5.321,
        "text": "some metadata filtering um there's"
      },
      {
        "start": 1769.279,
        "duration": 4.801,
        "text": "there's a lot to go here this is not"
      },
      {
        "start": 1771.12,
        "duration": 5.2,
        "text": "meant to be a um a dive into this and"
      },
      {
        "start": 1774.08,
        "duration": 4.079,
        "text": "it's actually probably a a good reason"
      },
      {
        "start": 1776.32,
        "duration": 3.76,
        "text": "to do it but we should create some"
      },
      {
        "start": 1778.159,
        "duration": 3.52,
        "text": "content about just how to use this"
      },
      {
        "start": 1780.08,
        "duration": 3.719,
        "text": "particular interface but that's a good"
      },
      {
        "start": 1781.679,
        "duration": 4.441,
        "text": "question there's limited search fun"
      },
      {
        "start": 1783.799,
        "duration": 5.321,
        "text": "functionality uh but it is not meant to"
      },
      {
        "start": 1786.12,
        "duration": 4.88,
        "text": "replace a a li a full Library like llama"
      },
      {
        "start": 1789.12,
        "duration": 4.32,
        "text": "index it's just there to like explore"
      },
      {
        "start": 1791.0,
        "duration": 5.519,
        "text": "your data and see what's in there um but"
      },
      {
        "start": 1793.44,
        "duration": 4.8,
        "text": "that's great question uh thanks Wayne um"
      },
      {
        "start": 1796.519,
        "duration": 4.561,
        "text": "so"
      },
      {
        "start": 1798.24,
        "duration": 5.84,
        "text": "another question from Albert saying do"
      },
      {
        "start": 1801.08,
        "duration": 4.319,
        "text": "we need to copy your astv values or"
      },
      {
        "start": 1804.08,
        "duration": 4.199,
        "text": "create our own"
      },
      {
        "start": 1805.399,
        "duration": 8.561,
        "text": "tables create your own tables thank you"
      },
      {
        "start": 1808.279,
        "duration": 8.441,
        "text": "for asking that question um the uh yes"
      },
      {
        "start": 1813.96,
        "duration": 4.76,
        "text": "the you w to and this is a good point"
      },
      {
        "start": 1816.72,
        "duration": 3.88,
        "text": "too you when this is something we talked"
      },
      {
        "start": 1818.72,
        "duration": 3.679,
        "text": "about like that privacy aspect you don't"
      },
      {
        "start": 1820.6,
        "duration": 5.88,
        "text": "want to just throw your data into chat"
      },
      {
        "start": 1822.399,
        "duration": 6.561,
        "text": "GPT for instance and expect privacy um"
      },
      {
        "start": 1826.48,
        "duration": 4.52,
        "text": "it especially in regulated environments"
      },
      {
        "start": 1828.96,
        "duration": 3.959,
        "text": "uh if you're in finance healthare that"
      },
      {
        "start": 1831.0,
        "duration": 5.44,
        "text": "sort of thing you want to have your own"
      },
      {
        "start": 1832.919,
        "duration": 7.521,
        "text": "database with your own key um probably a"
      },
      {
        "start": 1836.44,
        "duration": 7.4,
        "text": "good time to mention that Astra is uh"
      },
      {
        "start": 1840.44,
        "duration": 4.76,
        "text": "it's got all the tickets PCI Hippa um"
      },
      {
        "start": 1843.84,
        "duration": 3.04,
        "text": "all those things that will make your"
      },
      {
        "start": 1845.2,
        "duration": 4.199,
        "text": "life a lot easier when you're working in"
      },
      {
        "start": 1846.88,
        "duration": 2.519,
        "text": "regulated"
      },
      {
        "start": 1850.159,
        "duration": 4.721,
        "text": "environments all right um let's move"
      },
      {
        "start": 1852.96,
        "duration": 3.439,
        "text": "along I I see more questions but we can"
      },
      {
        "start": 1854.88,
        "duration": 3.399,
        "text": "pick those up I just want to make sure"
      },
      {
        "start": 1856.399,
        "duration": 3.481,
        "text": "we get to your part ye and then we can"
      },
      {
        "start": 1858.279,
        "duration": 3.4,
        "text": "we'll answer questions towards the end"
      },
      {
        "start": 1859.88,
        "duration": 4.88,
        "text": "as well um these are great though keep"
      },
      {
        "start": 1861.679,
        "duration": 6.521,
        "text": "them coming we'll get to you all right"
      },
      {
        "start": 1864.76,
        "duration": 7.32,
        "text": "so uh when I'm when I'm running when I"
      },
      {
        "start": 1868.2,
        "duration": 7.4,
        "text": "run this file go back to this right"
      },
      {
        "start": 1872.08,
        "duration": 5.04,
        "text": "here uh when I do the compil documents"
      },
      {
        "start": 1875.6,
        "duration": 4.28,
        "text": "what what actually I'm gonna just go"
      },
      {
        "start": 1877.12,
        "duration": 5.559,
        "text": "ahead and run it real quick um actually"
      },
      {
        "start": 1879.88,
        "duration": 5.279,
        "text": "should I run it probably not um when I"
      },
      {
        "start": 1882.679,
        "duration": 4.88,
        "text": "run the compil documents um because"
      },
      {
        "start": 1885.159,
        "duration": 4.4,
        "text": "it'll take a while uh I and I saw a"
      },
      {
        "start": 1887.559,
        "duration": 4.561,
        "text": "question is like what embeddings do you"
      },
      {
        "start": 1889.559,
        "duration": 7.0,
        "text": "are we using in this case it's the open"
      },
      {
        "start": 1892.12,
        "duration": 7.64,
        "text": "AI Ada embedding um you could and this"
      },
      {
        "start": 1896.559,
        "duration": 5.24,
        "text": "is another topic worth diving into a lot"
      },
      {
        "start": 1899.76,
        "duration": 4.48,
        "text": "there are a lot of embeddings a lot of"
      },
      {
        "start": 1901.799,
        "duration": 4.84,
        "text": "folks are talking about E5 is a cool kid"
      },
      {
        "start": 1904.24,
        "duration": 3.35,
        "text": "um I don't know ye do you what's your"
      },
      {
        "start": 1906.639,
        "duration": 3.801,
        "text": "favorite embedding"
      },
      {
        "start": 1907.59,
        "duration": 7.25,
        "text": "[Laughter]"
      },
      {
        "start": 1910.44,
        "duration": 7.599,
        "text": "ye you're on mute still oh sorry um I"
      },
      {
        "start": 1914.84,
        "duration": 6.76,
        "text": "was yeah so over open AI I definitely"
      },
      {
        "start": 1918.039,
        "duration": 5.681,
        "text": "start with open Ai and then um you know"
      },
      {
        "start": 1921.6,
        "duration": 3.919,
        "text": "coher has put out some cool embeddings"
      },
      {
        "start": 1923.72,
        "duration": 4.76,
        "text": "um coher V3 it's a little bit different"
      },
      {
        "start": 1925.519,
        "duration": 5.321,
        "text": "because the query and the and the answer"
      },
      {
        "start": 1928.48,
        "duration": 4.88,
        "text": "need to be embedded using different"
      },
      {
        "start": 1930.84,
        "duration": 5.6,
        "text": "settings um and then there's lots of"
      },
      {
        "start": 1933.36,
        "duration": 4.52,
        "text": "lots of embeddings on the leaderboard um"
      },
      {
        "start": 1936.44,
        "duration": 4.239,
        "text": "but the reason why I would suggest"
      },
      {
        "start": 1937.88,
        "duration": 4.919,
        "text": "starting with openi embeddings is"
      },
      {
        "start": 1940.679,
        "duration": 4.801,
        "text": "because"
      },
      {
        "start": 1942.799,
        "duration": 5.521,
        "text": "um with opening ey edings like so many"
      },
      {
        "start": 1945.48,
        "duration": 5.679,
        "text": "people are using them that your behavior"
      },
      {
        "start": 1948.32,
        "duration": 3.8,
        "text": "is going to be relatively predictable um"
      },
      {
        "start": 1951.159,
        "duration": 2.801,
        "text": "if you look at the hugging face"
      },
      {
        "start": 1952.12,
        "duration": 4.279,
        "text": "leaderboard there's actually lots of"
      },
      {
        "start": 1953.96,
        "duration": 4.679,
        "text": "Open Source models they're great but you"
      },
      {
        "start": 1956.399,
        "duration": 7.12,
        "text": "really should test them yourself on your"
      },
      {
        "start": 1958.639,
        "duration": 6.201,
        "text": "own data right yeah so so yeah um but"
      },
      {
        "start": 1963.519,
        "duration": 3.841,
        "text": "you know open source Community is"
      },
      {
        "start": 1964.84,
        "duration": 3.6,
        "text": "fantastic and we love them um but you"
      },
      {
        "start": 1967.36,
        "duration": 4.199,
        "text": "should you should definitely test it"
      },
      {
        "start": 1968.44,
        "duration": 5.68,
        "text": "yourself because the benchmarks are"
      },
      {
        "start": 1971.559,
        "duration": 4.801,
        "text": "synthetic so the performance may or may"
      },
      {
        "start": 1974.12,
        "duration": 4.919,
        "text": "not be what you need for your"
      },
      {
        "start": 1976.36,
        "duration": 2.679,
        "text": "application"
      },
      {
        "start": 1979.2,
        "duration": 4.079,
        "text": "yeah that again this is like we're"
      },
      {
        "start": 1981.679,
        "duration": 3.761,
        "text": "creating we're creating need for new"
      },
      {
        "start": 1983.279,
        "duration": 4.76,
        "text": "content out of this particular Workshop"
      },
      {
        "start": 1985.44,
        "duration": 4.719,
        "text": "I mean just picking embeddings is is a"
      },
      {
        "start": 1988.039,
        "duration": 3.801,
        "text": "somewhat it's a use case dependent"
      },
      {
        "start": 1990.159,
        "duration": 3.681,
        "text": "almost like a data modeling exercise in"
      },
      {
        "start": 1991.84,
        "duration": 3.04,
        "text": "a lot of ways um and you got to think"
      },
      {
        "start": 1993.84,
        "duration": 2.839,
        "text": "about like what are you trying to"
      },
      {
        "start": 1994.88,
        "duration": 4.44,
        "text": "accomplish with your embedding is it"
      },
      {
        "start": 1996.679,
        "duration": 7.48,
        "text": "text is it images what mode of data is"
      },
      {
        "start": 1999.32,
        "duration": 7.319,
        "text": "it multimodal Etc so um we're gonna um"
      },
      {
        "start": 2004.159,
        "duration": 5.64,
        "text": "if you noticed I started this uh started"
      },
      {
        "start": 2006.639,
        "duration": 6.441,
        "text": "the thing I'm going to kill it um but"
      },
      {
        "start": 2009.799,
        "duration": 5.72,
        "text": "right now what it's actually doing is um"
      },
      {
        "start": 2013.08,
        "duration": 4.839,
        "text": "going through all the text chunking it"
      },
      {
        "start": 2015.519,
        "duration": 3.241,
        "text": "going to open AI running up my bill"
      },
      {
        "start": 2017.919,
        "duration": 4.081,
        "text": "right"
      },
      {
        "start": 2018.76,
        "duration": 6.159,
        "text": "now and um it's creating the embeddings"
      },
      {
        "start": 2022.0,
        "duration": 5.44,
        "text": "and then dropping those into Astra so I"
      },
      {
        "start": 2024.919,
        "duration": 4.201,
        "text": "think this takes a second but um you'll"
      },
      {
        "start": 2027.44,
        "duration": 4.239,
        "text": "start seeing these pop up on here"
      },
      {
        "start": 2029.12,
        "duration": 4.32,
        "text": "shortly it'll it'll start saying oh yeah"
      },
      {
        "start": 2031.679,
        "duration": 4.441,
        "text": "here here comes all your here comes all"
      },
      {
        "start": 2033.44,
        "duration": 4.479,
        "text": "your data uh there's a bit of a lag and"
      },
      {
        "start": 2036.12,
        "duration": 4.84,
        "text": "like let's see last five minutes there"
      },
      {
        "start": 2037.919,
        "duration": 5.561,
        "text": "we go um when it shows up we'll go back"
      },
      {
        "start": 2040.96,
        "duration": 5.04,
        "text": "over there and check it out but um yeah"
      },
      {
        "start": 2043.48,
        "duration": 4.56,
        "text": "so the the idea right now is it's just"
      },
      {
        "start": 2046.0,
        "duration": 5.28,
        "text": "creating all the embeddings so I'm gonna"
      },
      {
        "start": 2048.04,
        "duration": 7.52,
        "text": "go and kill this right now control c ah"
      },
      {
        "start": 2051.28,
        "duration": 6.68,
        "text": "okay sorry um and I'm gonna start I'm"
      },
      {
        "start": 2055.56,
        "duration": 7.039,
        "text": "gonna start the UI portion of this now"
      },
      {
        "start": 2057.96,
        "duration": 6.719,
        "text": "there is a UI that um that is basic is"
      },
      {
        "start": 2062.599,
        "duration": 5.601,
        "text": "well the UI is using a python script if"
      },
      {
        "start": 2064.679,
        "duration": 5.2,
        "text": "you don't have intercom or slack um I"
      },
      {
        "start": 2068.2,
        "duration": 3.8,
        "text": "think one of the things we were talking"
      },
      {
        "start": 2069.879,
        "duration": 5.161,
        "text": "about is adding an actual like a maybe a"
      },
      {
        "start": 2072.0,
        "duration": 4.879,
        "text": "react or something nextjs UI to it um"
      },
      {
        "start": 2075.04,
        "duration": 3.639,
        "text": "slack and intercom were the first use"
      },
      {
        "start": 2076.879,
        "duration": 4.04,
        "text": "cases but this is gonna grow as we go"
      },
      {
        "start": 2078.679,
        "duration": 4.4,
        "text": "along if you want to contribute that's"
      },
      {
        "start": 2080.919,
        "duration": 3.76,
        "text": "an awesome contribution and I would love"
      },
      {
        "start": 2083.079,
        "duration": 4.481,
        "text": "to promote"
      },
      {
        "start": 2084.679,
        "duration": 4.24,
        "text": "it um yeah if you build something I will"
      },
      {
        "start": 2087.56,
        "duration": 3.2,
        "text": "get you in a workshop and we'll talk"
      },
      {
        "start": 2088.919,
        "duration": 4.0,
        "text": "about it how about"
      },
      {
        "start": 2090.76,
        "duration": 5.56,
        "text": "that that's that's you"
      },
      {
        "start": 2092.919,
        "duration": 5.601,
        "text": "too all right so I'm gonna start oh so"
      },
      {
        "start": 2096.32,
        "duration": 4.88,
        "text": "the what this is this back end is it"
      },
      {
        "start": 2098.52,
        "duration": 5.52,
        "text": "we'll start up and essentially what it's"
      },
      {
        "start": 2101.2,
        "duration": 7.0,
        "text": "doing is is it's creating this uh the"
      },
      {
        "start": 2104.04,
        "duration": 6.76,
        "text": "back end um go away um I'm creating a"
      },
      {
        "start": 2108.2,
        "duration": 5.04,
        "text": "backend that will allow a front end to"
      },
      {
        "start": 2110.8,
        "duration": 5.92,
        "text": "interact and do the this is where the"
      },
      {
        "start": 2113.24,
        "duration": 5.359,
        "text": "rag stuff starts to happen so LL index"
      },
      {
        "start": 2116.72,
        "duration": 3.68,
        "text": "is really involved in there it's"
      },
      {
        "start": 2118.599,
        "duration": 3.721,
        "text": "interacting with Astra on the back end"
      },
      {
        "start": 2120.4,
        "duration": 3.439,
        "text": "Etc now I'm going to create another"
      },
      {
        "start": 2122.32,
        "duration": 5.72,
        "text": "terminal"
      },
      {
        "start": 2123.839,
        "duration": 7.0,
        "text": "here and I'm going to try python script"
      },
      {
        "start": 2128.04,
        "duration": 5.319,
        "text": "so uh this you can"
      },
      {
        "start": 2130.839,
        "duration": 4.681,
        "text": "just copy and paste this and actually"
      },
      {
        "start": 2133.359,
        "duration": 3.841,
        "text": "put a real query in here um one of the"
      },
      {
        "start": 2135.52,
        "duration": 3.24,
        "text": "things I don't like about G pod is you"
      },
      {
        "start": 2137.2,
        "duration": 4.04,
        "text": "can't use the arrow"
      },
      {
        "start": 2138.76,
        "duration": 3.88,
        "text": "key uh but that's okay it's like we're"
      },
      {
        "start": 2141.24,
        "duration": 6.64,
        "text": "terminal from"
      },
      {
        "start": 2142.64,
        "duration": 8.32,
        "text": "1999 um so what like what is"
      },
      {
        "start": 2147.88,
        "duration": 5.52,
        "text": "s because that's the data that I put in"
      },
      {
        "start": 2150.96,
        "duration": 6.68,
        "text": "there and it should give me an answer"
      },
      {
        "start": 2153.4,
        "duration": 8.439,
        "text": "back and after you's finished"
      },
      {
        "start": 2157.64,
        "duration": 6.64,
        "text": "um then it'll say it like a"
      },
      {
        "start": 2161.839,
        "duration": 4.401,
        "text": "pirate which I think is so much cooler"
      },
      {
        "start": 2164.28,
        "duration": 5.64,
        "text": "when you're when you're interacting with"
      },
      {
        "start": 2166.24,
        "duration": 8.64,
        "text": "docs it'll be like Si say"
      },
      {
        "start": 2169.92,
        "duration": 6.919,
        "text": "m um but yeah this is a it never I mean"
      },
      {
        "start": 2174.88,
        "duration": 4.04,
        "text": "if I came up to you and say what's SII"
      },
      {
        "start": 2176.839,
        "duration": 4.721,
        "text": "and you didn't know what it was you may"
      },
      {
        "start": 2178.92,
        "duration": 6.199,
        "text": "hallucinate but in this case it actually"
      },
      {
        "start": 2181.56,
        "duration": 6.2,
        "text": "pulled the information from the docs and"
      },
      {
        "start": 2185.119,
        "duration": 6.121,
        "text": "uh did a pretty good pretty good answer"
      },
      {
        "start": 2187.76,
        "duration": 7.04,
        "text": "because this is right out of the about"
      },
      {
        "start": 2191.24,
        "duration": 7.44,
        "text": "and it gave me the exact"
      },
      {
        "start": 2194.8,
        "duration": 6.519,
        "text": "answer okay uh ye I think we need to"
      },
      {
        "start": 2198.68,
        "duration": 5.56,
        "text": "move on to the next portion of"
      },
      {
        "start": 2201.319,
        "duration": 5.201,
        "text": "this oops awesome um yeah and just to"
      },
      {
        "start": 2204.24,
        "duration": 3.92,
        "text": "answer a couple questions come can you"
      },
      {
        "start": 2206.52,
        "duration": 4.88,
        "text": "touch on structured versus unstructured"
      },
      {
        "start": 2208.16,
        "duration": 4.72,
        "text": "data sources we have a whole bunch of"
      },
      {
        "start": 2211.4,
        "duration": 3.6,
        "text": "different loaders for different types of"
      },
      {
        "start": 2212.88,
        "duration": 4.4,
        "text": "data in llama index that is definitely"
      },
      {
        "start": 2215.0,
        "duration": 4.72,
        "text": "one of those things um that's quite"
      },
      {
        "start": 2217.28,
        "duration": 4.48,
        "text": "important is how you get the data into a"
      },
      {
        "start": 2219.72,
        "duration": 6.08,
        "text": "format that's optimal for"
      },
      {
        "start": 2221.76,
        "duration": 6.2,
        "text": "LS um as Patrick has shown you know he's"
      },
      {
        "start": 2225.8,
        "duration": 4.72,
        "text": "um you know in this example already they"
      },
      {
        "start": 2227.96,
        "duration": 4.24,
        "text": "have uh some of this processing already"
      },
      {
        "start": 2230.52,
        "duration": 4.36,
        "text": "and then um limit on how big the"
      },
      {
        "start": 2232.2,
        "duration": 7.08,
        "text": "knowledge base can be there is no limit"
      },
      {
        "start": 2234.88,
        "duration": 6.12,
        "text": "but but as you get more data there are"
      },
      {
        "start": 2239.28,
        "duration": 3.72,
        "text": "more advanced strategies so so that kind"
      },
      {
        "start": 2241.0,
        "duration": 4.839,
        "text": "of that goes in quite well I think into"
      },
      {
        "start": 2243.0,
        "duration": 4.839,
        "text": "this sort of like next piece of diving"
      },
      {
        "start": 2245.839,
        "duration": 6.121,
        "text": "into llama index so so we can start the"
      },
      {
        "start": 2247.839,
        "duration": 5.641,
        "text": "first slide um this in itself could be"
      },
      {
        "start": 2251.96,
        "duration": 5.52,
        "text": "an hour right"
      },
      {
        "start": 2253.48,
        "duration": 6.32,
        "text": "so we going to talk about two two things"
      },
      {
        "start": 2257.48,
        "duration": 5.359,
        "text": "production Rag and LM quirks right so if"
      },
      {
        "start": 2259.8,
        "duration": 4.76,
        "text": "you want to use lm's and you're a"
      },
      {
        "start": 2262.839,
        "duration": 5.881,
        "text": "developer like I'm a developer I'm not"
      },
      {
        "start": 2264.56,
        "duration": 5.08,
        "text": "scientist right um and this is sort of"
      },
      {
        "start": 2268.72,
        "duration": 3.44,
        "text": "first"
      },
      {
        "start": 2269.64,
        "duration": 4.56,
        "text": "time really you want to be thinking"
      },
      {
        "start": 2272.16,
        "duration": 4.48,
        "text": "about these things like you know like"
      },
      {
        "start": 2274.2,
        "duration": 4.119,
        "text": "first off like how do I get this thing"
      },
      {
        "start": 2276.64,
        "duration": 3.479,
        "text": "production this is why I'm so excited"
      },
      {
        "start": 2278.319,
        "duration": 3.681,
        "text": "about what dat STX is built is because"
      },
      {
        "start": 2280.119,
        "duration": 3.24,
        "text": "they are they they're using this in"
      },
      {
        "start": 2282.0,
        "duration": 4.48,
        "text": "production so you can see what the"
      },
      {
        "start": 2283.359,
        "duration": 7.601,
        "text": "production code looks like um and it's"
      },
      {
        "start": 2286.48,
        "duration": 5.72,
        "text": "open source um so so we'll talk a little"
      },
      {
        "start": 2290.96,
        "duration": 4.24,
        "text": "bit about some of the production rack"
      },
      {
        "start": 2292.2,
        "duration": 4.28,
        "text": "strategies we have in index um if we go"
      },
      {
        "start": 2295.2,
        "duration": 5.76,
        "text": "to the next slide"
      },
      {
        "start": 2296.48,
        "duration": 6.56,
        "text": "here so there you go um so this the"
      },
      {
        "start": 2300.96,
        "duration": 4.399,
        "text": "example I highly recommend you look at"
      },
      {
        "start": 2303.04,
        "duration": 4.84,
        "text": "it it's open source so you can change it"
      },
      {
        "start": 2305.359,
        "duration": 4.121,
        "text": "right you can customiz and that is the"
      },
      {
        "start": 2307.88,
        "duration": 2.68,
        "text": "number one thing when you're building a"
      },
      {
        "start": 2309.48,
        "duration": 3.48,
        "text": "production"
      },
      {
        "start": 2310.56,
        "duration": 5.32,
        "text": "rag production rag pipeline a production"
      },
      {
        "start": 2312.96,
        "duration": 7.2,
        "text": "rag application is thinking about how"
      },
      {
        "start": 2315.88,
        "duration": 7.0,
        "text": "and tuning how the data your data is"
      },
      {
        "start": 2320.16,
        "duration": 4.919,
        "text": "working with that system so data STX has"
      },
      {
        "start": 2322.88,
        "duration": 5.6,
        "text": "done a lot of tuning to make sure that"
      },
      {
        "start": 2325.079,
        "duration": 4.961,
        "text": "it works well with their system um we we"
      },
      {
        "start": 2328.48,
        "duration": 4.119,
        "text": "also have an example this is a different"
      },
      {
        "start": 2330.04,
        "duration": 6.039,
        "text": "type of example it's SEC insights"
      },
      {
        "start": 2332.599,
        "duration": 6.321,
        "text": "similar idea you know how can we tune it"
      },
      {
        "start": 2336.079,
        "duration": 4.24,
        "text": "properly for this particular type of"
      },
      {
        "start": 2338.92,
        "duration": 3.72,
        "text": "document source which in this case is"
      },
      {
        "start": 2340.319,
        "duration": 3.52,
        "text": "SEC vales so if we go to the next slide"
      },
      {
        "start": 2342.64,
        "duration": 3.719,
        "text": "I'll show you a couple of things that we"
      },
      {
        "start": 2343.839,
        "duration": 5.561,
        "text": "have and one is this thing called sub"
      },
      {
        "start": 2346.359,
        "duration": 5.121,
        "text": "question query engine um this is in in"
      },
      {
        "start": 2349.4,
        "duration": 5.12,
        "text": "llama index um there there are"
      },
      {
        "start": 2351.48,
        "duration": 5.359,
        "text": "equivalent things in other um other"
      },
      {
        "start": 2354.52,
        "duration": 5.44,
        "text": "Frameworks also but the idea is to do"
      },
      {
        "start": 2356.839,
        "duration": 4.721,
        "text": "question de decomposition so when a"
      },
      {
        "start": 2359.96,
        "duration": 3.8,
        "text": "question comes in not all questions are"
      },
      {
        "start": 2361.56,
        "duration": 4.039,
        "text": "created equal right when a question"
      },
      {
        "start": 2363.76,
        "duration": 5.64,
        "text": "comes in especially when you have large"
      },
      {
        "start": 2365.599,
        "duration": 7.841,
        "text": "volumes of data you need to think what"
      },
      {
        "start": 2369.4,
        "duration": 6.6,
        "text": "document do I actually want this um this"
      },
      {
        "start": 2373.44,
        "duration": 5.08,
        "text": "question to go to so for example right"
      },
      {
        "start": 2376.0,
        "duration": 4.76,
        "text": "like if you're if you're doing an doing"
      },
      {
        "start": 2378.52,
        "duration": 4.599,
        "text": "a sec filings application like we were"
      },
      {
        "start": 2380.76,
        "duration": 4.96,
        "text": "doing what you don't want to do is you"
      },
      {
        "start": 2383.119,
        "duration": 5.521,
        "text": "don't want to pull the financial data"
      },
      {
        "start": 2385.72,
        "duration": 8.16,
        "text": "for Microsoft when they're asking about"
      },
      {
        "start": 2388.64,
        "duration": 6.04,
        "text": "apple right so um if you go to SEC and I"
      },
      {
        "start": 2393.88,
        "duration": 2.12,
        "text": "don't think we're going to have time"
      },
      {
        "start": 2394.68,
        "duration": 3.439,
        "text": "today to actually play around with it"
      },
      {
        "start": 2396.0,
        "duration": 5.92,
        "text": "but if you go you'll see this sub"
      },
      {
        "start": 2398.119,
        "duration": 6.601,
        "text": "question decomposition in action right"
      },
      {
        "start": 2401.92,
        "duration": 5.199,
        "text": "if if somebody's asking you to compare"
      },
      {
        "start": 2404.72,
        "duration": 5.599,
        "text": "two things right like compare the"
      },
      {
        "start": 2407.119,
        "duration": 6.401,
        "text": "revenue of Microsoft versus Apple then"
      },
      {
        "start": 2410.319,
        "duration": 8.681,
        "text": "you really want to decompose it into two"
      },
      {
        "start": 2413.52,
        "duration": 6.96,
        "text": "questions um to say okay um is Microsoft"
      },
      {
        "start": 2419.0,
        "duration": 3.2,
        "text": "um you know what's the revenue of"
      },
      {
        "start": 2420.48,
        "duration": 4.599,
        "text": "Microsoft what's the revenue of apple"
      },
      {
        "start": 2422.2,
        "duration": 4.76,
        "text": "and then combine them together so um"
      },
      {
        "start": 2425.079,
        "duration": 4.52,
        "text": "this decomposition and the sort of"
      },
      {
        "start": 2426.96,
        "duration": 6.0,
        "text": "categorization of your question is very"
      },
      {
        "start": 2429.599,
        "duration": 6.641,
        "text": "very useful um sub question query engine"
      },
      {
        "start": 2432.96,
        "duration": 4.6,
        "text": "is what we use in SEC insites and um"
      },
      {
        "start": 2436.24,
        "duration": 4.04,
        "text": "there's actually a whole host of"
      },
      {
        "start": 2437.56,
        "duration": 4.12,
        "text": "strategies in this area so so this is"
      },
      {
        "start": 2440.28,
        "duration": 3.96,
        "text": "like sort of like one one production"
      },
      {
        "start": 2441.68,
        "duration": 4.76,
        "text": "rack strategy I'm going to go try talk"
      },
      {
        "start": 2444.24,
        "duration": 4.839,
        "text": "about another one in the next slide I"
      },
      {
        "start": 2446.44,
        "duration": 5.28,
        "text": "think it's the next slide yes okay so"
      },
      {
        "start": 2449.079,
        "duration": 6.24,
        "text": "the next the other strategy that I"
      },
      {
        "start": 2451.72,
        "duration": 5.8,
        "text": "would yes some techn no your"
      },
      {
        "start": 2455.319,
        "duration": 6.121,
        "text": "slides"
      },
      {
        "start": 2457.52,
        "duration": 5.799,
        "text": "um so the next the next strategy is like"
      },
      {
        "start": 2461.44,
        "duration": 3.28,
        "text": "small to big right so so let's back up a"
      },
      {
        "start": 2463.319,
        "duration": 4.321,
        "text": "second real quick right so what are"
      },
      {
        "start": 2464.72,
        "duration": 6.08,
        "text": "embeddings embeddings are like Patrick"
      },
      {
        "start": 2467.64,
        "duration": 5.0,
        "text": "was mentioning these lists of numbers"
      },
      {
        "start": 2470.8,
        "duration": 3.6,
        "text": "that correspond to a specific piece of"
      },
      {
        "start": 2472.64,
        "duration": 3.679,
        "text": "text so that sounds pretty easy right"
      },
      {
        "start": 2474.4,
        "duration": 3.719,
        "text": "you just take the text you chunk you"
      },
      {
        "start": 2476.319,
        "duration": 3.481,
        "text": "chop it up and then you just send it to"
      },
      {
        "start": 2478.119,
        "duration": 6.401,
        "text": "the embeddings and you're"
      },
      {
        "start": 2479.8,
        "duration": 7.88,
        "text": "done except except okay opening eyes and"
      },
      {
        "start": 2484.52,
        "duration": 6.92,
        "text": "beddings are 1,000"
      },
      {
        "start": 2487.68,
        "duration": 5.36,
        "text": "536 floating Point numbers right there's"
      },
      {
        "start": 2491.44,
        "duration": 2.919,
        "text": "really no way it's it's really a black"
      },
      {
        "start": 2493.04,
        "duration": 3.84,
        "text": "box like there's no way for me to go"
      },
      {
        "start": 2494.359,
        "duration": 4.24,
        "text": "into the 1,536 and double check their"
      },
      {
        "start": 2496.88,
        "duration": 2.8,
        "text": "Mark like like oh yeah this this one"
      },
      {
        "start": 2498.599,
        "duration": 2.48,
        "text": "need to be a little higher that one"
      },
      {
        "start": 2499.68,
        "duration": 5.12,
        "text": "needs to be a little lower does not work"
      },
      {
        "start": 2501.079,
        "duration": 5.161,
        "text": "like that right um so what is it"
      },
      {
        "start": 2504.8,
        "duration": 3.92,
        "text": "actually doing what is the model"
      },
      {
        "start": 2506.24,
        "duration": 6.64,
        "text": "actually doing"
      },
      {
        "start": 2508.72,
        "duration": 6.52,
        "text": "um it's a blackbox but if you look at"
      },
      {
        "start": 2512.88,
        "duration": 4.719,
        "text": "the literature around natural language"
      },
      {
        "start": 2515.24,
        "duration": 3.96,
        "text": "processing basically you can think of a"
      },
      {
        "start": 2517.599,
        "duration": 2.52,
        "text": "few different things this doing one is"
      },
      {
        "start": 2519.2,
        "duration": 4.2,
        "text": "actually"
      },
      {
        "start": 2520.119,
        "duration": 4.96,
        "text": "keywords so you're like oh well you know"
      },
      {
        "start": 2523.4,
        "duration": 3.64,
        "text": "ining search it's also called semantic"
      },
      {
        "start": 2525.079,
        "duration": 4.921,
        "text": "so it's about semantic meeting yes so"
      },
      {
        "start": 2527.04,
        "duration": 4.559,
        "text": "semantic meeting is the second one but"
      },
      {
        "start": 2530.0,
        "duration": 4.4,
        "text": "why why would keywords even be involved"
      },
      {
        "start": 2531.599,
        "duration": 5.48,
        "text": "because if you don't have like useful"
      },
      {
        "start": 2534.4,
        "duration": 4.32,
        "text": "keywords if like especially rare"
      },
      {
        "start": 2537.079,
        "duration": 6.161,
        "text": "keywords then you're not going to get"
      },
      {
        "start": 2538.72,
        "duration": 7.48,
        "text": "good search results like um so so rare"
      },
      {
        "start": 2543.24,
        "duration": 4.879,
        "text": "keywords are is one of them um semantic"
      },
      {
        "start": 2546.2,
        "duration": 6.84,
        "text": "mean intention like what's the intention"
      },
      {
        "start": 2548.119,
        "duration": 7.601,
        "text": "of the text um another one that for sure"
      },
      {
        "start": 2553.04,
        "duration": 3.88,
        "text": "is in there in that mix is synonyms"
      },
      {
        "start": 2555.72,
        "duration": 3.32,
        "text": "right so this is this is the place where"
      },
      {
        "start": 2556.92,
        "duration": 5.0,
        "text": "like embedding search becomes magical"
      },
      {
        "start": 2559.04,
        "duration": 5.4,
        "text": "this is like why you you know you think"
      },
      {
        "start": 2561.92,
        "duration": 4.08,
        "text": "okay well I'm not just going to use like"
      },
      {
        "start": 2564.44,
        "duration": 2.8,
        "text": "you know Google Search right like Google"
      },
      {
        "start": 2566.0,
        "duration": 4.52,
        "text": "search has been around for 20 years"
      },
      {
        "start": 2567.24,
        "duration": 5.56,
        "text": "right I'm not going to use like BM 2.5"
      },
      {
        "start": 2570.52,
        "duration": 3.799,
        "text": "to you know just do keyword search on my"
      },
      {
        "start": 2572.8,
        "duration": 5.44,
        "text": "data"
      },
      {
        "start": 2574.319,
        "duration": 6.881,
        "text": "because when embedding search is working"
      },
      {
        "start": 2578.24,
        "duration": 5.52,
        "text": "it's like it can find relationships"
      },
      {
        "start": 2581.2,
        "duration": 4.24,
        "text": "between things that keyword search just"
      },
      {
        "start": 2583.76,
        "duration": 4.28,
        "text": "can't find or you have to like have a"
      },
      {
        "start": 2585.44,
        "duration": 3.84,
        "text": "huge synonym table or you have to you"
      },
      {
        "start": 2588.04,
        "duration": 3.68,
        "text": "know you have to do like a bunch of"
      },
      {
        "start": 2589.28,
        "duration": 4.2,
        "text": "manual special casing with hortic all"
      },
      {
        "start": 2591.72,
        "duration": 3.96,
        "text": "which Google does by the way Google and"
      },
      {
        "start": 2593.48,
        "duration": 4.2,
        "text": "Bing all do this um but embedding search"
      },
      {
        "start": 2595.68,
        "duration": 3.6,
        "text": "just does that for you in an automatic"
      },
      {
        "start": 2597.68,
        "duration": 5.159,
        "text": "way"
      },
      {
        "start": 2599.28,
        "duration": 5.4,
        "text": "um so but now let's think about this a"
      },
      {
        "start": 2602.839,
        "duration": 3.681,
        "text": "little bit so you have this thing that's"
      },
      {
        "start": 2604.68,
        "duration": 3.08,
        "text": "trying to capture the meaning right it's"
      },
      {
        "start": 2606.52,
        "duration": 2.4,
        "text": "trying to capture like like unique"
      },
      {
        "start": 2607.76,
        "duration": 2.319,
        "text": "keywords it's trying to capture a"
      },
      {
        "start": 2608.92,
        "duration": 3.36,
        "text": "meaning it's trying to capture like"
      },
      {
        "start": 2610.079,
        "duration": 6.841,
        "text": "synonyms for those"
      },
      {
        "start": 2612.28,
        "duration": 6.279,
        "text": "meanings then figuring out what to embed"
      },
      {
        "start": 2616.92,
        "duration": 3.6,
        "text": "what chunk of text to embed becomes"
      },
      {
        "start": 2618.559,
        "duration": 5.881,
        "text": "really important because if your chunks"
      },
      {
        "start": 2620.52,
        "duration": 6.559,
        "text": "of text are not are too big right"
      },
      {
        "start": 2624.44,
        "duration": 4.76,
        "text": "they're too big then what happens is"
      },
      {
        "start": 2627.079,
        "duration": 4.0,
        "text": "that meaning"
      },
      {
        "start": 2629.2,
        "duration": 5.639,
        "text": "becomes sort of"
      },
      {
        "start": 2631.079,
        "duration": 5.0,
        "text": "diluted right like all your embeddings"
      },
      {
        "start": 2634.839,
        "duration": 2.561,
        "text": "when when you actually look at the thing"
      },
      {
        "start": 2636.079,
        "duration": 3.76,
        "text": "they start becoming the same like"
      },
      {
        "start": 2637.4,
        "duration": 4.159,
        "text": "they're all very very similar because"
      },
      {
        "start": 2639.839,
        "duration": 6.081,
        "text": "you know you have like this big chunk of"
      },
      {
        "start": 2641.559,
        "duration": 7.081,
        "text": "text in you know over the entire file"
      },
      {
        "start": 2645.92,
        "duration": 6.24,
        "text": "um the meaning becomes very diluted if"
      },
      {
        "start": 2648.64,
        "duration": 5.16,
        "text": "you think about it then the smallest"
      },
      {
        "start": 2652.16,
        "duration": 5.36,
        "text": "chunks of text have the most"
      },
      {
        "start": 2653.8,
        "duration": 5.44,
        "text": "concentrated meaning however however"
      },
      {
        "start": 2657.52,
        "duration": 4.039,
        "text": "there's a limit right so what what is"
      },
      {
        "start": 2659.24,
        "duration": 3.879,
        "text": "the sort of like the smallest chunk of"
      },
      {
        "start": 2661.559,
        "duration": 3.04,
        "text": "text that has the most concentrated"
      },
      {
        "start": 2663.119,
        "duration": 4.44,
        "text": "meaning but still"
      },
      {
        "start": 2664.599,
        "duration": 4.281,
        "text": "has has a coherent meaning right you"
      },
      {
        "start": 2667.559,
        "duration": 4.201,
        "text": "don't want to get to the word because"
      },
      {
        "start": 2668.88,
        "duration": 5.479,
        "text": "the word itself is not a coherent"
      },
      {
        "start": 2671.76,
        "duration": 5.96,
        "text": "intention um so you think it's a"
      },
      {
        "start": 2674.359,
        "duration": 8.681,
        "text": "sentence and that's true oh oh sorry no"
      },
      {
        "start": 2677.72,
        "duration": 7.72,
        "text": "worries it's a sentence right so um and"
      },
      {
        "start": 2683.04,
        "duration": 4.519,
        "text": "that's where you know the smallest chunk"
      },
      {
        "start": 2685.44,
        "duration": 4.72,
        "text": "of text is so so we're going to try that"
      },
      {
        "start": 2687.559,
        "duration": 5.04,
        "text": "so I wrote a couple sentences I I think"
      },
      {
        "start": 2690.16,
        "duration": 4.28,
        "text": "it's the next slide we'll see I I got"
      },
      {
        "start": 2692.599,
        "duration": 5.24,
        "text": "we're gonna find out we're gonna find"
      },
      {
        "start": 2694.44,
        "duration": 7.04,
        "text": "out right so oh no the next slide sorry"
      },
      {
        "start": 2697.839,
        "duration": 5.081,
        "text": "so small to big embed small retrieve big"
      },
      {
        "start": 2701.48,
        "duration": 3.92,
        "text": "that's the strategy we're GNA use and"
      },
      {
        "start": 2702.92,
        "duration": 8.04,
        "text": "here's why okay so so so we'll go to"
      },
      {
        "start": 2705.4,
        "duration": 7.76,
        "text": "next I'll show you ESRB are you making"
      },
      {
        "start": 2710.96,
        "duration": 4.24,
        "text": "word I'm calling it small to big on"
      },
      {
        "start": 2713.16,
        "duration": 4.08,
        "text": "Twitter but I'm like maybe maybe maybe"
      },
      {
        "start": 2715.2,
        "duration": 3.48,
        "text": "we should call it the esrv strategy yeah"
      },
      {
        "start": 2717.24,
        "duration": 3.24,
        "text": "I think everyone that's watching should"
      },
      {
        "start": 2718.68,
        "duration": 3.159,
        "text": "shime in here so yeah we'll just"
      },
      {
        "start": 2720.48,
        "duration": 3.839,
        "text": "Outsource this right now we'll go to the"
      },
      {
        "start": 2721.839,
        "duration": 4.441,
        "text": "next slide but if you have an idea throw"
      },
      {
        "start": 2724.319,
        "duration": 3.52,
        "text": "it in the chat because clearly year"
      },
      {
        "start": 2726.28,
        "duration": 4.72,
        "text": "needs it ye needs his"
      },
      {
        "start": 2727.839,
        "duration": 5.441,
        "text": "Workshop yes okay so so here here here's"
      },
      {
        "start": 2731.0,
        "duration": 4.64,
        "text": "our text right fairly straightforward"
      },
      {
        "start": 2733.28,
        "duration": 3.88,
        "text": "Patrick mcon is software engineer and VP"
      },
      {
        "start": 2735.64,
        "duration": 4.76,
        "text": "of development relations he started with"
      },
      {
        "start": 2737.16,
        "duration": 5.24,
        "text": "d STX in 2012 previously M worked at"
      },
      {
        "start": 2740.4,
        "duration": 4.24,
        "text": "Hopson as their Chief Architect okay"
      },
      {
        "start": 2742.4,
        "duration": 5.159,
        "text": "very very simple straightforward three"
      },
      {
        "start": 2744.64,
        "duration": 5.6,
        "text": "sentences and then we have the query"
      },
      {
        "start": 2747.559,
        "duration": 6.28,
        "text": "where does Patrick mum work I incourage"
      },
      {
        "start": 2750.24,
        "duration": 6.24,
        "text": "you to try this out using as okay like"
      },
      {
        "start": 2753.839,
        "duration": 3.641,
        "text": "literally you know you know Patrick is"
      },
      {
        "start": 2756.48,
        "duration": 2.639,
        "text": "showing you you have to do like all"
      },
      {
        "start": 2757.48,
        "duration": 3.68,
        "text": "these embs These are three embeddings"
      },
      {
        "start": 2759.119,
        "duration": 5.641,
        "text": "like literally three vectors and then"
      },
      {
        "start": 2761.16,
        "duration": 5.84,
        "text": "you add one more Vector for the qu um so"
      },
      {
        "start": 2764.76,
        "duration": 3.76,
        "text": "Patrick tell a guess which sentence like"
      },
      {
        "start": 2767.0,
        "duration": 5.48,
        "text": "if we've eded each sentence which"
      },
      {
        "start": 2768.52,
        "duration": 6.4,
        "text": "sentence do you think would uh would the"
      },
      {
        "start": 2772.48,
        "duration": 5.639,
        "text": "embedding model say is the most uh"
      },
      {
        "start": 2774.92,
        "duration": 5.919,
        "text": "nearest neighbor the the the most"
      },
      {
        "start": 2778.119,
        "duration": 6.44,
        "text": "relevant uh probably"
      },
      {
        "start": 2780.839,
        "duration": 5.641,
        "text": "the second one because second right"
      },
      {
        "start": 2784.559,
        "duration": 4.241,
        "text": "right he he started with with data"
      },
      {
        "start": 2786.48,
        "duration": 5.16,
        "text": "Stacks in 2012 that makes the most sense"
      },
      {
        "start": 2788.8,
        "duration": 5.88,
        "text": "that's the one that you we care about I"
      },
      {
        "start": 2791.64,
        "duration": 6.52,
        "text": "have to say Patrick you're wrong um why"
      },
      {
        "start": 2794.68,
        "duration": 5.399,
        "text": "I was so close why I had a 5050 chance"
      },
      {
        "start": 2798.16,
        "duration": 3.76,
        "text": "so so we go I'll show you I'll show you"
      },
      {
        "start": 2800.079,
        "duration": 4.721,
        "text": "what the actual answer"
      },
      {
        "start": 2801.92,
        "duration": 4.76,
        "text": "is all right all right here we go the"
      },
      {
        "start": 2804.8,
        "duration": 4.759,
        "text": "right answer"
      },
      {
        "start": 2806.68,
        "duration": 6.24,
        "text": "is it's probably it's probably the third"
      },
      {
        "start": 2809.559,
        "duration": 5.481,
        "text": "one okay and and why why is that um"
      },
      {
        "start": 2812.92,
        "duration": 3.48,
        "text": "because mcfaden is not a very common"
      },
      {
        "start": 2815.04,
        "duration": 4.44,
        "text": "word"
      },
      {
        "start": 2816.4,
        "duration": 5.28,
        "text": "no right and so the second sentence"
      },
      {
        "start": 2819.48,
        "duration": 4.359,
        "text": "which has the right information in it"
      },
      {
        "start": 2821.68,
        "duration": 5.28,
        "text": "does not have the word mcfaden in it"
      },
      {
        "start": 2823.839,
        "duration": 8.561,
        "text": "right so the model even though once"
      },
      {
        "start": 2826.96,
        "duration": 9.76,
        "text": "again is a black box um it is not"
      },
      {
        "start": 2832.4,
        "duration": 7.12,
        "text": "um it's not going to prefer that second"
      },
      {
        "start": 2836.72,
        "duration": 4.16,
        "text": "sentence um in fact it's going to prefer"
      },
      {
        "start": 2839.52,
        "duration": 3.68,
        "text": "if you go to the next slide it's going"
      },
      {
        "start": 2840.88,
        "duration": 3.56,
        "text": "to prefer the first and third sentences"
      },
      {
        "start": 2843.2,
        "duration": 3.639,
        "text": "these are the sentences that's probably"
      },
      {
        "start": 2844.44,
        "duration": 6.159,
        "text": "going to pick out with the top of"
      },
      {
        "start": 2846.839,
        "duration": 5.441,
        "text": "two so here this is this is where it"
      },
      {
        "start": 2850.599,
        "duration": 3.281,
        "text": "becomes very important right so"
      },
      {
        "start": 2852.28,
        "duration": 3.079,
        "text": "obviously you like okay well we just"
      },
      {
        "start": 2853.88,
        "duration": 2.959,
        "text": "embed more right we just embed the whole"
      },
      {
        "start": 2855.359,
        "duration": 3.561,
        "text": "thing right we can embed the whole thing"
      },
      {
        "start": 2856.839,
        "duration": 4.28,
        "text": "but then once again the the embedding"
      },
      {
        "start": 2858.92,
        "duration": 4.919,
        "text": "becomes diluted so if you want the most"
      },
      {
        "start": 2861.119,
        "duration": 7.081,
        "text": "concentrated embeddings but you still"
      },
      {
        "start": 2863.839,
        "duration": 6.52,
        "text": "want to get the relevant information you"
      },
      {
        "start": 2868.2,
        "duration": 4.56,
        "text": "have to use this embed small retrieve"
      },
      {
        "start": 2870.359,
        "duration": 5.121,
        "text": "big strategy and we found in production"
      },
      {
        "start": 2872.76,
        "duration": 4.28,
        "text": "with other people that it really does"
      },
      {
        "start": 2875.48,
        "duration": 5.2,
        "text": "work"
      },
      {
        "start": 2877.04,
        "duration": 5.16,
        "text": "um so we have two built-in modules in L"
      },
      {
        "start": 2880.68,
        "duration": 4.72,
        "text": "Index this is something that we are"
      },
      {
        "start": 2882.2,
        "duration": 7.76,
        "text": "actively doing so if we go to next"
      },
      {
        "start": 2885.4,
        "duration": 5.76,
        "text": "slide you check out one is one is called"
      },
      {
        "start": 2889.96,
        "duration": 3.399,
        "text": "I was gonna say that's a really"
      },
      {
        "start": 2891.16,
        "duration": 6.56,
        "text": "interesting I I never thought about like"
      },
      {
        "start": 2893.359,
        "duration": 9.76,
        "text": "names being triggers for bad a&n"
      },
      {
        "start": 2897.72,
        "duration": 8.04,
        "text": "searches but that's so true yeah because"
      },
      {
        "start": 2903.119,
        "duration": 4.321,
        "text": "you're like well why you know this this"
      },
      {
        "start": 2905.76,
        "duration": 5.2,
        "text": "is stupider than we thought right but"
      },
      {
        "start": 2907.44,
        "duration": 6.04,
        "text": "it's not because if you think about it"
      },
      {
        "start": 2910.96,
        "duration": 5.159,
        "text": "like what if it went and you know"
      },
      {
        "start": 2913.48,
        "duration": 4.04,
        "text": "because he said does this blah blah blah"
      },
      {
        "start": 2916.119,
        "duration": 2.521,
        "text": "what if it goes and picks up another"
      },
      {
        "start": 2917.52,
        "duration": 2.68,
        "text": "sentence from like you know somebody"
      },
      {
        "start": 2918.64,
        "duration": 5.0,
        "text": "else's bio right that you put in your"
      },
      {
        "start": 2920.2,
        "duration": 5.48,
        "text": "database right doing picking out the"
      },
      {
        "start": 2923.64,
        "duration": 6.199,
        "text": "ones the sentences of MC feden is"
      },
      {
        "start": 2925.68,
        "duration": 6.6,
        "text": "actually the safe smart thing to do um"
      },
      {
        "start": 2929.839,
        "duration": 3.801,
        "text": "but it does not give you the full"
      },
      {
        "start": 2932.28,
        "duration": 2.72,
        "text": "context that you need so so that's"
      },
      {
        "start": 2933.64,
        "duration": 2.84,
        "text": "that's where we have the notes on this"
      },
      {
        "start": 2935.0,
        "duration": 3.44,
        "text": "window window"
      },
      {
        "start": 2936.48,
        "duration": 4.72,
        "text": "strategy um we have another one if you"
      },
      {
        "start": 2938.44,
        "duration": 5.159,
        "text": "go to next slide uh similar idea it's"
      },
      {
        "start": 2941.2,
        "duration": 4.2,
        "text": "called the autom mering Retriever and"
      },
      {
        "start": 2943.599,
        "duration": 2.841,
        "text": "similar idea is like basically hey you"
      },
      {
        "start": 2945.4,
        "duration": 2.48,
        "text": "know if you're retrieving a bunch of"
      },
      {
        "start": 2946.44,
        "duration": 2.96,
        "text": "small chunks and like we see that you're"
      },
      {
        "start": 2947.88,
        "duration": 3.679,
        "text": "retrieving all of these then we're just"
      },
      {
        "start": 2949.4,
        "duration": 3.439,
        "text": "going to combine it so you also get the"
      },
      {
        "start": 2951.559,
        "duration": 3.28,
        "text": "you know if you're retrieving the first"
      },
      {
        "start": 2952.839,
        "duration": 3.52,
        "text": "second and fourth sentences we're going"
      },
      {
        "start": 2954.839,
        "duration": 3.361,
        "text": "to give you the third sentence also in"
      },
      {
        "start": 2956.359,
        "duration": 4.24,
        "text": "the retrieval because it's probably"
      },
      {
        "start": 2958.2,
        "duration": 4.119,
        "text": "important even though the even though"
      },
      {
        "start": 2960.599,
        "duration": 4.24,
        "text": "the embedding model doesn't think it's"
      },
      {
        "start": 2962.319,
        "duration": 4.48,
        "text": "that close so if we go to the next slide"
      },
      {
        "start": 2964.839,
        "duration": 3.041,
        "text": "here"
      },
      {
        "start": 2966.799,
        "duration": 3.841,
        "text": "okay"
      },
      {
        "start": 2967.88,
        "duration": 5.52,
        "text": "so this this is the other thing that you"
      },
      {
        "start": 2970.64,
        "duration": 5.88,
        "text": "have to be aware of um you know p patj"
      },
      {
        "start": 2973.4,
        "duration": 5.0,
        "text": "and I are old techies so we remember qus"
      },
      {
        "start": 2976.52,
        "duration": 4.68,
        "text": "mode right so you have Netscape"
      },
      {
        "start": 2978.4,
        "duration": 6.8,
        "text": "Navigator here this is iie I think this"
      },
      {
        "start": 2981.2,
        "duration": 8.04,
        "text": "is I4 right classic classic I4 good old"
      },
      {
        "start": 2985.2,
        "duration": 6.32,
        "text": "days right and uh and and you know the"
      },
      {
        "start": 2989.24,
        "duration": 4.119,
        "text": "painful thing of having to make sure to"
      },
      {
        "start": 2991.52,
        "duration": 4.799,
        "text": "support these browsers for years and"
      },
      {
        "start": 2993.359,
        "duration": 4.48,
        "text": "years later um so so the web development"
      },
      {
        "start": 2996.319,
        "duration": 5.441,
        "text": "Community came up with this idea of"
      },
      {
        "start": 2997.839,
        "duration": 7.361,
        "text": "corks mode right"
      },
      {
        "start": 3001.76,
        "duration": 6.28,
        "text": "um why because when these browsers came"
      },
      {
        "start": 3005.2,
        "duration": 5.76,
        "text": "out they were you know very rough right"
      },
      {
        "start": 3008.04,
        "duration": 5.84,
        "text": "like the the their treatment of HTML of"
      },
      {
        "start": 3010.96,
        "duration": 6.44,
        "text": "of JavaScript of CSS was all very very"
      },
      {
        "start": 3013.88,
        "duration": 5.959,
        "text": "rough um similarly right now since we"
      },
      {
        "start": 3017.4,
        "duration": 5.719,
        "text": "are very very early literally very very"
      },
      {
        "start": 3019.839,
        "duration": 6.161,
        "text": "early if we go to the next slide um we"
      },
      {
        "start": 3023.119,
        "duration": 5.881,
        "text": "are in LM quirks mode like literally"
      },
      {
        "start": 3026.0,
        "duration": 5.24,
        "text": "these things you know open Ai and propic"
      },
      {
        "start": 3029.0,
        "duration": 5.119,
        "text": "llama 2 like they've come out literally"
      },
      {
        "start": 3031.24,
        "duration": 5.28,
        "text": "months ago right opening I just"
      },
      {
        "start": 3034.119,
        "duration": 4.921,
        "text": "announced four turbo like I don't know"
      },
      {
        "start": 3036.52,
        "duration": 6.0,
        "text": "like less than a month ago and fra came"
      },
      {
        "start": 3039.04,
        "duration": 5.84,
        "text": "out with quad 2.1 I think like two weeks"
      },
      {
        "start": 3042.52,
        "duration": 5.72,
        "text": "ago lamu has been around for like four"
      },
      {
        "start": 3044.88,
        "duration": 4.719,
        "text": "or five months they have a lot of quirks"
      },
      {
        "start": 3048.24,
        "duration": 2.359,
        "text": "um once again this is a whole"
      },
      {
        "start": 3049.599,
        "duration": 2.52,
        "text": "presentation but I'm just going to show"
      },
      {
        "start": 3050.599,
        "duration": 6.121,
        "text": "you a couple quirks real real real"
      },
      {
        "start": 3052.119,
        "duration": 6.401,
        "text": "simple so qu number one um"
      },
      {
        "start": 3056.72,
        "duration": 4.52,
        "text": "what does decreasing temperature do in"
      },
      {
        "start": 3058.52,
        "duration": 5.44,
        "text": "and out okay I'm not going to this"
      },
      {
        "start": 3061.24,
        "duration": 4.64,
        "text": "shouldn't be too too embarrassing uh"
      },
      {
        "start": 3063.96,
        "duration": 4.359,
        "text": "what what does decreasing top PE do in"
      },
      {
        "start": 3065.88,
        "duration": 3.679,
        "text": "LM Patrick do do you know the the first"
      },
      {
        "start": 3068.319,
        "duration": 2.601,
        "text": "one decreasing temperature what happens"
      },
      {
        "start": 3069.559,
        "duration": 5.8,
        "text": "if you turn down the"
      },
      {
        "start": 3070.92,
        "duration": 6.28,
        "text": "temperature uh you get a a less spec"
      },
      {
        "start": 3075.359,
        "duration": 3.76,
        "text": "well you get less spicy answers you get"
      },
      {
        "start": 3077.2,
        "duration": 3.72,
        "text": "more generalized answers right you get"
      },
      {
        "start": 3079.119,
        "duration": 4.401,
        "text": "less spicy answers it becomes less"
      },
      {
        "start": 3080.92,
        "duration": 5.72,
        "text": "random right I'm using the word spicy in"
      },
      {
        "start": 3083.52,
        "duration": 6.559,
        "text": "a very technical way yes yeah the"
      },
      {
        "start": 3086.64,
        "duration": 7.32,
        "text": "technical word spicy decreasing top p in"
      },
      {
        "start": 3090.079,
        "duration": 7.601,
        "text": "an LM does the same thing it also makes"
      },
      {
        "start": 3093.96,
        "duration": 6.119,
        "text": "the um it also makes the answers less"
      },
      {
        "start": 3097.68,
        "duration": 5.56,
        "text": "random and if we go to the third"
      },
      {
        "start": 3100.079,
        "duration": 5.04,
        "text": "question all right what does decrease in"
      },
      {
        "start": 3103.24,
        "duration": 4.879,
        "text": "top K do in an L I'm gonna tell you it"
      },
      {
        "start": 3105.119,
        "duration": 6.72,
        "text": "does exactly the same thing it makes the"
      },
      {
        "start": 3108.119,
        "duration": 5.96,
        "text": "answers less random so this is how we"
      },
      {
        "start": 3111.839,
        "duration": 3.801,
        "text": "know we're in quirks mode right because"
      },
      {
        "start": 3114.079,
        "duration": 3.601,
        "text": "you think you know your software product"
      },
      {
        "start": 3115.64,
        "duration": 3.479,
        "text": "engineer been doing this for a while why"
      },
      {
        "start": 3117.68,
        "duration": 4.0,
        "text": "do we have three knobs that do basically"
      },
      {
        "start": 3119.119,
        "duration": 4.281,
        "text": "the same thing well because it's these"
      },
      {
        "start": 3121.68,
        "duration": 4.96,
        "text": "things were built by product Engineers"
      },
      {
        "start": 3123.4,
        "duration": 4.52,
        "text": "they're built by mathematicians right so"
      },
      {
        "start": 3126.64,
        "duration": 2.52,
        "text": "the mathematicians said well you know"
      },
      {
        "start": 3127.92,
        "duration": 2.96,
        "text": "each of these things does a different"
      },
      {
        "start": 3129.16,
        "duration": 4.919,
        "text": "thing mathematically which is true which"
      },
      {
        "start": 3130.88,
        "duration": 4.679,
        "text": "is true but from from from you know a"
      },
      {
        "start": 3134.079,
        "duration": 3.961,
        "text": "developer from a software developer who"
      },
      {
        "start": 3135.559,
        "duration": 3.961,
        "text": "just wants to get something to work it's"
      },
      {
        "start": 3138.04,
        "duration": 3.92,
        "text": "kind of annoying that we have three"
      },
      {
        "start": 3139.52,
        "duration": 4.76,
        "text": "knobs that do very very similar things"
      },
      {
        "start": 3141.96,
        "duration": 3.839,
        "text": "so if we go to next"
      },
      {
        "start": 3144.28,
        "duration": 4.279,
        "text": "slide"
      },
      {
        "start": 3145.799,
        "duration": 4.481,
        "text": "um related right so often times when we"
      },
      {
        "start": 3148.559,
        "duration": 3.681,
        "text": "deal with computers right we want the"
      },
      {
        "start": 3150.28,
        "duration": 4.16,
        "text": "computer to return the same thing to us"
      },
      {
        "start": 3152.24,
        "duration": 3.8,
        "text": "every time this is this you know I've"
      },
      {
        "start": 3154.44,
        "duration": 3.96,
        "text": "been programming as a software developer"
      },
      {
        "start": 3156.04,
        "duration": 4.799,
        "text": "for 20 years I want to make sure"
      },
      {
        "start": 3158.4,
        "duration": 3.8,
        "text": "everything's reproducible right you know"
      },
      {
        "start": 3160.839,
        "duration": 3.841,
        "text": "you don't want to have like these bugs"
      },
      {
        "start": 3162.2,
        "duration": 5.599,
        "text": "that come in like you know only when the"
      },
      {
        "start": 3164.68,
        "duration": 6.32,
        "text": "customer is you know in you know on"
      },
      {
        "start": 3167.799,
        "duration": 5.441,
        "text": "vacation in the Japan or you know like"
      },
      {
        "start": 3171.0,
        "duration": 5.319,
        "text": "you want things to do the same thing"
      },
      {
        "start": 3173.24,
        "duration": 5.48,
        "text": "every time and with lm's you want the"
      },
      {
        "start": 3176.319,
        "duration": 4.28,
        "text": "same result every time so what do we do"
      },
      {
        "start": 3178.72,
        "duration": 4.68,
        "text": "well the sort of if we go to next Slide"
      },
      {
        "start": 3180.599,
        "duration": 4.76,
        "text": "the sort of very classic thing is to set"
      },
      {
        "start": 3183.4,
        "duration": 3.719,
        "text": "the temperature to zero right because"
      },
      {
        "start": 3185.359,
        "duration": 5.401,
        "text": "like we said we decrease the temperature"
      },
      {
        "start": 3187.119,
        "duration": 4.881,
        "text": "knob you turn it down um it becomes less"
      },
      {
        "start": 3190.76,
        "duration": 2.079,
        "text": "random if you turn it down all the way"
      },
      {
        "start": 3192.0,
        "duration": 3.28,
        "text": "to"
      },
      {
        "start": 3192.839,
        "duration": 6.641,
        "text": "zero then that's as low as you can turn"
      },
      {
        "start": 3195.28,
        "duration": 7.48,
        "text": "it right pretty boring yeah so does that"
      },
      {
        "start": 3199.48,
        "duration": 6.4,
        "text": "work well next slide let's"
      },
      {
        "start": 3202.76,
        "duration": 5.4,
        "text": "see no it doesn't so"
      },
      {
        "start": 3205.88,
        "duration": 4.919,
        "text": "um AMJ last year you know was like yeah"
      },
      {
        "start": 3208.16,
        "duration": 5.88,
        "text": "no even at temperature zero it does not"
      },
      {
        "start": 3210.799,
        "duration": 5.32,
        "text": "actually give deterministic output okay"
      },
      {
        "start": 3214.04,
        "duration": 3.519,
        "text": "um so this is this is one of the things"
      },
      {
        "start": 3216.119,
        "duration": 5.641,
        "text": "that you have to deal with as an"
      },
      {
        "start": 3217.559,
        "duration": 8.441,
        "text": "engineer as an AI engineer so next"
      },
      {
        "start": 3221.76,
        "duration": 5.839,
        "text": "slide but wait there's more okay so not"
      },
      {
        "start": 3226.0,
        "duration": 3.0,
        "text": "only so okay you're like well maybe"
      },
      {
        "start": 3227.599,
        "duration": 3.24,
        "text": "maybe it's okay because you know temp"
      },
      {
        "start": 3229.0,
        "duration": 3.44,
        "text": "zero does make it more deterministic"
      },
      {
        "start": 3230.839,
        "duration": 3.52,
        "text": "it's just not entirely deterministic"
      },
      {
        "start": 3232.44,
        "duration": 3.679,
        "text": "right you know you might get like four"
      },
      {
        "start": 3234.359,
        "duration": 5.24,
        "text": "or five different answers instead of you"
      },
      {
        "start": 3236.119,
        "duration": 4.561,
        "text": "know a million different answers so but"
      },
      {
        "start": 3239.599,
        "duration": 4.121,
        "text": "there's actually there's actually a"
      },
      {
        "start": 3240.68,
        "duration": 4.28,
        "text": "bigger problem with temp z um so if we"
      },
      {
        "start": 3243.72,
        "duration": 4.2,
        "text": "go to next"
      },
      {
        "start": 3244.96,
        "duration": 5.96,
        "text": "slide temp zero makes the model"
      },
      {
        "start": 3247.92,
        "duration": 7.28,
        "text": "Dumber um this is well documented and"
      },
      {
        "start": 3250.92,
        "duration": 6.679,
        "text": "for a long time like even even in the AI"
      },
      {
        "start": 3255.2,
        "duration": 5.2,
        "text": "hacking Community we weren't sure why um"
      },
      {
        "start": 3257.599,
        "duration": 4.801,
        "text": "but then I came came grab this paper uh"
      },
      {
        "start": 3260.4,
        "duration": 3.36,
        "text": "written by this guy hugging face so the"
      },
      {
        "start": 3262.4,
        "duration": 4.12,
        "text": "next"
      },
      {
        "start": 3263.76,
        "duration": 4.0,
        "text": "slide um so so he wrote this paper and"
      },
      {
        "start": 3266.52,
        "duration": 3.96,
        "text": "he basically said look you know what"
      },
      {
        "start": 3267.76,
        "duration": 5.039,
        "text": "happens when you make temp equals zero"
      },
      {
        "start": 3270.48,
        "duration": 5.119,
        "text": "is the search becomes a greedy search"
      },
      {
        "start": 3272.799,
        "duration": 6.641,
        "text": "and it always picks the absolute most"
      },
      {
        "start": 3275.599,
        "duration": 7.121,
        "text": "probable next token but that inhibits"
      },
      {
        "start": 3279.44,
        "duration": 6.2,
        "text": "the L's ability to look ahead several"
      },
      {
        "start": 3282.72,
        "duration": 5.879,
        "text": "tokens and find the token that's like"
      },
      {
        "start": 3285.64,
        "duration": 5.4,
        "text": "you know the the tokens that are like"
      },
      {
        "start": 3288.599,
        "duration": 5.601,
        "text": "three tokens deep that are actually more"
      },
      {
        "start": 3291.04,
        "duration": 6.319,
        "text": "probable than just the absolute next"
      },
      {
        "start": 3294.2,
        "duration": 4.96,
        "text": "token you and yeah it's interesting"
      },
      {
        "start": 3297.359,
        "duration": 3.281,
        "text": "because I this particular thing I"
      },
      {
        "start": 3299.16,
        "duration": 3.959,
        "text": "remember somebody giving me a really"
      },
      {
        "start": 3300.64,
        "duration": 5.56,
        "text": "good analogy about is like um early"
      },
      {
        "start": 3303.119,
        "duration": 5.761,
        "text": "chess programs like way back in the day"
      },
      {
        "start": 3306.2,
        "duration": 4.879,
        "text": "they were as good as how many moves that"
      },
      {
        "start": 3308.88,
        "duration": 4.88,
        "text": "they tried to do ahead"
      },
      {
        "start": 3311.079,
        "duration": 5.801,
        "text": "right yeah if you had a chess program"
      },
      {
        "start": 3313.76,
        "duration": 4.92,
        "text": "that was on your like your old Apple 2"
      },
      {
        "start": 3316.88,
        "duration": 4.52,
        "text": "it would do like three or four moves"
      },
      {
        "start": 3318.68,
        "duration": 4.28,
        "text": "ahead and that's it and you know it"
      },
      {
        "start": 3321.4,
        "duration": 4.52,
        "text": "wasn't very it wasn't forward-looking"
      },
      {
        "start": 3322.96,
        "duration": 5.2,
        "text": "but as computers got more powerful it"
      },
      {
        "start": 3325.92,
        "duration": 4.159,
        "text": "would look hundreds or thousands of"
      },
      {
        "start": 3328.16,
        "duration": 4.24,
        "text": "moves ahead and predict like create this"
      },
      {
        "start": 3330.079,
        "duration": 4.641,
        "text": "prediction tree and say oh this is the"
      },
      {
        "start": 3332.4,
        "duration": 4.12,
        "text": "best path based on all the different"
      },
      {
        "start": 3334.72,
        "duration": 3.96,
        "text": "permutations and I I thought that was"
      },
      {
        "start": 3336.52,
        "duration": 4.599,
        "text": "really interesting because it is just"
      },
      {
        "start": 3338.68,
        "duration": 6.8,
        "text": "like that right that is exactly what the"
      },
      {
        "start": 3341.119,
        "duration": 6.081,
        "text": "Alum is doing but it also so um it's"
      },
      {
        "start": 3345.48,
        "duration": 3.72,
        "text": "also doing because there's so many"
      },
      {
        "start": 3347.2,
        "duration": 4.919,
        "text": "choices right because unlike chess right"
      },
      {
        "start": 3349.2,
        "duration": 5.639,
        "text": "because chest this tree is relative I"
      },
      {
        "start": 3352.119,
        "duration": 4.561,
        "text": "mean it's still a very large tree don't"
      },
      {
        "start": 3354.839,
        "duration": 5.681,
        "text": "get get me wrong but it's relatively"
      },
      {
        "start": 3356.68,
        "duration": 5.72,
        "text": "narrow in lm's case at every token"
      },
      {
        "start": 3360.52,
        "duration": 3.519,
        "text": "there's literally tens of thousands"
      },
      {
        "start": 3362.4,
        "duration": 3.679,
        "text": "hundreds of thousands of"
      },
      {
        "start": 3364.039,
        "duration": 4.08,
        "text": "choices"
      },
      {
        "start": 3366.079,
        "duration": 5.72,
        "text": "um"
      },
      {
        "start": 3368.119,
        "duration": 4.881,
        "text": "LMS can perform their smartness by doing"
      },
      {
        "start": 3371.799,
        "duration": 3.24,
        "text": "it"
      },
      {
        "start": 3373.0,
        "duration": 3.96,
        "text": "probabilistically right but when you set"
      },
      {
        "start": 3375.039,
        "duration": 5.481,
        "text": "temp to zero you take away that"
      },
      {
        "start": 3376.96,
        "duration": 4.72,
        "text": "probabilistic ability and then it then"
      },
      {
        "start": 3380.52,
        "duration": 2.559,
        "text": "just says okay well I'm just going to"
      },
      {
        "start": 3381.68,
        "duration": 3.76,
        "text": "give you the the the absolute most"
      },
      {
        "start": 3383.079,
        "duration": 4.121,
        "text": "probable one so so they do a sample so"
      },
      {
        "start": 3385.44,
        "duration": 3.96,
        "text": "so they they they sampled the"
      },
      {
        "start": 3387.2,
        "duration": 3.399,
        "text": "distribution and temperature so this is"
      },
      {
        "start": 3389.4,
        "duration": 3.679,
        "text": "where the math comes and temperature"
      },
      {
        "start": 3390.599,
        "duration": 4.0,
        "text": "technically is is actually cont"
      },
      {
        "start": 3393.079,
        "duration": 3.161,
        "text": "controlling the shape of that"
      },
      {
        "start": 3394.599,
        "duration": 6.081,
        "text": "probability"
      },
      {
        "start": 3396.24,
        "duration": 7.839,
        "text": "distribution um so so yeah so so there"
      },
      {
        "start": 3400.68,
        "duration": 5.679,
        "text": "are many many many quirks out there for"
      },
      {
        "start": 3404.079,
        "duration": 4.801,
        "text": "LMS so soort of where I wanted to leave"
      },
      {
        "start": 3406.359,
        "duration": 4.601,
        "text": "you all at is if we go to the next"
      },
      {
        "start": 3408.88,
        "duration": 4.159,
        "text": "slide is that one day there will be"
      },
      {
        "start": 3410.96,
        "duration": 5.599,
        "text": "standards mode right like I said I"
      },
      {
        "start": 3413.039,
        "duration": 5.241,
        "text": "believe that one day most programs if"
      },
      {
        "start": 3416.559,
        "duration": 5.721,
        "text": "not all programs are going to use l in"
      },
      {
        "start": 3418.28,
        "duration": 8.839,
        "text": "some capacity one day they will work um"
      },
      {
        "start": 3422.28,
        "duration": 8.92,
        "text": "in a very predictable way but next"
      },
      {
        "start": 3427.119,
        "duration": 5.2,
        "text": "slide that's not today right so one of"
      },
      {
        "start": 3431.2,
        "duration": 3.2,
        "text": "the questions why do you want to use"
      },
      {
        "start": 3432.319,
        "duration": 4.441,
        "text": "llama index next"
      },
      {
        "start": 3434.4,
        "duration": 3.32,
        "text": "slide you can let us deal with the qus"
      },
      {
        "start": 3436.76,
        "duration": 4.2,
        "text": "instead of having to deal with them"
      },
      {
        "start": 3437.72,
        "duration": 6.68,
        "text": "yourself so yeah that's that's the end"
      },
      {
        "start": 3440.96,
        "duration": 4.68,
        "text": "of uh my section I see a couple of"
      },
      {
        "start": 3444.4,
        "duration": 3.959,
        "text": "questions is"
      },
      {
        "start": 3445.64,
        "duration": 4.28,
        "text": "here yeah let's let's uh we're we're"
      },
      {
        "start": 3448.359,
        "duration": 3.321,
        "text": "kind of at the top of the hour actually"
      },
      {
        "start": 3449.92,
        "duration": 3.399,
        "text": "totally are at the top of the hour um I"
      },
      {
        "start": 3451.68,
        "duration": 3.32,
        "text": "think now let's just jump into some"
      },
      {
        "start": 3453.319,
        "duration": 6.0,
        "text": "questions there's some really good ones"
      },
      {
        "start": 3455.0,
        "duration": 7.839,
        "text": "on here um and SE didn't have a question"
      },
      {
        "start": 3459.319,
        "duration": 7.401,
        "text": "he he has a bug report for us uh back"
      },
      {
        "start": 3462.839,
        "duration": 5.441,
        "text": "online yes yes good job yes so try try"
      },
      {
        "start": 3466.72,
        "duration": 4.0,
        "text": "it out and and more importantly look at"
      },
      {
        "start": 3468.28,
        "duration": 6.68,
        "text": "the source code because they did a great"
      },
      {
        "start": 3470.72,
        "duration": 5.96,
        "text": "job oh man I gotta go back find that"
      },
      {
        "start": 3474.96,
        "duration": 4.159,
        "text": "what was the what was the URL hang on"
      },
      {
        "start": 3476.68,
        "duration": 6.28,
        "text": "talk with us hang on let me let me talk"
      },
      {
        "start": 3479.119,
        "duration": 7.841,
        "text": "withs yeah hold on hold"
      },
      {
        "start": 3482.96,
        "duration": 7.32,
        "text": "on your next job S is to build it with"
      },
      {
        "start": 3486.96,
        "duration": 6.32,
        "text": "Astro yeah come on S then you'll get the"
      },
      {
        "start": 3490.28,
        "duration": 5.799,
        "text": "monitoring that will tell you like hey"
      },
      {
        "start": 3493.28,
        "duration": 4.039,
        "text": "the qu aren coming in what's going on"
      },
      {
        "start": 3496.079,
        "duration": 4.52,
        "text": "all right here we are we're doing this"
      },
      {
        "start": 3497.319,
        "duration": 5.121,
        "text": "again we're doing it live sem okay here"
      },
      {
        "start": 3500.599,
        "duration": 3.121,
        "text": "we"
      },
      {
        "start": 3502.44,
        "duration": 3.56,
        "text": "[Music]"
      },
      {
        "start": 3503.72,
        "duration": 6.359,
        "text": "go look at"
      },
      {
        "start": 3506.0,
        "duration": 10.64,
        "text": "this speeds up retrieval too look at"
      },
      {
        "start": 3510.079,
        "duration": 9.921,
        "text": "that see well done all right um okay so"
      },
      {
        "start": 3516.64,
        "duration": 5.64,
        "text": "so Ursa has a good question here says uh"
      },
      {
        "start": 3520.0,
        "duration": 4.039,
        "text": "how do we assess quality are there are"
      },
      {
        "start": 3522.28,
        "duration": 3.759,
        "text": "there metrics Pat"
      },
      {
        "start": 3524.039,
        "duration": 3.481,
        "text": "Patrick I'll let you take that first and"
      },
      {
        "start": 3526.039,
        "duration": 3.641,
        "text": "we can talk a little bit about some"
      },
      {
        "start": 3527.52,
        "duration": 5.839,
        "text": "things we we looked at also well with"
      },
      {
        "start": 3529.68,
        "duration": 5.28,
        "text": "a&n searches you do get a a score for"
      },
      {
        "start": 3533.359,
        "duration": 3.96,
        "text": "the retrieval and that's something"
      },
      {
        "start": 3534.96,
        "duration": 5.599,
        "text": "that's really like it's interesting"
      },
      {
        "start": 3537.319,
        "duration": 5.201,
        "text": "because with Vector search we in"
      },
      {
        "start": 3540.559,
        "duration": 4.721,
        "text": "database world we we looked we always"
      },
      {
        "start": 3542.52,
        "duration": 5.4,
        "text": "talk about two things which is latency"
      },
      {
        "start": 3545.28,
        "duration": 4.2,
        "text": "and um throughput you know those are"
      },
      {
        "start": 3547.92,
        "duration": 5.439,
        "text": "those are quality metrics of your"
      },
      {
        "start": 3549.48,
        "duration": 6.359,
        "text": "database transactions but um now it's"
      },
      {
        "start": 3553.359,
        "duration": 4.361,
        "text": "relevance and is a third thing and the"
      },
      {
        "start": 3555.839,
        "duration": 4.0,
        "text": "relevance score is really critical"
      },
      {
        "start": 3557.72,
        "duration": 5.52,
        "text": "because um and what you're doing is"
      },
      {
        "start": 3559.839,
        "duration": 5.441,
        "text": "you're saying hey I here's a thing find"
      },
      {
        "start": 3563.24,
        "duration": 4.599,
        "text": "the things that are close to it and the"
      },
      {
        "start": 3565.28,
        "duration": 4.6,
        "text": "algorithm is able to say an approximate"
      },
      {
        "start": 3567.839,
        "duration": 5.561,
        "text": "nearest neighbor algorithm is able to"
      },
      {
        "start": 3569.88,
        "duration": 7.0,
        "text": "say here's how close it is and so um and"
      },
      {
        "start": 3573.4,
        "duration": 6.76,
        "text": "it'll be a zero to one number so you'll"
      },
      {
        "start": 3576.88,
        "duration": 6.919,
        "text": "get like a seven well that's like a 70%"
      },
      {
        "start": 3580.16,
        "duration": 6.28,
        "text": "match right um and it's up to you and so"
      },
      {
        "start": 3583.799,
        "duration": 4.481,
        "text": "uh Ursula when when I think of quality"
      },
      {
        "start": 3586.44,
        "duration": 3.8,
        "text": "and what's the metrics you know it's up"
      },
      {
        "start": 3588.28,
        "duration": 3.92,
        "text": "to you but like maybe you want the"
      },
      {
        "start": 3590.24,
        "duration": 5.04,
        "text": "highest quality so you want closer to"
      },
      {
        "start": 3592.2,
        "duration": 5.359,
        "text": "like 85 to 90% or better uh on your"
      },
      {
        "start": 3595.28,
        "duration": 4.16,
        "text": "retrievals so that you just won't use an"
      },
      {
        "start": 3597.559,
        "duration": 3.921,
        "text": "answer then this where may this where"
      },
      {
        "start": 3599.44,
        "duration": 4.32,
        "text": "might come in where you say hey if it's"
      },
      {
        "start": 3601.48,
        "duration": 5.16,
        "text": "less than a 90% then just say I don't"
      },
      {
        "start": 3603.76,
        "duration": 4.68,
        "text": "know like that that just straight up say"
      },
      {
        "start": 3606.64,
        "duration": 5.0,
        "text": "that and that's kind of how most humans"
      },
      {
        "start": 3608.44,
        "duration": 4.679,
        "text": "work although not all the time Some"
      },
      {
        "start": 3611.64,
        "duration": 5.399,
        "text": "Humans make up"
      },
      {
        "start": 3613.119,
        "duration": 5.601,
        "text": "answers but and then Jameson Jameson had"
      },
      {
        "start": 3617.039,
        "duration": 2.961,
        "text": "had a similar one which is like you know"
      },
      {
        "start": 3618.72,
        "duration": 2.92,
        "text": "like if you have similar queries that"
      },
      {
        "start": 3620.0,
        "duration": 3.839,
        "text": "are coming in that are slightly"
      },
      {
        "start": 3621.64,
        "duration": 5.919,
        "text": "different one of the things I absolutely"
      },
      {
        "start": 3623.839,
        "duration": 5.361,
        "text": "encourage you to do is check to see look"
      },
      {
        "start": 3627.559,
        "duration": 4.081,
        "text": "at look at the embeddings you're getting"
      },
      {
        "start": 3629.2,
        "duration": 5.72,
        "text": "back right and then if the embeddings"
      },
      {
        "start": 3631.64,
        "duration": 5.04,
        "text": "are not similar ask yourself why right"
      },
      {
        "start": 3634.92,
        "duration": 4.199,
        "text": "look at the look at what's coming back"
      },
      {
        "start": 3636.68,
        "duration": 4.919,
        "text": "from the vector DB and look at your"
      },
      {
        "start": 3639.119,
        "duration": 7.121,
        "text": "embeddings yeah yeah that's those are"
      },
      {
        "start": 3641.599,
        "duration": 7.24,
        "text": "really critical things um in the Q&A um"
      },
      {
        "start": 3646.24,
        "duration": 4.359,
        "text": "there is uh harp as ask this question"
      },
      {
        "start": 3648.839,
        "duration": 3.681,
        "text": "I'm going to I'm going to give it to you"
      },
      {
        "start": 3650.599,
        "duration": 3.921,
        "text": "um because this is right in your thing"
      },
      {
        "start": 3652.52,
        "duration": 3.4,
        "text": "so he says ye the example you mentioned"
      },
      {
        "start": 3654.52,
        "duration": 3.279,
        "text": "regarding Patrick's dat is since the"
      },
      {
        "start": 3655.92,
        "duration": 4.04,
        "text": "model searching from the Corpus and it"
      },
      {
        "start": 3657.799,
        "duration": 4.161,
        "text": "will look for the word work so ideally"
      },
      {
        "start": 3659.96,
        "duration": 3.2,
        "text": "it should give the second sentence but"
      },
      {
        "start": 3661.96,
        "duration": 3.72,
        "text": "the"
      },
      {
        "start": 3663.16,
        "duration": 4.439,
        "text": "ideal the IDE ideally it should give the"
      },
      {
        "start": 3665.68,
        "duration": 3.56,
        "text": "second sent was the ideal first aners"
      },
      {
        "start": 3667.599,
        "duration": 5.44,
        "text": "how do you fix"
      },
      {
        "start": 3669.24,
        "duration": 6.799,
        "text": "that yeah I small B small small small to"
      },
      {
        "start": 3673.039,
        "duration": 5.28,
        "text": "big absolutely because because there's"
      },
      {
        "start": 3676.039,
        "duration": 4.641,
        "text": "there's or or you just say you know I'm"
      },
      {
        "start": 3678.319,
        "duration": 4.881,
        "text": "just going to do bigger chunks I I think"
      },
      {
        "start": 3680.68,
        "duration": 9.399,
        "text": "Patrick yeah everybody's disconnected so"
      },
      {
        "start": 3683.2,
        "duration": 11.32,
        "text": "uh oh I think we're oh it shut down yeah"
      },
      {
        "start": 3690.079,
        "duration": 7.04,
        "text": "so wow it cut us off that went by fast"
      },
      {
        "start": 3694.52,
        "duration": 4.279,
        "text": "Patrick it was fun it did go by fast"
      },
      {
        "start": 3697.119,
        "duration": 5.801,
        "text": "yeah we're no longer live are"
      },
      {
        "start": 3698.799,
        "duration": 6.481,
        "text": "we guess so yeah okay so we'll say"
      },
      {
        "start": 3702.92,
        "duration": 4.36,
        "text": "something yeah Yep looks like looks like"
      },
      {
        "start": 3705.28,
        "duration": 6.039,
        "text": "our hour is"
      },
      {
        "start": 3707.28,
        "duration": 8.44,
        "text": "up you want to do you want to put your"
      },
      {
        "start": 3711.319,
        "duration": 6.161,
        "text": "uh please uh get in touch"
      },
      {
        "start": 3715.72,
        "duration": 5.559,
        "text": "with us do you want to put your LinkedIn"
      },
      {
        "start": 3717.48,
        "duration": 3.799,
        "text": "in there and then yeah I will I"
      },
      {
        "start": 3725.039,
        "duration": 8.681,
        "text": "will wow we just got shut down"
      },
      {
        "start": 3729.4,
        "duration": 4.32,
        "text": "man the trains got to run on"
      },
      {
        "start": 3741.079,
        "duration": 5.801,
        "text": "time all right d this is fun I'm I'm"
      },
      {
        "start": 3744.48,
        "duration": 4.639,
        "text": "glad we did this boy opened up like 800"
      },
      {
        "start": 3746.88,
        "duration": 2.239,
        "text": "more"
      },
      {
        "start": 3751.0,
        "duration": 5.799,
        "text": "doors"
      },
      {
        "start": 3753.48,
        "duration": 9.879,
        "text": "um yeah the application working which"
      },
      {
        "start": 3756.799,
        "duration": 10.76,
        "text": "one um yeah okay all right see you later"
      },
      {
        "start": 3763.359,
        "duration": 4.2,
        "text": "thanks a lot thanks all right bye"
      },
      {
        "start": 3767.96,
        "duration": 3.0,
        "text": "bye"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T17:27:33.267028+00:00"
}