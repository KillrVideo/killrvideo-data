{
  "video_id": "w0zsV-qlPCE",
  "title": "DS201.08 Peer to Peer | Foundations of Apache Cassandra",
  "description": "#DataStaxAcademy #DS201\nDS201.08 PEER TO PEER\nAs opposed to a relational set up, Apache Cassandra uses a peer-to-peer system. Let's explore how this system is designed to keep you online when bad things happen.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-06T04:00:13Z",
  "thumbnail": "https://i.ytimg.com/vi/w0zsV-qlPCE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax",
    "tutorial",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=w0zsV-qlPCE",
  "transcript": {
    "available": true,
    "language": "Chinese",
    "language_code": "zh",
    "is_generated": false,
    "text": "DS201.8: 端对端(P2P) 好 现在让我们花些时间来讨论P2P 我们现在看到的是在关系型数据库中一种常规的结构 客户端-服务器端(client-server)模型 它已经存在多年了 我敢确定你见过它 让我们来讨论它在关系型数据库中\n是如何与复制策略(Replication strategy)协同工作的 我们有一个主节点(Leader node) 这个节点几乎要对所有事物负责 如写入、更新、读取 在主节点的背后有用于数据读取的读副本(read replicas) 这些副本节点因为架构上的局限 收到复制更新会有一定的延迟 它们的数据更新不会跟主节点完全同步 因为它们只是副本 这样的主从结构的情况会带来什么呢？ 我们会将整个系统进行切分(Shard) 切分？！真的？！ 切分时会产生什么问题呢？ 让我们来仔细看看这个问题 我们的数据将会分散在多个分片(Shard)中 每一个分片可以储存一部分数据 比如你的客户数据的一部分 接着会发生什么呢？ 之后要做的就是数据路由(Routing) 这意味着你可能要写一些代码 来指出将数据放在何处 以及当你需要数据时去哪里找数据 这也意味着 由于你的数据的存储方式是分散的 你不再能享受使用JOIN、聚合函数、GROUP BY的便利 如果主节点出了问题 那会发生什么呢？ 如果主节点突然宕机 我们会感到很受伤 在这种情况下 我们能做的只有等待令人害怕的Failover 朋友们 时间就是金钱 我们可承担不起Failover 因为它有时会花几秒 甚至更多时间 来产生一个新的主节点 这时候你的用户只能坐在那里 盯着他们的应用程序干等 他们只能干等 还有一种可能会发生的情况是 你的各个节点不再能互相看到对方 这不是好现象 因为主节点不能看到它的副本节点 大家都处在一个不好的状态 这可能会造成混乱 如果那些节点无法互相看到对方 这会将一个具有高度一致性的系统完全搞乱 从节点必须要与主节点保持一致 如果它们看不到主节点或主节点看不到它们  它们就无法保持一致 当这种情况发生时 就得产生新的主节点 噢不！这下你会有两个主节点 天要塌了 真实的P2P系统是怎么运作的呢？ 这个问题也许是你想最先问的 在Apache Cassandra中 P2P结构是这样工作的 在集群中有副本数据 所有的副本在P2P结构中被视为完全一样 没有主节点和从节点之分 所有节点完全一样 不过这里会有协调节点(coordinator)\n你可能在其他课程中已经听过这个概念了 协调节点从客户端获得数据 然后分别向负责这部分数据的各个副本节点异步写入数据 假设数据被发送给了集群另一端的一个协调节点 这完全不是问题 这个协调节点同样会将数据发送给正确的副本节点们 耶！一切都很完美 如果我们将这个集群从中间分开 会出现什么情况呢 噢不！脑裂(split-brain)问题来了 当真如此？ 其实不然 因为Apache Cassandra可以自动处理这个问题 而无需用到Failover 每一个可以被客户端看到的节点都还是在线的 只要你还能写入副本 那么集群就是还在线且在运行中的 这个部分其实是可以进行配置的 你可以提高标准 不接受这种“脑裂”情况的发生 或是降低标准 对这种“脑裂”情况完全接受 这个部分是由你来控制的 以便使其符合环境的需求 在集群分裂的情况下 当你向其中一个分区的协调节点写入数据时 它会向它能看到的一个或多个副本节点写入数据 在我们的例子中右边的集群分区里 协调节点能够看到两个副本节点 所以它会向这两个节点都写入数据 这个部分是由一致性级别(consistency level)来控制的 我们在其他的课程中提到过这个概念 它非常重要 一定要理解这个概念 从而确保当你需要使用这个概念的时候你能正确应用 在有不好的事情发生的时候 Apache Cassandra的设计让你的数据库依然能保持在线 比如有人把咖啡洒在了服务器机房 导致几个节点停止运转 或者有人切断了某处的电线或网线 或者发生其他微小的问题或甚至重大的灾难 Apache Cassandra建构的方式可以应对这些可能发生的事情 并助你持续取得进展",
    "segments": [
      {
        "start": 0.611,
        "duration": 5.931,
        "text": "DS201.8: 端对端(P2P)"
      },
      {
        "start": 6.614,
        "duration": 4.261,
        "text": "好 现在让我们花些时间来讨论P2P"
      },
      {
        "start": 10.875,
        "duration": 3.581,
        "text": "我们现在看到的是在关系型数据库中一种常规的结构"
      },
      {
        "start": 14.456,
        "duration": 2.015,
        "text": "客户端-服务器端(client-server)模型"
      },
      {
        "start": 16.471,
        "duration": 2.078,
        "text": "它已经存在多年了"
      },
      {
        "start": 18.549,
        "duration": 1.219,
        "text": "我敢确定你见过它"
      },
      {
        "start": 19.768,
        "duration": 4.617,
        "text": "让我们来讨论它在关系型数据库中\n是如何与复制策略(Replication strategy)协同工作的"
      },
      {
        "start": 24.385,
        "duration": 1.423,
        "text": "我们有一个主节点(Leader node)"
      },
      {
        "start": 25.808,
        "duration": 5.825,
        "text": "这个节点几乎要对所有事物负责 如写入、更新、读取"
      },
      {
        "start": 31.633,
        "duration": 2.873,
        "text": "在主节点的背后有用于数据读取的读副本(read replicas)"
      },
      {
        "start": 34.506,
        "duration": 3.833,
        "text": "这些副本节点因为架构上的局限 收到复制更新会有一定的延迟"
      },
      {
        "start": 38.339,
        "duration": 3.357,
        "text": "它们的数据更新不会跟主节点完全同步 因为它们只是副本"
      },
      {
        "start": 41.696,
        "duration": 1.887,
        "text": "这样的主从结构的情况会带来什么呢？"
      },
      {
        "start": 43.583,
        "duration": 1.036,
        "text": "我们会将整个系统进行切分(Shard)"
      },
      {
        "start": 44.619,
        "duration": 2.0,
        "text": "切分？！真的？！"
      },
      {
        "start": 46.619,
        "duration": 2.222,
        "text": "切分时会产生什么问题呢？"
      },
      {
        "start": 48.841,
        "duration": 2.029,
        "text": "让我们来仔细看看这个问题"
      },
      {
        "start": 50.87,
        "duration": 2.798,
        "text": "我们的数据将会分散在多个分片(Shard)中"
      },
      {
        "start": 53.668,
        "duration": 4.712,
        "text": "每一个分片可以储存一部分数据 比如你的客户数据的一部分"
      },
      {
        "start": 58.38,
        "duration": 1.557,
        "text": "接着会发生什么呢？"
      },
      {
        "start": 59.937,
        "duration": 1.804,
        "text": "之后要做的就是数据路由(Routing)"
      },
      {
        "start": 61.741,
        "duration": 2.409,
        "text": "这意味着你可能要写一些代码"
      },
      {
        "start": 64.15,
        "duration": 3.47,
        "text": "来指出将数据放在何处 以及当你需要数据时去哪里找数据"
      },
      {
        "start": 67.62,
        "duration": 4.155,
        "text": "这也意味着 由于你的数据的存储方式是分散的"
      },
      {
        "start": 71.775,
        "duration": 2.245,
        "text": "你不再能享受使用JOIN、聚合函数、GROUP BY的便利"
      },
      {
        "start": 74.02,
        "duration": 2.193,
        "text": "如果主节点出了问题 那会发生什么呢？"
      },
      {
        "start": 76.213,
        "duration": 1.556,
        "text": "如果主节点突然宕机"
      },
      {
        "start": 77.769,
        "duration": 2.19,
        "text": "我们会感到很受伤"
      },
      {
        "start": 79.959,
        "duration": 3.907,
        "text": "在这种情况下 我们能做的只有等待令人害怕的Failover"
      },
      {
        "start": 83.866,
        "duration": 2.962,
        "text": "朋友们 时间就是金钱 我们可承担不起Failover"
      },
      {
        "start": 86.828,
        "duration": 4.718,
        "text": "因为它有时会花几秒 甚至更多时间 来产生一个新的主节点"
      },
      {
        "start": 91.682,
        "duration": 4.151,
        "text": "这时候你的用户只能坐在那里 盯着他们的应用程序干等"
      },
      {
        "start": 96.0,
        "duration": 1.715,
        "text": "他们只能干等"
      },
      {
        "start": 98.029,
        "duration": 2.365,
        "text": "还有一种可能会发生的情况是"
      },
      {
        "start": 100.394,
        "duration": 2.991,
        "text": "你的各个节点不再能互相看到对方"
      },
      {
        "start": 103.385,
        "duration": 2.941,
        "text": "这不是好现象 因为主节点不能看到它的副本节点"
      },
      {
        "start": 106.326,
        "duration": 1.456,
        "text": "大家都处在一个不好的状态"
      },
      {
        "start": 107.782,
        "duration": 1.795,
        "text": "这可能会造成混乱"
      },
      {
        "start": 109.577,
        "duration": 2.253,
        "text": "如果那些节点无法互相看到对方"
      },
      {
        "start": 111.83,
        "duration": 3.373,
        "text": "这会将一个具有高度一致性的系统完全搞乱"
      },
      {
        "start": 115.203,
        "duration": 2.332,
        "text": "从节点必须要与主节点保持一致"
      },
      {
        "start": 117.535,
        "duration": 2.958,
        "text": "如果它们看不到主节点或主节点看不到它们"
      },
      {
        "start": 120.493,
        "duration": 1.563,
        "text": " 它们就无法保持一致"
      },
      {
        "start": 122.056,
        "duration": 2.866,
        "text": "当这种情况发生时 就得产生新的主节点"
      },
      {
        "start": 124.922,
        "duration": 2.999,
        "text": "噢不！这下你会有两个主节点"
      },
      {
        "start": 127.921,
        "duration": 1.507,
        "text": "天要塌了"
      },
      {
        "start": 129.428,
        "duration": 2.531,
        "text": "真实的P2P系统是怎么运作的呢？"
      },
      {
        "start": 131.959,
        "duration": 2.261,
        "text": "这个问题也许是你想最先问的"
      },
      {
        "start": 134.22,
        "duration": 2.572,
        "text": "在Apache Cassandra中 P2P结构是这样工作的"
      },
      {
        "start": 136.792,
        "duration": 2.313,
        "text": "在集群中有副本数据"
      },
      {
        "start": 139.105,
        "duration": 3.308,
        "text": "所有的副本在P2P结构中被视为完全一样"
      },
      {
        "start": 142.413,
        "duration": 3.66,
        "text": "没有主节点和从节点之分 所有节点完全一样"
      },
      {
        "start": 146.073,
        "duration": 3.673,
        "text": "不过这里会有协调节点(coordinator)\n你可能在其他课程中已经听过这个概念了"
      },
      {
        "start": 149.746,
        "duration": 2.777,
        "text": "协调节点从客户端获得数据"
      },
      {
        "start": 152.523,
        "duration": 4.045,
        "text": "然后分别向负责这部分数据的各个副本节点异步写入数据"
      },
      {
        "start": 156.568,
        "duration": 3.764,
        "text": "假设数据被发送给了集群另一端的一个协调节点"
      },
      {
        "start": 160.332,
        "duration": 1.255,
        "text": "这完全不是问题"
      },
      {
        "start": 161.587,
        "duration": 3.568,
        "text": "这个协调节点同样会将数据发送给正确的副本节点们"
      },
      {
        "start": 165.155,
        "duration": 2.261,
        "text": "耶！一切都很完美"
      },
      {
        "start": 168.579,
        "duration": 2.863,
        "text": "如果我们将这个集群从中间分开 会出现什么情况呢"
      },
      {
        "start": 171.442,
        "duration": 2.0,
        "text": "噢不！脑裂(split-brain)问题来了"
      },
      {
        "start": 173.442,
        "duration": 1.268,
        "text": "当真如此？"
      },
      {
        "start": 174.71,
        "duration": 1.006,
        "text": "其实不然"
      },
      {
        "start": 175.716,
        "duration": 3.398,
        "text": "因为Apache Cassandra可以自动处理这个问题"
      },
      {
        "start": 179.114,
        "duration": 1.83,
        "text": "而无需用到Failover"
      },
      {
        "start": 180.944,
        "duration": 4.457,
        "text": "每一个可以被客户端看到的节点都还是在线的"
      },
      {
        "start": 185.401,
        "duration": 3.599,
        "text": "只要你还能写入副本 那么集群就是还在线且在运行中的"
      },
      {
        "start": 189.732,
        "duration": 2.0,
        "text": "这个部分其实是可以进行配置的"
      },
      {
        "start": 191.732,
        "duration": 3.399,
        "text": "你可以提高标准 不接受这种“脑裂”情况的发生"
      },
      {
        "start": 195.131,
        "duration": 3.646,
        "text": "或是降低标准 对这种“脑裂”情况完全接受"
      },
      {
        "start": 198.777,
        "duration": 4.025,
        "text": "这个部分是由你来控制的 以便使其符合环境的需求"
      },
      {
        "start": 202.802,
        "duration": 3.033,
        "text": "在集群分裂的情况下 当你向其中一个分区的协调节点写入数据时"
      },
      {
        "start": 205.835,
        "duration": 3.607,
        "text": "它会向它能看到的一个或多个副本节点写入数据"
      },
      {
        "start": 209.442,
        "duration": 2.0,
        "text": "在我们的例子中右边的集群分区里"
      },
      {
        "start": 211.442,
        "duration": 1.486,
        "text": "协调节点能够看到两个副本节点"
      },
      {
        "start": 212.928,
        "duration": 1.69,
        "text": "所以它会向这两个节点都写入数据"
      },
      {
        "start": 214.618,
        "duration": 2.601,
        "text": "这个部分是由一致性级别(consistency level)来控制的"
      },
      {
        "start": 217.219,
        "duration": 2.0,
        "text": "我们在其他的课程中提到过这个概念"
      },
      {
        "start": 219.219,
        "duration": 2.0,
        "text": "它非常重要 一定要理解这个概念"
      },
      {
        "start": 221.219,
        "duration": 2.105,
        "text": "从而确保当你需要使用这个概念的时候你能正确应用"
      },
      {
        "start": 223.324,
        "duration": 2.221,
        "text": "在有不好的事情发生的时候"
      },
      {
        "start": 225.545,
        "duration": 3.149,
        "text": "Apache Cassandra的设计让你的数据库依然能保持在线"
      },
      {
        "start": 228.694,
        "duration": 4.836,
        "text": "比如有人把咖啡洒在了服务器机房 导致几个节点停止运转"
      },
      {
        "start": 233.53,
        "duration": 2.47,
        "text": "或者有人切断了某处的电线或网线"
      },
      {
        "start": 236.0,
        "duration": 3.464,
        "text": "或者发生其他微小的问题或甚至重大的灾难"
      },
      {
        "start": 239.464,
        "duration": 3.242,
        "text": "Apache Cassandra建构的方式可以应对这些可能发生的事情"
      },
      {
        "start": 242.706,
        "duration": 1.765,
        "text": "并助你持续取得进展"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T02:04:44.364641+00:00"
}