{
  "video_id": "u8L1ngNJA-0",
  "title": "Distributed Data Show Episode 14: Distributed Tracing with Luke Tillman",
  "description": "Luke Tillman talks about his dogfooding project for DataStax Academy, challenges of developing microservice applications, and how distributed tracing throughout the stack can help.\n\nABOUT DATASTAX ENTERPRISE 5\nDataStax Enterprise 5.0, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.0 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax EnterpriseÂ©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-09-26T15:00:06Z",
  "thumbnail": "https://i.ytimg.com/vi/u8L1ngNJA-0/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "talk",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=u8L1ngNJA-0",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems welcome once again distributed data show I'm Jeff carpenter and I'm here in the studio today with Luke Tillman hello everyone so I don't know what everyone thinks an evangelist does but it turns out that we actually have real developer chops were real people real developers real software engineers and architects too and we happen to do a lot of fun stuff to promote things that we love and talk about things that we love but you know we're developers and technologists at heart so I want to talk to a little to Luke a little bit about what you've been doing lately because I would consider you maybe this is term is overused and over baked a little bit but a full-stack developer would you own that would you own that or not yeah you know it's funny I saw a tweet this morning somebody said my favorite my favorite part of looking through a codebase where a full-stack developer has has worked on it is figuring out which part of the stack they didn't know which is totally true yeah like it's a I mean yeah I know a little I know enough to be dangerous I think legit that I think that you're a legit full stack developer and the and maybe the proper sense of the word I'll give you the credit for that so I want to hear about your latest project that you're working on ok so um it just don't call me a 10x developer like that oh no way yeah that term derives me crazy so yeah so I'm a Technical Evangelist right I've been with the attacks now for going on for years and you know originally one of the original projects that I worked on when I started at theta stacks was killer video which was our reference application that now you and and David Gilardi have kind of taken over stewardship of we haven't screwed it up yet yeah hopefully you know don't screw that up but so for me as an evangelist one thing that's really important is getting my hands on technology and you know I like I just love writing code and so you know to me it's like I always want to have a project I always want to have something where I'm writing code or doing something and so I kind of had an opportunity where our Academy site DSA for short so data stacks Academy this is Academy data stacks comm there you go like shameless plug so we had this project where we wanted to kind of do some more dogfooding of our own are are being data stacks own product so we wanted to start building more parts of the Academy site that people go and learn on on top of data stacks Enterprise so we actually have a cloud scale data problem right we do justifiable usage of our own product I love it yeah so so what we were so the problem in particular that we were kind of trying to solve was people are like as people come on to data stacks Academy and they take courses and those courses have units in them and they kind of like make progress as they go along through through those courses we want to record you know how far along are you in the course where did you leave off you know like right and you can imagine that you know we have you know not a huge number of courses right now but a good amount of free content up there and you know if you break it down to the unit level we've got even more inside of each of those courses and then you multiply that by all the number of users that we have which we do have a bunch you know quite a few users on Dax Academy and what we had is we had this table where we were storing all of this progress information on who made progress and when they made it and where where are they and stuff easily talking millions of data points yeah and and and and as the number of courses continued to grow and as the number of users continued to grow we could kind of see this table that was in my sequel starting to creak a little bit and so it's so it's kind of like the classic it's funny like it's kind of like the classic how do we take and and like distribute this across you know this is this amount of data across more than one write more than one machine so hey I know how to solve that and so it was it's kind of a cool thing like we're standing up you know as part of this project it's kind of not only moved starting to move some of our data stacks Academy data on to data stacks Enterprise but we're also you know this is all going to be an AWS so we're gonna be a DMC ok whoa your acronyms yeah yeah spell it out so data stacks manage cloud so we're gonna be a data stacks managed cloud customer like an internal customer base exactly so they're gonna go ahead and run our DSC cluster for us but it was also kind of an opportunity to stand up an entirely new stack so behind the scenes were actually standing up even though most of the stocks academy has historically been PHP sort of Drupal based system like it's you know typical sort of like many apps that are yeah like a lot of content management the content management system like Drupal or WordPress so we're standing up an entirely new stack for some of this with where we're doing primarily most of the development in nodejs because it's an easy language for a lot of people to sort of pick up and and a lot of people on the team already kind of have that that language those language skills right okay so you you pick this new technology stack what about architectural eru on the microservices bandwagon oh yes so you know everybody's everybody's on the microservices bang bandwagon these days so yeah we're trying to do a microservices architecture behind the scenes sort of do a modern do a modern architecture you know we haven't you know I feel like microservices is almost like it's almost like passe at this point like we're you know like people are starting to move on to server lists and functions as a service and yo I see right it's almost like Pico services well maybe we better start talking about something else then no III just so I've done a micro services architecture myself on a past life so I know a little bit of the ins and outs and some of the temptations especially if you're starting with everyone talks about you know hate carving up a monolith and carving off microservices and using strangler pattern to kind of carve off little bits at a time and start with your lowest risk services and we a lot of us have probably heard that sort of methodology okay but I've done this and you're doing this to where you're actually starting from scratch with micro-services what are the perils and pitfalls so we could do a whole show about the perils and pitfalls probably of once you like once you take a system and just distribute it you know and like put the network in the middle like holy crap but you know that so one one thing that is definitely a challenge once you go to micro services and I think this this is something that people run into a quite a bit is is observability right so observability becomes super important once you once you've taken something that was you know kind of a single thing running in process sort of the monolith kind of thing and you start breaking it out across multiple processes distributed around a network you know you you start to you start to run into the problem of for example you know if a call is slow how do I know what was slow in that like in that call like once you know once things are fanning out to all these you know to all these different micro services you know how do I sort of how do I keep track of you know what's going on in my system how do I know what's going on in my system and so this is where the idea of distributed tracing has become super popular over the last few years gotcha okay excellent so what do you mean by distributed tracing unpack that a little bit and maybe you know what what problem are you trying to solve by introducing distributed tracing yeah so maybe you it's good to start with maybe kind of a description of what does the you know kind of the architecture of the thing that I've been building look like and so if we have I love arc I love hearing about people's architectures yeah yeah so like just briefly kind of what we have is we you know react components on the front end so we're you know we're still having to integrate this with the existing data stacks Academy site and so you know we've got these sort of smaller react components that we can embed in different parts of the existing a sort of Drupal site and those react components on the front end they are talking to an API like running on a web server that's actually talking graph QL so I don't know if anybody's ever gone and an investigative graph QL but this is a project from from Facebook kind of cool way of doing API is especially when you're using your front-end to talk to some sort of back-end so we've got this graph QL API you know github actually just released a giant graph QL API for all of their like all of their developer it guys so you've seen some adoption out there and they're probably this graph QL API then it it takes and as people request different parts of our graph sort of our graph of things that the front-end might need access to like courses and units and users and all of these things those calls then get translated by the graph QL API on a web server somewhere to the kind of fan-out to micro services on the backend and so you know originally we were using G RPC and you can this could be rust api's you know on the backend you really you could be using whatever you want for your micro services that are running on the backend and so the graph QL API is basically kind of just acting as an API gateway that fans out to these various micro services and so the problem you're trying to solve with distributed tracing is you know okay this you got this call that starts on the client in the browser for example with these react components it goes to this graph QL server that this graph QL API server you know that's a web server and then that may fan out to two or three or ten or who knows how many remember service calls yeah so how do you know like first of all how many like how many micro service calls are happening as a result of your front-end right you know calling the backend how do I get some observability into you know like wow did I really write some super inefficient you know like I'm making tons of calls that I shouldn't be this is kind of like oh RMS when you used to have the Select and Plus one problem where an orm would generate like a sequel query that would would generate up you know 50 sequel queries kind of thing in my so you want to know am i generating like 50 micro-services calls from from one sort of call from the front-end and then how do I know like what you know if it's slow how do I know like where was it slow like was it a particular service you know was it that service for example talking to a database was that that service talking to some external service you know how do you get you know how do you figure that out so you know observability still is the problem that you're trying to solve okay so what were your technology choices that that you made there and how does this all work together right so um so there's a number of kind of things out there right now and what I ended up sort of settling on for the time being and and maybe at the end we can talk a little bit more about some other options but what I ended up doing was Zipkin so Zipkin is a pretty popular open-source project that is is for doing distributed tracing I think it's based on Google's dapper paper maybe yeah so basically you've got you have this framework it has you know it has plugins and code available essentially for multiple languages and sort of conceptually the idea it's pretty simple you know most most developers when they if they were to take a look at this would would probably get it right away that you know what we want to do is when you know when our client makes a call you know we want to start with some sort of tracing ID like some sort of unique identifier so you could think you know if you're familiar with the santur you might think of this as a UUID kind of scenario where i've got some sort of unique ID for for a call that starts on the client and then when that call reaches my web server so in my case it was a graph qlo api server you know i have some way to basically pull that tracing ID out that was created you know at the client and then I want to propagate that make sure that tracing ID gets propagated to all of the sort of all the child calls then that might so all the other communication that goes on whether it's HTTP calls to other micro services or it's those it's those micro services then making calls to their databases over teas connections or whatever it is they use basically I want to keep track of how long first of all each of those each of those calls takes but then I also want to make sure that it's all that all of those calls are sort of tied together by a single tracing ID so I can sort of see the the anatomy you know how many how many calls were made to other services and and be able to correlate it all back to a single sort of client request that kicked it off okay gotcha gotcha so is there sort of a an expansion factor there you've got that one client call that initiated everything and then does that expand out into other IDs below that yes so so the idea at least in sip can the the sort of the data model are sort of the nomenclature they use is they call these spans so you have one route span which basically spans the entire duration starting on the client from the time the client makes the request so our react component all the way until the client receives a response so you know it got a response back from the graph QL API server but then underneath that you know sort of route span you might have a bunch of child spans which are you know your calls to the other services so you know the graph QL API calls the user service or calls the course controller service and and those spans have their own timing information and have maybe their own meta data that's being collected and then you can even have you know it's completely messed in that service then maybe it makes a call to a database or something like that and so you could have a child span underneath you know underneath the you know so two levels deep here and we've got timing information for how long it took to do a sequel query or something like that right okay so what about sort of aggregating upward one of the things that I've seen is a need to identify errors or let's say Layton sees associated with a particular user login session so is there a way to sort of aggregate that up multiple user calls for that for the same user into a session concept right so um we used to get this all the time my last company my last company Hobson's we were kind of a software-as-a-service company and you know you get support tickets and I'm sure a lot of people have probably probably had this where a user is complaining X is slow it's all it's driven by the helpdesk right yeah yes and and so you might have some sort of what's that users ID or what's that user's login or what was their session kind of thing or this might even start not not from like a helpdesk it might start from like logs right so you get err logs and the error log has information about you know your logging information about what session this error happened in or something like that and so yeah with with SIPC and you can you're kind of free to record whatever kind of metadata you want with each call with each span you can kind of associate whatever sort of they call them annotations right which are basically just key value pairs so it's you know you can kind of associate whatever data you want so you could absolutely record a user ID key value pair as part of your trace data or a session ID key value pair or you know and and it really actually varies kind of based on what you what it is you're tracing so you can imagine for an HTTP call we might you know we might record not just the timing information but also what was the status code that came back you know it wasn't a 200 was it a 500 was it a 404 right that kind of thing so are we using like header requests and response headers for transmitting these so I don't have to build in I don't have to add like this arbitrary tracing ID parameter to every method on my yeah yeah yes so that's that's actually conceptually that's Zipkin defines sort of these these sort of well-known header names okay that are like X - whatever that are for propagating at least with HTTP calls you know this is right this is how you propagate you know this is how you propagate the tracing ID to child services and okay so on and so forth yep okay so you're getting all of this tracing data and you're able to correlate it once presumably you're able to look it up and find it somewhere so we've skipped the part where we talked about where you put all of this tracing data can you talk about that yeah so Zipkin like funny enough I guess it supports Cassandra right so in our ad so in our case what we're doing is we're going to be storing this data directly in our EMC or adidas tux managed cloud cluster so you know we'll have data stacks enterprise cluster that's going to store this tracing data and it you know when it inserts data into Cassandra it has like a default TTL on it so it's gonna know okay you're not gonna be keeping data around forever and I have some other storage formats I think that they support out of the box I can't remember off the top my head right now what those what those other storage mechanisms are that they they support but they do support some other ones and then it also comes with sort of a UI then for drilling down into that tracing data so they've got this pretty simple little UI for going in and finding for example the most recent traces and you can kind of look and you get a visual representation of the spans and or you could find you can go in and sort of sort them by what are the longest traces yeah maybe you're trying to try those long right trying to long wait and see trying to find really bad late and sees where people had a bad time that's like it's yeah that can be super helpful so you kind of get this out of the box you also get this UI for sort of drilling down into into what's going on ok good so I'm pretty confident based on what you have explained to me that you have the services tier and even you know kind of that graph QL API layer pretty well instrumented at this point but I mean let's take this all the way end and like can you take this all the way out to the client and can you take it all the way down to the database yes so yeah you absolutely can so right now the way the project stands right now I have not instrumented I've not instrumented our client like our react components so basically traces right now in our current project they start at the servers and once once it hits the graph QL API that's when we start doing tracing data but it's absolutely possible to to add essentially start with a tracing ID on the client side and Simkin comes with libraries for working with JavaScript for example if you're doing you know JavaScript front-end kind of development that make it pretty easy to to do that I actually did so as far as going all the way down to the database tier you know obviously we're using DLC as our storage for for these services right and so what I ended up doing because you know clearly there's no there's no at this point it's sort of out-of-the-box DSE instrumentation is I did a little bit of client instrumentation which is basically just a wrapping of the nodejs driver for DSC so kind of a proxy okay they're sort of thing that intercepts calls to execute and batch calls on made to DSC and it kind of records some specific things like what for example what is the cql query you know that I'm running kind of kind of information so that's you know part of that custom metadata that we can record in Zipkin we can record whatever we want and so I'm wrapping the node.js driver and basically you know kind of did this this instrumentation sort of manually it might actually you know be a cool open-source project at some point like maybe I can release it as you know kind of a public thing on github if people are instrument yeah interested in seeing how that was done but so another thing though is in Cassini I think it was consumed with three diet before tracing became pluggable on the actual server side so in DC and Cassandra you can actually plug in your own implementation of you know kind of what to do when you're tracing calls because if you've ever you can turn tracing on and off I don't know if anybody's ever tried this in the driver but you can turn tracing on and off in the DSC drivers right and pretty much all I think all across all our languages that we support and you get all this sort of rich kind of information you can see it in studio for example like if you ever using data stack studio and you know you go to do a cql query you can turn tracing on right and you'll get this sort of kind of almost like a query plan like from sequel and where you kind of see like how many how many tombstones read and where you know how many tables have had to hit or how many tables on disk it had to hit right blah blah blah and am i right to say that there it's leveraging kind of a feature of the seat maybe a lesser known feature of CQ o which is metadata that can be applied to messages right there you know going across right yep and so you can surface this information so one option I would have would be to sort of like turn tracing on for some queries like on my client side like turn tracing on and then use you know sort of take that tracing in though that the drivers sort of surfaces and try to put that data into Zipkin kind of recorded as annotations but another option you have because the server side is pluggable as of because nato 3.4 is you can actually just plug that in on the server side and have cassandra whenever it does a trace or DSC whenever it does a trace actually send that data to Zipkin so it can sort of participate just like any of your micro services servers would participate in tracing right and so right now there's actually there's a plug-in out there the last pickle guys did a cool plugin for doing that with open source Cassandra I haven't tried it yet to see if it works with DSC but that's definitely on my roadmap of somewhere down the road you know trying to figure out okay you know how do we do this with DSC and can we make this work and in the data stacks manage cloud environment kind of things so I think that would be cool to have like have the the server kind of do it for me instead of having to write code right itself right so yeah there's there is a little bit of trade-off here about what you get for free from using Zipkin as a framework versus you know what additional instrumentation code you might desire to write on top of that can you talk a little bit about you know where that dividing line and how you think about that yeah so Zipkin has a lot of plugins or so for example we're in node.js so there are packages on NPM the you know sort of the package manager for a node and the package registry for for node that are plugins that will wrap some really popular libraries that people might use in a microservices architecture so for example the fetch library which a lot of people use for doing HTTP calls just sort of plain old HTTP calls like we're calling a rest service for example they have instrumentation that is available already as a package that'll wrap that's for you express is a really popular package in node.js for doing servers you know HTTP servers web servers so if you're if you've got an express server they have they have plugins that will sort of do that out of the box you don't have to write your own instrumentation code but I did you know end up end up having to write a fair amount you know like for her stuff that wasn't common like out there yet so you know like Cassandra DSE kind of stuff I had to write some of that okay and the so funny funny story it's kind of almost a kind of almost an aside but so we were we were using G RPC so we had graph QL API server that fanned out to our micro services on the back and micro services and this is actually if anybody has ever gone and looked at killer video this is a very similar architecture to what we used in in killer video we were using G RPC to talk to the back-end services so the write the back-end services were G RPC so if anyone's listening out there and they don't know what G RPC is this is an RPC framework from Google and you kind of define your your services in protocol buffers format so you write protocol buffers is the interface definition language and then you can take those protocol buffers files and compile them to eight or ten different supported languages and sort of have typed clients with you know request in response objects that are typed and if you're in a strongly typed language like C sharp or Java and and so you get a lot of kind of cool stuff and then one of the other cool things that it has is it offers a built in HTTP to transports so HTTP to being the new version that's just kind of starting to see adoption in various browsers and and whatnot so it comes with a transport built in for all of the languages that it supports where you know when I my graph QL server when I go to make a call via G RPC to one of the backend G RPC server's services and it uses HTTP 2 as the as the transport and so you know we're like yeah alright this is exactly like killer video this was really cool and we're gonna be deploying this to AWS and so I'm thinking well we'll just use you know I kind of did a cursory reading of the I made the classic mistake of doing a cursory reading of the AWS Doc's for their application load balancers and it says yeah we support HTTP too and I'm like great I can just you know I'll be able to load balanced my G RPC services and whatnot yeah but I feel a but coming and then but and so welcome to find out that what Amazon's load balancers actually do right now is they they take HTTP to traffic and it may sort of terminated a terminate yeah at the load balancer and then when it actually goes to your back-end service it's actually HTTP one traffic they actually turn it into HTTP one traffic which would totally break the HTTP to transport that we had that that G RPC uses so okay like so basically we couldn't use Amazon's load balancers with our G RPC services sort of out of the box okay so implications of all this yeah servitude Tracy so implication is you know we had to figure out alright what do we do like you know what do we do do we just rip out the H to transport and replace it with something else or so that we can still use the Amazon load balancers or do we do something else like some other way of load balancing and communication between services and so I spent a little bit of time actually looking at envoy from lift so and I know you and I have actually talked about this it's the sort of service mesh idea where lyft is sort of runs or lyft envoy runs sort of a sidecar and acts as a proxy to all of your services so it runs as a sidecar next to your services and anytime you need to make a service call you just care of all you're out of process yeah yep and and it runs like if I need to make a service call to another service I can just call localhost where the sidecar is running and then it figures out because it's got built-in service discovery and routing capabilities and load balancing and stuff it can figure out then where to actually send that traffic to you know and so I was looking at that because they actually support HTTP too so I wouldn't have to rip out the the G RPC but one of the cool things actually that envoy also offers is sort of like a plugin is they actually offer built-in support for for tracing so for distributed tracing and so any call that I basically would make through Envoy wood could automatically get recorded and pushed into I think they support Zipkin right now as as an amazing provider so yeah so you kind of almost get this like out of the box kind of black box level of tracing where all your HTTP calls you know HTTP 1 & 2 are getting you know traced at least at a low level you're actually gonna be able to see these timing the timing spans and I'm guessing they record you know HTTP status of the responses and that sort of thing and you kind of get it out of the you know out of the box with something like convoy which is pretty cool like it's pretty cool sort of base level of tracing that you could get now that would be cool to do somewhere down the road you know I think though and then we can do our service mesh episode but I'm not ready I wasn't ready to commit because I am a small engineering team of one right now on this so I wasn't ready to commit to you know also having to run something else that I wasn't super familiar with yet in production but it's pretty cool like you know sort of the base level you can get now of course you're still gonna always want to do some sort of higher level like you know what you did at your previous job when you were working with hotels it's not gonna be the same sort of application or domain that I'm working in when I'm working on user progress and and who's making progress on courses and units and and so you're still gonna want to write instrumentation there's a fermentation specific to your domain that you're going to want to have exactly so you're still gonna always kind of do want to do this white box type of you know you might get this black box stuff kind of like tracing out of something like envoy you know out of the box which is actually a really great base to start from but you're still always gonna want to do your domain-specific stuff you know at a higher level so nice well I think the at this point we've peaked everyone's interests enough but now they want to go do this themselves where should they go to learn about distributed tracing so so there's two two places one that I didn't really mention there's an initiative called open tracing that is basically a vendor-neutral standard for doing distributed tracing and that's that which is a cloud native it's a cloud native foundation project yep and it's at I think they're they're at open tracing IO and one of the tracers that they actually support as far as some implementation wise so you know it's sort of open tracing is sort of a API you know describing the API of right how we do this in a vendor neutral way that everybody can agree on and then and then there's a bunch of tracers than that are actually supported one of which is Zipkin so if you want to find find out more about Zipkin i think their website is Zipkin dot io so you can go and check that out as well excellent well thank you Luke for this guided tour that you have offered to us about distributed tracing this is a really interesting area I think for helping developers and distributed systems be able to grasp what is going on how to solve some of the hard problems how to track down those long tail agencies it's a real enabler for that you know that's a very big deal so one more advertisement before we go if you will happen to be at the strata data conference in New York City here in late September we will have a data Stax presence there and and I will be there along with Patrick McFadden and David Gilardi Sebastien NIST Eva's who's been a guest on the show I think will also be hanging out so there would be a good variety of characters there and we'd love to meet you if you have want to come and and see us at the data sex booth at strata thanks a lot and we'll see you next time thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data stacks Academy and tell us what you think you can also find us on the data stacks Academy YouTube channel or find our podcast on iTunes Google Play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode you [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.31,
        "duration": 4.29,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.6,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.13,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.67,
        "text": "large-scale distributed systems welcome"
      },
      {
        "start": 16.59,
        "duration": 4.65,
        "text": "once again distributed data show I'm"
      },
      {
        "start": 19.32,
        "duration": 4.17,
        "text": "Jeff carpenter and I'm here in the"
      },
      {
        "start": 21.24,
        "duration": 5.31,
        "text": "studio today with Luke Tillman hello"
      },
      {
        "start": 23.49,
        "duration": 7.08,
        "text": "everyone so I don't know what everyone"
      },
      {
        "start": 26.55,
        "duration": 6.93,
        "text": "thinks an evangelist does but it turns"
      },
      {
        "start": 30.57,
        "duration": 4.86,
        "text": "out that we actually have real developer"
      },
      {
        "start": 33.48,
        "duration": 3.87,
        "text": "chops were real people real developers"
      },
      {
        "start": 35.43,
        "duration": 5.969,
        "text": "real software engineers and architects"
      },
      {
        "start": 37.35,
        "duration": 6.54,
        "text": "too and we happen to do a lot of fun"
      },
      {
        "start": 41.399,
        "duration": 4.32,
        "text": "stuff to promote things that we love and"
      },
      {
        "start": 43.89,
        "duration": 4.56,
        "text": "talk about things that we love but you"
      },
      {
        "start": 45.719,
        "duration": 5.101,
        "text": "know we're developers and technologists"
      },
      {
        "start": 48.45,
        "duration": 4.62,
        "text": "at heart so I want to talk to a little"
      },
      {
        "start": 50.82,
        "duration": 5.07,
        "text": "to Luke a little bit about what you've"
      },
      {
        "start": 53.07,
        "duration": 5.309,
        "text": "been doing lately because I would"
      },
      {
        "start": 55.89,
        "duration": 4.62,
        "text": "consider you maybe this is term is"
      },
      {
        "start": 58.379,
        "duration": 4.291,
        "text": "overused and over baked a little bit but"
      },
      {
        "start": 60.51,
        "duration": 4.53,
        "text": "a full-stack developer would you own"
      },
      {
        "start": 62.67,
        "duration": 3.48,
        "text": "that would you own that or not yeah you"
      },
      {
        "start": 65.04,
        "duration": 3.06,
        "text": "know it's funny I saw a tweet this"
      },
      {
        "start": 66.15,
        "duration": 2.91,
        "text": "morning somebody said my favorite my"
      },
      {
        "start": 68.1,
        "duration": 2.309,
        "text": "favorite part of looking through a"
      },
      {
        "start": 69.06,
        "duration": 3.809,
        "text": "codebase where a full-stack developer"
      },
      {
        "start": 70.409,
        "duration": 3.921,
        "text": "has has worked on it is figuring out"
      },
      {
        "start": 72.869,
        "duration": 5.761,
        "text": "which part of the stack they didn't know"
      },
      {
        "start": 74.33,
        "duration": 6.31,
        "text": "which is totally true yeah like it's a I"
      },
      {
        "start": 78.63,
        "duration": 6.21,
        "text": "mean yeah I know a little I know enough"
      },
      {
        "start": 80.64,
        "duration": 6.39,
        "text": "to be dangerous I think legit that I"
      },
      {
        "start": 84.84,
        "duration": 4.11,
        "text": "think that you're a legit full stack"
      },
      {
        "start": 87.03,
        "duration": 3.21,
        "text": "developer and the and maybe the proper"
      },
      {
        "start": 88.95,
        "duration": 3.45,
        "text": "sense of the word I'll give you the"
      },
      {
        "start": 90.24,
        "duration": 4.68,
        "text": "credit for that so I want to hear about"
      },
      {
        "start": 92.4,
        "duration": 6.21,
        "text": "your latest project that you're working"
      },
      {
        "start": 94.92,
        "duration": 7.379,
        "text": "on ok so um it just don't call me a 10x"
      },
      {
        "start": 98.61,
        "duration": 7.23,
        "text": "developer like that oh no way yeah that"
      },
      {
        "start": 102.299,
        "duration": 5.551,
        "text": "term derives me crazy so yeah so I'm a"
      },
      {
        "start": 105.84,
        "duration": 5.19,
        "text": "Technical Evangelist right I've been"
      },
      {
        "start": 107.85,
        "duration": 6.75,
        "text": "with the attacks now for going on for"
      },
      {
        "start": 111.03,
        "duration": 4.799,
        "text": "years and you know originally one of the"
      },
      {
        "start": 114.6,
        "duration": 2.46,
        "text": "original projects that I worked on when"
      },
      {
        "start": 115.829,
        "duration": 2.281,
        "text": "I started at theta stacks was killer"
      },
      {
        "start": 117.06,
        "duration": 3.809,
        "text": "video which was our reference"
      },
      {
        "start": 118.11,
        "duration": 3.869,
        "text": "application that now you and and David"
      },
      {
        "start": 120.869,
        "duration": 2.941,
        "text": "Gilardi have kind of taken over"
      },
      {
        "start": 121.979,
        "duration": 3.541,
        "text": "stewardship of"
      },
      {
        "start": 123.81,
        "duration": 3.0,
        "text": "we haven't screwed it up yet yeah"
      },
      {
        "start": 125.52,
        "duration": 5.67,
        "text": "hopefully you know don't screw that up"
      },
      {
        "start": 126.81,
        "duration": 5.43,
        "text": "but so for me as an evangelist one thing"
      },
      {
        "start": 131.19,
        "duration": 4.29,
        "text": "that's really important is getting my"
      },
      {
        "start": 132.24,
        "duration": 5.94,
        "text": "hands on technology and you know I like"
      },
      {
        "start": 135.48,
        "duration": 4.05,
        "text": "I just love writing code and so you know"
      },
      {
        "start": 138.18,
        "duration": 2.55,
        "text": "to me it's like I always want to have a"
      },
      {
        "start": 139.53,
        "duration": 2.31,
        "text": "project I always want to have something"
      },
      {
        "start": 140.73,
        "duration": 2.88,
        "text": "where I'm writing code or doing"
      },
      {
        "start": 141.84,
        "duration": 5.64,
        "text": "something and so I kind of had an"
      },
      {
        "start": 143.61,
        "duration": 6.18,
        "text": "opportunity where our Academy site DSA"
      },
      {
        "start": 147.48,
        "duration": 4.34,
        "text": "for short so data stacks Academy this is"
      },
      {
        "start": 149.79,
        "duration": 8.1,
        "text": "Academy data stacks comm there you go"
      },
      {
        "start": 151.82,
        "duration": 8.26,
        "text": "like shameless plug so we had this"
      },
      {
        "start": 157.89,
        "duration": 6.06,
        "text": "project where we wanted to kind of do"
      },
      {
        "start": 160.08,
        "duration": 7.11,
        "text": "some more dogfooding of our own are are"
      },
      {
        "start": 163.95,
        "duration": 5.52,
        "text": "being data stacks own product so we"
      },
      {
        "start": 167.19,
        "duration": 4.2,
        "text": "wanted to start building more parts of"
      },
      {
        "start": 169.47,
        "duration": 4.17,
        "text": "the Academy site that people go and"
      },
      {
        "start": 171.39,
        "duration": 5.64,
        "text": "learn on on top of data stacks"
      },
      {
        "start": 173.64,
        "duration": 7.349,
        "text": "Enterprise so we actually have a cloud"
      },
      {
        "start": 177.03,
        "duration": 6.42,
        "text": "scale data problem right we do"
      },
      {
        "start": 180.989,
        "duration": 5.731,
        "text": "justifiable usage of our own product I"
      },
      {
        "start": 183.45,
        "duration": 4.71,
        "text": "love it yeah so so what we were so the"
      },
      {
        "start": 186.72,
        "duration": 4.29,
        "text": "problem in particular that we were kind"
      },
      {
        "start": 188.16,
        "duration": 4.92,
        "text": "of trying to solve was people are like"
      },
      {
        "start": 191.01,
        "duration": 4.5,
        "text": "as people come on to data stacks Academy"
      },
      {
        "start": 193.08,
        "duration": 4.469,
        "text": "and they take courses and those courses"
      },
      {
        "start": 195.51,
        "duration": 4.759,
        "text": "have units in them and they kind of like"
      },
      {
        "start": 197.549,
        "duration": 5.341,
        "text": "make progress as they go along through"
      },
      {
        "start": 200.269,
        "duration": 4.151,
        "text": "through those courses we want to record"
      },
      {
        "start": 202.89,
        "duration": 4.05,
        "text": "you know how far along are you in the"
      },
      {
        "start": 204.42,
        "duration": 4.2,
        "text": "course where did you leave off you know"
      },
      {
        "start": 206.94,
        "duration": 4.019,
        "text": "like right and you can imagine that you"
      },
      {
        "start": 208.62,
        "duration": 4.8,
        "text": "know we have you know not a huge number"
      },
      {
        "start": 210.959,
        "duration": 5.161,
        "text": "of courses right now but a good amount"
      },
      {
        "start": 213.42,
        "duration": 4.02,
        "text": "of free content up there and you know if"
      },
      {
        "start": 216.12,
        "duration": 3.06,
        "text": "you break it down to the unit level"
      },
      {
        "start": 217.44,
        "duration": 3.51,
        "text": "we've got even more inside of each of"
      },
      {
        "start": 219.18,
        "duration": 4.41,
        "text": "those courses and then you multiply that"
      },
      {
        "start": 220.95,
        "duration": 5.009,
        "text": "by all the number of users that we have"
      },
      {
        "start": 223.59,
        "duration": 6.36,
        "text": "which we do have a bunch you know quite"
      },
      {
        "start": 225.959,
        "duration": 5.791,
        "text": "a few users on Dax Academy and what we"
      },
      {
        "start": 229.95,
        "duration": 3.3,
        "text": "had is we had this table where we were"
      },
      {
        "start": 231.75,
        "duration": 3.57,
        "text": "storing all of this progress information"
      },
      {
        "start": 233.25,
        "duration": 3.84,
        "text": "on who made progress and when they made"
      },
      {
        "start": 235.32,
        "duration": 3.57,
        "text": "it and where where are they and stuff"
      },
      {
        "start": 237.09,
        "duration": 5.399,
        "text": "easily talking millions of data points"
      },
      {
        "start": 238.89,
        "duration": 5.069,
        "text": "yeah and and and and as the number of"
      },
      {
        "start": 242.489,
        "duration": 2.911,
        "text": "courses continued to grow and as the"
      },
      {
        "start": 243.959,
        "duration": 4.351,
        "text": "number of users continued to grow"
      },
      {
        "start": 245.4,
        "duration": 5.19,
        "text": "we could kind of see this table that was"
      },
      {
        "start": 248.31,
        "duration": 4.08,
        "text": "in my sequel starting to creak a little"
      },
      {
        "start": 250.59,
        "duration": 4.2,
        "text": "bit and so it's so it's kind of like the"
      },
      {
        "start": 252.39,
        "duration": 4.05,
        "text": "classic it's funny like it's kind of"
      },
      {
        "start": 254.79,
        "duration": 5.04,
        "text": "like the classic"
      },
      {
        "start": 256.44,
        "duration": 5.64,
        "text": "how do we take and and like distribute"
      },
      {
        "start": 259.83,
        "duration": 4.5,
        "text": "this across you know this is this amount"
      },
      {
        "start": 262.08,
        "duration": 5.01,
        "text": "of data across more than one write more"
      },
      {
        "start": 264.33,
        "duration": 7.65,
        "text": "than one machine so hey I know how to"
      },
      {
        "start": 267.09,
        "duration": 6.6,
        "text": "solve that and so it was it's kind of a"
      },
      {
        "start": 271.98,
        "duration": 3.0,
        "text": "cool thing like we're standing up you"
      },
      {
        "start": 273.69,
        "duration": 3.36,
        "text": "know as part of this project it's kind"
      },
      {
        "start": 274.98,
        "duration": 4.58,
        "text": "of not only moved starting to move some"
      },
      {
        "start": 277.05,
        "duration": 5.0,
        "text": "of our data stacks Academy data on to"
      },
      {
        "start": 279.56,
        "duration": 4.87,
        "text": "data stacks Enterprise but we're also"
      },
      {
        "start": 282.05,
        "duration": 8.04,
        "text": "you know this is all going to be an AWS"
      },
      {
        "start": 284.43,
        "duration": 8.91,
        "text": "so we're gonna be a DMC ok whoa your"
      },
      {
        "start": 290.09,
        "duration": 4.66,
        "text": "acronyms yeah yeah spell it out so data"
      },
      {
        "start": 293.34,
        "duration": 4.56,
        "text": "stacks manage cloud so we're gonna be a"
      },
      {
        "start": 294.75,
        "duration": 4.98,
        "text": "data stacks managed cloud customer like"
      },
      {
        "start": 297.9,
        "duration": 3.96,
        "text": "an internal customer base exactly so"
      },
      {
        "start": 299.73,
        "duration": 4.53,
        "text": "they're gonna go ahead and run our DSC"
      },
      {
        "start": 301.86,
        "duration": 3.96,
        "text": "cluster for us but it was also kind of"
      },
      {
        "start": 304.26,
        "duration": 5.07,
        "text": "an opportunity to stand up an entirely"
      },
      {
        "start": 305.82,
        "duration": 5.85,
        "text": "new stack so behind the scenes were"
      },
      {
        "start": 309.33,
        "duration": 4.67,
        "text": "actually standing up even though most of"
      },
      {
        "start": 311.67,
        "duration": 4.95,
        "text": "the stocks academy has historically been"
      },
      {
        "start": 314.0,
        "duration": 4.15,
        "text": "PHP sort of Drupal based system like"
      },
      {
        "start": 316.62,
        "duration": 3.51,
        "text": "it's you know typical sort of like many"
      },
      {
        "start": 318.15,
        "duration": 4.89,
        "text": "apps that are yeah like a lot of content"
      },
      {
        "start": 320.13,
        "duration": 5.4,
        "text": "management the content management system"
      },
      {
        "start": 323.04,
        "duration": 4.02,
        "text": "like Drupal or WordPress so we're"
      },
      {
        "start": 325.53,
        "duration": 3.6,
        "text": "standing up an entirely new stack for"
      },
      {
        "start": 327.06,
        "duration": 3.63,
        "text": "some of this with where we're doing"
      },
      {
        "start": 329.13,
        "duration": 4.23,
        "text": "primarily most of the development in"
      },
      {
        "start": 330.69,
        "duration": 3.96,
        "text": "nodejs because it's an easy language for"
      },
      {
        "start": 333.36,
        "duration": 3.809,
        "text": "a lot of people to sort of pick up and"
      },
      {
        "start": 334.65,
        "duration": 5.91,
        "text": "and a lot of people on the team already"
      },
      {
        "start": 337.169,
        "duration": 6.361,
        "text": "kind of have that that language those"
      },
      {
        "start": 340.56,
        "duration": 5.52,
        "text": "language skills right okay so you you"
      },
      {
        "start": 343.53,
        "duration": 4.83,
        "text": "pick this new technology stack what"
      },
      {
        "start": 346.08,
        "duration": 4.589,
        "text": "about architectural eru on the"
      },
      {
        "start": 348.36,
        "duration": 4.11,
        "text": "microservices bandwagon oh yes so you"
      },
      {
        "start": 350.669,
        "duration": 3.75,
        "text": "know everybody's everybody's on the"
      },
      {
        "start": 352.47,
        "duration": 3.69,
        "text": "microservices bang bandwagon these days"
      },
      {
        "start": 354.419,
        "duration": 3.361,
        "text": "so yeah we're trying to do a"
      },
      {
        "start": 356.16,
        "duration": 3.9,
        "text": "microservices architecture behind the"
      },
      {
        "start": 357.78,
        "duration": 5.04,
        "text": "scenes sort of do a modern do a modern"
      },
      {
        "start": 360.06,
        "duration": 4.44,
        "text": "architecture you know we haven't you"
      },
      {
        "start": 362.82,
        "duration": 4.41,
        "text": "know I feel like microservices is almost"
      },
      {
        "start": 364.5,
        "duration": 4.23,
        "text": "like it's almost like passe at this"
      },
      {
        "start": 367.23,
        "duration": 3.33,
        "text": "point like we're you know like people"
      },
      {
        "start": 368.73,
        "duration": 4.35,
        "text": "are starting to move on to server lists"
      },
      {
        "start": 370.56,
        "duration": 4.53,
        "text": "and functions as a service and yo I see"
      },
      {
        "start": 373.08,
        "duration": 3.54,
        "text": "right it's almost like Pico services"
      },
      {
        "start": 375.09,
        "duration": 5.82,
        "text": "well maybe we better start talking about"
      },
      {
        "start": 376.62,
        "duration": 6.72,
        "text": "something else then no III just"
      },
      {
        "start": 380.91,
        "duration": 6.509,
        "text": "so I've done a micro services"
      },
      {
        "start": 383.34,
        "duration": 5.639,
        "text": "architecture myself on a past life so I"
      },
      {
        "start": 387.419,
        "duration": 1.921,
        "text": "know a little bit of the ins and outs"
      },
      {
        "start": 388.979,
        "duration": 1.921,
        "text": "and"
      },
      {
        "start": 389.34,
        "duration": 4.2,
        "text": "some of the temptations especially if"
      },
      {
        "start": 390.9,
        "duration": 4.049,
        "text": "you're starting with everyone talks"
      },
      {
        "start": 393.54,
        "duration": 3.39,
        "text": "about you know hate carving up a"
      },
      {
        "start": 394.949,
        "duration": 3.741,
        "text": "monolith and carving off microservices"
      },
      {
        "start": 396.93,
        "duration": 5.01,
        "text": "and using strangler pattern to kind of"
      },
      {
        "start": 398.69,
        "duration": 5.47,
        "text": "carve off little bits at a time and"
      },
      {
        "start": 401.94,
        "duration": 4.56,
        "text": "start with your lowest risk services and"
      },
      {
        "start": 404.16,
        "duration": 6.09,
        "text": "we a lot of us have probably heard that"
      },
      {
        "start": 406.5,
        "duration": 5.31,
        "text": "sort of methodology okay but I've done"
      },
      {
        "start": 410.25,
        "duration": 2.82,
        "text": "this and you're doing this to where"
      },
      {
        "start": 411.81,
        "duration": 4.47,
        "text": "you're actually starting from scratch"
      },
      {
        "start": 413.07,
        "duration": 6.99,
        "text": "with micro-services what are the perils"
      },
      {
        "start": 416.28,
        "duration": 5.34,
        "text": "and pitfalls so we could do a whole show"
      },
      {
        "start": 420.06,
        "duration": 3.93,
        "text": "about the perils and pitfalls probably"
      },
      {
        "start": 421.62,
        "duration": 3.63,
        "text": "of once you like once you take a system"
      },
      {
        "start": 423.99,
        "duration": 2.76,
        "text": "and just distribute it you know and like"
      },
      {
        "start": 425.25,
        "duration": 4.5,
        "text": "put the network in the middle like holy"
      },
      {
        "start": 426.75,
        "duration": 4.95,
        "text": "crap but you know that so one one thing"
      },
      {
        "start": 429.75,
        "duration": 4.82,
        "text": "that is definitely a challenge once you"
      },
      {
        "start": 431.7,
        "duration": 6.0,
        "text": "go to micro services and I think this"
      },
      {
        "start": 434.57,
        "duration": 6.219,
        "text": "this is something that people run into a"
      },
      {
        "start": 437.7,
        "duration": 6.089,
        "text": "quite a bit is is observability right so"
      },
      {
        "start": 440.789,
        "duration": 4.231,
        "text": "observability becomes super important"
      },
      {
        "start": 443.789,
        "duration": 3.331,
        "text": "once you once you've taken something"
      },
      {
        "start": 445.02,
        "duration": 3.78,
        "text": "that was you know kind of a single thing"
      },
      {
        "start": 447.12,
        "duration": 4.019,
        "text": "running in process sort of the monolith"
      },
      {
        "start": 448.8,
        "duration": 4.8,
        "text": "kind of thing and you start breaking it"
      },
      {
        "start": 451.139,
        "duration": 5.961,
        "text": "out across multiple processes"
      },
      {
        "start": 453.6,
        "duration": 7.439,
        "text": "distributed around a network you know"
      },
      {
        "start": 457.1,
        "duration": 7.15,
        "text": "you you start to you start to run into"
      },
      {
        "start": 461.039,
        "duration": 7.111,
        "text": "the problem of for example you know if a"
      },
      {
        "start": 464.25,
        "duration": 6.57,
        "text": "call is slow how do I know what was slow"
      },
      {
        "start": 468.15,
        "duration": 4.829,
        "text": "in that like in that call like once you"
      },
      {
        "start": 470.82,
        "duration": 3.63,
        "text": "know once things are fanning out to all"
      },
      {
        "start": 472.979,
        "duration": 4.44,
        "text": "these you know to all these different"
      },
      {
        "start": 474.45,
        "duration": 5.79,
        "text": "micro services you know how do I sort of"
      },
      {
        "start": 477.419,
        "duration": 3.961,
        "text": "how do I keep track of you know what's"
      },
      {
        "start": 480.24,
        "duration": 3.929,
        "text": "going on in my system how do I know"
      },
      {
        "start": 481.38,
        "duration": 6.06,
        "text": "what's going on in my system and so this"
      },
      {
        "start": 484.169,
        "duration": 5.041,
        "text": "is where the idea of distributed tracing"
      },
      {
        "start": 487.44,
        "duration": 2.699,
        "text": "has become super popular over the last"
      },
      {
        "start": 489.21,
        "duration": 4.53,
        "text": "few years"
      },
      {
        "start": 490.139,
        "duration": 6.481,
        "text": "gotcha okay excellent so what do you"
      },
      {
        "start": 493.74,
        "duration": 4.649,
        "text": "mean by distributed tracing unpack that"
      },
      {
        "start": 496.62,
        "duration": 3.72,
        "text": "a little bit and maybe you know what"
      },
      {
        "start": 498.389,
        "duration": 5.061,
        "text": "what problem are you trying to solve by"
      },
      {
        "start": 500.34,
        "duration": 5.49,
        "text": "introducing distributed tracing yeah so"
      },
      {
        "start": 503.45,
        "duration": 5.29,
        "text": "maybe you it's good to start with maybe"
      },
      {
        "start": 505.83,
        "duration": 4.589,
        "text": "kind of a description of what does the"
      },
      {
        "start": 508.74,
        "duration": 3.33,
        "text": "you know kind of the architecture of the"
      },
      {
        "start": 510.419,
        "duration": 5.731,
        "text": "thing that I've been building look like"
      },
      {
        "start": 512.07,
        "duration": 5.399,
        "text": "and so if we have I love arc I love"
      },
      {
        "start": 516.15,
        "duration": 4.41,
        "text": "hearing about people's architectures"
      },
      {
        "start": 517.469,
        "duration": 4.561,
        "text": "yeah yeah so like just briefly kind of"
      },
      {
        "start": 520.56,
        "duration": 3.9,
        "text": "what we have is we"
      },
      {
        "start": 522.03,
        "duration": 3.99,
        "text": "you know react components on the front"
      },
      {
        "start": 524.46,
        "duration": 3.51,
        "text": "end so we're you know we're still having"
      },
      {
        "start": 526.02,
        "duration": 4.26,
        "text": "to integrate this with the existing data"
      },
      {
        "start": 527.97,
        "duration": 4.44,
        "text": "stacks Academy site and so you know"
      },
      {
        "start": 530.28,
        "duration": 3.84,
        "text": "we've got these sort of smaller react"
      },
      {
        "start": 532.41,
        "duration": 3.93,
        "text": "components that we can embed in"
      },
      {
        "start": 534.12,
        "duration": 4.65,
        "text": "different parts of the existing a sort"
      },
      {
        "start": 536.34,
        "duration": 3.9,
        "text": "of Drupal site and those react"
      },
      {
        "start": 538.77,
        "duration": 5.07,
        "text": "components on the front end they are"
      },
      {
        "start": 540.24,
        "duration": 5.46,
        "text": "talking to an API like running on a web"
      },
      {
        "start": 543.84,
        "duration": 3.51,
        "text": "server that's actually talking graph QL"
      },
      {
        "start": 545.7,
        "duration": 3.9,
        "text": "so I don't know if anybody's ever gone"
      },
      {
        "start": 547.35,
        "duration": 5.19,
        "text": "and an investigative graph QL but this"
      },
      {
        "start": 549.6,
        "duration": 6.66,
        "text": "is a project from from Facebook kind of"
      },
      {
        "start": 552.54,
        "duration": 5.88,
        "text": "cool way of doing API is especially when"
      },
      {
        "start": 556.26,
        "duration": 3.9,
        "text": "you're using your front-end to talk to"
      },
      {
        "start": 558.42,
        "duration": 3.18,
        "text": "some sort of back-end so we've got this"
      },
      {
        "start": 560.16,
        "duration": 3.81,
        "text": "graph QL API"
      },
      {
        "start": 561.6,
        "duration": 4.44,
        "text": "you know github actually just released a"
      },
      {
        "start": 563.97,
        "duration": 4.77,
        "text": "giant graph QL API for all of their like"
      },
      {
        "start": 566.04,
        "duration": 5.1,
        "text": "all of their developer it guys so you've"
      },
      {
        "start": 568.74,
        "duration": 4.98,
        "text": "seen some adoption out there and they're"
      },
      {
        "start": 571.14,
        "duration": 3.06,
        "text": "probably this graph QL API then it it"
      },
      {
        "start": 573.72,
        "duration": 2.58,
        "text": "takes"
      },
      {
        "start": 574.2,
        "duration": 5.25,
        "text": "and as people request different parts of"
      },
      {
        "start": 576.3,
        "duration": 5.25,
        "text": "our graph sort of our graph of things"
      },
      {
        "start": 579.45,
        "duration": 5.07,
        "text": "that the front-end might need access to"
      },
      {
        "start": 581.55,
        "duration": 5.43,
        "text": "like courses and units and users and all"
      },
      {
        "start": 584.52,
        "duration": 4.83,
        "text": "of these things those calls then get"
      },
      {
        "start": 586.98,
        "duration": 4.85,
        "text": "translated by the graph QL API on a web"
      },
      {
        "start": 589.35,
        "duration": 5.66,
        "text": "server somewhere to the kind of fan-out"
      },
      {
        "start": 591.83,
        "duration": 5.92,
        "text": "to micro services on the backend and so"
      },
      {
        "start": 595.01,
        "duration": 5.35,
        "text": "you know originally we were using G RPC"
      },
      {
        "start": 597.75,
        "duration": 3.72,
        "text": "and you can this could be rust api's you"
      },
      {
        "start": 600.36,
        "duration": 2.46,
        "text": "know on the backend you really you could"
      },
      {
        "start": 601.47,
        "duration": 2.73,
        "text": "be using whatever you want for your"
      },
      {
        "start": 602.82,
        "duration": 3.69,
        "text": "micro services that are running on the"
      },
      {
        "start": 604.2,
        "duration": 3.81,
        "text": "backend and so the graph QL API is"
      },
      {
        "start": 606.51,
        "duration": 3.81,
        "text": "basically kind of just acting as an API"
      },
      {
        "start": 608.01,
        "duration": 4.38,
        "text": "gateway that fans out to these various"
      },
      {
        "start": 610.32,
        "duration": 3.57,
        "text": "micro services and so the problem you're"
      },
      {
        "start": 612.39,
        "duration": 3.33,
        "text": "trying to solve with distributed tracing"
      },
      {
        "start": 613.89,
        "duration": 3.42,
        "text": "is you know okay this you got this call"
      },
      {
        "start": 615.72,
        "duration": 3.6,
        "text": "that starts on the client in the browser"
      },
      {
        "start": 617.31,
        "duration": 5.01,
        "text": "for example with these react components"
      },
      {
        "start": 619.32,
        "duration": 5.31,
        "text": "it goes to this graph QL server that"
      },
      {
        "start": 622.32,
        "duration": 4.38,
        "text": "this graph QL API server you know that's"
      },
      {
        "start": 624.63,
        "duration": 7.26,
        "text": "a web server and then that may fan out"
      },
      {
        "start": 626.7,
        "duration": 7.98,
        "text": "to two or three or ten or who knows how"
      },
      {
        "start": 631.89,
        "duration": 4.38,
        "text": "many remember service calls yeah so how"
      },
      {
        "start": 634.68,
        "duration": 3.99,
        "text": "do you know like first of all how many"
      },
      {
        "start": 636.27,
        "duration": 4.35,
        "text": "like how many micro service calls are"
      },
      {
        "start": 638.67,
        "duration": 4.14,
        "text": "happening as a result of your front-end"
      },
      {
        "start": 640.62,
        "duration": 4.47,
        "text": "right you know calling the backend how"
      },
      {
        "start": 642.81,
        "duration": 4.05,
        "text": "do I get some observability into you"
      },
      {
        "start": 645.09,
        "duration": 4.98,
        "text": "know like wow did I really write some"
      },
      {
        "start": 646.86,
        "duration": 4.92,
        "text": "super inefficient you know like I'm"
      },
      {
        "start": 650.07,
        "duration": 3.57,
        "text": "making tons of calls that I shouldn't be"
      },
      {
        "start": 651.78,
        "duration": 3.27,
        "text": "this is kind of like oh RMS when you"
      },
      {
        "start": 653.64,
        "duration": 2.94,
        "text": "used to have the Select and Plus"
      },
      {
        "start": 655.05,
        "duration": 3.39,
        "text": "one problem where an orm would generate"
      },
      {
        "start": 656.58,
        "duration": 3.54,
        "text": "like a sequel query that would would"
      },
      {
        "start": 658.44,
        "duration": 2.94,
        "text": "generate up you know 50 sequel queries"
      },
      {
        "start": 660.12,
        "duration": 3.089,
        "text": "kind of thing in my so you want to know"
      },
      {
        "start": 661.38,
        "duration": 5.07,
        "text": "am i generating like 50 micro-services"
      },
      {
        "start": 663.209,
        "duration": 4.56,
        "text": "calls from from one sort of call from"
      },
      {
        "start": 666.45,
        "duration": 3.15,
        "text": "the front-end and then how do I know"
      },
      {
        "start": 667.769,
        "duration": 3.541,
        "text": "like what you know if it's slow how do I"
      },
      {
        "start": 669.6,
        "duration": 3.57,
        "text": "know like where was it slow like was it"
      },
      {
        "start": 671.31,
        "duration": 4.2,
        "text": "a particular service you know was it"
      },
      {
        "start": 673.17,
        "duration": 4.68,
        "text": "that service for example talking to a"
      },
      {
        "start": 675.51,
        "duration": 4.53,
        "text": "database was that that service talking"
      },
      {
        "start": 677.85,
        "duration": 3.6,
        "text": "to some external service you know how do"
      },
      {
        "start": 680.04,
        "duration": 4.47,
        "text": "you get you know how do you figure that"
      },
      {
        "start": 681.45,
        "duration": 4.74,
        "text": "out so you know observability still is"
      },
      {
        "start": 684.51,
        "duration": 3.96,
        "text": "the problem that you're trying to solve"
      },
      {
        "start": 686.19,
        "duration": 4.709,
        "text": "okay so what were your technology"
      },
      {
        "start": 688.47,
        "duration": 5.52,
        "text": "choices that that you made there and how"
      },
      {
        "start": 690.899,
        "duration": 5.13,
        "text": "does this all work together right so um"
      },
      {
        "start": 693.99,
        "duration": 3.539,
        "text": "so there's a number of kind of things"
      },
      {
        "start": 696.029,
        "duration": 3.601,
        "text": "out there right now and what I ended up"
      },
      {
        "start": 697.529,
        "duration": 3.99,
        "text": "sort of settling on for the time being"
      },
      {
        "start": 699.63,
        "duration": 4.019,
        "text": "and and maybe at the end we can talk a"
      },
      {
        "start": 701.519,
        "duration": 4.801,
        "text": "little bit more about some other options"
      },
      {
        "start": 703.649,
        "duration": 6.0,
        "text": "but what I ended up doing was Zipkin so"
      },
      {
        "start": 706.32,
        "duration": 6.87,
        "text": "Zipkin is a pretty popular open-source"
      },
      {
        "start": 709.649,
        "duration": 5.661,
        "text": "project that is is for doing distributed"
      },
      {
        "start": 713.19,
        "duration": 6.36,
        "text": "tracing I think it's based on Google's"
      },
      {
        "start": 715.31,
        "duration": 6.13,
        "text": "dapper paper maybe yeah so basically"
      },
      {
        "start": 719.55,
        "duration": 4.56,
        "text": "you've got you have this framework it"
      },
      {
        "start": 721.44,
        "duration": 4.019,
        "text": "has you know it has plugins and code"
      },
      {
        "start": 724.11,
        "duration": 3.66,
        "text": "available essentially for multiple"
      },
      {
        "start": 725.459,
        "duration": 4.921,
        "text": "languages and sort of conceptually the"
      },
      {
        "start": 727.77,
        "duration": 4.23,
        "text": "idea it's pretty simple you know most"
      },
      {
        "start": 730.38,
        "duration": 2.73,
        "text": "most developers when they if they were"
      },
      {
        "start": 732.0,
        "duration": 3.18,
        "text": "to take a look at this would would"
      },
      {
        "start": 733.11,
        "duration": 4.44,
        "text": "probably get it right away that you know"
      },
      {
        "start": 735.18,
        "duration": 4.89,
        "text": "what we want to do is when you know when"
      },
      {
        "start": 737.55,
        "duration": 4.47,
        "text": "our client makes a call you know we want"
      },
      {
        "start": 740.07,
        "duration": 3.99,
        "text": "to start with some sort of tracing ID"
      },
      {
        "start": 742.02,
        "duration": 3.0,
        "text": "like some sort of unique identifier so"
      },
      {
        "start": 744.06,
        "duration": 2.01,
        "text": "you could think you know if you're"
      },
      {
        "start": 745.02,
        "duration": 4.319,
        "text": "familiar with the santur you might think"
      },
      {
        "start": 746.07,
        "duration": 5.61,
        "text": "of this as a UUID kind of scenario where"
      },
      {
        "start": 749.339,
        "duration": 3.931,
        "text": "i've got some sort of unique ID for for"
      },
      {
        "start": 751.68,
        "duration": 5.13,
        "text": "a call that starts on the client and"
      },
      {
        "start": 753.27,
        "duration": 5.34,
        "text": "then when that call reaches my web"
      },
      {
        "start": 756.81,
        "duration": 4.399,
        "text": "server so in my case it was a graph qlo"
      },
      {
        "start": 758.61,
        "duration": 5.7,
        "text": "api server you know i have some way to"
      },
      {
        "start": 761.209,
        "duration": 5.531,
        "text": "basically pull that tracing ID out that"
      },
      {
        "start": 764.31,
        "duration": 5.01,
        "text": "was created you know at the client and"
      },
      {
        "start": 766.74,
        "duration": 4.8,
        "text": "then I want to propagate that make sure"
      },
      {
        "start": 769.32,
        "duration": 6.0,
        "text": "that tracing ID gets propagated to all"
      },
      {
        "start": 771.54,
        "duration": 4.739,
        "text": "of the sort of all the child calls then"
      },
      {
        "start": 775.32,
        "duration": 3.019,
        "text": "that might so all the other"
      },
      {
        "start": 776.279,
        "duration": 5.281,
        "text": "communication that goes on whether it's"
      },
      {
        "start": 778.339,
        "duration": 7.12,
        "text": "HTTP calls to other micro services or"
      },
      {
        "start": 781.56,
        "duration": 5.46,
        "text": "it's those it's those micro services"
      },
      {
        "start": 785.459,
        "duration": 2.281,
        "text": "then making calls to their databases"
      },
      {
        "start": 787.02,
        "duration": 2.31,
        "text": "over teas"
      },
      {
        "start": 787.74,
        "duration": 4.8,
        "text": "connections or whatever it is they use"
      },
      {
        "start": 789.33,
        "duration": 6.36,
        "text": "basically I want to keep track of how"
      },
      {
        "start": 792.54,
        "duration": 5.46,
        "text": "long first of all each of those each of"
      },
      {
        "start": 795.69,
        "duration": 4.53,
        "text": "those calls takes but then I also want"
      },
      {
        "start": 798.0,
        "duration": 4.35,
        "text": "to make sure that it's all that all of"
      },
      {
        "start": 800.22,
        "duration": 4.29,
        "text": "those calls are sort of tied together by"
      },
      {
        "start": 802.35,
        "duration": 6.18,
        "text": "a single tracing ID so I can sort of see"
      },
      {
        "start": 804.51,
        "duration": 5.52,
        "text": "the the anatomy you know how many how"
      },
      {
        "start": 808.53,
        "duration": 3.75,
        "text": "many calls were made to other services"
      },
      {
        "start": 810.03,
        "duration": 4.38,
        "text": "and and be able to correlate it all back"
      },
      {
        "start": 812.28,
        "duration": 4.8,
        "text": "to a single sort of client request that"
      },
      {
        "start": 814.41,
        "duration": 5.67,
        "text": "kicked it off okay gotcha gotcha so is"
      },
      {
        "start": 817.08,
        "duration": 4.77,
        "text": "there sort of a an expansion factor"
      },
      {
        "start": 820.08,
        "duration": 4.98,
        "text": "there you've got that one client call"
      },
      {
        "start": 821.85,
        "duration": 5.58,
        "text": "that initiated everything and then does"
      },
      {
        "start": 825.06,
        "duration": 5.19,
        "text": "that expand out into other IDs below"
      },
      {
        "start": 827.43,
        "duration": 5.43,
        "text": "that yes so so the idea at least in sip"
      },
      {
        "start": 830.25,
        "duration": 4.77,
        "text": "can the the sort of the data model are"
      },
      {
        "start": 832.86,
        "duration": 4.44,
        "text": "sort of the nomenclature they use is"
      },
      {
        "start": 835.02,
        "duration": 4.59,
        "text": "they call these spans so you have one"
      },
      {
        "start": 837.3,
        "duration": 4.74,
        "text": "route span which basically spans the"
      },
      {
        "start": 839.61,
        "duration": 3.57,
        "text": "entire duration starting on the client"
      },
      {
        "start": 842.04,
        "duration": 1.62,
        "text": "from the time the client makes the"
      },
      {
        "start": 843.18,
        "duration": 3.3,
        "text": "request"
      },
      {
        "start": 843.66,
        "duration": 5.1,
        "text": "so our react component all the way until"
      },
      {
        "start": 846.48,
        "duration": 3.45,
        "text": "the client receives a response so you"
      },
      {
        "start": 848.76,
        "duration": 3.45,
        "text": "know it got a response back from the"
      },
      {
        "start": 849.93,
        "duration": 3.96,
        "text": "graph QL API server but then underneath"
      },
      {
        "start": 852.21,
        "duration": 3.63,
        "text": "that you know sort of route span you"
      },
      {
        "start": 853.89,
        "duration": 5.25,
        "text": "might have a bunch of child spans which"
      },
      {
        "start": 855.84,
        "duration": 5.16,
        "text": "are you know your calls to the other"
      },
      {
        "start": 859.14,
        "duration": 4.32,
        "text": "services so you know the graph QL API"
      },
      {
        "start": 861.0,
        "duration": 5.04,
        "text": "calls the user service or calls the"
      },
      {
        "start": 863.46,
        "duration": 4.11,
        "text": "course controller service and and those"
      },
      {
        "start": 866.04,
        "duration": 3.33,
        "text": "spans have their own timing information"
      },
      {
        "start": 867.57,
        "duration": 4.38,
        "text": "and have maybe their own meta data"
      },
      {
        "start": 869.37,
        "duration": 4.5,
        "text": "that's being collected and then you can"
      },
      {
        "start": 871.95,
        "duration": 3.57,
        "text": "even have you know it's completely"
      },
      {
        "start": 873.87,
        "duration": 4.23,
        "text": "messed in"
      },
      {
        "start": 875.52,
        "duration": 4.14,
        "text": "that service then maybe it makes a call"
      },
      {
        "start": 878.1,
        "duration": 2.82,
        "text": "to a database or something like that and"
      },
      {
        "start": 879.66,
        "duration": 4.14,
        "text": "so you could have a child span"
      },
      {
        "start": 880.92,
        "duration": 4.38,
        "text": "underneath you know underneath the you"
      },
      {
        "start": 883.8,
        "duration": 3.66,
        "text": "know so two levels deep here and we've"
      },
      {
        "start": 885.3,
        "duration": 3.6,
        "text": "got timing information for how long it"
      },
      {
        "start": 887.46,
        "duration": 3.6,
        "text": "took to do a sequel query or something"
      },
      {
        "start": 888.9,
        "duration": 4.53,
        "text": "like that right okay so what about sort"
      },
      {
        "start": 891.06,
        "duration": 4.8,
        "text": "of aggregating upward one of the things"
      },
      {
        "start": 893.43,
        "duration": 5.4,
        "text": "that I've seen is a need to identify"
      },
      {
        "start": 895.86,
        "duration": 5.37,
        "text": "errors or let's say Layton sees"
      },
      {
        "start": 898.83,
        "duration": 4.05,
        "text": "associated with a particular user login"
      },
      {
        "start": 901.23,
        "duration": 3.84,
        "text": "session so is there a way to sort of"
      },
      {
        "start": 902.88,
        "duration": 4.05,
        "text": "aggregate that up multiple user calls"
      },
      {
        "start": 905.07,
        "duration": 5.1,
        "text": "for that for the same user into a"
      },
      {
        "start": 906.93,
        "duration": 5.31,
        "text": "session concept right so um we used to"
      },
      {
        "start": 910.17,
        "duration": 4.08,
        "text": "get this all the time my last company my"
      },
      {
        "start": 912.24,
        "duration": 4.2,
        "text": "last company Hobson's we were kind of a"
      },
      {
        "start": 914.25,
        "duration": 3.6,
        "text": "software-as-a-service company and you"
      },
      {
        "start": 916.44,
        "duration": 2.82,
        "text": "know you get support tickets and I'm"
      },
      {
        "start": 917.85,
        "duration": 3.03,
        "text": "sure a lot of people have probably"
      },
      {
        "start": 919.26,
        "duration": 2.16,
        "text": "probably had this where a user is"
      },
      {
        "start": 920.88,
        "duration": 2.61,
        "text": "complaining"
      },
      {
        "start": 921.42,
        "duration": 4.71,
        "text": "X is slow it's all it's driven by the"
      },
      {
        "start": 923.49,
        "duration": 4.77,
        "text": "helpdesk right yeah yes and and so you"
      },
      {
        "start": 926.13,
        "duration": 4.53,
        "text": "might have some sort of what's that"
      },
      {
        "start": 928.26,
        "duration": 4.14,
        "text": "users ID or what's that user's login or"
      },
      {
        "start": 930.66,
        "duration": 3.45,
        "text": "what was their session kind of thing or"
      },
      {
        "start": 932.4,
        "duration": 4.08,
        "text": "this might even start not not from like"
      },
      {
        "start": 934.11,
        "duration": 5.04,
        "text": "a helpdesk it might start from like logs"
      },
      {
        "start": 936.48,
        "duration": 5.43,
        "text": "right so you get err logs and the error"
      },
      {
        "start": 939.15,
        "duration": 4.26,
        "text": "log has information about you know your"
      },
      {
        "start": 941.91,
        "duration": 2.97,
        "text": "logging information about what session"
      },
      {
        "start": 943.41,
        "duration": 1.71,
        "text": "this error happened in or something like"
      },
      {
        "start": 944.88,
        "duration": 2.87,
        "text": "that"
      },
      {
        "start": 945.12,
        "duration": 4.83,
        "text": "and so yeah with with SIPC and you can"
      },
      {
        "start": 947.75,
        "duration": 5.62,
        "text": "you're kind of free to record whatever"
      },
      {
        "start": 949.95,
        "duration": 5.22,
        "text": "kind of metadata you want with each call"
      },
      {
        "start": 953.37,
        "duration": 3.57,
        "text": "with each span you can kind of associate"
      },
      {
        "start": 955.17,
        "duration": 3.81,
        "text": "whatever sort of they call them"
      },
      {
        "start": 956.94,
        "duration": 3.69,
        "text": "annotations right which are basically"
      },
      {
        "start": 958.98,
        "duration": 2.91,
        "text": "just key value pairs so it's you know"
      },
      {
        "start": 960.63,
        "duration": 3.48,
        "text": "you can kind of associate whatever data"
      },
      {
        "start": 961.89,
        "duration": 5.88,
        "text": "you want so you could absolutely record"
      },
      {
        "start": 964.11,
        "duration": 5.85,
        "text": "a user ID key value pair as part of your"
      },
      {
        "start": 967.77,
        "duration": 4.38,
        "text": "trace data or a session ID key value"
      },
      {
        "start": 969.96,
        "duration": 5.25,
        "text": "pair or you know and and it really"
      },
      {
        "start": 972.15,
        "duration": 5.19,
        "text": "actually varies kind of based on what"
      },
      {
        "start": 975.21,
        "duration": 5.85,
        "text": "you what it is you're tracing so you can"
      },
      {
        "start": 977.34,
        "duration": 5.88,
        "text": "imagine for an HTTP call we might you"
      },
      {
        "start": 981.06,
        "duration": 4.59,
        "text": "know we might record not just the timing"
      },
      {
        "start": 983.22,
        "duration": 4.05,
        "text": "information but also what was the status"
      },
      {
        "start": 985.65,
        "duration": 5.31,
        "text": "code that came back you know it wasn't a"
      },
      {
        "start": 987.27,
        "duration": 5.19,
        "text": "200 was it a 500 was it a 404 right that"
      },
      {
        "start": 990.96,
        "duration": 3.27,
        "text": "kind of thing so are we using like"
      },
      {
        "start": 992.46,
        "duration": 3.06,
        "text": "header requests and response headers for"
      },
      {
        "start": 994.23,
        "duration": 3.69,
        "text": "transmitting these so I don't have to"
      },
      {
        "start": 995.52,
        "duration": 4.92,
        "text": "build in I don't have to add like this"
      },
      {
        "start": 997.92,
        "duration": 4.35,
        "text": "arbitrary tracing ID parameter to every"
      },
      {
        "start": 1000.44,
        "duration": 4.07,
        "text": "method on my yeah yeah yes so that's"
      },
      {
        "start": 1002.27,
        "duration": 6.12,
        "text": "that's actually conceptually that's"
      },
      {
        "start": 1004.51,
        "duration": 6.13,
        "text": "Zipkin defines sort of these these sort"
      },
      {
        "start": 1008.39,
        "duration": 5.61,
        "text": "of well-known header names okay that are"
      },
      {
        "start": 1010.64,
        "duration": 5.85,
        "text": "like X - whatever that are for"
      },
      {
        "start": 1014.0,
        "duration": 3.6,
        "text": "propagating at least with HTTP calls you"
      },
      {
        "start": 1016.49,
        "duration": 3.21,
        "text": "know this is right this is how you"
      },
      {
        "start": 1017.6,
        "duration": 4.17,
        "text": "propagate you know this is how you"
      },
      {
        "start": 1019.7,
        "duration": 4.47,
        "text": "propagate the tracing ID to child"
      },
      {
        "start": 1021.77,
        "duration": 4.679,
        "text": "services and okay so on and so forth yep"
      },
      {
        "start": 1024.17,
        "duration": 4.47,
        "text": "okay so you're getting all of this"
      },
      {
        "start": 1026.449,
        "duration": 5.431,
        "text": "tracing data and you're able to"
      },
      {
        "start": 1028.64,
        "duration": 5.22,
        "text": "correlate it once presumably you're able"
      },
      {
        "start": 1031.88,
        "duration": 3.66,
        "text": "to look it up and find it somewhere so"
      },
      {
        "start": 1033.86,
        "duration": 3.33,
        "text": "we've skipped the part where we talked"
      },
      {
        "start": 1035.54,
        "duration": 3.51,
        "text": "about where you put all of this tracing"
      },
      {
        "start": 1037.19,
        "duration": 5.31,
        "text": "data can you talk about that yeah so"
      },
      {
        "start": 1039.05,
        "duration": 6.72,
        "text": "Zipkin like funny enough I guess it"
      },
      {
        "start": 1042.5,
        "duration": 6.09,
        "text": "supports Cassandra right so in our ad so"
      },
      {
        "start": 1045.77,
        "duration": 4.74,
        "text": "in our case what we're doing is we're"
      },
      {
        "start": 1048.59,
        "duration": 2.78,
        "text": "going to be storing this data directly"
      },
      {
        "start": 1050.51,
        "duration": 3.41,
        "text": "in our"
      },
      {
        "start": 1051.37,
        "duration": 4.11,
        "text": "EMC or adidas tux managed cloud cluster"
      },
      {
        "start": 1053.92,
        "duration": 3.18,
        "text": "so you know we'll have data stacks"
      },
      {
        "start": 1055.48,
        "duration": 3.99,
        "text": "enterprise cluster that's going to store"
      },
      {
        "start": 1057.1,
        "duration": 4.86,
        "text": "this tracing data and it you know when"
      },
      {
        "start": 1059.47,
        "duration": 5.01,
        "text": "it inserts data into Cassandra it has"
      },
      {
        "start": 1061.96,
        "duration": 4.41,
        "text": "like a default TTL on it so it's gonna"
      },
      {
        "start": 1064.48,
        "duration": 4.77,
        "text": "know okay you're not gonna be keeping"
      },
      {
        "start": 1066.37,
        "duration": 4.29,
        "text": "data around forever and I have some"
      },
      {
        "start": 1069.25,
        "duration": 2.61,
        "text": "other storage formats I think that they"
      },
      {
        "start": 1070.66,
        "duration": 2.58,
        "text": "support out of the box I can't remember"
      },
      {
        "start": 1071.86,
        "duration": 3.48,
        "text": "off the top my head right now what those"
      },
      {
        "start": 1073.24,
        "duration": 4.14,
        "text": "what those other storage mechanisms are"
      },
      {
        "start": 1075.34,
        "duration": 3.27,
        "text": "that they they support but they do"
      },
      {
        "start": 1077.38,
        "duration": 3.42,
        "text": "support some other ones and then it also"
      },
      {
        "start": 1078.61,
        "duration": 4.62,
        "text": "comes with sort of a UI then for"
      },
      {
        "start": 1080.8,
        "duration": 4.17,
        "text": "drilling down into that tracing data so"
      },
      {
        "start": 1083.23,
        "duration": 4.77,
        "text": "they've got this pretty simple little UI"
      },
      {
        "start": 1084.97,
        "duration": 4.89,
        "text": "for going in and finding for example the"
      },
      {
        "start": 1088.0,
        "duration": 3.69,
        "text": "most recent traces and you can kind of"
      },
      {
        "start": 1089.86,
        "duration": 4.47,
        "text": "look and you get a visual representation"
      },
      {
        "start": 1091.69,
        "duration": 4.44,
        "text": "of the spans and or you could find you"
      },
      {
        "start": 1094.33,
        "duration": 3.87,
        "text": "can go in and sort of sort them by what"
      },
      {
        "start": 1096.13,
        "duration": 3.72,
        "text": "are the longest traces yeah maybe you're"
      },
      {
        "start": 1098.2,
        "duration": 3.3,
        "text": "trying to try those long right trying to"
      },
      {
        "start": 1099.85,
        "duration": 3.57,
        "text": "long wait and see trying to find really"
      },
      {
        "start": 1101.5,
        "duration": 5.34,
        "text": "bad late and sees where people had a bad"
      },
      {
        "start": 1103.42,
        "duration": 4.74,
        "text": "time that's like it's yeah that can be"
      },
      {
        "start": 1106.84,
        "duration": 3.3,
        "text": "super helpful so you kind of get this"
      },
      {
        "start": 1108.16,
        "duration": 4.2,
        "text": "out of the box you also get this UI for"
      },
      {
        "start": 1110.14,
        "duration": 5.49,
        "text": "sort of drilling down into into what's"
      },
      {
        "start": 1112.36,
        "duration": 5.34,
        "text": "going on ok good so I'm pretty confident"
      },
      {
        "start": 1115.63,
        "duration": 4.02,
        "text": "based on what you have explained to me"
      },
      {
        "start": 1117.7,
        "duration": 5.37,
        "text": "that you have the services tier and even"
      },
      {
        "start": 1119.65,
        "duration": 4.98,
        "text": "you know kind of that graph QL API layer"
      },
      {
        "start": 1123.07,
        "duration": 3.45,
        "text": "pretty well instrumented at this point"
      },
      {
        "start": 1124.63,
        "duration": 3.39,
        "text": "but I mean let's take this all the way"
      },
      {
        "start": 1126.52,
        "duration": 3.51,
        "text": "end and like can you take this all the"
      },
      {
        "start": 1128.02,
        "duration": 3.87,
        "text": "way out to the client and can you take"
      },
      {
        "start": 1130.03,
        "duration": 5.94,
        "text": "it all the way down to the database yes"
      },
      {
        "start": 1131.89,
        "duration": 6.3,
        "text": "so yeah you absolutely can so right now"
      },
      {
        "start": 1135.97,
        "duration": 4.98,
        "text": "the way the project stands right now I"
      },
      {
        "start": 1138.19,
        "duration": 4.56,
        "text": "have not instrumented I've not"
      },
      {
        "start": 1140.95,
        "duration": 4.2,
        "text": "instrumented our client like our react"
      },
      {
        "start": 1142.75,
        "duration": 4.14,
        "text": "components so basically traces right now"
      },
      {
        "start": 1145.15,
        "duration": 3.48,
        "text": "in our current project they start at the"
      },
      {
        "start": 1146.89,
        "duration": 3.51,
        "text": "servers and once once it hits the graph"
      },
      {
        "start": 1148.63,
        "duration": 3.36,
        "text": "QL API that's when we start doing"
      },
      {
        "start": 1150.4,
        "duration": 5.07,
        "text": "tracing data but it's absolutely"
      },
      {
        "start": 1151.99,
        "duration": 5.81,
        "text": "possible to to add essentially start"
      },
      {
        "start": 1155.47,
        "duration": 5.73,
        "text": "with a tracing ID on the client side and"
      },
      {
        "start": 1157.8,
        "duration": 4.72,
        "text": "Simkin comes with libraries for working"
      },
      {
        "start": 1161.2,
        "duration": 3.36,
        "text": "with JavaScript for example if you're"
      },
      {
        "start": 1162.52,
        "duration": 4.02,
        "text": "doing you know JavaScript front-end kind"
      },
      {
        "start": 1164.56,
        "duration": 7.47,
        "text": "of development that make it pretty easy"
      },
      {
        "start": 1166.54,
        "duration": 7.11,
        "text": "to to do that I actually did so as far"
      },
      {
        "start": 1172.03,
        "duration": 4.41,
        "text": "as going all the way down to the"
      },
      {
        "start": 1173.65,
        "duration": 6.57,
        "text": "database tier you know obviously we're"
      },
      {
        "start": 1176.44,
        "duration": 5.88,
        "text": "using DLC as our storage for for these"
      },
      {
        "start": 1180.22,
        "duration": 3.45,
        "text": "services right and so what I ended up"
      },
      {
        "start": 1182.32,
        "duration": 2.37,
        "text": "doing because you know clearly there's"
      },
      {
        "start": 1183.67,
        "duration": 2.91,
        "text": "no"
      },
      {
        "start": 1184.69,
        "duration": 5.82,
        "text": "there's no at this point it's sort of"
      },
      {
        "start": 1186.58,
        "duration": 5.7,
        "text": "out-of-the-box DSE instrumentation is I"
      },
      {
        "start": 1190.51,
        "duration": 3.24,
        "text": "did a little bit of client"
      },
      {
        "start": 1192.28,
        "duration": 4.98,
        "text": "instrumentation which is basically just"
      },
      {
        "start": 1193.75,
        "duration": 6.39,
        "text": "a wrapping of the nodejs driver for DSC"
      },
      {
        "start": 1197.26,
        "duration": 5.28,
        "text": "so kind of a proxy okay they're sort of"
      },
      {
        "start": 1200.14,
        "duration": 6.06,
        "text": "thing that intercepts calls to execute"
      },
      {
        "start": 1202.54,
        "duration": 5.31,
        "text": "and batch calls on made to DSC and it"
      },
      {
        "start": 1206.2,
        "duration": 3.51,
        "text": "kind of records some specific things"
      },
      {
        "start": 1207.85,
        "duration": 3.6,
        "text": "like what for example what is the cql"
      },
      {
        "start": 1209.71,
        "duration": 3.63,
        "text": "query you know that I'm running kind of"
      },
      {
        "start": 1211.45,
        "duration": 3.69,
        "text": "kind of information so that's you know"
      },
      {
        "start": 1213.34,
        "duration": 3.45,
        "text": "part of that custom metadata that we can"
      },
      {
        "start": 1215.14,
        "duration": 4.11,
        "text": "record in Zipkin we can record whatever"
      },
      {
        "start": 1216.79,
        "duration": 4.68,
        "text": "we want and so I'm wrapping the node.js"
      },
      {
        "start": 1219.25,
        "duration": 4.92,
        "text": "driver and basically you know kind of"
      },
      {
        "start": 1221.47,
        "duration": 5.4,
        "text": "did this this instrumentation sort of"
      },
      {
        "start": 1224.17,
        "duration": 4.5,
        "text": "manually it might actually you know be a"
      },
      {
        "start": 1226.87,
        "duration": 3.39,
        "text": "cool open-source project at some point"
      },
      {
        "start": 1228.67,
        "duration": 3.57,
        "text": "like maybe I can release it as you know"
      },
      {
        "start": 1230.26,
        "duration": 4.29,
        "text": "kind of a public thing on github if"
      },
      {
        "start": 1232.24,
        "duration": 6.12,
        "text": "people are instrument yeah interested in"
      },
      {
        "start": 1234.55,
        "duration": 5.94,
        "text": "seeing how that was done but so another"
      },
      {
        "start": 1238.36,
        "duration": 4.28,
        "text": "thing though is in Cassini I think it"
      },
      {
        "start": 1240.49,
        "duration": 5.4,
        "text": "was consumed with three diet before"
      },
      {
        "start": 1242.64,
        "duration": 8.62,
        "text": "tracing became pluggable on the actual"
      },
      {
        "start": 1245.89,
        "duration": 7.44,
        "text": "server side so in DC and Cassandra you"
      },
      {
        "start": 1251.26,
        "duration": 4.68,
        "text": "can actually plug in your own"
      },
      {
        "start": 1253.33,
        "duration": 4.11,
        "text": "implementation of you know kind of what"
      },
      {
        "start": 1255.94,
        "duration": 3.48,
        "text": "to do when you're tracing calls because"
      },
      {
        "start": 1257.44,
        "duration": 3.12,
        "text": "if you've ever you can turn tracing on"
      },
      {
        "start": 1259.42,
        "duration": 2.61,
        "text": "and off I don't know if anybody's ever"
      },
      {
        "start": 1260.56,
        "duration": 3.15,
        "text": "tried this in the driver but you can"
      },
      {
        "start": 1262.03,
        "duration": 3.39,
        "text": "turn tracing on and off in the DSC"
      },
      {
        "start": 1263.71,
        "duration": 4.47,
        "text": "drivers right and pretty much all I"
      },
      {
        "start": 1265.42,
        "duration": 4.97,
        "text": "think all across all our languages that"
      },
      {
        "start": 1268.18,
        "duration": 4.44,
        "text": "we support and you get all this sort of"
      },
      {
        "start": 1270.39,
        "duration": 3.82,
        "text": "rich kind of information you can see it"
      },
      {
        "start": 1272.62,
        "duration": 3.57,
        "text": "in studio for example like if you ever"
      },
      {
        "start": 1274.21,
        "duration": 3.42,
        "text": "using data stack studio and you know you"
      },
      {
        "start": 1276.19,
        "duration": 2.82,
        "text": "go to do a cql query you can turn"
      },
      {
        "start": 1277.63,
        "duration": 4.59,
        "text": "tracing on right and you'll get this"
      },
      {
        "start": 1279.01,
        "duration": 4.83,
        "text": "sort of kind of almost like a query plan"
      },
      {
        "start": 1282.22,
        "duration": 3.81,
        "text": "like from sequel and where you kind of"
      },
      {
        "start": 1283.84,
        "duration": 4.5,
        "text": "see like how many how many tombstones"
      },
      {
        "start": 1286.03,
        "duration": 3.75,
        "text": "read and where you know how many tables"
      },
      {
        "start": 1288.34,
        "duration": 3.12,
        "text": "have had to hit or how many tables on"
      },
      {
        "start": 1289.78,
        "duration": 4.32,
        "text": "disk it had to hit right blah blah blah"
      },
      {
        "start": 1291.46,
        "duration": 5.61,
        "text": "and am i right to say that there it's"
      },
      {
        "start": 1294.1,
        "duration": 4.71,
        "text": "leveraging kind of a feature of the seat"
      },
      {
        "start": 1297.07,
        "duration": 4.08,
        "text": "maybe a lesser known feature of CQ o"
      },
      {
        "start": 1298.81,
        "duration": 4.08,
        "text": "which is metadata that can be applied to"
      },
      {
        "start": 1301.15,
        "duration": 5.13,
        "text": "messages right there you know going"
      },
      {
        "start": 1302.89,
        "duration": 4.8,
        "text": "across right yep and so you can surface"
      },
      {
        "start": 1306.28,
        "duration": 3.54,
        "text": "this information so one option I would"
      },
      {
        "start": 1307.69,
        "duration": 4.71,
        "text": "have would be to sort of like turn"
      },
      {
        "start": 1309.82,
        "duration": 4.59,
        "text": "tracing on for some queries like on my"
      },
      {
        "start": 1312.4,
        "duration": 5.19,
        "text": "client side like turn tracing on and"
      },
      {
        "start": 1314.41,
        "duration": 3.81,
        "text": "then use you know sort of take that"
      },
      {
        "start": 1317.59,
        "duration": 2.579,
        "text": "tracing in"
      },
      {
        "start": 1318.22,
        "duration": 5.28,
        "text": "though that the drivers sort of surfaces"
      },
      {
        "start": 1320.169,
        "duration": 5.341,
        "text": "and try to put that data into Zipkin"
      },
      {
        "start": 1323.5,
        "duration": 3.27,
        "text": "kind of recorded as annotations but"
      },
      {
        "start": 1325.51,
        "duration": 3.21,
        "text": "another option you have because the"
      },
      {
        "start": 1326.77,
        "duration": 4.5,
        "text": "server side is pluggable as of because"
      },
      {
        "start": 1328.72,
        "duration": 5.01,
        "text": "nato 3.4 is you can actually just plug"
      },
      {
        "start": 1331.27,
        "duration": 4.92,
        "text": "that in on the server side and have"
      },
      {
        "start": 1333.73,
        "duration": 4.679,
        "text": "cassandra whenever it does a trace or"
      },
      {
        "start": 1336.19,
        "duration": 4.65,
        "text": "DSC whenever it does a trace actually"
      },
      {
        "start": 1338.409,
        "duration": 4.831,
        "text": "send that data to Zipkin so it can sort"
      },
      {
        "start": 1340.84,
        "duration": 4.65,
        "text": "of participate just like any of your"
      },
      {
        "start": 1343.24,
        "duration": 4.74,
        "text": "micro services servers would participate"
      },
      {
        "start": 1345.49,
        "duration": 4.14,
        "text": "in tracing right and so right now"
      },
      {
        "start": 1347.98,
        "duration": 3.39,
        "text": "there's actually there's a plug-in out"
      },
      {
        "start": 1349.63,
        "duration": 3.72,
        "text": "there the last pickle guys did a cool"
      },
      {
        "start": 1351.37,
        "duration": 3.51,
        "text": "plugin for doing that with open source"
      },
      {
        "start": 1353.35,
        "duration": 3.66,
        "text": "Cassandra I haven't tried it yet to see"
      },
      {
        "start": 1354.88,
        "duration": 3.6,
        "text": "if it works with DSC but that's"
      },
      {
        "start": 1357.01,
        "duration": 3.779,
        "text": "definitely on my roadmap of somewhere"
      },
      {
        "start": 1358.48,
        "duration": 4.47,
        "text": "down the road you know trying to figure"
      },
      {
        "start": 1360.789,
        "duration": 4.681,
        "text": "out okay you know how do we do this with"
      },
      {
        "start": 1362.95,
        "duration": 4.44,
        "text": "DSC and can we make this work and in the"
      },
      {
        "start": 1365.47,
        "duration": 4.199,
        "text": "data stacks manage cloud environment"
      },
      {
        "start": 1367.39,
        "duration": 4.14,
        "text": "kind of things so I think that would be"
      },
      {
        "start": 1369.669,
        "duration": 3.271,
        "text": "cool to have like have the the server"
      },
      {
        "start": 1371.53,
        "duration": 4.17,
        "text": "kind of do it for me instead of having"
      },
      {
        "start": 1372.94,
        "duration": 4.29,
        "text": "to write code right itself right so yeah"
      },
      {
        "start": 1375.7,
        "duration": 2.94,
        "text": "there's there is a little bit of"
      },
      {
        "start": 1377.23,
        "duration": 3.21,
        "text": "trade-off here about what you get for"
      },
      {
        "start": 1378.64,
        "duration": 4.26,
        "text": "free from using Zipkin as a framework"
      },
      {
        "start": 1380.44,
        "duration": 4.8,
        "text": "versus you know what additional"
      },
      {
        "start": 1382.9,
        "duration": 3.84,
        "text": "instrumentation code you might desire to"
      },
      {
        "start": 1385.24,
        "duration": 3.36,
        "text": "write on top of that can you talk a"
      },
      {
        "start": 1386.74,
        "duration": 3.66,
        "text": "little bit about you know where that"
      },
      {
        "start": 1388.6,
        "duration": 7.559,
        "text": "dividing line and how you think about"
      },
      {
        "start": 1390.4,
        "duration": 8.639,
        "text": "that yeah so Zipkin has a lot of plugins"
      },
      {
        "start": 1396.159,
        "duration": 6.661,
        "text": "or so for example we're in node.js so"
      },
      {
        "start": 1399.039,
        "duration": 5.13,
        "text": "there are packages on NPM the you know"
      },
      {
        "start": 1402.82,
        "duration": 4.64,
        "text": "sort of the package manager for a node"
      },
      {
        "start": 1404.169,
        "duration": 6.601,
        "text": "and the package registry for for node"
      },
      {
        "start": 1407.46,
        "duration": 4.99,
        "text": "that are plugins that will wrap some"
      },
      {
        "start": 1410.77,
        "duration": 3.149,
        "text": "really popular libraries that people"
      },
      {
        "start": 1412.45,
        "duration": 4.17,
        "text": "might use in a microservices"
      },
      {
        "start": 1413.919,
        "duration": 5.161,
        "text": "architecture so for example the fetch"
      },
      {
        "start": 1416.62,
        "duration": 4.62,
        "text": "library which a lot of people use for"
      },
      {
        "start": 1419.08,
        "duration": 3.99,
        "text": "doing HTTP calls just sort of plain old"
      },
      {
        "start": 1421.24,
        "duration": 3.78,
        "text": "HTTP calls like we're calling a rest"
      },
      {
        "start": 1423.07,
        "duration": 3.57,
        "text": "service for example they have"
      },
      {
        "start": 1425.02,
        "duration": 3.6,
        "text": "instrumentation that is available"
      },
      {
        "start": 1426.64,
        "duration": 5.31,
        "text": "already as a package that'll wrap that's"
      },
      {
        "start": 1428.62,
        "duration": 5.88,
        "text": "for you express is a really popular"
      },
      {
        "start": 1431.95,
        "duration": 5.729,
        "text": "package in node.js for doing servers you"
      },
      {
        "start": 1434.5,
        "duration": 4.799,
        "text": "know HTTP servers web servers so if"
      },
      {
        "start": 1437.679,
        "duration": 4.351,
        "text": "you're if you've got an express server"
      },
      {
        "start": 1439.299,
        "duration": 4.591,
        "text": "they have they have plugins that will"
      },
      {
        "start": 1442.03,
        "duration": 4.29,
        "text": "sort of do that out of the box you don't"
      },
      {
        "start": 1443.89,
        "duration": 5.88,
        "text": "have to write your own instrumentation"
      },
      {
        "start": 1446.32,
        "duration": 5.069,
        "text": "code but I did you know end up end up"
      },
      {
        "start": 1449.77,
        "duration": 3.33,
        "text": "having to write a fair amount"
      },
      {
        "start": 1451.389,
        "duration": 4.14,
        "text": "you know like for her stuff that wasn't"
      },
      {
        "start": 1453.1,
        "duration": 4.23,
        "text": "common like out there yet so you know"
      },
      {
        "start": 1455.529,
        "duration": 3.9,
        "text": "like Cassandra DSE kind of stuff I had"
      },
      {
        "start": 1457.33,
        "duration": 5.729,
        "text": "to write some of that okay"
      },
      {
        "start": 1459.429,
        "duration": 5.551,
        "text": "and the so funny funny story it's kind"
      },
      {
        "start": 1463.059,
        "duration": 6.06,
        "text": "of almost a kind of almost an aside but"
      },
      {
        "start": 1464.98,
        "duration": 7.74,
        "text": "so we were we were using G RPC so we had"
      },
      {
        "start": 1469.119,
        "duration": 6.211,
        "text": "graph QL API server that fanned out to"
      },
      {
        "start": 1472.72,
        "duration": 4.319,
        "text": "our micro services on the back and micro"
      },
      {
        "start": 1475.33,
        "duration": 3.11,
        "text": "services and this is actually if anybody"
      },
      {
        "start": 1477.039,
        "duration": 4.051,
        "text": "has ever gone and looked at killer video"
      },
      {
        "start": 1478.44,
        "duration": 5.14,
        "text": "this is a very similar architecture to"
      },
      {
        "start": 1481.09,
        "duration": 5.64,
        "text": "what we used in in killer video we were"
      },
      {
        "start": 1483.58,
        "duration": 5.099,
        "text": "using G RPC to talk to the back-end"
      },
      {
        "start": 1486.73,
        "duration": 4.679,
        "text": "services so the write the back-end"
      },
      {
        "start": 1488.679,
        "duration": 3.661,
        "text": "services were G RPC so if anyone's"
      },
      {
        "start": 1491.409,
        "duration": 3.181,
        "text": "listening out there and they don't know"
      },
      {
        "start": 1492.34,
        "duration": 5.1,
        "text": "what G RPC is this is an RPC framework"
      },
      {
        "start": 1494.59,
        "duration": 6.059,
        "text": "from Google and you kind of define your"
      },
      {
        "start": 1497.44,
        "duration": 5.219,
        "text": "your services in protocol buffers format"
      },
      {
        "start": 1500.649,
        "duration": 4.5,
        "text": "so you write protocol buffers is the"
      },
      {
        "start": 1502.659,
        "duration": 4.2,
        "text": "interface definition language and then"
      },
      {
        "start": 1505.149,
        "duration": 4.561,
        "text": "you can take those protocol buffers"
      },
      {
        "start": 1506.859,
        "duration": 5.64,
        "text": "files and compile them to eight or ten"
      },
      {
        "start": 1509.71,
        "duration": 4.679,
        "text": "different supported languages and sort"
      },
      {
        "start": 1512.499,
        "duration": 3.601,
        "text": "of have typed clients with you know"
      },
      {
        "start": 1514.389,
        "duration": 3.87,
        "text": "request in response objects that are"
      },
      {
        "start": 1516.1,
        "duration": 5.279,
        "text": "typed and if you're in a strongly typed"
      },
      {
        "start": 1518.259,
        "duration": 4.471,
        "text": "language like C sharp or Java and and so"
      },
      {
        "start": 1521.379,
        "duration": 2.4,
        "text": "you get a lot of kind of cool stuff and"
      },
      {
        "start": 1522.73,
        "duration": 4.59,
        "text": "then one of the other cool things that"
      },
      {
        "start": 1523.779,
        "duration": 6.181,
        "text": "it has is it offers a built in HTTP to"
      },
      {
        "start": 1527.32,
        "duration": 5.189,
        "text": "transports so HTTP to being the new"
      },
      {
        "start": 1529.96,
        "duration": 6.419,
        "text": "version that's just kind of starting to"
      },
      {
        "start": 1532.509,
        "duration": 6.721,
        "text": "see adoption in various browsers and and"
      },
      {
        "start": 1536.379,
        "duration": 4.951,
        "text": "whatnot so it comes with a transport"
      },
      {
        "start": 1539.23,
        "duration": 4.259,
        "text": "built in for all of the languages that"
      },
      {
        "start": 1541.33,
        "duration": 4.229,
        "text": "it supports where you know when I my"
      },
      {
        "start": 1543.489,
        "duration": 4.53,
        "text": "graph QL server when I go to make a call"
      },
      {
        "start": 1545.559,
        "duration": 5.58,
        "text": "via G RPC to one of the backend G RPC"
      },
      {
        "start": 1548.019,
        "duration": 6.24,
        "text": "server's services and it uses HTTP 2 as"
      },
      {
        "start": 1551.139,
        "duration": 5.341,
        "text": "the as the transport and so you know"
      },
      {
        "start": 1554.259,
        "duration": 3.6,
        "text": "we're like yeah alright this is exactly"
      },
      {
        "start": 1556.48,
        "duration": 4.049,
        "text": "like killer video this was really cool"
      },
      {
        "start": 1557.859,
        "duration": 5.731,
        "text": "and we're gonna be deploying this to AWS"
      },
      {
        "start": 1560.529,
        "duration": 4.681,
        "text": "and so I'm thinking well we'll just use"
      },
      {
        "start": 1563.59,
        "duration": 3.419,
        "text": "you know I kind of did a cursory reading"
      },
      {
        "start": 1565.21,
        "duration": 3.51,
        "text": "of the I made the classic mistake of"
      },
      {
        "start": 1567.009,
        "duration": 3.841,
        "text": "doing a cursory reading of the AWS Doc's"
      },
      {
        "start": 1568.72,
        "duration": 3.87,
        "text": "for their application load balancers and"
      },
      {
        "start": 1570.85,
        "duration": 3.179,
        "text": "it says yeah we support HTTP too and I'm"
      },
      {
        "start": 1572.59,
        "duration": 3.269,
        "text": "like great I can just you know I'll be"
      },
      {
        "start": 1574.029,
        "duration": 3.01,
        "text": "able to load balanced my G RPC services"
      },
      {
        "start": 1575.859,
        "duration": 4.31,
        "text": "and whatnot"
      },
      {
        "start": 1577.039,
        "duration": 6.281,
        "text": "yeah but I feel a but coming and then"
      },
      {
        "start": 1580.169,
        "duration": 5.01,
        "text": "but and so welcome to find out that what"
      },
      {
        "start": 1583.32,
        "duration": 4.5,
        "text": "Amazon's load balancers actually do"
      },
      {
        "start": 1585.179,
        "duration": 4.471,
        "text": "right now is they they take HTTP to"
      },
      {
        "start": 1587.82,
        "duration": 3.75,
        "text": "traffic and it may sort of terminated a"
      },
      {
        "start": 1589.65,
        "duration": 4.259,
        "text": "terminate yeah at the load balancer and"
      },
      {
        "start": 1591.57,
        "duration": 4.38,
        "text": "then when it actually goes to your"
      },
      {
        "start": 1593.909,
        "duration": 3.961,
        "text": "back-end service it's actually HTTP one"
      },
      {
        "start": 1595.95,
        "duration": 5.04,
        "text": "traffic they actually turn it into HTTP"
      },
      {
        "start": 1597.87,
        "duration": 7.62,
        "text": "one traffic which would totally break"
      },
      {
        "start": 1600.99,
        "duration": 6.569,
        "text": "the HTTP to transport that we had that"
      },
      {
        "start": 1605.49,
        "duration": 4.62,
        "text": "that G RPC uses so okay like so"
      },
      {
        "start": 1607.559,
        "duration": 5.1,
        "text": "basically we couldn't use Amazon's load"
      },
      {
        "start": 1610.11,
        "duration": 3.66,
        "text": "balancers with our G RPC services sort"
      },
      {
        "start": 1612.659,
        "duration": 4.051,
        "text": "of out of the box"
      },
      {
        "start": 1613.77,
        "duration": 4.11,
        "text": "okay so implications of all this yeah"
      },
      {
        "start": 1616.71,
        "duration": 3.78,
        "text": "servitude Tracy"
      },
      {
        "start": 1617.88,
        "duration": 5.07,
        "text": "so implication is you know we had to"
      },
      {
        "start": 1620.49,
        "duration": 3.96,
        "text": "figure out alright what do we do like"
      },
      {
        "start": 1622.95,
        "duration": 3.81,
        "text": "you know what do we do do we just rip"
      },
      {
        "start": 1624.45,
        "duration": 4.079,
        "text": "out the H to transport and replace it"
      },
      {
        "start": 1626.76,
        "duration": 4.26,
        "text": "with something else or so that we can"
      },
      {
        "start": 1628.529,
        "duration": 4.89,
        "text": "still use the Amazon load balancers or"
      },
      {
        "start": 1631.02,
        "duration": 4.68,
        "text": "do we do something else like some other"
      },
      {
        "start": 1633.419,
        "duration": 4.051,
        "text": "way of load balancing and communication"
      },
      {
        "start": 1635.7,
        "duration": 4.5,
        "text": "between services and so I spent a little"
      },
      {
        "start": 1637.47,
        "duration": 5.55,
        "text": "bit of time actually looking at envoy"
      },
      {
        "start": 1640.2,
        "duration": 5.339,
        "text": "from lift so and I know you and I have"
      },
      {
        "start": 1643.02,
        "duration": 7.11,
        "text": "actually talked about this it's the sort"
      },
      {
        "start": 1645.539,
        "duration": 7.591,
        "text": "of service mesh idea where lyft is sort"
      },
      {
        "start": 1650.13,
        "duration": 6.57,
        "text": "of runs or lyft envoy runs sort of a"
      },
      {
        "start": 1653.13,
        "duration": 5.34,
        "text": "sidecar and acts as a proxy to all of"
      },
      {
        "start": 1656.7,
        "duration": 3.18,
        "text": "your services so it runs as a sidecar"
      },
      {
        "start": 1658.47,
        "duration": 2.52,
        "text": "next to your services and anytime you"
      },
      {
        "start": 1659.88,
        "duration": 2.399,
        "text": "need to make a service call you just"
      },
      {
        "start": 1660.99,
        "duration": 4.83,
        "text": "care of all you're out of process yeah"
      },
      {
        "start": 1662.279,
        "duration": 5.191,
        "text": "yep and and it runs like if I need to"
      },
      {
        "start": 1665.82,
        "duration": 3.87,
        "text": "make a service call to another service I"
      },
      {
        "start": 1667.47,
        "duration": 3.809,
        "text": "can just call localhost where the"
      },
      {
        "start": 1669.69,
        "duration": 3.359,
        "text": "sidecar is running and then it figures"
      },
      {
        "start": 1671.279,
        "duration": 4.26,
        "text": "out because it's got built-in service"
      },
      {
        "start": 1673.049,
        "duration": 4.081,
        "text": "discovery and routing capabilities and"
      },
      {
        "start": 1675.539,
        "duration": 2.971,
        "text": "load balancing and stuff it can figure"
      },
      {
        "start": 1677.13,
        "duration": 5.34,
        "text": "out then where to actually send that"
      },
      {
        "start": 1678.51,
        "duration": 5.519,
        "text": "traffic to you know and so I was looking"
      },
      {
        "start": 1682.47,
        "duration": 3.51,
        "text": "at that because they actually support"
      },
      {
        "start": 1684.029,
        "duration": 4.14,
        "text": "HTTP too so I wouldn't have to rip out"
      },
      {
        "start": 1685.98,
        "duration": 4.11,
        "text": "the the G RPC but one of the cool things"
      },
      {
        "start": 1688.169,
        "duration": 4.471,
        "text": "actually that envoy also offers is sort"
      },
      {
        "start": 1690.09,
        "duration": 6.39,
        "text": "of like a plugin is they actually offer"
      },
      {
        "start": 1692.64,
        "duration": 6.33,
        "text": "built-in support for for tracing so for"
      },
      {
        "start": 1696.48,
        "duration": 4.41,
        "text": "distributed tracing and so any call that"
      },
      {
        "start": 1698.97,
        "duration": 5.04,
        "text": "I basically would make through Envoy"
      },
      {
        "start": 1700.89,
        "duration": 4.89,
        "text": "wood could automatically get recorded"
      },
      {
        "start": 1704.01,
        "duration": 2.95,
        "text": "and pushed into I think they support"
      },
      {
        "start": 1705.78,
        "duration": 3.129,
        "text": "Zipkin right now as"
      },
      {
        "start": 1706.96,
        "duration": 3.54,
        "text": "as an amazing provider so yeah so you"
      },
      {
        "start": 1708.909,
        "duration": 3.841,
        "text": "kind of almost get this like out of the"
      },
      {
        "start": 1710.5,
        "duration": 4.74,
        "text": "box kind of black box level of tracing"
      },
      {
        "start": 1712.75,
        "duration": 5.37,
        "text": "where all your HTTP calls you know HTTP"
      },
      {
        "start": 1715.24,
        "duration": 5.1,
        "text": "1 & 2 are getting you know traced at"
      },
      {
        "start": 1718.12,
        "duration": 3.659,
        "text": "least at a low level you're actually"
      },
      {
        "start": 1720.34,
        "duration": 2.699,
        "text": "gonna be able to see these timing the"
      },
      {
        "start": 1721.779,
        "duration": 4.26,
        "text": "timing spans and I'm guessing they"
      },
      {
        "start": 1723.039,
        "duration": 4.981,
        "text": "record you know HTTP status of the"
      },
      {
        "start": 1726.039,
        "duration": 3.781,
        "text": "responses and that sort of thing"
      },
      {
        "start": 1728.02,
        "duration": 3.69,
        "text": "and you kind of get it out of the you"
      },
      {
        "start": 1729.82,
        "duration": 3.089,
        "text": "know out of the box with something like"
      },
      {
        "start": 1731.71,
        "duration": 2.91,
        "text": "convoy which is pretty cool like it's"
      },
      {
        "start": 1732.909,
        "duration": 3.9,
        "text": "pretty cool sort of base level of"
      },
      {
        "start": 1734.62,
        "duration": 3.63,
        "text": "tracing that you could get now that"
      },
      {
        "start": 1736.809,
        "duration": 4.051,
        "text": "would be cool to do somewhere down the"
      },
      {
        "start": 1738.25,
        "duration": 7.86,
        "text": "road you know I think though and then we"
      },
      {
        "start": 1740.86,
        "duration": 6.919,
        "text": "can do our service mesh episode but I'm"
      },
      {
        "start": 1746.11,
        "duration": 3.96,
        "text": "not ready I wasn't ready to commit"
      },
      {
        "start": 1747.779,
        "duration": 5.951,
        "text": "because I am a small engineering team of"
      },
      {
        "start": 1750.07,
        "duration": 6.479,
        "text": "one right now on this so I wasn't ready"
      },
      {
        "start": 1753.73,
        "duration": 4.199,
        "text": "to commit to you know also having to run"
      },
      {
        "start": 1756.549,
        "duration": 4.471,
        "text": "something else that I wasn't super"
      },
      {
        "start": 1757.929,
        "duration": 5.161,
        "text": "familiar with yet in production but it's"
      },
      {
        "start": 1761.02,
        "duration": 3.48,
        "text": "pretty cool like you know sort of the"
      },
      {
        "start": 1763.09,
        "duration": 2.819,
        "text": "base level you can get now of course"
      },
      {
        "start": 1764.5,
        "duration": 4.169,
        "text": "you're still gonna always want to do"
      },
      {
        "start": 1765.909,
        "duration": 5.221,
        "text": "some sort of higher level like you know"
      },
      {
        "start": 1768.669,
        "duration": 3.721,
        "text": "what you did at your previous job when"
      },
      {
        "start": 1771.13,
        "duration": 3.48,
        "text": "you were working with hotels it's not"
      },
      {
        "start": 1772.39,
        "duration": 3.96,
        "text": "gonna be the same sort of application or"
      },
      {
        "start": 1774.61,
        "duration": 4.08,
        "text": "domain that I'm working in when I'm"
      },
      {
        "start": 1776.35,
        "duration": 4.079,
        "text": "working on user progress and and who's"
      },
      {
        "start": 1778.69,
        "duration": 3.0,
        "text": "making progress on courses and units and"
      },
      {
        "start": 1780.429,
        "duration": 2.671,
        "text": "and so you're still gonna want to write"
      },
      {
        "start": 1781.69,
        "duration": 3.39,
        "text": "instrumentation there's a fermentation"
      },
      {
        "start": 1783.1,
        "duration": 3.72,
        "text": "specific to your domain that you're"
      },
      {
        "start": 1785.08,
        "duration": 3.06,
        "text": "going to want to have exactly so you're"
      },
      {
        "start": 1786.82,
        "duration": 2.969,
        "text": "still gonna always kind of do want to do"
      },
      {
        "start": 1788.14,
        "duration": 3.269,
        "text": "this white box type of you know you"
      },
      {
        "start": 1789.789,
        "duration": 4.441,
        "text": "might get this black box stuff kind of"
      },
      {
        "start": 1791.409,
        "duration": 3.781,
        "text": "like tracing out of something like envoy"
      },
      {
        "start": 1794.23,
        "duration": 3.03,
        "text": "you know out of the box which is"
      },
      {
        "start": 1795.19,
        "duration": 3.45,
        "text": "actually a really great base to start"
      },
      {
        "start": 1797.26,
        "duration": 3.33,
        "text": "from but you're still always gonna want"
      },
      {
        "start": 1798.64,
        "duration": 4.38,
        "text": "to do your domain-specific stuff you"
      },
      {
        "start": 1800.59,
        "duration": 4.89,
        "text": "know at a higher level so nice well I"
      },
      {
        "start": 1803.02,
        "duration": 5.909,
        "text": "think the at this point we've peaked"
      },
      {
        "start": 1805.48,
        "duration": 4.74,
        "text": "everyone's interests enough but now they"
      },
      {
        "start": 1808.929,
        "duration": 2.401,
        "text": "want to go do this themselves where"
      },
      {
        "start": 1810.22,
        "duration": 4.74,
        "text": "should they go to learn about"
      },
      {
        "start": 1811.33,
        "duration": 6.39,
        "text": "distributed tracing so so there's two"
      },
      {
        "start": 1814.96,
        "duration": 4.439,
        "text": "two places one that I didn't really"
      },
      {
        "start": 1817.72,
        "duration": 4.17,
        "text": "mention there's an initiative called"
      },
      {
        "start": 1819.399,
        "duration": 5.821,
        "text": "open tracing that is basically a"
      },
      {
        "start": 1821.89,
        "duration": 5.46,
        "text": "vendor-neutral standard for doing"
      },
      {
        "start": 1825.22,
        "duration": 4.02,
        "text": "distributed tracing and that's that"
      },
      {
        "start": 1827.35,
        "duration": 3.929,
        "text": "which is a cloud native it's a cloud"
      },
      {
        "start": 1829.24,
        "duration": 3.72,
        "text": "native foundation project yep and it's"
      },
      {
        "start": 1831.279,
        "duration": 3.831,
        "text": "at I think they're they're at open"
      },
      {
        "start": 1832.96,
        "duration": 4.37,
        "text": "tracing IO and"
      },
      {
        "start": 1835.11,
        "duration": 5.49,
        "text": "one of the tracers that they actually"
      },
      {
        "start": 1837.33,
        "duration": 5.01,
        "text": "support as far as some implementation"
      },
      {
        "start": 1840.6,
        "duration": 3.569,
        "text": "wise so you know it's sort of open"
      },
      {
        "start": 1842.34,
        "duration": 4.079,
        "text": "tracing is sort of a API"
      },
      {
        "start": 1844.169,
        "duration": 3.87,
        "text": "you know describing the API of right how"
      },
      {
        "start": 1846.419,
        "duration": 4.021,
        "text": "we do this in a vendor neutral way that"
      },
      {
        "start": 1848.039,
        "duration": 4.02,
        "text": "everybody can agree on and then and then"
      },
      {
        "start": 1850.44,
        "duration": 3.54,
        "text": "there's a bunch of tracers than that are"
      },
      {
        "start": 1852.059,
        "duration": 4.321,
        "text": "actually supported one of which is"
      },
      {
        "start": 1853.98,
        "duration": 3.72,
        "text": "Zipkin so if you want to find find out"
      },
      {
        "start": 1856.38,
        "duration": 3.99,
        "text": "more about Zipkin i think their website"
      },
      {
        "start": 1857.7,
        "duration": 6.27,
        "text": "is Zipkin dot io so you can go and check"
      },
      {
        "start": 1860.37,
        "duration": 6.57,
        "text": "that out as well excellent well thank"
      },
      {
        "start": 1863.97,
        "duration": 4.949,
        "text": "you Luke for this guided tour that you"
      },
      {
        "start": 1866.94,
        "duration": 3.989,
        "text": "have offered to us about distributed"
      },
      {
        "start": 1868.919,
        "duration": 5.671,
        "text": "tracing this is a really interesting"
      },
      {
        "start": 1870.929,
        "duration": 6.151,
        "text": "area I think for helping developers and"
      },
      {
        "start": 1874.59,
        "duration": 4.62,
        "text": "distributed systems be able to grasp"
      },
      {
        "start": 1877.08,
        "duration": 3.78,
        "text": "what is going on how to solve some of"
      },
      {
        "start": 1879.21,
        "duration": 4.56,
        "text": "the hard problems how to track down"
      },
      {
        "start": 1880.86,
        "duration": 4.559,
        "text": "those long tail agencies it's a real"
      },
      {
        "start": 1883.77,
        "duration": 4.44,
        "text": "enabler for that you know that's a very"
      },
      {
        "start": 1885.419,
        "duration": 6.271,
        "text": "big deal so one more advertisement"
      },
      {
        "start": 1888.21,
        "duration": 6.089,
        "text": "before we go if you will happen to be at"
      },
      {
        "start": 1891.69,
        "duration": 6.54,
        "text": "the strata data conference in New York"
      },
      {
        "start": 1894.299,
        "duration": 6.031,
        "text": "City here in late September we will have"
      },
      {
        "start": 1898.23,
        "duration": 3.63,
        "text": "a data Stax presence there and and I"
      },
      {
        "start": 1900.33,
        "duration": 4.709,
        "text": "will be there along with Patrick"
      },
      {
        "start": 1901.86,
        "duration": 4.98,
        "text": "McFadden and David Gilardi Sebastien"
      },
      {
        "start": 1905.039,
        "duration": 3.601,
        "text": "NIST Eva's who's been a guest on the"
      },
      {
        "start": 1906.84,
        "duration": 3.48,
        "text": "show I think will also be hanging out so"
      },
      {
        "start": 1908.64,
        "duration": 3.75,
        "text": "there would be a good variety of"
      },
      {
        "start": 1910.32,
        "duration": 4.32,
        "text": "characters there and we'd love to meet"
      },
      {
        "start": 1912.39,
        "duration": 4.31,
        "text": "you if you have want to come and and see"
      },
      {
        "start": 1914.64,
        "duration": 5.24,
        "text": "us at the data sex booth at strata"
      },
      {
        "start": 1916.7,
        "duration": 5.44,
        "text": "thanks a lot and we'll see you next time"
      },
      {
        "start": 1919.88,
        "duration": 4.24,
        "text": "thank you for joining us again for the"
      },
      {
        "start": 1922.14,
        "duration": 3.69,
        "text": "distributed data show we love your"
      },
      {
        "start": 1924.12,
        "duration": 3.539,
        "text": "feedback so go to the distributed data"
      },
      {
        "start": 1925.83,
        "duration": 3.66,
        "text": "show page on data stacks Academy and"
      },
      {
        "start": 1927.659,
        "duration": 3.51,
        "text": "tell us what you think you can also find"
      },
      {
        "start": 1929.49,
        "duration": 4.35,
        "text": "us on the data stacks Academy YouTube"
      },
      {
        "start": 1931.169,
        "duration": 4.711,
        "text": "channel or find our podcast on iTunes"
      },
      {
        "start": 1933.84,
        "duration": 4.5,
        "text": "Google Play or wherever you get great"
      },
      {
        "start": 1935.88,
        "duration": 4.169,
        "text": "podcast while you're there make sure and"
      },
      {
        "start": 1938.34,
        "duration": 3.049,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 1940.049,
        "duration": 1.871,
        "text": "episode"
      },
      {
        "start": 1941.389,
        "duration": 3.64,
        "text": "you"
      },
      {
        "start": 1941.92,
        "duration": 3.109,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:20:42.265013+00:00"
}