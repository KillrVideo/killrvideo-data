{
  "video_id": "5V5rGDTHs20",
  "title": "DS210.18 Repair | Operations with Apache Cassandra",
  "description": "#DataStaxAcademy #DS210\nDS210.18 REPAIR\nIn this unit, we discuss repair in a running Apache Cassandra cluster. While it sounds tedious, it is just something which we have to understand. With DataStax Enterprise 6, repair is even less of a problem for the user.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-11T12:41:05Z",
  "thumbnail": "https://i.ytimg.com/vi/5V5rGDTHs20/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax",
    "tutorial",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=5V5rGDTHs20",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] let's talk about repair in a running cassander cluster an old and very important topic and probably one that if you talk to other folks that have been running a cassandra cluster for a long time they know well about repair but it doesn't have to be painful it's just something you need to understand how it works and with dsc6 it's actually going to be a lot less of a problem for you so what is a repair that is a good question a lot of times i hear folks that are new to cassandra say you know repair that means it's broken right the original term for repair was anti-entropy repair meaning that there was some bad things that had happened somewhere in the cluster that you're accounting for when you're running a large scale distributed system a lot of times things just randomly go bad a bit gets dropped a disc doesn't do it right something may happen and as that happens over time you start getting a degraded quality of your data you need a process that runs behind the scenes that can fix that that is ultra important if you want your data to be consistent over time so a repair in a cassandra cluster is that it's a consistency check across all the nodes to make sure that all the data is correct so when does it occur well a few times there's an actual action where you can say i want to run a repair that's a nodule repair command or in some sort of operation and like a read a read operation at quorum if it notices there's inconsistency it will rectify that with a repair and more interestingly if you're using something like a consistency level of one there's something called a read repair chance and that's just there to make sure that it runs a repair when you do a one it happens periodically and by default ten percent of the reads at one you can bring it up or turn it off usually the defaults just fine so why is it so necessary there are situations where a repair is absolutely necessary for instance if a node goes offline for a long period of time beyond the gc grace meaning how long that it stores hints on the other nodes well if it goes offline for that much longer then you need to run a repair to make sure that all that data is consistent once that node goes offline this is mandatory another situation is if perhaps maybe it overloaded and missed some rights this can happen in a large system you just have a bad day for one node that can make your data inconsistent repair will fix that problem so how does a repair work well there's a couple of stages that happen first when a node goes to another node and says hey let's look at our consistency what it does is it creates what's called a merkle tree a merkle tree is a data structure that shows all the differences from one thing to the other this is a data structure that's created just to show this is data that's missing on this node once the merkle tree is created then it uses that to stream data from the right node to the node that needs the data so this is how it keeps up its consistency so it's more or less a two-stage process build the merkle tree then stream the data so what about that miracle tree as you can see from this diagram there is a comparison that happens between the two things a merkle tree is a data structure that's used in computer science to show differences and do comparisons it's a very fast algorithm to do that and it's really based on a node and leaf pattern it gives you a good fast traversal of finding bad data or in this case missing data in large volumes knowing all the reasons why to run a repair when do you run it back to that main reason maybe you had a node that was offline for a while that's a good time when you bring it back online go ahead and run a repair just as long as it's not completely outside of that gc grace period if the node's been out of gc grace then that node should never go back into the cluster you do a remove node get rid of it if it's still inside gc grace when you bring it back online that's when you run a repair to make sure that the data on that node is consistent we also recommend that you run it on a very regular basis inside the gc grace window so if your gc grace is 10 days you repair every single node in your cluster at least once inside that 10 days that's what keeps your data consistent over time and is really just housekeeping of keeping track of all your data and making sure it's consistent without having to worry about if it's not or if there's been problems you will have problems over time just expect it and run repairs all the time so what about the workload on that node well yes repair can be a pretty heavy operation creating the merkle tree isn't usually the biggest problem it's the streaming moving that much data into the system is gonna be a heavy operation you're dumping large volumes of data in a stream into the running node so keep that in mind if you do have a large event you're gonna need to compensate for that knowing that that node is going to be pretty overwhelmed there are a few things you can do to help mitigate that such as running an incremental repair or even a sub-range repair this breaks down the load into smaller chunks and makes it easier for the node to digest so what is a primary range repair if you look at this diagram you'll see that each one of these nodes has a range of data that is its primary range that's the token that's assigned to the node so when you want to repair that primary range with its replicas that is what's known as a primary range repair you repair only that node's primary and you do that as you walk through every single node this is a way to limit the amount of data that you're repairing across the system only repairing the nodes primary means that you have to do it on every single node sub-range repair is a way to define a token range and say i only want to do a small bit of the token range for that node this is helpful if you're trying to do just a little bit at a time or parallelize that task there are many ways that that can run continuously but it minimizes the amount of load put on each particular node so how do you do it very simple the node tool command with repair is the first stop there's a lot of options inside the no tool repair command as you can see on this list you have pr which is the partitioner range or you have a way where you can put in the start and end tokens if you want to do a range repair you can even do a repair on a particular key space and table there are a lot of options but know how to use repair for your use case if you have a running cluster getting to know how repair works is really critical and if you're using op center the repair service is really helpful it kind of takes away a lot of the pain but also makes it a continuous operation in the background so this is all about repair there's a lot to learn but i think this is a good start",
    "segments": [
      {
        "start": 1.43,
        "duration": 5.33,
        "text": "[Music]"
      },
      {
        "start": 7.12,
        "duration": 4.0,
        "text": "let's talk about"
      },
      {
        "start": 8.08,
        "duration": 5.84,
        "text": "repair in a running cassander cluster"
      },
      {
        "start": 11.12,
        "duration": 4.639,
        "text": "an old and very important topic and"
      },
      {
        "start": 13.92,
        "duration": 3.279,
        "text": "probably one that if you talk to other"
      },
      {
        "start": 15.759,
        "duration": 2.881,
        "text": "folks that have been running a cassandra"
      },
      {
        "start": 17.199,
        "duration": 3.761,
        "text": "cluster for a long time"
      },
      {
        "start": 18.64,
        "duration": 4.0,
        "text": "they know well about repair but it"
      },
      {
        "start": 20.96,
        "duration": 2.72,
        "text": "doesn't have to be painful"
      },
      {
        "start": 22.64,
        "duration": 4.16,
        "text": "it's just something you need to"
      },
      {
        "start": 23.68,
        "duration": 4.88,
        "text": "understand how it works and with dsc6"
      },
      {
        "start": 26.8,
        "duration": 3.52,
        "text": "it's actually going to be a lot less of"
      },
      {
        "start": 28.56,
        "duration": 5.2,
        "text": "a problem for you so"
      },
      {
        "start": 30.32,
        "duration": 5.44,
        "text": "what is a repair that is a good question"
      },
      {
        "start": 33.76,
        "duration": 3.12,
        "text": "a lot of times i hear folks that are new"
      },
      {
        "start": 35.76,
        "duration": 3.76,
        "text": "to cassandra say"
      },
      {
        "start": 36.88,
        "duration": 3.6,
        "text": "you know repair that means it's broken"
      },
      {
        "start": 39.52,
        "duration": 2.719,
        "text": "right"
      },
      {
        "start": 40.48,
        "duration": 4.559,
        "text": "the original term for repair was"
      },
      {
        "start": 42.239,
        "duration": 4.48,
        "text": "anti-entropy repair meaning that"
      },
      {
        "start": 45.039,
        "duration": 3.281,
        "text": "there was some bad things that had"
      },
      {
        "start": 46.719,
        "duration": 3.041,
        "text": "happened somewhere in the cluster that"
      },
      {
        "start": 48.32,
        "duration": 2.64,
        "text": "you're accounting for"
      },
      {
        "start": 49.76,
        "duration": 3.68,
        "text": "when you're running a large scale"
      },
      {
        "start": 50.96,
        "duration": 3.919,
        "text": "distributed system a lot of times things"
      },
      {
        "start": 53.44,
        "duration": 3.599,
        "text": "just randomly go bad"
      },
      {
        "start": 54.879,
        "duration": 4.32,
        "text": "a bit gets dropped a disc doesn't do it"
      },
      {
        "start": 57.039,
        "duration": 4.881,
        "text": "right something may happen"
      },
      {
        "start": 59.199,
        "duration": 5.201,
        "text": "and as that happens over time you start"
      },
      {
        "start": 61.92,
        "duration": 4.72,
        "text": "getting a degraded quality of your data"
      },
      {
        "start": 64.4,
        "duration": 4.079,
        "text": "you need a process that runs behind the"
      },
      {
        "start": 66.64,
        "duration": 4.159,
        "text": "scenes that can fix that"
      },
      {
        "start": 68.479,
        "duration": 3.601,
        "text": "that is ultra important if you want your"
      },
      {
        "start": 70.799,
        "duration": 4.401,
        "text": "data to be consistent"
      },
      {
        "start": 72.08,
        "duration": 5.76,
        "text": "over time so a repair in a cassandra"
      },
      {
        "start": 75.2,
        "duration": 4.48,
        "text": "cluster is that it's a consistency check"
      },
      {
        "start": 77.84,
        "duration": 4.0,
        "text": "across all the nodes to make sure that"
      },
      {
        "start": 79.68,
        "duration": 5.119,
        "text": "all the data is correct"
      },
      {
        "start": 81.84,
        "duration": 3.599,
        "text": "so when does it occur well a few times"
      },
      {
        "start": 84.799,
        "duration": 2.881,
        "text": "there's"
      },
      {
        "start": 85.439,
        "duration": 3.761,
        "text": "an actual action where you can say i"
      },
      {
        "start": 87.68,
        "duration": 2.64,
        "text": "want to run a repair that's a nodule"
      },
      {
        "start": 89.2,
        "duration": 3.76,
        "text": "repair command"
      },
      {
        "start": 90.32,
        "duration": 3.28,
        "text": "or in some sort of operation and like a"
      },
      {
        "start": 92.96,
        "duration": 2.72,
        "text": "read"
      },
      {
        "start": 93.6,
        "duration": 3.6,
        "text": "a read operation at quorum if it notices"
      },
      {
        "start": 95.68,
        "duration": 4.079,
        "text": "there's inconsistency"
      },
      {
        "start": 97.2,
        "duration": 3.599,
        "text": "it will rectify that with a repair and"
      },
      {
        "start": 99.759,
        "duration": 2.481,
        "text": "more interestingly"
      },
      {
        "start": 100.799,
        "duration": 3.6,
        "text": "if you're using something like a"
      },
      {
        "start": 102.24,
        "duration": 3.839,
        "text": "consistency level of one"
      },
      {
        "start": 104.399,
        "duration": 3.76,
        "text": "there's something called a read repair"
      },
      {
        "start": 106.079,
        "duration": 4.32,
        "text": "chance and that's just there"
      },
      {
        "start": 108.159,
        "duration": 3.28,
        "text": "to make sure that it runs a repair when"
      },
      {
        "start": 110.399,
        "duration": 3.68,
        "text": "you do a one"
      },
      {
        "start": 111.439,
        "duration": 5.04,
        "text": "it happens periodically and by default"
      },
      {
        "start": 114.079,
        "duration": 5.121,
        "text": "ten percent of the reads at one"
      },
      {
        "start": 116.479,
        "duration": 4.96,
        "text": "you can bring it up or turn it off"
      },
      {
        "start": 119.2,
        "duration": 4.959,
        "text": "usually the defaults just fine"
      },
      {
        "start": 121.439,
        "duration": 4.881,
        "text": "so why is it so necessary there are"
      },
      {
        "start": 124.159,
        "duration": 3.121,
        "text": "situations where a repair is absolutely"
      },
      {
        "start": 126.32,
        "duration": 3.04,
        "text": "necessary"
      },
      {
        "start": 127.28,
        "duration": 3.679,
        "text": "for instance if a node goes offline for"
      },
      {
        "start": 129.36,
        "duration": 3.92,
        "text": "a long period of time"
      },
      {
        "start": 130.959,
        "duration": 4.401,
        "text": "beyond the gc grace meaning how long"
      },
      {
        "start": 133.28,
        "duration": 3.679,
        "text": "that it stores hints on the other nodes"
      },
      {
        "start": 135.36,
        "duration": 3.76,
        "text": "well if it goes offline for that much"
      },
      {
        "start": 136.959,
        "duration": 3.841,
        "text": "longer then you need to run a repair to"
      },
      {
        "start": 139.12,
        "duration": 3.6,
        "text": "make sure that all that data is"
      },
      {
        "start": 140.8,
        "duration": 5.04,
        "text": "consistent once that node goes offline"
      },
      {
        "start": 142.72,
        "duration": 5.12,
        "text": "this is mandatory another situation is"
      },
      {
        "start": 145.84,
        "duration": 3.039,
        "text": "if perhaps maybe it overloaded and"
      },
      {
        "start": 147.84,
        "duration": 3.28,
        "text": "missed some rights"
      },
      {
        "start": 148.879,
        "duration": 4.241,
        "text": "this can happen in a large system you"
      },
      {
        "start": 151.12,
        "duration": 3.92,
        "text": "just have a bad day for one node"
      },
      {
        "start": 153.12,
        "duration": 4.0,
        "text": "that can make your data inconsistent"
      },
      {
        "start": 155.04,
        "duration": 5.12,
        "text": "repair will fix that problem"
      },
      {
        "start": 157.12,
        "duration": 5.119,
        "text": "so how does a repair work well there's a"
      },
      {
        "start": 160.16,
        "duration": 4.4,
        "text": "couple of stages that happen"
      },
      {
        "start": 162.239,
        "duration": 3.601,
        "text": "first when a node goes to another node"
      },
      {
        "start": 164.56,
        "duration": 2.64,
        "text": "and says hey let's look at our"
      },
      {
        "start": 165.84,
        "duration": 2.88,
        "text": "consistency"
      },
      {
        "start": 167.2,
        "duration": 3.679,
        "text": "what it does is it creates what's called"
      },
      {
        "start": 168.72,
        "duration": 2.799,
        "text": "a merkle tree a merkle tree is a data"
      },
      {
        "start": 170.879,
        "duration": 2.321,
        "text": "structure"
      },
      {
        "start": 171.519,
        "duration": 3.44,
        "text": "that shows all the differences from one"
      },
      {
        "start": 173.2,
        "duration": 2.88,
        "text": "thing to the other this is a data"
      },
      {
        "start": 174.959,
        "duration": 3.681,
        "text": "structure that's created"
      },
      {
        "start": 176.08,
        "duration": 3.04,
        "text": "just to show this is data that's missing"
      },
      {
        "start": 178.64,
        "duration": 2.239,
        "text": "on"
      },
      {
        "start": 179.12,
        "duration": 3.759,
        "text": "this node once the merkle tree is"
      },
      {
        "start": 180.879,
        "duration": 4.64,
        "text": "created then it uses that"
      },
      {
        "start": 182.879,
        "duration": 4.161,
        "text": "to stream data from the right node to"
      },
      {
        "start": 185.519,
        "duration": 2.961,
        "text": "the node that needs the data"
      },
      {
        "start": 187.04,
        "duration": 3.76,
        "text": "so this is how it keeps up its"
      },
      {
        "start": 188.48,
        "duration": 3.839,
        "text": "consistency so it's more or less a"
      },
      {
        "start": 190.8,
        "duration": 3.519,
        "text": "two-stage process"
      },
      {
        "start": 192.319,
        "duration": 5.2,
        "text": "build the merkle tree then stream the"
      },
      {
        "start": 194.319,
        "duration": 5.121,
        "text": "data so what about that miracle tree"
      },
      {
        "start": 197.519,
        "duration": 3.841,
        "text": "as you can see from this diagram there"
      },
      {
        "start": 199.44,
        "duration": 2.879,
        "text": "is a comparison that happens between the"
      },
      {
        "start": 201.36,
        "duration": 3.68,
        "text": "two things"
      },
      {
        "start": 202.319,
        "duration": 4.401,
        "text": "a merkle tree is a data structure that's"
      },
      {
        "start": 205.04,
        "duration": 3.759,
        "text": "used in computer science to show"
      },
      {
        "start": 206.72,
        "duration": 4.159,
        "text": "differences and do comparisons it's a"
      },
      {
        "start": 208.799,
        "duration": 4.961,
        "text": "very fast algorithm to do that"
      },
      {
        "start": 210.879,
        "duration": 3.92,
        "text": "and it's really based on a node and leaf"
      },
      {
        "start": 213.76,
        "duration": 3.68,
        "text": "pattern"
      },
      {
        "start": 214.799,
        "duration": 3.44,
        "text": "it gives you a good fast traversal of"
      },
      {
        "start": 217.44,
        "duration": 4.0,
        "text": "finding"
      },
      {
        "start": 218.239,
        "duration": 6.401,
        "text": "bad data or in this case missing data"
      },
      {
        "start": 221.44,
        "duration": 6.48,
        "text": "in large volumes knowing all the reasons"
      },
      {
        "start": 224.64,
        "duration": 5.519,
        "text": "why to run a repair when do you run it"
      },
      {
        "start": 227.92,
        "duration": 4.48,
        "text": "back to that main reason maybe you had a"
      },
      {
        "start": 230.159,
        "duration": 3.521,
        "text": "node that was offline for a while"
      },
      {
        "start": 232.4,
        "duration": 4.0,
        "text": "that's a good time when you bring it"
      },
      {
        "start": 233.68,
        "duration": 4.639,
        "text": "back online go ahead and run a repair"
      },
      {
        "start": 236.4,
        "duration": 3.759,
        "text": "just as long as it's not completely"
      },
      {
        "start": 238.319,
        "duration": 4.401,
        "text": "outside of that gc grace period"
      },
      {
        "start": 240.159,
        "duration": 4.16,
        "text": "if the node's been out of gc grace then"
      },
      {
        "start": 242.72,
        "duration": 3.68,
        "text": "that node should never go back into the"
      },
      {
        "start": 244.319,
        "duration": 2.56,
        "text": "cluster you do a remove node get rid of"
      },
      {
        "start": 246.4,
        "duration": 2.24,
        "text": "it"
      },
      {
        "start": 246.879,
        "duration": 3.28,
        "text": "if it's still inside gc grace when you"
      },
      {
        "start": 248.64,
        "duration": 3.2,
        "text": "bring it back online"
      },
      {
        "start": 250.159,
        "duration": 3.201,
        "text": "that's when you run a repair to make"
      },
      {
        "start": 251.84,
        "duration": 2.479,
        "text": "sure that the data on that node is"
      },
      {
        "start": 253.36,
        "duration": 2.96,
        "text": "consistent"
      },
      {
        "start": 254.319,
        "duration": 3.681,
        "text": "we also recommend that you run it on a"
      },
      {
        "start": 256.32,
        "duration": 4.72,
        "text": "very regular basis"
      },
      {
        "start": 258.0,
        "duration": 4.56,
        "text": "inside the gc grace window so if your gc"
      },
      {
        "start": 261.04,
        "duration": 3.28,
        "text": "grace is 10 days"
      },
      {
        "start": 262.56,
        "duration": 3.84,
        "text": "you repair every single node in your"
      },
      {
        "start": 264.32,
        "duration": 2.64,
        "text": "cluster at least once inside that 10"
      },
      {
        "start": 266.4,
        "duration": 2.239,
        "text": "days"
      },
      {
        "start": 266.96,
        "duration": 3.76,
        "text": "that's what keeps your data consistent"
      },
      {
        "start": 268.639,
        "duration": 4.401,
        "text": "over time and is really"
      },
      {
        "start": 270.72,
        "duration": 3.28,
        "text": "just housekeeping of keeping track of"
      },
      {
        "start": 273.04,
        "duration": 2.56,
        "text": "all your data"
      },
      {
        "start": 274.0,
        "duration": 3.36,
        "text": "and making sure it's consistent without"
      },
      {
        "start": 275.6,
        "duration": 2.96,
        "text": "having to worry about if it's not or if"
      },
      {
        "start": 277.36,
        "duration": 3.76,
        "text": "there's been problems"
      },
      {
        "start": 278.56,
        "duration": 4.88,
        "text": "you will have problems over time just"
      },
      {
        "start": 281.12,
        "duration": 4.56,
        "text": "expect it and run repairs all the time"
      },
      {
        "start": 283.44,
        "duration": 3.36,
        "text": "so what about the workload on that node"
      },
      {
        "start": 285.68,
        "duration": 4.0,
        "text": "well yes"
      },
      {
        "start": 286.8,
        "duration": 4.16,
        "text": "repair can be a pretty heavy operation"
      },
      {
        "start": 289.68,
        "duration": 3.519,
        "text": "creating the merkle tree"
      },
      {
        "start": 290.96,
        "duration": 3.519,
        "text": "isn't usually the biggest problem it's"
      },
      {
        "start": 293.199,
        "duration": 4.401,
        "text": "the streaming"
      },
      {
        "start": 294.479,
        "duration": 4.801,
        "text": "moving that much data into the system is"
      },
      {
        "start": 297.6,
        "duration": 3.92,
        "text": "gonna be a heavy operation"
      },
      {
        "start": 299.28,
        "duration": 4.16,
        "text": "you're dumping large volumes of data in"
      },
      {
        "start": 301.52,
        "duration": 4.399,
        "text": "a stream into the running node"
      },
      {
        "start": 303.44,
        "duration": 3.52,
        "text": "so keep that in mind if you do have a"
      },
      {
        "start": 305.919,
        "duration": 2.801,
        "text": "large event"
      },
      {
        "start": 306.96,
        "duration": 3.04,
        "text": "you're gonna need to compensate for that"
      },
      {
        "start": 308.72,
        "duration": 3.039,
        "text": "knowing that that node is going to be"
      },
      {
        "start": 310.0,
        "duration": 4.08,
        "text": "pretty overwhelmed there are a few"
      },
      {
        "start": 311.759,
        "duration": 4.801,
        "text": "things you can do to help mitigate that"
      },
      {
        "start": 314.08,
        "duration": 4.24,
        "text": "such as running an incremental repair or"
      },
      {
        "start": 316.56,
        "duration": 3.68,
        "text": "even a sub-range repair this"
      },
      {
        "start": 318.32,
        "duration": 3.36,
        "text": "breaks down the load into smaller chunks"
      },
      {
        "start": 320.24,
        "duration": 2.48,
        "text": "and makes it easier for the node to"
      },
      {
        "start": 321.68,
        "duration": 4.16,
        "text": "digest"
      },
      {
        "start": 322.72,
        "duration": 4.8,
        "text": "so what is a primary range repair if you"
      },
      {
        "start": 325.84,
        "duration": 3.28,
        "text": "look at this diagram you'll see that"
      },
      {
        "start": 327.52,
        "duration": 4.399,
        "text": "each one of these nodes"
      },
      {
        "start": 329.12,
        "duration": 4.48,
        "text": "has a range of data that is its primary"
      },
      {
        "start": 331.919,
        "duration": 2.481,
        "text": "range that's the token that's assigned"
      },
      {
        "start": 333.6,
        "duration": 2.64,
        "text": "to the node"
      },
      {
        "start": 334.4,
        "duration": 3.6,
        "text": "so when you want to repair that primary"
      },
      {
        "start": 336.24,
        "duration": 3.28,
        "text": "range with its replicas"
      },
      {
        "start": 338.0,
        "duration": 3.28,
        "text": "that is what's known as a primary range"
      },
      {
        "start": 339.52,
        "duration": 4.08,
        "text": "repair you repair"
      },
      {
        "start": 341.28,
        "duration": 3.919,
        "text": "only that node's primary and you do that"
      },
      {
        "start": 343.6,
        "duration": 3.36,
        "text": "as you walk through every single node"
      },
      {
        "start": 345.199,
        "duration": 3.521,
        "text": "this is a way to limit the amount of"
      },
      {
        "start": 346.96,
        "duration": 2.4,
        "text": "data that you're repairing across the"
      },
      {
        "start": 348.72,
        "duration": 2.4,
        "text": "system"
      },
      {
        "start": 349.36,
        "duration": 4.0,
        "text": "only repairing the nodes primary means"
      },
      {
        "start": 351.12,
        "duration": 6.0,
        "text": "that you have to do it on every single"
      },
      {
        "start": 353.36,
        "duration": 6.08,
        "text": "node sub-range repair is a way to define"
      },
      {
        "start": 357.12,
        "duration": 3.359,
        "text": "a token range and say i only want to do"
      },
      {
        "start": 359.44,
        "duration": 3.199,
        "text": "a small bit"
      },
      {
        "start": 360.479,
        "duration": 3.761,
        "text": "of the token range for that node this is"
      },
      {
        "start": 362.639,
        "duration": 3.361,
        "text": "helpful if you're trying to do"
      },
      {
        "start": 364.24,
        "duration": 3.44,
        "text": "just a little bit at a time or"
      },
      {
        "start": 366.0,
        "duration": 3.36,
        "text": "parallelize that task"
      },
      {
        "start": 367.68,
        "duration": 3.359,
        "text": "there are many ways that that can run"
      },
      {
        "start": 369.36,
        "duration": 3.92,
        "text": "continuously but it"
      },
      {
        "start": 371.039,
        "duration": 3.361,
        "text": "minimizes the amount of load put on each"
      },
      {
        "start": 373.28,
        "duration": 3.919,
        "text": "particular node"
      },
      {
        "start": 374.4,
        "duration": 3.76,
        "text": "so how do you do it very simple the node"
      },
      {
        "start": 377.199,
        "duration": 3.921,
        "text": "tool command"
      },
      {
        "start": 378.16,
        "duration": 4.0,
        "text": "with repair is the first stop there's a"
      },
      {
        "start": 381.12,
        "duration": 3.519,
        "text": "lot of options"
      },
      {
        "start": 382.16,
        "duration": 3.92,
        "text": "inside the no tool repair command as you"
      },
      {
        "start": 384.639,
        "duration": 3.761,
        "text": "can see on this list"
      },
      {
        "start": 386.08,
        "duration": 4.0,
        "text": "you have pr which is the partitioner"
      },
      {
        "start": 388.4,
        "duration": 3.519,
        "text": "range or you have a way where you can"
      },
      {
        "start": 390.08,
        "duration": 3.92,
        "text": "put in the start and end tokens if you"
      },
      {
        "start": 391.919,
        "duration": 4.0,
        "text": "want to do a range repair"
      },
      {
        "start": 394.0,
        "duration": 3.84,
        "text": "you can even do a repair on a particular"
      },
      {
        "start": 395.919,
        "duration": 4.881,
        "text": "key space and table"
      },
      {
        "start": 397.84,
        "duration": 4.24,
        "text": "there are a lot of options but know how"
      },
      {
        "start": 400.8,
        "duration": 3.6,
        "text": "to use repair"
      },
      {
        "start": 402.08,
        "duration": 3.119,
        "text": "for your use case if you have a running"
      },
      {
        "start": 404.4,
        "duration": 2.56,
        "text": "cluster"
      },
      {
        "start": 405.199,
        "duration": 3.84,
        "text": "getting to know how repair works is"
      },
      {
        "start": 406.96,
        "duration": 2.639,
        "text": "really critical and if you're using op"
      },
      {
        "start": 409.039,
        "duration": 2.88,
        "text": "center"
      },
      {
        "start": 409.599,
        "duration": 3.281,
        "text": "the repair service is really helpful it"
      },
      {
        "start": 411.919,
        "duration": 2.961,
        "text": "kind of takes away"
      },
      {
        "start": 412.88,
        "duration": 4.08,
        "text": "a lot of the pain but also makes it a"
      },
      {
        "start": 414.88,
        "duration": 4.879,
        "text": "continuous operation in the background"
      },
      {
        "start": 416.96,
        "duration": 3.76,
        "text": "so this is all about repair there's a"
      },
      {
        "start": 419.759,
        "duration": 7.681,
        "text": "lot to learn"
      },
      {
        "start": 420.72,
        "duration": 6.72,
        "text": "but i think this is a good start"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T01:29:26.333794+00:00"
}