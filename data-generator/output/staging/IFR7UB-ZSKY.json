{
  "video_id": "IFR7UB-ZSKY",
  "title": "DS330.12 Loading Data Using DSE Graph Loader | DataStax Enterprise 6 Graph",
  "description": "#DataStaxAcademy #DS330\nDS330.12 Loading Data Using DSE Graph Loader\nIn this section, you will learn all about using the DataStax Enterprise Graph Loader. The DSE Graph Loader is a customizable command-line utility thatâ€™s great for loading small to medium size graph datasets.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T01:21:40Z",
  "thumbnail": "https://i.ytimg.com/vi/IFR7UB-ZSKY/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "dse",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=IFR7UB-ZSKY",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] let's talk about loading data using the datastax enterprise graph loader the datastax graph loader is just one of five ways you can load data into an existing graph in this presentation we'll be covering the graph loader in depth but there are four other ways you can load data into dataset's graph the graph api is used when creating small to medium sized graphs one can execute individual statements in the gremlin console or in data stack studio or write a script that uses many statements programmatically now this method is generally slower than gremlin i o however gremlin i o is more suitable when exporting and importing existing graphs grammar mutating traversals are more suitable for mutating existing graphs now the graph loader utility is capable of parsing existing collections of text files and data sets stored in jdbc compatible databases and loading such data as graphs into datastax enterprise this utility is designed for loading small to medium sized graphs as well there is a spark based bulk loading mechanism that is ideal for large graphs the dsc graph loader is a customizable command line utility that's great for loading small to medium-sized graph data sets it can load data from a variety of sources including flat files and database connections through jdbc it is a groovy based tool so while you can incorporate transformations into your data mappings this method is deprecated and should not be used this is an overview of how the data stacks graph loader works first a user must create a loading script in groovy this script tells the graph loader about preferred configurations data sources and data mappings the graph order will use the mapper script to read data from their respective data sources and load it into dse graph there are three data processing stages that the data stacks enterprise graph loader goes through first there's a preparation phase this is where the graph loader will validate the data from the data sources check to make sure that you have the proper schema in place and of course validate the loading strip for any possible issues then the graph loader will begin loading or retrieving existing vertices and caches them for use in the third step which is the edge and property loading the edge and property loading stage is generally the most time consuming when loading multi properties the schema should reflect that fact to avoid having upsets let's talk about the different data sources and file formats you can use with the data stacks graph loader you have support for all the formats you'd expect csv json delimited text and also support for graph specific formats such as graphs on graphml and grio what's also interesting is that the datastax graph loader can load data directly from jdbc compatible databases and this includes other graph databases such as titan janus and neo4j next we're going to be discussing loading script design for the dsc graph loader as we talked about previously the loading script defines the graph loader configuration it defines the data sources and defines the data mappings and because it is a groovy based tool it also supports groovy based transformations though this functionality is deprecated here are some of the configurations that you can define with the datastax graph loader the options address and graph are straightforward and required create graph enables the creation of a new graph by default and if you want the best performance you should be loading data into an existing graph with well-defined schema that has indices to support useful lookups during data loading therefore create schema should be set to false another performance related optimization is possible with load new equals true if you're loading a new data set data stack's graph footer will rely on this option will not waste time verifying if a vertex or edge already exists in the graph it will assume to be imported graph elements are new and have unique ids there is also a finer grain mechanism to specify existence of specific graph elements when defining a data mapping we'll cover this later in the presentation there are many other options for customization so please take a look at the documentation for an expansive list here are a few parameters you can adjust for increasing or decreasing performance read threads is the number of threads used to read data from the data input load vertex threads is the number of threads used for loading vertices by default it's set to zero which will force the number to be the number of physical cores divided by two load edge threads controls the number of threads used for loading edges and properties and will default to zero which translates to the number of nodes in a respective data center times six now that we know some of the important configurations for the datastax graph folder let's put them to good use here's how you define configurations within your loading script notice the config declaration followed by the parameter and the value you can also see an alternate syntax at the bottom using a comma to separate parameters on a single line once we have our configurations defined it's time to define our input sources you can see that from the file method we can specify which type of file format we're loading and whether or not there's a specific delimiter or header associated with it now if your input data is one of three main graph file formats the syntax is a little bit different we call the graph method specifically the file name and then the type of graph format we're reading from lastly here's how we can load data from a jdbc compatible database you first need to create a database connection which we can do by calling the database method provide a connection string database type and then of course the authentication then we can use that database connection to query for our data in sql format once we have our inputs defined we can then use the transformation api please note that this will be deprecated and might be replaced with a different api in the future the main methods you have access to are the map flat map and filter transformations each will create a new data set that's formed by applying a function on each element of the input data set with a map there's a one-to-one correspondence between input and output elements with a flat map there's a one-to-many correspondence as you would expect with filter the new data set is formed by the elements in the input data set that return true with a function f here's an example on how to create transformations in your loading script as you can see we define our input then filter on it to keep users who are over the age of 21. then we use the map method to add a u in front of the user id value so for example 25 would now become u25 in this example flat map adds m in front of the movie id for example 44 becomes m44 next it splits the genres literal into the list of genres and modifies each element of the list to be a map with fields movie id and genre this returns a new belongs to data set created by expanding lists returned by the lambda function this new data set can later be mapped to edges in a graph this is how you map input data to graph constituents simply put you call the load method which takes input data and specify whether you're loading vertices or edges the as vertices or as edges method takes a mapper input which we'll discuss next now before we create our mappings let's get introduced to the mapping api each vertex or edge must have a label use label or label field a key is what uniquely identifies a graph element it's not necessarily a vertex or edge id vertex property and property can map fields to properties they do not need to be used explicitly if a field and property names are the same because any data field becomes a vertex or edge property by default similarly value may not need to be used explicitly use ignore to not create properties out of fields by default is new and exists allow for finer grained mechanisms to specify existence of specific graph elements when defining a data mapping they override the behavior specified by the load new configuration option nv and out v help define neighbors of a vertex n e and out e help define incident edges of a vertex envy and out v with different signatures help define endpoints of an edge there are more methods so please consult the documentation for more information now let's put what we just learned to good use here's an example of mapping our person data to vertices since we're loading vertices we use the as vertices method to begin to map our data the label of this vertex is person and the key within the input data is person id both examples here are valid they just use slightly different syntax here's an example of mapping actors to edges this mapping is a little more in depth because we need to tell the graph loader which adjacent vertices to create an edge between because we're loading new edges to existing vertices we can call the exist method to our vertex mappings again this is for optimization both examples do the same thing with different syntax and both are valid now that we've learned how to create our own loading script it's time to learn how to actually run the graph loader all you need to do is run the graph loader utility specify your loading script and any additional configuration it's also worth noting that the command line options can be overridden by the loading script options make sure that you're using the datastax graph loader that matches with your datastax enterprise version it's time to put your new graph loader knowledge to use with this hands-on exercise",
    "segments": [
      {
        "start": 1.47,
        "duration": 5.31,
        "text": "[Music]"
      },
      {
        "start": 7.359,
        "duration": 3.601,
        "text": "let's talk about loading data using the"
      },
      {
        "start": 8.96,
        "duration": 3.839,
        "text": "datastax enterprise graph loader"
      },
      {
        "start": 10.96,
        "duration": 3.52,
        "text": "the datastax graph loader is just one of"
      },
      {
        "start": 12.799,
        "duration": 3.441,
        "text": "five ways you can load data"
      },
      {
        "start": 14.48,
        "duration": 3.52,
        "text": "into an existing graph in this"
      },
      {
        "start": 16.24,
        "duration": 3.68,
        "text": "presentation we'll be covering the graph"
      },
      {
        "start": 18.0,
        "duration": 3.76,
        "text": "loader in depth but there are four"
      },
      {
        "start": 19.92,
        "duration": 3.119,
        "text": "other ways you can load data into"
      },
      {
        "start": 21.76,
        "duration": 2.96,
        "text": "dataset's graph"
      },
      {
        "start": 23.039,
        "duration": 4.16,
        "text": "the graph api is used when creating"
      },
      {
        "start": 24.72,
        "duration": 4.559,
        "text": "small to medium sized graphs"
      },
      {
        "start": 27.199,
        "duration": 4.08,
        "text": "one can execute individual statements in"
      },
      {
        "start": 29.279,
        "duration": 2.8,
        "text": "the gremlin console or in data stack"
      },
      {
        "start": 31.279,
        "duration": 2.481,
        "text": "studio"
      },
      {
        "start": 32.079,
        "duration": 3.841,
        "text": "or write a script that uses many"
      },
      {
        "start": 33.76,
        "duration": 4.24,
        "text": "statements programmatically"
      },
      {
        "start": 35.92,
        "duration": 3.2,
        "text": "now this method is generally slower than"
      },
      {
        "start": 38.0,
        "duration": 2.8,
        "text": "gremlin i o"
      },
      {
        "start": 39.12,
        "duration": 3.72,
        "text": "however gremlin i o is more suitable"
      },
      {
        "start": 40.8,
        "duration": 3.52,
        "text": "when exporting and importing existing"
      },
      {
        "start": 42.84,
        "duration": 3.16,
        "text": "graphs"
      },
      {
        "start": 44.32,
        "duration": 4.16,
        "text": "grammar mutating traversals are more"
      },
      {
        "start": 46.0,
        "duration": 4.32,
        "text": "suitable for mutating existing graphs"
      },
      {
        "start": 48.48,
        "duration": 3.919,
        "text": "now the graph loader utility is capable"
      },
      {
        "start": 50.32,
        "duration": 3.759,
        "text": "of parsing existing collections of text"
      },
      {
        "start": 52.399,
        "duration": 3.121,
        "text": "files and data sets stored in jdbc"
      },
      {
        "start": 54.079,
        "duration": 3.12,
        "text": "compatible databases"
      },
      {
        "start": 55.52,
        "duration": 3.28,
        "text": "and loading such data as graphs into"
      },
      {
        "start": 57.199,
        "duration": 3.04,
        "text": "datastax enterprise"
      },
      {
        "start": 58.8,
        "duration": 4.0,
        "text": "this utility is designed for loading"
      },
      {
        "start": 60.239,
        "duration": 4.64,
        "text": "small to medium sized graphs as well"
      },
      {
        "start": 62.8,
        "duration": 5.6,
        "text": "there is a spark based bulk loading"
      },
      {
        "start": 64.879,
        "duration": 5.761,
        "text": "mechanism that is ideal for large graphs"
      },
      {
        "start": 68.4,
        "duration": 3.759,
        "text": "the dsc graph loader is a customizable"
      },
      {
        "start": 70.64,
        "duration": 3.519,
        "text": "command line utility that's great for"
      },
      {
        "start": 72.159,
        "duration": 2.721,
        "text": "loading small to medium-sized graph data"
      },
      {
        "start": 74.159,
        "duration": 2.241,
        "text": "sets"
      },
      {
        "start": 74.88,
        "duration": 3.12,
        "text": "it can load data from a variety of"
      },
      {
        "start": 76.4,
        "duration": 4.24,
        "text": "sources including flat files and"
      },
      {
        "start": 78.0,
        "duration": 4.799,
        "text": "database connections through jdbc"
      },
      {
        "start": 80.64,
        "duration": 4.08,
        "text": "it is a groovy based tool so while you"
      },
      {
        "start": 82.799,
        "duration": 3.761,
        "text": "can incorporate transformations into"
      },
      {
        "start": 84.72,
        "duration": 5.439,
        "text": "your data mappings this method is"
      },
      {
        "start": 86.56,
        "duration": 3.599,
        "text": "deprecated and should not be used"
      },
      {
        "start": 90.64,
        "duration": 3.119,
        "text": "this is an overview of how the data"
      },
      {
        "start": 92.079,
        "duration": 3.36,
        "text": "stacks graph loader works"
      },
      {
        "start": 93.759,
        "duration": 3.68,
        "text": "first a user must create a loading"
      },
      {
        "start": 95.439,
        "duration": 3.121,
        "text": "script in groovy this script tells the"
      },
      {
        "start": 97.439,
        "duration": 3.201,
        "text": "graph loader about preferred"
      },
      {
        "start": 98.56,
        "duration": 3.12,
        "text": "configurations data sources and data"
      },
      {
        "start": 100.64,
        "duration": 2.64,
        "text": "mappings"
      },
      {
        "start": 101.68,
        "duration": 3.04,
        "text": "the graph order will use the mapper"
      },
      {
        "start": 103.28,
        "duration": 3.44,
        "text": "script to read data from their"
      },
      {
        "start": 104.72,
        "duration": 3.6,
        "text": "respective data sources and load it into"
      },
      {
        "start": 106.72,
        "duration": 3.28,
        "text": "dse graph"
      },
      {
        "start": 108.32,
        "duration": 3.119,
        "text": "there are three data processing stages"
      },
      {
        "start": 110.0,
        "duration": 2.799,
        "text": "that the data stacks enterprise graph"
      },
      {
        "start": 111.439,
        "duration": 3.441,
        "text": "loader goes through"
      },
      {
        "start": 112.799,
        "duration": 3.521,
        "text": "first there's a preparation phase this"
      },
      {
        "start": 114.88,
        "duration": 3.36,
        "text": "is where the graph loader will validate"
      },
      {
        "start": 116.32,
        "duration": 3.119,
        "text": "the data from the data sources"
      },
      {
        "start": 118.24,
        "duration": 3.199,
        "text": "check to make sure that you have the"
      },
      {
        "start": 119.439,
        "duration": 3.441,
        "text": "proper schema in place and of course"
      },
      {
        "start": 121.439,
        "duration": 3.68,
        "text": "validate the loading strip for any"
      },
      {
        "start": 122.88,
        "duration": 4.4,
        "text": "possible issues"
      },
      {
        "start": 125.119,
        "duration": 4.081,
        "text": "then the graph loader will begin loading"
      },
      {
        "start": 127.28,
        "duration": 4.24,
        "text": "or retrieving existing vertices and"
      },
      {
        "start": 129.2,
        "duration": 5.039,
        "text": "caches them for use in the third step"
      },
      {
        "start": 131.52,
        "duration": 4.64,
        "text": "which is the edge and property loading"
      },
      {
        "start": 134.239,
        "duration": 3.761,
        "text": "the edge and property loading stage is"
      },
      {
        "start": 136.16,
        "duration": 3.92,
        "text": "generally the most time consuming"
      },
      {
        "start": 138.0,
        "duration": 3.36,
        "text": "when loading multi properties the schema"
      },
      {
        "start": 140.08,
        "duration": 3.84,
        "text": "should reflect that fact"
      },
      {
        "start": 141.36,
        "duration": 4.0,
        "text": "to avoid having upsets let's talk about"
      },
      {
        "start": 143.92,
        "duration": 2.959,
        "text": "the different data sources and file"
      },
      {
        "start": 145.36,
        "duration": 2.64,
        "text": "formats you can use with the data stacks"
      },
      {
        "start": 146.879,
        "duration": 3.121,
        "text": "graph loader"
      },
      {
        "start": 148.0,
        "duration": 3.519,
        "text": "you have support for all the formats"
      },
      {
        "start": 150.0,
        "duration": 4.16,
        "text": "you'd expect csv"
      },
      {
        "start": 151.519,
        "duration": 4.481,
        "text": "json delimited text and also support for"
      },
      {
        "start": 154.16,
        "duration": 5.12,
        "text": "graph specific formats such as graphs"
      },
      {
        "start": 156.0,
        "duration": 5.12,
        "text": "on graphml and grio what's also"
      },
      {
        "start": 159.28,
        "duration": 4.0,
        "text": "interesting is that the datastax graph"
      },
      {
        "start": 161.12,
        "duration": 3.68,
        "text": "loader can load data directly from jdbc"
      },
      {
        "start": 163.28,
        "duration": 3.12,
        "text": "compatible databases"
      },
      {
        "start": 164.8,
        "duration": 4.48,
        "text": "and this includes other graph databases"
      },
      {
        "start": 166.4,
        "duration": 4.24,
        "text": "such as titan janus and neo4j"
      },
      {
        "start": 169.28,
        "duration": 3.599,
        "text": "next we're going to be discussing"
      },
      {
        "start": 170.64,
        "duration": 3.2,
        "text": "loading script design for the dsc graph"
      },
      {
        "start": 172.879,
        "duration": 2.72,
        "text": "loader"
      },
      {
        "start": 173.84,
        "duration": 3.6,
        "text": "as we talked about previously the"
      },
      {
        "start": 175.599,
        "duration": 3.441,
        "text": "loading script defines the graph loader"
      },
      {
        "start": 177.44,
        "duration": 4.32,
        "text": "configuration it defines the data"
      },
      {
        "start": 179.04,
        "duration": 4.4,
        "text": "sources and defines the data mappings"
      },
      {
        "start": 181.76,
        "duration": 2.8,
        "text": "and because it is a groovy based tool it"
      },
      {
        "start": 183.44,
        "duration": 2.4,
        "text": "also supports groovy based"
      },
      {
        "start": 184.56,
        "duration": 4.08,
        "text": "transformations though this"
      },
      {
        "start": 185.84,
        "duration": 4.08,
        "text": "functionality is deprecated"
      },
      {
        "start": 188.64,
        "duration": 2.8,
        "text": "here are some of the configurations that"
      },
      {
        "start": 189.92,
        "duration": 2.72,
        "text": "you can define with the datastax graph"
      },
      {
        "start": 191.44,
        "duration": 3.6,
        "text": "loader"
      },
      {
        "start": 192.64,
        "duration": 4.64,
        "text": "the options address and graph are"
      },
      {
        "start": 195.04,
        "duration": 4.16,
        "text": "straightforward and required"
      },
      {
        "start": 197.28,
        "duration": 3.599,
        "text": "create graph enables the creation of a"
      },
      {
        "start": 199.2,
        "duration": 3.36,
        "text": "new graph by default"
      },
      {
        "start": 200.879,
        "duration": 3.36,
        "text": "and if you want the best performance you"
      },
      {
        "start": 202.56,
        "duration": 3.679,
        "text": "should be loading data into an existing"
      },
      {
        "start": 204.239,
        "duration": 4.08,
        "text": "graph with well-defined schema that has"
      },
      {
        "start": 206.239,
        "duration": 3.28,
        "text": "indices to support useful lookups during"
      },
      {
        "start": 208.319,
        "duration": 3.28,
        "text": "data loading"
      },
      {
        "start": 209.519,
        "duration": 4.161,
        "text": "therefore create schema should be set to"
      },
      {
        "start": 211.599,
        "duration": 2.961,
        "text": "false another performance related"
      },
      {
        "start": 213.68,
        "duration": 3.919,
        "text": "optimization"
      },
      {
        "start": 214.56,
        "duration": 5.039,
        "text": "is possible with load new equals true"
      },
      {
        "start": 217.599,
        "duration": 3.761,
        "text": "if you're loading a new data set data"
      },
      {
        "start": 219.599,
        "duration": 3.841,
        "text": "stack's graph footer will rely on this"
      },
      {
        "start": 221.36,
        "duration": 4.159,
        "text": "option will not waste time verifying if"
      },
      {
        "start": 223.44,
        "duration": 3.2,
        "text": "a vertex or edge already exists in the"
      },
      {
        "start": 225.519,
        "duration": 3.041,
        "text": "graph"
      },
      {
        "start": 226.64,
        "duration": 5.12,
        "text": "it will assume to be imported graph"
      },
      {
        "start": 228.56,
        "duration": 5.28,
        "text": "elements are new and have unique ids"
      },
      {
        "start": 231.76,
        "duration": 3.039,
        "text": "there is also a finer grain mechanism to"
      },
      {
        "start": 233.84,
        "duration": 2.88,
        "text": "specify"
      },
      {
        "start": 234.799,
        "duration": 4.241,
        "text": "existence of specific graph elements"
      },
      {
        "start": 236.72,
        "duration": 3.519,
        "text": "when defining a data mapping"
      },
      {
        "start": 239.04,
        "duration": 3.839,
        "text": "we'll cover this later in the"
      },
      {
        "start": 240.239,
        "duration": 2.64,
        "text": "presentation"
      },
      {
        "start": 243.2,
        "duration": 3.039,
        "text": "there are many other options for"
      },
      {
        "start": 244.64,
        "duration": 5.599,
        "text": "customization so please take a look at"
      },
      {
        "start": 246.239,
        "duration": 4.0,
        "text": "the documentation for an expansive list"
      },
      {
        "start": 250.48,
        "duration": 4.64,
        "text": "here are a few parameters you can adjust"
      },
      {
        "start": 252.239,
        "duration": 4.481,
        "text": "for increasing or decreasing performance"
      },
      {
        "start": 255.12,
        "duration": 4.399,
        "text": "read threads is the number of threads"
      },
      {
        "start": 256.72,
        "duration": 4.479,
        "text": "used to read data from the data input"
      },
      {
        "start": 259.519,
        "duration": 3.601,
        "text": "load vertex threads is the number of"
      },
      {
        "start": 261.199,
        "duration": 2.801,
        "text": "threads used for loading vertices by"
      },
      {
        "start": 263.12,
        "duration": 2.88,
        "text": "default"
      },
      {
        "start": 264.0,
        "duration": 3.759,
        "text": "it's set to zero which will force the"
      },
      {
        "start": 266.0,
        "duration": 2.88,
        "text": "number to be the number of physical"
      },
      {
        "start": 267.759,
        "duration": 3.601,
        "text": "cores divided by"
      },
      {
        "start": 268.88,
        "duration": 4.16,
        "text": "two load edge threads controls the"
      },
      {
        "start": 271.36,
        "duration": 3.76,
        "text": "number of threads used for loading edges"
      },
      {
        "start": 273.04,
        "duration": 3.92,
        "text": "and properties and will default to zero"
      },
      {
        "start": 275.12,
        "duration": 4.96,
        "text": "which translates to the number of nodes"
      },
      {
        "start": 276.96,
        "duration": 4.56,
        "text": "in a respective data center times six"
      },
      {
        "start": 280.08,
        "duration": 3.36,
        "text": "now that we know some of the important"
      },
      {
        "start": 281.52,
        "duration": 4.16,
        "text": "configurations for the datastax graph"
      },
      {
        "start": 283.44,
        "duration": 3.92,
        "text": "folder let's put them to good use"
      },
      {
        "start": 285.68,
        "duration": 3.6,
        "text": "here's how you define configurations"
      },
      {
        "start": 287.36,
        "duration": 4.08,
        "text": "within your loading script"
      },
      {
        "start": 289.28,
        "duration": 4.08,
        "text": "notice the config declaration followed"
      },
      {
        "start": 291.44,
        "duration": 4.08,
        "text": "by the parameter and the value"
      },
      {
        "start": 293.36,
        "duration": 3.92,
        "text": "you can also see an alternate syntax at"
      },
      {
        "start": 295.52,
        "duration": 5.2,
        "text": "the bottom using a comma to separate"
      },
      {
        "start": 297.28,
        "duration": 5.28,
        "text": "parameters on a single line"
      },
      {
        "start": 300.72,
        "duration": 4.319,
        "text": "once we have our configurations defined"
      },
      {
        "start": 302.56,
        "duration": 4.4,
        "text": "it's time to define our input sources"
      },
      {
        "start": 305.039,
        "duration": 3.761,
        "text": "you can see that from the file method we"
      },
      {
        "start": 306.96,
        "duration": 3.28,
        "text": "can specify which type of file format"
      },
      {
        "start": 308.8,
        "duration": 2.959,
        "text": "we're loading and whether or not there's"
      },
      {
        "start": 310.24,
        "duration": 4.0,
        "text": "a specific delimiter or header"
      },
      {
        "start": 311.759,
        "duration": 4.961,
        "text": "associated with it"
      },
      {
        "start": 314.24,
        "duration": 4.32,
        "text": "now if your input data is one of three"
      },
      {
        "start": 316.72,
        "duration": 4.4,
        "text": "main graph file formats"
      },
      {
        "start": 318.56,
        "duration": 3.76,
        "text": "the syntax is a little bit different we"
      },
      {
        "start": 321.12,
        "duration": 3.359,
        "text": "call the graph method"
      },
      {
        "start": 322.32,
        "duration": 5.84,
        "text": "specifically the file name and then the"
      },
      {
        "start": 324.479,
        "duration": 3.681,
        "text": "type of graph format we're reading from"
      },
      {
        "start": 329.52,
        "duration": 4.08,
        "text": "lastly here's how we can load data from"
      },
      {
        "start": 331.36,
        "duration": 3.6,
        "text": "a jdbc compatible database"
      },
      {
        "start": 333.6,
        "duration": 3.12,
        "text": "you first need to create a database"
      },
      {
        "start": 334.96,
        "duration": 3.04,
        "text": "connection which we can do by calling"
      },
      {
        "start": 336.72,
        "duration": 3.44,
        "text": "the database method"
      },
      {
        "start": 338.0,
        "duration": 3.28,
        "text": "provide a connection string database"
      },
      {
        "start": 340.16,
        "duration": 2.879,
        "text": "type and then of course the"
      },
      {
        "start": 341.28,
        "duration": 3.6,
        "text": "authentication"
      },
      {
        "start": 343.039,
        "duration": 3.361,
        "text": "then we can use that database connection"
      },
      {
        "start": 344.88,
        "duration": 4.72,
        "text": "to query for our data"
      },
      {
        "start": 346.4,
        "duration": 3.2,
        "text": "in sql format"
      },
      {
        "start": 350.8,
        "duration": 4.32,
        "text": "once we have our inputs defined we can"
      },
      {
        "start": 352.8,
        "duration": 4.399,
        "text": "then use the transformation api"
      },
      {
        "start": 355.12,
        "duration": 3.28,
        "text": "please note that this will be deprecated"
      },
      {
        "start": 357.199,
        "duration": 3.201,
        "text": "and might be replaced with a different"
      },
      {
        "start": 358.4,
        "duration": 3.519,
        "text": "api in the future"
      },
      {
        "start": 360.4,
        "duration": 3.44,
        "text": "the main methods you have access to are"
      },
      {
        "start": 361.919,
        "duration": 3.041,
        "text": "the map flat map and filter"
      },
      {
        "start": 363.84,
        "duration": 2.56,
        "text": "transformations"
      },
      {
        "start": 364.96,
        "duration": 3.28,
        "text": "each will create a new data set that's"
      },
      {
        "start": 366.4,
        "duration": 4.88,
        "text": "formed by applying a function on"
      },
      {
        "start": 368.24,
        "duration": 3.6,
        "text": "each element of the input data set with"
      },
      {
        "start": 371.28,
        "duration": 2.16,
        "text": "a map"
      },
      {
        "start": 371.84,
        "duration": 3.919,
        "text": "there's a one-to-one correspondence"
      },
      {
        "start": 373.44,
        "duration": 4.479,
        "text": "between input and output elements"
      },
      {
        "start": 375.759,
        "duration": 3.681,
        "text": "with a flat map there's a one-to-many"
      },
      {
        "start": 377.919,
        "duration": 3.521,
        "text": "correspondence"
      },
      {
        "start": 379.44,
        "duration": 4.08,
        "text": "as you would expect with filter the new"
      },
      {
        "start": 381.44,
        "duration": 3.92,
        "text": "data set is formed by the elements in"
      },
      {
        "start": 383.52,
        "duration": 5.36,
        "text": "the input data set that return"
      },
      {
        "start": 385.36,
        "duration": 3.52,
        "text": "true with a function f"
      },
      {
        "start": 388.96,
        "duration": 4.079,
        "text": "here's an example on how to create"
      },
      {
        "start": 390.24,
        "duration": 5.44,
        "text": "transformations in your loading script"
      },
      {
        "start": 393.039,
        "duration": 4.641,
        "text": "as you can see we define our input then"
      },
      {
        "start": 395.68,
        "duration": 3.68,
        "text": "filter on it to keep users who are over"
      },
      {
        "start": 397.68,
        "duration": 4.48,
        "text": "the age of 21."
      },
      {
        "start": 399.36,
        "duration": 4.24,
        "text": "then we use the map method to add a u in"
      },
      {
        "start": 402.16,
        "duration": 2.319,
        "text": "front of the user id value so for"
      },
      {
        "start": 403.6,
        "duration": 4.64,
        "text": "example"
      },
      {
        "start": 404.479,
        "duration": 6.961,
        "text": "25 would now become u25"
      },
      {
        "start": 408.24,
        "duration": 5.92,
        "text": "in this example flat map adds m"
      },
      {
        "start": 411.44,
        "duration": 3.36,
        "text": "in front of the movie id for example 44"
      },
      {
        "start": 414.16,
        "duration": 4.0,
        "text": "becomes"
      },
      {
        "start": 414.8,
        "duration": 6.0,
        "text": "m44 next it splits the genres"
      },
      {
        "start": 418.16,
        "duration": 3.92,
        "text": "literal into the list of genres and"
      },
      {
        "start": 420.8,
        "duration": 3.6,
        "text": "modifies each element"
      },
      {
        "start": 422.08,
        "duration": 3.04,
        "text": "of the list to be a map with fields"
      },
      {
        "start": 424.4,
        "duration": 4.239,
        "text": "movie id"
      },
      {
        "start": 425.12,
        "duration": 4.16,
        "text": "and genre this returns a new belongs to"
      },
      {
        "start": 428.639,
        "duration": 2.96,
        "text": "data set"
      },
      {
        "start": 429.28,
        "duration": 4.0,
        "text": "created by expanding lists returned by"
      },
      {
        "start": 431.599,
        "duration": 3.6,
        "text": "the lambda function"
      },
      {
        "start": 433.28,
        "duration": 4.96,
        "text": "this new data set can later be mapped to"
      },
      {
        "start": 435.199,
        "duration": 5.041,
        "text": "edges in a graph"
      },
      {
        "start": 438.24,
        "duration": 3.44,
        "text": "this is how you map input data to graph"
      },
      {
        "start": 440.24,
        "duration": 3.359,
        "text": "constituents"
      },
      {
        "start": 441.68,
        "duration": 3.519,
        "text": "simply put you call the load method"
      },
      {
        "start": 443.599,
        "duration": 3.521,
        "text": "which takes input data and"
      },
      {
        "start": 445.199,
        "duration": 3.28,
        "text": "specify whether you're loading vertices"
      },
      {
        "start": 447.12,
        "duration": 4.079,
        "text": "or edges"
      },
      {
        "start": 448.479,
        "duration": 4.881,
        "text": "the as vertices or as edges method takes"
      },
      {
        "start": 451.199,
        "duration": 6.321,
        "text": "a mapper input which we'll discuss"
      },
      {
        "start": 453.36,
        "duration": 6.959,
        "text": "next now before we create our mappings"
      },
      {
        "start": 457.52,
        "duration": 5.44,
        "text": "let's get introduced to the mapping api"
      },
      {
        "start": 460.319,
        "duration": 3.681,
        "text": "each vertex or edge must have a label"
      },
      {
        "start": 462.96,
        "duration": 3.919,
        "text": "use label or"
      },
      {
        "start": 464.0,
        "duration": 4.8,
        "text": "label field a key is what uniquely"
      },
      {
        "start": 466.879,
        "duration": 4.801,
        "text": "identifies a graph element it's not"
      },
      {
        "start": 468.8,
        "duration": 5.04,
        "text": "necessarily a vertex or edge id"
      },
      {
        "start": 471.68,
        "duration": 3.6,
        "text": "vertex property and property can map"
      },
      {
        "start": 473.84,
        "duration": 3.199,
        "text": "fields to properties"
      },
      {
        "start": 475.28,
        "duration": 3.52,
        "text": "they do not need to be used explicitly"
      },
      {
        "start": 477.039,
        "duration": 2.56,
        "text": "if a field and property names are the"
      },
      {
        "start": 478.8,
        "duration": 2.88,
        "text": "same because"
      },
      {
        "start": 479.599,
        "duration": 4.401,
        "text": "any data field becomes a vertex or edge"
      },
      {
        "start": 481.68,
        "duration": 5.12,
        "text": "property by default"
      },
      {
        "start": 484.0,
        "duration": 3.919,
        "text": "similarly value may not need to be used"
      },
      {
        "start": 486.8,
        "duration": 4.239,
        "text": "explicitly"
      },
      {
        "start": 487.919,
        "duration": 5.921,
        "text": "use ignore to not create properties out"
      },
      {
        "start": 491.039,
        "duration": 2.801,
        "text": "of fields by default"
      },
      {
        "start": 494.4,
        "duration": 4.16,
        "text": "is new and exists allow for finer"
      },
      {
        "start": 496.4,
        "duration": 4.32,
        "text": "grained mechanisms to specify existence"
      },
      {
        "start": 498.56,
        "duration": 3.919,
        "text": "of specific graph elements when defining"
      },
      {
        "start": 500.72,
        "duration": 4.08,
        "text": "a data mapping"
      },
      {
        "start": 502.479,
        "duration": 6.241,
        "text": "they override the behavior specified by"
      },
      {
        "start": 504.8,
        "duration": 7.2,
        "text": "the load new configuration option"
      },
      {
        "start": 508.72,
        "duration": 5.52,
        "text": "nv and out v help define neighbors of a"
      },
      {
        "start": 512.0,
        "duration": 5.36,
        "text": "vertex"
      },
      {
        "start": 514.24,
        "duration": 5.44,
        "text": "n e and out e help define incident edges"
      },
      {
        "start": 517.36,
        "duration": 5.599,
        "text": "of a vertex"
      },
      {
        "start": 519.68,
        "duration": 6.96,
        "text": "envy and out v with different signatures"
      },
      {
        "start": 522.959,
        "duration": 5.601,
        "text": "help define endpoints of an edge"
      },
      {
        "start": 526.64,
        "duration": 5.199,
        "text": "there are more methods so please consult"
      },
      {
        "start": 528.56,
        "duration": 4.88,
        "text": "the documentation for more information"
      },
      {
        "start": 531.839,
        "duration": 4.0,
        "text": "now let's put what we just learned to"
      },
      {
        "start": 533.44,
        "duration": 4.48,
        "text": "good use here's an example of mapping"
      },
      {
        "start": 535.839,
        "duration": 4.321,
        "text": "our person data to vertices"
      },
      {
        "start": 537.92,
        "duration": 4.479,
        "text": "since we're loading vertices we use the"
      },
      {
        "start": 540.16,
        "duration": 3.84,
        "text": "as vertices method to begin to map our"
      },
      {
        "start": 542.399,
        "duration": 3.921,
        "text": "data"
      },
      {
        "start": 544.0,
        "duration": 4.08,
        "text": "the label of this vertex is person and"
      },
      {
        "start": 546.32,
        "duration": 4.16,
        "text": "the key within the input data"
      },
      {
        "start": 548.08,
        "duration": 3.12,
        "text": "is person id both examples here are"
      },
      {
        "start": 550.48,
        "duration": 3.76,
        "text": "valid"
      },
      {
        "start": 551.2,
        "duration": 5.28,
        "text": "they just use slightly different syntax"
      },
      {
        "start": 554.24,
        "duration": 3.44,
        "text": "here's an example of mapping actors to"
      },
      {
        "start": 556.48,
        "duration": 2.799,
        "text": "edges"
      },
      {
        "start": 557.68,
        "duration": 3.68,
        "text": "this mapping is a little more in depth"
      },
      {
        "start": 559.279,
        "duration": 4.321,
        "text": "because we need to tell the graph loader"
      },
      {
        "start": 561.36,
        "duration": 4.479,
        "text": "which adjacent vertices to create an"
      },
      {
        "start": 563.6,
        "duration": 3.919,
        "text": "edge between"
      },
      {
        "start": 565.839,
        "duration": 4.081,
        "text": "because we're loading new edges to"
      },
      {
        "start": 567.519,
        "duration": 2.961,
        "text": "existing vertices we can call the exist"
      },
      {
        "start": 569.92,
        "duration": 3.599,
        "text": "method"
      },
      {
        "start": 570.48,
        "duration": 5.359,
        "text": "to our vertex mappings again this is for"
      },
      {
        "start": 573.519,
        "duration": 4.241,
        "text": "optimization"
      },
      {
        "start": 575.839,
        "duration": 5.44,
        "text": "both examples do the same thing with"
      },
      {
        "start": 577.76,
        "duration": 5.04,
        "text": "different syntax and both are valid"
      },
      {
        "start": 581.279,
        "duration": 3.041,
        "text": "now that we've learned how to create our"
      },
      {
        "start": 582.8,
        "duration": 3.599,
        "text": "own loading script it's time to learn"
      },
      {
        "start": 584.32,
        "duration": 3.92,
        "text": "how to actually run the graph loader"
      },
      {
        "start": 586.399,
        "duration": 3.601,
        "text": "all you need to do is run the graph"
      },
      {
        "start": 588.24,
        "duration": 3.52,
        "text": "loader utility specify"
      },
      {
        "start": 590.0,
        "duration": 3.76,
        "text": "your loading script and any additional"
      },
      {
        "start": 591.76,
        "duration": 3.68,
        "text": "configuration it's also worth noting"
      },
      {
        "start": 593.76,
        "duration": 4.72,
        "text": "that the command line options can be"
      },
      {
        "start": 595.44,
        "duration": 4.88,
        "text": "overridden by the loading script options"
      },
      {
        "start": 598.48,
        "duration": 3.599,
        "text": "make sure that you're using the datastax"
      },
      {
        "start": 600.32,
        "duration": 5.519,
        "text": "graph loader that matches with your"
      },
      {
        "start": 602.079,
        "duration": 3.76,
        "text": "datastax enterprise version"
      },
      {
        "start": 606.16,
        "duration": 5.119,
        "text": "it's time to put your new graph loader"
      },
      {
        "start": 607.76,
        "duration": 3.519,
        "text": "knowledge to use with this hands-on"
      },
      {
        "start": 611.88,
        "duration": 3.0,
        "text": "exercise"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T22:47:36.655927+00:00"
}