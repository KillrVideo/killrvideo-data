{
  "video_id": "V2iKyt-zen4",
  "title": "Distributed Data Show Episode 9: Avoiding Apache Cassandra Replication Mistakes with DuyHai Doan",
  "description": "DuyHai Doan (@doanduyhai) shares about his experiences supporting DataStax customers in Europe, including some of the most common misunderstandings he sees regarding configuring Apache Cassandra and DataStax Enterprise clusters for high availability. \n\nABOUT DATASTAX ENTERPRISE 5\nDataStax Enterprise 5.0, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.0 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax Enterprise©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-08-22T15:00:01Z",
  "thumbnail": "https://i.ytimg.com/vi/V2iKyt-zen4/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=V2iKyt-zen4",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems hi this is Jeff carpenter this is another episode of the distributed data show I am here live in the studio with mr. Patrick McFadden hi there Jeff how are you and I am joined via the interwebs by mr. David Gilardi hello and as usual we have Luke Tillman hello everyone and I am excited to share that today we have a complete set of evangelists yes that's right joining us from Paris France were there there abouts is mr. twee higuaín and we will be enjoying talking to him today he is frequently all over the place in Europe not just doing this evangelist thing but supporting our sales engineering teams out there as well so he gets a lot of customer interaction and has a lot of great things to share with us yeah hello everyone Adri i we we have questions today lots of questions and so this is the thing that I feel like you could bring a lot of really interesting stuff to the to this show because you've got great stories you've been out there you've seen some interesting things I'm always riveted by some of the stories you run into quite amazing but so today we're going to ask some questions about that and so first of all what is going on in the field I mean you've got some interesting stories can you pick a couple for us oh sure so recently I has been involved with a loser and I just realized that even Jesus and Cassandra people seem get confused about high availability in their mind the more nuts you have and the higher availability you get which is completely wrong so let's say you have a cluster of 100 nodes right and if you set your application factor to 1 and if you lose one node you will one hundredths of your data and therefore you are no longer strictly high highly available so indeed the high availability is more dependent on the replication factor the more because you have and the higher the availability you also need to take into account the consistency level to be used for example if your application factor is three and you are using consistency level one you can afford to lose up to two notes at the same time and if you are using consistency level column you can only lose one not because coram require you to have at least three replicas out of two replicas out of three to be online in order to be to execute the request in fact so in to increase your fader programs you can sometimes use I have seen very few people in fact they choose to have replication factor equal to five and in fact in this case with consistency level one they can lose up to four notes by five so you can lose up to four notes without compromising their availability or they can lose up to two notes at the same time if they are using consistency level quorum so long story short the replication factor is in fact the key to get high availability majority of customer user they will choose a replication factor three in some rare case when they need immediate consistency and the availability to lose the eight failed ability to lose two notes at the same time they will choose replication factor five but the price in terms of storage is quite expensive so ways like backup you said replication factor of five which you know I agree you almost never see in production so what like explain to people listening what is the ration why would someone choose to use a replication factor of five and be able to tolerate two replicas going down like that so excellent question so indeed there is a real niche use case for this equipment so imagine that you are performing some rolling upgrade on your cluster so it's very classical scenario so it means that you have one not off line for a short period of time to to put the new binaries and to restart the now try and if you are unlucky during this period of time and another note goes down you will lose availability right so in some rare case and if you are really a paranoid customer ups you may want to have replication factor 5 to shield yourself from this scenario but really to be honest I find that it does not work to pay the cost for two extra copies just for this edge case all right all right so fair enough fair enough but I want to come back to the number note right how does it impact contendere operations then if availability doesn't depend on it so in fact the number of machines in your cluster will determine how your workload will be will be distributed the spoilers Cassandra set up in production is usually three machines right and if you want immediate consistency using quorum you should have replication factor free but then it means that each of your node will manage 100% of your data and in fact there is no real data distribution in this case now let's say you have four nodes and you keep your replication factor to three each node will manage now three fourths of your data which is slightly better but not that great and having five knots mean that each node will manage now three fifths of your data right so as we can see the more machines you have and the better your workload will be spread out and of course we make the assumption that the token range are allocated evenly and there is no data secure so I want to get back to a point you made and I think this is really important for people who are conveyed at least not heavily experienced with using replication factor and what that really means you say if you want immediate consistent using quorum you should use RF equal 3yr f3o type thank you for asking this question it will allow me to highlight some classical Cavett's that's Cassandra beginners they get caught with so let's set aside replication factor one because it's nonsensical for production now we have the choice between replication factor two and three when you are using quorum for immediate consistency it means that you need a suite majority so if you have free copy of your data the sick majority is to write but now if you have two copies the street majority of two is two so in this specific case consistency quorum is equivalent to consistency level all and it means that you give up an high availability if one node goes down interestingly enough I have seen some experienced people they did crazy things so they use replication factor two of course they are writing at consistency level one to have high availability and they are also reading with consistency level one but you know that you can set there is a parameter there you can set the repair chance which is a property of your table and those people they are setting really a chance to a value very close to one so that it is pretty much equivalent to read it through to read your data at consistency level on and if you lose one node during a in production the read repair will still succeed because it is not a hard requirement to have two copies of data so it is a really exotic I will say exotic usage of Cassandra okay so would that be the same thing or you could you get the equivalent behavior if you use the consistency level all and then the downgrading consistency retry policy on the dir side pretty much in fact but to finish I would I would not recommend people using this trick because you know having the application factor 3 is much more safer you you don't you do not need to choose your mind and in fact the difference between replication factor 2 & 3 is not that much expensive you are just paying for one extra copy that's not a big deal really yeah and that's probably especially true when you have more than one data center so you're already you know duplicating your data so more than one copy really isn't that big of a deal right yeah and talking about multi data center again Cassandra beginners they get always surprised during my presentation when I told them that 100 of % of their data is replicated in each data center it did even if they belong to the same cluster each data center has its own replication factor and it makes things a little bit more complicated to result to reason with consistency level so suppose you have two data center right c1 + DC - in DC one you set replication factor to five and in DC - you set replication factor to 3 or 5 here and 3 here now on the cluster level you have 5 + 3 equals to 8 copies of your data in total plus the wide a request which is using consistency level quorum now we can put a straight majority of the total number of copies so it means that quorum requires 5 copies out of 8 and if your client is connecting to data center 1 which has 5 copy it is likely that all the 5 copies in this DC will reply back faster than the other copies in DC - but if your client is connecting to DC - which has only 3 copies you're pretty sure every time you will require two extra copy from the Odyssey and in this case you have a huge impact on your latency another tricky consistency level is each forum so each column means that for each request we require a suite majority of Tripucka in HTC to reply right so with our example in DC one we have five copies of data will go at three copies our five should reply to your request and in DC to where we have three copies we require that two of them are replying to your request so when you are using each column you will give up for sure on high availability whenever a whole data center goes down but the advantage of this consistency level is that you are guaranteed to have your data consistent across data center so this is the price to pay to have consistency across data center warranty okay so what if I want strong B across my data centers as well being able to survive the failure one of them um this is a very thing very interesting question so I have been challenged recently with some user and they want exactly this requirement so let's start from the beginning in order to have some consistency across data center we cannot use local one consistency level or local quorum of course so we we move them out of the equation if we use each column as I said before we lose high availability in case of one data center failure so now what do we have left we have on the quorum less as an alternative and now the trick is how to choose the correct number of data centers and the correct replication factor in each of them to fulfill the requirement so let's stop if we go for two data center by example three copies in datacenter one and Twitter copies in datacenter - so now we have in total six copy of data and a global quorum on six require four write Sigma jority of six is four so it means that whenever 1dc goes down your quorum cannot be achieved right because you will always have a one copy of data missing if we choose replication factor of five for DC one and reflect replication factor three - DC DC - the quorum of five plus three equal eight requires five replicas so if this C one goes down again we are basically back to the previous situation now if we have three datacenter it's become more interesting three data center replication factor - in each of them so two plus two plus two equal to six to have a global quorum out of six copies of data you require four of them to be online whenever one PC goes down you lose two copies but you still have four other copies across two other data center so in this this is the correct answer you have three data center in each of them you have two copies and in this scenario you can use column consistency level and you can afford to lose one data center completely and still have high availability so let's follow up a little bit on high availability what are the consequences of losing multiple nodes so we know you said this already that with an RF of three and a consistency level of one we can afford to lose two nodes simultaneously and still be online but it's not guaranteed in all cases is there a particular scenario where maybe Bob distribution of replicas could lead to data loss or you know is there an edge case here so no in fact just sort of try to replicate each small range of tokens on different notes so losing all three replicas when you have two physical notes down is not possible there is still a case where it can happen it is when you host you are hosting - Cassandra processes on the same physical machine so in this case all the grantees of course are off that's why in fact we have a feature in data section for Christ we call multi and Suns it is useful when in some you know big companies you can only order big boxes and buy big boxes I mean hundreds of CPU cores hundreds of gigabytes of RAM and a dozen of hard drives so in this case not to waste all the resources you can host multiple instances of Cassandra on the same box but with DSM in the instance we try our best to dispatch each replica of the Cassandra not on different physical boxes using drug awareness and so on however there is no magic you should always remember that if you have for example replication factor of three and only two boxes losing one box we will surely lead to losing two replicas out of three for some token wrenches right no magic but no magic do you have any you'd like your trademark term dude there is no magical hassel okay so that's really interesting when you're talking about using some of these big box machines and then the interaction of that with racks so how does this work with replicas distribution when you have a multi data center set up so as I said earlier 100 of 100 percent of your data set is replicated inside each data center so losing a whole DC is not a problem as long as you have at least one DC surviving now there is a subtour detail that most users ignore which is also each data center manages its own ranges of tokens each token value is cluster wider means that if you are using six seconds like in the old days the token value on each note no matter in which DC it is should be different so we can see on internet some blog posts are people giving some rules how to choose the correct and range so some folks they are just incrementing by one when you change when you switch from one DC to another DC and that's the idea okay everyone take a second just digest that for a little bit that was a lot of really intense information so and I appreciate that I mean you are definitely an expert in this field and if you if you are listening and understanding what do we hi just told you your life is going to be a way a lot better but let's lighten it up a little bit I mean I think this is let's get into some fun stuff here I want to like change off from you know some more the more technical deep dive details here just some funny things that you've seen out in the field what without naming names we want to protect the innocent what are some of the funny things that you've seen in the field oh so very classical story some people call me hey we have a performance issue in production okay but the weird thing is we we have the same environment from pre-production and production and we didn't face those issue so I asked them did you have the same data set or the same workload when you test it your pre-production and they said yes yes of course we we try to replicate the same workload at the production and so what kind of CPU do you have okay how many how much gram do you have okay what is your disk oh we are using a SAN got worse it got worse we're all like oh that's the punchline oh no it's not the best part a story so those guys say but you know what we were benchmarking a lot of time and the performance was great so yeah there's no problem I did a problem with the Sun is you can benchmark 1000 times it doesn't mean anything why because you never know who is using your fan you can be just lucky during one month doing some 1000 benchmark and everything is fine and then when you get to production some some project they are just loading a bunch of data using the same Sun and then it will kill your bandwidth with the disk does that what happened yeah okay and I said okay okay we understand now in fact having benchmark having good benchmark results understand it's not a proof at all at all actually because it's a good way lie to everyone and saying are saying as awesome and what if it's not a shared resource like the case that you mentioned is it still a bad idea I mean come on there's zero times that Santa is the right answer okay thanks Sochi yeah very good it's a book it's all about predictability if you cannot predict your bandwidth in fact you can cover you can not control your prediction period yeah and then I think that that's the key is and I think that's were a lot of new users stumble into and that's why you mentioning is because you talk to a lot of new users is these are just things you learn to experience and hopefully you out there are listening please listen please there is there's good body of evidence don't don't think that you're special that's one of my favorites oh everyone else fail because they're not good at this we are how many times have you heard that we I oh boy yeah all right I think we've consumed enough Internet bandwidth for right now do we hide thank you very much for joining us today welcome acid waste and we hope to see you again soon you'll be I'm sure you'd be a host on this as well so thank you everyone for joining us today thank you thank you thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data Stax Academy and tell us what you think you can also find us on the data Stax Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.14,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.34,
        "duration": 4.2,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.17,
        "duration": 4.259,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.54,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.429,
        "duration": 7.831,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.59,
        "duration": 8.37,
        "text": "large-scale distributed systems hi this"
      },
      {
        "start": 16.26,
        "duration": 4.89,
        "text": "is Jeff carpenter this is another"
      },
      {
        "start": 18.96,
        "duration": 4.62,
        "text": "episode of the distributed data show I"
      },
      {
        "start": 21.15,
        "duration": 4.53,
        "text": "am here live in the studio with mr."
      },
      {
        "start": 23.58,
        "duration": 5.97,
        "text": "Patrick McFadden hi there Jeff how are"
      },
      {
        "start": 25.68,
        "duration": 5.519,
        "text": "you and I am joined via the interwebs by"
      },
      {
        "start": 29.55,
        "duration": 7.73,
        "text": "mr. David Gilardi"
      },
      {
        "start": 31.199,
        "duration": 9.901,
        "text": "hello and as usual we have Luke Tillman"
      },
      {
        "start": 37.28,
        "duration": 6.509,
        "text": "hello everyone and I am excited to share"
      },
      {
        "start": 41.1,
        "duration": 5.93,
        "text": "that today we have a complete set of"
      },
      {
        "start": 43.789,
        "duration": 6.071,
        "text": "evangelists yes that's right joining us"
      },
      {
        "start": 47.03,
        "duration": 5.799,
        "text": "from Paris France"
      },
      {
        "start": 49.86,
        "duration": 6.51,
        "text": "were there there abouts is mr. twee"
      },
      {
        "start": 52.829,
        "duration": 6.21,
        "text": "higuaín and we will be enjoying talking"
      },
      {
        "start": 56.37,
        "duration": 5.939,
        "text": "to him today he is frequently all over"
      },
      {
        "start": 59.039,
        "duration": 5.211,
        "text": "the place in Europe not just doing this"
      },
      {
        "start": 62.309,
        "duration": 4.261,
        "text": "evangelist thing but supporting our"
      },
      {
        "start": 64.25,
        "duration": 3.85,
        "text": "sales engineering teams out there as"
      },
      {
        "start": 66.57,
        "duration": 3.93,
        "text": "well so he gets a lot of customer"
      },
      {
        "start": 68.1,
        "duration": 4.86,
        "text": "interaction and has a lot of great"
      },
      {
        "start": 70.5,
        "duration": 3.18,
        "text": "things to share with us yeah hello"
      },
      {
        "start": 72.96,
        "duration": 4.26,
        "text": "everyone"
      },
      {
        "start": 73.68,
        "duration": 5.22,
        "text": "Adri i we we have questions today lots"
      },
      {
        "start": 77.22,
        "duration": 4.469,
        "text": "of questions and so this is the thing"
      },
      {
        "start": 78.9,
        "duration": 4.71,
        "text": "that I feel like you could bring a lot"
      },
      {
        "start": 81.689,
        "duration": 4.081,
        "text": "of really interesting stuff to the to"
      },
      {
        "start": 83.61,
        "duration": 3.6,
        "text": "this show because you've got great"
      },
      {
        "start": 85.77,
        "duration": 3.389,
        "text": "stories you've been out there you've"
      },
      {
        "start": 87.21,
        "duration": 3.869,
        "text": "seen some interesting things"
      },
      {
        "start": 89.159,
        "duration": 4.561,
        "text": "I'm always riveted by some of the"
      },
      {
        "start": 91.079,
        "duration": 5.161,
        "text": "stories you run into quite amazing but"
      },
      {
        "start": 93.72,
        "duration": 5.13,
        "text": "so today we're going to ask some"
      },
      {
        "start": 96.24,
        "duration": 5.04,
        "text": "questions about that and so first of all"
      },
      {
        "start": 98.85,
        "duration": 4.17,
        "text": "what is going on in the field I mean"
      },
      {
        "start": 101.28,
        "duration": 4.979,
        "text": "you've got some interesting stories can"
      },
      {
        "start": 103.02,
        "duration": 6.15,
        "text": "you pick a couple for us oh sure"
      },
      {
        "start": 106.259,
        "duration": 5.64,
        "text": "so recently I has been involved with a"
      },
      {
        "start": 109.17,
        "duration": 4.92,
        "text": "loser and I just realized that even"
      },
      {
        "start": 111.899,
        "duration": 5.01,
        "text": "Jesus and Cassandra people seem get"
      },
      {
        "start": 114.09,
        "duration": 5.819,
        "text": "confused about high availability in"
      },
      {
        "start": 116.909,
        "duration": 5.67,
        "text": "their mind the more nuts you have and"
      },
      {
        "start": 119.909,
        "duration": 5.221,
        "text": "the higher availability you get which is"
      },
      {
        "start": 122.579,
        "duration": 6.001,
        "text": "completely wrong so let's say you have a"
      },
      {
        "start": 125.13,
        "duration": 6.45,
        "text": "cluster of 100 nodes right and if you"
      },
      {
        "start": 128.58,
        "duration": 4.57,
        "text": "set your application factor to 1 and if"
      },
      {
        "start": 131.58,
        "duration": 3.989,
        "text": "you lose one node you will"
      },
      {
        "start": 133.15,
        "duration": 4.89,
        "text": "one hundredths of your data and"
      },
      {
        "start": 135.569,
        "duration": 6.041,
        "text": "therefore you are no longer strictly"
      },
      {
        "start": 138.04,
        "duration": 6.559,
        "text": "high highly available so indeed the high"
      },
      {
        "start": 141.61,
        "duration": 6.269,
        "text": "availability is more dependent on the"
      },
      {
        "start": 144.599,
        "duration": 7.871,
        "text": "replication factor the more because you"
      },
      {
        "start": 147.879,
        "duration": 9.381,
        "text": "have and the higher the availability you"
      },
      {
        "start": 152.47,
        "duration": 7.859,
        "text": "also need to take into account the"
      },
      {
        "start": 157.26,
        "duration": 6.63,
        "text": "consistency level to be used for example"
      },
      {
        "start": 160.329,
        "duration": 7.44,
        "text": "if your application factor is three and"
      },
      {
        "start": 163.89,
        "duration": 6.04,
        "text": "you are using consistency level one you"
      },
      {
        "start": 167.769,
        "duration": 5.09,
        "text": "can afford to lose up to two notes at"
      },
      {
        "start": 169.93,
        "duration": 5.97,
        "text": "the same time and if you are using"
      },
      {
        "start": 172.859,
        "duration": 5.981,
        "text": "consistency level column you can only"
      },
      {
        "start": 175.9,
        "duration": 6.149,
        "text": "lose one not because coram require you"
      },
      {
        "start": 178.84,
        "duration": 6.239,
        "text": "to have at least three replicas out of"
      },
      {
        "start": 182.049,
        "duration": 6.27,
        "text": "two replicas out of three to be online"
      },
      {
        "start": 185.079,
        "duration": 6.72,
        "text": "in order to be to execute the request in"
      },
      {
        "start": 188.319,
        "duration": 6.78,
        "text": "fact so in to increase your fader"
      },
      {
        "start": 191.799,
        "duration": 6.0,
        "text": "programs you can sometimes use I have"
      },
      {
        "start": 195.099,
        "duration": 5.371,
        "text": "seen very few people in fact they choose"
      },
      {
        "start": 197.799,
        "duration": 5.28,
        "text": "to have replication factor equal to five"
      },
      {
        "start": 200.47,
        "duration": 5.4,
        "text": "and in fact in this case with"
      },
      {
        "start": 203.079,
        "duration": 6.09,
        "text": "consistency level one they can lose up"
      },
      {
        "start": 205.87,
        "duration": 6.72,
        "text": "to four notes by five so you can lose up"
      },
      {
        "start": 209.169,
        "duration": 6.481,
        "text": "to four notes without compromising their"
      },
      {
        "start": 212.59,
        "duration": 5.519,
        "text": "availability or they can lose up to two"
      },
      {
        "start": 215.65,
        "duration": 6.39,
        "text": "notes at the same time if they are using"
      },
      {
        "start": 218.109,
        "duration": 6.571,
        "text": "consistency level quorum so long story"
      },
      {
        "start": 222.04,
        "duration": 6.169,
        "text": "short the replication factor is in fact"
      },
      {
        "start": 224.68,
        "duration": 6.54,
        "text": "the key to get high availability"
      },
      {
        "start": 228.209,
        "duration": 5.831,
        "text": "majority of customer user they will"
      },
      {
        "start": 231.22,
        "duration": 5.75,
        "text": "choose a replication factor three in"
      },
      {
        "start": 234.04,
        "duration": 6.14,
        "text": "some rare case when they need immediate"
      },
      {
        "start": 236.97,
        "duration": 7.269,
        "text": "consistency and the availability to lose"
      },
      {
        "start": 240.18,
        "duration": 5.739,
        "text": "the eight failed ability to lose two"
      },
      {
        "start": 244.239,
        "duration": 5.22,
        "text": "notes at the same time they will choose"
      },
      {
        "start": 245.919,
        "duration": 6.53,
        "text": "replication factor five but the price in"
      },
      {
        "start": 249.459,
        "duration": 5.731,
        "text": "terms of storage is quite expensive so"
      },
      {
        "start": 252.449,
        "duration": 5.981,
        "text": "ways like backup you said replication"
      },
      {
        "start": 255.19,
        "duration": 7.05,
        "text": "factor of five which you know I agree"
      },
      {
        "start": 258.43,
        "duration": 6.6,
        "text": "you almost never see in production so"
      },
      {
        "start": 262.24,
        "duration": 4.26,
        "text": "what like explain to people listening"
      },
      {
        "start": 265.03,
        "duration": 3.99,
        "text": "what is the ration"
      },
      {
        "start": 266.5,
        "duration": 4.89,
        "text": "why would someone choose to use a"
      },
      {
        "start": 269.02,
        "duration": 4.62,
        "text": "replication factor of five and be able"
      },
      {
        "start": 271.39,
        "duration": 5.07,
        "text": "to tolerate two replicas going down like"
      },
      {
        "start": 273.64,
        "duration": 6.21,
        "text": "that so excellent question so indeed"
      },
      {
        "start": 276.46,
        "duration": 6.12,
        "text": "there is a real niche use case for this"
      },
      {
        "start": 279.85,
        "duration": 4.95,
        "text": "equipment so imagine that you are"
      },
      {
        "start": 282.58,
        "duration": 5.34,
        "text": "performing some rolling upgrade on your"
      },
      {
        "start": 284.8,
        "duration": 6.66,
        "text": "cluster so it's very classical scenario"
      },
      {
        "start": 287.92,
        "duration": 6.18,
        "text": "so it means that you have one not off"
      },
      {
        "start": 291.46,
        "duration": 4.59,
        "text": "line for a short period of time to to"
      },
      {
        "start": 294.1,
        "duration": 5.43,
        "text": "put the new binaries and to restart the"
      },
      {
        "start": 296.05,
        "duration": 6.24,
        "text": "now try and if you are unlucky during"
      },
      {
        "start": 299.53,
        "duration": 6.45,
        "text": "this period of time and another note"
      },
      {
        "start": 302.29,
        "duration": 7.14,
        "text": "goes down you will lose availability"
      },
      {
        "start": 305.98,
        "duration": 5.73,
        "text": "right so in some rare case and if you"
      },
      {
        "start": 309.43,
        "duration": 5.31,
        "text": "are really a paranoid customer ups you"
      },
      {
        "start": 311.71,
        "duration": 5.19,
        "text": "may want to have replication factor 5 to"
      },
      {
        "start": 314.74,
        "duration": 5.1,
        "text": "shield yourself from this scenario but"
      },
      {
        "start": 316.9,
        "duration": 5.49,
        "text": "really to be honest I find that it does"
      },
      {
        "start": 319.84,
        "duration": 5.97,
        "text": "not work to pay the cost for two extra"
      },
      {
        "start": 322.39,
        "duration": 5.4,
        "text": "copies just for this edge case all right"
      },
      {
        "start": 325.81,
        "duration": 3.09,
        "text": "all right so fair enough fair enough but"
      },
      {
        "start": 327.79,
        "duration": 3.48,
        "text": "I want to come back to the number note"
      },
      {
        "start": 328.9,
        "duration": 4.98,
        "text": "right how does it impact contendere"
      },
      {
        "start": 331.27,
        "duration": 5.67,
        "text": "operations then if availability doesn't"
      },
      {
        "start": 333.88,
        "duration": 6.83,
        "text": "depend on it so in fact the number of"
      },
      {
        "start": 336.94,
        "duration": 6.42,
        "text": "machines in your cluster will determine"
      },
      {
        "start": 340.71,
        "duration": 5.68,
        "text": "how your workload will be will be"
      },
      {
        "start": 343.36,
        "duration": 5.309,
        "text": "distributed the spoilers Cassandra set"
      },
      {
        "start": 346.39,
        "duration": 4.68,
        "text": "up in production is usually three"
      },
      {
        "start": 348.669,
        "duration": 4.261,
        "text": "machines right and if you want immediate"
      },
      {
        "start": 351.07,
        "duration": 4.62,
        "text": "consistency using quorum"
      },
      {
        "start": 352.93,
        "duration": 6.03,
        "text": "you should have replication factor free"
      },
      {
        "start": 355.69,
        "duration": 7.47,
        "text": "but then it means that each of your node"
      },
      {
        "start": 358.96,
        "duration": 5.76,
        "text": "will manage 100% of your data and in"
      },
      {
        "start": 363.16,
        "duration": 5.28,
        "text": "fact there is no real data distribution"
      },
      {
        "start": 364.72,
        "duration": 5.4,
        "text": "in this case now let's say you have four"
      },
      {
        "start": 368.44,
        "duration": 4.32,
        "text": "nodes and you keep your replication"
      },
      {
        "start": 370.12,
        "duration": 6.81,
        "text": "factor to three each node will manage"
      },
      {
        "start": 372.76,
        "duration": 6.65,
        "text": "now three fourths of your data which is"
      },
      {
        "start": 376.93,
        "duration": 5.16,
        "text": "slightly better but not that great and"
      },
      {
        "start": 379.41,
        "duration": 4.9,
        "text": "having five knots mean that each node"
      },
      {
        "start": 382.09,
        "duration": 5.52,
        "text": "will manage now three fifths of your"
      },
      {
        "start": 384.31,
        "duration": 6.18,
        "text": "data right so as we can see the more"
      },
      {
        "start": 387.61,
        "duration": 5.22,
        "text": "machines you have and the better your"
      },
      {
        "start": 390.49,
        "duration": 4.83,
        "text": "workload will be spread out and of"
      },
      {
        "start": 392.83,
        "duration": 5.459,
        "text": "course we make the assumption that the"
      },
      {
        "start": 395.32,
        "duration": 4.8,
        "text": "token range are allocated evenly and"
      },
      {
        "start": 398.289,
        "duration": 4.441,
        "text": "there is no data secure"
      },
      {
        "start": 400.12,
        "duration": 4.049,
        "text": "so I want to get back to a point you"
      },
      {
        "start": 402.73,
        "duration": 3.93,
        "text": "made and I think this is really"
      },
      {
        "start": 404.169,
        "duration": 4.911,
        "text": "important for people who are conveyed at"
      },
      {
        "start": 406.66,
        "duration": 4.83,
        "text": "least not heavily experienced with using"
      },
      {
        "start": 409.08,
        "duration": 4.6,
        "text": "replication factor and what that really"
      },
      {
        "start": 411.49,
        "duration": 4.52,
        "text": "means you say if you want immediate"
      },
      {
        "start": 413.68,
        "duration": 8.61,
        "text": "consistent using quorum you should use"
      },
      {
        "start": 416.01,
        "duration": 8.26,
        "text": "RF equal 3yr f3o type thank you for"
      },
      {
        "start": 422.29,
        "duration": 5.22,
        "text": "asking this question it will allow me to"
      },
      {
        "start": 424.27,
        "duration": 4.83,
        "text": "highlight some classical Cavett's that's"
      },
      {
        "start": 427.51,
        "duration": 5.07,
        "text": "Cassandra beginners they get caught with"
      },
      {
        "start": 429.1,
        "duration": 5.58,
        "text": "so let's set aside replication factor"
      },
      {
        "start": 432.58,
        "duration": 4.41,
        "text": "one because it's nonsensical for"
      },
      {
        "start": 434.68,
        "duration": 5.69,
        "text": "production now we have the choice"
      },
      {
        "start": 436.99,
        "duration": 5.989,
        "text": "between replication factor two and three"
      },
      {
        "start": 440.37,
        "duration": 4.81,
        "text": "when you are using quorum for immediate"
      },
      {
        "start": 442.979,
        "duration": 5.561,
        "text": "consistency it means that you need a"
      },
      {
        "start": 445.18,
        "duration": 5.459,
        "text": "suite majority so if you have free copy"
      },
      {
        "start": 448.54,
        "duration": 5.73,
        "text": "of your data the sick majority is to"
      },
      {
        "start": 450.639,
        "duration": 6.061,
        "text": "write but now if you have two copies the"
      },
      {
        "start": 454.27,
        "duration": 6.0,
        "text": "street majority of two is two"
      },
      {
        "start": 456.7,
        "duration": 5.76,
        "text": "so in this specific case consistency"
      },
      {
        "start": 460.27,
        "duration": 5.519,
        "text": "quorum is equivalent to consistency"
      },
      {
        "start": 462.46,
        "duration": 6.54,
        "text": "level all and it means that you give up"
      },
      {
        "start": 465.789,
        "duration": 6.721,
        "text": "an high availability if one node goes"
      },
      {
        "start": 469.0,
        "duration": 6.419,
        "text": "down interestingly enough I have seen"
      },
      {
        "start": 472.51,
        "duration": 5.85,
        "text": "some experienced people they did crazy"
      },
      {
        "start": 475.419,
        "duration": 5.22,
        "text": "things so they use replication factor"
      },
      {
        "start": 478.36,
        "duration": 4.739,
        "text": "two of course they are writing at"
      },
      {
        "start": 480.639,
        "duration": 5.101,
        "text": "consistency level one to have high"
      },
      {
        "start": 483.099,
        "duration": 5.161,
        "text": "availability and they are also reading"
      },
      {
        "start": 485.74,
        "duration": 4.62,
        "text": "with consistency level one but you know"
      },
      {
        "start": 488.26,
        "duration": 4.35,
        "text": "that you can set there is a parameter"
      },
      {
        "start": 490.36,
        "duration": 4.71,
        "text": "there you can set the repair chance"
      },
      {
        "start": 492.61,
        "duration": 4.65,
        "text": "which is a property of your table and"
      },
      {
        "start": 495.07,
        "duration": 6.21,
        "text": "those people they are setting really a"
      },
      {
        "start": 497.26,
        "duration": 7.11,
        "text": "chance to a value very close to one so"
      },
      {
        "start": 501.28,
        "duration": 5.13,
        "text": "that it is pretty much equivalent to"
      },
      {
        "start": 504.37,
        "duration": 4.919,
        "text": "read it through to read your data at"
      },
      {
        "start": 506.41,
        "duration": 7.47,
        "text": "consistency level on and if you lose one"
      },
      {
        "start": 509.289,
        "duration": 6.901,
        "text": "node during a in production the read"
      },
      {
        "start": 513.88,
        "duration": 4.05,
        "text": "repair will still succeed because it is"
      },
      {
        "start": 516.19,
        "duration": 5.67,
        "text": "not a hard requirement to have two"
      },
      {
        "start": 517.93,
        "duration": 6.98,
        "text": "copies of data so it is a really exotic"
      },
      {
        "start": 521.86,
        "duration": 6.93,
        "text": "I will say exotic usage of Cassandra"
      },
      {
        "start": 524.91,
        "duration": 5.32,
        "text": "okay so would that be the same thing or"
      },
      {
        "start": 528.79,
        "duration": 4.32,
        "text": "you could you get the equivalent"
      },
      {
        "start": 530.23,
        "duration": 5.4,
        "text": "behavior if you use"
      },
      {
        "start": 533.11,
        "duration": 5.63,
        "text": "the consistency level all and then the"
      },
      {
        "start": 535.63,
        "duration": 7.829,
        "text": "downgrading consistency retry policy on"
      },
      {
        "start": 538.74,
        "duration": 6.81,
        "text": "the dir side pretty much in fact but to"
      },
      {
        "start": 543.459,
        "duration": 5.221,
        "text": "finish I would I would not recommend"
      },
      {
        "start": 545.55,
        "duration": 6.34,
        "text": "people using this trick because you know"
      },
      {
        "start": 548.68,
        "duration": 5.909,
        "text": "having the application factor 3 is much"
      },
      {
        "start": 551.89,
        "duration": 5.67,
        "text": "more safer you you don't you do not need"
      },
      {
        "start": 554.589,
        "duration": 4.831,
        "text": "to choose your mind and in fact the"
      },
      {
        "start": 557.56,
        "duration": 5.04,
        "text": "difference between replication factor 2"
      },
      {
        "start": 559.42,
        "duration": 6.3,
        "text": "& 3 is not that much expensive you are"
      },
      {
        "start": 562.6,
        "duration": 4.29,
        "text": "just paying for one extra copy that's"
      },
      {
        "start": 565.72,
        "duration": 3.359,
        "text": "not a big deal really"
      },
      {
        "start": 566.89,
        "duration": 4.11,
        "text": "yeah and that's probably especially true"
      },
      {
        "start": 569.079,
        "duration": 4.351,
        "text": "when you have more than one data center"
      },
      {
        "start": 571.0,
        "duration": 3.839,
        "text": "so you're already you know duplicating"
      },
      {
        "start": 573.43,
        "duration": 3.95,
        "text": "your data so more than one copy really"
      },
      {
        "start": 574.839,
        "duration": 7.021,
        "text": "isn't that big of a deal right yeah and"
      },
      {
        "start": 577.38,
        "duration": 6.16,
        "text": "talking about multi data center again"
      },
      {
        "start": 581.86,
        "duration": 4.65,
        "text": "Cassandra beginners they get always"
      },
      {
        "start": 583.54,
        "duration": 7.08,
        "text": "surprised during my presentation when I"
      },
      {
        "start": 586.51,
        "duration": 8.009,
        "text": "told them that 100 of % of their data is"
      },
      {
        "start": 590.62,
        "duration": 6.24,
        "text": "replicated in each data center it did"
      },
      {
        "start": 594.519,
        "duration": 4.621,
        "text": "even if they belong to the same cluster"
      },
      {
        "start": 596.86,
        "duration": 5.669,
        "text": "each data center has its own replication"
      },
      {
        "start": 599.14,
        "duration": 5.52,
        "text": "factor and it makes things a little bit"
      },
      {
        "start": 602.529,
        "duration": 4.741,
        "text": "more complicated to result to reason"
      },
      {
        "start": 604.66,
        "duration": 5.6,
        "text": "with consistency level so suppose you"
      },
      {
        "start": 607.27,
        "duration": 5.85,
        "text": "have two data center right c1 + DC - in"
      },
      {
        "start": 610.26,
        "duration": 6.1,
        "text": "DC one you set replication factor to"
      },
      {
        "start": 613.12,
        "duration": 6.51,
        "text": "five and in DC - you set replication"
      },
      {
        "start": 616.36,
        "duration": 6.419,
        "text": "factor to 3 or 5 here and 3 here now on"
      },
      {
        "start": 619.63,
        "duration": 7.41,
        "text": "the cluster level you have 5 + 3 equals"
      },
      {
        "start": 622.779,
        "duration": 7.62,
        "text": "to 8 copies of your data in total plus"
      },
      {
        "start": 627.04,
        "duration": 7.26,
        "text": "the wide a request which is using"
      },
      {
        "start": 630.399,
        "duration": 9.271,
        "text": "consistency level quorum now we can put"
      },
      {
        "start": 634.3,
        "duration": 7.89,
        "text": "a straight majority of the total number"
      },
      {
        "start": 639.67,
        "duration": 7.14,
        "text": "of copies so it means that quorum"
      },
      {
        "start": 642.19,
        "duration": 7.2,
        "text": "requires 5 copies out of 8 and if your"
      },
      {
        "start": 646.81,
        "duration": 5.639,
        "text": "client is connecting to data center 1"
      },
      {
        "start": 649.39,
        "duration": 6.5,
        "text": "which has 5 copy it is likely that all"
      },
      {
        "start": 652.449,
        "duration": 7.89,
        "text": "the 5 copies in this DC will reply back"
      },
      {
        "start": 655.89,
        "duration": 7.03,
        "text": "faster than the other copies in DC - but"
      },
      {
        "start": 660.339,
        "duration": 5.37,
        "text": "if your client is connecting to DC -"
      },
      {
        "start": 662.92,
        "duration": 3.87,
        "text": "which has only 3 copies"
      },
      {
        "start": 665.709,
        "duration": 3.091,
        "text": "you're pretty sure"
      },
      {
        "start": 666.79,
        "duration": 5.12,
        "text": "every time you will require two extra"
      },
      {
        "start": 668.8,
        "duration": 7.52,
        "text": "copy from the Odyssey and in this case"
      },
      {
        "start": 671.91,
        "duration": 8.26,
        "text": "you have a huge impact on your latency"
      },
      {
        "start": 676.32,
        "duration": 7.96,
        "text": "another tricky consistency level is each"
      },
      {
        "start": 680.17,
        "duration": 7.08,
        "text": "forum so each column means that for each"
      },
      {
        "start": 684.28,
        "duration": 3.84,
        "text": "request we require a suite majority of"
      },
      {
        "start": 687.25,
        "duration": 3.66,
        "text": "Tripucka"
      },
      {
        "start": 688.12,
        "duration": 7.05,
        "text": "in HTC to reply right so with our"
      },
      {
        "start": 690.91,
        "duration": 7.5,
        "text": "example in DC one we have five copies of"
      },
      {
        "start": 695.17,
        "duration": 6.09,
        "text": "data will go at three copies our five"
      },
      {
        "start": 698.41,
        "duration": 4.77,
        "text": "should reply to your request and in DC"
      },
      {
        "start": 701.26,
        "duration": 4.77,
        "text": "to where we have three copies we require"
      },
      {
        "start": 703.18,
        "duration": 5.37,
        "text": "that two of them are replying to your"
      },
      {
        "start": 706.03,
        "duration": 6.3,
        "text": "request so when you are using each"
      },
      {
        "start": 708.55,
        "duration": 7.05,
        "text": "column you will give up for sure on high"
      },
      {
        "start": 712.33,
        "duration": 6.48,
        "text": "availability whenever a whole data"
      },
      {
        "start": 715.6,
        "duration": 6.87,
        "text": "center goes down but the advantage of"
      },
      {
        "start": 718.81,
        "duration": 7.38,
        "text": "this consistency level is that you are"
      },
      {
        "start": 722.47,
        "duration": 7.44,
        "text": "guaranteed to have your data consistent"
      },
      {
        "start": 726.19,
        "duration": 6.36,
        "text": "across data center so this is the price"
      },
      {
        "start": 729.91,
        "duration": 4.92,
        "text": "to pay to have consistency across data"
      },
      {
        "start": 732.55,
        "duration": 5.34,
        "text": "center warranty okay"
      },
      {
        "start": 734.83,
        "duration": 5.19,
        "text": "so what if I want strong B across my"
      },
      {
        "start": 737.89,
        "duration": 7.32,
        "text": "data centers as well being able to"
      },
      {
        "start": 740.02,
        "duration": 7.65,
        "text": "survive the failure one of them um this"
      },
      {
        "start": 745.21,
        "duration": 5.04,
        "text": "is a very thing very interesting"
      },
      {
        "start": 747.67,
        "duration": 6.09,
        "text": "question so I have been challenged"
      },
      {
        "start": 750.25,
        "duration": 7.92,
        "text": "recently with some user and they want"
      },
      {
        "start": 753.76,
        "duration": 6.99,
        "text": "exactly this requirement so let's start"
      },
      {
        "start": 758.17,
        "duration": 5.76,
        "text": "from the beginning in order to have some"
      },
      {
        "start": 760.75,
        "duration": 6.42,
        "text": "consistency across data center we cannot"
      },
      {
        "start": 763.93,
        "duration": 6.12,
        "text": "use local one consistency level or local"
      },
      {
        "start": 767.17,
        "duration": 6.54,
        "text": "quorum of course so we we move them out"
      },
      {
        "start": 770.05,
        "duration": 5.75,
        "text": "of the equation if we use each column as"
      },
      {
        "start": 773.71,
        "duration": 5.88,
        "text": "I said before we lose high availability"
      },
      {
        "start": 775.8,
        "duration": 5.92,
        "text": "in case of one data center failure so"
      },
      {
        "start": 779.59,
        "duration": 6.0,
        "text": "now what do we have left we have on the"
      },
      {
        "start": 781.72,
        "duration": 6.36,
        "text": "quorum less as an alternative and now"
      },
      {
        "start": 785.59,
        "duration": 5.67,
        "text": "the trick is how to choose the correct"
      },
      {
        "start": 788.08,
        "duration": 5.61,
        "text": "number of data centers and the correct"
      },
      {
        "start": 791.26,
        "duration": 5.58,
        "text": "replication factor in each of them to"
      },
      {
        "start": 793.69,
        "duration": 5.46,
        "text": "fulfill the requirement so let's stop if"
      },
      {
        "start": 796.84,
        "duration": 6.81,
        "text": "we go for two data center"
      },
      {
        "start": 799.15,
        "duration": 7.58,
        "text": "by example three copies in datacenter"
      },
      {
        "start": 803.65,
        "duration": 6.15,
        "text": "one and Twitter copies in datacenter -"
      },
      {
        "start": 806.73,
        "duration": 8.2,
        "text": "so now we have in total six copy of data"
      },
      {
        "start": 809.8,
        "duration": 10.05,
        "text": "and a global quorum on six require four"
      },
      {
        "start": 814.93,
        "duration": 9.69,
        "text": "write Sigma jority of six is four so it"
      },
      {
        "start": 819.85,
        "duration": 8.04,
        "text": "means that whenever 1dc goes down your"
      },
      {
        "start": 824.62,
        "duration": 6.45,
        "text": "quorum cannot be achieved right because"
      },
      {
        "start": 827.89,
        "duration": 7.74,
        "text": "you will always have a one copy of data"
      },
      {
        "start": 831.07,
        "duration": 7.53,
        "text": "missing if we choose replication factor"
      },
      {
        "start": 835.63,
        "duration": 6.899,
        "text": "of five for DC one and reflect"
      },
      {
        "start": 838.6,
        "duration": 7.64,
        "text": "replication factor three - DC DC - the"
      },
      {
        "start": 842.529,
        "duration": 7.381,
        "text": "quorum of five plus three equal eight"
      },
      {
        "start": 846.24,
        "duration": 6.28,
        "text": "requires five replicas so if this C one"
      },
      {
        "start": 849.91,
        "duration": 6.33,
        "text": "goes down again we are basically back to"
      },
      {
        "start": 852.52,
        "duration": 6.93,
        "text": "the previous situation now if we have"
      },
      {
        "start": 856.24,
        "duration": 5.039,
        "text": "three datacenter it's become more"
      },
      {
        "start": 859.45,
        "duration": 3.93,
        "text": "interesting three data center"
      },
      {
        "start": 861.279,
        "duration": 6.901,
        "text": "replication factor - in each of them so"
      },
      {
        "start": 863.38,
        "duration": 6.84,
        "text": "two plus two plus two equal to six to"
      },
      {
        "start": 868.18,
        "duration": 3.87,
        "text": "have a global quorum out of six copies"
      },
      {
        "start": 870.22,
        "duration": 6.45,
        "text": "of data you require four of them to be"
      },
      {
        "start": 872.05,
        "duration": 7.14,
        "text": "online whenever one PC goes down you"
      },
      {
        "start": 876.67,
        "duration": 4.95,
        "text": "lose two copies but you still have four"
      },
      {
        "start": 879.19,
        "duration": 5.13,
        "text": "other copies across two other data"
      },
      {
        "start": 881.62,
        "duration": 3.089,
        "text": "center so in this this is the correct"
      },
      {
        "start": 884.32,
        "duration": 3.45,
        "text": "answer"
      },
      {
        "start": 884.709,
        "duration": 6.121,
        "text": "you have three data center in each of"
      },
      {
        "start": 887.77,
        "duration": 5.04,
        "text": "them you have two copies and in this"
      },
      {
        "start": 890.83,
        "duration": 4.83,
        "text": "scenario you can use column consistency"
      },
      {
        "start": 892.81,
        "duration": 5.1,
        "text": "level and you can afford to lose one"
      },
      {
        "start": 895.66,
        "duration": 6.299,
        "text": "data center completely and still have"
      },
      {
        "start": 897.91,
        "duration": 5.7,
        "text": "high availability so let's follow up a"
      },
      {
        "start": 901.959,
        "duration": 4.561,
        "text": "little bit on high availability what are"
      },
      {
        "start": 903.61,
        "duration": 5.46,
        "text": "the consequences of losing multiple"
      },
      {
        "start": 906.52,
        "duration": 4.62,
        "text": "nodes so we know you said this already"
      },
      {
        "start": 909.07,
        "duration": 4.56,
        "text": "that with an RF of three and a"
      },
      {
        "start": 911.14,
        "duration": 5.699,
        "text": "consistency level of one we can afford"
      },
      {
        "start": 913.63,
        "duration": 5.7,
        "text": "to lose two nodes simultaneously and"
      },
      {
        "start": 916.839,
        "duration": 3.75,
        "text": "still be online but it's not guaranteed"
      },
      {
        "start": 919.33,
        "duration": 4.14,
        "text": "in all cases is there a particular"
      },
      {
        "start": 920.589,
        "duration": 6.691,
        "text": "scenario where maybe Bob distribution of"
      },
      {
        "start": 923.47,
        "duration": 6.54,
        "text": "replicas could lead to data loss or you"
      },
      {
        "start": 927.28,
        "duration": 4.98,
        "text": "know is there an edge case here so no in"
      },
      {
        "start": 930.01,
        "duration": 2.879,
        "text": "fact just sort of try to replicate each"
      },
      {
        "start": 932.26,
        "duration": 3.78,
        "text": "small"
      },
      {
        "start": 932.889,
        "duration": 6.031,
        "text": "range of tokens on different notes so"
      },
      {
        "start": 936.04,
        "duration": 5.31,
        "text": "losing all three replicas when you have"
      },
      {
        "start": 938.92,
        "duration": 6.449,
        "text": "two physical notes down is not possible"
      },
      {
        "start": 941.35,
        "duration": 6.479,
        "text": "there is still a case where it can"
      },
      {
        "start": 945.369,
        "duration": 5.791,
        "text": "happen it is when you host you are"
      },
      {
        "start": 947.829,
        "duration": 5.94,
        "text": "hosting - Cassandra processes on the"
      },
      {
        "start": 951.16,
        "duration": 5.839,
        "text": "same physical machine so in this case"
      },
      {
        "start": 953.769,
        "duration": 6.63,
        "text": "all the grantees of course are off"
      },
      {
        "start": 956.999,
        "duration": 5.02,
        "text": "that's why in fact we have a feature in"
      },
      {
        "start": 960.399,
        "duration": 2.391,
        "text": "data section for Christ we call multi"
      },
      {
        "start": 962.019,
        "duration": 3.78,
        "text": "and Suns"
      },
      {
        "start": 962.79,
        "duration": 4.959,
        "text": "it is useful when in some you know big"
      },
      {
        "start": 965.799,
        "duration": 5.82,
        "text": "companies you can only order big boxes"
      },
      {
        "start": 967.749,
        "duration": 7.68,
        "text": "and buy big boxes I mean hundreds of CPU"
      },
      {
        "start": 971.619,
        "duration": 6.63,
        "text": "cores hundreds of gigabytes of RAM and a"
      },
      {
        "start": 975.429,
        "duration": 5.731,
        "text": "dozen of hard drives so in this case not"
      },
      {
        "start": 978.249,
        "duration": 5.041,
        "text": "to waste all the resources you can host"
      },
      {
        "start": 981.16,
        "duration": 5.07,
        "text": "multiple instances of Cassandra on the"
      },
      {
        "start": 983.29,
        "duration": 6.769,
        "text": "same box but with DSM in the instance we"
      },
      {
        "start": 986.23,
        "duration": 7.859,
        "text": "try our best to dispatch each replica of"
      },
      {
        "start": 990.059,
        "duration": 6.81,
        "text": "the Cassandra not on different physical"
      },
      {
        "start": 994.089,
        "duration": 6.33,
        "text": "boxes using drug awareness and so on"
      },
      {
        "start": 996.869,
        "duration": 5.65,
        "text": "however there is no magic you should"
      },
      {
        "start": 1000.419,
        "duration": 4.2,
        "text": "always remember that if you have for"
      },
      {
        "start": 1002.519,
        "duration": 5.28,
        "text": "example replication factor of three and"
      },
      {
        "start": 1004.619,
        "duration": 5.22,
        "text": "only two boxes losing one box we will"
      },
      {
        "start": 1007.799,
        "duration": 4.73,
        "text": "surely lead to losing two replicas out"
      },
      {
        "start": 1009.839,
        "duration": 7.74,
        "text": "of three for some token wrenches right"
      },
      {
        "start": 1012.529,
        "duration": 7.36,
        "text": "no magic but no magic do you have any"
      },
      {
        "start": 1017.579,
        "duration": 5.581,
        "text": "you'd like your trademark term dude"
      },
      {
        "start": 1019.889,
        "duration": 4.861,
        "text": "there is no magical hassel okay so"
      },
      {
        "start": 1023.16,
        "duration": 3.149,
        "text": "that's really interesting when you're"
      },
      {
        "start": 1024.75,
        "duration": 4.74,
        "text": "talking about using some of these big"
      },
      {
        "start": 1026.309,
        "duration": 6.811,
        "text": "box machines and then the interaction of"
      },
      {
        "start": 1029.49,
        "duration": 5.88,
        "text": "that with racks so how does this work"
      },
      {
        "start": 1033.12,
        "duration": 5.669,
        "text": "with replicas distribution when you have"
      },
      {
        "start": 1035.37,
        "duration": 6.719,
        "text": "a multi data center set up so as I said"
      },
      {
        "start": 1038.789,
        "duration": 5.941,
        "text": "earlier 100 of 100 percent of your data"
      },
      {
        "start": 1042.089,
        "duration": 5.521,
        "text": "set is replicated inside each data"
      },
      {
        "start": 1044.73,
        "duration": 5.309,
        "text": "center so losing a whole DC is not a"
      },
      {
        "start": 1047.61,
        "duration": 5.52,
        "text": "problem as long as you have at least one"
      },
      {
        "start": 1050.039,
        "duration": 7.531,
        "text": "DC surviving now there is a subtour"
      },
      {
        "start": 1053.13,
        "duration": 7.62,
        "text": "detail that most users ignore which is"
      },
      {
        "start": 1057.57,
        "duration": 6.8,
        "text": "also each data center manages its own"
      },
      {
        "start": 1060.75,
        "duration": 5.76,
        "text": "ranges of tokens each token value is"
      },
      {
        "start": 1064.37,
        "duration": 4.63,
        "text": "cluster wider"
      },
      {
        "start": 1066.51,
        "duration": 3.9,
        "text": "means that if you are using six seconds"
      },
      {
        "start": 1069.0,
        "duration": 4.83,
        "text": "like in the old days"
      },
      {
        "start": 1070.41,
        "duration": 6.87,
        "text": "the token value on each note no matter"
      },
      {
        "start": 1073.83,
        "duration": 6.26,
        "text": "in which DC it is should be different so"
      },
      {
        "start": 1077.28,
        "duration": 6.84,
        "text": "we can see on internet some blog posts"
      },
      {
        "start": 1080.09,
        "duration": 6.55,
        "text": "are people giving some rules how to"
      },
      {
        "start": 1084.12,
        "duration": 4.76,
        "text": "choose the correct and range so some"
      },
      {
        "start": 1086.64,
        "duration": 4.98,
        "text": "folks they are just incrementing by one"
      },
      {
        "start": 1088.88,
        "duration": 7.86,
        "text": "when you change when you switch from one"
      },
      {
        "start": 1091.62,
        "duration": 9.96,
        "text": "DC to another DC and that's the idea"
      },
      {
        "start": 1096.74,
        "duration": 7.66,
        "text": "okay everyone take a second just digest"
      },
      {
        "start": 1101.58,
        "duration": 5.91,
        "text": "that for a little bit that was a lot of"
      },
      {
        "start": 1104.4,
        "duration": 4.53,
        "text": "really intense information so and I"
      },
      {
        "start": 1107.49,
        "duration": 3.75,
        "text": "appreciate that I mean you are"
      },
      {
        "start": 1108.93,
        "duration": 5.19,
        "text": "definitely an expert in this field and"
      },
      {
        "start": 1111.24,
        "duration": 5.7,
        "text": "if you if you are listening and"
      },
      {
        "start": 1114.12,
        "duration": 5.64,
        "text": "understanding what do we hi just told"
      },
      {
        "start": 1116.94,
        "duration": 5.55,
        "text": "you your life is going to be a way a lot"
      },
      {
        "start": 1119.76,
        "duration": 5.43,
        "text": "better but let's lighten it up a little"
      },
      {
        "start": 1122.49,
        "duration": 5.91,
        "text": "bit I mean I think this is let's get"
      },
      {
        "start": 1125.19,
        "duration": 5.1,
        "text": "into some fun stuff here I want to like"
      },
      {
        "start": 1128.4,
        "duration": 3.81,
        "text": "change off from you know some more the"
      },
      {
        "start": 1130.29,
        "duration": 4.23,
        "text": "more technical deep dive details here"
      },
      {
        "start": 1132.21,
        "duration": 6.15,
        "text": "just some funny things that you've seen"
      },
      {
        "start": 1134.52,
        "duration": 5.85,
        "text": "out in the field what without naming"
      },
      {
        "start": 1138.36,
        "duration": 3.63,
        "text": "names we want to protect the innocent"
      },
      {
        "start": 1140.37,
        "duration": 5.28,
        "text": "what are some of the funny things that"
      },
      {
        "start": 1141.99,
        "duration": 7.95,
        "text": "you've seen in the field oh so very"
      },
      {
        "start": 1145.65,
        "duration": 8.16,
        "text": "classical story some people call me hey"
      },
      {
        "start": 1149.94,
        "duration": 8.16,
        "text": "we have a performance issue in"
      },
      {
        "start": 1153.81,
        "duration": 7.77,
        "text": "production okay but the weird thing is"
      },
      {
        "start": 1158.1,
        "duration": 6.09,
        "text": "we we have the same environment from"
      },
      {
        "start": 1161.58,
        "duration": 5.16,
        "text": "pre-production and production and we"
      },
      {
        "start": 1164.19,
        "duration": 5.04,
        "text": "didn't face those issue so I asked them"
      },
      {
        "start": 1166.74,
        "duration": 5.55,
        "text": "did you have the same data set or the"
      },
      {
        "start": 1169.23,
        "duration": 5.46,
        "text": "same workload when you test it your"
      },
      {
        "start": 1172.29,
        "duration": 4.98,
        "text": "pre-production and they said yes yes of"
      },
      {
        "start": 1174.69,
        "duration": 6.06,
        "text": "course we we try to replicate the same"
      },
      {
        "start": 1177.27,
        "duration": 6.84,
        "text": "workload at the production and so what"
      },
      {
        "start": 1180.75,
        "duration": 7.95,
        "text": "kind of CPU do you have okay how many"
      },
      {
        "start": 1184.11,
        "duration": 11.55,
        "text": "how much gram do you have okay what is"
      },
      {
        "start": 1188.7,
        "duration": 8.87,
        "text": "your disk oh we are using a SAN got"
      },
      {
        "start": 1195.66,
        "duration": 3.65,
        "text": "worse it got worse"
      },
      {
        "start": 1197.57,
        "duration": 6.27,
        "text": "we're all like oh that's the punchline"
      },
      {
        "start": 1199.31,
        "duration": 8.27,
        "text": "oh no it's not the best part a story so"
      },
      {
        "start": 1203.84,
        "duration": 7.29,
        "text": "those guys say but you know what we were"
      },
      {
        "start": 1207.58,
        "duration": 6.73,
        "text": "benchmarking a lot of time and the"
      },
      {
        "start": 1211.13,
        "duration": 6.51,
        "text": "performance was great so yeah there's no"
      },
      {
        "start": 1214.31,
        "duration": 7.56,
        "text": "problem I did a problem with the Sun is"
      },
      {
        "start": 1217.64,
        "duration": 5.43,
        "text": "you can benchmark 1000 times it doesn't"
      },
      {
        "start": 1221.87,
        "duration": 4.17,
        "text": "mean anything"
      },
      {
        "start": 1223.07,
        "duration": 5.82,
        "text": "why because you never know who is using"
      },
      {
        "start": 1226.04,
        "duration": 6.48,
        "text": "your fan you can be just lucky during"
      },
      {
        "start": 1228.89,
        "duration": 5.52,
        "text": "one month doing some 1000 benchmark and"
      },
      {
        "start": 1232.52,
        "duration": 5.25,
        "text": "everything is fine and then when you get"
      },
      {
        "start": 1234.41,
        "duration": 5.88,
        "text": "to production some some project they are"
      },
      {
        "start": 1237.77,
        "duration": 4.77,
        "text": "just loading a bunch of data using the"
      },
      {
        "start": 1240.29,
        "duration": 5.37,
        "text": "same Sun and then it will kill your"
      },
      {
        "start": 1242.54,
        "duration": 6.21,
        "text": "bandwidth with the disk does that what"
      },
      {
        "start": 1245.66,
        "duration": 7.65,
        "text": "happened yeah okay and I said okay okay"
      },
      {
        "start": 1248.75,
        "duration": 7.95,
        "text": "we understand now in fact having"
      },
      {
        "start": 1253.31,
        "duration": 6.75,
        "text": "benchmark having good benchmark results"
      },
      {
        "start": 1256.7,
        "duration": 6.39,
        "text": "understand it's not a proof at all at"
      },
      {
        "start": 1260.06,
        "duration": 4.65,
        "text": "all actually because it's a good way lie"
      },
      {
        "start": 1263.09,
        "duration": 4.23,
        "text": "to everyone and saying are saying as"
      },
      {
        "start": 1264.71,
        "duration": 4.11,
        "text": "awesome and what if it's not a shared"
      },
      {
        "start": 1267.32,
        "duration": 3.3,
        "text": "resource like the case that you"
      },
      {
        "start": 1268.82,
        "duration": 5.19,
        "text": "mentioned is it still a bad idea"
      },
      {
        "start": 1270.62,
        "duration": 5.91,
        "text": "I mean come on there's zero times that"
      },
      {
        "start": 1274.01,
        "duration": 6.06,
        "text": "Santa is the right answer okay thanks"
      },
      {
        "start": 1276.53,
        "duration": 4.62,
        "text": "Sochi yeah very good"
      },
      {
        "start": 1280.07,
        "duration": 3.92,
        "text": "it's a book it's all about"
      },
      {
        "start": 1281.15,
        "duration": 6.99,
        "text": "predictability if you cannot predict"
      },
      {
        "start": 1283.99,
        "duration": 6.88,
        "text": "your bandwidth in fact you can cover you"
      },
      {
        "start": 1288.14,
        "duration": 5.61,
        "text": "can not control your prediction period"
      },
      {
        "start": 1290.87,
        "duration": 5.61,
        "text": "yeah and then I think that that's the"
      },
      {
        "start": 1293.75,
        "duration": 4.26,
        "text": "key is and I think that's were a lot of"
      },
      {
        "start": 1296.48,
        "duration": 3.15,
        "text": "new users stumble into and that's why"
      },
      {
        "start": 1298.01,
        "duration": 4.26,
        "text": "you mentioning is because you talk to a"
      },
      {
        "start": 1299.63,
        "duration": 4.5,
        "text": "lot of new users is these are just"
      },
      {
        "start": 1302.27,
        "duration": 5.28,
        "text": "things you learn to experience and"
      },
      {
        "start": 1304.13,
        "duration": 6.72,
        "text": "hopefully you out there are listening"
      },
      {
        "start": 1307.55,
        "duration": 4.74,
        "text": "please listen please there is there's"
      },
      {
        "start": 1310.85,
        "duration": 3.03,
        "text": "good body of evidence"
      },
      {
        "start": 1312.29,
        "duration": 3.27,
        "text": "don't don't think that you're special"
      },
      {
        "start": 1313.88,
        "duration": 2.97,
        "text": "that's one of my favorites oh everyone"
      },
      {
        "start": 1315.56,
        "duration": 3.84,
        "text": "else fail because they're not good at"
      },
      {
        "start": 1316.85,
        "duration": 3.62,
        "text": "this we are how many times have you"
      },
      {
        "start": 1319.4,
        "duration": 5.55,
        "text": "heard that we I"
      },
      {
        "start": 1320.47,
        "duration": 6.67,
        "text": "oh boy yeah all right I think we've"
      },
      {
        "start": 1324.95,
        "duration": 5.13,
        "text": "consumed enough Internet bandwidth for"
      },
      {
        "start": 1327.14,
        "duration": 4.1,
        "text": "right now do we hide thank you very much"
      },
      {
        "start": 1330.08,
        "duration": 5.9,
        "text": "for joining us today"
      },
      {
        "start": 1331.24,
        "duration": 6.24,
        "text": "welcome acid waste and we hope to see"
      },
      {
        "start": 1335.98,
        "duration": 4.199,
        "text": "you again soon you'll be I'm sure you'd"
      },
      {
        "start": 1337.48,
        "duration": 4.579,
        "text": "be a host on this as well so thank you"
      },
      {
        "start": 1340.179,
        "duration": 5.551,
        "text": "everyone for joining us today thank you"
      },
      {
        "start": 1342.059,
        "duration": 5.831,
        "text": "thank you thank you for joining us again"
      },
      {
        "start": 1345.73,
        "duration": 3.929,
        "text": "for the distributed data show we love"
      },
      {
        "start": 1347.89,
        "duration": 3.779,
        "text": "your feedback so go to the distributed"
      },
      {
        "start": 1349.659,
        "duration": 3.841,
        "text": "data show page on data Stax Academy and"
      },
      {
        "start": 1351.669,
        "duration": 3.331,
        "text": "tell us what you think you can also find"
      },
      {
        "start": 1353.5,
        "duration": 4.38,
        "text": "us on the data Stax Academy YouTube"
      },
      {
        "start": 1355.0,
        "duration": 4.89,
        "text": "channel or find our podcast on itunes"
      },
      {
        "start": 1357.88,
        "duration": 4.5,
        "text": "google play or wherever you get great"
      },
      {
        "start": 1359.89,
        "duration": 3.93,
        "text": "podcast while you're there make sure and"
      },
      {
        "start": 1362.38,
        "duration": 3.58,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 1363.82,
        "duration": 5.249,
        "text": "episode"
      },
      {
        "start": 1365.96,
        "duration": 3.109,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:24:43.343682+00:00"
}