{
  "video_id": "w_PbuW6MytA",
  "title": "DS320.06 Spark Essentials: Resilient Distributed Datasets | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.06 Spark Essentials: Resilient Distributed Datasets\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:25:51Z",
  "thumbnail": "https://i.ytimg.com/vi/w_PbuW6MytA/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=w_PbuW6MytA",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] to understand spark you have to have a pretty deep understanding of resilient distributed data sets or rdds we took a quick look at them in the word count example but i'd like to dive in a little harder now and look at the api look at some of their properties and really try to get an understanding of what they are now spark's not a database spark's a distributed computing framework so it doesn't have a data model as such in the way that say cassandra does or a relational database does but it does have a data abstraction rdds are that abstraction so it's really important that we talk through this and this become a thing that you're pretty confident with now the very words resilient distributed and data set require a little bit of explanation it is of course a data set it's a collection of data items of some kind it's distributed meaning you've got too much work to do to do it on one computer it's also resilient so the cluster is able to maintain pieces of rdds around the cluster recompute them as needed as a core function importantly rdds are immutable so you can't really change an rdd you can transform it which means i'm going to take my old rdd and make a new rdd that's a function of the old one also rdds are ideally in memory the idea is to try to get computation to take place in memory as much as possible and never go to disk rdds are of course typed you're looking here at a key value pair rdd which is a pretty important type of rdd and that so-called pair rdd has types we need to know what the type of the key is and what the type of the value is here this looks like the ages of people so the names of those people those will be strings and the ages those will be integers here's an example of the partitioning of an rdd the table on the left is kind of how we think about that we think of all the data we've got this abstraction that lets us consider that the rdd is this one unified thing in reality of course it's spread all over a bunch of computers and there's all kinds of difficult work that the framework is doing to make that possible based on some partitioning function the records of the rdd are broken up and distributed around the cluster and because spark remembers the lineage of the data or it keeps this this graph of the computational steps we're able to tolerate the loss of some part of our data if you look at the slide the top node had alice and tom originally and the middle node had sarah bob ron and bob well that middle node died and so its records got distributed to the other two nodes it was effectively removed from the cluster and that work was given to other nodes rdds are immutable this is key because spark is a distributed framework and adopts paradigms from functional programming anything you can do to make data immutable is going to simplify everything else that the framework does and that our development does with it so rdds are read only things we can create them we can effectively destroy them or allow them to kind of pass out of existence we can't change them in place all we can do is take an rdd and transform it into a new one you see here in the slide that we're doing just that we have this big rdd and then i'm going to filter it by age and i say i have this new rdd and i want that only to be people who are 21 or over and i've done that that that new rdd that i've created on the right uh has that filter applied but i have not done anything to alter the source rdd because i can't they're immutable and that's a good thing to the greatest extent possible rdds are processed in memory now they don't have to be spark has provisions to put data onto disk in various ways uh and bring it back into memory but we would like to partition data and arrange our data sets such that it's able to do its work in memory that's always going to be a win when we look at optimization we'll talk about some techniques for making that happen",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.48,
        "duration": 2.32,
        "text": "to understand spark you have to have a"
      },
      {
        "start": 8.08,
        "duration": 3.2,
        "text": "pretty deep"
      },
      {
        "start": 8.8,
        "duration": 4.24,
        "text": "understanding of resilient distributed"
      },
      {
        "start": 11.28,
        "duration": 3.359,
        "text": "data sets or rdds"
      },
      {
        "start": 13.04,
        "duration": 3.12,
        "text": "we took a quick look at them in the word"
      },
      {
        "start": 14.639,
        "duration": 2.72,
        "text": "count example but i'd like to dive in a"
      },
      {
        "start": 16.16,
        "duration": 3.119,
        "text": "little harder now"
      },
      {
        "start": 17.359,
        "duration": 3.601,
        "text": "and look at the api look at some of"
      },
      {
        "start": 19.279,
        "duration": 3.281,
        "text": "their properties and really try to get"
      },
      {
        "start": 20.96,
        "duration": 3.04,
        "text": "an understanding of what they are"
      },
      {
        "start": 22.56,
        "duration": 2.879,
        "text": "now spark's not a database spark's a"
      },
      {
        "start": 24.0,
        "duration": 3.279,
        "text": "distributed computing framework so it"
      },
      {
        "start": 25.439,
        "duration": 4.24,
        "text": "doesn't have a data model as such"
      },
      {
        "start": 27.279,
        "duration": 3.84,
        "text": "in the way that say cassandra does or a"
      },
      {
        "start": 29.679,
        "duration": 4.56,
        "text": "relational database does"
      },
      {
        "start": 31.119,
        "duration": 4.801,
        "text": "but it does have a data abstraction rdds"
      },
      {
        "start": 34.239,
        "duration": 3.201,
        "text": "are that abstraction so it's really"
      },
      {
        "start": 35.92,
        "duration": 2.72,
        "text": "important that we talk through this"
      },
      {
        "start": 37.44,
        "duration": 3.84,
        "text": "and this become a thing that you're"
      },
      {
        "start": 38.64,
        "duration": 4.64,
        "text": "pretty confident with now the very words"
      },
      {
        "start": 41.28,
        "duration": 3.759,
        "text": "resilient distributed and data set"
      },
      {
        "start": 43.28,
        "duration": 3.2,
        "text": "require a little bit of explanation"
      },
      {
        "start": 45.039,
        "duration": 3.761,
        "text": "it is of course a data set it's a"
      },
      {
        "start": 46.48,
        "duration": 4.8,
        "text": "collection of data items"
      },
      {
        "start": 48.8,
        "duration": 4.32,
        "text": "of some kind it's distributed meaning"
      },
      {
        "start": 51.28,
        "duration": 3.68,
        "text": "you've got too much work to do"
      },
      {
        "start": 53.12,
        "duration": 4.72,
        "text": "to do it on one computer it's also"
      },
      {
        "start": 54.96,
        "duration": 3.759,
        "text": "resilient so the cluster is able to"
      },
      {
        "start": 57.84,
        "duration": 3.359,
        "text": "maintain"
      },
      {
        "start": 58.719,
        "duration": 3.52,
        "text": "pieces of rdds around the cluster"
      },
      {
        "start": 61.199,
        "duration": 3.6,
        "text": "recompute them"
      },
      {
        "start": 62.239,
        "duration": 3.521,
        "text": "as needed as a core function importantly"
      },
      {
        "start": 64.799,
        "duration": 3.121,
        "text": "rdds are"
      },
      {
        "start": 65.76,
        "duration": 3.84,
        "text": "immutable so you can't really change an"
      },
      {
        "start": 67.92,
        "duration": 3.84,
        "text": "rdd you can transform it"
      },
      {
        "start": 69.6,
        "duration": 4.24,
        "text": "which means i'm going to take my old rdd"
      },
      {
        "start": 71.76,
        "duration": 2.8,
        "text": "and make a new rdd that's a function of"
      },
      {
        "start": 73.84,
        "duration": 3.84,
        "text": "the old one"
      },
      {
        "start": 74.56,
        "duration": 5.199,
        "text": "also rdds are ideally in memory the idea"
      },
      {
        "start": 77.68,
        "duration": 4.0,
        "text": "is to try to get computation to take"
      },
      {
        "start": 79.759,
        "duration": 4.801,
        "text": "place in memory as much as possible"
      },
      {
        "start": 81.68,
        "duration": 3.68,
        "text": "and never go to disk rdds are of course"
      },
      {
        "start": 84.56,
        "duration": 3.04,
        "text": "typed"
      },
      {
        "start": 85.36,
        "duration": 4.079,
        "text": "you're looking here at a key value pair"
      },
      {
        "start": 87.6,
        "duration": 3.04,
        "text": "rdd which is a pretty important type of"
      },
      {
        "start": 89.439,
        "duration": 4.401,
        "text": "rdd"
      },
      {
        "start": 90.64,
        "duration": 4.72,
        "text": "and that so-called pair rdd has types we"
      },
      {
        "start": 93.84,
        "duration": 3.279,
        "text": "need to know what the type of the key is"
      },
      {
        "start": 95.36,
        "duration": 3.759,
        "text": "and what the type of the value is"
      },
      {
        "start": 97.119,
        "duration": 3.04,
        "text": "here this looks like the ages of people"
      },
      {
        "start": 99.119,
        "duration": 2.32,
        "text": "so the"
      },
      {
        "start": 100.159,
        "duration": 2.801,
        "text": "names of those people those will be"
      },
      {
        "start": 101.439,
        "duration": 2.241,
        "text": "strings and the ages those will be"
      },
      {
        "start": 102.96,
        "duration": 2.4,
        "text": "integers"
      },
      {
        "start": 103.68,
        "duration": 4.399,
        "text": "here's an example of the partitioning of"
      },
      {
        "start": 105.36,
        "duration": 4.399,
        "text": "an rdd the table on the left is kind of"
      },
      {
        "start": 108.079,
        "duration": 3.441,
        "text": "how we think about that we think of all"
      },
      {
        "start": 109.759,
        "duration": 3.121,
        "text": "the data we've got this abstraction that"
      },
      {
        "start": 111.52,
        "duration": 3.919,
        "text": "lets us consider that"
      },
      {
        "start": 112.88,
        "duration": 4.239,
        "text": "the rdd is this one unified thing in"
      },
      {
        "start": 115.439,
        "duration": 3.201,
        "text": "reality of course it's spread all over a"
      },
      {
        "start": 117.119,
        "duration": 2.64,
        "text": "bunch of computers and there's all kinds"
      },
      {
        "start": 118.64,
        "duration": 3.439,
        "text": "of difficult work"
      },
      {
        "start": 119.759,
        "duration": 4.241,
        "text": "that the framework is doing to make that"
      },
      {
        "start": 122.079,
        "duration": 3.36,
        "text": "possible based on some partitioning"
      },
      {
        "start": 124.0,
        "duration": 2.64,
        "text": "function the records of the rdd are"
      },
      {
        "start": 125.439,
        "duration": 3.52,
        "text": "broken up and distributed"
      },
      {
        "start": 126.64,
        "duration": 4.319,
        "text": "around the cluster and because spark"
      },
      {
        "start": 128.959,
        "duration": 3.441,
        "text": "remembers the lineage of the data or it"
      },
      {
        "start": 130.959,
        "duration": 3.681,
        "text": "keeps this this graph"
      },
      {
        "start": 132.4,
        "duration": 3.6,
        "text": "of the computational steps we're able to"
      },
      {
        "start": 134.64,
        "duration": 4.08,
        "text": "tolerate the loss"
      },
      {
        "start": 136.0,
        "duration": 3.36,
        "text": "of some part of our data if you look at"
      },
      {
        "start": 138.72,
        "duration": 2.64,
        "text": "the slide"
      },
      {
        "start": 139.36,
        "duration": 3.04,
        "text": "the top node had alice and tom"
      },
      {
        "start": 141.36,
        "duration": 4.16,
        "text": "originally"
      },
      {
        "start": 142.4,
        "duration": 3.6,
        "text": "and the middle node had sarah bob ron"
      },
      {
        "start": 145.52,
        "duration": 2.96,
        "text": "and bob"
      },
      {
        "start": 146.0,
        "duration": 4.239,
        "text": "well that middle node died and so its"
      },
      {
        "start": 148.48,
        "duration": 3.92,
        "text": "records got distributed"
      },
      {
        "start": 150.239,
        "duration": 3.921,
        "text": "to the other two nodes it was"
      },
      {
        "start": 152.4,
        "duration": 4.64,
        "text": "effectively removed from the cluster"
      },
      {
        "start": 154.16,
        "duration": 3.6,
        "text": "and that work was given to other nodes"
      },
      {
        "start": 157.04,
        "duration": 4.08,
        "text": "rdds"
      },
      {
        "start": 157.76,
        "duration": 4.72,
        "text": "are immutable this is key because spark"
      },
      {
        "start": 161.12,
        "duration": 4.08,
        "text": "is a distributed framework"
      },
      {
        "start": 162.48,
        "duration": 3.44,
        "text": "and adopts paradigms from functional"
      },
      {
        "start": 165.2,
        "duration": 2.0,
        "text": "programming"
      },
      {
        "start": 165.92,
        "duration": 3.12,
        "text": "anything you can do to make data"
      },
      {
        "start": 167.2,
        "duration": 3.36,
        "text": "immutable is going to simplify"
      },
      {
        "start": 169.04,
        "duration": 3.76,
        "text": "everything else that the framework does"
      },
      {
        "start": 170.56,
        "duration": 4.8,
        "text": "and that our development does with it so"
      },
      {
        "start": 172.8,
        "duration": 3.439,
        "text": "rdds are read only things we can create"
      },
      {
        "start": 175.36,
        "duration": 2.959,
        "text": "them"
      },
      {
        "start": 176.239,
        "duration": 4.0,
        "text": "we can effectively destroy them or allow"
      },
      {
        "start": 178.319,
        "duration": 4.081,
        "text": "them to kind of pass out of existence"
      },
      {
        "start": 180.239,
        "duration": 3.441,
        "text": "we can't change them in place all we can"
      },
      {
        "start": 182.4,
        "duration": 3.44,
        "text": "do is"
      },
      {
        "start": 183.68,
        "duration": 3.04,
        "text": "take an rdd and transform it into a new"
      },
      {
        "start": 185.84,
        "duration": 2.72,
        "text": "one"
      },
      {
        "start": 186.72,
        "duration": 4.08,
        "text": "you see here in the slide that we're"
      },
      {
        "start": 188.56,
        "duration": 5.039,
        "text": "doing just that we have this big rdd"
      },
      {
        "start": 190.8,
        "duration": 3.6,
        "text": "and then i'm going to filter it by age"
      },
      {
        "start": 193.599,
        "duration": 2.801,
        "text": "and i say i"
      },
      {
        "start": 194.4,
        "duration": 4.72,
        "text": "have this new rdd and i want that only"
      },
      {
        "start": 196.4,
        "duration": 4.8,
        "text": "to be people who are 21 or over"
      },
      {
        "start": 199.12,
        "duration": 3.28,
        "text": "and i've done that that that new rdd"
      },
      {
        "start": 201.2,
        "duration": 3.679,
        "text": "that i've created on the right"
      },
      {
        "start": 202.4,
        "duration": 3.52,
        "text": "uh has that filter applied but i have"
      },
      {
        "start": 204.879,
        "duration": 3.521,
        "text": "not done anything"
      },
      {
        "start": 205.92,
        "duration": 3.599,
        "text": "to alter the source rdd because i can't"
      },
      {
        "start": 208.4,
        "duration": 1.759,
        "text": "they're immutable and that's a good"
      },
      {
        "start": 209.519,
        "duration": 2.561,
        "text": "thing"
      },
      {
        "start": 210.159,
        "duration": 3.201,
        "text": "to the greatest extent possible rdds are"
      },
      {
        "start": 212.08,
        "duration": 3.68,
        "text": "processed in"
      },
      {
        "start": 213.36,
        "duration": 3.04,
        "text": "memory now they don't have to be spark"
      },
      {
        "start": 215.76,
        "duration": 3.039,
        "text": "has"
      },
      {
        "start": 216.4,
        "duration": 3.44,
        "text": "provisions to put data onto disk in"
      },
      {
        "start": 218.799,
        "duration": 3.121,
        "text": "various ways"
      },
      {
        "start": 219.84,
        "duration": 4.08,
        "text": "uh and bring it back into memory but we"
      },
      {
        "start": 221.92,
        "duration": 4.08,
        "text": "would like to partition data"
      },
      {
        "start": 223.92,
        "duration": 3.2,
        "text": "and arrange our data sets such that it's"
      },
      {
        "start": 226.0,
        "duration": 3.28,
        "text": "able to"
      },
      {
        "start": 227.12,
        "duration": 3.36,
        "text": "do its work in memory that's always"
      },
      {
        "start": 229.28,
        "duration": 2.48,
        "text": "going to be a win when we look at"
      },
      {
        "start": 230.48,
        "duration": 10.399,
        "text": "optimization we'll talk about some"
      },
      {
        "start": 231.76,
        "duration": 9.119,
        "text": "techniques for making that happen"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:52:38.613352+00:00"
}