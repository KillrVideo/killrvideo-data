{
  "video_id": "zCQFqhQSo7Y",
  "title": "Realtime Java and AI ep10 - JVector and Cassandra",
  "description": "Join Aaron, Mary, and Cédrick this week as they sit down with DataStax's founder Jonathan Ellis to hear the details of how he built Vector Search for Apache Cassandra® and DataStax Astra DB, and how his development journey resulted in the release of JVector.",
  "published_at": "2023-10-11T06:36:17Z",
  "thumbnail": "https://i.ytimg.com/vi/zCQFqhQSo7Y/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "search",
    "vector",
    "apache_cassandra",
    "astra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=zCQFqhQSo7Y",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] hello everyone welcome to another I think it's episode 10 yeah of our something like that something right yeah I can't believe it's been like this song so it's about our real time uh geni uh with with Java so let's crack the code but today we are very happy to have Jonathan Ellis our founder uh of uh data sex and uh to join us and then of course also Cedric our um leader in one of the engineering teams and formerly with the def lead so uh and of course Erin and myself so yeah so with that uh we want to welcome Jonathan and uh today we'll kind of have a chat about Vector search delighted to be here thanks for having me join you thank you yeah yeah you know maybe maybe a good start you know would be Jonathan real quick just uh you know for for our listeners tell everyone a little bit about yourself yeah uh so I started data Stacks uh in 2010 to commercialized Apache Cassandra I uh LED our Cassandra engineering for a few years and then I kind of got pulled over to the dark side of management um I yeah I I I burned out on that uh it it it doesn't make me happy writing code makes me happy so this year I went back to uh writing code and I've led the development of vector search for Cassandra and for data STX Astra yeah I you know I can understand that I also have some role with more and more management until I I I reach the the roof and I said no no no no no no no bring me back into the cave doing code yeah I mean nothing against people I've I've known some great Engineers who became great managers but but uh that that that's not how my mind works uh I really enjoy the part of actually you know writing the code and and debugging the code and and all of that well I can definitely relate to that too um you know when I when I was at I was at Target for for several years and my role there was mostly in a in a DBA operator kind of a role um and when I first came back to data stacks and then started working with with Cedric you know we we had our first Workshop we were getting ready for and I had to write a bunch of java code for it I'm like oh my God I forgot how awesome this is it's just it just been a while yeah you're not kidding so so okay so this this might not be where we wanted to take the episode but so first of all writing code is just awesome you know just from first principles that you're creating something uh out of nothing right like something that didn't exist now it does and it and that's just the best feeling but come on like I timed coming back back to toode uh really amazingly well uh because this is the year of uh having an AI intern that that helps you write code and the the I guess the two things that I love about that is um well I guess there's three things three things that I love about it maybe more we'll keep going but the first one is that just that I can just give the the simple project or the simple boilerplate classes to GPT and I've gone as far as saying hey I need you to write me a thread safe bit set and you know that's the kind of thing that it's it's in its abilities but you'll need to go back and forth a little bit to to get it correct but it can do it and doing that with with GPT is just at least five times faster than doing it by hand like can I do that by hand sure is it fun not really you know you're you're you're not it's not particularly novel it's just you just have to make it work um but the the second thing that's really useful for me and I think I suspect this is true for for other people with ADHD as well like when I when I get to a a problem that you know especially an unanticipated problem then that that gets that can be really hard for me to to just even though it's not most difficult problem in the world just getting the motivation and the energy to push through that right can be really difficult and having GPT there to say hey here's what I ran into what do you suggest and even though it's answers are not always useful maybe I would say maybe 40% of the time maybe even less but just having that to bounce ideas off of just really really valuable to to you know in the past I've lost entire afternoons or entire days to like oh I ran into this problem and I I I'm gonna fart around on you know Hacker News for the rest of the day that that has happened right uh so that's really useful for me and then uh I I said I I said three what was the third one going to be uh oh the third one is code interpreter or they changed the name to Advanced Data analysis or something but that's super useful for doing these kind of oneoff uh python tools like I've had it write tools to uh do analysis on the git history for me or visualizing the you know I've printed out the stages of the graph that I that my index is represented by printed out the stages as it was constructed and I told code interpreter visualize this for me so there's that that's just an entire another category of uh it's it's a little bit the same category of the first where you're like you're giving an intern projects to do but it's different because it like this is kind of frontend code uh and that's not my thing so having having something that's familiar at a basic level with all the libraries in the world more or less is just really useful totally totally yeah and and that's how I feel about chat GPT right if we build it to use it's really big help but the thing is there are no guard wh so it can be unintentional people can be using it for something else that's not shouldn't be used but but to put it to good use definitely I think it's is you know good thing so yeah so not going too deep but you know me I like to have Elegant code so I can spend a lot of time doing generics and using the ler subject and the more you do doing that the more fluent your API can become and you see your uh method Ging smaller and smaller and when I got to the point where it's almost one one one line for each meod and everything's work as we expect you know say oh yeah hey GPT optimize that now it's to line oh yeah better than me now wonder so so uh you know yeah bringing us bringing us back to our our our core um you know uh subject here so now let's let's move on to uh to J Vector you know Jonathan that's kind of we brought you here to here to talk a little about so um the it's my favorite subject in the world outstanding the initial implementation I was going to say of a a vector on astb was done with uh Lucine hnsw right yeah so more specifically it was H it was a fork of Lucine where I took the hnsw code and I made it uh concurrent uh so not only concurrent but I made it non-blocking so you can have multiple threads building the index at the same time uh without blocking each other nice so yeah that that was that was a good starting point uh having the Lucine implementation saved us a ton of time uh not just not just from like oh like we're going to use this out of the box but you know we did some pretty heavy surgery on it but just having that they Michael I forget his last name but Michael who wrote most of the hnsw implementation there had a really comprehensive test suite and that was super useful in uh getting the bugs out of the concurrent implementation as well so yeah that's what we that's what we did our open beta on and that's what we G on as well wow wonderful excellent excellent it's not good enough that's yeah yeah right so so the the challenge with hnsw and well let's back up the good things about hnsw and this is why everybody starts with hnsw right so you know if you look at the the general purpose Vector search databases out there wv8 uses hnsw quadrant uses hnsw uh elastic and uh solar and open search I'll use lucin's hnsw everybody uses that for two reasons one is that you can build it incrementally so a bunch of the Alternatives if you're the the main alternative to graph based so hnsw is part of a a larger category of uh approximate nearest neighbor algorithms that use a graph-based structure uh and with the graph based family you can build them incrementally without knowing your entire data set ahead of time the the main alternative that people use are variants of I'm going to partition these vectors somehow and then when when I have a query I'll select the partitions that are closest to the query and then I'll just look in those partitions so it's an alternative way of reducing the work that you have to do to to do that search uh the problem with those is that you do need to know your entire data set ahead of time before you can create accurate partitions so when you're building a database where you want to you know every time someone inserts a row you want to be able to uh query that and search and find that Vector that they just inserted uh the partitioning approaches just aren't uh a good fit right so the uh with the other nice thing about uh the graph based family and hnsw in particular is that uh not only is it fast but it's also accurate uh so if you pick a uh an if you pick a a default or a close to default configuration from Facebook's face uh Vector indexing library for instance and face is a great great piece of work from Facebook that gives you basically every Vector search algorithm that we know of or or every Vector indexing algorithm that we know of uh is implemented in face but most of the algorithms there if you just pick the default parameters and say okay index my data you'll probably get around 50% recall meaning uh if I as for the top 10 five of the actual top 10 will be in the 10 results that the approximate nearest neighbor algorithm gives me back uh so that's completely acceptable for a lot of use cases by the way but right you know 50% most of us would say that's a failing grade uh in uh in most contexts so you want to you want to be able to do better and hnsw uh you can depending on the on the data set and how how aggressive the index is and so forth but you can easily get to from you know 75% to 95% uh pretty repeatedly uh and so it's the combination of the speed and the accuracy it's pretty tough to beat now and and and that's why so many people use it so you asked what was the problem with that the problem with that is that uh hnsw it uses a lot of memory uh for its index be uh just because of the nature of the Beast we can maybe we can go deeper on on the algorithms next time uh but it uses a lot of memory to to build the index and uh because it is a a graph-based algorithm what you're doing when you're searching for the nearest neighbors is you're basically doing a Brett first search and as you expand a node and say hey what what edges do you have what neighboring nodes or what neighboring vectors uh should I uh expand my search to every time you do that you need to find out is my search getting closer to my query because that's the goal is to drill down into the graph until you find the closest ones so you need to know if I'm actually if if going a specific Direction actually gets me closer or not and and doing that that uh computation of am I getting closer I'm I'm doing a DOT product or a cosine or a you Ian distance across massive vectors of you know 1536 Dimensions if you're using open AI embeddings which you probably shouldn't be uh but you know even if you're using a smaller embedding Vector like the E5 V2 that I usually recommend that's 384 dimensions that's still very very large that's still a lot yeah compared to like doing a uh a search in a in a database where you're saying select integers greater than five like that's a really really easy comparison uh by contrast so you're doing these massive comparisons uh and to do that you actually you need to have the vector in memory not just the the index in memory but the vector data needs to be in memory as well uh and so what what we found is as we started to push the index to the edge of you know fitting in memory and then beyond that edge uh the performance really deteriorates really quickly which is a little bit surprising uh coming from a a database background because in the database world there's definitely a very pronounced Paro principle where uh you have 80% of the workload touches 20% of the data uh so there's there's always this this hot data and then there's this colder data that that maybe uh you it's not as critical for it to be uh in in Ram but with the the vector search because of the way the graph is constructed you could there's it's almost completely random you have almost exactly the same probability of touching any given node versus any of the others uh and so there's no Paro principle to uh to save you there and uh and yeah once you get once you get outside of what fits in memory it it slows down massively as it's pulling those vectors off of dis while you're doing the search right so so at some point um along your journey here you know you're working with you Lu's hnsw and at at some point you know you get to you get to it and you're like you know I'm GNA stop doing surgery on this thing and I'm just going to create my own implementation so so how did that how did that evolve that's yeah so my My First Choice was to Upstream the the concurrent index to Lucine I don't say this to to you know throw blame anywhere like I've but you know for whatever reasons uh none of the Lucine committers were super interested in uh the new code uh that I was that I was proposing so uh yeah so what I ended up doing and I I really wanted this lowlevel indexing code to uh be available outside of Cassandra itself uh because I think it's more broadly useful than that um like what I want you know I we talked about a little bit at the beginning of how useful AI is in writing code what I want is a local co-pilot I want a local GPT that can answer questions about my code and uh right now those only exist as cloud services and so you know every time I get on an airplane it's like my productivity gets cut in half uh which is which is you kind of a drag uh and then there's like you know the whole privacy aspect and and all that other stuff as well um so what I want is I want intellig to be able to index my code and use Vector search to pull back the most relevant pieces and send it to uh you know llama 7 billion running on J llama all in intell like that that's totally possible today uh but until J Vector was open source there was that missing piece of how do we do the the vector search in Java you know partly because there isn't a really good embeddable uh Java Vector search Library out there and partly because hey open source is great you know the the cathedral and the bizaar having everyone bring a piece of the puzzle and and we collaborate and the whole is greater than the sum of the parts all those reasons uh I I wanted you know J Vector to uh to have its own home and be as accessible to as many people as possible so uh so I had a motivation to to make this excess accessible uh Vector search library and I also had a problem to solve which is making a uh making an index that can be faster than hnsw especially for larger than memory data sets and there's there's a couple options uh proposed in in research uh but the the one that I think is proved out the most in practiced is called disn so Microsoft actually Microsoft research published a paper I believe in 2019 about this new algorithm called disn and then they actually open sourced their implementation that's available if you search for uh GitHub dis Inn you'll find the Microsoft uh disc Inn implementation in C++ uh yeah and I I believe that that is in production in being uh so you can look at the commit history it's it's been a very active project uh up to and including today that was kind of the tiebreaker versus like there there are other algorithms that people are proposing and saying hey this is going to be uh even faster but one of the things when you're implementing a research paper like there's a lot of things that look superficially uh simple and then it turns out that there's a bunch of Gremlins that the paper authors didn't bother spelling out the solutions for um so the fact that that not only is this in uction but that there's there's a a code an open source code base that I can go uh dive through if I'm like oh okay how did they actually do this uh that that was really useful and in fact I did do that a few times uh oh wow I I maybe next time we can give some examples of of where that was useful uh so but long story short went with a dis an algorithm uh implemented it in J Vector the outcome is is that you can do your search without hitting dis at all uh and there's a there's an as risk there but more the right way to think of it is you're not hitting the disc during the search the reason that you can do that is that you're you're compressing the vectors uh with a lossy compression algorithm called Product quantization so you can kind of think of it as JPEG for vectors you lose a little bit of fidelity but it makes it much much much much smaller um and so you're you're performing the search with those compressed vectors which means not only am I not hitting dis but performing the comparison instead of uh you know doing it against a a vector of Dimension 384 I'm doing it against a vector of 1116 of that which is that 24 uh so it's it's a massive difference in speed from that as well so if you go to the V uh the J Vector project page there's a a graph there there where I Benchmark Lucine versus J Vector on a larger than memory data set right I saw that J Vector is something like 15 times faster but if you compare J Vector versus Lucine on a smaller than memory data set it's still like three to five times faster uh because you're reducing the computation that you need to do uh during the search this is a this is a really good example of you can beat your head against the wall trying to make your code faster and optimizing it super super at the low level as much as possible and you know maybe I would have been able to get another 10% or so out of hnsw doing that uh but the way you get to 5x the way you get to 15x is by using a better algorithm so that right it's it's always fun when when you get the chance to do that it's great really great yeah it's it's not only the algori right you add to look for the latest innovation in Java to to to achieve that or you know moving yeah uh that's that's true so I mean there's room for both uh so uh that J Vector uses plan's simd optimizations to make the dot product computations faster uh and last I checked it's been a while but the last time I checked that was getting us about an 80% performance Improvement so if you run J vecttor with Java 20 or 21 then you will get the simd uh optimizations if you run it with Java 11 or anything before 20 you don't get those optimizations but it will still run so so that's that's good to know yeah that's a that's that's an incentive to upgrade yeah exactly and it was for us too right like uh Astra was not running Java 21 until we came up with uh the simd optimizations in in J vector and said now it's worth your time to uh to upgrade oh for sure for sure yeah yeah interacting a lot with users I see still people saying yeah but I'm using gd8 and I think starting this year now it's your problem you know I I will not shoot a foot in my you know bullet in my foot anymore so a bare minimum and you know I feel comfortable with 17 round to be oh yeah yeah it that that is a little bit of a a source of frustration Apache Cassandra was on eight until recently and now I believe right uh the minimum is going to be 11 for for Cassandra 5.0 which is which is a big Improvement that's a big improvement over a but it's still is it three years old at this point is it older than that it it feel 11 I think so yeah yeah the jbk has been making such big improvements with pattern matching with record classes with lightweight threads and you don't get any of those on 11 so uh upgrade it yeah well that I'm just curious talking about jdk I mean now that jdk 21 has project Loom that comes out or the virtual threats so would you kind of Leverage on Virtual threats maybe at some point like in I guess what J vector or have you thought about it too so with with with J Vector I'm not I'm not completely sure how this is going to shake out but what we're taking what we're doing right now is we have an interface called random AIS reader and it's got half a dozen methods it's got like a a readint method and a read array of inss and a read array of floats uh and I think a read Boolean I think that might be it uh and the idea is that you can Implement those in whatever way fits the rest of your project so for Cassandra we have some you know internal classes that use map Dio and we have other classes that that Implement our own uh caching on top of direct IO and so you can create this Random Access reader uh from the J Vector interface uh on top of of either one of those um with lightweight the reason this is relevant for lightweight threads is that now now that we have that it becomes a lot more tractable to build asynchronous IO into your Java application so the jdk ships with asynchronous network IO now uh in the Cassandra case and J Vector case we're more concerned about dis iio which the jdk does not give us a solution for out of the box however there's uh at least one uh fairly uh mature Library out there for using linux's IO uring uh async IO interface from java uh and so I think uh this is the part that I'm not sure about because I haven't written the code yet but I think that the next step is going to be doing async iio on top of IOU ring and uh and we'll see whether that makes J Vector change its interface or not uh we may be able to fit it into the same interface but it may it may require changes the quest of improvements never HS yep yeah for sure yeah and and if yeah if you haven't taken look at IOU ring uh in a few years it's been it's been making almost as much progress as the jdk it it's really a lot it reminds me of when Cassandra was young uh that you know every every new uh big user uh pushed it in in directions that it hadn't gone before so when when Netflix started using it we added you know features that Netflix needed when Spotify started using it same story um that's been driven the Linux kernel is is driving in the same way because everybody needs fast asynchronous dis iio and uh yeah it's just been a very practically motivated set of improvements wonderful I guess um we definitely will have to have Jonathan back for another episode or more right and we'll go even deeper into J Vector um I'd love to yeah uh display this QR code here uh that's the J Vector GitHub repot uh so folks please uh sign up and and or not sign up but like follow that out and star follow and watch and do all that you can this is a great uh and then also before we go too uh we would like to share this running on G Vector now Java 21 so that's right yeah okay so don't forget to sign up for us for our extra DB so yeah so with that I think yeah there's definitely you know more stuff to talk about and I learned so much just within less than 30 minutes and that this has been amazing thank you so much John absolutely yeah thanks again for having me thank you thank you and thanks Aaron and thanks Cedric yeah too no Jonathan he's the guest thank you thank you all right all right goodbye everyone bye",
    "segments": [
      {
        "start": 0.0,
        "duration": 7.53,
        "text": "[Music]"
      },
      {
        "start": 8.2,
        "duration": 4.559,
        "text": "hello everyone welcome to another I"
      },
      {
        "start": 10.519,
        "duration": 3.721,
        "text": "think it's episode 10 yeah of our"
      },
      {
        "start": 12.759,
        "duration": 3.561,
        "text": "something like that something right yeah"
      },
      {
        "start": 14.24,
        "duration": 6.36,
        "text": "I can't believe it's been like this song"
      },
      {
        "start": 16.32,
        "duration": 8.36,
        "text": "so it's about our real time uh geni uh"
      },
      {
        "start": 20.6,
        "duration": 6.4,
        "text": "with with Java so let's crack the code"
      },
      {
        "start": 24.68,
        "duration": 6.2,
        "text": "but today we are very happy to have"
      },
      {
        "start": 27.0,
        "duration": 6.2,
        "text": "Jonathan Ellis our founder uh of uh data"
      },
      {
        "start": 30.88,
        "duration": 5.64,
        "text": "sex and uh to join us and then of course"
      },
      {
        "start": 33.2,
        "duration": 5.72,
        "text": "also Cedric our um leader in one of the"
      },
      {
        "start": 36.52,
        "duration": 5.68,
        "text": "engineering teams and formerly with the"
      },
      {
        "start": 38.92,
        "duration": 6.36,
        "text": "def lead so uh and of course Erin and"
      },
      {
        "start": 42.2,
        "duration": 5.72,
        "text": "myself so yeah so with that uh we want"
      },
      {
        "start": 45.28,
        "duration": 6.68,
        "text": "to welcome Jonathan and uh today we'll"
      },
      {
        "start": 47.92,
        "duration": 5.56,
        "text": "kind of have a chat about Vector search"
      },
      {
        "start": 51.96,
        "duration": 4.399,
        "text": "delighted to be here thanks for having"
      },
      {
        "start": 53.48,
        "duration": 4.399,
        "text": "me join you thank you yeah yeah you know"
      },
      {
        "start": 56.359,
        "duration": 3.561,
        "text": "maybe maybe a good start you know would"
      },
      {
        "start": 57.879,
        "duration": 3.721,
        "text": "be Jonathan real quick just uh you know"
      },
      {
        "start": 59.92,
        "duration": 4.84,
        "text": "for for our listeners tell everyone a"
      },
      {
        "start": 61.6,
        "duration": 5.92,
        "text": "little bit about yourself yeah uh so I"
      },
      {
        "start": 64.76,
        "duration": 7.88,
        "text": "started data Stacks uh in 2010 to"
      },
      {
        "start": 67.52,
        "duration": 6.88,
        "text": "commercialized Apache Cassandra I uh LED"
      },
      {
        "start": 72.64,
        "duration": 3.479,
        "text": "our Cassandra engineering for a few"
      },
      {
        "start": 74.4,
        "duration": 3.88,
        "text": "years and then I kind of got pulled over"
      },
      {
        "start": 76.119,
        "duration": 7.0,
        "text": "to the dark side of"
      },
      {
        "start": 78.28,
        "duration": 7.72,
        "text": "management um I yeah I I I burned out on"
      },
      {
        "start": 83.119,
        "duration": 5.481,
        "text": "that uh it it it doesn't make me happy"
      },
      {
        "start": 86.0,
        "duration": 5.799,
        "text": "writing code makes me happy so this year"
      },
      {
        "start": 88.6,
        "duration": 6.12,
        "text": "I went back to uh writing code and I've"
      },
      {
        "start": 91.799,
        "duration": 5.32,
        "text": "led the development of vector search for"
      },
      {
        "start": 94.72,
        "duration": 5.439,
        "text": "Cassandra and for data STX"
      },
      {
        "start": 97.119,
        "duration": 5.32,
        "text": "Astra yeah I you know I can understand"
      },
      {
        "start": 100.159,
        "duration": 5.881,
        "text": "that I also have some role with more and"
      },
      {
        "start": 102.439,
        "duration": 6.28,
        "text": "more management until I I I reach the"
      },
      {
        "start": 106.04,
        "duration": 6.439,
        "text": "the roof and I said no no no no no no no"
      },
      {
        "start": 108.719,
        "duration": 3.76,
        "text": "bring me back into the cave doing"
      },
      {
        "start": 112.799,
        "duration": 5.161,
        "text": "code yeah I mean nothing against people"
      },
      {
        "start": 115.92,
        "duration": 5.559,
        "text": "I've I've known some great Engineers who"
      },
      {
        "start": 117.96,
        "duration": 6.439,
        "text": "became great managers but but uh that"
      },
      {
        "start": 121.479,
        "duration": 5.521,
        "text": "that that's not how my mind works uh I"
      },
      {
        "start": 124.399,
        "duration": 4.601,
        "text": "really enjoy the part of actually you"
      },
      {
        "start": 127.0,
        "duration": 4.48,
        "text": "know writing the code and and debugging"
      },
      {
        "start": 129.0,
        "duration": 4.76,
        "text": "the code and and all of"
      },
      {
        "start": 131.48,
        "duration": 5.36,
        "text": "that well I can definitely relate to"
      },
      {
        "start": 133.76,
        "duration": 5.559,
        "text": "that too um you know when I when I was"
      },
      {
        "start": 136.84,
        "duration": 4.679,
        "text": "at I was at Target for for several years"
      },
      {
        "start": 139.319,
        "duration": 5.2,
        "text": "and my role there was mostly in a in a"
      },
      {
        "start": 141.519,
        "duration": 4.561,
        "text": "DBA operator kind of a role um and when"
      },
      {
        "start": 144.519,
        "duration": 3.481,
        "text": "I first came back to data stacks and"
      },
      {
        "start": 146.08,
        "duration": 3.4,
        "text": "then started working with with Cedric"
      },
      {
        "start": 148.0,
        "duration": 2.519,
        "text": "you know we we had our first Workshop we"
      },
      {
        "start": 149.48,
        "duration": 2.44,
        "text": "were getting ready for and I had to"
      },
      {
        "start": 150.519,
        "duration": 4.0,
        "text": "write a bunch of java code for it I'm"
      },
      {
        "start": 151.92,
        "duration": 5.48,
        "text": "like oh my God I forgot how awesome this"
      },
      {
        "start": 154.519,
        "duration": 5.321,
        "text": "is it's just it just been a while yeah"
      },
      {
        "start": 157.4,
        "duration": 3.68,
        "text": "you're not kidding so so okay so this"
      },
      {
        "start": 159.84,
        "duration": 3.92,
        "text": "this might not be where we wanted to"
      },
      {
        "start": 161.08,
        "duration": 4.92,
        "text": "take the episode but so first of all"
      },
      {
        "start": 163.76,
        "duration": 4.119,
        "text": "writing code is just awesome you know"
      },
      {
        "start": 166.0,
        "duration": 5.04,
        "text": "just from first principles that you're"
      },
      {
        "start": 167.879,
        "duration": 5.481,
        "text": "creating something uh out of nothing"
      },
      {
        "start": 171.04,
        "duration": 5.479,
        "text": "right like something that didn't exist"
      },
      {
        "start": 173.36,
        "duration": 5.959,
        "text": "now it does and it and that's just the"
      },
      {
        "start": 176.519,
        "duration": 4.561,
        "text": "best feeling but come on like I timed"
      },
      {
        "start": 179.319,
        "duration": 4.801,
        "text": "coming back back to"
      },
      {
        "start": 181.08,
        "duration": 7.48,
        "text": "toode uh really amazingly well uh"
      },
      {
        "start": 184.12,
        "duration": 8.56,
        "text": "because this is the year of uh having an"
      },
      {
        "start": 188.56,
        "duration": 7.64,
        "text": "AI intern that that helps you write code"
      },
      {
        "start": 192.68,
        "duration": 7.119,
        "text": "and the the I guess the two things that"
      },
      {
        "start": 196.2,
        "duration": 5.08,
        "text": "I love about that is um well I guess"
      },
      {
        "start": 199.799,
        "duration": 3.281,
        "text": "there's three things three things that I"
      },
      {
        "start": 201.28,
        "duration": 5.519,
        "text": "love about it maybe more we'll keep"
      },
      {
        "start": 203.08,
        "duration": 6.2,
        "text": "going but the first one is that just"
      },
      {
        "start": 206.799,
        "duration": 5.281,
        "text": "that I can just give the the simple"
      },
      {
        "start": 209.28,
        "duration": 6.44,
        "text": "project or the simple boilerplate"
      },
      {
        "start": 212.08,
        "duration": 6.04,
        "text": "classes to GPT and I've gone as far as"
      },
      {
        "start": 215.72,
        "duration": 6.28,
        "text": "saying hey I need you to write me a"
      },
      {
        "start": 218.12,
        "duration": 5.52,
        "text": "thread safe bit set and you know that's"
      },
      {
        "start": 222.0,
        "duration": 3.159,
        "text": "the kind of thing that it's it's in its"
      },
      {
        "start": 223.64,
        "duration": 3.76,
        "text": "abilities but you'll need to go back and"
      },
      {
        "start": 225.159,
        "duration": 5.921,
        "text": "forth a little bit to to get it correct"
      },
      {
        "start": 227.4,
        "duration": 7.8,
        "text": "but it can do it and doing that with"
      },
      {
        "start": 231.08,
        "duration": 5.96,
        "text": "with GPT is just at least five times"
      },
      {
        "start": 235.2,
        "duration": 4.039,
        "text": "faster than doing it by hand like can I"
      },
      {
        "start": 237.04,
        "duration": 4.6,
        "text": "do that by hand sure is it fun not"
      },
      {
        "start": 239.239,
        "duration": 4.84,
        "text": "really you know you're you're you're not"
      },
      {
        "start": 241.64,
        "duration": 5.48,
        "text": "it's not particularly novel it's just"
      },
      {
        "start": 244.079,
        "duration": 4.681,
        "text": "you just have to make it work um but the"
      },
      {
        "start": 247.12,
        "duration": 6.16,
        "text": "the second thing that's really useful"
      },
      {
        "start": 248.76,
        "duration": 7.159,
        "text": "for me and I think I suspect this is"
      },
      {
        "start": 253.28,
        "duration": 5.959,
        "text": "true for for other people with ADHD as"
      },
      {
        "start": 255.919,
        "duration": 5.56,
        "text": "well like when I when I get to a a"
      },
      {
        "start": 259.239,
        "duration": 5.921,
        "text": "problem that you know especially an"
      },
      {
        "start": 261.479,
        "duration": 5.881,
        "text": "unanticipated problem then that that"
      },
      {
        "start": 265.16,
        "duration": 5.24,
        "text": "gets that can be really hard for me to"
      },
      {
        "start": 267.36,
        "duration": 4.76,
        "text": "to just even though it's not most"
      },
      {
        "start": 270.4,
        "duration": 4.48,
        "text": "difficult problem in the world just"
      },
      {
        "start": 272.12,
        "duration": 5.28,
        "text": "getting the motivation and the energy to"
      },
      {
        "start": 274.88,
        "duration": 6.08,
        "text": "push through that right can be really"
      },
      {
        "start": 277.4,
        "duration": 5.519,
        "text": "difficult and having GPT there to say"
      },
      {
        "start": 280.96,
        "duration": 5.2,
        "text": "hey here's what I ran into what do you"
      },
      {
        "start": 282.919,
        "duration": 6.081,
        "text": "suggest and even though it's answers are"
      },
      {
        "start": 286.16,
        "duration": 5.92,
        "text": "not always useful maybe I would say"
      },
      {
        "start": 289.0,
        "duration": 7.88,
        "text": "maybe 40% of the time maybe even less"
      },
      {
        "start": 292.08,
        "duration": 8.399,
        "text": "but just having that to bounce ideas off"
      },
      {
        "start": 296.88,
        "duration": 5.92,
        "text": "of just really really valuable to to you"
      },
      {
        "start": 300.479,
        "duration": 5.241,
        "text": "know in the past I've lost entire"
      },
      {
        "start": 302.8,
        "duration": 6.2,
        "text": "afternoons or entire days to like oh I"
      },
      {
        "start": 305.72,
        "duration": 6.039,
        "text": "ran into this problem and I I I'm gonna"
      },
      {
        "start": 309.0,
        "duration": 4.72,
        "text": "fart around on you know Hacker News for"
      },
      {
        "start": 311.759,
        "duration": 3.88,
        "text": "the rest of the day that that has"
      },
      {
        "start": 313.72,
        "duration": 5.8,
        "text": "happened right uh so that's really"
      },
      {
        "start": 315.639,
        "duration": 5.601,
        "text": "useful for me and then uh I I said I I"
      },
      {
        "start": 319.52,
        "duration": 4.119,
        "text": "said three what was the third one going"
      },
      {
        "start": 321.24,
        "duration": 4.12,
        "text": "to be uh oh the third one is code"
      },
      {
        "start": 323.639,
        "duration": 4.201,
        "text": "interpreter or they changed the name to"
      },
      {
        "start": 325.36,
        "duration": 5.36,
        "text": "Advanced Data analysis or something but"
      },
      {
        "start": 327.84,
        "duration": 6.24,
        "text": "that's super useful for doing these kind"
      },
      {
        "start": 330.72,
        "duration": 7.28,
        "text": "of oneoff uh python tools like I've had"
      },
      {
        "start": 334.08,
        "duration": 6.72,
        "text": "it write tools to uh do analysis on the"
      },
      {
        "start": 338.0,
        "duration": 5.319,
        "text": "git history for me or"
      },
      {
        "start": 340.8,
        "duration": 5.399,
        "text": "visualizing the you know I've printed"
      },
      {
        "start": 343.319,
        "duration": 5.681,
        "text": "out the stages of the graph that I that"
      },
      {
        "start": 346.199,
        "duration": 5.161,
        "text": "my index is represented by printed out"
      },
      {
        "start": 349.0,
        "duration": 4.96,
        "text": "the stages as it was constructed and I"
      },
      {
        "start": 351.36,
        "duration": 5.44,
        "text": "told code interpreter visualize this for"
      },
      {
        "start": 353.96,
        "duration": 6.04,
        "text": "me so there's that that's just an entire"
      },
      {
        "start": 356.8,
        "duration": 4.76,
        "text": "another category of uh it's it's a"
      },
      {
        "start": 360.0,
        "duration": 3.52,
        "text": "little bit the same category of the"
      },
      {
        "start": 361.56,
        "duration": 4.96,
        "text": "first where you're like you're giving an"
      },
      {
        "start": 363.52,
        "duration": 5.959,
        "text": "intern projects to do but it's different"
      },
      {
        "start": 366.52,
        "duration": 7.0,
        "text": "because it like this is kind of frontend"
      },
      {
        "start": 369.479,
        "duration": 7.201,
        "text": "code uh and that's not my thing"
      },
      {
        "start": 373.52,
        "duration": 5.56,
        "text": "so having having something that's"
      },
      {
        "start": 376.68,
        "duration": 4.799,
        "text": "familiar at a basic level with all the"
      },
      {
        "start": 379.08,
        "duration": 6.08,
        "text": "libraries in the world more or less is"
      },
      {
        "start": 381.479,
        "duration": 6.201,
        "text": "just really useful totally totally yeah"
      },
      {
        "start": 385.16,
        "duration": 4.36,
        "text": "and and that's how I feel about chat GPT"
      },
      {
        "start": 387.68,
        "duration": 3.44,
        "text": "right if we build it to use it's really"
      },
      {
        "start": 389.52,
        "duration": 4.44,
        "text": "big help but the thing is there are no"
      },
      {
        "start": 391.12,
        "duration": 4.4,
        "text": "guard wh so it can be unintentional"
      },
      {
        "start": 393.96,
        "duration": 3.88,
        "text": "people can be using it for something"
      },
      {
        "start": 395.52,
        "duration": 4.2,
        "text": "else that's not shouldn't be used but"
      },
      {
        "start": 397.84,
        "duration": 5.0,
        "text": "but to put it to good use definitely I"
      },
      {
        "start": 399.72,
        "duration": 5.44,
        "text": "think it's is you know good thing so"
      },
      {
        "start": 402.84,
        "duration": 5.0,
        "text": "yeah so not going too deep but you know"
      },
      {
        "start": 405.16,
        "duration": 5.56,
        "text": "me I like to have Elegant code so I can"
      },
      {
        "start": 407.84,
        "duration": 5.28,
        "text": "spend a lot of time doing generics and"
      },
      {
        "start": 410.72,
        "duration": 5.44,
        "text": "using the ler subject and the more you"
      },
      {
        "start": 413.12,
        "duration": 5.68,
        "text": "do doing that the more fluent your API"
      },
      {
        "start": 416.16,
        "duration": 5.52,
        "text": "can become and you see your uh method"
      },
      {
        "start": 418.8,
        "duration": 5.16,
        "text": "Ging smaller and smaller and when I got"
      },
      {
        "start": 421.68,
        "duration": 4.16,
        "text": "to the point where it's almost one one"
      },
      {
        "start": 423.96,
        "duration": 4.44,
        "text": "one line for each meod and everything's"
      },
      {
        "start": 425.84,
        "duration": 6.88,
        "text": "work as we expect you know say oh yeah"
      },
      {
        "start": 428.4,
        "duration": 6.519,
        "text": "hey GPT optimize that now it's to line"
      },
      {
        "start": 432.72,
        "duration": 6.199,
        "text": "oh"
      },
      {
        "start": 434.919,
        "duration": 5.601,
        "text": "yeah better than me now wonder so so uh"
      },
      {
        "start": 438.919,
        "duration": 4.761,
        "text": "you know yeah bringing us bringing us"
      },
      {
        "start": 440.52,
        "duration": 6.2,
        "text": "back to our our our core um you know uh"
      },
      {
        "start": 443.68,
        "duration": 5.199,
        "text": "subject here so now let's let's move on"
      },
      {
        "start": 446.72,
        "duration": 3.4,
        "text": "to uh to J Vector you know Jonathan"
      },
      {
        "start": 448.879,
        "duration": 3.44,
        "text": "that's kind of we brought you here to"
      },
      {
        "start": 450.12,
        "duration": 5.479,
        "text": "here to talk a little about so um the"
      },
      {
        "start": 452.319,
        "duration": 5.481,
        "text": "it's my favorite subject in the world"
      },
      {
        "start": 455.599,
        "duration": 5.04,
        "text": "outstanding the initial implementation I"
      },
      {
        "start": 457.8,
        "duration": 7.359,
        "text": "was going to say of a a vector on astb"
      },
      {
        "start": 460.639,
        "duration": 7.4,
        "text": "was done with uh Lucine hnsw right yeah"
      },
      {
        "start": 465.159,
        "duration": 7.241,
        "text": "so more specifically it was H it was a"
      },
      {
        "start": 468.039,
        "duration": 10.401,
        "text": "fork of Lucine where I took the hnsw"
      },
      {
        "start": 472.4,
        "duration": 8.16,
        "text": "code and I made it uh concurrent uh so"
      },
      {
        "start": 478.44,
        "duration": 5.0,
        "text": "not only concurrent but I made it"
      },
      {
        "start": 480.56,
        "duration": 5.88,
        "text": "non-blocking so you can have multiple"
      },
      {
        "start": 483.44,
        "duration": 6.52,
        "text": "threads building the index at the same"
      },
      {
        "start": 486.44,
        "duration": 5.56,
        "text": "time uh without blocking each other nice"
      },
      {
        "start": 489.96,
        "duration": 5.239,
        "text": "so yeah that that was that was a good"
      },
      {
        "start": 492.0,
        "duration": 6.72,
        "text": "starting point uh having the Lucine"
      },
      {
        "start": 495.199,
        "duration": 7.041,
        "text": "implementation saved us a ton of time uh"
      },
      {
        "start": 498.72,
        "duration": 5.36,
        "text": "not just not just from like oh like"
      },
      {
        "start": 502.24,
        "duration": 3.28,
        "text": "we're going to use this out of the box"
      },
      {
        "start": 504.08,
        "duration": 5.399,
        "text": "but you know we did some pretty heavy"
      },
      {
        "start": 505.52,
        "duration": 6.04,
        "text": "surgery on it but just having that they"
      },
      {
        "start": 509.479,
        "duration": 4.081,
        "text": "Michael I forget his last name but"
      },
      {
        "start": 511.56,
        "duration": 4.0,
        "text": "Michael who wrote most of the hnsw"
      },
      {
        "start": 513.56,
        "duration": 3.8,
        "text": "implementation there had a really"
      },
      {
        "start": 515.56,
        "duration": 4.68,
        "text": "comprehensive test suite and that was"
      },
      {
        "start": 517.36,
        "duration": 4.96,
        "text": "super useful in uh getting the bugs out"
      },
      {
        "start": 520.24,
        "duration": 3.719,
        "text": "of the concurrent implementation as well"
      },
      {
        "start": 522.32,
        "duration": 3.48,
        "text": "so yeah that's what we that's what we"
      },
      {
        "start": 523.959,
        "duration": 6.521,
        "text": "did our open beta on and that's what we"
      },
      {
        "start": 525.8,
        "duration": 7.64,
        "text": "G on as well wow wonderful excellent"
      },
      {
        "start": 530.48,
        "duration": 5.799,
        "text": "excellent it's not good enough that's"
      },
      {
        "start": 533.44,
        "duration": 6.2,
        "text": "yeah yeah right so so the the challenge"
      },
      {
        "start": 536.279,
        "duration": 5.8,
        "text": "with hnsw and well let's back up the"
      },
      {
        "start": 539.64,
        "duration": 5.68,
        "text": "good things about hnsw and this is why"
      },
      {
        "start": 542.079,
        "duration": 5.481,
        "text": "everybody starts with hnsw right so you"
      },
      {
        "start": 545.32,
        "duration": 4.28,
        "text": "know if you look at the the general"
      },
      {
        "start": 547.56,
        "duration": 5.959,
        "text": "purpose Vector search databases out"
      },
      {
        "start": 549.6,
        "duration": 8.96,
        "text": "there wv8 uses hnsw quadrant uses"
      },
      {
        "start": 553.519,
        "duration": 7.241,
        "text": "hnsw uh elastic and uh solar and open"
      },
      {
        "start": 558.56,
        "duration": 6.04,
        "text": "search I'll use lucin's"
      },
      {
        "start": 560.76,
        "duration": 6.28,
        "text": "hnsw everybody uses that for two reasons"
      },
      {
        "start": 564.6,
        "duration": 5.4,
        "text": "one is that you can build it"
      },
      {
        "start": 567.04,
        "duration": 5.359,
        "text": "incrementally so a bunch of the"
      },
      {
        "start": 570.0,
        "duration": 5.6,
        "text": "Alternatives if you're the the main"
      },
      {
        "start": 572.399,
        "duration": 6.521,
        "text": "alternative to graph based so hnsw is"
      },
      {
        "start": 575.6,
        "duration": 5.56,
        "text": "part of a a larger category of uh"
      },
      {
        "start": 578.92,
        "duration": 4.88,
        "text": "approximate nearest neighbor algorithms"
      },
      {
        "start": 581.16,
        "duration": 5.119,
        "text": "that use a graph-based structure uh and"
      },
      {
        "start": 583.8,
        "duration": 4.599,
        "text": "with the graph based family you can"
      },
      {
        "start": 586.279,
        "duration": 4.841,
        "text": "build them incrementally without knowing"
      },
      {
        "start": 588.399,
        "duration": 5.68,
        "text": "your entire data set ahead of time the"
      },
      {
        "start": 591.12,
        "duration": 5.6,
        "text": "the main alternative that people use are"
      },
      {
        "start": 594.079,
        "duration": 5.241,
        "text": "variants of I'm going to partition these"
      },
      {
        "start": 596.72,
        "duration": 5.96,
        "text": "vectors somehow and then when when I"
      },
      {
        "start": 599.32,
        "duration": 5.24,
        "text": "have a query I'll select the partitions"
      },
      {
        "start": 602.68,
        "duration": 4.0,
        "text": "that are closest to the query and then"
      },
      {
        "start": 604.56,
        "duration": 4.08,
        "text": "I'll just look in those partitions so"
      },
      {
        "start": 606.68,
        "duration": 4.04,
        "text": "it's an alternative way of reducing the"
      },
      {
        "start": 608.64,
        "duration": 5.16,
        "text": "work that you have to do to to do that"
      },
      {
        "start": 610.72,
        "duration": 6.08,
        "text": "search uh the problem with those is that"
      },
      {
        "start": 613.8,
        "duration": 5.76,
        "text": "you do need to know your entire data set"
      },
      {
        "start": 616.8,
        "duration": 5.36,
        "text": "ahead of time before you can create"
      },
      {
        "start": 619.56,
        "duration": 4.68,
        "text": "accurate partitions so when you're"
      },
      {
        "start": 622.16,
        "duration": 3.64,
        "text": "building a database where you want to"
      },
      {
        "start": 624.24,
        "duration": 4.32,
        "text": "you know every time someone inserts a"
      },
      {
        "start": 625.8,
        "duration": 4.96,
        "text": "row you want to be able to uh query that"
      },
      {
        "start": 628.56,
        "duration": 4.76,
        "text": "and search and find that Vector that"
      },
      {
        "start": 630.76,
        "duration": 6.56,
        "text": "they just inserted uh the partitioning"
      },
      {
        "start": 633.32,
        "duration": 6.759,
        "text": "approaches just aren't uh a good fit"
      },
      {
        "start": 637.32,
        "duration": 5.56,
        "text": "right so the uh with the other nice"
      },
      {
        "start": 640.079,
        "duration": 6.481,
        "text": "thing about uh the graph based family"
      },
      {
        "start": 642.88,
        "duration": 6.8,
        "text": "and hnsw in particular is that uh not"
      },
      {
        "start": 646.56,
        "duration": 8.04,
        "text": "only is it fast but it's also accurate"
      },
      {
        "start": 649.68,
        "duration": 7.0,
        "text": "uh so if you pick a uh an if you pick a"
      },
      {
        "start": 654.6,
        "duration": 5.2,
        "text": "a default or a close to default"
      },
      {
        "start": 656.68,
        "duration": 5.959,
        "text": "configuration from Facebook's face"
      },
      {
        "start": 659.8,
        "duration": 5.08,
        "text": "uh Vector indexing library for instance"
      },
      {
        "start": 662.639,
        "duration": 5.601,
        "text": "and face is a great great piece of work"
      },
      {
        "start": 664.88,
        "duration": 5.56,
        "text": "from Facebook that gives you basically"
      },
      {
        "start": 668.24,
        "duration": 4.44,
        "text": "every Vector search algorithm that we"
      },
      {
        "start": 670.44,
        "duration": 4.12,
        "text": "know of or or every Vector indexing"
      },
      {
        "start": 672.68,
        "duration": 4.36,
        "text": "algorithm that we know of uh is"
      },
      {
        "start": 674.56,
        "duration": 4.92,
        "text": "implemented in face but most of the"
      },
      {
        "start": 677.04,
        "duration": 4.56,
        "text": "algorithms there if you just pick the"
      },
      {
        "start": 679.48,
        "duration": 7.28,
        "text": "default parameters and say okay index my"
      },
      {
        "start": 681.6,
        "duration": 9.28,
        "text": "data you'll probably get around 50%"
      },
      {
        "start": 686.76,
        "duration": 7.28,
        "text": "recall meaning uh if I as for the top 10"
      },
      {
        "start": 690.88,
        "duration": 6.12,
        "text": "five of the actual top 10 will be in the"
      },
      {
        "start": 694.04,
        "duration": 6.56,
        "text": "10 results that the approximate nearest"
      },
      {
        "start": 697.0,
        "duration": 5.639,
        "text": "neighbor algorithm gives me back uh so"
      },
      {
        "start": 700.6,
        "duration": 4.4,
        "text": "that's completely acceptable for a lot"
      },
      {
        "start": 702.639,
        "duration": 4.361,
        "text": "of use cases by the way but right you"
      },
      {
        "start": 705.0,
        "duration": 5.76,
        "text": "know 50% most of us would say that's a"
      },
      {
        "start": 707.0,
        "duration": 5.279,
        "text": "failing grade uh in uh in most contexts"
      },
      {
        "start": 710.76,
        "duration": 3.16,
        "text": "so you want to you want to be able to do"
      },
      {
        "start": 712.279,
        "duration": 5.161,
        "text": "better and"
      },
      {
        "start": 713.92,
        "duration": 5.719,
        "text": "hnsw uh you can depending on the on the"
      },
      {
        "start": 717.44,
        "duration": 4.639,
        "text": "data set and how how aggressive the"
      },
      {
        "start": 719.639,
        "duration": 6.0,
        "text": "index is and so forth but you can easily"
      },
      {
        "start": 722.079,
        "duration": 8.961,
        "text": "get to from you know 75% to"
      },
      {
        "start": 725.639,
        "duration": 7.281,
        "text": "95% uh pretty repeatedly uh and so it's"
      },
      {
        "start": 731.04,
        "duration": 5.32,
        "text": "the combination of the speed and the"
      },
      {
        "start": 732.92,
        "duration": 5.64,
        "text": "accuracy it's pretty tough to beat now"
      },
      {
        "start": 736.36,
        "duration": 2.919,
        "text": "and and and that's why so many people"
      },
      {
        "start": 738.56,
        "duration": 3.56,
        "text": "use"
      },
      {
        "start": 739.279,
        "duration": 5.441,
        "text": "it so you asked what was the problem"
      },
      {
        "start": 742.12,
        "duration": 3.519,
        "text": "with that the problem with that is that"
      },
      {
        "start": 744.72,
        "duration": 5.2,
        "text": "uh"
      },
      {
        "start": 745.639,
        "duration": 6.88,
        "text": "hnsw it uses a lot of memory uh for its"
      },
      {
        "start": 749.92,
        "duration": 4.64,
        "text": "index be uh just because of the nature"
      },
      {
        "start": 752.519,
        "duration": 4.961,
        "text": "of the Beast we can maybe we can go"
      },
      {
        "start": 754.56,
        "duration": 4.92,
        "text": "deeper on on the algorithms next time uh"
      },
      {
        "start": 757.48,
        "duration": 5.039,
        "text": "but it uses a lot of memory to to build"
      },
      {
        "start": 759.48,
        "duration": 5.159,
        "text": "the index and uh because it is a a"
      },
      {
        "start": 762.519,
        "duration": 4.0,
        "text": "graph-based algorithm what you're doing"
      },
      {
        "start": 764.639,
        "duration": 3.841,
        "text": "when you're searching for the nearest"
      },
      {
        "start": 766.519,
        "duration": 6.88,
        "text": "neighbors is you're basically doing a"
      },
      {
        "start": 768.48,
        "duration": 7.08,
        "text": "Brett first search and as you expand a"
      },
      {
        "start": 773.399,
        "duration": 4.481,
        "text": "node and say hey what what edges do you"
      },
      {
        "start": 775.56,
        "duration": 3.959,
        "text": "have what neighboring nodes or what"
      },
      {
        "start": 777.88,
        "duration": 5.48,
        "text": "neighboring vectors"
      },
      {
        "start": 779.519,
        "duration": 6.12,
        "text": "uh should I uh expand my search to every"
      },
      {
        "start": 783.36,
        "duration": 6.039,
        "text": "time you do that you need to find out is"
      },
      {
        "start": 785.639,
        "duration": 5.361,
        "text": "my search getting closer to my query"
      },
      {
        "start": 789.399,
        "duration": 2.961,
        "text": "because that's the goal is to drill down"
      },
      {
        "start": 791.0,
        "duration": 3.639,
        "text": "into the graph until you find the"
      },
      {
        "start": 792.36,
        "duration": 4.039,
        "text": "closest ones so you need to know if I'm"
      },
      {
        "start": 794.639,
        "duration": 4.521,
        "text": "actually if if going a specific"
      },
      {
        "start": 796.399,
        "duration": 6.721,
        "text": "Direction actually gets me closer or not"
      },
      {
        "start": 799.16,
        "duration": 7.239,
        "text": "and and doing that that uh computation"
      },
      {
        "start": 803.12,
        "duration": 6.079,
        "text": "of am I getting closer I'm I'm doing a"
      },
      {
        "start": 806.399,
        "duration": 6.321,
        "text": "DOT product or a cosine or a you Ian"
      },
      {
        "start": 809.199,
        "duration": 5.681,
        "text": "distance across massive vectors of you"
      },
      {
        "start": 812.72,
        "duration": 4.359,
        "text": "know 1536 Dimensions if you're using"
      },
      {
        "start": 814.88,
        "duration": 5.84,
        "text": "open AI embeddings which you probably"
      },
      {
        "start": 817.079,
        "duration": 6.841,
        "text": "shouldn't be uh but you know even if"
      },
      {
        "start": 820.72,
        "duration": 6.6,
        "text": "you're using a smaller embedding Vector"
      },
      {
        "start": 823.92,
        "duration": 5.64,
        "text": "like the E5 V2 that I usually recommend"
      },
      {
        "start": 827.32,
        "duration": 4.28,
        "text": "that's 384 dimensions that's still very"
      },
      {
        "start": 829.56,
        "duration": 5.32,
        "text": "very large that's still a lot yeah"
      },
      {
        "start": 831.6,
        "duration": 4.799,
        "text": "compared to like doing a uh a search in"
      },
      {
        "start": 834.88,
        "duration": 3.56,
        "text": "a in a database where you're saying"
      },
      {
        "start": 836.399,
        "duration": 4.601,
        "text": "select integers greater than five like"
      },
      {
        "start": 838.44,
        "duration": 4.56,
        "text": "that's a really really easy comparison"
      },
      {
        "start": 841.0,
        "duration": 4.92,
        "text": "uh by contrast so you're doing these"
      },
      {
        "start": 843.0,
        "duration": 4.839,
        "text": "massive comparisons uh and to do that"
      },
      {
        "start": 845.92,
        "duration": 3.76,
        "text": "you actually you need to have the vector"
      },
      {
        "start": 847.839,
        "duration": 4.081,
        "text": "in memory not just the the index in"
      },
      {
        "start": 849.68,
        "duration": 5.599,
        "text": "memory but the vector data needs to be"
      },
      {
        "start": 851.92,
        "duration": 7.12,
        "text": "in memory as well uh and so what what we"
      },
      {
        "start": 855.279,
        "duration": 6.401,
        "text": "found is as we started to push the index"
      },
      {
        "start": 859.04,
        "duration": 6.12,
        "text": "to the edge of you know fitting in"
      },
      {
        "start": 861.68,
        "duration": 5.44,
        "text": "memory and then beyond that edge uh the"
      },
      {
        "start": 865.16,
        "duration": 4.56,
        "text": "performance really deteriorates really"
      },
      {
        "start": 867.12,
        "duration": 4.8,
        "text": "quickly which is a little bit surprising"
      },
      {
        "start": 869.72,
        "duration": 5.08,
        "text": "uh coming from a a database background"
      },
      {
        "start": 871.92,
        "duration": 5.479,
        "text": "because in the database world there's"
      },
      {
        "start": 874.8,
        "duration": 5.8,
        "text": "definitely a very pronounced Paro"
      },
      {
        "start": 877.399,
        "duration": 6.961,
        "text": "principle where uh you have 80% of the"
      },
      {
        "start": 880.6,
        "duration": 5.32,
        "text": "workload touches 20% of the data uh so"
      },
      {
        "start": 884.36,
        "duration": 4.039,
        "text": "there's there's always this this hot"
      },
      {
        "start": 885.92,
        "duration": 5.44,
        "text": "data and then there's this colder data"
      },
      {
        "start": 888.399,
        "duration": 7.281,
        "text": "that that maybe uh you it's not as"
      },
      {
        "start": 891.36,
        "duration": 6.88,
        "text": "critical for it to be uh in in Ram but"
      },
      {
        "start": 895.68,
        "duration": 4.8,
        "text": "with the the vector search because of"
      },
      {
        "start": 898.24,
        "duration": 4.279,
        "text": "the way the graph is constructed you"
      },
      {
        "start": 900.48,
        "duration": 4.32,
        "text": "could there's it's almost completely"
      },
      {
        "start": 902.519,
        "duration": 5.041,
        "text": "random you have almost exactly the same"
      },
      {
        "start": 904.8,
        "duration": 5.92,
        "text": "probability of touching any given node"
      },
      {
        "start": 907.56,
        "duration": 6.839,
        "text": "versus any of the others uh and so"
      },
      {
        "start": 910.72,
        "duration": 7.2,
        "text": "there's no Paro principle to uh to save"
      },
      {
        "start": 914.399,
        "duration": 5.161,
        "text": "you there and uh and yeah once you get"
      },
      {
        "start": 917.92,
        "duration": 4.52,
        "text": "once you get outside of what fits in"
      },
      {
        "start": 919.56,
        "duration": 5.12,
        "text": "memory it it slows down massively as"
      },
      {
        "start": 922.44,
        "duration": 4.88,
        "text": "it's pulling those vectors off of dis"
      },
      {
        "start": 924.68,
        "duration": 5.959,
        "text": "while you're doing the search right so"
      },
      {
        "start": 927.32,
        "duration": 5.16,
        "text": "so at some point um along your journey"
      },
      {
        "start": 930.639,
        "duration": 3.281,
        "text": "here you know you're working with you"
      },
      {
        "start": 932.48,
        "duration": 4.4,
        "text": "Lu's"
      },
      {
        "start": 933.92,
        "duration": 4.2,
        "text": "hnsw and at at some point you know you"
      },
      {
        "start": 936.88,
        "duration": 3.6,
        "text": "get to you get to it and you're like you"
      },
      {
        "start": 938.12,
        "duration": 3.519,
        "text": "know I'm GNA stop doing surgery on this"
      },
      {
        "start": 940.48,
        "duration": 3.64,
        "text": "thing and I'm just going to create my"
      },
      {
        "start": 941.639,
        "duration": 6.241,
        "text": "own implementation so so how did that"
      },
      {
        "start": 944.12,
        "duration": 7.12,
        "text": "how did that evolve that's yeah so my My"
      },
      {
        "start": 947.88,
        "duration": 6.92,
        "text": "First Choice was to Upstream the the"
      },
      {
        "start": 951.24,
        "duration": 6.839,
        "text": "concurrent index to Lucine I don't say"
      },
      {
        "start": 954.8,
        "duration": 5.24,
        "text": "this to to you know throw blame anywhere"
      },
      {
        "start": 958.079,
        "duration": 4.641,
        "text": "like I've but you know for whatever"
      },
      {
        "start": 960.04,
        "duration": 6.52,
        "text": "reasons uh none of the Lucine committers"
      },
      {
        "start": 962.72,
        "duration": 8.4,
        "text": "were super interested in uh the new code"
      },
      {
        "start": 966.56,
        "duration": 6.36,
        "text": "uh that I was that I was proposing so uh"
      },
      {
        "start": 971.12,
        "duration": 4.6,
        "text": "yeah so what I ended up doing and I I"
      },
      {
        "start": 972.92,
        "duration": 6.8,
        "text": "really wanted this lowlevel indexing"
      },
      {
        "start": 975.72,
        "duration": 6.2,
        "text": "code to uh be available outside of"
      },
      {
        "start": 979.72,
        "duration": 5.72,
        "text": "Cassandra itself uh because I think it's"
      },
      {
        "start": 981.92,
        "duration": 5.96,
        "text": "more broadly useful than that um like"
      },
      {
        "start": 985.44,
        "duration": 3.879,
        "text": "what I want you know I we talked about a"
      },
      {
        "start": 987.88,
        "duration": 4.92,
        "text": "little bit at the beginning of how"
      },
      {
        "start": 989.319,
        "duration": 7.241,
        "text": "useful AI is in writing code what I want"
      },
      {
        "start": 992.8,
        "duration": 6.2,
        "text": "is a local co-pilot I want a local GPT"
      },
      {
        "start": 996.56,
        "duration": 5.16,
        "text": "that can answer questions about my code"
      },
      {
        "start": 999.0,
        "duration": 4.92,
        "text": "and uh right now those only exist as"
      },
      {
        "start": 1001.72,
        "duration": 4.119,
        "text": "cloud services and so you know every"
      },
      {
        "start": 1003.92,
        "duration": 5.399,
        "text": "time I get on an airplane it's like my"
      },
      {
        "start": 1005.839,
        "duration": 6.081,
        "text": "productivity gets cut in half uh which"
      },
      {
        "start": 1009.319,
        "duration": 3.841,
        "text": "is which is you kind of a drag uh and"
      },
      {
        "start": 1011.92,
        "duration": 3.359,
        "text": "then there's like you know the whole"
      },
      {
        "start": 1013.16,
        "duration": 5.599,
        "text": "privacy aspect and and all that other"
      },
      {
        "start": 1015.279,
        "duration": 6.081,
        "text": "stuff as well um so what I want is I"
      },
      {
        "start": 1018.759,
        "duration": 5.121,
        "text": "want intellig to be able to index my"
      },
      {
        "start": 1021.36,
        "duration": 6.439,
        "text": "code and use Vector search to pull back"
      },
      {
        "start": 1023.88,
        "duration": 7.199,
        "text": "the most relevant pieces and send it to"
      },
      {
        "start": 1027.799,
        "duration": 7.361,
        "text": "uh you know llama 7 billion running on J"
      },
      {
        "start": 1031.079,
        "duration": 8.0,
        "text": "llama all in intell like that that's"
      },
      {
        "start": 1035.16,
        "duration": 6.08,
        "text": "totally possible today uh but until J"
      },
      {
        "start": 1039.079,
        "duration": 4.281,
        "text": "Vector was open source there was that"
      },
      {
        "start": 1041.24,
        "duration": 5.599,
        "text": "missing piece of how do we do the the"
      },
      {
        "start": 1043.36,
        "duration": 6.36,
        "text": "vector search in Java you know partly"
      },
      {
        "start": 1046.839,
        "duration": 6.041,
        "text": "because there isn't a really good"
      },
      {
        "start": 1049.72,
        "duration": 5.68,
        "text": "embeddable uh Java Vector search Library"
      },
      {
        "start": 1052.88,
        "duration": 4.56,
        "text": "out there and partly because hey open"
      },
      {
        "start": 1055.4,
        "duration": 4.2,
        "text": "source is great you know the the"
      },
      {
        "start": 1057.44,
        "duration": 4.239,
        "text": "cathedral and the bizaar having everyone"
      },
      {
        "start": 1059.6,
        "duration": 3.76,
        "text": "bring a piece of the puzzle and and we"
      },
      {
        "start": 1061.679,
        "duration": 3.321,
        "text": "collaborate and the whole is greater"
      },
      {
        "start": 1063.36,
        "duration": 4.6,
        "text": "than the sum of the parts all those"
      },
      {
        "start": 1065.0,
        "duration": 5.52,
        "text": "reasons uh I I wanted you know J Vector"
      },
      {
        "start": 1067.96,
        "duration": 5.36,
        "text": "to uh to have its own home and be as"
      },
      {
        "start": 1070.52,
        "duration": 7.24,
        "text": "accessible to as many people as possible"
      },
      {
        "start": 1073.32,
        "duration": 6.64,
        "text": "so uh so I had a motivation to to make"
      },
      {
        "start": 1077.76,
        "duration": 5.44,
        "text": "this excess accessible uh Vector search"
      },
      {
        "start": 1079.96,
        "duration": 7.12,
        "text": "library and I also had a problem to"
      },
      {
        "start": 1083.2,
        "duration": 5.92,
        "text": "solve which is making a uh making an"
      },
      {
        "start": 1087.08,
        "duration": 4.4,
        "text": "index that can be faster than"
      },
      {
        "start": 1089.12,
        "duration": 6.24,
        "text": "hnsw especially for larger than memory"
      },
      {
        "start": 1091.48,
        "duration": 7.92,
        "text": "data sets and there's there's a couple"
      },
      {
        "start": 1095.36,
        "duration": 5.76,
        "text": "options uh proposed in in research uh"
      },
      {
        "start": 1099.4,
        "duration": 5.32,
        "text": "but the the one that I think is proved"
      },
      {
        "start": 1101.12,
        "duration": 6.28,
        "text": "out the most in practiced is called disn"
      },
      {
        "start": 1104.72,
        "duration": 5.64,
        "text": "so Microsoft actually Microsoft research"
      },
      {
        "start": 1107.4,
        "duration": 5.88,
        "text": "published a paper I believe in 2019"
      },
      {
        "start": 1110.36,
        "duration": 4.72,
        "text": "about this new algorithm called disn and"
      },
      {
        "start": 1113.28,
        "duration": 3.68,
        "text": "then they actually open sourced their"
      },
      {
        "start": 1115.08,
        "duration": 4.8,
        "text": "implementation that's available if you"
      },
      {
        "start": 1116.96,
        "duration": 6.24,
        "text": "search for uh GitHub dis Inn you'll find"
      },
      {
        "start": 1119.88,
        "duration": 4.24,
        "text": "the Microsoft uh disc Inn implementation"
      },
      {
        "start": 1123.2,
        "duration": 5.32,
        "text": "in"
      },
      {
        "start": 1124.12,
        "duration": 7.559,
        "text": "C++ uh yeah and I I believe that that is"
      },
      {
        "start": 1128.52,
        "duration": 5.92,
        "text": "in production in being uh so you can"
      },
      {
        "start": 1131.679,
        "duration": 5.721,
        "text": "look at the commit history it's it's"
      },
      {
        "start": 1134.44,
        "duration": 4.84,
        "text": "been a very active project uh up to and"
      },
      {
        "start": 1137.4,
        "duration": 4.399,
        "text": "including today that was kind of the"
      },
      {
        "start": 1139.28,
        "duration": 4.24,
        "text": "tiebreaker versus like there there are"
      },
      {
        "start": 1141.799,
        "duration": 3.161,
        "text": "other algorithms that people are"
      },
      {
        "start": 1143.52,
        "duration": 5.6,
        "text": "proposing and saying hey this is going"
      },
      {
        "start": 1144.96,
        "duration": 7.079,
        "text": "to be uh even faster but one of the"
      },
      {
        "start": 1149.12,
        "duration": 5.48,
        "text": "things when you're implementing a"
      },
      {
        "start": 1152.039,
        "duration": 3.961,
        "text": "research paper like there's a lot of"
      },
      {
        "start": 1154.6,
        "duration": 3.4,
        "text": "things that look"
      },
      {
        "start": 1156.0,
        "duration": 4.36,
        "text": "superficially uh simple and then it"
      },
      {
        "start": 1158.0,
        "duration": 4.72,
        "text": "turns out that there's a bunch of"
      },
      {
        "start": 1160.36,
        "duration": 5.439,
        "text": "Gremlins that the paper authors didn't"
      },
      {
        "start": 1162.72,
        "duration": 5.16,
        "text": "bother spelling out the solutions for um"
      },
      {
        "start": 1165.799,
        "duration": 6.0,
        "text": "so the fact that that not only is this"
      },
      {
        "start": 1167.88,
        "duration": 5.88,
        "text": "in uction but that there's there's a a"
      },
      {
        "start": 1171.799,
        "duration": 5.841,
        "text": "code an open source code base that I can"
      },
      {
        "start": 1173.76,
        "duration": 6.44,
        "text": "go uh dive through if I'm like oh okay"
      },
      {
        "start": 1177.64,
        "duration": 4.519,
        "text": "how did they actually do this uh that"
      },
      {
        "start": 1180.2,
        "duration": 5.959,
        "text": "that was really useful and in fact I did"
      },
      {
        "start": 1182.159,
        "duration": 6.201,
        "text": "do that a few times uh oh wow I I maybe"
      },
      {
        "start": 1186.159,
        "duration": 5.601,
        "text": "next time we can give some examples of"
      },
      {
        "start": 1188.36,
        "duration": 6.319,
        "text": "of where that was useful uh so but long"
      },
      {
        "start": 1191.76,
        "duration": 5.36,
        "text": "story short went with a dis an algorithm"
      },
      {
        "start": 1194.679,
        "duration": 5.401,
        "text": "uh implemented it in J Vector the"
      },
      {
        "start": 1197.12,
        "duration": 7.0,
        "text": "outcome is is that you can do your"
      },
      {
        "start": 1200.08,
        "duration": 6.24,
        "text": "search without hitting dis at all uh and"
      },
      {
        "start": 1204.12,
        "duration": 4.52,
        "text": "there's a there's an as risk there but"
      },
      {
        "start": 1206.32,
        "duration": 3.76,
        "text": "more the right way to think of it is"
      },
      {
        "start": 1208.64,
        "duration": 3.76,
        "text": "you're not hitting the disc during the"
      },
      {
        "start": 1210.08,
        "duration": 4.479,
        "text": "search the reason that you can do that"
      },
      {
        "start": 1212.4,
        "duration": 4.92,
        "text": "is that you're you're compressing the"
      },
      {
        "start": 1214.559,
        "duration": 5.12,
        "text": "vectors uh with a lossy compression"
      },
      {
        "start": 1217.32,
        "duration": 3.92,
        "text": "algorithm called Product quantization so"
      },
      {
        "start": 1219.679,
        "duration": 3.041,
        "text": "you can kind of think of it as JPEG for"
      },
      {
        "start": 1221.24,
        "duration": 3.679,
        "text": "vectors you lose a little bit of"
      },
      {
        "start": 1222.72,
        "duration": 5.76,
        "text": "fidelity but it makes it much much much"
      },
      {
        "start": 1224.919,
        "duration": 4.841,
        "text": "much smaller um and so you're you're"
      },
      {
        "start": 1228.48,
        "duration": 3.84,
        "text": "performing the search with those"
      },
      {
        "start": 1229.76,
        "duration": 6.96,
        "text": "compressed vectors which means not only"
      },
      {
        "start": 1232.32,
        "duration": 8.8,
        "text": "am I not hitting dis but performing the"
      },
      {
        "start": 1236.72,
        "duration": 8.28,
        "text": "comparison instead of uh you know doing"
      },
      {
        "start": 1241.12,
        "duration": 6.64,
        "text": "it against a a vector of Dimension 384"
      },
      {
        "start": 1245.0,
        "duration": 6.4,
        "text": "I'm doing it against a vector of 1116 of"
      },
      {
        "start": 1247.76,
        "duration": 5.56,
        "text": "that which is that 24 uh so it's it's a"
      },
      {
        "start": 1251.4,
        "duration": 4.519,
        "text": "massive difference in speed from that as"
      },
      {
        "start": 1253.32,
        "duration": 4.64,
        "text": "well so if you go to the V uh the J"
      },
      {
        "start": 1255.919,
        "duration": 4.76,
        "text": "Vector project page there's a a graph"
      },
      {
        "start": 1257.96,
        "duration": 5.4,
        "text": "there there where I Benchmark Lucine"
      },
      {
        "start": 1260.679,
        "duration": 4.841,
        "text": "versus J Vector on a larger than memory"
      },
      {
        "start": 1263.36,
        "duration": 4.6,
        "text": "data set right I saw that J Vector is"
      },
      {
        "start": 1265.52,
        "duration": 4.6,
        "text": "something like 15 times faster but if"
      },
      {
        "start": 1267.96,
        "duration": 4.599,
        "text": "you compare J Vector versus Lucine on a"
      },
      {
        "start": 1270.12,
        "duration": 4.919,
        "text": "smaller than memory data set it's still"
      },
      {
        "start": 1272.559,
        "duration": 5.041,
        "text": "like three to five times faster uh"
      },
      {
        "start": 1275.039,
        "duration": 5.561,
        "text": "because you're reducing the computation"
      },
      {
        "start": 1277.6,
        "duration": 5.0,
        "text": "that you need to do uh during the search"
      },
      {
        "start": 1280.6,
        "duration": 4.959,
        "text": "this is a this is a really good example"
      },
      {
        "start": 1282.6,
        "duration": 5.88,
        "text": "of you can beat your head against the"
      },
      {
        "start": 1285.559,
        "duration": 6.161,
        "text": "wall trying to make your code faster and"
      },
      {
        "start": 1288.48,
        "duration": 5.96,
        "text": "optimizing it super super at the low"
      },
      {
        "start": 1291.72,
        "duration": 3.88,
        "text": "level as much as possible and you know"
      },
      {
        "start": 1294.44,
        "duration": 5.119,
        "text": "maybe I would have been able to get"
      },
      {
        "start": 1295.6,
        "duration": 7.72,
        "text": "another 10% or so out of hnsw doing that"
      },
      {
        "start": 1299.559,
        "duration": 6.521,
        "text": "uh but the way you get to 5x the way you"
      },
      {
        "start": 1303.32,
        "duration": 5.839,
        "text": "get to 15x is by using a better"
      },
      {
        "start": 1306.08,
        "duration": 5.28,
        "text": "algorithm so that right it's it's always"
      },
      {
        "start": 1309.159,
        "duration": 6.441,
        "text": "fun when when you get the chance to do"
      },
      {
        "start": 1311.36,
        "duration": 6.72,
        "text": "that it's great really great yeah it's"
      },
      {
        "start": 1315.6,
        "duration": 4.76,
        "text": "it's not only the algori right you add"
      },
      {
        "start": 1318.08,
        "duration": 5.64,
        "text": "to look for the latest innovation in"
      },
      {
        "start": 1320.36,
        "duration": 5.64,
        "text": "Java to to to achieve that or you know"
      },
      {
        "start": 1323.72,
        "duration": 5.76,
        "text": "moving yeah uh that's that's true so I"
      },
      {
        "start": 1326.0,
        "duration": 7.679,
        "text": "mean there's room for both uh so uh that"
      },
      {
        "start": 1329.48,
        "duration": 7.52,
        "text": "J Vector uses plan's simd optimizations"
      },
      {
        "start": 1333.679,
        "duration": 6.88,
        "text": "to make the dot product computations"
      },
      {
        "start": 1337.0,
        "duration": 5.44,
        "text": "faster uh and last I checked it's been a"
      },
      {
        "start": 1340.559,
        "duration": 4.641,
        "text": "while but the last time I"
      },
      {
        "start": 1342.44,
        "duration": 5.64,
        "text": "checked that was getting us about an 80%"
      },
      {
        "start": 1345.2,
        "duration": 6.12,
        "text": "performance Improvement so if you run J"
      },
      {
        "start": 1348.08,
        "duration": 6.68,
        "text": "vecttor with Java 20 or 21 then you will"
      },
      {
        "start": 1351.32,
        "duration": 6.839,
        "text": "get the simd uh optimizations if you run"
      },
      {
        "start": 1354.76,
        "duration": 5.32,
        "text": "it with Java 11 or anything before 20"
      },
      {
        "start": 1358.159,
        "duration": 5.281,
        "text": "you don't get those optimizations but it"
      },
      {
        "start": 1360.08,
        "duration": 5.52,
        "text": "will still run so so that's that's good"
      },
      {
        "start": 1363.44,
        "duration": 5.04,
        "text": "to know yeah that's a that's that's an"
      },
      {
        "start": 1365.6,
        "duration": 5.76,
        "text": "incentive to upgrade yeah"
      },
      {
        "start": 1368.48,
        "duration": 7.559,
        "text": "exactly and it was for us too right like"
      },
      {
        "start": 1371.36,
        "duration": 6.96,
        "text": "uh Astra was not running Java 21 until"
      },
      {
        "start": 1376.039,
        "duration": 4.76,
        "text": "we came up with uh the simd"
      },
      {
        "start": 1378.32,
        "duration": 5.2,
        "text": "optimizations in in J vector and said"
      },
      {
        "start": 1380.799,
        "duration": 6.601,
        "text": "now it's worth your time to uh to"
      },
      {
        "start": 1383.52,
        "duration": 6.68,
        "text": "upgrade oh for sure for sure yeah yeah"
      },
      {
        "start": 1387.4,
        "duration": 4.84,
        "text": "interacting a lot with users I see still"
      },
      {
        "start": 1390.2,
        "duration": 5.28,
        "text": "people saying yeah but I'm using"
      },
      {
        "start": 1392.24,
        "duration": 5.88,
        "text": "gd8 and I think starting this year now"
      },
      {
        "start": 1395.48,
        "duration": 5.24,
        "text": "it's your problem you know I I will not"
      },
      {
        "start": 1398.12,
        "duration": 4.559,
        "text": "shoot a foot in my you know bullet in my"
      },
      {
        "start": 1400.72,
        "duration": 5.04,
        "text": "foot anymore"
      },
      {
        "start": 1402.679,
        "duration": 6.24,
        "text": "so a bare minimum and you know I feel"
      },
      {
        "start": 1405.76,
        "duration": 5.56,
        "text": "comfortable with 17 round to be oh yeah"
      },
      {
        "start": 1408.919,
        "duration": 5.601,
        "text": "yeah it that that is a little bit of a a"
      },
      {
        "start": 1411.32,
        "duration": 5.8,
        "text": "source of frustration Apache Cassandra"
      },
      {
        "start": 1414.52,
        "duration": 5.2,
        "text": "was on eight until recently and now I"
      },
      {
        "start": 1417.12,
        "duration": 6.12,
        "text": "believe right uh the minimum is going to"
      },
      {
        "start": 1419.72,
        "duration": 5.16,
        "text": "be 11 for for Cassandra 5.0 which is"
      },
      {
        "start": 1423.24,
        "duration": 5.439,
        "text": "which is a big Improvement that's a big"
      },
      {
        "start": 1424.88,
        "duration": 5.08,
        "text": "improvement over a but it's still is it"
      },
      {
        "start": 1428.679,
        "duration": 4.6,
        "text": "three years old at this point is it"
      },
      {
        "start": 1429.96,
        "duration": 6.04,
        "text": "older than that it it feel 11 I think so"
      },
      {
        "start": 1433.279,
        "duration": 4.681,
        "text": "yeah yeah the jbk has been making such"
      },
      {
        "start": 1436.0,
        "duration": 4.72,
        "text": "big improvements with pattern matching"
      },
      {
        "start": 1437.96,
        "duration": 4.4,
        "text": "with record classes with lightweight"
      },
      {
        "start": 1440.72,
        "duration": 6.4,
        "text": "threads and you don't get any of those"
      },
      {
        "start": 1442.36,
        "duration": 7.199,
        "text": "on 11 so uh upgrade it"
      },
      {
        "start": 1447.12,
        "duration": 5.2,
        "text": "yeah well that I'm just curious talking"
      },
      {
        "start": 1449.559,
        "duration": 4.561,
        "text": "about jdk I mean now that jdk 21 has"
      },
      {
        "start": 1452.32,
        "duration": 4.479,
        "text": "project Loom that comes out or the"
      },
      {
        "start": 1454.12,
        "duration": 4.6,
        "text": "virtual threats so would you kind of"
      },
      {
        "start": 1456.799,
        "duration": 4.201,
        "text": "Leverage on Virtual threats maybe at"
      },
      {
        "start": 1458.72,
        "duration": 4.88,
        "text": "some point like in I guess what J vector"
      },
      {
        "start": 1461.0,
        "duration": 5.0,
        "text": "or have you thought about it too so with"
      },
      {
        "start": 1463.6,
        "duration": 3.76,
        "text": "with with J Vector I'm not I'm not"
      },
      {
        "start": 1466.0,
        "duration": 3.64,
        "text": "completely sure how this is going to"
      },
      {
        "start": 1467.36,
        "duration": 4.72,
        "text": "shake out but what we're taking what"
      },
      {
        "start": 1469.64,
        "duration": 4.8,
        "text": "we're doing right now is we have an"
      },
      {
        "start": 1472.08,
        "duration": 4.36,
        "text": "interface called random AIS reader and"
      },
      {
        "start": 1474.44,
        "duration": 5.68,
        "text": "it's got half a dozen methods it's got"
      },
      {
        "start": 1476.44,
        "duration": 6.52,
        "text": "like a a readint method and a read array"
      },
      {
        "start": 1480.12,
        "duration": 4.799,
        "text": "of inss and a read array of floats uh"
      },
      {
        "start": 1482.96,
        "duration": 4.959,
        "text": "and I think a read Boolean I think that"
      },
      {
        "start": 1484.919,
        "duration": 6.48,
        "text": "might be it uh and the idea is that you"
      },
      {
        "start": 1487.919,
        "duration": 6.521,
        "text": "can Implement those in whatever way fits"
      },
      {
        "start": 1491.399,
        "duration": 5.681,
        "text": "the rest of your project so for"
      },
      {
        "start": 1494.44,
        "duration": 6.239,
        "text": "Cassandra we have some you know internal"
      },
      {
        "start": 1497.08,
        "duration": 6.04,
        "text": "classes that use map Dio and we have"
      },
      {
        "start": 1500.679,
        "duration": 5.88,
        "text": "other classes that that Implement our"
      },
      {
        "start": 1503.12,
        "duration": 5.559,
        "text": "own uh caching on top of direct IO and"
      },
      {
        "start": 1506.559,
        "duration": 5.441,
        "text": "so you can create this Random Access"
      },
      {
        "start": 1508.679,
        "duration": 7.24,
        "text": "reader uh from the J Vector interface uh"
      },
      {
        "start": 1512.0,
        "duration": 5.24,
        "text": "on top of of either one of those um with"
      },
      {
        "start": 1515.919,
        "duration": 4.321,
        "text": "lightweight the reason this is relevant"
      },
      {
        "start": 1517.24,
        "duration": 7.48,
        "text": "for lightweight threads is that now now"
      },
      {
        "start": 1520.24,
        "duration": 6.439,
        "text": "that we have that it becomes a lot more"
      },
      {
        "start": 1524.72,
        "duration": 5.76,
        "text": "tractable"
      },
      {
        "start": 1526.679,
        "duration": 6.561,
        "text": "to build asynchronous IO into your Java"
      },
      {
        "start": 1530.48,
        "duration": 6.0,
        "text": "application so the jdk ships with"
      },
      {
        "start": 1533.24,
        "duration": 5.28,
        "text": "asynchronous network IO now uh in the"
      },
      {
        "start": 1536.48,
        "duration": 4.84,
        "text": "Cassandra case and J Vector case we're"
      },
      {
        "start": 1538.52,
        "duration": 5.159,
        "text": "more concerned about dis iio which the"
      },
      {
        "start": 1541.32,
        "duration": 6.04,
        "text": "jdk does not give us a solution for out"
      },
      {
        "start": 1543.679,
        "duration": 5.561,
        "text": "of the box however there's uh at least"
      },
      {
        "start": 1547.36,
        "duration": 4.76,
        "text": "one uh"
      },
      {
        "start": 1549.24,
        "duration": 7.2,
        "text": "fairly uh mature Library out there for"
      },
      {
        "start": 1552.12,
        "duration": 6.279,
        "text": "using linux's IO uring uh async IO"
      },
      {
        "start": 1556.44,
        "duration": 5.119,
        "text": "interface from java"
      },
      {
        "start": 1558.399,
        "duration": 4.441,
        "text": "uh and so I think uh this is the part"
      },
      {
        "start": 1561.559,
        "duration": 3.36,
        "text": "that I'm not sure about because I"
      },
      {
        "start": 1562.84,
        "duration": 4.0,
        "text": "haven't written the code yet but I think"
      },
      {
        "start": 1564.919,
        "duration": 6.201,
        "text": "that the next step is going to be doing"
      },
      {
        "start": 1566.84,
        "duration": 6.8,
        "text": "async iio on top of IOU ring and uh and"
      },
      {
        "start": 1571.12,
        "duration": 4.72,
        "text": "we'll see whether that makes J Vector"
      },
      {
        "start": 1573.64,
        "duration": 3.919,
        "text": "change its interface or not uh we may be"
      },
      {
        "start": 1575.84,
        "duration": 4.199,
        "text": "able to fit it into the same interface"
      },
      {
        "start": 1577.559,
        "duration": 6.48,
        "text": "but it may it may require changes the"
      },
      {
        "start": 1580.039,
        "duration": 7.041,
        "text": "quest of improvements never HS yep yeah"
      },
      {
        "start": 1584.039,
        "duration": 6.081,
        "text": "for sure yeah and and if yeah if you"
      },
      {
        "start": 1587.08,
        "duration": 5.36,
        "text": "haven't taken look at IOU ring uh in a"
      },
      {
        "start": 1590.12,
        "duration": 4.439,
        "text": "few years it's been it's been making"
      },
      {
        "start": 1592.44,
        "duration": 8.2,
        "text": "almost as much progress as the jdk it"
      },
      {
        "start": 1594.559,
        "duration": 8.84,
        "text": "it's really a lot it reminds me of when"
      },
      {
        "start": 1600.64,
        "duration": 8.12,
        "text": "Cassandra was young uh that you know"
      },
      {
        "start": 1603.399,
        "duration": 8.121,
        "text": "every every new uh big user uh pushed it"
      },
      {
        "start": 1608.76,
        "duration": 4.799,
        "text": "in in directions that it hadn't gone"
      },
      {
        "start": 1611.52,
        "duration": 3.84,
        "text": "before so when when Netflix started"
      },
      {
        "start": 1613.559,
        "duration": 3.641,
        "text": "using it we added you know features that"
      },
      {
        "start": 1615.36,
        "duration": 5.0,
        "text": "Netflix needed when Spotify started"
      },
      {
        "start": 1617.2,
        "duration": 6.0,
        "text": "using it same story um that's been"
      },
      {
        "start": 1620.36,
        "duration": 5.319,
        "text": "driven the Linux kernel is is driving in"
      },
      {
        "start": 1623.2,
        "duration": 8.28,
        "text": "the same way because everybody needs"
      },
      {
        "start": 1625.679,
        "duration": 8.041,
        "text": "fast asynchronous dis iio and uh yeah"
      },
      {
        "start": 1631.48,
        "duration": 4.64,
        "text": "it's just been a very"
      },
      {
        "start": 1633.72,
        "duration": 5.959,
        "text": "practically motivated set of"
      },
      {
        "start": 1636.12,
        "duration": 5.6,
        "text": "improvements wonderful I guess um we"
      },
      {
        "start": 1639.679,
        "duration": 5.081,
        "text": "definitely will have to have Jonathan"
      },
      {
        "start": 1641.72,
        "duration": 6.839,
        "text": "back for another episode or more right"
      },
      {
        "start": 1644.76,
        "duration": 7.639,
        "text": "and we'll go even deeper into J Vector"
      },
      {
        "start": 1648.559,
        "duration": 6.72,
        "text": "um I'd love to yeah uh display this QR"
      },
      {
        "start": 1652.399,
        "duration": 6.241,
        "text": "code here uh that's the J Vector GitHub"
      },
      {
        "start": 1655.279,
        "duration": 5.961,
        "text": "repot uh so folks please uh sign up and"
      },
      {
        "start": 1658.64,
        "duration": 5.6,
        "text": "and or not sign up but like follow that"
      },
      {
        "start": 1661.24,
        "duration": 5.799,
        "text": "out and star follow and watch and do all"
      },
      {
        "start": 1664.24,
        "duration": 5.76,
        "text": "that you can this is a great uh and then"
      },
      {
        "start": 1667.039,
        "duration": 5.76,
        "text": "also before we go too uh we would like"
      },
      {
        "start": 1670.0,
        "duration": 2.799,
        "text": "to share"
      },
      {
        "start": 1674.88,
        "duration": 6.919,
        "text": "this running on G Vector now"
      },
      {
        "start": 1678.36,
        "duration": 5.799,
        "text": "Java 21 so that's right yeah okay so"
      },
      {
        "start": 1681.799,
        "duration": 6.201,
        "text": "don't forget to sign up for us for our"
      },
      {
        "start": 1684.159,
        "duration": 5.601,
        "text": "extra DB so yeah so with that I think"
      },
      {
        "start": 1688.0,
        "duration": 3.32,
        "text": "yeah there's definitely you know more"
      },
      {
        "start": 1689.76,
        "duration": 4.159,
        "text": "stuff to talk about and I learned so"
      },
      {
        "start": 1691.32,
        "duration": 5.0,
        "text": "much just within less than 30 minutes"
      },
      {
        "start": 1693.919,
        "duration": 4.76,
        "text": "and that this has been amazing thank you"
      },
      {
        "start": 1696.32,
        "duration": 4.44,
        "text": "so much John absolutely yeah thanks"
      },
      {
        "start": 1698.679,
        "duration": 3.921,
        "text": "again for having me thank you thank you"
      },
      {
        "start": 1700.76,
        "duration": 5.519,
        "text": "and thanks Aaron and thanks Cedric yeah"
      },
      {
        "start": 1702.6,
        "duration": 5.28,
        "text": "too no Jonathan he's the guest thank you"
      },
      {
        "start": 1706.279,
        "duration": 4.161,
        "text": "thank you all right all right goodbye"
      },
      {
        "start": 1707.88,
        "duration": 2.56,
        "text": "everyone"
      },
      {
        "start": 1719.159,
        "duration": 3.0,
        "text": "bye"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T17:34:36.484707+00:00"
}