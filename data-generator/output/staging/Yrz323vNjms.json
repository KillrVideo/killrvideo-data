{
  "video_id": "Yrz323vNjms",
  "title": "DS320.03 Introduction: Spark Shell | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.03 Introduction: Spark Shell\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:25:14Z",
  "thumbnail": "https://i.ytimg.com/vi/Yrz323vNjms/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "introduction",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=Yrz323vNjms",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] earlier i said spark did traditional batch mode analytics computations and also had an interactive mode you can get to know spark interactively through the shell we're going to be using the scala version of the spark shell in this course and that is really the regular scala reple that comes with that language that's the interactive scala execution environment with spark apis and a few objects created for you those are famously the spark context called sc we're going to be using that over and over again the cassandra sql context or the csc and also the hive context or hc we won't touch the hive context much but it is there now if you're interested in exploring python or r there are interactive clients for those too called pi spark and spark r again we'll be focusing on the scala version here starting it is just as easy as that if you're using data stacks enterprise type dse spark and you're in a spark rebel there are of course a number of command line options that say might point you at a particular masternode over the network or limit the amount of memory or cores that might be allocated for computation so here's an example on top of connecting to a remote cluster you see we have to provide a network address of the master node for that shell to connect to and on the bottom you see an example of how to connect to a local master once you're in the spark shell you can execute regular scala code as you see up above and of course interact with the spark context as you see in those two lines down below because the spark shell wants your life to be nice it gives you tab completion to make api exploration just a little simpler and paste mode which is kind of neat if you have a multi-line expression that lets you enter that whole thing with new lines otherwise hitting enter is going to cause the shell to actually interpret each line as a separate expression you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.08,
        "duration": 4.08,
        "text": "earlier i said spark did traditional"
      },
      {
        "start": 8.0,
        "duration": 3.759,
        "text": "batch mode analytics computations and"
      },
      {
        "start": 10.16,
        "duration": 3.2,
        "text": "also had an interactive mode"
      },
      {
        "start": 11.759,
        "duration": 2.96,
        "text": "you can get to know spark interactively"
      },
      {
        "start": 13.36,
        "duration": 1.76,
        "text": "through the shell we're going to be"
      },
      {
        "start": 14.719,
        "duration": 2.881,
        "text": "using"
      },
      {
        "start": 15.12,
        "duration": 3.28,
        "text": "the scala version of the spark shell in"
      },
      {
        "start": 17.6,
        "duration": 2.8,
        "text": "this course"
      },
      {
        "start": 18.4,
        "duration": 3.68,
        "text": "and that is really the regular scala"
      },
      {
        "start": 20.4,
        "duration": 3.84,
        "text": "reple that comes with that language"
      },
      {
        "start": 22.08,
        "duration": 3.199,
        "text": "that's the interactive scala execution"
      },
      {
        "start": 24.24,
        "duration": 4.16,
        "text": "environment with"
      },
      {
        "start": 25.279,
        "duration": 3.441,
        "text": "spark apis and a few objects created for"
      },
      {
        "start": 28.4,
        "duration": 2.4,
        "text": "you"
      },
      {
        "start": 28.72,
        "duration": 3.76,
        "text": "those are famously the spark context"
      },
      {
        "start": 30.8,
        "duration": 4.4,
        "text": "called sc we're going to be using that"
      },
      {
        "start": 32.48,
        "duration": 4.56,
        "text": "over and over again the cassandra sql"
      },
      {
        "start": 35.2,
        "duration": 4.96,
        "text": "context or the csc"
      },
      {
        "start": 37.04,
        "duration": 4.96,
        "text": "and also the hive context or hc we won't"
      },
      {
        "start": 40.16,
        "duration": 2.559,
        "text": "touch the hive context much but it is"
      },
      {
        "start": 42.0,
        "duration": 2.079,
        "text": "there"
      },
      {
        "start": 42.719,
        "duration": 3.601,
        "text": "now if you're interested in exploring"
      },
      {
        "start": 44.079,
        "duration": 4.081,
        "text": "python or r there are interactive"
      },
      {
        "start": 46.32,
        "duration": 2.32,
        "text": "clients for those too called pi spark"
      },
      {
        "start": 48.16,
        "duration": 3.039,
        "text": "and"
      },
      {
        "start": 48.64,
        "duration": 3.84,
        "text": "spark r again we'll be focusing on the"
      },
      {
        "start": 51.199,
        "duration": 3.601,
        "text": "scala version here"
      },
      {
        "start": 52.48,
        "duration": 4.079,
        "text": "starting it is just as easy as that if"
      },
      {
        "start": 54.8,
        "duration": 4.96,
        "text": "you're using data stacks enterprise type"
      },
      {
        "start": 56.559,
        "duration": 4.48,
        "text": "dse spark and you're in a spark rebel"
      },
      {
        "start": 59.76,
        "duration": 3.2,
        "text": "there are of course a number of command"
      },
      {
        "start": 61.039,
        "duration": 4.08,
        "text": "line options that say might point you at"
      },
      {
        "start": 62.96,
        "duration": 4.4,
        "text": "a particular masternode over the network"
      },
      {
        "start": 65.119,
        "duration": 4.641,
        "text": "or limit the amount of memory or cores"
      },
      {
        "start": 67.36,
        "duration": 3.92,
        "text": "that might be allocated for computation"
      },
      {
        "start": 69.76,
        "duration": 3.52,
        "text": "so here's an example on top of"
      },
      {
        "start": 71.28,
        "duration": 3.44,
        "text": "connecting to a remote cluster"
      },
      {
        "start": 73.28,
        "duration": 3.12,
        "text": "you see we have to provide a network"
      },
      {
        "start": 74.72,
        "duration": 2.8,
        "text": "address of the master node for that"
      },
      {
        "start": 76.4,
        "duration": 3.12,
        "text": "shell to connect to"
      },
      {
        "start": 77.52,
        "duration": 3.919,
        "text": "and on the bottom you see an example of"
      },
      {
        "start": 79.52,
        "duration": 3.36,
        "text": "how to connect to a local master"
      },
      {
        "start": 81.439,
        "duration": 3.36,
        "text": "once you're in the spark shell you can"
      },
      {
        "start": 82.88,
        "duration": 2.48,
        "text": "execute regular scala code as you see up"
      },
      {
        "start": 84.799,
        "duration": 2.401,
        "text": "above"
      },
      {
        "start": 85.36,
        "duration": 3.04,
        "text": "and of course interact with the spark"
      },
      {
        "start": 87.2,
        "duration": 3.2,
        "text": "context as you see"
      },
      {
        "start": 88.4,
        "duration": 3.52,
        "text": "in those two lines down below because"
      },
      {
        "start": 90.4,
        "duration": 2.48,
        "text": "the spark shell wants your life to be"
      },
      {
        "start": 91.92,
        "duration": 3.6,
        "text": "nice it gives you"
      },
      {
        "start": 92.88,
        "duration": 3.68,
        "text": "tab completion to make api exploration"
      },
      {
        "start": 95.52,
        "duration": 2.88,
        "text": "just a little simpler"
      },
      {
        "start": 96.56,
        "duration": 3.68,
        "text": "and paste mode which is kind of neat if"
      },
      {
        "start": 98.4,
        "duration": 3.359,
        "text": "you have a multi-line expression"
      },
      {
        "start": 100.24,
        "duration": 3.28,
        "text": "that lets you enter that whole thing"
      },
      {
        "start": 101.759,
        "duration": 2.961,
        "text": "with new lines otherwise"
      },
      {
        "start": 103.52,
        "duration": 3.2,
        "text": "hitting enter is going to cause the"
      },
      {
        "start": 104.72,
        "duration": 9.359,
        "text": "shell to actually interpret each line as"
      },
      {
        "start": 106.72,
        "duration": 9.439,
        "text": "a separate expression"
      },
      {
        "start": 114.079,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:55:42.466674+00:00"
}