{
  "video_id": "0uXJXme8ENQ",
  "title": "Distributed Data Show Episode 54: Graph Processing Trends with Jonathan Lacefield",
  "description": "We sit down with Jonathan Lacefield to discuss the history of DataStax Enterprise Graph, common use cases, and future directions including multi-model enhancements. \n\nHighlights\n0:15 - Welcoming Jonathan back to the show and a quick review of his background in product management\n1:56 - Jonathan gives us a quick overview of graph database history at DataStax - Aurelius, Titan, Apache TinkerPop, Gremlin, and key figures like Marco Rodriguez and Matthias Broecheler\n5:48 - How using Cassandra as the pluggable storage layer for Titan led to the creation of  DataStax Enterprise Graph\n8:40 - The natural relationship between graph processing and analytics/graph analytics. Traditionally this has meant extracting operational data to a separate database for graph analytic processing, but DSE Graph supports both operational and analytic queries, and the trend is toward abstracting the operational/analytic choice from the application developer\n12:35 - DSE Graph has been in 3 releases: 5.0, 5.1, and 6.0. The trend has been toward improving scalability and ease of use. We’re working toward a unified multi-model architecture in which all data can be accessed CQL, Gremlin and Spark SQL.\n17:28 - Problems being solved with graph databases - Customer 360, Authorization, Entity Resolution\n22:22 - Future directions for DSE Graph - continued support for multi-model, hybrid cloud, writing data once and accessing through the right API for the job - CQL, SQL, Gremlin\n25:33 - Privacy is an emerging use case for graph, especially the ability to give users more selective control over what personal data is maintained\n27:37 - Graph query languages like Gremlin, Cypher require a paradigm shift for developers - domain specific languages provide a way to minimize this learning curve\n33:20 - DSE 6 is the foundation for a lot of great things for DSE Graph, and we’d really like your feedback on how to make it even better\n\n\nABOUT DATASTAX ENTERPRISE 6\nDataStax  powers  the  Right-Now  Enterprise  with  ",
  "published_at": "2018-07-03T15:00:01Z",
  "thumbnail": "https://i.ytimg.com/vi/0uXJXme8ENQ/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cql",
    "cassandra",
    "query",
    "database",
    "architecture",
    "dse",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=0uXJXme8ENQ",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems welcome to this week's episode of the distributed data show i'm jeff carpenter with me is jonathan Lacefield hey Joe welcome back to the show we've had you on before um you didn't bring Denise with you this time no she didn't bring you or that's more accurate oh yeah dr. Denise gots no favorite guests of ours but you are both very fond of graph databases and we want to talk with you about what trends we're seeing with graph databases yeah but before we do that I like to set context so we have a little bit of the history of graph databases in general the data stocks take on that involvement with graph databases we have our own product DSC graph can you trace a little bit of that history for me yeah and as part of let me just give some context about my role with with graph databases so Denise is very much on the field she's an expert PhD in graph so I come from a different background I was a solution architect with data stacks for a long time kind of generalist information architect Enterprise Architect and 2016 I took over the product management role for graph right okay product management responsibilities for graph which is great I came out of what we call the field or services from working directly with customers and now trying to solve you know their problems but from our product perspective from within our engineering org and what's really sweet is that I get to either see staffs or more ideally work with a lot of customers in a lot of ways and what's really nice is that I listen so it's not my job to go in and actually fix a problem it's to listen to what what is the problem right it might not be what you first thought right and then you know generalize that back but yeah so with that context you know history of graph databases at data stacks so I think late 2014 early 2015 somewhere around there we purchased a company named Aurelius yes and so Aurelius they did two fundamental things in the graph space and I'm gonna use that term very loosely graph space not just graph database but sure so you know was a small company of experts in computer science and they were solving graph problems and two other major inventions were first Apache tinker pop which is a graph processing framework a lot of tools for graph processing and one of the main ones is the language or API they use to express graph queries which is called gremlin gremlin okay so really just created that but they also had and that was done by dr. Marco Rodriguez and then his partner in Aurelius dr. Matthias and I get him butchers last name I'll give it a shot bro Shiller created a really a prototype in a pioneering distributed graph database so graph databases have a kind of a mixed history if you look in the supercomputing space they kind of have been around for a little while but really they've been around I would say about ten years or so so there's it's a relatively young database category and what Matthias did was look at trends and big data and a sequel and apply distributed processing and combine that with graph problems and he created a distributed graph database open source named Titan okay so there's a distinction that you made they don't want to kind of pick up on a little bit there between graph processing and graph database yeah there's that important to us to understand it is right so graph processing really all the graph pieces have it have the roots inside of you know mat pure mathematics races where Denise shines this is her PhD area focus so I can have data structures that are columns and rows or whatnot and apply graft techniques a classic example here is Google Pagerank PageRank is a graph algorithm it walks across a network and really cares about what we call connectivity and graph how many you know how many views is this page have and how does that influence the popularity of this page and so forth and so forth and it's through a network of thing that's graph processing based in mathematics and that is different than a graph database a graph database is optimized to store data in a data format that makes processing faster or solves a part of that processing problem right okay good so the the idea there and what ticker pop I guess and gremlin are providing us are kind of the tools for expressing those analysis of the relationships that we need to perform for our applications and then we need the storage underneath that that kind of helps optimize that that access and traversing those relationships between nodes yeah good way to think of gremlin is we needed a way to natively Express graph processing yeah against data structures we we needed a way to programmatically do that without having to reinvent that every time kind of like what SQL did for relational databases or clearing rows and columns and tables we needed something like that for graph processing that's what gremlin gives us is a nice API to do just that okay good so yeah so I took us down a digression a little bit but I hopefully kind of helps educate us a little bit more I'm definitely learning things all the time here about the kind of the key elements here in the graph world so take us like there was an acquisition of Aurelius sure then yeah and something with that right inside did a sax Enterprise that's correct yeah yeah no that sums it up we did something boom probably right no what happened is so the Titan codebase Matthias has a great story he tells but the Titan codebase actually came a lot of it out of his PhD work and it's that dormant for a while and then he did start up get back and so what it really is did they looked at data stacks and what they were excited to come to data sacks because we had this distributed data platform and it already solved a lot of the challenges that we're facing with their open source Titan database and really what it comes down to is Titan was a graph database processing engine think of it real simple terms is like a query optimizing engine yeah sitting on top of a pluggable storage engine okay typically Cassandra could be HBase dribbly Berkeley DB yeah and then they had a separate pluggable indexing engine and reason for that and something that's become apparent to me is most graph problems are search problems and we'll come back and revisit that okay thought later yes but all they had all these three different you know broken apart pieces and they saw data stacks with our nice integration already there and they're like holy cow we have an opportunity to work with some top engineers and then we have an opportunity to greenfield our ideas and really take a second full pass at it and so they were excited to come here and that's what they did they took the lessons they learn from building Titan all their customer experiences and you know gremlin is a standard API and it's you you become certified on tinker popping the gremlin from a database vendor perspective right they applied all that and they built DC graph from the from the ground up essentially as a second pass at solving this graph database problem right okay so it sounds like they actually had a workable product that was useful to people but I'm guessing reading between the lines problems of scale is this right like what you know kind of what drove that yeah for that integration with Cassandra and more Search Indexing flexibility etc it was scale but there were also some fundamental challenges with Titan with the consistency and synchronizing data because of all engines your yeah your indexes become could become very out of sync with your data okay and that was a real when it comes out to a fundamental problem a design of having that pluggable architecture and so they had tools that would run they would take your graph offline and okay interesting yeah so the the ability to kind of like read your rights and me have your indexes be up to date in sync right and accurate yes yes yes yeah and then and then from there it is scale and it's processing and by working with within the construct of data stacks we can solve bigger problems so when you look at how we're attacking graph analytics remember we first spoke about graph processing being a thing graph databases being a thing graph processing really happens a lot of it in an analytical construct I need to do something with my full graph or big sub graph yeah so what is it that makes it an analytic problem is it that scope of the fact that you're skimming across your entire data center how do I know yeah it's an analytic sure to to real things there there are again PageRank or finding shortest paths there there are analytical algorithms that I'll want to perform on a graph and to do that would be analogous to finding let's say the most you know most popular people within my network of customers influencers if you will write a very classic connectivity type of algorithm yeah that is very math heavy very computational heavy very analytics heavy if you will okay so that that kind of falls or I need to do a traversal across my entire graph and then one of those things so it's either the size of the data if I need to scan like do a full scan or I'm gonna do something very analytical in nature wouldn't make it a gravity analytics problem okay and what was cool I'll just just to finish that thought out there yeah yeah is because we were you know DSC has deep integration with spark what what traditionally would happen you would pull out this is with most graph database vendors and is still true today with a lot of other graph database vendors a very traditional data architecture thing I have this graph database that was set up to do operational traversals and then I'm gonna extract that full graph put it in something like a Hadoop yes or you know some kind of flat file format and then Rowan Clark graph analytics on it with like sparkle that I need a different processing engine right to an allylic Straub's yeah yeah so what what's sweet so that coming here they're like holy cow you have spark already integrated the data movements already handled I have a way just different really simply isolate workload and my data is already there it's replicated there I can run you know graph analytics without fully extracting all my data on going through that full full problem and if you know if you really look at what Marco was shooting for with gremlin was the ability to have kind of blur the lines between transactionally analytical processing so I have a traversal so we can do that now right right that's exactly right and and maybe this traversal because of the the data size it's going to should be an analytics thing but why are we providing that complication to our users right let's it's a graph processing problem let's let the engine figure out the implementation details for how to execute the process okay excellent so that so we support that now is that you don't necessarily have to be caught that conscious of whether this is a it's we are taking steps to get there so right now we have the ability for a user to write one piece of gremlin and to say I'm going to run it transactional or we run analytics mm-hmm all right and it's literally just how I execute it so if you're using our studio product which I know you you're a fan of I yes big fan literally to say I'm we run a transactional or analytical but yeah we're we're we're heading if you look at a roadmap at how we're releasing software yeah it's very much to take advantage of the unified platform of data stacks so our users wouldn't have to necessarily for simple simple type queries there are times where they would want to be explicit with analytics but where they're heading you know is hey I don't have to think of that complexity is this correct transactional processing or graphing on unix processing it's a graph process i have a graph database it'll handle all the execution for me good good okay so we've started to talk a little bit about some of those future directions but is there anything else that that you want to summarize I know that we've had three releases of DC graph now counting this latest release with DSC six right right so is there any brief history that you want to trace about how that's matured before we kind of look forward into the future yeah so they're probably the first thing to talk about is the first relief of DC graph which is actually with data stacks 500 DEA's okay yep so you know we don't really count graphs separately so it's just dizzy graph I it's part of yes that's right it's been in three data Sox releases right and we've had a really good adoption which is form I rolled wonderful to see so we're getting a lot of great feedback and it's helping to shape our roadmap some of the original assumptions you know going out there really well maybe that's okay because we have the ability to react to that so yeah so over the past almost year and a half almost two years now that graph has been a product you know really looking at features to help it scale and driving those down into our you know our database layer which would be the newest version of Apache Cassandra this is where things like in the latest release 6o where thread procore really helps graph from a processing perspective yeah you're reaping the benefits of those 2x performance improvements absolutely all the advantages of that all the effort which we put into our spark integration things like JDBC and having always-on SQL what's really cool about our spark integration what we're trying to build is really a unified multi model so I saw your data once I can access it through cql through Gremlin through spark spark sequel what-have-you and and we're almost there right today you have a graph model and you're going to access it without the gremlin or analytics but here's what's really cool about what we've done with 6o and our analytic story with spark sequel or if I don't want to use spark sequel just use something more native to spark like scholar I can combine data that's stored in my graph data stored in CQL data I having a flat file stored on DSC FS and process all that together and this is really handy for a big use case of ours which is like us building customer 360s right because that inherent capabilities required to execute entity resolution problems and I know Denise yes about it okay so yeah this is for me this is kind of really helping to flesh out that vision of what a true multi model capability really is it's not just about the fact that I can actually access data using multiple different kind of data models or ways of looking at data but also that let me have this graph processing engine that it's able to do that on our behalf that I don't have to you know be extracting data from one kind of data model and inserting it into the graph so that I can then do graph processing on it it's more really kind of like an integrated product under the hood it is and what the biggest learning for me when I started I sort of dude in 2016 release do you see father huh I started in this role up in stacks almost five years now but graph processing doesn't necessarily mean graph database mm-hmm and we said that in the beginning and what our customers have learned and what we're we're helping to enable is that multi-model story I have a graph problem but I need to solve that with the right tools for each you know breaking down a problem and existing data sources right I don't necessarily need to do everything in grandma okay cool right there are things if I just want to know like simple heuristics of what's in my graph maybe SQL is the right way to go because it's I have a bi tool if I need to do you know so match intensive processing maybe you know analytics would push down into DC search is the right way to go is the right tool I don't necessarily need to do that what the point is a lot you know what I've learned working with customers is that the original thought from a customer is I have a graph problem I need a graph database and what we actually do is we come in and we say look you yes you just is a graph problem or no it's not but most a lot of times it is yes times it is right but hey guess what you don't have to solve that with just the graph database there are better ways to solve some of these problems when we break them down and then leverage the graph for the parts that it's good at okay that makes a lot of sense okay so it sounds like in these customer interactions you get a lot of exposure to what people are the problems that people are trying to solve with graph processing graph databases you know a lot of those requests for new capability roll into you so what are you seeing like what are what are the trends that you see coming up in terms of what people need in this space yeah it's a good question so I would say you know the graph markets still fairly young compared even to no sequel or I hate using big data but like the Hadoop market yeah that's fine but so it's still early days but there's definitely some the graph vendors graph database vendors where we're talking about you know database vendors or processing engines they've helped educate the market on some good canonical graph use cases and we're seeing certainly trends and adopts in there so for instance customer 360s yes fraud from edge section yeah yeah another really interesting use case we're seeing a lot is like permissions or authentication authorization more authorization okay and what we're seeing is particularly for larger companies or digital native offerings from companies so like video game platforms or you know if a company has multiple media channels right how do I control a single users ability to access different pieces okay because you're it's a graph problems you call that an identity manage is it bigger than that it's about access control and it is it is larger than that and I don't know the right term I guess that's kind of my job I need to think on that but we lump it under the bucket of identity management internally yeah but it's really it's it's a network problem at the heart of it that's right and yes I can think of it like groups of interesting problem groups of users I move to a new department and my large IT organization right well permissions should I keep which should go away this is I mean how many times have I been able to access things gone back and been able to access things that I probably should have not been there anymore and I was like yeah let's send an emote of that person make sure I can take it off that access list well then it gets more complicated when you flip it and you add in the the security concerns that companies have today so think think enough from the person level now this is what I love about graphic yes I think from a single document perspective who has access to this document yes okay what departments do they work in who do they know right right is there a chance that you know I have somebody that's gonna leak something out that I don't want to how do I control at the document level and track who has access to that so that's the way that you're actually probably want to manage some of the sensitive documents and artifacts and systems it's from the perspective of the asset itself you're not starting with the people right what's really nice about graph databases so to talk them there is the flexibility to attack a problem I can attack it from the customer I need to set up authorization for them to access the right things but then I can go all the way down to this individual document and traverse my graph and figure out how those two things connect and maybe I need to attack the problem now from the document level up right and very flexible way to do that to model it to access it nice well any what are what other areas ah you know we are really getting into entity resolution a lot and I mentioned that earlier yeah unpack that for those that not familiar with that term yeah the real innocent one sentence the mansplaining version of doing this is how do i how can I tell that two people are different or they are actually the same if I see two traces of a person that maybe a MAC address maybe something from like a you know a thumb reader maybe a signature anything like that how can I tell that this signal this piece of information belongs to it's the same person right right and that's that's very important for really all of these use cases it's seminal because without that piece there's no way I can tell that this person has access that document right if I'm oh there's no way to tell you know I could over count people I could over provision made all sorts of ramifications there but that is something we are solving very and this is why I love Denise on a team he has a PhD this is area study but we are solving really hard problems at scale around it to you another solution and it's it's fun it's challenging and you know as a product managers - frontal for product line it's uh I think it can be very rewarding for us as we look in the future okay so it's interesting to me how many of these use cases are strongly related to you know people and relationships and it just makes it very fun in terms of the practicality of graph processing for solving these kinds of problems so you're out there you're hearing these needs and and new areas in which graph is being applied and what does that mean what are the implications for our product and and where you're going with that yeah I mean I can I can broad brush I can't give you specifics I'll list all the Jiro's - if you want me to but no you me I don't know I guess I could write those down it's you know when you look at what we're doing you know we have our mantra being you know a fantastic cloud database that solves hard problems for companies that are looking to reap the rewards of clouds protect themselves from being beholden to the cloud provider because a lot of times what our customers are telling us that you know they are leveraging infrastructure from their competitor mm-hmm all right claw feathers or yes yes we know who that might be I think right and it's not just one company right but yeah so you know we have this great platform of very flexible hybrid cloud deployments in providing Graaff capabilities on top of that but when you look at what we're doing in this space particularly it gets around what I will use the term multi model capabilities yeah cloak wheelie using the right tool for the job and without requiring you to re transform restore reprocess data so what we're heading is because that's where the mistakes happen oh yeah soon this is near to my heart is an Enterprise Architect kind of background with a focus on data yeah correctness matters and anytime you have to demean you start forking rights doing anything like that you can get out of sync yeah exactly things break things get dropped but you know messages get dropped these things happen right right right so the ability to write that data once and have this this incredible platform distributed and give you fine-grained controls how you want to serve it a globally across multiple data centers but then access data through the right tool is where we're heading so cql gremlin again SQL and really making that a great experience for users so that they can build their applications quickly using the right tools for the job taking an advantage of you know all the thought we put into the platform but also really being able to capitalize on the tools we have because their problems are getting harder connect you know the relationships you spoke about yeah just happening out in the world more and more as we you know put everything online about ourselves we start it car all that kind of stuff boy yeah these are gonna be real you know there were real challenges and people need to solve them quickly and easily because they're being disruptive right and that's that's their direction we're heading is enabling that environment here's a great place to store your data it's gonna be secured globally distributed if controls over that yeah and then you have the ability to again use the right tool for the job without requiring you to rewrite your data so that's really interesting you're mentioning kind of all this data that's being reported about us that were self reporting by using social media and that is being reported about us because of applications and sensors that that we encounter all the time um so is that a problem that graph is gonna be able to help us with it all hey it is in it right uh see you know yeah at an individual level we're starting to see that in Europe is kind of leading the way with GDP are absolutely I you know I yeah we'll leave that for another show but yes so having the ability in GDP are is very explicit I need the ability to get access to all of the data associated with me yes everything I need everything you have on me I want to see it all guess what that is correct problem yes its graph wrong okay and so sweet yes yeah we absolutely are setting up the ability to really control that and provide and enable our excuse me enable our customers control that and right can you delete all that please right right that that's right that's exactly right so but so that's you know for our own control of our own security and privacy huh I think we're gonna see that a lot more because the other interesting part is I'm really seeing how much of our information is being collected by companies by users and what they're trying to do with it which is not from nefarious purposes but if they are collecting it so a lot of a lot of cars like you know ways all that kind of stuff we really do don't think about with IOT sensor based information and having the capability to tie it all to an individual person right keep anonymization is I'm not freaking me out right now no no we know we know that these things are happening and right what the question is you know the the degree to which I trust that my identity is actually being removed from some of these records I'm not so sure that that's happening as much as I would want right but yes so we are enabling both sides of that I was saying yeah okay good so what about the this is how we've been talking about how we see the need evolving over the next few years and some of the new areas that the graph is gonna push more and more into you what needs to happen with the technology or do you see graph databases graph processing going in the next several years yeah the the biggest thing is really the API itself okay so there are two fundamental graph database types there's something called an RDF and there's a property and we're a property graph graph right RDF has a standard language called sparkle and inside the property there are there's kind of the leading standard language which is gremlin used by all sorts of vendors and then there's neo4j cipher which has a couple of vendors associated with the hunt well I I don't think any of working with customers across that whole gambit and going to conferences and speaking with users again you know across the whole game is just to learn there's still a barrier to entry with ever language you want to use if people could just somehow yes use SQL - right okay so this is like because it breaks all the constructs there right yeah that would be different I mean one of the one of the examples that I like to share with people is the example of some of these traversals just like in terms of navigating relationships between people or something like that and you look by comparison at the SQL statements that you would have to write for that and what a mess it is and multiple levels of joins etc and then the simplicity just in terms of the sheer length of the query is much smaller with great ways but if you start to dive into that and if you have a programming background you can look and see this is a fluent API I can I can sort of begin to follow this pattern but I mean there are there is a learning curve because it isn't like something that you've used before right so what do we do right so we're doing a couple of different things there's just the you're helping by the way so thank you okay pure education getting the message out lots of tutorials examples providing a message in as many different ways to be consumable by users as possible right so that's you know that's attacking the problem from an education perspective enablement perspective right the data sex Academy slack room is awesome for that right I don't know if you talk about that but we're on their data section folks are always on this slide you can find us there and you can get feedback and write lots of questions there yes hit us on slack yeah absolutely but then there's also things we're looking at from a language perspective so we mentioned data stack sick so with always-on sparks equal that literally does allow you for very simple things to write SQL against your full set of vertices and full set of edges you we don't want to recreate the environment where you have this terrible 50 join you know nested correlated sub-query type of that's my fancy sequel word by way scenario yeah yeah we're complexities but but we do need to solve this learning curve so one of the things that we are starting to invest in is something we call domain-specific languages yes okay so this is the concept has been around for a while in fact I would say a lot of the BI tools like the old school here's an old bi tool reference before you ever heard of Breo I've not yeah so it was like old old old okay but Business Objects and tableau and all of these tools what they do is essentially provide a semantic layer on top of the data and they abstract all the physical formats so business users analysts give me a customer give me their name right drag and drop yeah we're we're gremlin provides that capability we that was released this past year some point and we're as data stacks is a database provider looking at how do we provide a standard set of these these domain-specific languages for key use cases that we're seeing over and over so instead of having to have some not just the ability for like I know that we've had for a while and that like in Java right the ability to create your own domain-specific language right and that's coming more and more into c-sharp and no does that I think it's Python to flag yeah sorry for those too when we wish driver it is that but you're talking about actually contributing to different industries creation of domain-specific languages that are kind of that we can start standardizing around right and then you know extending yeah yeah certainly one area we're looking at and again it takes the verbosity which is you know not as bad definitely more brief than SQL but for or for folks who are not technical who don't understand you know the Builder patterns and how to write gremlin just customer name babe yes and or you know look up this customer is literally working with the objects and the native languages of our business users so that's that's a big area we're going on so you look at we have this swath of enablement and education and then advantages in the product itself either accessing graph data through more natural for very simple traversals or queries or lookups SQL how do we extend and build on top of gremlins DSL to enable our business users to have a nice tool a nice way to interact with with data as well right good ease of use is is everything education and ease of use right getting people to where they can be productive right so you have any final thoughts for us um no I think yeah so I think this is gonna be a very exciting I get excited there and I knew it yeah I got like 80 oh yeah I'm really excited now that DSE six o is out yeah we have a lot of really practical but very cool and fundamentally changing technology that's gonna come out here as we look forward 6o is like the foundation and what we're gonna be able to do now and I can't talk about specifics yes yeah okay holy cow it's it's it's going to change the graph space categorically and I'm really excited for that I'm really excited to take part of it and I'm kind of honored and privileged to do that and then also we want to hear feedback oh yes okay I'm I'm on that public slack Channel people can always reach me it's at J Lacefield I'm pretty heavy participant in our Stack Overflow as well and Denise same way she also my partner in crime want to hear that feedback from the users customers be great excellent and that's anything from how does this work or teach me how to do this to you I think this might be a bug this might be broken or there's a rough edge here that yeah I need to help me out help me out with and you do it all and then even what we really love is when people just talk about their problems is this a graph problem or not alright does this require graph database yeah cuz those are great conversations are very very meaningful yeah excellent well I appreciate all that you're doing in the graph space in particular and appreciate having you on again and we would like to call first dibs on when you have things that you can share about where graph is going and future releases come back we will talk you've talked about you don't have to wait that long like if yeah you don't have to wait until the next release comes out but it's fine whenever we'd love to have you on thank you very much yeah thanks have your people call my people oh great thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data Stax Academy and tell us what you think you can also find us on the data Stax Academy YouTube channel or find our podcast on iTunes Google Play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode you [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.37,
        "duration": 4.11,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.48,
        "duration": 4.17,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.55,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.16,
        "text": "large-scale distributed systems welcome"
      },
      {
        "start": 17.01,
        "duration": 3.81,
        "text": "to this week's episode of the"
      },
      {
        "start": 18.81,
        "duration": 4.92,
        "text": "distributed data show i'm jeff carpenter"
      },
      {
        "start": 20.82,
        "duration": 4.619,
        "text": "with me is jonathan Lacefield hey Joe"
      },
      {
        "start": 23.73,
        "duration": 3.78,
        "text": "welcome back to the show we've had you"
      },
      {
        "start": 25.439,
        "duration": 3.901,
        "text": "on before um you didn't bring Denise"
      },
      {
        "start": 27.51,
        "duration": 4.56,
        "text": "with you this time no she didn't bring"
      },
      {
        "start": 29.34,
        "duration": 4.739,
        "text": "you or that's more accurate oh yeah dr."
      },
      {
        "start": 32.07,
        "duration": 6.03,
        "text": "Denise gots no favorite guests of ours"
      },
      {
        "start": 34.079,
        "duration": 5.64,
        "text": "but you are both very fond of graph"
      },
      {
        "start": 38.1,
        "duration": 4.29,
        "text": "databases and we want to talk with you"
      },
      {
        "start": 39.719,
        "duration": 5.43,
        "text": "about what trends we're seeing with"
      },
      {
        "start": 42.39,
        "duration": 5.579,
        "text": "graph databases yeah but before we do"
      },
      {
        "start": 45.149,
        "duration": 5.551,
        "text": "that I like to set context so we have a"
      },
      {
        "start": 47.969,
        "duration": 5.25,
        "text": "little bit of the history of graph"
      },
      {
        "start": 50.7,
        "duration": 4.589,
        "text": "databases in general the data stocks"
      },
      {
        "start": 53.219,
        "duration": 4.081,
        "text": "take on that involvement with graph"
      },
      {
        "start": 55.289,
        "duration": 3.36,
        "text": "databases we have our own product DSC"
      },
      {
        "start": 57.3,
        "duration": 3.419,
        "text": "graph can you trace a little bit of that"
      },
      {
        "start": 58.649,
        "duration": 3.93,
        "text": "history for me yeah and as part of let"
      },
      {
        "start": 60.719,
        "duration": 3.87,
        "text": "me just give some context about my role"
      },
      {
        "start": 62.579,
        "duration": 3.571,
        "text": "with with graph databases so Denise is"
      },
      {
        "start": 64.589,
        "duration": 3.39,
        "text": "very much on the field she's an expert"
      },
      {
        "start": 66.15,
        "duration": 3.36,
        "text": "PhD in graph so I come from a different"
      },
      {
        "start": 67.979,
        "duration": 3.301,
        "text": "background I was a solution architect"
      },
      {
        "start": 69.51,
        "duration": 3.84,
        "text": "with data stacks for a long time kind of"
      },
      {
        "start": 71.28,
        "duration": 6.18,
        "text": "generalist information architect"
      },
      {
        "start": 73.35,
        "duration": 5.46,
        "text": "Enterprise Architect and 2016 I took"
      },
      {
        "start": 77.46,
        "duration": 3.39,
        "text": "over the product management role for"
      },
      {
        "start": 78.81,
        "duration": 3.3,
        "text": "graph right okay product management"
      },
      {
        "start": 80.85,
        "duration": 3.33,
        "text": "responsibilities for graph which is"
      },
      {
        "start": 82.11,
        "duration": 4.049,
        "text": "great I came out of what we call the"
      },
      {
        "start": 84.18,
        "duration": 4.02,
        "text": "field or services from working directly"
      },
      {
        "start": 86.159,
        "duration": 4.231,
        "text": "with customers and now trying to solve"
      },
      {
        "start": 88.2,
        "duration": 3.57,
        "text": "you know their problems but from our"
      },
      {
        "start": 90.39,
        "duration": 3.45,
        "text": "product perspective from within our"
      },
      {
        "start": 91.77,
        "duration": 5.16,
        "text": "engineering org and what's really sweet"
      },
      {
        "start": 93.84,
        "duration": 5.13,
        "text": "is that I get to either see staffs or"
      },
      {
        "start": 96.93,
        "duration": 4.74,
        "text": "more ideally work with a lot of"
      },
      {
        "start": 98.97,
        "duration": 5.039,
        "text": "customers in a lot of ways and what's"
      },
      {
        "start": 101.67,
        "duration": 5.04,
        "text": "really nice is that I listen so it's not"
      },
      {
        "start": 104.009,
        "duration": 5.311,
        "text": "my job to go in and actually fix a"
      },
      {
        "start": 106.71,
        "duration": 4.35,
        "text": "problem it's to listen to what what is"
      },
      {
        "start": 109.32,
        "duration": 3.57,
        "text": "the problem right it might not be what"
      },
      {
        "start": 111.06,
        "duration": 3.379,
        "text": "you first thought right and then you"
      },
      {
        "start": 112.89,
        "duration": 4.2,
        "text": "know generalize that back but yeah so"
      },
      {
        "start": 114.439,
        "duration": 5.831,
        "text": "with that context you know history of"
      },
      {
        "start": 117.09,
        "duration": 5.96,
        "text": "graph databases at data stacks so I"
      },
      {
        "start": 120.27,
        "duration": 5.78,
        "text": "think late 2014"
      },
      {
        "start": 123.05,
        "duration": 5.19,
        "text": "early 2015 somewhere around there we"
      },
      {
        "start": 126.05,
        "duration": 8.37,
        "text": "purchased a company named Aurelius yes"
      },
      {
        "start": 128.24,
        "duration": 9.0,
        "text": "and so Aurelius they did two fundamental"
      },
      {
        "start": 134.42,
        "duration": 4.38,
        "text": "things in the graph space and I'm gonna"
      },
      {
        "start": 137.24,
        "duration": 5.46,
        "text": "use that term very loosely graph space"
      },
      {
        "start": 138.8,
        "duration": 6.78,
        "text": "not just graph database but sure so you"
      },
      {
        "start": 142.7,
        "duration": 4.98,
        "text": "know was a small company of experts in"
      },
      {
        "start": 145.58,
        "duration": 4.26,
        "text": "computer science and they were solving"
      },
      {
        "start": 147.68,
        "duration": 5.04,
        "text": "graph problems and two other major"
      },
      {
        "start": 149.84,
        "duration": 5.58,
        "text": "inventions were first Apache tinker pop"
      },
      {
        "start": 152.72,
        "duration": 4.98,
        "text": "which is a graph processing framework a"
      },
      {
        "start": 155.42,
        "duration": 4.92,
        "text": "lot of tools for graph processing and"
      },
      {
        "start": 157.7,
        "duration": 5.49,
        "text": "one of the main ones is the language or"
      },
      {
        "start": 160.34,
        "duration": 5.19,
        "text": "API they use to express graph"
      },
      {
        "start": 163.19,
        "duration": 4.29,
        "text": "queries which is called gremlin gremlin"
      },
      {
        "start": 165.53,
        "duration": 4.56,
        "text": "okay so really just created that but"
      },
      {
        "start": 167.48,
        "duration": 6.66,
        "text": "they also had and that was done by dr."
      },
      {
        "start": 170.09,
        "duration": 6.6,
        "text": "Marco Rodriguez and then his partner in"
      },
      {
        "start": 174.14,
        "duration": 3.84,
        "text": "Aurelius dr. Matthias and I get him"
      },
      {
        "start": 176.69,
        "duration": 6.12,
        "text": "butchers last name I'll give it a shot"
      },
      {
        "start": 177.98,
        "duration": 6.96,
        "text": "bro Shiller created a really a prototype"
      },
      {
        "start": 182.81,
        "duration": 6.69,
        "text": "in a pioneering distributed graph"
      },
      {
        "start": 184.94,
        "duration": 6.93,
        "text": "database so graph databases have a kind"
      },
      {
        "start": 189.5,
        "duration": 4.56,
        "text": "of a mixed history if you look in the"
      },
      {
        "start": 191.87,
        "duration": 3.93,
        "text": "supercomputing space they kind of have"
      },
      {
        "start": 194.06,
        "duration": 3.3,
        "text": "been around for a little while but"
      },
      {
        "start": 195.8,
        "duration": 4.02,
        "text": "really they've been around I would say"
      },
      {
        "start": 197.36,
        "duration": 5.849,
        "text": "about ten years or so so there's it's a"
      },
      {
        "start": 199.82,
        "duration": 6.18,
        "text": "relatively young database category and"
      },
      {
        "start": 203.209,
        "duration": 4.861,
        "text": "what Matthias did was look at trends and"
      },
      {
        "start": 206.0,
        "duration": 4.92,
        "text": "big data and a sequel and apply"
      },
      {
        "start": 208.07,
        "duration": 4.98,
        "text": "distributed processing and combine that"
      },
      {
        "start": 210.92,
        "duration": 4.289,
        "text": "with graph problems and he created a"
      },
      {
        "start": 213.05,
        "duration": 5.07,
        "text": "distributed graph database open source"
      },
      {
        "start": 215.209,
        "duration": 3.931,
        "text": "named Titan okay so there's a"
      },
      {
        "start": 218.12,
        "duration": 2.49,
        "text": "distinction that you made they don't"
      },
      {
        "start": 219.14,
        "duration": 4.38,
        "text": "want to kind of pick up on a little bit"
      },
      {
        "start": 220.61,
        "duration": 5.73,
        "text": "there between graph processing and graph"
      },
      {
        "start": 223.52,
        "duration": 7.14,
        "text": "database yeah there's that important to"
      },
      {
        "start": 226.34,
        "duration": 6.63,
        "text": "us to understand it is right so graph"
      },
      {
        "start": 230.66,
        "duration": 6.09,
        "text": "processing really all the graph pieces"
      },
      {
        "start": 232.97,
        "duration": 6.12,
        "text": "have it have the roots inside of you"
      },
      {
        "start": 236.75,
        "duration": 5.07,
        "text": "know mat pure mathematics races where"
      },
      {
        "start": 239.09,
        "duration": 5.6,
        "text": "Denise shines this is her PhD area focus"
      },
      {
        "start": 241.82,
        "duration": 4.8,
        "text": "so I can have data structures that are"
      },
      {
        "start": 244.69,
        "duration": 4.18,
        "text": "columns and rows or"
      },
      {
        "start": 246.62,
        "duration": 4.88,
        "text": "whatnot and apply graft techniques a"
      },
      {
        "start": 248.87,
        "duration": 5.699,
        "text": "classic example here is Google Pagerank"
      },
      {
        "start": 251.5,
        "duration": 5.53,
        "text": "PageRank is a graph algorithm it walks"
      },
      {
        "start": 254.569,
        "duration": 4.95,
        "text": "across a network and really cares about"
      },
      {
        "start": 257.03,
        "duration": 3.81,
        "text": "what we call connectivity and graph how"
      },
      {
        "start": 259.519,
        "duration": 2.43,
        "text": "many you know how many views is this"
      },
      {
        "start": 260.84,
        "duration": 3.6,
        "text": "page have and how does that influence"
      },
      {
        "start": 261.949,
        "duration": 4.411,
        "text": "the popularity of this page and so forth"
      },
      {
        "start": 264.44,
        "duration": 3.96,
        "text": "and so forth and it's through a network"
      },
      {
        "start": 266.36,
        "duration": 4.559,
        "text": "of thing that's graph processing based"
      },
      {
        "start": 268.4,
        "duration": 5.28,
        "text": "in mathematics and that is different"
      },
      {
        "start": 270.919,
        "duration": 6.691,
        "text": "than a graph database a graph database"
      },
      {
        "start": 273.68,
        "duration": 11.01,
        "text": "is optimized to store data in a data"
      },
      {
        "start": 277.61,
        "duration": 9.72,
        "text": "format that makes processing faster or"
      },
      {
        "start": 284.69,
        "duration": 5.82,
        "text": "solves a part of that processing problem"
      },
      {
        "start": 287.33,
        "duration": 5.04,
        "text": "right okay good so the the idea there"
      },
      {
        "start": 290.51,
        "duration": 3.659,
        "text": "and what ticker pop I guess and gremlin"
      },
      {
        "start": 292.37,
        "duration": 4.71,
        "text": "are providing us are kind of the tools"
      },
      {
        "start": 294.169,
        "duration": 4.021,
        "text": "for expressing those analysis of the"
      },
      {
        "start": 297.08,
        "duration": 3.45,
        "text": "relationships that we need to perform"
      },
      {
        "start": 298.19,
        "duration": 5.01,
        "text": "for our applications and then we need"
      },
      {
        "start": 300.53,
        "duration": 5.1,
        "text": "the storage underneath that that kind of"
      },
      {
        "start": 303.2,
        "duration": 4.23,
        "text": "helps optimize that that access and"
      },
      {
        "start": 305.63,
        "duration": 3.539,
        "text": "traversing those relationships between"
      },
      {
        "start": 307.43,
        "duration": 5.18,
        "text": "nodes yeah good way to think of gremlin"
      },
      {
        "start": 309.169,
        "duration": 5.941,
        "text": "is we needed a way to natively Express"
      },
      {
        "start": 312.61,
        "duration": 4.84,
        "text": "graph processing yeah against data"
      },
      {
        "start": 315.11,
        "duration": 3.84,
        "text": "structures we we needed a way to"
      },
      {
        "start": 317.45,
        "duration": 3.57,
        "text": "programmatically do that without having"
      },
      {
        "start": 318.95,
        "duration": 5.1,
        "text": "to reinvent that every time kind of like"
      },
      {
        "start": 321.02,
        "duration": 5.82,
        "text": "what SQL did for relational databases or"
      },
      {
        "start": 324.05,
        "duration": 4.619,
        "text": "clearing rows and columns and tables we"
      },
      {
        "start": 326.84,
        "duration": 3.63,
        "text": "needed something like that for graph"
      },
      {
        "start": 328.669,
        "duration": 6.631,
        "text": "processing that's what gremlin gives us"
      },
      {
        "start": 330.47,
        "duration": 7.77,
        "text": "is a nice API to do just that okay good"
      },
      {
        "start": 335.3,
        "duration": 4.71,
        "text": "so yeah so I took us down a digression a"
      },
      {
        "start": 338.24,
        "duration": 3.78,
        "text": "little bit but I hopefully kind of helps"
      },
      {
        "start": 340.01,
        "duration": 3.06,
        "text": "educate us a little bit more I'm"
      },
      {
        "start": 342.02,
        "duration": 4.619,
        "text": "definitely learning things all the time"
      },
      {
        "start": 343.07,
        "duration": 6.93,
        "text": "here about the kind of the key elements"
      },
      {
        "start": 346.639,
        "duration": 5.371,
        "text": "here in the graph world so take us like"
      },
      {
        "start": 350.0,
        "duration": 4.979,
        "text": "there was an acquisition of Aurelius"
      },
      {
        "start": 352.01,
        "duration": 5.82,
        "text": "sure then yeah and something with that"
      },
      {
        "start": 354.979,
        "duration": 5.16,
        "text": "right inside did a sax Enterprise that's"
      },
      {
        "start": 357.83,
        "duration": 6.24,
        "text": "correct yeah yeah no that sums it up we"
      },
      {
        "start": 360.139,
        "duration": 7.771,
        "text": "did something boom probably right no"
      },
      {
        "start": 364.07,
        "duration": 6.33,
        "text": "what happened is so the Titan codebase"
      },
      {
        "start": 367.91,
        "duration": 4.229,
        "text": "Matthias has a great story he tells but"
      },
      {
        "start": 370.4,
        "duration": 4.17,
        "text": "the Titan codebase actually came a lot"
      },
      {
        "start": 372.139,
        "duration": 3.951,
        "text": "of it out of his PhD work and it's that"
      },
      {
        "start": 374.57,
        "duration": 4.04,
        "text": "dormant for a while and then he did"
      },
      {
        "start": 376.09,
        "duration": 4.26,
        "text": "start up get back and so what it really"
      },
      {
        "start": 378.61,
        "duration": 3.45,
        "text": "is did they looked at data stacks and"
      },
      {
        "start": 380.35,
        "duration": 3.69,
        "text": "what they were excited to come to data"
      },
      {
        "start": 382.06,
        "duration": 5.04,
        "text": "sacks because we had this distributed"
      },
      {
        "start": 384.04,
        "duration": 4.26,
        "text": "data platform and it already solved a"
      },
      {
        "start": 387.1,
        "duration": 4.05,
        "text": "lot of the challenges that we're facing"
      },
      {
        "start": 388.3,
        "duration": 4.679,
        "text": "with their open source Titan database"
      },
      {
        "start": 391.15,
        "duration": 4.62,
        "text": "and really what it comes down to is"
      },
      {
        "start": 392.979,
        "duration": 4.651,
        "text": "Titan was a graph database processing"
      },
      {
        "start": 395.77,
        "duration": 3.78,
        "text": "engine think of it real simple terms is"
      },
      {
        "start": 397.63,
        "duration": 4.17,
        "text": "like a query optimizing engine yeah"
      },
      {
        "start": 399.55,
        "duration": 4.619,
        "text": "sitting on top of a pluggable storage"
      },
      {
        "start": 401.8,
        "duration": 4.71,
        "text": "engine okay typically Cassandra could be"
      },
      {
        "start": 404.169,
        "duration": 5.011,
        "text": "HBase dribbly Berkeley DB yeah and then"
      },
      {
        "start": 406.51,
        "duration": 6.15,
        "text": "they had a separate pluggable indexing"
      },
      {
        "start": 409.18,
        "duration": 5.67,
        "text": "engine and reason for that and something"
      },
      {
        "start": 412.66,
        "duration": 4.17,
        "text": "that's become apparent to me is most"
      },
      {
        "start": 414.85,
        "duration": 3.78,
        "text": "graph problems are search problems and"
      },
      {
        "start": 416.83,
        "duration": 3.87,
        "text": "we'll come back and revisit that okay"
      },
      {
        "start": 418.63,
        "duration": 3.599,
        "text": "thought later yes but all they had all"
      },
      {
        "start": 420.7,
        "duration": 3.75,
        "text": "these three different you know broken"
      },
      {
        "start": 422.229,
        "duration": 3.901,
        "text": "apart pieces and they saw data stacks"
      },
      {
        "start": 424.45,
        "duration": 3.87,
        "text": "with our nice integration already there"
      },
      {
        "start": 426.13,
        "duration": 4.02,
        "text": "and they're like holy cow we have an"
      },
      {
        "start": 428.32,
        "duration": 3.63,
        "text": "opportunity to work with some top"
      },
      {
        "start": 430.15,
        "duration": 3.989,
        "text": "engineers and then we have an"
      },
      {
        "start": 431.95,
        "duration": 5.16,
        "text": "opportunity to greenfield our ideas and"
      },
      {
        "start": 434.139,
        "duration": 4.411,
        "text": "really take a second full pass at it and"
      },
      {
        "start": 437.11,
        "duration": 2.91,
        "text": "so they were excited to come here and"
      },
      {
        "start": 438.55,
        "duration": 4.86,
        "text": "that's what they did they took the"
      },
      {
        "start": 440.02,
        "duration": 7.2,
        "text": "lessons they learn from building Titan"
      },
      {
        "start": 443.41,
        "duration": 5.759,
        "text": "all their customer experiences and you"
      },
      {
        "start": 447.22,
        "duration": 4.47,
        "text": "know gremlin is a standard API and it's"
      },
      {
        "start": 449.169,
        "duration": 3.75,
        "text": "you you become certified on tinker"
      },
      {
        "start": 451.69,
        "duration": 2.97,
        "text": "popping the gremlin from a database"
      },
      {
        "start": 452.919,
        "duration": 4.68,
        "text": "vendor perspective right they applied"
      },
      {
        "start": 454.66,
        "duration": 5.069,
        "text": "all that and they built DC graph from"
      },
      {
        "start": 457.599,
        "duration": 3.871,
        "text": "the from the ground up essentially as a"
      },
      {
        "start": 459.729,
        "duration": 4.261,
        "text": "second pass at solving this graph"
      },
      {
        "start": 461.47,
        "duration": 3.81,
        "text": "database problem right okay so it sounds"
      },
      {
        "start": 463.99,
        "duration": 3.989,
        "text": "like they actually had a workable"
      },
      {
        "start": 465.28,
        "duration": 5.04,
        "text": "product that was useful to people but"
      },
      {
        "start": 467.979,
        "duration": 5.071,
        "text": "I'm guessing reading between the lines"
      },
      {
        "start": 470.32,
        "duration": 4.2,
        "text": "problems of scale is this right like"
      },
      {
        "start": 473.05,
        "duration": 4.29,
        "text": "what you know kind of what drove that"
      },
      {
        "start": 474.52,
        "duration": 5.85,
        "text": "yeah for that integration with Cassandra"
      },
      {
        "start": 477.34,
        "duration": 5.25,
        "text": "and more Search Indexing flexibility etc"
      },
      {
        "start": 480.37,
        "duration": 5.97,
        "text": "it was scale but there were also some"
      },
      {
        "start": 482.59,
        "duration": 6.06,
        "text": "fundamental challenges with Titan with"
      },
      {
        "start": 486.34,
        "duration": 5.549,
        "text": "the consistency and synchronizing data"
      },
      {
        "start": 488.65,
        "duration": 5.579,
        "text": "because of all engines your yeah your"
      },
      {
        "start": 491.889,
        "duration": 3.87,
        "text": "indexes become could become very out of"
      },
      {
        "start": 494.229,
        "duration": 3.78,
        "text": "sync with your data okay"
      },
      {
        "start": 495.759,
        "duration": 4.56,
        "text": "and that was a real when it comes out to"
      },
      {
        "start": 498.009,
        "duration": 4.59,
        "text": "a fundamental problem a design of having"
      },
      {
        "start": 500.319,
        "duration": 3.6,
        "text": "that pluggable architecture and so they"
      },
      {
        "start": 502.599,
        "duration": 4.141,
        "text": "had tools that would run they would take"
      },
      {
        "start": 503.919,
        "duration": 5.131,
        "text": "your graph offline and okay interesting"
      },
      {
        "start": 506.74,
        "duration": 4.349,
        "text": "yeah so the the ability to kind of like"
      },
      {
        "start": 509.05,
        "duration": 4.799,
        "text": "read your rights and me have your"
      },
      {
        "start": 511.089,
        "duration": 5.25,
        "text": "indexes be up to date in sync right and"
      },
      {
        "start": 513.849,
        "duration": 4.951,
        "text": "accurate yes yes yes yeah and then and"
      },
      {
        "start": 516.339,
        "duration": 5.76,
        "text": "then from there it is scale and it's"
      },
      {
        "start": 518.8,
        "duration": 5.969,
        "text": "processing and by working with within"
      },
      {
        "start": 522.099,
        "duration": 4.471,
        "text": "the construct of data stacks we can"
      },
      {
        "start": 524.769,
        "duration": 4.641,
        "text": "solve bigger problems so when you look"
      },
      {
        "start": 526.57,
        "duration": 5.49,
        "text": "at how we're attacking graph analytics"
      },
      {
        "start": 529.41,
        "duration": 4.84,
        "text": "remember we first spoke about graph"
      },
      {
        "start": 532.06,
        "duration": 5.31,
        "text": "processing being a thing graph databases"
      },
      {
        "start": 534.25,
        "duration": 6.06,
        "text": "being a thing graph processing really"
      },
      {
        "start": 537.37,
        "duration": 5.01,
        "text": "happens a lot of it in an analytical"
      },
      {
        "start": 540.31,
        "duration": 5.339,
        "text": "construct I need to do something with my"
      },
      {
        "start": 542.38,
        "duration": 5.009,
        "text": "full graph or big sub graph yeah so what"
      },
      {
        "start": 545.649,
        "duration": 3.481,
        "text": "is it that makes it an analytic problem"
      },
      {
        "start": 547.389,
        "duration": 3.39,
        "text": "is it that scope of the fact that you're"
      },
      {
        "start": 549.13,
        "duration": 4.649,
        "text": "skimming across your entire data center"
      },
      {
        "start": 550.779,
        "duration": 6.631,
        "text": "how do I know yeah it's an analytic sure"
      },
      {
        "start": 553.779,
        "duration": 5.851,
        "text": "to to real things there there are again"
      },
      {
        "start": 557.41,
        "duration": 5.19,
        "text": "PageRank or finding shortest paths there"
      },
      {
        "start": 559.63,
        "duration": 6.0,
        "text": "there are analytical algorithms that"
      },
      {
        "start": 562.6,
        "duration": 5.88,
        "text": "I'll want to perform on a graph and to"
      },
      {
        "start": 565.63,
        "duration": 5.939,
        "text": "do that would be analogous to finding"
      },
      {
        "start": 568.48,
        "duration": 6.62,
        "text": "let's say the most you know most popular"
      },
      {
        "start": 571.569,
        "duration": 5.52,
        "text": "people within my network of customers"
      },
      {
        "start": 575.1,
        "duration": 5.56,
        "text": "influencers if you will write a very"
      },
      {
        "start": 577.089,
        "duration": 5.61,
        "text": "classic connectivity type of algorithm"
      },
      {
        "start": 580.66,
        "duration": 4.109,
        "text": "yeah that is very math heavy very"
      },
      {
        "start": 582.699,
        "duration": 4.2,
        "text": "computational heavy very analytics heavy"
      },
      {
        "start": 584.769,
        "duration": 4.56,
        "text": "if you will okay so that that kind of"
      },
      {
        "start": 586.899,
        "duration": 4.531,
        "text": "falls or I need to do a traversal across"
      },
      {
        "start": 589.329,
        "duration": 3.541,
        "text": "my entire graph and then one of those"
      },
      {
        "start": 591.43,
        "duration": 3.719,
        "text": "things so it's either the size of the"
      },
      {
        "start": 592.87,
        "duration": 4.589,
        "text": "data if I need to scan like do a full"
      },
      {
        "start": 595.149,
        "duration": 3.721,
        "text": "scan or I'm gonna do something very"
      },
      {
        "start": 597.459,
        "duration": 3.271,
        "text": "analytical in nature wouldn't make it a"
      },
      {
        "start": 598.87,
        "duration": 3.719,
        "text": "gravity analytics problem okay and what"
      },
      {
        "start": 600.73,
        "duration": 4.589,
        "text": "was cool I'll just just to finish that"
      },
      {
        "start": 602.589,
        "duration": 4.8,
        "text": "thought out there yeah yeah is because"
      },
      {
        "start": 605.319,
        "duration": 3.661,
        "text": "we were you know DSC has deep"
      },
      {
        "start": 607.389,
        "duration": 2.671,
        "text": "integration with spark what what"
      },
      {
        "start": 608.98,
        "duration": 3.9,
        "text": "traditionally would happen you would"
      },
      {
        "start": 610.06,
        "duration": 4.74,
        "text": "pull out this is with most graph"
      },
      {
        "start": 612.88,
        "duration": 3.509,
        "text": "database vendors and is still true today"
      },
      {
        "start": 614.8,
        "duration": 4.11,
        "text": "with a lot of other graph database"
      },
      {
        "start": 616.389,
        "duration": 4.25,
        "text": "vendors a very traditional data"
      },
      {
        "start": 618.91,
        "duration": 3.81,
        "text": "architecture thing I have this graph"
      },
      {
        "start": 620.639,
        "duration": 4.581,
        "text": "database that was set up to do"
      },
      {
        "start": 622.72,
        "duration": 4.239,
        "text": "operational traversals"
      },
      {
        "start": 625.22,
        "duration": 4.229,
        "text": "and then I'm gonna extract that full"
      },
      {
        "start": 626.959,
        "duration": 6.511,
        "text": "graph put it in something like a Hadoop"
      },
      {
        "start": 629.449,
        "duration": 5.611,
        "text": "yes or you know some kind of flat file"
      },
      {
        "start": 633.47,
        "duration": 3.659,
        "text": "format and then Rowan Clark graph"
      },
      {
        "start": 635.06,
        "duration": 4.199,
        "text": "analytics on it with like sparkle that I"
      },
      {
        "start": 637.129,
        "duration": 5.4,
        "text": "need a different processing engine right"
      },
      {
        "start": 639.259,
        "duration": 5.731,
        "text": "to an allylic Straub's yeah"
      },
      {
        "start": 642.529,
        "duration": 3.99,
        "text": "yeah so what what's sweet so that coming"
      },
      {
        "start": 644.99,
        "duration": 3.57,
        "text": "here they're like holy cow you have"
      },
      {
        "start": 646.519,
        "duration": 3.601,
        "text": "spark already integrated the data"
      },
      {
        "start": 648.56,
        "duration": 3.449,
        "text": "movements already handled I have a way"
      },
      {
        "start": 650.12,
        "duration": 4.29,
        "text": "just different really simply isolate"
      },
      {
        "start": 652.009,
        "duration": 4.591,
        "text": "workload and my data is already there"
      },
      {
        "start": 654.41,
        "duration": 4.619,
        "text": "it's replicated there I can run you know"
      },
      {
        "start": 656.6,
        "duration": 3.839,
        "text": "graph analytics without fully extracting"
      },
      {
        "start": 659.029,
        "duration": 4.5,
        "text": "all my data on going through that full"
      },
      {
        "start": 660.439,
        "duration": 4.71,
        "text": "full problem and if you know if you"
      },
      {
        "start": 663.529,
        "duration": 4.79,
        "text": "really look at what Marco was shooting"
      },
      {
        "start": 665.149,
        "duration": 6.081,
        "text": "for with gremlin was the ability to have"
      },
      {
        "start": 668.319,
        "duration": 6.041,
        "text": "kind of blur the lines between"
      },
      {
        "start": 671.23,
        "duration": 5.44,
        "text": "transactionally analytical processing so"
      },
      {
        "start": 674.36,
        "duration": 5.669,
        "text": "I have a traversal so we can do that now"
      },
      {
        "start": 676.67,
        "duration": 5.49,
        "text": "right right that's exactly right and and"
      },
      {
        "start": 680.029,
        "duration": 3.66,
        "text": "maybe this traversal because of the the"
      },
      {
        "start": 682.16,
        "duration": 5.039,
        "text": "data size it's going to should be an"
      },
      {
        "start": 683.689,
        "duration": 5.311,
        "text": "analytics thing but why are we providing"
      },
      {
        "start": 687.199,
        "duration": 4.2,
        "text": "that complication to our users right"
      },
      {
        "start": 689.0,
        "duration": 5.009,
        "text": "let's it's a graph processing problem"
      },
      {
        "start": 691.399,
        "duration": 4.021,
        "text": "let's let the engine figure out the"
      },
      {
        "start": 694.009,
        "duration": 4.68,
        "text": "implementation details for how to"
      },
      {
        "start": 695.42,
        "duration": 5.339,
        "text": "execute the process okay excellent so"
      },
      {
        "start": 698.689,
        "duration": 4.38,
        "text": "that so we support that now is that you"
      },
      {
        "start": 700.759,
        "duration": 4.89,
        "text": "don't necessarily have to be caught that"
      },
      {
        "start": 703.069,
        "duration": 4.801,
        "text": "conscious of whether this is a it's we"
      },
      {
        "start": 705.649,
        "duration": 3.721,
        "text": "are taking steps to get there"
      },
      {
        "start": 707.87,
        "duration": 3.18,
        "text": "so right now we have the ability for a"
      },
      {
        "start": 709.37,
        "duration": 3.42,
        "text": "user to write one piece of gremlin and"
      },
      {
        "start": 711.05,
        "duration": 4.11,
        "text": "to say I'm going to run it transactional"
      },
      {
        "start": 712.79,
        "duration": 4.919,
        "text": "or we run analytics mm-hmm all right and"
      },
      {
        "start": 715.16,
        "duration": 4.109,
        "text": "it's literally just how I execute it so"
      },
      {
        "start": 717.709,
        "duration": 4.32,
        "text": "if you're using our studio product which"
      },
      {
        "start": 719.269,
        "duration": 3.93,
        "text": "I know you you're a fan of I yes big fan"
      },
      {
        "start": 722.029,
        "duration": 3.24,
        "text": "literally to say I'm we run a"
      },
      {
        "start": 723.199,
        "duration": 3.69,
        "text": "transactional or analytical but yeah"
      },
      {
        "start": 725.269,
        "duration": 3.361,
        "text": "we're we're we're heading if you look at"
      },
      {
        "start": 726.889,
        "duration": 4.44,
        "text": "a roadmap at how we're releasing"
      },
      {
        "start": 728.63,
        "duration": 5.069,
        "text": "software yeah it's very much to take"
      },
      {
        "start": 731.329,
        "duration": 4.591,
        "text": "advantage of the unified platform of"
      },
      {
        "start": 733.699,
        "duration": 5.25,
        "text": "data stacks so our users wouldn't have"
      },
      {
        "start": 735.92,
        "duration": 4.44,
        "text": "to necessarily for simple simple type"
      },
      {
        "start": 738.949,
        "duration": 3.901,
        "text": "queries there are times where they would"
      },
      {
        "start": 740.36,
        "duration": 4.56,
        "text": "want to be explicit with analytics but"
      },
      {
        "start": 742.85,
        "duration": 3.33,
        "text": "where they're heading you know is hey I"
      },
      {
        "start": 744.92,
        "duration": 3.269,
        "text": "don't have to think of that complexity"
      },
      {
        "start": 746.18,
        "duration": 3.209,
        "text": "is this correct transactional processing"
      },
      {
        "start": 748.189,
        "duration": 2.4,
        "text": "or graphing on unix processing it's a"
      },
      {
        "start": 749.389,
        "duration": 3.211,
        "text": "graph process i have a graph database"
      },
      {
        "start": 750.589,
        "duration": 5.981,
        "text": "it'll handle all the execution for me"
      },
      {
        "start": 752.6,
        "duration": 5.83,
        "text": "good good okay so we've started to"
      },
      {
        "start": 756.57,
        "duration": 3.6,
        "text": "talk a little bit about some of those"
      },
      {
        "start": 758.43,
        "duration": 3.84,
        "text": "future directions but is there anything"
      },
      {
        "start": 760.17,
        "duration": 5.01,
        "text": "else that that you want to summarize I"
      },
      {
        "start": 762.27,
        "duration": 5.49,
        "text": "know that we've had three releases of DC"
      },
      {
        "start": 765.18,
        "duration": 5.82,
        "text": "graph now counting this latest release"
      },
      {
        "start": 767.76,
        "duration": 4.65,
        "text": "with DSC six right right so is there any"
      },
      {
        "start": 771.0,
        "duration": 3.18,
        "text": "brief history that you want to trace"
      },
      {
        "start": 772.41,
        "duration": 4.02,
        "text": "about how that's matured before we kind"
      },
      {
        "start": 774.18,
        "duration": 4.83,
        "text": "of look forward into the future yeah"
      },
      {
        "start": 776.43,
        "duration": 4.56,
        "text": "so they're probably the first thing to"
      },
      {
        "start": 779.01,
        "duration": 3.98,
        "text": "talk about is the first relief of DC"
      },
      {
        "start": 780.99,
        "duration": 6.42,
        "text": "graph which is actually with data stacks"
      },
      {
        "start": 782.99,
        "duration": 6.85,
        "text": "500 DEA's okay yep so you know we don't"
      },
      {
        "start": 787.41,
        "duration": 4.11,
        "text": "really count graphs separately so it's"
      },
      {
        "start": 789.84,
        "duration": 4.5,
        "text": "just dizzy graph I it's part of yes"
      },
      {
        "start": 791.52,
        "duration": 6.06,
        "text": "that's right it's been in three data Sox"
      },
      {
        "start": 794.34,
        "duration": 5.67,
        "text": "releases right and we've had a really"
      },
      {
        "start": 797.58,
        "duration": 4.26,
        "text": "good adoption which is form I rolled"
      },
      {
        "start": 800.01,
        "duration": 3.69,
        "text": "wonderful to see so we're getting a lot"
      },
      {
        "start": 801.84,
        "duration": 4.05,
        "text": "of great feedback and it's helping to"
      },
      {
        "start": 803.7,
        "duration": 4.11,
        "text": "shape our roadmap some of the original"
      },
      {
        "start": 805.89,
        "duration": 4.44,
        "text": "assumptions you know going out there"
      },
      {
        "start": 807.81,
        "duration": 5.31,
        "text": "really well maybe that's okay because we"
      },
      {
        "start": 810.33,
        "duration": 6.15,
        "text": "have the ability to react to that so"
      },
      {
        "start": 813.12,
        "duration": 5.16,
        "text": "yeah so over the past almost year and a"
      },
      {
        "start": 816.48,
        "duration": 4.41,
        "text": "half almost two years now that graph has"
      },
      {
        "start": 818.28,
        "duration": 5.82,
        "text": "been a product you know really looking"
      },
      {
        "start": 820.89,
        "duration": 6.18,
        "text": "at features to help it scale and driving"
      },
      {
        "start": 824.1,
        "duration": 5.28,
        "text": "those down into our you know our"
      },
      {
        "start": 827.07,
        "duration": 4.68,
        "text": "database layer which would be the newest"
      },
      {
        "start": 829.38,
        "duration": 4.17,
        "text": "version of Apache Cassandra this is"
      },
      {
        "start": 831.75,
        "duration": 6.39,
        "text": "where things like in the latest release"
      },
      {
        "start": 833.55,
        "duration": 7.08,
        "text": "6o where thread procore really helps"
      },
      {
        "start": 838.14,
        "duration": 4.29,
        "text": "graph from a processing perspective yeah"
      },
      {
        "start": 840.63,
        "duration": 5.07,
        "text": "you're reaping the benefits of those 2x"
      },
      {
        "start": 842.43,
        "duration": 5.91,
        "text": "performance improvements absolutely all"
      },
      {
        "start": 845.7,
        "duration": 4.76,
        "text": "the advantages of that all the effort"
      },
      {
        "start": 848.34,
        "duration": 5.78,
        "text": "which we put into our spark integration"
      },
      {
        "start": 850.46,
        "duration": 7.42,
        "text": "things like JDBC and having always-on"
      },
      {
        "start": 854.12,
        "duration": 6.19,
        "text": "SQL what's really cool about our spark"
      },
      {
        "start": 857.88,
        "duration": 4.89,
        "text": "integration what we're trying to build"
      },
      {
        "start": 860.31,
        "duration": 4.08,
        "text": "is really a unified multi model so I saw"
      },
      {
        "start": 862.77,
        "duration": 4.44,
        "text": "your data once I can access it through"
      },
      {
        "start": 864.39,
        "duration": 5.43,
        "text": "cql through Gremlin through spark spark"
      },
      {
        "start": 867.21,
        "duration": 3.63,
        "text": "sequel what-have-you and and we're"
      },
      {
        "start": 869.82,
        "duration": 3.69,
        "text": "almost there"
      },
      {
        "start": 870.84,
        "duration": 3.99,
        "text": "right today you have a graph model and"
      },
      {
        "start": 873.51,
        "duration": 3.42,
        "text": "you're going to access it without the"
      },
      {
        "start": 874.83,
        "duration": 3.33,
        "text": "gremlin or analytics but here's what's"
      },
      {
        "start": 876.93,
        "duration": 4.14,
        "text": "really cool about what we've done with"
      },
      {
        "start": 878.16,
        "duration": 5.43,
        "text": "6o and our analytic story with spark"
      },
      {
        "start": 881.07,
        "duration": 4.02,
        "text": "sequel or if I don't want to use spark"
      },
      {
        "start": 883.59,
        "duration": 3.229,
        "text": "sequel just use something more native to"
      },
      {
        "start": 885.09,
        "duration": 4.07,
        "text": "spark like scholar"
      },
      {
        "start": 886.819,
        "duration": 5.76,
        "text": "I can combine data that's stored in my"
      },
      {
        "start": 889.16,
        "duration": 7.109,
        "text": "graph data stored in CQL data I having a"
      },
      {
        "start": 892.579,
        "duration": 5.61,
        "text": "flat file stored on DSC FS and process"
      },
      {
        "start": 896.269,
        "duration": 4.891,
        "text": "all that together and this is really"
      },
      {
        "start": 898.189,
        "duration": 5.27,
        "text": "handy for a big use case of ours which"
      },
      {
        "start": 901.16,
        "duration": 6.269,
        "text": "is like us building customer 360s right"
      },
      {
        "start": 903.459,
        "duration": 6.1,
        "text": "because that inherent capabilities"
      },
      {
        "start": 907.429,
        "duration": 6.39,
        "text": "required to execute entity resolution"
      },
      {
        "start": 909.559,
        "duration": 5.101,
        "text": "problems and I know Denise yes about it"
      },
      {
        "start": 913.819,
        "duration": 3.96,
        "text": "okay"
      },
      {
        "start": 914.66,
        "duration": 4.709,
        "text": "so yeah this is for me this is kind of"
      },
      {
        "start": 917.779,
        "duration": 4.47,
        "text": "really helping to flesh out that vision"
      },
      {
        "start": 919.369,
        "duration": 4.71,
        "text": "of what a true multi model capability"
      },
      {
        "start": 922.249,
        "duration": 4.95,
        "text": "really is it's not just about the fact"
      },
      {
        "start": 924.079,
        "duration": 5.16,
        "text": "that I can actually access data using"
      },
      {
        "start": 927.199,
        "duration": 3.841,
        "text": "multiple different kind of data models"
      },
      {
        "start": 929.239,
        "duration": 3.63,
        "text": "or ways of looking at data but also that"
      },
      {
        "start": 931.04,
        "duration": 3.63,
        "text": "let me have this graph processing engine"
      },
      {
        "start": 932.869,
        "duration": 4.46,
        "text": "that it's able to do that on our behalf"
      },
      {
        "start": 934.67,
        "duration": 5.579,
        "text": "that I don't have to you know be"
      },
      {
        "start": 937.329,
        "duration": 5.26,
        "text": "extracting data from one kind of data"
      },
      {
        "start": 940.249,
        "duration": 4.56,
        "text": "model and inserting it into the graph so"
      },
      {
        "start": 942.589,
        "duration": 4.5,
        "text": "that I can then do graph processing on"
      },
      {
        "start": 944.809,
        "duration": 4.56,
        "text": "it it's more really kind of like an"
      },
      {
        "start": 947.089,
        "duration": 5.15,
        "text": "integrated product under the hood it is"
      },
      {
        "start": 949.369,
        "duration": 6.0,
        "text": "and what the biggest learning for me"
      },
      {
        "start": 952.239,
        "duration": 4.93,
        "text": "when I started I sort of dude in 2016"
      },
      {
        "start": 955.369,
        "duration": 4.111,
        "text": "release do you see father huh"
      },
      {
        "start": 957.169,
        "duration": 5.371,
        "text": "I started in this role up in stacks"
      },
      {
        "start": 959.48,
        "duration": 4.769,
        "text": "almost five years now but graph"
      },
      {
        "start": 962.54,
        "duration": 4.229,
        "text": "processing doesn't necessarily mean"
      },
      {
        "start": 964.249,
        "duration": 4.981,
        "text": "graph database mm-hmm and we said that"
      },
      {
        "start": 966.769,
        "duration": 4.92,
        "text": "in the beginning and what our customers"
      },
      {
        "start": 969.23,
        "duration": 5.669,
        "text": "have learned and what we're we're"
      },
      {
        "start": 971.689,
        "duration": 6.51,
        "text": "helping to enable is that multi-model"
      },
      {
        "start": 974.899,
        "duration": 6.06,
        "text": "story I have a graph problem but I need"
      },
      {
        "start": 978.199,
        "duration": 4.38,
        "text": "to solve that with the right tools for"
      },
      {
        "start": 980.959,
        "duration": 5.55,
        "text": "each you know breaking down a problem"
      },
      {
        "start": 982.579,
        "duration": 5.55,
        "text": "and existing data sources right I don't"
      },
      {
        "start": 986.509,
        "duration": 4.62,
        "text": "necessarily need to do everything in"
      },
      {
        "start": 988.129,
        "duration": 4.44,
        "text": "grandma okay cool right there are things"
      },
      {
        "start": 991.129,
        "duration": 3.12,
        "text": "if I just want to know like simple"
      },
      {
        "start": 992.569,
        "duration": 4.11,
        "text": "heuristics of what's in my graph maybe"
      },
      {
        "start": 994.249,
        "duration": 6.42,
        "text": "SQL is the right way to go because it's"
      },
      {
        "start": 996.679,
        "duration": 7.171,
        "text": "I have a bi tool if I need to do you"
      },
      {
        "start": 1000.669,
        "duration": 5.76,
        "text": "know so match intensive processing maybe"
      },
      {
        "start": 1003.85,
        "duration": 4.589,
        "text": "you know analytics would push down into"
      },
      {
        "start": 1006.429,
        "duration": 3.421,
        "text": "DC search is the right way to go is the"
      },
      {
        "start": 1008.439,
        "duration": 2.581,
        "text": "right tool I don't necessarily need to"
      },
      {
        "start": 1009.85,
        "duration": 4.44,
        "text": "do that"
      },
      {
        "start": 1011.02,
        "duration": 4.83,
        "text": "what the point is a lot you know what"
      },
      {
        "start": 1014.29,
        "duration": 3.9,
        "text": "I've learned working with customers is"
      },
      {
        "start": 1015.85,
        "duration": 4.32,
        "text": "that the original thought from a"
      },
      {
        "start": 1018.19,
        "duration": 4.05,
        "text": "customer is I have a graph problem I"
      },
      {
        "start": 1020.17,
        "duration": 3.66,
        "text": "need a graph database and what we"
      },
      {
        "start": 1022.24,
        "duration": 3.839,
        "text": "actually do is we come in and we say"
      },
      {
        "start": 1023.83,
        "duration": 4.14,
        "text": "look you yes you just is a graph problem"
      },
      {
        "start": 1026.079,
        "duration": 4.38,
        "text": "or no it's not but most a lot of times"
      },
      {
        "start": 1027.97,
        "duration": 4.65,
        "text": "it is yes times it is right but hey"
      },
      {
        "start": 1030.459,
        "duration": 4.321,
        "text": "guess what you don't have to solve that"
      },
      {
        "start": 1032.62,
        "duration": 4.62,
        "text": "with just the graph database there are"
      },
      {
        "start": 1034.78,
        "duration": 5.789,
        "text": "better ways to solve some of these"
      },
      {
        "start": 1037.24,
        "duration": 5.339,
        "text": "problems when we break them down and"
      },
      {
        "start": 1040.569,
        "duration": 4.861,
        "text": "then leverage the graph for the parts"
      },
      {
        "start": 1042.579,
        "duration": 5.431,
        "text": "that it's good at okay that makes a lot"
      },
      {
        "start": 1045.43,
        "duration": 4.62,
        "text": "of sense okay so it sounds like in these"
      },
      {
        "start": 1048.01,
        "duration": 4.95,
        "text": "customer interactions you get a lot of"
      },
      {
        "start": 1050.05,
        "duration": 4.62,
        "text": "exposure to what people are the problems"
      },
      {
        "start": 1052.96,
        "duration": 3.87,
        "text": "that people are trying to solve with"
      },
      {
        "start": 1054.67,
        "duration": 5.36,
        "text": "graph processing graph databases you"
      },
      {
        "start": 1056.83,
        "duration": 6.06,
        "text": "know a lot of those requests for new"
      },
      {
        "start": 1060.03,
        "duration": 4.57,
        "text": "capability roll into you so what are you"
      },
      {
        "start": 1062.89,
        "duration": 3.48,
        "text": "seeing like what are what are the trends"
      },
      {
        "start": 1064.6,
        "duration": 4.53,
        "text": "that you see coming up in terms of what"
      },
      {
        "start": 1066.37,
        "duration": 3.6,
        "text": "people need in this space yeah it's a"
      },
      {
        "start": 1069.13,
        "duration": 4.8,
        "text": "good question"
      },
      {
        "start": 1069.97,
        "duration": 6.93,
        "text": "so I would say you know the graph"
      },
      {
        "start": 1073.93,
        "duration": 6.51,
        "text": "markets still fairly young compared even"
      },
      {
        "start": 1076.9,
        "duration": 5.79,
        "text": "to no sequel or I hate using big data"
      },
      {
        "start": 1080.44,
        "duration": 4.86,
        "text": "but like the Hadoop market yeah that's"
      },
      {
        "start": 1082.69,
        "duration": 5.09,
        "text": "fine but so it's still early days but"
      },
      {
        "start": 1085.3,
        "duration": 4.8,
        "text": "there's definitely some the graph"
      },
      {
        "start": 1087.78,
        "duration": 3.73,
        "text": "vendors graph database vendors where"
      },
      {
        "start": 1090.1,
        "duration": 3.45,
        "text": "we're talking about you know database"
      },
      {
        "start": 1091.51,
        "duration": 4.1,
        "text": "vendors or processing engines they've"
      },
      {
        "start": 1093.55,
        "duration": 4.65,
        "text": "helped educate the market on some good"
      },
      {
        "start": 1095.61,
        "duration": 4.24,
        "text": "canonical graph use cases and we're"
      },
      {
        "start": 1098.2,
        "duration": 4.64,
        "text": "seeing certainly trends and adopts in"
      },
      {
        "start": 1099.85,
        "duration": 5.52,
        "text": "there so for instance customer 360s yes"
      },
      {
        "start": 1102.84,
        "duration": 4.48,
        "text": "fraud from edge section yeah yeah"
      },
      {
        "start": 1105.37,
        "duration": 6.12,
        "text": "another really interesting use case"
      },
      {
        "start": 1107.32,
        "duration": 7.47,
        "text": "we're seeing a lot is like permissions"
      },
      {
        "start": 1111.49,
        "duration": 5.37,
        "text": "or authentication authorization more"
      },
      {
        "start": 1114.79,
        "duration": 6.74,
        "text": "authorization okay and what we're seeing"
      },
      {
        "start": 1116.86,
        "duration": 8.73,
        "text": "is particularly for larger companies or"
      },
      {
        "start": 1121.53,
        "duration": 8.08,
        "text": "digital native offerings from companies"
      },
      {
        "start": 1125.59,
        "duration": 7.86,
        "text": "so like video game platforms or you know"
      },
      {
        "start": 1129.61,
        "duration": 6.72,
        "text": "if a company has multiple media channels"
      },
      {
        "start": 1133.45,
        "duration": 5.43,
        "text": "right how do I control a single users"
      },
      {
        "start": 1136.33,
        "duration": 4.86,
        "text": "ability to access different pieces okay"
      },
      {
        "start": 1138.88,
        "duration": 3.52,
        "text": "because you're it's a graph problems you"
      },
      {
        "start": 1141.19,
        "duration": 3.94,
        "text": "call that an identity manage"
      },
      {
        "start": 1142.4,
        "duration": 5.04,
        "text": "is it bigger than that it's about access"
      },
      {
        "start": 1145.13,
        "duration": 3.69,
        "text": "control and it is it is larger than that"
      },
      {
        "start": 1147.44,
        "duration": 2.7,
        "text": "and I don't know the right term I guess"
      },
      {
        "start": 1148.82,
        "duration": 4.95,
        "text": "that's kind of my job I need to think on"
      },
      {
        "start": 1150.14,
        "duration": 6.36,
        "text": "that but we lump it under the bucket of"
      },
      {
        "start": 1153.77,
        "duration": 4.98,
        "text": "identity management internally yeah but"
      },
      {
        "start": 1156.5,
        "duration": 5.52,
        "text": "it's really it's it's a network problem"
      },
      {
        "start": 1158.75,
        "duration": 4.59,
        "text": "at the heart of it that's right and yes"
      },
      {
        "start": 1162.02,
        "duration": 3.27,
        "text": "I can think of it like groups of"
      },
      {
        "start": 1163.34,
        "duration": 4.26,
        "text": "interesting problem groups of users I"
      },
      {
        "start": 1165.29,
        "duration": 4.17,
        "text": "move to a new department and my large IT"
      },
      {
        "start": 1167.6,
        "duration": 4.26,
        "text": "organization right well permissions"
      },
      {
        "start": 1169.46,
        "duration": 4.7,
        "text": "should I keep which should go away this"
      },
      {
        "start": 1171.86,
        "duration": 5.61,
        "text": "is I mean how many times have I been"
      },
      {
        "start": 1174.16,
        "duration": 5.53,
        "text": "able to access things gone back and been"
      },
      {
        "start": 1177.47,
        "duration": 4.56,
        "text": "able to access things that I probably"
      },
      {
        "start": 1179.69,
        "duration": 4.02,
        "text": "should have not been there anymore and I"
      },
      {
        "start": 1182.03,
        "duration": 2.88,
        "text": "was like yeah let's send an emote of"
      },
      {
        "start": 1183.71,
        "duration": 3.54,
        "text": "that person make sure I can take it off"
      },
      {
        "start": 1184.91,
        "duration": 4.08,
        "text": "that access list well then it gets more"
      },
      {
        "start": 1187.25,
        "duration": 5.45,
        "text": "complicated when you flip it and you add"
      },
      {
        "start": 1188.99,
        "duration": 6.24,
        "text": "in the the security concerns that"
      },
      {
        "start": 1192.7,
        "duration": 4.39,
        "text": "companies have today so think think"
      },
      {
        "start": 1195.23,
        "duration": 4.26,
        "text": "enough from the person level now this is"
      },
      {
        "start": 1197.09,
        "duration": 4.35,
        "text": "what I love about graphic yes"
      },
      {
        "start": 1199.49,
        "duration": 3.96,
        "text": "I think from a single document"
      },
      {
        "start": 1201.44,
        "duration": 4.8,
        "text": "perspective who has access to this"
      },
      {
        "start": 1203.45,
        "duration": 4.89,
        "text": "document yes okay what departments do"
      },
      {
        "start": 1206.24,
        "duration": 4.17,
        "text": "they work in who do they know right"
      },
      {
        "start": 1208.34,
        "duration": 3.54,
        "text": "right is there a chance that you know I"
      },
      {
        "start": 1210.41,
        "duration": 3.27,
        "text": "have somebody that's gonna leak"
      },
      {
        "start": 1211.88,
        "duration": 4.26,
        "text": "something out that I don't want to how"
      },
      {
        "start": 1213.68,
        "duration": 4.53,
        "text": "do I control at the document level and"
      },
      {
        "start": 1216.14,
        "duration": 4.47,
        "text": "track who has access to that so that's"
      },
      {
        "start": 1218.21,
        "duration": 4.95,
        "text": "the way that you're actually probably"
      },
      {
        "start": 1220.61,
        "duration": 5.19,
        "text": "want to manage some of the sensitive"
      },
      {
        "start": 1223.16,
        "duration": 4.71,
        "text": "documents and artifacts and systems it's"
      },
      {
        "start": 1225.8,
        "duration": 3.87,
        "text": "from the perspective of the asset itself"
      },
      {
        "start": 1227.87,
        "duration": 4.32,
        "text": "you're not starting with the people"
      },
      {
        "start": 1229.67,
        "duration": 6.24,
        "text": "right what's really nice about graph"
      },
      {
        "start": 1232.19,
        "duration": 6.0,
        "text": "databases so to talk them there is the"
      },
      {
        "start": 1235.91,
        "duration": 4.14,
        "text": "flexibility to attack a problem I can"
      },
      {
        "start": 1238.19,
        "duration": 3.99,
        "text": "attack it from the customer I need to"
      },
      {
        "start": 1240.05,
        "duration": 3.51,
        "text": "set up authorization for them to access"
      },
      {
        "start": 1242.18,
        "duration": 3.48,
        "text": "the right things but then I can go all"
      },
      {
        "start": 1243.56,
        "duration": 4.35,
        "text": "the way down to this individual document"
      },
      {
        "start": 1245.66,
        "duration": 4.02,
        "text": "and traverse my graph and figure out how"
      },
      {
        "start": 1247.91,
        "duration": 3.42,
        "text": "those two things connect and maybe I"
      },
      {
        "start": 1249.68,
        "duration": 4.44,
        "text": "need to attack the problem now from the"
      },
      {
        "start": 1251.33,
        "duration": 4.98,
        "text": "document level up right and very"
      },
      {
        "start": 1254.12,
        "duration": 3.0,
        "text": "flexible way to do that to model it to"
      },
      {
        "start": 1256.31,
        "duration": 3.75,
        "text": "access it"
      },
      {
        "start": 1257.12,
        "duration": 5.58,
        "text": "nice well any what are what other areas"
      },
      {
        "start": 1260.06,
        "duration": 4.98,
        "text": "ah you know we are really getting into"
      },
      {
        "start": 1262.7,
        "duration": 3.53,
        "text": "entity resolution a lot and I mentioned"
      },
      {
        "start": 1265.04,
        "duration": 3.58,
        "text": "that earlier"
      },
      {
        "start": 1266.23,
        "duration": 4.25,
        "text": "yeah unpack that for those that"
      },
      {
        "start": 1268.62,
        "duration": 5.07,
        "text": "not familiar with that term yeah the"
      },
      {
        "start": 1270.48,
        "duration": 6.6,
        "text": "real innocent one sentence the"
      },
      {
        "start": 1273.69,
        "duration": 6.33,
        "text": "mansplaining version of doing this is"
      },
      {
        "start": 1277.08,
        "duration": 6.36,
        "text": "how do i how can I tell that two people"
      },
      {
        "start": 1280.02,
        "duration": 5.76,
        "text": "are different or they are actually the"
      },
      {
        "start": 1283.44,
        "duration": 4.77,
        "text": "same if I see two traces of a person"
      },
      {
        "start": 1285.78,
        "duration": 5.16,
        "text": "that maybe a MAC address maybe something"
      },
      {
        "start": 1288.21,
        "duration": 6.48,
        "text": "from like a you know a thumb reader"
      },
      {
        "start": 1290.94,
        "duration": 6.69,
        "text": "maybe a signature anything like that how"
      },
      {
        "start": 1294.69,
        "duration": 5.28,
        "text": "can I tell that this signal this piece"
      },
      {
        "start": 1297.63,
        "duration": 4.77,
        "text": "of information belongs to it's the same"
      },
      {
        "start": 1299.97,
        "duration": 5.49,
        "text": "person right right and that's that's"
      },
      {
        "start": 1302.4,
        "duration": 4.98,
        "text": "very important for really all of these"
      },
      {
        "start": 1305.46,
        "duration": 4.23,
        "text": "use cases it's seminal because without"
      },
      {
        "start": 1307.38,
        "duration": 4.26,
        "text": "that piece there's no way I can tell"
      },
      {
        "start": 1309.69,
        "duration": 4.86,
        "text": "that this person has access that"
      },
      {
        "start": 1311.64,
        "duration": 4.89,
        "text": "document right if I'm oh there's no way"
      },
      {
        "start": 1314.55,
        "duration": 4.379,
        "text": "to tell you know I could over count"
      },
      {
        "start": 1316.53,
        "duration": 5.16,
        "text": "people I could over provision made all"
      },
      {
        "start": 1318.929,
        "duration": 4.621,
        "text": "sorts of ramifications there but that is"
      },
      {
        "start": 1321.69,
        "duration": 4.02,
        "text": "something we are solving very and this"
      },
      {
        "start": 1323.55,
        "duration": 4.83,
        "text": "is why I love Denise on a team he has a"
      },
      {
        "start": 1325.71,
        "duration": 4.74,
        "text": "PhD this is area study but we are"
      },
      {
        "start": 1328.38,
        "duration": 4.08,
        "text": "solving really hard problems at scale"
      },
      {
        "start": 1330.45,
        "duration": 5.04,
        "text": "around it to you another solution and"
      },
      {
        "start": 1332.46,
        "duration": 5.52,
        "text": "it's it's fun it's challenging and you"
      },
      {
        "start": 1335.49,
        "duration": 4.47,
        "text": "know as a product managers - frontal for"
      },
      {
        "start": 1337.98,
        "duration": 3.9,
        "text": "product line it's uh I think it can be"
      },
      {
        "start": 1339.96,
        "duration": 4.29,
        "text": "very rewarding for us as we look in the"
      },
      {
        "start": 1341.88,
        "duration": 5.31,
        "text": "future okay so it's interesting to me"
      },
      {
        "start": 1344.25,
        "duration": 5.76,
        "text": "how many of these use cases are strongly"
      },
      {
        "start": 1347.19,
        "duration": 5.97,
        "text": "related to you know people and"
      },
      {
        "start": 1350.01,
        "duration": 4.89,
        "text": "relationships and it just makes it very"
      },
      {
        "start": 1353.16,
        "duration": 4.86,
        "text": "fun in terms of the practicality of"
      },
      {
        "start": 1354.9,
        "duration": 6.06,
        "text": "graph processing for solving these kinds"
      },
      {
        "start": 1358.02,
        "duration": 5.58,
        "text": "of problems so you're out there you're"
      },
      {
        "start": 1360.96,
        "duration": 5.55,
        "text": "hearing these needs and and new areas in"
      },
      {
        "start": 1363.6,
        "duration": 3.87,
        "text": "which graph is being applied and what"
      },
      {
        "start": 1366.51,
        "duration": 3.33,
        "text": "does that mean what are the implications"
      },
      {
        "start": 1367.47,
        "duration": 4.44,
        "text": "for our product and and where you're"
      },
      {
        "start": 1369.84,
        "duration": 3.41,
        "text": "going with that yeah I mean I can I can"
      },
      {
        "start": 1371.91,
        "duration": 3.899,
        "text": "broad brush I can't give you specifics"
      },
      {
        "start": 1373.25,
        "duration": 7.09,
        "text": "I'll list all the Jiro's - if you want"
      },
      {
        "start": 1375.809,
        "duration": 6.73,
        "text": "me to but no you me I don't know I guess"
      },
      {
        "start": 1380.34,
        "duration": 4.61,
        "text": "I could write those down"
      },
      {
        "start": 1382.539,
        "duration": 6.161,
        "text": "it's you know when you look at what"
      },
      {
        "start": 1384.95,
        "duration": 6.18,
        "text": "we're doing you know we have our mantra"
      },
      {
        "start": 1388.7,
        "duration": 4.56,
        "text": "being you know a fantastic cloud"
      },
      {
        "start": 1391.13,
        "duration": 5.46,
        "text": "database that solves hard problems for"
      },
      {
        "start": 1393.26,
        "duration": 5.82,
        "text": "companies that are looking to reap the"
      },
      {
        "start": 1396.59,
        "duration": 5.219,
        "text": "rewards of clouds protect themselves"
      },
      {
        "start": 1399.08,
        "duration": 4.83,
        "text": "from being beholden to the cloud"
      },
      {
        "start": 1401.809,
        "duration": 4.171,
        "text": "provider because a lot of times what our"
      },
      {
        "start": 1403.91,
        "duration": 3.629,
        "text": "customers are telling us that you know"
      },
      {
        "start": 1405.98,
        "duration": 3.48,
        "text": "they are leveraging infrastructure from"
      },
      {
        "start": 1407.539,
        "duration": 3.961,
        "text": "their competitor mm-hmm all right claw"
      },
      {
        "start": 1409.46,
        "duration": 3.93,
        "text": "feathers or yes yes we know who that"
      },
      {
        "start": 1411.5,
        "duration": 3.39,
        "text": "might be I think right and it's not just"
      },
      {
        "start": 1413.39,
        "duration": 2.82,
        "text": "one company right"
      },
      {
        "start": 1414.89,
        "duration": 3.419,
        "text": "but yeah so you know we have this great"
      },
      {
        "start": 1416.21,
        "duration": 3.99,
        "text": "platform of very flexible hybrid cloud"
      },
      {
        "start": 1418.309,
        "duration": 4.201,
        "text": "deployments in providing Graaff"
      },
      {
        "start": 1420.2,
        "duration": 4.17,
        "text": "capabilities on top of that but when you"
      },
      {
        "start": 1422.51,
        "duration": 4.71,
        "text": "look at what we're doing in this space"
      },
      {
        "start": 1424.37,
        "duration": 4.799,
        "text": "particularly it gets around what I will"
      },
      {
        "start": 1427.22,
        "duration": 4.589,
        "text": "use the term multi model capabilities"
      },
      {
        "start": 1429.169,
        "duration": 5.161,
        "text": "yeah cloak wheelie using the right tool"
      },
      {
        "start": 1431.809,
        "duration": 5.461,
        "text": "for the job and without requiring you to"
      },
      {
        "start": 1434.33,
        "duration": 5.31,
        "text": "re transform restore reprocess data"
      },
      {
        "start": 1437.27,
        "duration": 5.01,
        "text": "so what we're heading is because that's"
      },
      {
        "start": 1439.64,
        "duration": 3.899,
        "text": "where the mistakes happen oh yeah soon"
      },
      {
        "start": 1442.28,
        "duration": 2.82,
        "text": "this is near to my heart is an"
      },
      {
        "start": 1443.539,
        "duration": 2.821,
        "text": "Enterprise Architect kind of background"
      },
      {
        "start": 1445.1,
        "duration": 4.92,
        "text": "with a focus on data"
      },
      {
        "start": 1446.36,
        "duration": 5.46,
        "text": "yeah correctness matters and anytime you"
      },
      {
        "start": 1450.02,
        "duration": 4.2,
        "text": "have to demean you start forking rights"
      },
      {
        "start": 1451.82,
        "duration": 2.849,
        "text": "doing anything like that you can get out"
      },
      {
        "start": 1454.22,
        "duration": 3.329,
        "text": "of sync"
      },
      {
        "start": 1454.669,
        "duration": 4.111,
        "text": "yeah exactly things break things get"
      },
      {
        "start": 1457.549,
        "duration": 2.851,
        "text": "dropped but you know messages get"
      },
      {
        "start": 1458.78,
        "duration": 4.29,
        "text": "dropped these things happen"
      },
      {
        "start": 1460.4,
        "duration": 4.59,
        "text": "right right right so the ability to"
      },
      {
        "start": 1463.07,
        "duration": 5.07,
        "text": "write that data once and have this this"
      },
      {
        "start": 1464.99,
        "duration": 4.47,
        "text": "incredible platform distributed and give"
      },
      {
        "start": 1468.14,
        "duration": 2.909,
        "text": "you fine-grained controls how you want"
      },
      {
        "start": 1469.46,
        "duration": 3.87,
        "text": "to serve it a globally across multiple"
      },
      {
        "start": 1471.049,
        "duration": 5.911,
        "text": "data centers but then access data"
      },
      {
        "start": 1473.33,
        "duration": 7.26,
        "text": "through the right tool is where we're"
      },
      {
        "start": 1476.96,
        "duration": 5.64,
        "text": "heading so cql gremlin again SQL and"
      },
      {
        "start": 1480.59,
        "duration": 3.93,
        "text": "really making that a great experience"
      },
      {
        "start": 1482.6,
        "duration": 3.809,
        "text": "for users so that they can build their"
      },
      {
        "start": 1484.52,
        "duration": 5.33,
        "text": "applications quickly using the right"
      },
      {
        "start": 1486.409,
        "duration": 5.52,
        "text": "tools for the job taking an advantage of"
      },
      {
        "start": 1489.85,
        "duration": 3.67,
        "text": "you know all the thought we put into the"
      },
      {
        "start": 1491.929,
        "duration": 3.99,
        "text": "platform but also really being able to"
      },
      {
        "start": 1493.52,
        "duration": 3.87,
        "text": "capitalize on the tools we have because"
      },
      {
        "start": 1495.919,
        "duration": 3.481,
        "text": "their problems are getting harder"
      },
      {
        "start": 1497.39,
        "duration": 2.49,
        "text": "connect you know the relationships you"
      },
      {
        "start": 1499.4,
        "duration": 2.519,
        "text": "spoke about"
      },
      {
        "start": 1499.88,
        "duration": 4.71,
        "text": "yeah just happening out in the world"
      },
      {
        "start": 1501.919,
        "duration": 4.081,
        "text": "more and more as we you know put"
      },
      {
        "start": 1504.59,
        "duration": 2.35,
        "text": "everything online about ourselves we"
      },
      {
        "start": 1506.0,
        "duration": 3.73,
        "text": "start"
      },
      {
        "start": 1506.94,
        "duration": 4.05,
        "text": "it car all that kind of stuff boy yeah"
      },
      {
        "start": 1509.73,
        "duration": 2.49,
        "text": "these are gonna be real you know there"
      },
      {
        "start": 1510.99,
        "duration": 2.7,
        "text": "were real challenges and people need to"
      },
      {
        "start": 1512.22,
        "duration": 3.06,
        "text": "solve them quickly and easily because"
      },
      {
        "start": 1513.69,
        "duration": 4.08,
        "text": "they're being disruptive right and"
      },
      {
        "start": 1515.28,
        "duration": 4.47,
        "text": "that's that's their direction we're"
      },
      {
        "start": 1517.77,
        "duration": 3.51,
        "text": "heading is enabling that environment"
      },
      {
        "start": 1519.75,
        "duration": 3.69,
        "text": "here's a great place to store your data"
      },
      {
        "start": 1521.28,
        "duration": 4.56,
        "text": "it's gonna be secured globally"
      },
      {
        "start": 1523.44,
        "duration": 4.34,
        "text": "distributed if controls over that yeah"
      },
      {
        "start": 1525.84,
        "duration": 4.53,
        "text": "and then you have the ability to again"
      },
      {
        "start": 1527.78,
        "duration": 4.69,
        "text": "use the right tool for the job without"
      },
      {
        "start": 1530.37,
        "duration": 3.69,
        "text": "requiring you to rewrite your data so"
      },
      {
        "start": 1532.47,
        "duration": 3.06,
        "text": "that's really interesting you're"
      },
      {
        "start": 1534.06,
        "duration": 4.41,
        "text": "mentioning kind of all this data that's"
      },
      {
        "start": 1535.53,
        "duration": 5.58,
        "text": "being reported about us that were self"
      },
      {
        "start": 1538.47,
        "duration": 5.09,
        "text": "reporting by using social media and that"
      },
      {
        "start": 1541.11,
        "duration": 4.89,
        "text": "is being reported about us because of"
      },
      {
        "start": 1543.56,
        "duration": 5.08,
        "text": "applications and sensors that that we"
      },
      {
        "start": 1546.0,
        "duration": 4.83,
        "text": "encounter all the time um so is that a"
      },
      {
        "start": 1548.64,
        "duration": 5.16,
        "text": "problem that graph is gonna be able to"
      },
      {
        "start": 1550.83,
        "duration": 6.15,
        "text": "help us with it all hey it is in it"
      },
      {
        "start": 1553.8,
        "duration": 4.86,
        "text": "right uh see you know yeah at an"
      },
      {
        "start": 1556.98,
        "duration": 4.05,
        "text": "individual level we're starting to see"
      },
      {
        "start": 1558.66,
        "duration": 5.63,
        "text": "that in Europe is kind of leading the"
      },
      {
        "start": 1561.03,
        "duration": 5.04,
        "text": "way with GDP are absolutely I you know I"
      },
      {
        "start": 1564.29,
        "duration": 5.23,
        "text": "yeah we'll leave that for another show"
      },
      {
        "start": 1566.07,
        "duration": 4.29,
        "text": "but yes so having the ability in GDP are"
      },
      {
        "start": 1569.52,
        "duration": 3.45,
        "text": "is very explicit"
      },
      {
        "start": 1570.36,
        "duration": 4.53,
        "text": "I need the ability to get access to all"
      },
      {
        "start": 1572.97,
        "duration": 3.63,
        "text": "of the data associated with me yes"
      },
      {
        "start": 1574.89,
        "duration": 3.39,
        "text": "everything I need everything you have on"
      },
      {
        "start": 1576.6,
        "duration": 4.32,
        "text": "me I want to see it all guess what that"
      },
      {
        "start": 1578.28,
        "duration": 6.51,
        "text": "is correct problem yes its graph wrong"
      },
      {
        "start": 1580.92,
        "duration": 6.39,
        "text": "okay and so sweet yes yeah we absolutely"
      },
      {
        "start": 1584.79,
        "duration": 5.13,
        "text": "are setting up the ability to really"
      },
      {
        "start": 1587.31,
        "duration": 4.83,
        "text": "control that and provide and enable our"
      },
      {
        "start": 1589.92,
        "duration": 3.78,
        "text": "excuse me enable our customers control"
      },
      {
        "start": 1592.14,
        "duration": 2.07,
        "text": "that and right can you delete all that"
      },
      {
        "start": 1593.7,
        "duration": 4.26,
        "text": "please"
      },
      {
        "start": 1594.21,
        "duration": 5.82,
        "text": "right right that that's right that's"
      },
      {
        "start": 1597.96,
        "duration": 3.69,
        "text": "exactly right so but so that's you know"
      },
      {
        "start": 1600.03,
        "duration": 3.36,
        "text": "for our own control of our own security"
      },
      {
        "start": 1601.65,
        "duration": 4.41,
        "text": "and privacy huh I think we're gonna see"
      },
      {
        "start": 1603.39,
        "duration": 3.99,
        "text": "that a lot more because the other"
      },
      {
        "start": 1606.06,
        "duration": 2.91,
        "text": "interesting part is I'm really seeing"
      },
      {
        "start": 1607.38,
        "duration": 4.83,
        "text": "how much of our information is being"
      },
      {
        "start": 1608.97,
        "duration": 4.41,
        "text": "collected by companies by users and what"
      },
      {
        "start": 1612.21,
        "duration": 3.48,
        "text": "they're trying to do with it which is"
      },
      {
        "start": 1613.38,
        "duration": 4.14,
        "text": "not from nefarious purposes but if they"
      },
      {
        "start": 1615.69,
        "duration": 5.37,
        "text": "are collecting it so a lot of a lot of"
      },
      {
        "start": 1617.52,
        "duration": 5.49,
        "text": "cars like you know ways all that kind of"
      },
      {
        "start": 1621.06,
        "duration": 4.77,
        "text": "stuff we really do don't think about"
      },
      {
        "start": 1623.01,
        "duration": 4.74,
        "text": "with IOT sensor based information and"
      },
      {
        "start": 1625.83,
        "duration": 4.67,
        "text": "having the capability to tie it all to"
      },
      {
        "start": 1627.75,
        "duration": 4.63,
        "text": "an individual person right keep"
      },
      {
        "start": 1630.5,
        "duration": 4.009,
        "text": "anonymization is"
      },
      {
        "start": 1632.38,
        "duration": 3.45,
        "text": "I'm not freaking me out right now no no"
      },
      {
        "start": 1634.509,
        "duration": 3.091,
        "text": "we know we know that these things are"
      },
      {
        "start": 1635.83,
        "duration": 5.49,
        "text": "happening and right what the question is"
      },
      {
        "start": 1637.6,
        "duration": 5.549,
        "text": "you know the the degree to which I trust"
      },
      {
        "start": 1641.32,
        "duration": 3.989,
        "text": "that my identity is actually being"
      },
      {
        "start": 1643.149,
        "duration": 4.201,
        "text": "removed from some of these records I'm"
      },
      {
        "start": 1645.309,
        "duration": 5.131,
        "text": "not so sure that that's happening as"
      },
      {
        "start": 1647.35,
        "duration": 6.0,
        "text": "much as I would want right but yes so we"
      },
      {
        "start": 1650.44,
        "duration": 6.63,
        "text": "are enabling both sides of that I was"
      },
      {
        "start": 1653.35,
        "duration": 5.789,
        "text": "saying yeah okay good so what about the"
      },
      {
        "start": 1657.07,
        "duration": 4.859,
        "text": "this is how we've been talking about how"
      },
      {
        "start": 1659.139,
        "duration": 4.53,
        "text": "we see the need evolving over the next"
      },
      {
        "start": 1661.929,
        "duration": 3.421,
        "text": "few years and some of the new areas that"
      },
      {
        "start": 1663.669,
        "duration": 4.171,
        "text": "the graph is gonna push more and more"
      },
      {
        "start": 1665.35,
        "duration": 5.1,
        "text": "into you what needs to happen with the"
      },
      {
        "start": 1667.84,
        "duration": 4.35,
        "text": "technology or do you see graph databases"
      },
      {
        "start": 1670.45,
        "duration": 4.679,
        "text": "graph processing going in the next"
      },
      {
        "start": 1672.19,
        "duration": 7.859,
        "text": "several years yeah the the biggest thing"
      },
      {
        "start": 1675.129,
        "duration": 8.491,
        "text": "is really the API itself okay so there"
      },
      {
        "start": 1680.049,
        "duration": 6.0,
        "text": "are two fundamental graph database types"
      },
      {
        "start": 1683.62,
        "duration": 4.32,
        "text": "there's something called an RDF and"
      },
      {
        "start": 1686.049,
        "duration": 5.88,
        "text": "there's a property and we're a property"
      },
      {
        "start": 1687.94,
        "duration": 6.599,
        "text": "graph graph right RDF has a standard"
      },
      {
        "start": 1691.929,
        "duration": 5.941,
        "text": "language called sparkle and inside the"
      },
      {
        "start": 1694.539,
        "duration": 4.651,
        "text": "property there are there's kind of the"
      },
      {
        "start": 1697.87,
        "duration": 3.57,
        "text": "leading standard language which is"
      },
      {
        "start": 1699.19,
        "duration": 4.17,
        "text": "gremlin used by all sorts of vendors and"
      },
      {
        "start": 1701.44,
        "duration": 3.51,
        "text": "then there's neo4j cipher which has a"
      },
      {
        "start": 1703.36,
        "duration": 6.36,
        "text": "couple of vendors associated with the"
      },
      {
        "start": 1704.95,
        "duration": 6.78,
        "text": "hunt well I I don't think any of working"
      },
      {
        "start": 1709.72,
        "duration": 3.99,
        "text": "with customers across that whole gambit"
      },
      {
        "start": 1711.73,
        "duration": 4.649,
        "text": "and going to conferences and speaking"
      },
      {
        "start": 1713.71,
        "duration": 5.73,
        "text": "with users again you know across the"
      },
      {
        "start": 1716.379,
        "duration": 5.191,
        "text": "whole game is just to learn there's"
      },
      {
        "start": 1719.44,
        "duration": 4.65,
        "text": "still a barrier to entry with ever"
      },
      {
        "start": 1721.57,
        "duration": 8.609,
        "text": "language you want to use if people could"
      },
      {
        "start": 1724.09,
        "duration": 8.85,
        "text": "just somehow yes use SQL - right okay so"
      },
      {
        "start": 1730.179,
        "duration": 4.681,
        "text": "this is like because it breaks all the"
      },
      {
        "start": 1732.94,
        "duration": 3.51,
        "text": "constructs there right yeah that would"
      },
      {
        "start": 1734.86,
        "duration": 3.029,
        "text": "be different I mean one of the one of"
      },
      {
        "start": 1736.45,
        "duration": 4.949,
        "text": "the examples that I like to share with"
      },
      {
        "start": 1737.889,
        "duration": 4.29,
        "text": "people is the example of some of these"
      },
      {
        "start": 1741.399,
        "duration": 2.671,
        "text": "traversals"
      },
      {
        "start": 1742.179,
        "duration": 3.24,
        "text": "just like in terms of navigating"
      },
      {
        "start": 1744.07,
        "duration": 3.449,
        "text": "relationships between people or"
      },
      {
        "start": 1745.419,
        "duration": 4.441,
        "text": "something like that and you look by"
      },
      {
        "start": 1747.519,
        "duration": 3.691,
        "text": "comparison at the SQL statements that"
      },
      {
        "start": 1749.86,
        "duration": 2.939,
        "text": "you would have to write for that and"
      },
      {
        "start": 1751.21,
        "duration": 4.799,
        "text": "what a mess it is and multiple levels of"
      },
      {
        "start": 1752.799,
        "duration": 6.0,
        "text": "joins etc and then the simplicity just"
      },
      {
        "start": 1756.009,
        "duration": 5.55,
        "text": "in terms of the sheer length of the"
      },
      {
        "start": 1758.799,
        "duration": 5.941,
        "text": "query is much smaller with great ways"
      },
      {
        "start": 1761.559,
        "duration": 5.281,
        "text": "but if you start to dive into that"
      },
      {
        "start": 1764.74,
        "duration": 3.84,
        "text": "and if you have a programming background"
      },
      {
        "start": 1766.84,
        "duration": 4.41,
        "text": "you can look and see this is a fluent"
      },
      {
        "start": 1768.58,
        "duration": 6.0,
        "text": "API I can I can sort of begin to follow"
      },
      {
        "start": 1771.25,
        "duration": 5.13,
        "text": "this pattern but I mean there are there"
      },
      {
        "start": 1774.58,
        "duration": 5.09,
        "text": "is a learning curve because it isn't"
      },
      {
        "start": 1776.38,
        "duration": 7.62,
        "text": "like something that you've used before"
      },
      {
        "start": 1779.67,
        "duration": 6.82,
        "text": "right so what do we do right so we're"
      },
      {
        "start": 1784.0,
        "duration": 5.46,
        "text": "doing a couple of different things"
      },
      {
        "start": 1786.49,
        "duration": 5.43,
        "text": "there's just the you're helping by the"
      },
      {
        "start": 1789.46,
        "duration": 4.08,
        "text": "way so thank you okay pure education"
      },
      {
        "start": 1791.92,
        "duration": 3.87,
        "text": "getting the message out lots of"
      },
      {
        "start": 1793.54,
        "duration": 4.41,
        "text": "tutorials examples providing a message"
      },
      {
        "start": 1795.79,
        "duration": 4.59,
        "text": "in as many different ways to be"
      },
      {
        "start": 1797.95,
        "duration": 4.08,
        "text": "consumable by users as possible right so"
      },
      {
        "start": 1800.38,
        "duration": 2.78,
        "text": "that's you know that's attacking the"
      },
      {
        "start": 1802.03,
        "duration": 4.23,
        "text": "problem from an education perspective"
      },
      {
        "start": 1803.16,
        "duration": 5.35,
        "text": "enablement perspective right the data"
      },
      {
        "start": 1806.26,
        "duration": 4.2,
        "text": "sex Academy slack room is awesome for"
      },
      {
        "start": 1808.51,
        "duration": 3.72,
        "text": "that right I don't know if you talk"
      },
      {
        "start": 1810.46,
        "duration": 2.88,
        "text": "about that but we're on their data"
      },
      {
        "start": 1812.23,
        "duration": 3.03,
        "text": "section folks are always on this slide"
      },
      {
        "start": 1813.34,
        "duration": 4.02,
        "text": "you can find us there and you can get"
      },
      {
        "start": 1815.26,
        "duration": 3.9,
        "text": "feedback and write lots of questions"
      },
      {
        "start": 1817.36,
        "duration": 2.58,
        "text": "there yes hit us on slack yeah"
      },
      {
        "start": 1819.16,
        "duration": 2.79,
        "text": "absolutely"
      },
      {
        "start": 1819.94,
        "duration": 3.26,
        "text": "but then there's also things we're"
      },
      {
        "start": 1821.95,
        "duration": 4.83,
        "text": "looking at from a language perspective"
      },
      {
        "start": 1823.2,
        "duration": 6.58,
        "text": "so we mentioned data stack sick so with"
      },
      {
        "start": 1826.78,
        "duration": 5.279,
        "text": "always-on sparks equal that literally"
      },
      {
        "start": 1829.78,
        "duration": 4.59,
        "text": "does allow you for very simple things to"
      },
      {
        "start": 1832.059,
        "duration": 4.861,
        "text": "write SQL against your full set of"
      },
      {
        "start": 1834.37,
        "duration": 3.96,
        "text": "vertices and full set of edges you we"
      },
      {
        "start": 1836.92,
        "duration": 4.889,
        "text": "don't want to recreate the environment"
      },
      {
        "start": 1838.33,
        "duration": 5.82,
        "text": "where you have this terrible 50 join you"
      },
      {
        "start": 1841.809,
        "duration": 5.211,
        "text": "know nested correlated sub-query type of"
      },
      {
        "start": 1844.15,
        "duration": 5.52,
        "text": "that's my fancy sequel word by way"
      },
      {
        "start": 1847.02,
        "duration": 4.81,
        "text": "scenario yeah yeah we're complexities"
      },
      {
        "start": 1849.67,
        "duration": 4.05,
        "text": "but but we do need to solve this"
      },
      {
        "start": 1851.83,
        "duration": 4.83,
        "text": "learning curve so one of the things that"
      },
      {
        "start": 1853.72,
        "duration": 3.99,
        "text": "we are starting to invest in is"
      },
      {
        "start": 1856.66,
        "duration": 5.01,
        "text": "something we call domain-specific"
      },
      {
        "start": 1857.71,
        "duration": 5.58,
        "text": "languages yes okay so this is the"
      },
      {
        "start": 1861.67,
        "duration": 3.27,
        "text": "concept has been around for a while in"
      },
      {
        "start": 1863.29,
        "duration": 4.44,
        "text": "fact I would say a lot of the BI tools"
      },
      {
        "start": 1864.94,
        "duration": 4.02,
        "text": "like the old school here's an old bi"
      },
      {
        "start": 1867.73,
        "duration": 1.62,
        "text": "tool reference before you ever heard of"
      },
      {
        "start": 1868.96,
        "duration": 3.0,
        "text": "Breo"
      },
      {
        "start": 1869.35,
        "duration": 5.73,
        "text": "I've not yeah so it was like old old old"
      },
      {
        "start": 1871.96,
        "duration": 5.01,
        "text": "okay but Business Objects and tableau"
      },
      {
        "start": 1875.08,
        "duration": 3.42,
        "text": "and all of these tools what they do is"
      },
      {
        "start": 1876.97,
        "duration": 3.209,
        "text": "essentially provide a semantic layer on"
      },
      {
        "start": 1878.5,
        "duration": 4.86,
        "text": "top of the data and they abstract all"
      },
      {
        "start": 1880.179,
        "duration": 5.461,
        "text": "the physical formats so business users"
      },
      {
        "start": 1883.36,
        "duration": 4.319,
        "text": "analysts give me a customer give me"
      },
      {
        "start": 1885.64,
        "duration": 5.07,
        "text": "their name right drag and drop yeah"
      },
      {
        "start": 1887.679,
        "duration": 4.961,
        "text": "we're we're gremlin provides that"
      },
      {
        "start": 1890.71,
        "duration": 3.72,
        "text": "capability we"
      },
      {
        "start": 1892.64,
        "duration": 4.44,
        "text": "that was released this past year some"
      },
      {
        "start": 1894.43,
        "duration": 4.99,
        "text": "point and we're as data stacks is a"
      },
      {
        "start": 1897.08,
        "duration": 5.67,
        "text": "database provider looking at how do we"
      },
      {
        "start": 1899.42,
        "duration": 5.37,
        "text": "provide a standard set of these these"
      },
      {
        "start": 1902.75,
        "duration": 3.99,
        "text": "domain-specific languages for key use"
      },
      {
        "start": 1904.79,
        "duration": 3.69,
        "text": "cases that we're seeing over and over so"
      },
      {
        "start": 1906.74,
        "duration": 3.42,
        "text": "instead of having to have some not just"
      },
      {
        "start": 1908.48,
        "duration": 3.36,
        "text": "the ability for like I know that we've"
      },
      {
        "start": 1910.16,
        "duration": 3.3,
        "text": "had for a while and that like in Java"
      },
      {
        "start": 1911.84,
        "duration": 3.3,
        "text": "right the ability to create your own"
      },
      {
        "start": 1913.46,
        "duration": 3.81,
        "text": "domain-specific language right and"
      },
      {
        "start": 1915.14,
        "duration": 5.76,
        "text": "that's coming more and more into c-sharp"
      },
      {
        "start": 1917.27,
        "duration": 6.54,
        "text": "and no does that I think it's Python to"
      },
      {
        "start": 1920.9,
        "duration": 6.0,
        "text": "flag yeah sorry for those too when we"
      },
      {
        "start": 1923.81,
        "duration": 5.88,
        "text": "wish driver it is that but you're"
      },
      {
        "start": 1926.9,
        "duration": 4.29,
        "text": "talking about actually contributing to"
      },
      {
        "start": 1929.69,
        "duration": 3.24,
        "text": "different industries creation of"
      },
      {
        "start": 1931.19,
        "duration": 3.15,
        "text": "domain-specific languages that are kind"
      },
      {
        "start": 1932.93,
        "duration": 3.54,
        "text": "of that we can start standardizing"
      },
      {
        "start": 1934.34,
        "duration": 4.35,
        "text": "around right and then you know extending"
      },
      {
        "start": 1936.47,
        "duration": 4.65,
        "text": "yeah yeah certainly one area we're"
      },
      {
        "start": 1938.69,
        "duration": 5.34,
        "text": "looking at and again it takes the"
      },
      {
        "start": 1941.12,
        "duration": 6.33,
        "text": "verbosity which is you know not as bad"
      },
      {
        "start": 1944.03,
        "duration": 5.07,
        "text": "definitely more brief than SQL but for"
      },
      {
        "start": 1947.45,
        "duration": 4.59,
        "text": "or for folks who are not technical who"
      },
      {
        "start": 1949.1,
        "duration": 4.85,
        "text": "don't understand you know the Builder"
      },
      {
        "start": 1952.04,
        "duration": 5.82,
        "text": "patterns and how to write gremlin just"
      },
      {
        "start": 1953.95,
        "duration": 5.74,
        "text": "customer name babe yes and or you know"
      },
      {
        "start": 1957.86,
        "duration": 3.48,
        "text": "look up this customer is literally"
      },
      {
        "start": 1959.69,
        "duration": 4.98,
        "text": "working with the objects and the native"
      },
      {
        "start": 1961.34,
        "duration": 4.77,
        "text": "languages of our business users so"
      },
      {
        "start": 1964.67,
        "duration": 4.2,
        "text": "that's that's a big area we're going on"
      },
      {
        "start": 1966.11,
        "duration": 5.07,
        "text": "so you look at we have this swath of"
      },
      {
        "start": 1968.87,
        "duration": 4.8,
        "text": "enablement and education and then"
      },
      {
        "start": 1971.18,
        "duration": 5.88,
        "text": "advantages in the product itself either"
      },
      {
        "start": 1973.67,
        "duration": 6.15,
        "text": "accessing graph data through more"
      },
      {
        "start": 1977.06,
        "duration": 4.01,
        "text": "natural for very simple traversals or"
      },
      {
        "start": 1979.82,
        "duration": 4.86,
        "text": "queries or lookups"
      },
      {
        "start": 1981.07,
        "duration": 7.75,
        "text": "SQL how do we extend and build on top of"
      },
      {
        "start": 1984.68,
        "duration": 6.0,
        "text": "gremlins DSL to enable our business"
      },
      {
        "start": 1988.82,
        "duration": 3.75,
        "text": "users to have a nice tool a nice way to"
      },
      {
        "start": 1990.68,
        "duration": 4.59,
        "text": "interact with with data as well right"
      },
      {
        "start": 1992.57,
        "duration": 5.31,
        "text": "good ease of use is is everything"
      },
      {
        "start": 1995.27,
        "duration": 4.01,
        "text": "education and ease of use right getting"
      },
      {
        "start": 1997.88,
        "duration": 3.78,
        "text": "people to where they can be productive"
      },
      {
        "start": 1999.28,
        "duration": 7.54,
        "text": "right so you have any final thoughts for"
      },
      {
        "start": 2001.66,
        "duration": 7.29,
        "text": "us um no I think yeah so I think this is"
      },
      {
        "start": 2006.82,
        "duration": 3.63,
        "text": "gonna be a very exciting I get excited"
      },
      {
        "start": 2008.95,
        "duration": 7.86,
        "text": "there and I knew it yeah I got like 80"
      },
      {
        "start": 2010.45,
        "duration": 9.33,
        "text": "oh yeah I'm really excited now that DSE"
      },
      {
        "start": 2016.81,
        "duration": 8.08,
        "text": "six o is out yeah we have a lot of"
      },
      {
        "start": 2019.78,
        "duration": 7.6,
        "text": "really practical but very cool"
      },
      {
        "start": 2024.89,
        "duration": 4.74,
        "text": "and fundamentally changing technology"
      },
      {
        "start": 2027.38,
        "duration": 5.25,
        "text": "that's gonna come out here as we look"
      },
      {
        "start": 2029.63,
        "duration": 4.74,
        "text": "forward 6o is like the foundation and"
      },
      {
        "start": 2032.63,
        "duration": 3.36,
        "text": "what we're gonna be able to do now and I"
      },
      {
        "start": 2034.37,
        "duration": 4.29,
        "text": "can't talk about specifics yes yeah okay"
      },
      {
        "start": 2035.99,
        "duration": 6.33,
        "text": "holy cow it's it's it's going to change"
      },
      {
        "start": 2038.66,
        "duration": 5.28,
        "text": "the graph space categorically and I'm"
      },
      {
        "start": 2042.32,
        "duration": 3.18,
        "text": "really excited for that I'm really"
      },
      {
        "start": 2043.94,
        "duration": 4.26,
        "text": "excited to take part of it and I'm kind"
      },
      {
        "start": 2045.5,
        "duration": 5.76,
        "text": "of honored and privileged to do that and"
      },
      {
        "start": 2048.2,
        "duration": 4.53,
        "text": "then also we want to hear feedback oh"
      },
      {
        "start": 2051.26,
        "duration": 3.54,
        "text": "yes okay"
      },
      {
        "start": 2052.73,
        "duration": 4.439,
        "text": "I'm I'm on that public slack Channel"
      },
      {
        "start": 2054.8,
        "duration": 4.859,
        "text": "people can always reach me it's at J"
      },
      {
        "start": 2057.169,
        "duration": 4.051,
        "text": "Lacefield I'm pretty heavy participant"
      },
      {
        "start": 2059.659,
        "duration": 4.71,
        "text": "in our Stack Overflow as well"
      },
      {
        "start": 2061.22,
        "duration": 4.949,
        "text": "and Denise same way she also my partner"
      },
      {
        "start": 2064.369,
        "duration": 4.77,
        "text": "in crime want to hear that feedback from"
      },
      {
        "start": 2066.169,
        "duration": 5.7,
        "text": "the users customers be great excellent"
      },
      {
        "start": 2069.139,
        "duration": 4.381,
        "text": "and that's anything from how does this"
      },
      {
        "start": 2071.869,
        "duration": 3.901,
        "text": "work or teach me how to do this to you I"
      },
      {
        "start": 2073.52,
        "duration": 4.139,
        "text": "think this might be a bug this might be"
      },
      {
        "start": 2075.77,
        "duration": 3.81,
        "text": "broken or there's a rough edge here that"
      },
      {
        "start": 2077.659,
        "duration": 3.72,
        "text": "yeah I need to help me out help me out"
      },
      {
        "start": 2079.58,
        "duration": 3.539,
        "text": "with and you do it all and then even"
      },
      {
        "start": 2081.379,
        "duration": 3.091,
        "text": "what we really love is when people just"
      },
      {
        "start": 2083.119,
        "duration": 3.151,
        "text": "talk about their problems is this a"
      },
      {
        "start": 2084.47,
        "duration": 3.389,
        "text": "graph problem or not alright does this"
      },
      {
        "start": 2086.27,
        "duration": 3.42,
        "text": "require graph database yeah cuz those"
      },
      {
        "start": 2087.859,
        "duration": 4.711,
        "text": "are great conversations are very very"
      },
      {
        "start": 2089.69,
        "duration": 4.8,
        "text": "meaningful yeah excellent well I"
      },
      {
        "start": 2092.57,
        "duration": 5.46,
        "text": "appreciate all that you're doing in the"
      },
      {
        "start": 2094.49,
        "duration": 5.52,
        "text": "graph space in particular and appreciate"
      },
      {
        "start": 2098.03,
        "duration": 5.04,
        "text": "having you on again and we would like to"
      },
      {
        "start": 2100.01,
        "duration": 5.19,
        "text": "call first dibs on when you have things"
      },
      {
        "start": 2103.07,
        "duration": 4.95,
        "text": "that you can share about where graph is"
      },
      {
        "start": 2105.2,
        "duration": 3.84,
        "text": "going and future releases come back we"
      },
      {
        "start": 2108.02,
        "duration": 1.8,
        "text": "will talk you've talked about you don't"
      },
      {
        "start": 2109.04,
        "duration": 3.39,
        "text": "have to wait that long"
      },
      {
        "start": 2109.82,
        "duration": 4.289,
        "text": "like if yeah you don't have to wait"
      },
      {
        "start": 2112.43,
        "duration": 2.58,
        "text": "until the next release comes out but"
      },
      {
        "start": 2114.109,
        "duration": 2.821,
        "text": "it's fine"
      },
      {
        "start": 2115.01,
        "duration": 3.54,
        "text": "whenever we'd love to have you on thank"
      },
      {
        "start": 2116.93,
        "duration": 2.46,
        "text": "you very much yeah thanks have your"
      },
      {
        "start": 2118.55,
        "duration": 5.16,
        "text": "people call my people"
      },
      {
        "start": 2119.39,
        "duration": 6.57,
        "text": "oh great thank you for joining us again"
      },
      {
        "start": 2123.71,
        "duration": 3.96,
        "text": "for the distributed data show we love"
      },
      {
        "start": 2125.96,
        "duration": 3.75,
        "text": "your feedback so go to the distributed"
      },
      {
        "start": 2127.67,
        "duration": 3.87,
        "text": "data show page on data Stax Academy and"
      },
      {
        "start": 2129.71,
        "duration": 3.33,
        "text": "tell us what you think you can also find"
      },
      {
        "start": 2131.54,
        "duration": 4.35,
        "text": "us on the data Stax Academy YouTube"
      },
      {
        "start": 2133.04,
        "duration": 4.89,
        "text": "channel or find our podcast on iTunes"
      },
      {
        "start": 2135.89,
        "duration": 4.5,
        "text": "Google Play or wherever you get great"
      },
      {
        "start": 2137.93,
        "duration": 4.17,
        "text": "podcast while you're there make sure and"
      },
      {
        "start": 2140.39,
        "duration": 3.06,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 2142.1,
        "duration": 1.86,
        "text": "episode"
      },
      {
        "start": 2143.45,
        "duration": 3.62,
        "text": "you"
      },
      {
        "start": 2143.96,
        "duration": 3.11,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T06:29:18.965259+00:00"
}