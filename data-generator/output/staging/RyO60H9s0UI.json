{
  "video_id": "RyO60H9s0UI",
  "title": "K8ssandra 1.1 Walkthrough Featuring MinIO Backup",
  "description": "Alexander Dejanovski demonstrates how to install and run the K8ssandra 1.1 release, featuring the ability to do backups with Cassandra Medusa to storage managed by MinIO. For more information see: https://k8ssandra.io/blog/2021/04/09/backing-up-k8ssandra-with-minio/\n\nMORE ON K8SSANDRA\nWebsite: https://k8ssandra.io​\nTwitter: https://twitter.com/k8ssandra​\n\nCONNECT WITH DATASTAX DEVELOPERS\nSubscribe: http://www.youtube.com/c/datastaxdevs?sub_confirmation=1\nTwitter: https://twitter.com/datastaxdevs​\nTwitch: https://www.twitch.tv/datastaxdevs​\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev​ for more free learning resources.",
  "published_at": "2021-04-23T13:59:44Z",
  "thumbnail": "https://i.ytimg.com/vi/RyO60H9s0UI/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "workshop",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "demo",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=RyO60H9s0UI",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "hey folks today i'm going to give you a little demo of kate sandra we're going to see how to deploy kit sandra on a kubernetes cluster how to run multitool commands and check the casino logs we'll see how to access cqlsh and we'll run stress tests using nosql bench we'll see how to check metrics using grafana and then we'll do some scale up operations on stargate and cassandra and we'll run repair using reaper and finally we'll perform some backup and restore operations using medusa so first i'm going to create a cluster on my laptop using kind unlike minicube kind can create kubernetes clusters with several uh worker nodes okay our kubernetes cluster should be up let's check that two moves we have three worker notes in the control plane let's check our spaces okay now first thing we're going to do is install traffic uh using helm traffic is our balancer and reverse proxy for kate sandra and i'm going to use a custom values file which is available in our documentation okay so now i'm going to install minio mineo is an object storage tool which is s3 compatible and runs in kubernetes so i'm gonna install it through helm as well you need some namespace and i'm gonna set some default settings so uh credentials mean i okay in ios secret and i'm gonna ask minajo to create a default bucket named casano meduza upon install okay let's now see what we have in the i mean i o key space namespace so we have a pod and we have service that exposes port 9000 so let's import forward it so that we can access uh the minion ui locally there we go so we have a category medusa bucket uh which is empty i still had a cookie uh on the browser but this is definitely secured now we're going to deploy kate sandra so i'm going to create a kate sandra namespace make it the default for cube ctl and i'm going to uh yeah create uh a secret for medusa to access me nio so it contains the minion credentials indicate sandra namespace okay so it's here there's a bucket key and now we're gonna install kate sandra so i'm gonna add the arcade center helm repo and the update command and install kate sandra in the case center namespace using a custom values file i'm going to show you in a second let's check it here we can see that kidsandra keys namespace is starting to create some pods and services so what are we deploying uh one cassandra data center with two nodes and custom heap sizes so that it fits on my laptop and one stargate pod we're gonna deploy medusa we're gonna deploy reaper and monitoring stack so there we can see that we have two stateful set sds pods which are the casino pods and one stargate pod we have of course caz operator the monitoring stack and medusa and reaper operators i'm gonna run two commands that will help me know when the deployment is fully done so this first command will wait for the cassandra data center object to be ready and the second one will check the rollout of the stargate component well this is starting let's go and check uh the consumer data center resource that was created by cas operator so we can see the events from the lifetime of that data center and the node statuses for now they don't have a host id once the node is ready it gets the host id so it seems like one is running yep so you see the host id there appear here uh and the cluster is still scaling up because we have one node left and you can see you can set our operator progress is updating okay so the percentage is our object is ready let's check again yep we have two host ids and the operator progress is ready now we are waiting for the stargate allowed to complete now stargate rollout is done uh let's see how we can check our center lock so if i try to get the logs from the cassandra pod it's going to tell me that we have several containers so cassandra reducer and server system logger so if you're looking for the system log files from cassandra it's going to be the system logger so logs the pod name the container name and there we have our system logs while the cassandra container outputs the logs from the management api and we also have the producer container which shows us that the jrpc server is started okay center is secured by default if you don't provide super user credentials we'll create a song for you uh so we have a few secrets that have been created bump install let me resize this okay this is the one we're going to use for no tool commands and cqlsh or cql access so we're gonna decode this username and put it in a variable and then same for the password okay [Music] for user and password all good and now we're going to use those to invoke cqlsh uh from within the first casano pod so we're going to run a cubectl exact and then notice sh just yet let's run multiple status okay we have two nodes let's do the same but now invoke cqlsh with our credentials all good and let's see what key spaces we have in here paper db system key space this is uh data input off from stargate all good [Music] now we're gonna create a job to run a stress test using no signal bench so here i'm gonna create a job using the nosql bench docker image and we're gonna run a moderate test 50 ops per second it's running on my laptop and we're gonna go through the kate sandra dc1 service which exposes the cassandra pods directly job created so let's see what we have here we have a no single bench pod that is currently creating and as soon as it starts we're going to be able to check the logs and follow them okay it's running and their icon is cube ctl logs okay so ramp up which means that now we should be able to see some metrics so let's hop here and okay so that's secured admin i mean one two three please change this in production uh fauna and then we're gonna go to the cassette overview dashboard okay and we see that indeed uh queries are being ran against the cluster and we have our throughputs latencies no status all that you need to monitor your cluster and we also have a more condensed dashboard which shows just a few of the metrics that are available okay so let's wait for that stress test to finish and the test is done so now we're gonna do a little scale up operation and add uh two stargate pods so i'm gonna update my custom values file set the number of replicas to 3 for stargate and update my install so i'm going to run helm upgrade and pass the values up okay so new target pods are creating and we're gonna check the status of this rollout okay our star goodness uh pods are ready now we're gonna run repair so let's go and check here if we can access reaper all good yeah the target nodes still show up in red sorry about that we need to update it so let's see if we can repair the base lines and we're gonna 10 segments per node activate it and there you go repair is running um so now we're gonna create a backup so this is done through helm as anything else in okay sandra so i'm gonna create a backup name backup one and it's gonna target our dc1 data center okay so now we can see that a backup object was created in pack one and if we check its definition we can see that both nodes have finished backing up and as soon as you have a finish time here it means the whole backup operation is done now let's go ahead and check video again to see what we have here okay so now we have some data we have two nodes folders backup index let's go here we have backup one that's all the metadata whoops uh and if we go back up a bit in the data folder let's go ahead and see baselines iot and we have some mrs tables good so let's now use cqlsh to truncate that table so select start let's first check that we have something in it we do truncated we have nothing left and now we're going to restore our backup so using helm again i'm going to start a restore operation i'm going to restore the backup one backup and let's go it's going to take a little more time as the cassandra pods have to be restarted and the restore operation takes place in an init container same as for the backup we have a cassandra restore object that was created in our kubernetes cluster and if we go and check its content we see that we have no finish time just yet so the back of the restore isn't done yet okay our restore is done let's now go and check that the data was actually restored [Music] there it is the last thing we're going to do now is scale up our cassandra pods to add one cassandra node so i'm gonna change that value to three and i'm gonna upgrade our helm install using the same command as before and we're going to see a third designer pod it's going to be added here and there you go so it's going to start up and join the clusters as the others that's all i have for now thank you for watching",
    "segments": [
      {
        "start": 1.68,
        "duration": 2.88,
        "text": "hey folks today i'm going to give you a"
      },
      {
        "start": 3.76,
        "duration": 5.68,
        "text": "little demo"
      },
      {
        "start": 4.56,
        "duration": 7.039,
        "text": "of kate sandra we're going to see how to"
      },
      {
        "start": 9.44,
        "duration": 3.76,
        "text": "deploy kit sandra on a kubernetes"
      },
      {
        "start": 11.599,
        "duration": 4.16,
        "text": "cluster how to"
      },
      {
        "start": 13.2,
        "duration": 4.159,
        "text": "run multitool commands and check the"
      },
      {
        "start": 15.759,
        "duration": 4.721,
        "text": "casino logs"
      },
      {
        "start": 17.359,
        "duration": 6.561,
        "text": "we'll see how to access cqlsh and"
      },
      {
        "start": 20.48,
        "duration": 5.84,
        "text": "we'll run stress tests using nosql bench"
      },
      {
        "start": 23.92,
        "duration": 3.76,
        "text": "we'll see how to check metrics using"
      },
      {
        "start": 26.32,
        "duration": 3.44,
        "text": "grafana"
      },
      {
        "start": 27.68,
        "duration": 3.12,
        "text": "and then we'll do some scale up"
      },
      {
        "start": 29.76,
        "duration": 5.04,
        "text": "operations"
      },
      {
        "start": 30.8,
        "duration": 7.36,
        "text": "on stargate and cassandra and we'll run"
      },
      {
        "start": 34.8,
        "duration": 5.279,
        "text": "repair using reaper and finally"
      },
      {
        "start": 38.16,
        "duration": 3.6,
        "text": "we'll perform some backup and restore"
      },
      {
        "start": 40.079,
        "duration": 6.081,
        "text": "operations using"
      },
      {
        "start": 41.76,
        "duration": 8.56,
        "text": "medusa so first i'm going to create"
      },
      {
        "start": 46.16,
        "duration": 7.6,
        "text": "a cluster on my laptop using"
      },
      {
        "start": 50.32,
        "duration": 8.079,
        "text": "kind unlike minicube"
      },
      {
        "start": 53.76,
        "duration": 8.56,
        "text": "kind can create kubernetes clusters with"
      },
      {
        "start": 58.399,
        "duration": 3.921,
        "text": "several uh worker nodes"
      },
      {
        "start": 64.64,
        "duration": 6.4,
        "text": "okay our kubernetes cluster should be"
      },
      {
        "start": 67.92,
        "duration": 6.4,
        "text": "up let's check"
      },
      {
        "start": 71.04,
        "duration": 6.56,
        "text": "that two moves we have three"
      },
      {
        "start": 74.32,
        "duration": 7.6,
        "text": "worker notes in the control plane"
      },
      {
        "start": 77.6,
        "duration": 7.68,
        "text": "let's check our spaces"
      },
      {
        "start": 81.92,
        "duration": 5.36,
        "text": "okay now first"
      },
      {
        "start": 85.28,
        "duration": 3.76,
        "text": "thing we're going to do is install"
      },
      {
        "start": 87.28,
        "duration": 5.04,
        "text": "traffic"
      },
      {
        "start": 89.04,
        "duration": 3.28,
        "text": "uh using helm"
      },
      {
        "start": 92.72,
        "duration": 4.96,
        "text": "traffic is our balancer"
      },
      {
        "start": 98.32,
        "duration": 6.72,
        "text": "and reverse proxy for kate sandra"
      },
      {
        "start": 102.24,
        "duration": 4.32,
        "text": "and i'm going to use a custom values"
      },
      {
        "start": 105.04,
        "duration": 6.399,
        "text": "file"
      },
      {
        "start": 106.56,
        "duration": 4.879,
        "text": "which is available in our documentation"
      },
      {
        "start": 111.52,
        "duration": 8.8,
        "text": "okay so now i'm going to install"
      },
      {
        "start": 115.68,
        "duration": 7.759,
        "text": "minio mineo is an object storage tool"
      },
      {
        "start": 120.32,
        "duration": 8.4,
        "text": "which is s3 compatible"
      },
      {
        "start": 123.439,
        "duration": 8.16,
        "text": "and runs in kubernetes"
      },
      {
        "start": 128.72,
        "duration": 3.36,
        "text": "so i'm gonna install it through helm as"
      },
      {
        "start": 131.599,
        "duration": 3.761,
        "text": "well"
      },
      {
        "start": 132.08,
        "duration": 6.48,
        "text": "you need some namespace and"
      },
      {
        "start": 135.36,
        "duration": 6.56,
        "text": "i'm gonna set some"
      },
      {
        "start": 138.56,
        "duration": 5.36,
        "text": "default settings so uh credentials mean"
      },
      {
        "start": 141.92,
        "duration": 4.959,
        "text": "i okay in ios secret"
      },
      {
        "start": 143.92,
        "duration": 4.24,
        "text": "and i'm gonna ask minajo to create a"
      },
      {
        "start": 146.879,
        "duration": 5.761,
        "text": "default bucket named"
      },
      {
        "start": 148.16,
        "duration": 7.52,
        "text": "casano meduza upon install"
      },
      {
        "start": 152.64,
        "duration": 6.0,
        "text": "okay let's now see"
      },
      {
        "start": 155.68,
        "duration": 2.96,
        "text": "what we have"
      },
      {
        "start": 159.44,
        "duration": 6.96,
        "text": "in the i mean i o key space namespace"
      },
      {
        "start": 163.76,
        "duration": 3.52,
        "text": "so we have a pod and we have service"
      },
      {
        "start": 166.4,
        "duration": 4.559,
        "text": "that exposes"
      },
      {
        "start": 167.28,
        "duration": 7.92,
        "text": "port 9000 so let's"
      },
      {
        "start": 170.959,
        "duration": 9.121,
        "text": "import forward it so that we can access"
      },
      {
        "start": 175.2,
        "duration": 4.88,
        "text": "uh the minion ui locally"
      },
      {
        "start": 182.879,
        "duration": 6.561,
        "text": "there we go so we have a category"
      },
      {
        "start": 186.319,
        "duration": 6.56,
        "text": "medusa bucket uh which is empty"
      },
      {
        "start": 189.44,
        "duration": 8.799,
        "text": "i still had a cookie uh on the browser"
      },
      {
        "start": 192.879,
        "duration": 8.561,
        "text": "but this is definitely secured"
      },
      {
        "start": 198.239,
        "duration": 5.601,
        "text": "now we're going to deploy kate sandra"
      },
      {
        "start": 201.44,
        "duration": 4.48,
        "text": "so i'm going to create a kate sandra"
      },
      {
        "start": 203.84,
        "duration": 7.039,
        "text": "namespace"
      },
      {
        "start": 205.92,
        "duration": 9.12,
        "text": "make it the default for cube ctl"
      },
      {
        "start": 210.879,
        "duration": 7.681,
        "text": "and i'm going to uh"
      },
      {
        "start": 215.04,
        "duration": 6.08,
        "text": "yeah create uh a secret"
      },
      {
        "start": 218.56,
        "duration": 5.84,
        "text": "for medusa to access me nio so it"
      },
      {
        "start": 221.12,
        "duration": 8.8,
        "text": "contains the minion credentials"
      },
      {
        "start": 224.4,
        "duration": 5.52,
        "text": "indicate sandra namespace"
      },
      {
        "start": 231.28,
        "duration": 7.28,
        "text": "okay so it's here there's a bucket key"
      },
      {
        "start": 234.72,
        "duration": 6.56,
        "text": "and now we're gonna install kate sandra"
      },
      {
        "start": 238.56,
        "duration": 4.72,
        "text": "so i'm gonna add the arcade center helm"
      },
      {
        "start": 241.28,
        "duration": 5.519,
        "text": "repo"
      },
      {
        "start": 243.28,
        "duration": 7.28,
        "text": "and the update command"
      },
      {
        "start": 246.799,
        "duration": 6.561,
        "text": "and install kate sandra"
      },
      {
        "start": 250.56,
        "duration": 4.959,
        "text": "in the case center namespace using a"
      },
      {
        "start": 253.36,
        "duration": 6.719,
        "text": "custom values file"
      },
      {
        "start": 255.519,
        "duration": 4.56,
        "text": "i'm going to show you in a second"
      },
      {
        "start": 261.68,
        "duration": 3.6,
        "text": "let's check it here we can see that"
      },
      {
        "start": 263.52,
        "duration": 5.04,
        "text": "kidsandra"
      },
      {
        "start": 265.28,
        "duration": 6.32,
        "text": "keys namespace is starting to"
      },
      {
        "start": 268.56,
        "duration": 6.16,
        "text": "create some pods and services"
      },
      {
        "start": 271.6,
        "duration": 6.24,
        "text": "so what are we deploying uh"
      },
      {
        "start": 274.72,
        "duration": 6.64,
        "text": "one cassandra data center with"
      },
      {
        "start": 277.84,
        "duration": 6.799,
        "text": "two nodes and custom heap sizes so that"
      },
      {
        "start": 281.36,
        "duration": 6.96,
        "text": "it fits on my laptop and"
      },
      {
        "start": 284.639,
        "duration": 3.681,
        "text": "one stargate pod"
      },
      {
        "start": 288.639,
        "duration": 3.761,
        "text": "we're gonna deploy medusa we're gonna"
      },
      {
        "start": 291.04,
        "duration": 6.8,
        "text": "deploy reaper"
      },
      {
        "start": 292.4,
        "duration": 5.44,
        "text": "and monitoring stack"
      },
      {
        "start": 301.6,
        "duration": 3.84,
        "text": "so there we can see that we have two"
      },
      {
        "start": 304.32,
        "duration": 4.879,
        "text": "stateful set"
      },
      {
        "start": 305.44,
        "duration": 6.88,
        "text": "sds pods which are the casino pods"
      },
      {
        "start": 309.199,
        "duration": 5.44,
        "text": "and one stargate pod we have of course"
      },
      {
        "start": 312.32,
        "duration": 4.96,
        "text": "caz operator"
      },
      {
        "start": 314.639,
        "duration": 3.28,
        "text": "the monitoring stack and medusa and"
      },
      {
        "start": 317.28,
        "duration": 3.28,
        "text": "reaper"
      },
      {
        "start": 317.919,
        "duration": 2.641,
        "text": "operators"
      },
      {
        "start": 321.12,
        "duration": 4.32,
        "text": "i'm gonna run two commands that will"
      },
      {
        "start": 323.28,
        "duration": 5.759,
        "text": "help me"
      },
      {
        "start": 325.44,
        "duration": 7.039,
        "text": "know when the deployment"
      },
      {
        "start": 329.039,
        "duration": 5.361,
        "text": "is fully done so this first command will"
      },
      {
        "start": 332.479,
        "duration": 4.401,
        "text": "wait for the cassandra data center"
      },
      {
        "start": 334.4,
        "duration": 5.84,
        "text": "object to be ready"
      },
      {
        "start": 336.88,
        "duration": 7.52,
        "text": "and the second one will check the"
      },
      {
        "start": 340.24,
        "duration": 4.16,
        "text": "rollout of the stargate component"
      },
      {
        "start": 350.88,
        "duration": 7.2,
        "text": "well this is starting let's go and check"
      },
      {
        "start": 355.039,
        "duration": 4.0,
        "text": "uh the consumer data center resource"
      },
      {
        "start": 358.08,
        "duration": 5.44,
        "text": "that was"
      },
      {
        "start": 359.039,
        "duration": 7.841,
        "text": "created by cas operator"
      },
      {
        "start": 363.52,
        "duration": 6.0,
        "text": "so we can see the events"
      },
      {
        "start": 366.88,
        "duration": 3.2,
        "text": "from the lifetime of that data center"
      },
      {
        "start": 369.52,
        "duration": 2.72,
        "text": "and"
      },
      {
        "start": 370.08,
        "duration": 3.36,
        "text": "the node statuses for now they don't"
      },
      {
        "start": 372.24,
        "duration": 4.32,
        "text": "have a host id"
      },
      {
        "start": 373.44,
        "duration": 3.68,
        "text": "once the node is ready it gets the host"
      },
      {
        "start": 376.56,
        "duration": 3.759,
        "text": "id"
      },
      {
        "start": 377.12,
        "duration": 6.32,
        "text": "so it seems like one is running yep so"
      },
      {
        "start": 380.319,
        "duration": 6.961,
        "text": "you see the host id there appear here"
      },
      {
        "start": 383.44,
        "duration": 6.96,
        "text": "uh and the cluster is still scaling up"
      },
      {
        "start": 387.28,
        "duration": 4.88,
        "text": "because we have one node left and you"
      },
      {
        "start": 390.4,
        "duration": 2.56,
        "text": "can see you can set our operator"
      },
      {
        "start": 392.16,
        "duration": 3.92,
        "text": "progress"
      },
      {
        "start": 392.96,
        "duration": 3.12,
        "text": "is updating"
      },
      {
        "start": 398.4,
        "duration": 3.359,
        "text": "okay so the percentage is our object is"
      },
      {
        "start": 400.96,
        "duration": 3.84,
        "text": "ready"
      },
      {
        "start": 401.759,
        "duration": 8.081,
        "text": "let's check again yep"
      },
      {
        "start": 404.8,
        "duration": 8.64,
        "text": "we have two host ids"
      },
      {
        "start": 409.84,
        "duration": 6.72,
        "text": "and the operator progress is ready"
      },
      {
        "start": 413.44,
        "duration": 6.479,
        "text": "now we are waiting for the stargate"
      },
      {
        "start": 416.56,
        "duration": 6.96,
        "text": "allowed to complete now"
      },
      {
        "start": 419.919,
        "duration": 6.641,
        "text": "stargate rollout is done"
      },
      {
        "start": 423.52,
        "duration": 6.079,
        "text": "uh let's see how we can check"
      },
      {
        "start": 426.56,
        "duration": 6.32,
        "text": "our center lock so if"
      },
      {
        "start": 429.599,
        "duration": 5.6,
        "text": "i try to get the logs from the"
      },
      {
        "start": 432.88,
        "duration": 3.599,
        "text": "cassandra pod it's going to tell me that"
      },
      {
        "start": 435.199,
        "duration": 4.321,
        "text": "we have"
      },
      {
        "start": 436.479,
        "duration": 3.761,
        "text": "several containers so cassandra reducer"
      },
      {
        "start": 439.52,
        "duration": 3.84,
        "text": "and server"
      },
      {
        "start": 440.24,
        "duration": 6.239,
        "text": "system logger so if you're looking for"
      },
      {
        "start": 443.36,
        "duration": 5.839,
        "text": "the system log files from cassandra"
      },
      {
        "start": 446.479,
        "duration": 5.44,
        "text": "it's going to be the system logger so"
      },
      {
        "start": 449.199,
        "duration": 7.601,
        "text": "logs the pod name the container name"
      },
      {
        "start": 451.919,
        "duration": 8.4,
        "text": "and there we have our system logs"
      },
      {
        "start": 456.8,
        "duration": 7.04,
        "text": "while the cassandra container"
      },
      {
        "start": 460.319,
        "duration": 6.801,
        "text": "outputs the logs from the management"
      },
      {
        "start": 463.84,
        "duration": 6.32,
        "text": "api and we"
      },
      {
        "start": 467.12,
        "duration": 5.84,
        "text": "also have the producer container"
      },
      {
        "start": 470.16,
        "duration": 5.2,
        "text": "which shows us that the jrpc server is"
      },
      {
        "start": 472.96,
        "duration": 5.6,
        "text": "started"
      },
      {
        "start": 475.36,
        "duration": 5.279,
        "text": "okay center is secured by default"
      },
      {
        "start": 478.56,
        "duration": 3.28,
        "text": "if you don't provide super user"
      },
      {
        "start": 480.639,
        "duration": 4.641,
        "text": "credentials we'll"
      },
      {
        "start": 481.84,
        "duration": 6.96,
        "text": "create a song for you uh so"
      },
      {
        "start": 485.28,
        "duration": 7.84,
        "text": "we have a few secrets that"
      },
      {
        "start": 488.8,
        "duration": 8.32,
        "text": "have been created bump install"
      },
      {
        "start": 493.12,
        "duration": 4.0,
        "text": "let me resize this okay"
      },
      {
        "start": 497.36,
        "duration": 3.519,
        "text": "this is the one we're going to use for"
      },
      {
        "start": 499.52,
        "duration": 5.32,
        "text": "no tool commands"
      },
      {
        "start": 500.879,
        "duration": 6.88,
        "text": "and cqlsh or"
      },
      {
        "start": 504.84,
        "duration": 6.68,
        "text": "cql access"
      },
      {
        "start": 507.759,
        "duration": 6.801,
        "text": "so we're gonna decode"
      },
      {
        "start": 511.52,
        "duration": 6.399,
        "text": "this username and put it in a"
      },
      {
        "start": 514.56,
        "duration": 7.039,
        "text": "variable and then"
      },
      {
        "start": 517.919,
        "duration": 6.0,
        "text": "same for the password"
      },
      {
        "start": 521.599,
        "duration": 2.32,
        "text": "okay"
      },
      {
        "start": 526.23,
        "duration": 6.65,
        "text": "[Music]"
      },
      {
        "start": 528.24,
        "duration": 7.68,
        "text": "for user and password all good"
      },
      {
        "start": 532.88,
        "duration": 7.04,
        "text": "and now we're going to use those to"
      },
      {
        "start": 535.92,
        "duration": 6.88,
        "text": "invoke cqlsh uh from within"
      },
      {
        "start": 539.92,
        "duration": 4.24,
        "text": "the first casano pod so we're going to"
      },
      {
        "start": 542.8,
        "duration": 4.4,
        "text": "run a cubectl"
      },
      {
        "start": 544.16,
        "duration": 5.92,
        "text": "exact and then notice"
      },
      {
        "start": 547.2,
        "duration": 6.079,
        "text": "sh just yet let's run multiple status"
      },
      {
        "start": 550.08,
        "duration": 6.52,
        "text": "okay we have two nodes"
      },
      {
        "start": 553.279,
        "duration": 7.361,
        "text": "let's do the same but now invoke"
      },
      {
        "start": 556.6,
        "duration": 7.48,
        "text": "cqlsh with our credentials"
      },
      {
        "start": 560.64,
        "duration": 6.48,
        "text": "all good and let's see what key spaces"
      },
      {
        "start": 564.08,
        "duration": 6.16,
        "text": "we have in here"
      },
      {
        "start": 567.12,
        "duration": 6.83,
        "text": "paper db system key space this is uh"
      },
      {
        "start": 570.24,
        "duration": 5.279,
        "text": "data input off from stargate all good"
      },
      {
        "start": 573.95,
        "duration": 5.81,
        "text": "[Music]"
      },
      {
        "start": 575.519,
        "duration": 7.841,
        "text": "now we're gonna create a"
      },
      {
        "start": 579.76,
        "duration": 6.639,
        "text": "job to run a stress test"
      },
      {
        "start": 583.36,
        "duration": 6.88,
        "text": "using no signal bench so here i'm gonna"
      },
      {
        "start": 586.399,
        "duration": 7.201,
        "text": "create a job using the nosql bench"
      },
      {
        "start": 590.24,
        "duration": 7.599,
        "text": "docker image and we're gonna"
      },
      {
        "start": 593.6,
        "duration": 6.4,
        "text": "run a moderate test 50 ops per second"
      },
      {
        "start": 597.839,
        "duration": 6.721,
        "text": "it's running on my laptop"
      },
      {
        "start": 600.0,
        "duration": 7.76,
        "text": "and we're gonna go through the"
      },
      {
        "start": 604.56,
        "duration": 7.92,
        "text": "kate sandra dc1 service which exposes"
      },
      {
        "start": 607.76,
        "duration": 4.72,
        "text": "the cassandra pods directly"
      },
      {
        "start": 612.72,
        "duration": 7.44,
        "text": "job created so let's see what we have"
      },
      {
        "start": 616.16,
        "duration": 8.72,
        "text": "here we have a no single bench pod"
      },
      {
        "start": 620.16,
        "duration": 4.72,
        "text": "that is currently creating"
      },
      {
        "start": 627.36,
        "duration": 3.2,
        "text": "and as soon as it starts we're going to"
      },
      {
        "start": 630.16,
        "duration": 4.88,
        "text": "be"
      },
      {
        "start": 630.56,
        "duration": 4.48,
        "text": "able to check the logs"
      },
      {
        "start": 636.16,
        "duration": 4.56,
        "text": "and follow them"
      },
      {
        "start": 641.76,
        "duration": 5.519,
        "text": "okay it's running and their icon is cube"
      },
      {
        "start": 645.04,
        "duration": 5.44,
        "text": "ctl logs"
      },
      {
        "start": 647.279,
        "duration": 5.601,
        "text": "okay so ramp up which means that"
      },
      {
        "start": 650.48,
        "duration": 4.32,
        "text": "now we should be able to see some"
      },
      {
        "start": 652.88,
        "duration": 8.959,
        "text": "metrics"
      },
      {
        "start": 654.8,
        "duration": 7.039,
        "text": "so let's hop here and"
      },
      {
        "start": 667.279,
        "duration": 2.401,
        "text": "okay"
      },
      {
        "start": 670.72,
        "duration": 4.48,
        "text": "so that's secured admin i mean one two"
      },
      {
        "start": 674.72,
        "duration": 3.76,
        "text": "three"
      },
      {
        "start": 675.2,
        "duration": 6.56,
        "text": "please change this in production"
      },
      {
        "start": 678.48,
        "duration": 3.84,
        "text": "uh fauna and then we're gonna go to the"
      },
      {
        "start": 681.76,
        "duration": 4.639,
        "text": "cassette"
      },
      {
        "start": 682.32,
        "duration": 7.199,
        "text": "overview dashboard okay"
      },
      {
        "start": 686.399,
        "duration": 6.801,
        "text": "and we see that indeed"
      },
      {
        "start": 689.519,
        "duration": 5.521,
        "text": "uh queries are being ran against the"
      },
      {
        "start": 693.2,
        "duration": 5.52,
        "text": "cluster"
      },
      {
        "start": 695.04,
        "duration": 7.2,
        "text": "and we have our throughputs latencies"
      },
      {
        "start": 698.72,
        "duration": 7.2,
        "text": "no status all that you need to monitor"
      },
      {
        "start": 702.24,
        "duration": 6.8,
        "text": "your cluster and we also have a"
      },
      {
        "start": 705.92,
        "duration": 3.12,
        "text": "more condensed"
      },
      {
        "start": 709.279,
        "duration": 7.281,
        "text": "dashboard which shows just a few"
      },
      {
        "start": 712.639,
        "duration": 7.521,
        "text": "of the metrics that are available"
      },
      {
        "start": 716.56,
        "duration": 7.279,
        "text": "okay so let's wait for"
      },
      {
        "start": 720.16,
        "duration": 8.239,
        "text": "that stress test to finish"
      },
      {
        "start": 723.839,
        "duration": 7.761,
        "text": "and the test is done"
      },
      {
        "start": 728.399,
        "duration": 6.801,
        "text": "so now we're gonna do a little scale up"
      },
      {
        "start": 731.6,
        "duration": 7.12,
        "text": "operation and add uh"
      },
      {
        "start": 735.2,
        "duration": 6.96,
        "text": "two stargate pods so i'm gonna"
      },
      {
        "start": 738.72,
        "duration": 7.119,
        "text": "update my"
      },
      {
        "start": 742.16,
        "duration": 3.679,
        "text": "custom values file"
      },
      {
        "start": 746.079,
        "duration": 4.88,
        "text": "set the number of replicas to 3 for"
      },
      {
        "start": 748.8,
        "duration": 5.44,
        "text": "stargate"
      },
      {
        "start": 750.959,
        "duration": 7.041,
        "text": "and update"
      },
      {
        "start": 754.24,
        "duration": 7.12,
        "text": "my install"
      },
      {
        "start": 758.0,
        "duration": 6.72,
        "text": "so i'm going to run helm upgrade"
      },
      {
        "start": 761.36,
        "duration": 3.36,
        "text": "and pass the values up"
      },
      {
        "start": 770.8,
        "duration": 9.68,
        "text": "okay so new target pods are creating"
      },
      {
        "start": 775.04,
        "duration": 5.44,
        "text": "and we're gonna check the status of this"
      },
      {
        "start": 784.839,
        "duration": 5.641,
        "text": "rollout"
      },
      {
        "start": 787.2,
        "duration": 6.4,
        "text": "okay our star goodness"
      },
      {
        "start": 790.48,
        "duration": 8.4,
        "text": "uh pods are ready"
      },
      {
        "start": 793.6,
        "duration": 9.679,
        "text": "now we're gonna run repair"
      },
      {
        "start": 798.88,
        "duration": 4.399,
        "text": "so let's go and check"
      },
      {
        "start": 803.44,
        "duration": 2.32,
        "text": "here"
      },
      {
        "start": 806.72,
        "duration": 6.4,
        "text": "if we can access reaper all good yeah"
      },
      {
        "start": 809.92,
        "duration": 6.88,
        "text": "the target nodes still show up"
      },
      {
        "start": 813.12,
        "duration": 7.04,
        "text": "in red sorry about that we need to"
      },
      {
        "start": 816.8,
        "duration": 7.52,
        "text": "update it so let's see if"
      },
      {
        "start": 820.16,
        "duration": 4.16,
        "text": "we can repair the base lines"
      },
      {
        "start": 825.68,
        "duration": 6.399,
        "text": "and we're gonna 10 segments"
      },
      {
        "start": 829.519,
        "duration": 2.56,
        "text": "per node"
      },
      {
        "start": 833.36,
        "duration": 2.8,
        "text": "activate it"
      },
      {
        "start": 836.56,
        "duration": 7.519,
        "text": "and there you go repair"
      },
      {
        "start": 840.16,
        "duration": 7.919,
        "text": "is running um"
      },
      {
        "start": 844.079,
        "duration": 7.041,
        "text": "so now we're gonna create a backup"
      },
      {
        "start": 848.079,
        "duration": 7.281,
        "text": "so this is done through helm"
      },
      {
        "start": 851.12,
        "duration": 8.719,
        "text": "as anything else in"
      },
      {
        "start": 855.36,
        "duration": 4.96,
        "text": "okay sandra so i'm gonna create a backup"
      },
      {
        "start": 859.839,
        "duration": 4.56,
        "text": "name"
      },
      {
        "start": 860.32,
        "duration": 11.519,
        "text": "backup one and it's gonna target"
      },
      {
        "start": 864.399,
        "duration": 11.601,
        "text": "our dc1 data center"
      },
      {
        "start": 871.839,
        "duration": 8.24,
        "text": "okay so now we can see that"
      },
      {
        "start": 876.0,
        "duration": 8.16,
        "text": "a backup object was created"
      },
      {
        "start": 880.079,
        "duration": 6.161,
        "text": "in pack one and if we check its"
      },
      {
        "start": 884.16,
        "duration": 5.359,
        "text": "definition"
      },
      {
        "start": 886.24,
        "duration": 7.2,
        "text": "we can see that both nodes have finished"
      },
      {
        "start": 889.519,
        "duration": 4.961,
        "text": "backing up and as soon as you have a"
      },
      {
        "start": 893.44,
        "duration": 4.8,
        "text": "finish time here"
      },
      {
        "start": 894.48,
        "duration": 6.56,
        "text": "it means the whole backup operation"
      },
      {
        "start": 898.24,
        "duration": 2.8,
        "text": "is done"
      },
      {
        "start": 901.6,
        "duration": 8.0,
        "text": "now let's go ahead and check"
      },
      {
        "start": 905.92,
        "duration": 7.039,
        "text": "video again to see what we"
      },
      {
        "start": 909.6,
        "duration": 6.799,
        "text": "have here okay"
      },
      {
        "start": 912.959,
        "duration": 7.361,
        "text": "so now we have some data we have"
      },
      {
        "start": 916.399,
        "duration": 6.481,
        "text": "two nodes folders backup index"
      },
      {
        "start": 920.32,
        "duration": 4.519,
        "text": "let's go here we have backup one that's"
      },
      {
        "start": 922.88,
        "duration": 4.639,
        "text": "all the metadata"
      },
      {
        "start": 924.839,
        "duration": 6.36,
        "text": "whoops uh"
      },
      {
        "start": 927.519,
        "duration": 5.921,
        "text": "and if we go back up a bit"
      },
      {
        "start": 931.199,
        "duration": 3.681,
        "text": "in the data folder let's go ahead and"
      },
      {
        "start": 933.44,
        "duration": 6.639,
        "text": "see baselines"
      },
      {
        "start": 934.88,
        "duration": 11.6,
        "text": "iot and we have some mrs tables"
      },
      {
        "start": 940.079,
        "duration": 11.76,
        "text": "good so let's now use cqlsh to"
      },
      {
        "start": 946.48,
        "duration": 5.359,
        "text": "truncate that table so select start"
      },
      {
        "start": 953.04,
        "duration": 3.2,
        "text": "let's first check that we have something"
      },
      {
        "start": 955.04,
        "duration": 3.52,
        "text": "in it"
      },
      {
        "start": 956.24,
        "duration": 2.32,
        "text": "we do"
      },
      {
        "start": 961.279,
        "duration": 2.721,
        "text": "truncated"
      },
      {
        "start": 964.48,
        "duration": 6.96,
        "text": "we have nothing left and now we're"
      },
      {
        "start": 968.079,
        "duration": 6.88,
        "text": "going to restore our backup"
      },
      {
        "start": 971.44,
        "duration": 7.36,
        "text": "so using helm again"
      },
      {
        "start": 974.959,
        "duration": 6.721,
        "text": "i'm going to start a restore operation"
      },
      {
        "start": 978.8,
        "duration": 5.36,
        "text": "i'm going to restore the backup one"
      },
      {
        "start": 981.68,
        "duration": 2.48,
        "text": "backup"
      },
      {
        "start": 984.24,
        "duration": 3.44,
        "text": "and let's go it's going to take a little"
      },
      {
        "start": 986.88,
        "duration": 3.68,
        "text": "more time"
      },
      {
        "start": 987.68,
        "duration": 4.159,
        "text": "as the cassandra pods have to be"
      },
      {
        "start": 990.56,
        "duration": 4.639,
        "text": "restarted"
      },
      {
        "start": 991.839,
        "duration": 6.8,
        "text": "and the restore operation takes place in"
      },
      {
        "start": 995.199,
        "duration": 3.44,
        "text": "an init container"
      },
      {
        "start": 1002.56,
        "duration": 5.839,
        "text": "same as for the backup we have"
      },
      {
        "start": 1005.759,
        "duration": 3.76,
        "text": "a cassandra restore object that was"
      },
      {
        "start": 1008.399,
        "duration": 4.721,
        "text": "created"
      },
      {
        "start": 1009.519,
        "duration": 4.161,
        "text": "in our kubernetes cluster and if we go"
      },
      {
        "start": 1013.12,
        "duration": 4.399,
        "text": "and check"
      },
      {
        "start": 1013.68,
        "duration": 7.519,
        "text": "its content we see that we have no"
      },
      {
        "start": 1017.519,
        "duration": 3.68,
        "text": "finish time just yet so"
      },
      {
        "start": 1021.519,
        "duration": 4.56,
        "text": "the back of the restore isn't done yet"
      },
      {
        "start": 1027.679,
        "duration": 6.561,
        "text": "okay our restore"
      },
      {
        "start": 1031.199,
        "duration": 5.681,
        "text": "is done let's now go"
      },
      {
        "start": 1034.24,
        "duration": 2.64,
        "text": "and check"
      },
      {
        "start": 1037.679,
        "duration": 5.201,
        "text": "that the data was actually restored"
      },
      {
        "start": 1044.849,
        "duration": 3.16,
        "text": "[Music]"
      },
      {
        "start": 1049.679,
        "duration": 7.601,
        "text": "there it is"
      },
      {
        "start": 1053.28,
        "duration": 7.519,
        "text": "the last thing we're going to do now is"
      },
      {
        "start": 1057.28,
        "duration": 6.56,
        "text": "scale up our cassandra"
      },
      {
        "start": 1060.799,
        "duration": 6.561,
        "text": "pods to add"
      },
      {
        "start": 1063.84,
        "duration": 6.64,
        "text": "one cassandra node so i'm gonna"
      },
      {
        "start": 1067.36,
        "duration": 6.88,
        "text": "change that value to"
      },
      {
        "start": 1070.48,
        "duration": 7.28,
        "text": "three and"
      },
      {
        "start": 1074.24,
        "duration": 7.679,
        "text": "i'm gonna upgrade our"
      },
      {
        "start": 1077.76,
        "duration": 6.96,
        "text": "helm install using the same command"
      },
      {
        "start": 1081.919,
        "duration": 2.801,
        "text": "as before"
      },
      {
        "start": 1085.84,
        "duration": 5.68,
        "text": "and we're going to see a third designer"
      },
      {
        "start": 1089.2,
        "duration": 2.32,
        "text": "pod"
      },
      {
        "start": 1091.679,
        "duration": 5.041,
        "text": "it's going to be added here and there"
      },
      {
        "start": 1094.799,
        "duration": 4.0,
        "text": "you go"
      },
      {
        "start": 1096.72,
        "duration": 3.36,
        "text": "so it's going to start up and join the"
      },
      {
        "start": 1098.799,
        "duration": 4.561,
        "text": "clusters"
      },
      {
        "start": 1100.08,
        "duration": 9.76,
        "text": "as the others that's all i have for now"
      },
      {
        "start": 1103.36,
        "duration": 6.48,
        "text": "thank you for watching"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T20:38:08.901227+00:00"
}