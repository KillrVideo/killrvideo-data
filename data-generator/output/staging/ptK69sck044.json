{
  "video_id": "ptK69sck044",
  "title": "DS320.30 Spark Streaming: Discretized Stream | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.30 Spark Streaming: Discretized Stream\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:31:21Z",
  "thumbnail": "https://i.ytimg.com/vi/ptK69sck044/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=ptK69sck044",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] most of spark is concerned with batch or maybe interactive analysis with data that is at rest the data has come from somewhere we bring it into spark we perform analysis on it and we put it somewhere when we're done some data though is not sitting in one place for us to access and analyze but it comes to us in a stream this is some kind of continuous source of data records that are being generated somewhere coming into our system and we want to analyze them in real time generate some kind of result and store that result this diagram shows us a very general form of that kind of thing there could be transactions from a business measurements from sensors in an internet of things application anything like that that's going to be a continuous real-time source of events that we want to process we'll take the results the aggregates the trend analysis whatever analysis we're coming up with store that somewhere and sometimes we also store the raw data somewhere as well different stream processing systems are going to have to make different decisions about how they deal with this some of them will take a record at a time as input like maybe storm or samsa and they'll process those records through the analysis and spit the results out others will batch up little chunks of those and deal with those in if you will micro batches spark streaming is an example of the latter so from that general form let's take a look at a very high level diagram of the architecture of spark streaming we'll start over on the left with input sources as you see there that can be a simple tcp socket it could be hdfs the cassandra file system kafka twitter akkacters anything like that that has the potential to be a constant stream of new things coming into the system those input streams are processed by receivers that's a new component that doesn't exist anywhere else in spark but that's the thing that reads the data from the input source and gets it into spark streaming receivers emit discretized streams and those are micro batches little collections of records that are coming in off the input sources batched up for processing by the spark engine and we're going to use the same spark engine that we've been using we'll see some slightly different apis emerge for doing stream processing but everything we've learned to date about partitioning about transformations actions all those apis all of those are going to apply the same we'll have to level up a little bit and learn a few new things but all those skills import which is good finally the spark cassandra connector will take the output of that spark analysis and put it back into cassandra the purpose here is that we've done some kind of analysis come up with some sort of aggregate result that is smaller and simpler than the streams themselves and we want that to be quickly readable in cassandra by the application whatever that application might be what is a d stream or a discretized stream well imagine the input source is just a sequence of ones and zeros you might be thinking well it's always a sequence of ones and zeros i realize that but in this case the abstraction we're going to look at is really just a sequence of ones and zeros coming in in the diagram we see that coming in on the input stream reading that in increasing time going from oldest to latest or right to left in this diagram we see 0 1 0 0 1 1 1 1 0 0 0 1 1 and so forth and then that gets broken up into four micro batches which really are actually just rdds we create four rdds out of that input stream the input stream we show here rdd one two three and four they may or may not have the same amount of data in them if the records are not arriving at a constant rate some of those micro batches which are generated on time boundaries might have more data or less since those are rdds we're able to send them into the regular spark engine and do analysis on them the way we normally would and here's a picture of just that sort of analysis we've got our d stream which is a sequence of these automatically generated rdds and we perform a filter operation on it we filter it such that we only want the values that are equal to one and that's what we get out in the rdds that you see at the bottom of the diagram [Music] you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.879,
        "duration": 3.601,
        "text": "most of spark is concerned with batch or"
      },
      {
        "start": 8.72,
        "duration": 3.999,
        "text": "maybe interactive analysis"
      },
      {
        "start": 10.48,
        "duration": 3.36,
        "text": "with data that is at rest the data has"
      },
      {
        "start": 12.719,
        "duration": 2.96,
        "text": "come from somewhere"
      },
      {
        "start": 13.84,
        "duration": 4.32,
        "text": "we bring it into spark we perform"
      },
      {
        "start": 15.679,
        "duration": 4.561,
        "text": "analysis on it and we put it somewhere"
      },
      {
        "start": 18.16,
        "duration": 3.76,
        "text": "when we're done some data though is not"
      },
      {
        "start": 20.24,
        "duration": 2.56,
        "text": "sitting in one place for us to access"
      },
      {
        "start": 21.92,
        "duration": 3.359,
        "text": "and analyze"
      },
      {
        "start": 22.8,
        "duration": 5.04,
        "text": "but it comes to us in a stream this is"
      },
      {
        "start": 25.279,
        "duration": 3.76,
        "text": "some kind of continuous source of data"
      },
      {
        "start": 27.84,
        "duration": 3.199,
        "text": "records that are being generated"
      },
      {
        "start": 29.039,
        "duration": 3.441,
        "text": "somewhere coming into our system and we"
      },
      {
        "start": 31.039,
        "duration": 3.68,
        "text": "want to analyze them"
      },
      {
        "start": 32.48,
        "duration": 3.44,
        "text": "in real time generate some kind of"
      },
      {
        "start": 34.719,
        "duration": 3.601,
        "text": "result and"
      },
      {
        "start": 35.92,
        "duration": 4.24,
        "text": "store that result this diagram shows us"
      },
      {
        "start": 38.32,
        "duration": 2.32,
        "text": "a very general form of that kind of"
      },
      {
        "start": 40.16,
        "duration": 2.0,
        "text": "thing"
      },
      {
        "start": 40.64,
        "duration": 3.919,
        "text": "there could be transactions from a"
      },
      {
        "start": 42.16,
        "duration": 4.079,
        "text": "business measurements from sensors in an"
      },
      {
        "start": 44.559,
        "duration": 3.041,
        "text": "internet of things application"
      },
      {
        "start": 46.239,
        "duration": 3.84,
        "text": "anything like that that's going to be a"
      },
      {
        "start": 47.6,
        "duration": 4.639,
        "text": "continuous real-time source of events"
      },
      {
        "start": 50.079,
        "duration": 3.921,
        "text": "that we want to process we'll take the"
      },
      {
        "start": 52.239,
        "duration": 2.401,
        "text": "results the aggregates the trend"
      },
      {
        "start": 54.0,
        "duration": 2.399,
        "text": "analysis"
      },
      {
        "start": 54.64,
        "duration": 3.599,
        "text": "whatever analysis we're coming up with"
      },
      {
        "start": 56.399,
        "duration": 2.721,
        "text": "store that somewhere and sometimes we"
      },
      {
        "start": 58.239,
        "duration": 3.681,
        "text": "also store"
      },
      {
        "start": 59.12,
        "duration": 4.32,
        "text": "the raw data somewhere as well different"
      },
      {
        "start": 61.92,
        "duration": 3.04,
        "text": "stream processing systems are going to"
      },
      {
        "start": 63.44,
        "duration": 2.8,
        "text": "have to make different decisions about"
      },
      {
        "start": 64.96,
        "duration": 2.88,
        "text": "how they deal with this"
      },
      {
        "start": 66.24,
        "duration": 3.04,
        "text": "some of them will take a record at a"
      },
      {
        "start": 67.84,
        "duration": 4.72,
        "text": "time as input like maybe"
      },
      {
        "start": 69.28,
        "duration": 4.64,
        "text": "storm or samsa and they'll process those"
      },
      {
        "start": 72.56,
        "duration": 2.16,
        "text": "records through the analysis and spit"
      },
      {
        "start": 73.92,
        "duration": 2.8,
        "text": "the results out"
      },
      {
        "start": 74.72,
        "duration": 3.6,
        "text": "others will batch up little chunks of"
      },
      {
        "start": 76.72,
        "duration": 3.84,
        "text": "those and deal with those"
      },
      {
        "start": 78.32,
        "duration": 4.08,
        "text": "in if you will micro batches spark"
      },
      {
        "start": 80.56,
        "duration": 3.44,
        "text": "streaming is an example of the latter so"
      },
      {
        "start": 82.4,
        "duration": 3.44,
        "text": "from that general form let's take a look"
      },
      {
        "start": 84.0,
        "duration": 3.439,
        "text": "at a very high level diagram of the"
      },
      {
        "start": 85.84,
        "duration": 3.12,
        "text": "architecture of spark streaming we'll"
      },
      {
        "start": 87.439,
        "duration": 2.161,
        "text": "start over on the left with input"
      },
      {
        "start": 88.96,
        "duration": 2.159,
        "text": "sources"
      },
      {
        "start": 89.6,
        "duration": 4.08,
        "text": "as you see there that can be a simple"
      },
      {
        "start": 91.119,
        "duration": 4.241,
        "text": "tcp socket it could be hdfs the"
      },
      {
        "start": 93.68,
        "duration": 4.799,
        "text": "cassandra file system"
      },
      {
        "start": 95.36,
        "duration": 4.719,
        "text": "kafka twitter akkacters anything like"
      },
      {
        "start": 98.479,
        "duration": 4.721,
        "text": "that that has the potential to be"
      },
      {
        "start": 100.079,
        "duration": 3.921,
        "text": "a constant stream of new things coming"
      },
      {
        "start": 103.2,
        "duration": 2.8,
        "text": "into the system"
      },
      {
        "start": 104.0,
        "duration": 3.92,
        "text": "those input streams are processed by"
      },
      {
        "start": 106.0,
        "duration": 3.28,
        "text": "receivers that's a new component"
      },
      {
        "start": 107.92,
        "duration": 3.36,
        "text": "that doesn't exist anywhere else in"
      },
      {
        "start": 109.28,
        "duration": 3.839,
        "text": "spark but that's the thing that reads"
      },
      {
        "start": 111.28,
        "duration": 3.36,
        "text": "the data from the input source"
      },
      {
        "start": 113.119,
        "duration": 4.081,
        "text": "and gets it into spark streaming"
      },
      {
        "start": 114.64,
        "duration": 5.68,
        "text": "receivers emit discretized"
      },
      {
        "start": 117.2,
        "duration": 4.64,
        "text": "streams and those are micro batches"
      },
      {
        "start": 120.32,
        "duration": 3.28,
        "text": "little collections of records that are"
      },
      {
        "start": 121.84,
        "duration": 4.559,
        "text": "coming in off the input sources"
      },
      {
        "start": 123.6,
        "duration": 3.519,
        "text": "batched up for processing by the spark"
      },
      {
        "start": 126.399,
        "duration": 2.48,
        "text": "engine"
      },
      {
        "start": 127.119,
        "duration": 3.2,
        "text": "and we're going to use the same spark"
      },
      {
        "start": 128.879,
        "duration": 3.521,
        "text": "engine that we've been using we'll see"
      },
      {
        "start": 130.319,
        "duration": 3.361,
        "text": "some slightly different apis emerge for"
      },
      {
        "start": 132.4,
        "duration": 3.44,
        "text": "doing stream processing"
      },
      {
        "start": 133.68,
        "duration": 3.52,
        "text": "but everything we've learned to date"
      },
      {
        "start": 135.84,
        "duration": 3.84,
        "text": "about partitioning"
      },
      {
        "start": 137.2,
        "duration": 3.44,
        "text": "about transformations actions all those"
      },
      {
        "start": 139.68,
        "duration": 2.88,
        "text": "apis"
      },
      {
        "start": 140.64,
        "duration": 3.28,
        "text": "all of those are going to apply the same"
      },
      {
        "start": 142.56,
        "duration": 2.48,
        "text": "we'll have to level up a little bit and"
      },
      {
        "start": 143.92,
        "duration": 2.72,
        "text": "learn a few new things"
      },
      {
        "start": 145.04,
        "duration": 3.52,
        "text": "but all those skills import which is"
      },
      {
        "start": 146.64,
        "duration": 3.44,
        "text": "good finally the spark cassandra"
      },
      {
        "start": 148.56,
        "duration": 2.8,
        "text": "connector will take the output of that"
      },
      {
        "start": 150.08,
        "duration": 3.2,
        "text": "spark analysis"
      },
      {
        "start": 151.36,
        "duration": 3.2,
        "text": "and put it back into cassandra the"
      },
      {
        "start": 153.28,
        "duration": 3.2,
        "text": "purpose here is that we've done some"
      },
      {
        "start": 154.56,
        "duration": 2.16,
        "text": "kind of analysis come up with some sort"
      },
      {
        "start": 156.48,
        "duration": 2.64,
        "text": "of"
      },
      {
        "start": 156.72,
        "duration": 3.12,
        "text": "aggregate result that is smaller and"
      },
      {
        "start": 159.12,
        "duration": 3.04,
        "text": "simpler"
      },
      {
        "start": 159.84,
        "duration": 4.0,
        "text": "than the streams themselves and we want"
      },
      {
        "start": 162.16,
        "duration": 4.24,
        "text": "that to be quickly readable"
      },
      {
        "start": 163.84,
        "duration": 4.399,
        "text": "in cassandra by the application whatever"
      },
      {
        "start": 166.4,
        "duration": 4.16,
        "text": "that application might be what is a d"
      },
      {
        "start": 168.239,
        "duration": 4.161,
        "text": "stream or a discretized stream well"
      },
      {
        "start": 170.56,
        "duration": 4.72,
        "text": "imagine the input source"
      },
      {
        "start": 172.4,
        "duration": 3.839,
        "text": "is just a sequence of ones and zeros you"
      },
      {
        "start": 175.28,
        "duration": 2.8,
        "text": "might be thinking well"
      },
      {
        "start": 176.239,
        "duration": 3.201,
        "text": "it's always a sequence of ones and zeros"
      },
      {
        "start": 178.08,
        "duration": 2.879,
        "text": "i realize that but"
      },
      {
        "start": 179.44,
        "duration": 3.36,
        "text": "in this case the abstraction we're going"
      },
      {
        "start": 180.959,
        "duration": 3.36,
        "text": "to look at is really just a sequence of"
      },
      {
        "start": 182.8,
        "duration": 3.6,
        "text": "ones and zeros coming in"
      },
      {
        "start": 184.319,
        "duration": 3.28,
        "text": "in the diagram we see that coming in on"
      },
      {
        "start": 186.4,
        "duration": 3.839,
        "text": "the input stream"
      },
      {
        "start": 187.599,
        "duration": 4.56,
        "text": "reading that in increasing time going"
      },
      {
        "start": 190.239,
        "duration": 4.961,
        "text": "from oldest to latest or right"
      },
      {
        "start": 192.159,
        "duration": 6.16,
        "text": "to left in this diagram we see 0"
      },
      {
        "start": 195.2,
        "duration": 6.08,
        "text": "1 0 0 1 1 1 1"
      },
      {
        "start": 198.319,
        "duration": 4.161,
        "text": "0 0 0 1 1 and so forth and then that"
      },
      {
        "start": 201.28,
        "duration": 4.239,
        "text": "gets broken up"
      },
      {
        "start": 202.48,
        "duration": 6.479,
        "text": "into four micro batches which"
      },
      {
        "start": 205.519,
        "duration": 6.0,
        "text": "really are actually just rdds we create"
      },
      {
        "start": 208.959,
        "duration": 3.041,
        "text": "four rdds out of that input stream the"
      },
      {
        "start": 211.519,
        "duration": 3.681,
        "text": "input stream"
      },
      {
        "start": 212.0,
        "duration": 5.28,
        "text": "we show here rdd one two three and four"
      },
      {
        "start": 215.2,
        "duration": 3.84,
        "text": "they may or may not have the same amount"
      },
      {
        "start": 217.28,
        "duration": 3.28,
        "text": "of data in them if the records are not"
      },
      {
        "start": 219.04,
        "duration": 2.96,
        "text": "arriving at a constant rate"
      },
      {
        "start": 220.56,
        "duration": 3.84,
        "text": "some of those micro batches which are"
      },
      {
        "start": 222.0,
        "duration": 5.04,
        "text": "generated on time boundaries"
      },
      {
        "start": 224.4,
        "duration": 4.559,
        "text": "might have more data or less since those"
      },
      {
        "start": 227.04,
        "duration": 3.6,
        "text": "are rdds we're able to send them into"
      },
      {
        "start": 228.959,
        "duration": 4.0,
        "text": "the regular spark engine"
      },
      {
        "start": 230.64,
        "duration": 3.04,
        "text": "and do analysis on them the way we"
      },
      {
        "start": 232.959,
        "duration": 2.321,
        "text": "normally would"
      },
      {
        "start": 233.68,
        "duration": 3.199,
        "text": "and here's a picture of just that sort"
      },
      {
        "start": 235.28,
        "duration": 3.76,
        "text": "of analysis we've got our d"
      },
      {
        "start": 236.879,
        "duration": 4.08,
        "text": "stream which is a sequence of these"
      },
      {
        "start": 239.04,
        "duration": 4.0,
        "text": "automatically generated rdds"
      },
      {
        "start": 240.959,
        "duration": 3.681,
        "text": "and we perform a filter operation on it"
      },
      {
        "start": 243.04,
        "duration": 3.04,
        "text": "we filter it such that we only want the"
      },
      {
        "start": 244.64,
        "duration": 4.4,
        "text": "values that are equal to one"
      },
      {
        "start": 246.08,
        "duration": 3.68,
        "text": "and that's what we get out in the rdds"
      },
      {
        "start": 249.04,
        "duration": 5.72,
        "text": "that you see"
      },
      {
        "start": 249.76,
        "duration": 8.24,
        "text": "at the bottom of the diagram"
      },
      {
        "start": 254.76,
        "duration": 5.319,
        "text": "[Music]"
      },
      {
        "start": 258.0,
        "duration": 2.079,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:26:26.820919+00:00"
}