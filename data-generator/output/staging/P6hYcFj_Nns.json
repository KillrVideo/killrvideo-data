{
  "video_id": "P6hYcFj_Nns",
  "title": "An Introduction to Machine Learning!",
  "description": "SLIDES/MATERIALS: \nhttps://github.com/HadesArchitect/CaSpark\n\nüí¨ CHAT = DISCORD, ask questions live: \nhttps://bit.ly/cassandra-workshop\n\n‚ùìFORUM = QUESTIONS during the week community.datastax.com : \nhttps://community.datastax.com\n\nüßë‚Äçü§ù‚Äçüßë THE WORKSHOP TEAM\n- Cedrick LUNVEN (@clunven, https://www.linkedin.com/in/clunven/)\n- David GILARDI (@SonicDMG, https://www.linkedin.com/in/david-gil...)\n- Aleksandr VOLOCHNEV (@HadesArchitect)\n- Eric ZIETLOW (@EricZietlow)\n- Erick RAMIREZ (@ErickRamirezAU)\n- Jack FRYER (https://www.linkedin.com/in/jack-frye...)\n- Bettina SWYNNERTON (https://www.linkedin.com/in/bettina-s...)\n\nüöÄ üöÄ ENJOY !! üöÄ üöÄ",
  "published_at": "2020-11-09T14:21:20Z",
  "thumbnail": "https://i.ytimg.com/vi/P6hYcFj_Nns/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "introduction",
    "workshop",
    "cassandra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=P6hYcFj_Nns",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "hello everyone and welcome to the another episode of data stocks Monday learning hi Cedric Hello Alex yeah so I see some people have joined us already it's a big pleasure to see you all here so if you can see us if you can hear us please set your thumbs up in the YouTube chats or Discord chat so we will know we are together and we can start yeah so today I will track uh the Youtube chat so if you do have a question don't hesitate I will stop Al Alex if we need to or if not I will try to answer you back in the chat yeah exactly so uh it looks like we are good I think we have sound I I think we have everything what we need so it must be good to start all right yeah okay so uh I believe some people here who attended one of our last events doesn't matter if it's a Cassandra Workshop series or maybe data stocks P learning we will introduce ourselves and you will know what's going on but in very short data Stacks Monday learning is our way to make your Monday Monday your best and most beloved day of a week because we are always trying to do something special on Mondays for you and be picking the most important technical topics only for from Engineers to Engineers no marketing absolutely for free yeah I mean I hope no no no no one of marketing is watching this video no they are not awake but you know one important Point as well is it's kind of beginner content on Mondays so you can start from scratch and learn yes exactly so we want to cover important topics for those who are not so much into their uh things like today we are going to speak about oops today we are going to speak about machine learning but not in the scientifical way or not in the very deep dive way you don't need to have a mathematics uh degree to get into that we always speak about complex things in a very simple way so even if you're a complete beginner in this field you can get everything we are talking about by the way as we are speaking about data stocks Monday learning next week we have something interesting especially for those uh who is already into the docker things or maybe who attended our Docker learning path next week we speak about kubernetes Native applications and will be a great expert in this field a guest speaker which is not a part of a data stack developer Advocates team and that's great because we love guests yes we do okay and today is going to be introduction to machine learning with Apache Cassandra and apach Spark we want to be practical so we don't want this Workshop to be too too theoretical we want you to be able to put your hands on and use real uh applications and real systems people use to apply machine learning into the real life so and let's just two words about ourselves you may be know us already that's Cedric on the left to me and or or on the right I don't know yes on the right this side exactly and well we work at the data stocks the main company let's say Behind the pajaka sunram B in apak Cassandra happen and uh we work at the developer relations team so we are engineers and developers um helping our developers to get better with the distributed applications and all the modern Technologies and Cedric maybe you will say something y sure so um I'm Cedric lven I'm leading the developer Advocate team um and also I'm quite a Java geek so I created ffj seven years ago already wow but it's pretty successful with 150k downloads a month so it's feure flipping for Java so meaning uh you can unable or disable part of your application at one time and I also add the chance to contribute to Jeepster so Jeepster is a scaffolding application a generator of application you provide the technology you want to use and the entity and that program will start you a full running app front end in JavaScript view angular um or react and back end as a spring Boot and now you can also have the back end with micronote uh and it's the ecosystem is just is becoming huge um yep and as you see we are big fans of open- source software and that's exactly the thing for today's Workshop as well as for every of the data Stacks Monday learning we are going to do all the things uh with open- Source Technologies only okay so uh few things we are going to do today and few things you have to understand like where and what uh is stored and available and what you may need streams that's a live stream I hope you are watching it live but if you don't that's still fine because all the materials stay available for you so at first we stream at twitch and YouTube but YouTube is the primary platform for me so twitch is a fallback Plan B if something goes wrong at YouTube then uh to ask questions you can ask questions at the YouTube chat by but as long as the YouTube uh stream is over chat is gone and you will not be able to ask questions after that to uh work uh like more permanent manner we use Discord and you can find us at Discord maybe uh cedri could you please uh copy paste the link to oh thank you you are thinking just ahead of time exactly yeah you don't even have to talk now you we just you know what what do they call that in English uh but and chocolate chocolate and peanut butter yeah something like that yeah we working more like a Bome now good now uh then next thing uh as we are going to push our hands on and uh press some buttons we will need some runtime in our case as it's the introduction to machine learning test with Apache Cassandra and Apache spark second we are going to use Apache Cassandra apach spark and a couple of tools required to apply machine learning to them and it may sound pretty complex but don't worry we have everything set up for you and to use that all together you may need some materials those are stored on GitHub and let me guess Cedric has put a link already yet not yet no because in the description the link is shrink so yeah in I need one more minute don't worry in the description link is a little bit outdated I would say I have to fix that but actually we have a newer link I will okay provid the proper link now done so it's going to be Academy everything is on datax Academy GitHub account yeah there you can see all the topic we have covered now we do have more than 50 workshops now there for you yeah definitely a lot of things good so um and to do practice practical steps you will have to choose if you want to use your environment or our environment your environment whatever would it be requires only a couple of things you need to have Docker and Docker compos as long as you have Docker and Docker compose you can get clone or just download our assets from machine learning workshop online repository at github.com data stack Academy machine learning workshop online and then you can just doer compose uh pull doer compose up and you have all the required things running what is running there I will show you later on during this Workshop but what I kindly ask you first please follow me and follow Cedric and do the Practical steps after the theoretical part of the workshop okay so it will it will make things much easier to you if you listen first true if uh by any reason you can't have Docker and Docker compos install it or your machine or maybe uh your laptop is not so powerful because well we are going to run pretty a lot of things to make the computations you have a second option you can contact me uh in LinkedIn or via email and I will uh create a cloud instance with all the requirements installed for you uh second option is maybe not so much comfortable because it's going to be temporary instance and we will terminate it pretty soon but for uh some hours two three hours is definitely can be granted to you well so let's start then machine learning machine learning is a field of study what gives computers the ability to learn without being explicitly programmed sounds great computers learn without explicit L program it but how it works in real life yeah I have copy pasted here definition from Wikipedia and that's as much as usual mostly useless if you know what's already you don't need that and if you know that and if you don't know it will not help because all of those definitions are too big and too complicated I prefer uh to use another definition which is much shorter machine learning is science of drawing cir circles and colorizing them it still explains nothing but at least it's short so it's already much easier to learn so we better will think of how it works first and then you will find which definition is better better works for you machine learning is a scientific way to process row data using algorithms to make better decisions in general it Works in a very simple way you have uh accumulated some data for example of your customers Behavior what they're liking what we are not liking or maybe data from the medical point of view in you if you work in the uh medicine any kind of data people may be interested in and then you process those data with some algorithms helping you to make bit better decisions in the end and there is no magic whatever machine learn learning does is the same thing as people could do but you know what computers are Computing much faster than humans so basically whatever computer machine learning can do you can do as well but in some cases it may take pretty long of time pretty long time what are the use cases for the machine learning you will see some of them soon but in general that's very often about forecasts what would be expect Ed Price or the best price for this product you are going to release uh what are the possible ratings for I don't know for example for a movie you are going to release or something whatever possible we uh in next Monday will you stay at home with us or will you go for a walk instead I recommend you to stay with us because well data Stacks Monday learning is a great thing then another Point aberation detection whatever un usual Behavior or unusual incident in the workflow it can be about fra detection in the banking very often use case intrusion detection as well uh any kind of again getting back to Medicine about the disease detection as well many others uh typical cases for classification face recognition image recognition categorization of the images but not only images of course spam detection one of the most favorite usage of machine learning in real life is the spam detection we will investigate it deeper today and also recommendation techniques navigation and many others machine learning is not more like uh just a fairy tale but it's a real thing which which got into every part of our lives and we saw uh What uh that's about applying algorithms to data to get some results to get better decisions to to get some highlights over this data what are those algorithms there are a lot of them we will take a closer look and um something uh we will cover today but in general you may think of those algorithms kind of as of mathematical functions as you give some data you receive some result if you have a function which multiplies everything by free and you give some data some number to this uh function you will have a result of an digit number you gave multiplied by three and so on so in general algorithm is some simple defined way to execute some operations with the data you give so nothing complex and you will see it very soon in real life examples on how they work and out of those algorithms two main groups we may discuss or two main cases supervis it and unsupervised first of there are more cases and more groups we may have um kind of half supervised approach and there are some more advanced things but that's introduction not a deep dive so we start simple in general all of the applications of um those algorithms can be separated into two different groups supervised or unsupervised what's the difference difference is very simple data is label it or not if data is labeled or must be labeled as a result it's the kind of a supervised um algorithm what does that mean very simple uh we have we know already we have some data or we have to classify it this email is a spam or not this operation this banking operation was fra subscription is canceled or not so that everything we can clear say okay this operation is uh fair this operation is fair this operation is froud this email is Spam this email is Spam this email is not spam we had this data already and now we are getting newa emails and now we have to classify them or label them speaking more scientifically so data is labeled or must be labeled and that's the purpose of a supervisor groups um typical cases uh is a CL speci ification as said so when you have to um say this this is a picture of a dock and this is a picture of the uh traffic light classification it's supervised then uh best site of a supervised algorithms uh and they are easy to test we will cover testing later during the making the steps how exactly it works but um uh in general uh like a little highlight of what we are going to do we split some data and we use part of the data we have to train the model you will see how it works and then we use second part of the data smaller part to test if it works correctly and um that's uh kind of uh this supervisor thing is easy to test because for example uh millions and millions and millions of people getting emails over their life uh sending some of those emails to spam and that spam spam not spam not spam spam spam that the job what we did what what I did and you I think too as well and uh because of that when like um when I receive emails nowadays uh and we are I'm using uh Google account for email both work and private you know what they're really very good in the detecting which email is Spam and which is not why because all the millions of the people were clicking spam or not spam all the years before okay and then it's easy to test unsupervised algorithms unsupervised approach is different data is not labeled and we don't care about if it's labeled or not that's not the thing for us uh that's a different approach which helps us to find patterns and data uh helps us to Cluster data so to separate um data we have into different groups to find a groups and find dependencies between them that belongs to uh animal detection that belongs to any kind of a grouping of the data we have that helps us to create associations between data pieces we have very useful in exploratory analysis when we don't really understand what data we have and want to get better knowledge of that and another problem uh so it's harder to test because we cannot be really sure what that's the final result we want to have is it spam or not we cannot say in this day it's unsupervised we don't have labels yeah and speaking of spam I just um you know working with the marketing team now we are also using some kind of machine learning to to shape the email not to look like a spam so you do have a machine learning trying to avoid you to get spam and at the marketing side we do have machine learning to push you email and make look it does not look spam that's funny yeah someone said some time ago what in the 21st century every company has to become has to become a data company or die and well that's not about just trying to collect as much data uh you may have but that's about also to process that properly yeah and that's very interesting so now we have machine learnings from all the sides of this um field let's say Okay so let's take a look before we get a deeper dive into how it works let's take a look a little demo I want to show you I want to show you a very simple thing those algorithms are in general simple to understand maybe hard to master that's okay for me but they're simple to understand and first thing will do is K means algorithm one of the algorithms will we will use today there is a great um tool to play with kin clustering algorithm I will send a link to the chat but please don't do it right now first listen to me otherwise you will miss the explanations and then ask the things in the chat we which we cover it already so what's the uh clustering thing very simple oops okay I will clean it up a little bit good so imagine that field is a city map there are some streets and buildings all the things like that and you know what we are going to create and deliver best pizza in the world like everyone loves pizza and we are going to bring it to a new level so and uh we want we have we are limited in budget so we want to establish our uh centers uh Pizza houses in the middle of the area with the Pizza Lovers of this city leave so we want to be geographically convenient for them to visit and also we want to um uh keep it easier for our careers to deliver pizza on very short time and you know what in the city there are different areas some of them use and buy pizza a lot and some of them are not so first thing I want to do as I'm setting somehow we got data I don't know there are many ways to get data of the people living in different areas of the city and those will be uh areas that uh people who buy pizza Leaf so I'm just making all the previous buys uh like that and now let's say Let's uh take a look at what the k means algorithm is it's unsupervised algorithm the data I have is not labeled they all are the same just only cordinates for example are different that's uh story of some orders of pizza I want to cover key means is uh not to categorize but to help me explore the data and find uh how to group them or how to Cluster them it's a clustering demo so we are going to build some glass clusters to group them and as I have some data here already uh and I will use theault setting of two clusters uh to be fix it in the future B one may work not best how this kin algorithm works first it takes all the field I have here specified and randomly allocates absolutely randomly allocates um cluster centers somewhere on the field it may sound pretty stupid I mean like I want to have more or less uh correct data not some random allocation but let's take a look how it works in the end after some steps of these algorithms you will find out you will see what it works pretty good after those uh centers are allocated it calculates the difference uh from all of the points to the current Center and tries to find the best direction to move uh the way which will decrease Delta which will decrease difference of uh lengths of all the lengths uh from the points allocated to the center and I can push the step button one and use it for calculated steps it moved them to the center okay and it looks like Delta now is uh already getting better with just one step calculating all the lengths and moving in the uh Center of mass Direction it's getting better and actually only one step was enough to allocate f for us like that but what will happen if I move Center to a new position it will restarts with everything and I do the step again so first thing algorithm does is calculates to length of all the lines we have here and then tries to calculate in which direction we should move the um Center uh so the groups will be identified in a better way okay and this was identification like you see we have pretty good situation here already we are grouping them but now some points belong to the uh red Center which is maybe not perfect in this case and after a couple of more steps okay vice versa we are moving in another Direction uh red Center gets points those are closer to the red Center then to the blue Center using exactly the same approach after every step they're trying to calculate which is may be closer to me and may should be consumed by one of the centers and which one is any another Center is not interested we when after a few steps with every next step we are getting more and more uh better grouping for those and in the end we have Delta position zero so it means what K means algorithm doesn't want to move anything it's fine and now why it's called it K means K means number of clusters we are going to have and why that's one of the let's say biggest possibilities and problems of these algorithms um from one point of view uh we may have limited amount of clusters right now we have only two but maybe these it will look better if we have uh if we may have more clusters and doing some steps and doing some steps we find out what with free clusters it works better will it work better with four clusters well maybe will it work better with five clusters maybe it's too much for us so uh playing with amount of clusters and our way to group those um um uh cluster those data pieces we have to try to group them and find the centers of groups may work pretty good for us one important point to understand here is amount of clusters is for humans to decide we cannot just um maybe you have some limited possible amount of things maybe uh it depends on what exactly do you have to find out we discuss it on the next steps in this example I can put centers uh Rand On My Own by default uh K means put them randomly as I said and then after every next step we see how it changes and how key means tries to find the geographical center so again process is very simple you have this line you have the set of lines sorry and you calculate uh Direction and the length of every of them and it looks like oh it looks like I have a very big Delta here difference between my center and other Center and the points of data is too high and then obviously I'm c will move V Center more to the U Southeast let's say boom of course because now it's for Center and now playing next step we will find how it will reallocate and recalculate everything depending on the amount of clusters you have so basically that was a very simple example yeah so question in the chat try to answer but um so how do you set this K do you try and learn so my first answer is this K is really tied to your own business so if you talk about the bus the pizza house you have a limited amount of budget so you know you can have three to four Pizza House and so you will compute for each what is the distance between the houses and and and and the data point and see if it's if it's worth adding a new uh Pizza House um but I think you know you should try and learn yep uh okay then so what comes next now okay we just uh have seen one of the algorithms in the Wild on how it works how it measures distances how it calculates vectors and moves the center to the best possible Direction how it works in real life and how do we apply data to the algorithm we are going to use how goes the learning workflow it consists of the uh few steps at first we have to prepare data because row data is very often useless for learning you will see it in the Practical part and first we prepare data when we split if the work in this case we discuss supervisor learning so we can test uh we split things uh into training set validating set and testing set we will need um then there is a training phase when we train when we train our model with a training set and use validating set to tune that there are some um things like K we can adjust and some others for another algorithms and testing set we use finally to estimate our model if it's good or not and finally as if we are satisfied with our model we can use it to work with a new data if we speak of a Spam example here first example preparation we have to get some emails and label them if it's spam or not let's say it's done for us already when we split uh given emails into training validating and testing and we use training set which is usually biggest one like around 80% of the data we have it depends on your strategy of course um to train the model we use validating set um to tune the model and find out uh if we can make it better if we we can reset up it maybe anyhow and finally we use testing set to estimate the model and if model is good we release the final model which now is going to process the new data we have or new emails we have and set if it's maybe spam or not yeah good now uh you may be want to jump inter actions but inter action uh but before that we have to discuss one more thing so we are very close to practical you cannot control what you can't measure so we want to speak about Matrix as we work with a supervisor algorithm now we can test and we can compare and we can assess the model if it's good or not so what kind of metric matters let's take a look and let's talk a little bit about the example we have that's year 2020 and all the pandemic is going over over and I'm sorry to touch this topic but I'm going to get uh into some uh medical things right now for uh estimation and metrix part we will talk about tumor and in this example we have 100 patients 100 people nine of them have malan tumor which is very bad and kind of deadly and um 91 of them have a banine tumor which is well also but not so bad and uh our model model we prepar it and model which we are going to assess in The Next Step uh gave the following results out of 100 people 9 malan tumor 91 benine tumor we detected successfully uh 90 uh true negative results so we have theing tumor not the um malan and there are 90 of them and we found out 90 of 91 of them which looks not so bad then uh false positive results we identified uh tumor as B but actually it been malan and false positive we have only one result so one person had a benine tumor but we identified is as malan as a bad one then we have all Al false negative in reality people had the bad tumor but we predicted it as a light kind of tumor eight results false negatives and finally one true positive it was very bad tumor and we identified it as a very bad tumor number of true positive results again one that's for example we will look we will work with now first metric we talk about the machine learning algorithms is the accuracy accuracy is a classification model metric it's the fraction of a prediction model identified correctly so accuracy easily speaking briefly speaking is a amount of correct predictions divided by total predictions in this example we have accuracy of 0.91 because 91 predictions were true we have true positive 1 to 90 it total 91 divided by 100 so accuracy 0.91 it's pretty high is that model good now wait for a second and try to think because uh well where is a flow we didn't discuss yet we just sent back home eight people without proper treatment because of a high level of false negatives out of nine people with malan tumor we got false negative on eight of them we could have better results literally by throwing a coin I mean literally in this case we send back home eight people out of nine and if you would throw a coin this amount would be much lesser mostly probably so um is this model um good or not so good well maybe not so good and we have to work on that so accuracy is an interesting thing from one point of view that's important to understand accuracy from another point of view you see like that's very clear is uh not about it's sometimes not the best thing we have high accuracy highest possible accuracy is one and we have accuracy zero .9 very close but the modu is still very bad so let's take a look if we have something better another kind of metrics we have to discuss is the precision versus recall uh Precision means uh positive predictive valuee uh Precision means uh amount of true positives divided by amount of all positives both true and false and for our um example for for our example with the tumor Precision is only 0.5 which is not so high so we see what it has like kind of very medium Precision but if it goes to the second side of a slide which is recall also known as sensitivity uh recall or sensitivity you can use both recall is maybe a more official name recall counts correctly identified positives out of all real positives and recall is amount of true positives divided by all real positives and for a Tor example recall is 0.11 so extremely low now uh well when we have a lot of uh metrics uh some more also coming uh what people are doing in the real life because yes we need metrix but now we see what accuracy is maybe not so relevant uh and precision recall uh they are great but they kind of contradict to each other then you start to tune your model to be more precise you start to use recall that's kind of a mathematic simple uh mathematic thing higher your Precision lower your recall and vice versa then people start to use um scientic metrics which calculate which use all of them as accuracy and precision and recall like F1 metric which is synthetical consisting of multiple of the values like precision and recall and in general that's a long story it doesn't matter if you uh don't get it too deep for now because that's not the purpose of this Workshop the purpose of this workshop for you is to understand the basics and in general it's very short we have we can measure efficiency of algorithms at least for supervised and uh not all of the m and Matrix may have like say different relevancy for your use case and one last thing before we go practical is I want to discuss underfitted and overfitted model in this case we have uh the H same set of data process it with uh differently configur it or maybe different algorithms we we are trying to predict some values on those things and we have uh three kind of models uh left Center and on the right and uh let's take at the let's take a look at the left example we have pieces of data our circles black circles here and we have this uh dotted line dotted line is the prediction is how our model works and in this case they see these result of this model aren't so good it's uh maybe wrong algorithm or not well configured algorithm and we see what this underfitted model is not accurate it's just too simple we have more complex um set of data and we have just one straight line so that's a bad example in the center we have a good feed or robust model which is well generalized model should not try to catch um and be perfectly uh precise on for every dot we have but in general it should find in this case the general Trend the main idea of the data we have and on the right side we have overfeed model that's exactly overtrained model which tries to Feit into every piece of data you have and as a result it's trying to be too much precise it gives bad result over a roll it's overfitted model it works perfect on the train data because it fits literally into every point of the uh train data you give but then as soon as you start test and it found outs like what something is not perfect um then it works not so good important for us we want to keep our models General enough and we don't want them to be too precise we will discuss it uh later more practical on one of the models well practice is golden talk talk is cheap show me the code show me how it works very simple um before we start few words about the tools we are going to use uh luckily those aren't the tools on the right but more the tools on the left I mean well it's still uh almost two months in year 2020 so we still have a chance yeah yeah yeah oh man that's you so what we are going to use first uh tool we are going to work with is the apach spark um full title is an open source distributed general purpose cluster Computing framework my God that's even sounds awful but uh explain explanation is very simple do you remember our ke means example we had like around 100 of dots and for every Center of mass let's say k means algorithm should have calculated the length and the vector and if I should move in this direction or maybe move in that direction so it's spread to a lot of computations but in the real world you are going to work with maybe billions of rows of data in explaining very simply spark helps you to run those computations on M multiple computers at once usually powerful servers so whatever we do today on this example you can calculate on your laptop because we work with data sets of some thousands but when you start to work with real big data your laptop is mostly Pro probably going to melt after an hour or maybe sooner so for this we in real world we use spark which helps us to distribute calculations over multiple servers uh spark is a great open- source tool and it works very well with the Apache Cassandra which is a second tool for us what is the Apache Cassandra and why do we care Apache Cassandra is a free open- source distributed decentralized noise Quil database in short it's a database which is a big data ready it ready to handle dos petabytes and hundreds petabytes of data over the world and that's one of the most powerful databases we have right now for example for a long time we were sure what the biggest Cassandra deployment uh was done by Apple you maybe have heard something about Apple they released those uh mobile phones with apple on the back doesn't matter so their deployment was around 100,000 notes but funny point we were wrong because we found out what uh there is a company which has even higher number uh with Huawei uh China has around 160,000 servers dedicated to work with Cassandra 160,000 servers to uh handle data so that's something I I call Big Data really and also there are guys like Netflix Instagram and so on and so forth good so Cassandra is a database to store Big Data I need to make good decisions uh in my business for example then Jupiter and data stack studio in our case they are very uh similar by the idea I use Jupiter to work uh with apach spark it's for me it will be just like a weap interface to work with spark simplifying that and I will use data stock Studio to work with papach Cassandra can you can consider data stack Studio as a web interface for apach candra then uh python well I will not spend too much time explaining what the python is uh and but well you may want to know what python is very widely used in the machine learning yeah uh when we have some libraries for python uh we will need to use today those a pandas pandas uh is the uh package providing all tools you need to work uh with the data for machine learning analysis in Python uh then p park is a simple integration Library which helps python to work with Apaches spark you will see uh NPI is a package for scientifical Computing with all the array objects uh linear algebra uh for transform and so on and so forth and then finally psychic learn psychic learn is again uh set of tools I would say big package including many many different things um to help you not only um work with data and run the machine learning algorithms and calculate something and predict something but also visualize that because well humans aren't computers we prefer to see first and how it works all together just to so everything what we are doing you can completely do with Apache Cassandra and apach Spark in our case to simplify setup we are using them packet together already by data stocks that's a package called a data stocks Enterprise it's uh free for non-commercial use like mean like that for educational purposes basically that's Cassandra spark and some more secret things uh bound together and on the left side we see data stack Studio to work with Cassandra where Ro data and on the right side we see Jupiter notebook to work with already our uh machine learning uh code we will use so uh that's how you work with a local environment doesn't matter but at first I say ask you to follow me and then do those steps on your own today we are going going to cover two steps and and um we you will have three more tasks to do on your own uh via Cloud instance or on your own laptop as you prefer first algorithm we will cover in the Practical step is a naive bias supervised classification algorithm it's kind of very old algorithm and very well known in the machine learning field uh watch that and how it works as usual Wikipedia definitions aren't so much helpful like with all this naive bias classifiers are a family of simple probabilistic classifiers basic on the applying bias theorem with strong knife and I don't like that let's move on and let's uh see how it's uh how to explain that easier for humans and funny enough this comic is the best possible explanation of the knife bias simple as that uh um it's written in the scientifical way I will explain in a moment but uh in general the idea is very short if you pick up a sea shell fact number one and if you don't hold it to your air fact number two you can mostly probably hear the ocean where is the trick of the chain of the dependencies we will we will work deeper on the next slide but uh really the that's the uh best possible explanation of a naive bias if you want to make a deeper dive follow me so I'm going to apply naive bias algorithm now uh first thing uh we have to prepare and label data and we will use very traditional spam problem so there are I don't know how many emails on the internet happen to be every day but amount is tremendous and every second even yeah yeah every even second every second and problem of most of them you don't want to read because they are trying to steal your money or steal your credentials or steal your something I don't know and uh we want to get rid of them so first as it's the supervisor mechanism we discussed before we are going to prepare and label our data what does that mean three million per second okay yeah yeah so that's why uh your laptop will be not enough although it's a good laptop but we still will need spark to run computations on multiple of servers yeah so well crazy um in this example we have one two 3 four five six seven emails very is very small small data set we agree like the amount is in billions and billions and billions usually uh but you will be surprised at how good this algorithm works even based on those seven of emails so what's the first preparation we do we work with the topics uh of emails subjects of emails and we have to label them and we have to identify if the email is Spam or not uh say as a result of those emails we have this little table we have three emails identified as spam money transfer receiv it get cash easy win money now and we have um five emails those are not spam uh greetings from Dad could you lend me money it was easy I miss you check your trip itinerary like uh should be more or less familiar to everyone some of them are spam some of them are not spam what we did right now we prepared our data and we label at this data very good now we know which email is Spam and which email is not spam first step we can do and we will need that later is we calculate the probab the chance of email to be spam just based on the numbers and the uh chance is pretty simple it's three of eight of email being spam in this example and five of eight email is not spam uh based on those numbers we have can we improve this knowledge let's take a look so um our database small database our data set small data set on the left and on the right we have a little story I received a new email with the subject easy money is it spam or not how human say that what is the chance it spam if a subject is Easy Money how scientists say the same idea that's the formula you've seen already probability of this uh email is Spam given it contains easy and money in the subject what will it be so this statement what is the chance of it spam if it has easy money and this uh formula let's say this statement they are exactly the same but second looks more scientifical so now you can write everything like that then you are calculating probabilities and now you will look like a data scientist um so and now we start to think of the topics subjects this email we are working with right now has Easy Money subject so uh we analyze that step by step uh we have uh money word money in two out of three spam emails so take a look that's our spam data set very small money transfer reive it win money now in two out of three spam emails we have had this uh word so probability of this um email uh will contain now not notice we have here spam and easy money on the right side we have facts on the left side we have uh what do we want to know and now out of this money two out of three spam has word V money we can calculate what's the probability of this email contains word money in the subject given its spam know it's spam it was labeled before we know what probability is two out of three and working with not spam we know what only one email out of five uh got this word money so we see probability what word will contain what email will contain money if it's uh not spam is one uh divided by five then we do the same job for easy word easy was once in spam and once in not spam one out of three spam so probability word contains easy sorry there is a type of uh in spam is 1 divided by three and 1 out of five 1 divided by five now where is a lot of numers so maybe you dizzy a little bit uh so okay now we have a set of probabilities how does that help us very simple and very cool feature conditional probability the chance what this email is Spam or not spam always equals one because email cannot be half spam well let's say it can be in some chances in some cases but we are discussing like the simple scenario okay so we know what email is or not or spam or not these probabilities counted together will or always will be equal one and now uh that's the uh heart of the naive bias algorithm we calculating probabilities uh of this uh based on the data set we have and that's uh very long thing and notice we are working of a very simple data set like how much more computational power you may need to calculate similar things on the real data set uh so we can uh cover that um in this way that's uh and downstairs we have it with real numbers and here with explanations uh probability of the email is Spam given it has words easy in money in subject is the result of all of the probabilities we calculated already first is uh what's the probability of this email to be spam in general um when uh what it contains easy uh and what it contains money and intersection of first probability is going to be 1 ided by 12 or as a final result when we are bringing them together 10 divided by 13 because we know what the overall probability can always can be only one and in the second example probability what is not spam will be the same thing but just apply data set from the not spam field uh data and we see what we have after processing very very simple uh flow which is very easy to distribute and calculate on multiple machines we have based on this data set of eight emails new email with subject easy easy money has probability to be spam over almost 77 persons and that's where a result of a very simple work uh on the eight emails we have right now and that's already pretty accurate I would say so um getting a little bit back how it works uh it's a reversed uh dependency first we uh calculate these data on the simple way so we have labeled emails we know what um money uh What uh probability the email will contain um so we trying to calculate probability this email will be spam based on the subject and then they are using reversed think probability this email will contain one of the key words we are looking for given its uh spam or not so these numbers like two divided by three comes from uh this data set of labeled emails man transfer re it get cash easy win money now two out of three and we are working only with subjects okay then bias algorithm we see but why it's called it naive bias how it comes uh very simple naive bias doesn't consider relation between facts for example if I write a word happy probability of the next word to be birthday is kind of significantly higher than the probability of the next word to be funerals and if I say long long ago chance what person next to me will proceed in a galaxy far far away is higher than any another phrase I don't know um this algorithm does not consider those dependencies uh it's all isolated facts um uh for this algorithm it may uh look like pretty stupid but surprisingly it's not uh on the uh big data sets it's at some point doesn't matter after all because usually you work with a data set not of eight emails but more like 8 billion emails at this size at this scale it doesn't matter after all and all what I say now is very easily explained on the right side of screen uh close to Cedric uh from the human point of view it can be or cold or warm outside for from the knif bias algorithm those are isolated facts and it can be sorry uh it's always ready to answer without considering the dependencies between facts we are taking now let's take a look how it works works so you will do it on your own we have a bunch of uh exercises to do now I'm at my Jupiter instance and uh here I work with uh Jupiter with I work with apach Park via Jupiter and with Cassandra as well yes so to get the Jupiter you can go um you know the compos upd as written in the Ry but hey please follow Alex uh and you can do the exercise later with your data set on your own yeah actually I know why people always uh run to do exercises uh during the workshop uh because um people use it to as soon as Workshop is done everyone quits and there will be no answer ever that's wrong we stay here for you even when Workshop is done we have our Discord server so you can it's you can completely go to our uh main chat uh in our Discord and work with us and ask us our questions and we will answer yes yes you can even create some dedicated rooms you know for topics if you want please ask we are 6,000 people in the Discord yeah definitely so um Workshop is not over as long as you don't want it to be over okay and and now there is no uh need to hurry and try to do everything with me you can do it alone and then ask questions via Discord and yeah as said you can clone this data Stacks Academy machine learning workshop online repa or you can um grab a cloud instance uh contacting me so as a result you anyway going to have two web interfaces one is um Jupiter and one is data stack studio and we start with Jupiter uh now I want to work with naive bias and this example was developed um hey there I just clicked that this example was developed by our former colleague uh Amanda and uh she's great she now works uh at Apple I believe and we miss her a lot but in your memory at data stocks let's say we will run this example and this example operates wines and wine qualities why because we can well you know I'm Russian because it's important as well oh okay you know I'm Russian so I'm not so much into Vines I cannot analyze them but maybe cedic will help us yeah basic I wouldn't trust Narin to to judge a wine so we will see uh if it algorithm works good or not so good we will see maybe it's not the best way and you know what that's always about iterational Improvement you try this one uh you train the model you get the results you assess the results and you see if you are satisfied or you are not satisfied and there is something to change so I don't know maybe this uh algorithm will work not so good for us okay yeah so um what we are trying to learn from this data set question can naive buyers be used to classify a wine rating score by its attributes so we have a set of wines uh people some experts uh try them and set some ratings like that's a great wine this one wine is not so great and what we want to try with a machine learning in this example we want to try to predict will those experts like our new V let's say or not and which kind of data we have first of all we have some wines with ratings already and we also know chemical um how it's called it in English chemical uh yeah chemical it's chemicals yeah yeah yeah uh those chemicals it contains and can it work together uh using naive bias or maybe not so much so uh how do you use Jupiter notebook this uh you will have exactly the same thing as I have right here you see what I've activated naive bias uh notebook uh by the way it's important every notebook is a pretty uh big thing it doesn't look like big thing but it's a big thing so uh if you have all of them running uh memory of your machine was probably going to be very busy so what you want to do as soon as your notebook is done I L suggest to shut it down otherwise if you have five of notebooks are running it will be too tight for them to work efficiently okay so there are some text Fields I will not touch and there are some executable lines I'm going to touch to execute a line I set my cursor on it so it's highlighted in green I will try to make it a little bit bigger yeah looks good I think it looks good mhm good and it's huge okay even better and I will do it full screen yeah great and I push the Run button to execute this statement and first one is very simple first two actually are very simple I'm in importing dependencies I will need and you may see some familiar depend dependencies here first like pandas we discussed it some minutes ago then P spark we used to connect to python to spark Park and Cassandra we use to connect to Cassandra we will need some random things and from P spark we uh import the most important thing for us machine learning classification we import naive bias algorithm and we will need some uh vectors vector assemblers and string indexers to prepare data uh for to be processed then next step I want to do is just a little helper function I run this uh string not string cell cell is a better name I run this cell to Define uh function I will need if you are into python you know what that's the way how we Define uh functions if you are not well you can just trust me it's good enough for today uh that's nothing big just helps us to display lines of code and then we start to load data first to work with data we will use Cassandra um you can do the same things uh loading data directly from the files but that's not how it works in real world so at first we connect to Cassandra and we let first we connect to Cassandra connected and we are going to uh create a key space we will store our data if you attended one of our Cassandra workshops before you know what what does that mean if you didn't and you don't know how Cassandra Works doesn't matter Cassandra is just Cassandra's key space is just a group of tables we are going to use together so here I'm creating keyspace to store my data good and I set these key space accelerate to be the default key space for me and I create table create table if not exist wine and that's what we have uh we are going to have in this table at first every vne has 11 chemical values acidity volatile acidity citric acid and so on and so forth and uh uh alcohol like so how much alcohol it has oops and finally the quality uh quality is uh um the result of this Vine being assessed by Vine experts uh maybe Cedric was one of them I don't know I wish I would well uh you still have enough time okay so we created with stable we can double check that by going to our data stock studio uh open our naive bias classification and at first I may ask to describe keyspace accelerate I have to make it a little bit bigger again yes please good so yeah it's here we have keyspace accelerate and we have uh table vines with all the values we discuss it and by the way you see there is a lot of lines and properties we haven't defined predefined properties for Cassandra Cassandra is the best tool to manage uh petabytes of data and dispatch from within very tiny milliseconds so if you work with high LS like that you definitely want to attend one of our Cassandra workshops uh closest intro to Cassandra Workshop happens to be this week I believe yep exactly this wedes day and Thursday two times yes yes yes yes yes and you know what I feel like you know having Cassandra to help uh spark to train the model is uh pretty relevant because you may want to use a distributed uh algorithm to train because it's a lot of data and Spark is distributed C is distributed I think it's working well together and it's not only using CSV files as you may uh tends to do uh when you're working with machine learning good okay so we have uh it prepared it now we have to load data set love the pictures yeah well that's Amanda I would set I still want cheese now you know oh yeah good so uh we are loading wine data sets from CSV files uh we have two CSV files prepared one for red and one for white uh wines uh so I simply execute this cell and it will take some time because we are reading from two files and uh inserting data okay it's done very well so now we can again open data stack studio and ask to show those values good and we see the data we have we've all disc discussed qualities very well then finally we are getting closer to spark so Cassandra is very good when you have to store data and disp tou it on the production uh real production workloads to not make your customers waiting candre is very quick and now we need spark to connect to Cassandra and load this data to execute machine learning operations so let's take a look what's going on I'm using previously imported spark session Builder um with application named demo doesn't matter master so Master of the spark cluster will be local that's a uh educational cluster not the real big one and I get or create the spark when I um I will execute it right now because it will take some time so we can walk when I have to define a wine data frame to do so I ask spark to read data in the format uh Cassandra with options what I'm going to read table wine keyspace accelerate and I need to load this data after that I'm printing output what's the count of the wine data frame I've downloaded data frame is a spark definition not the Cassandra one because here we are using spark as you could see it only loads data from Cassandra and we see what we have almost 6,500 wines and their estimations W yeah um why do you need more than two wines Cedric I mean white and red should because we are not Russian and drinking vodka oh no it's too complicated for me but whatever some flavors you know uh so we have show data frame that's the function we defined it in the beginning just to keep it like uh nice and we see what every wine has ID alcohol some chem IAL values and uh quality as well now next thing we want our wines to be the best so we are going to filter out all vnes with quality lower when uh five uh first we are using the spark feature called it filter so we are doing qu data frame. filter quality bigger than five we Define new data frame which is will be Vine six data frame with all the vines quality higher than five and we show this data frame boom so now you see what I have all the vines in this list uh with quality six or higher good then we have to prepare uh data to be properly Pro assess it so as we are using naive bias first everything has to be a vectors um to uh prepare that things we are using Vector assembler and as an input colum colums we are using alcohol chlorides um free sulfur and so on and so forth so all the chemical values we have uh preparing these uh uh vectors needed for um oh my god um for the naive bias to be uh processed and for us it will be just features as an output columns we need and then uh we uh prepare training data we will use to train with this assembler we transform WI six data frame and training data as a result of his data processing of wine six data frame with all the high quality wines we have uh prepared for the training few more things we need to do first one we uh need to set the labels as discussed that's a supervised learning so we need labels in this case labels will be built on the quality because we are going to work with quality and output colume will be just label and as a result we have uh here training data one using the values we prepared for us so we get our label indexer which is a St St string indexer based on the quality we are trying to classify those vnes we have into multiple groups uh based on their chemical values we are having here we are fitting these training data with indexer and finally uh transform with training data and I'm launching these and we receive the results we are creating the vectors with all the elements of wine in this case everything is already prepared and we have count of training data we have is uh 4,000 so we separated that and prepar it um so we uh have 4,000 and something wines of quality high enough to participate in our learning and now all the data is prepared and we finish it with preparational step and we need to split up our data set into training and set usually it works a little bit uh more complicated so we need training validating and test set for cross validation as that's a simpler example and starting from Basics we will have just training and test set and we will split 80 to 20 so first we just split we use training data with a random split so way will be splited randomly some goes to first set some goes to second set and proportion will be 0.8 0.2 uh and we have as a result two sets here train and tests I'm executing this one it's going to be pretty quick because we aren't uh doing learning yet we just doing the uh separation so we have three 3,366 uh in the training set and 747 in the test data frame now it's finally time to launch that uh so uh we are launching naive bias we Define that first um we here train the model we do with train data from the previous step we calculate our predictions uh based on the test data using the same model so here learning comes here we are doing our predictions I'm launching that okay so we are showing results of our predictions in this case quality is the new field predicted uh by our model that's uh this field is not available and um we can run these uh predictions to show the most important thing for us quality um and uh label predictions and probability so the fields required here and now uh we uh train it our model we process it test data that's important to remember test data goes to model without quality so the quality of that will be not available that's our predictions already not the the values from the data set we have and finally we use multiclass classification evaluator to evaluate the accuracy of our predictions so we did predictions are they good or not so all the previous lines are executed and now we can try to execute that and we see what test set accuracy is 0.6 so uh Cedric it looks like you were right right and machine learning or at least knife bias algorithm in this case is not the best way to uh try to predict the quality of wine maybe we should simply ask you next time I'm really maybe they need more data set I'm happy to enter those data I need to test the wi though good but that's not the end because we have uh some more things to cover so we will get back to this example very soon the only thing I want to tell you is I want to shut down this notebook otherwise I will have too much of the running uh notebooks in the end good okay so let me get back and now I want to take at take a look at the another algorithm we may need to use today to get better prediction on the uh data set we were working with random Forest is a supervised classification emble method and notice that's not an algorithm but the Ensemble method I was talking about algorithms and now there is an ensemble method what does that mean let's take a look first it all comes from a decision tree um uh on the left you as always have the definition from Wiki which never helps and I want to um explain that on the simple example on the right decision tree is a simple uh way very simple maybe one of the most simple uh algorithms possible decision Tre is an algorithm which basic which kind of answers questions uh yes no higher lower equals not equals and uh calculates things uh based on the answers trying to combine different questions and ANW um decision three for Titanic Survival on this case is at first level based on the gender at the second level based on the age and in the third layer based on the siblings count amount of brothers and sisters so here with the decision Tre we are calculating what's the probability what were the probability to survive survive in the Titanic disaster um back in in the last century so and that's a very simple decision Tre because yes they are simple um decision Tre algorithm tries to calculate the best possible decision tree uh based on the labels you are giving and we see how in this case uh answering first uh gender allows us answering first question allows us to uh Define the probability to survive and if it's situation is is more complicated then it tries to add more questions to answer with different values uh if H is more than 9.5 years probability to die for a gender male was 61% and depend if age was smaller than 9.5 then it depends of amount of siblings this kind of decision trees are generated easily by the algorithms and they have all a big problem uh by it is a single decision tree has a strong tendency to be overfeed it works perfectly with the data you're giving training data so giving generating those questions and answers and answering them uh it behaves very good on the training data but as soon as you give test data which was not available on the training time it immediately uh start to give very wrong answers because it's overfeed not General enough to solve this problem we use Ensemble method random Forest random Forest is a a method uh which unites multiple decision trees and as those decision trees uh answer ask and answer different questions they as a result give good General enough uh method uh and although every decision tree is very simple by it is they are also uh very uh good and reasonable United by random Forest method um my random Forest by uh it is also has some configurable parameters for example you may say what every decision tree has the same weight of the answer or you may say what the decision tree based on these values has higher uh weight uh for the following answer um in this case we will use the very simple approach so let's take a look Maybe random Forest will work better for us and cedc Has Cedric has something to be afraid of I don't know I have no fear good so I'm launching uh my random Forest notebook and in Data stock Studio I will jump back to notebooks and switch to random Forest notebook good so same data set um I may need to do a little clean up on data maybe but we will see so run run first two steps uh should be very familiar to you so I'm loading new um I'm loading dependencies uh in this case it will be a little bit different because I'm going to use uh python americ classification algorithm random Forest classifier which is again not an algorithm but emble method good I'm defining the uh so that's a new notebook and therefore it's a new environment so I have to redefine things I'm us it already I'm defining the same show DF uh function for pretty formatting of a data we work to I has to contact my Cassandra cluster and I will use the same uh key space it exist anyway and I will use that for all my data good so I want to kill this table and load the data again but actually it should has the same data as far as I remember so we can simply proceed to The Next Step so table is available data is loaded and we can start to work with spark directly okay so we have the data here and we see all the values we process it already now we will apply another approach so that's always about iterative and trying to find something what will works better so I'm creating data frame with one of higher qualities good and uh now I'm uh vectoring Vector fying um data I'm going to work with so that's the steps we did in the previous step uh we will need indexers um and vectors to prepare all the data uh to be strongly strongly mathematical for the random Forest to answer in the simple way very well and now we have to split our data again into training set and test set so you've seen that already we will use train set to train model and we will use test Set uh to evaluate model if it's good or not and now that's interesting uh thing happens so we will use random Forest classifier uh from uh spark Library um label column so the label we want to give will be label uh features column is the features so that's the think we prepared it in this previous step and finally number of trees do we want to have will be equal 10 m uh here we go with this step uh so we are running this random forest classifier and train that and when we do predictions one more time don't forget on the train data with a predictions our model will not have access to we quality estimated assessed by the experts but it will be result of the our model to work good so we done with training based on the 10 trees in this method and we can run predictions and show results uh show predictions uh based on the training we did before and now we can use multiclass classification evaluator to evaluate the accuracy of our prediction so this evaluator we need to estimate how it works if it's good or not label column will be label so the uh prediction so the quality for us is and um metric name is accuracy so we want to measure accuracy I'm running this one and we see what accuracy just jumped up from 0.61 to 0.7 so it looks like we are moving in the right direction uh um I see the question aren't we overfeeding the data if we would go into the smaller amount of trees when yes but you know what I would ask uh you in this case uh to try to play with the amount of uh trees and see if it if it will work better or not and when we can talk about that in Discord so uh and we have to say thank you because it was a great time together more than one and a half an hour and we are ready to try to answer some of your questions in General Life part of the workshop is done and we will be happy to see you again on all of our upcoming events yes so we just demo two algorithms with our Nave bins and random Forest if you see uh on you know Jupiter you can also try some FP growth and collaborating filterings which are more Deep dive but as usual everything is pretty well designed and written for you so yep so uh that's an intra very int level Workshop it's a big field uh and I want yeah it's a very big field so if you want to get a deeper di into that now you know uh at least how it works in general and uh it was a very good place to start but if you want to master that if you want to become a data scientist you definitely going to plan some time accordingly to learn all the required things uh uh thank you everyone uh for I see a question can we apply K means alga to this problem uh good question simple answer we could try but uh it will not work so in this case we work with um labels we understand what quality of this wine is five or six or seven or eight and so on and we want to see where our new estimation gets and uh K means is a good thing uh but um doubt if it will work so much uh for this example because well it's about different thing it's about grouping things things for example and yeah I wouldn't go with K means for this example definitely last thing I want to say for today we we are preparing something special for you but before it's ready we still have announcements of all of our upcoming events on event bride uh with data Stacks first we have an action certification exam preparation Workshop now data Stacks has great special project uh so you can become a certified kapach Cassandra expert absolutely for free zero expenses you only need to put your time into e and efforts into effort yeah efforts yeah there is no free meal you still have to but no money at all yeah so uh that's an associate level exam and uh even if you are beginner developer if you know how to write code uh you can handle this with our video courses video courses are available at the academy. dat.com and how to do and how to prepare for the certification completely explain it in this exam now uh Monday learning introduction to machine learning just finish it uh Cloud native Cassandra introduction to Cassandra this wedness day and this Thursday um so hope to see you soon next Monday we have kubernetes native applications so uh it's not easy now uh okay Cloud development and cloud cloud ecosystem and containerization kubernetes helps to develop and deliver applications a lot but that's uh still making your application efficient is a sh shared responsibility it's not only for operations guys to run it into the kubernetes but also for developers to understand some requirements in this Workshop we cover exactly the point how do you design and write your applic ation so way will be uh efficient uh in the operations time on the production I strongly recommend this one and uh finally upcoming next week we will have putting Apache Cassandra on automatic with kubernetes and um that's how we run Cassandra in kubernetes that's for those who already into Cassandra a little bit and one more thing I wanted to announce I hope Cedric will forgive me for announcing a little bit external event but I speak there so I hope it's a reason good enough to find that give me a moment oh you know um any content we provide of course we should promote it more um if you are not subscribed to the channel you should I mean we are live multiple times a week so twice on Monday uh this week is machine learning Wednesday Thursday it will be in TR candra and next week it will be a lot of kubernetes Monday Thursday and Wednesday will be on kubernetes pretty exciting stuff with a single Elm recipe you will get ton of things running yep uh so and last announcement so it's going to be uh Tuesday November 10th at 6:30 e so for European people it's going to be a deep night my God but yeah can you copy paste the link this this link on the chat absolutely you are very right good so um that's about uh designing CR silent systems based on Apachi Cassandra ideas I would say it this way uh so Apachi Cassandra is one of the most powerful distributed systems which is used by nearly all of the companies uh on top of a world who works with big data spread it over the world and I'm analyzing the general principles of this um system and what makes Apachi Cassandra so Rec silent and so powerful in the question of keeping data and being disaster tolerant and highly available and be able to answer your question within milliseconds in any moment of the time that's not a particular how to that's not a tutorial but more discussion of a general principles what makes application more efficient and able to survive any problems and be deployed in every part of the world at the same time yep good so that was Cedric LAN director of developer advocacy at data stacks and that was yeah Alex Al yeah and and we are very happy what you were here with us and we can't wait to see you on our events now we can meet you only virtually hope at some point this pandemic will disappear and we will meet again all all on all of the events around the world so far it's the dream only and for today uh we are done and happy to see you again on the next event thank you see you soon bye",
    "segments": [
      {
        "start": 0.08,
        "duration": 4.719,
        "text": "hello everyone and welcome to the"
      },
      {
        "start": 2.24,
        "duration": 8.12,
        "text": "another episode of data stocks Monday"
      },
      {
        "start": 4.799,
        "duration": 8.281,
        "text": "learning hi Cedric Hello Alex yeah so I"
      },
      {
        "start": 10.36,
        "duration": 5.239,
        "text": "see some people have joined us already"
      },
      {
        "start": 13.08,
        "duration": 5.039,
        "text": "it's a big pleasure to see you all here"
      },
      {
        "start": 15.599,
        "duration": 4.801,
        "text": "so if you can see us if you can hear us"
      },
      {
        "start": 18.119,
        "duration": 5.041,
        "text": "please set your thumbs up in the YouTube"
      },
      {
        "start": 20.4,
        "duration": 4.56,
        "text": "chats or Discord chat so we will know we"
      },
      {
        "start": 23.16,
        "duration": 5.039,
        "text": "are together and we can"
      },
      {
        "start": 24.96,
        "duration": 5.2,
        "text": "start yeah so today I will track uh the"
      },
      {
        "start": 28.199,
        "duration": 5.2,
        "text": "Youtube chat so if you do have a"
      },
      {
        "start": 30.16,
        "duration": 6.0,
        "text": "question don't hesitate I will stop Al"
      },
      {
        "start": 33.399,
        "duration": 4.881,
        "text": "Alex if we need to or if not I will try"
      },
      {
        "start": 36.16,
        "duration": 7.399,
        "text": "to answer you back in the"
      },
      {
        "start": 38.28,
        "duration": 9.279,
        "text": "chat yeah exactly so uh it looks like we"
      },
      {
        "start": 43.559,
        "duration": 7.64,
        "text": "are good I think we have sound I I think"
      },
      {
        "start": 47.559,
        "duration": 7.0,
        "text": "we have everything what we need so it"
      },
      {
        "start": 51.199,
        "duration": 7.441,
        "text": "must be good to start all right yeah"
      },
      {
        "start": 54.559,
        "duration": 6.8,
        "text": "okay so uh I believe some people here"
      },
      {
        "start": 58.64,
        "duration": 4.599,
        "text": "who attended one of our last events"
      },
      {
        "start": 61.359,
        "duration": 4.76,
        "text": "doesn't matter if it's a Cassandra"
      },
      {
        "start": 63.239,
        "duration": 5.481,
        "text": "Workshop series or maybe data stocks P"
      },
      {
        "start": 66.119,
        "duration": 4.921,
        "text": "learning we will introduce ourselves and"
      },
      {
        "start": 68.72,
        "duration": 4.68,
        "text": "you will know what's going on but in"
      },
      {
        "start": 71.04,
        "duration": 5.36,
        "text": "very short data Stacks Monday learning"
      },
      {
        "start": 73.4,
        "duration": 6.44,
        "text": "is our way to make your Monday Monday"
      },
      {
        "start": 76.4,
        "duration": 5.8,
        "text": "your best and most beloved day of a week"
      },
      {
        "start": 79.84,
        "duration": 6.44,
        "text": "because we are always trying to do"
      },
      {
        "start": 82.2,
        "duration": 6.559,
        "text": "something special on Mondays for you and"
      },
      {
        "start": 86.28,
        "duration": 4.64,
        "text": "be picking the most important technical"
      },
      {
        "start": 88.759,
        "duration": 4.521,
        "text": "topics only for from Engineers to"
      },
      {
        "start": 90.92,
        "duration": 5.159,
        "text": "Engineers no marketing"
      },
      {
        "start": 93.28,
        "duration": 5.64,
        "text": "absolutely for free yeah I mean I hope"
      },
      {
        "start": 96.079,
        "duration": 3.68,
        "text": "no no no no one of marketing is watching"
      },
      {
        "start": 98.92,
        "duration": 4.72,
        "text": "this"
      },
      {
        "start": 99.759,
        "duration": 6.36,
        "text": "video no they are not awake but you know"
      },
      {
        "start": 103.64,
        "duration": 5.4,
        "text": "one important Point as well is it's kind"
      },
      {
        "start": 106.119,
        "duration": 5.68,
        "text": "of beginner content on Mondays so you"
      },
      {
        "start": 109.04,
        "duration": 4.92,
        "text": "can start from scratch and learn yes"
      },
      {
        "start": 111.799,
        "duration": 4.761,
        "text": "exactly so we want to cover important"
      },
      {
        "start": 113.96,
        "duration": 6.04,
        "text": "topics for those who are not so much"
      },
      {
        "start": 116.56,
        "duration": 6.199,
        "text": "into their uh things like today we are"
      },
      {
        "start": 120.0,
        "duration": 5.24,
        "text": "going to speak about oops today we are"
      },
      {
        "start": 122.759,
        "duration": 5.121,
        "text": "going to speak about machine learning"
      },
      {
        "start": 125.24,
        "duration": 5.4,
        "text": "but not in the scientifical way or not"
      },
      {
        "start": 127.88,
        "duration": 5.96,
        "text": "in the very deep dive way you don't need"
      },
      {
        "start": 130.64,
        "duration": 6.319,
        "text": "to have a mathematics uh degree to get"
      },
      {
        "start": 133.84,
        "duration": 5.72,
        "text": "into that we always speak about complex"
      },
      {
        "start": 136.959,
        "duration": 4.441,
        "text": "things in a very simple way so even if"
      },
      {
        "start": 139.56,
        "duration": 4.6,
        "text": "you're a complete beginner in this field"
      },
      {
        "start": 141.4,
        "duration": 5.08,
        "text": "you can get everything we are talking"
      },
      {
        "start": 144.16,
        "duration": 4.92,
        "text": "about by the way as we are speaking"
      },
      {
        "start": 146.48,
        "duration": 4.56,
        "text": "about data stocks Monday learning next"
      },
      {
        "start": 149.08,
        "duration": 4.96,
        "text": "week we have something interesting"
      },
      {
        "start": 151.04,
        "duration": 6.559,
        "text": "especially for those uh who is already"
      },
      {
        "start": 154.04,
        "duration": 7.16,
        "text": "into the docker things or maybe who"
      },
      {
        "start": 157.599,
        "duration": 5.841,
        "text": "attended our Docker learning path next"
      },
      {
        "start": 161.2,
        "duration": 5.119,
        "text": "week we speak about kubernetes Native"
      },
      {
        "start": 163.44,
        "duration": 5.24,
        "text": "applications and will be a great expert"
      },
      {
        "start": 166.319,
        "duration": 4.361,
        "text": "in this field a guest speaker which is"
      },
      {
        "start": 168.68,
        "duration": 4.04,
        "text": "not a part of a data stack developer"
      },
      {
        "start": 170.68,
        "duration": 6.479,
        "text": "Advocates team and that's great because"
      },
      {
        "start": 172.72,
        "duration": 7.68,
        "text": "we love guests yes we do"
      },
      {
        "start": 177.159,
        "duration": 5.44,
        "text": "okay and today is going to be"
      },
      {
        "start": 180.4,
        "duration": 5.28,
        "text": "introduction to machine learning with"
      },
      {
        "start": 182.599,
        "duration": 5.72,
        "text": "Apache Cassandra and apach Spark we want"
      },
      {
        "start": 185.68,
        "duration": 5.36,
        "text": "to be practical so we don't want this"
      },
      {
        "start": 188.319,
        "duration": 5.321,
        "text": "Workshop to be too too theoretical we"
      },
      {
        "start": 191.04,
        "duration": 5.479,
        "text": "want you to be able to put your hands on"
      },
      {
        "start": 193.64,
        "duration": 5.319,
        "text": "and use real uh applications and real"
      },
      {
        "start": 196.519,
        "duration": 4.881,
        "text": "systems people use to apply machine"
      },
      {
        "start": 198.959,
        "duration": 4.321,
        "text": "learning into the real"
      },
      {
        "start": 201.4,
        "duration": 3.64,
        "text": "life"
      },
      {
        "start": 203.28,
        "duration": 5.72,
        "text": "so"
      },
      {
        "start": 205.04,
        "duration": 6.64,
        "text": "and let's just two words about ourselves"
      },
      {
        "start": 209.0,
        "duration": 5.959,
        "text": "you may be know us already that's Cedric"
      },
      {
        "start": 211.68,
        "duration": 5.88,
        "text": "on the left to me and or or on the right"
      },
      {
        "start": 214.959,
        "duration": 6.681,
        "text": "I don't know yes on the right this side"
      },
      {
        "start": 217.56,
        "duration": 6.679,
        "text": "exactly and well we work at the data"
      },
      {
        "start": 221.64,
        "duration": 5.48,
        "text": "stocks the main company let's say Behind"
      },
      {
        "start": 224.239,
        "duration": 5.521,
        "text": "the pajaka sunram B in apak Cassandra"
      },
      {
        "start": 227.12,
        "duration": 5.16,
        "text": "happen and uh we work at the developer"
      },
      {
        "start": 229.76,
        "duration": 5.88,
        "text": "relations team so we are engineers and"
      },
      {
        "start": 232.28,
        "duration": 5.159,
        "text": "developers um helping our developers to"
      },
      {
        "start": 235.64,
        "duration": 3.439,
        "text": "get better with the distributed"
      },
      {
        "start": 237.439,
        "duration": 3.72,
        "text": "applications and all the modern"
      },
      {
        "start": 239.079,
        "duration": 5.201,
        "text": "Technologies"
      },
      {
        "start": 241.159,
        "duration": 6.761,
        "text": "and Cedric maybe you will say something"
      },
      {
        "start": 244.28,
        "duration": 6.56,
        "text": "y sure so um I'm Cedric lven I'm leading"
      },
      {
        "start": 247.92,
        "duration": 6.48,
        "text": "the developer Advocate team um and also"
      },
      {
        "start": 250.84,
        "duration": 6.76,
        "text": "I'm quite a Java geek so I created ffj"
      },
      {
        "start": 254.4,
        "duration": 6.48,
        "text": "seven years ago already wow but it's"
      },
      {
        "start": 257.6,
        "duration": 7.08,
        "text": "pretty successful with 150k downloads a"
      },
      {
        "start": 260.88,
        "duration": 6.44,
        "text": "month so it's feure flipping for Java so"
      },
      {
        "start": 264.68,
        "duration": 5.44,
        "text": "meaning uh you can unable or disable"
      },
      {
        "start": 267.32,
        "duration": 5.92,
        "text": "part of your application at one time and"
      },
      {
        "start": 270.12,
        "duration": 5.96,
        "text": "I also add the chance to contribute to"
      },
      {
        "start": 273.24,
        "duration": 6.2,
        "text": "Jeepster so Jeepster is a scaffolding"
      },
      {
        "start": 276.08,
        "duration": 5.36,
        "text": "application a generator of application"
      },
      {
        "start": 279.44,
        "duration": 5.599,
        "text": "you provide the technology you want to"
      },
      {
        "start": 281.44,
        "duration": 6.319,
        "text": "use and the entity and that program will"
      },
      {
        "start": 285.039,
        "duration": 7.6,
        "text": "start you a full running app front end"
      },
      {
        "start": 287.759,
        "duration": 6.801,
        "text": "in JavaScript view angular um or react"
      },
      {
        "start": 292.639,
        "duration": 4.081,
        "text": "and back end as a spring Boot and now"
      },
      {
        "start": 294.56,
        "duration": 4.88,
        "text": "you can also have the back end with"
      },
      {
        "start": 296.72,
        "duration": 6.36,
        "text": "micronote uh and it's the ecosystem is"
      },
      {
        "start": 299.44,
        "duration": 6.12,
        "text": "just is becoming huge um yep and as you"
      },
      {
        "start": 303.08,
        "duration": 5.119,
        "text": "see we are big fans of open- source"
      },
      {
        "start": 305.56,
        "duration": 5.28,
        "text": "software and that's exactly the thing"
      },
      {
        "start": 308.199,
        "duration": 4.961,
        "text": "for today's Workshop as well as for"
      },
      {
        "start": 310.84,
        "duration": 4.84,
        "text": "every of the data Stacks Monday learning"
      },
      {
        "start": 313.16,
        "duration": 5.92,
        "text": "we are going to do all the things uh"
      },
      {
        "start": 315.68,
        "duration": 7.079,
        "text": "with open- Source Technologies"
      },
      {
        "start": 319.08,
        "duration": 6.8,
        "text": "only okay"
      },
      {
        "start": 322.759,
        "duration": 6.401,
        "text": "so uh few things we are going to do"
      },
      {
        "start": 325.88,
        "duration": 5.64,
        "text": "today and few things you have to"
      },
      {
        "start": 329.16,
        "duration": 4.599,
        "text": "understand like where and what uh is"
      },
      {
        "start": 331.52,
        "duration": 5.72,
        "text": "stored and available and what you may"
      },
      {
        "start": 333.759,
        "duration": 5.16,
        "text": "need streams that's a live stream I hope"
      },
      {
        "start": 337.24,
        "duration": 3.88,
        "text": "you are watching it live but if you"
      },
      {
        "start": 338.919,
        "duration": 5.321,
        "text": "don't that's still fine because all the"
      },
      {
        "start": 341.12,
        "duration": 5.799,
        "text": "materials stay available for you so at"
      },
      {
        "start": 344.24,
        "duration": 4.72,
        "text": "first we stream at twitch and YouTube"
      },
      {
        "start": 346.919,
        "duration": 4.72,
        "text": "but YouTube is the primary platform for"
      },
      {
        "start": 348.96,
        "duration": 4.84,
        "text": "me so twitch is a fallback Plan B if"
      },
      {
        "start": 351.639,
        "duration": 5.481,
        "text": "something goes wrong at"
      },
      {
        "start": 353.8,
        "duration": 6.36,
        "text": "YouTube then uh to ask questions you can"
      },
      {
        "start": 357.12,
        "duration": 5.96,
        "text": "ask questions at the YouTube chat by but"
      },
      {
        "start": 360.16,
        "duration": 5.24,
        "text": "as long as the YouTube uh stream is over"
      },
      {
        "start": 363.08,
        "duration": 6.04,
        "text": "chat is gone and you will not be able to"
      },
      {
        "start": 365.4,
        "duration": 6.6,
        "text": "ask questions after that to uh work uh"
      },
      {
        "start": 369.12,
        "duration": 6.16,
        "text": "like more permanent manner we use"
      },
      {
        "start": 372.0,
        "duration": 5.84,
        "text": "Discord and you can find us at Discord"
      },
      {
        "start": 375.28,
        "duration": 5.28,
        "text": "maybe uh cedri could you please uh copy"
      },
      {
        "start": 377.84,
        "duration": 5.52,
        "text": "paste the link to oh thank you you are"
      },
      {
        "start": 380.56,
        "duration": 4.68,
        "text": "thinking just ahead of time exactly yeah"
      },
      {
        "start": 383.36,
        "duration": 4.16,
        "text": "you don't even have to talk now you we"
      },
      {
        "start": 385.24,
        "duration": 5.56,
        "text": "just you know what what do they call"
      },
      {
        "start": 387.52,
        "duration": 5.399,
        "text": "that in English uh but and chocolate"
      },
      {
        "start": 390.8,
        "duration": 4.44,
        "text": "chocolate and peanut butter yeah"
      },
      {
        "start": 392.919,
        "duration": 6.081,
        "text": "something like that yeah we working more"
      },
      {
        "start": 395.24,
        "duration": 6.359,
        "text": "like a Bome now good now uh then next"
      },
      {
        "start": 399.0,
        "duration": 5.96,
        "text": "thing uh as we are going to push our"
      },
      {
        "start": 401.599,
        "duration": 6.641,
        "text": "hands on and uh press some buttons we"
      },
      {
        "start": 404.96,
        "duration": 4.88,
        "text": "will need some runtime in our case as"
      },
      {
        "start": 408.24,
        "duration": 4.44,
        "text": "it's the introduction to machine"
      },
      {
        "start": 409.84,
        "duration": 5.44,
        "text": "learning test with Apache Cassandra and"
      },
      {
        "start": 412.68,
        "duration": 4.84,
        "text": "Apache spark second we are going to use"
      },
      {
        "start": 415.28,
        "duration": 3.96,
        "text": "Apache Cassandra apach spark and a"
      },
      {
        "start": 417.52,
        "duration": 3.959,
        "text": "couple of tools required to apply"
      },
      {
        "start": 419.24,
        "duration": 5.0,
        "text": "machine learning to them and it may"
      },
      {
        "start": 421.479,
        "duration": 4.801,
        "text": "sound pretty complex but don't worry we"
      },
      {
        "start": 424.24,
        "duration": 5.28,
        "text": "have everything set up for"
      },
      {
        "start": 426.28,
        "duration": 6.919,
        "text": "you and to use that all together you may"
      },
      {
        "start": 429.52,
        "duration": 6.88,
        "text": "need some materials those are stored on"
      },
      {
        "start": 433.199,
        "duration": 4.881,
        "text": "GitHub and let me guess Cedric has put a"
      },
      {
        "start": 436.4,
        "duration": 4.84,
        "text": "link"
      },
      {
        "start": 438.08,
        "duration": 5.559,
        "text": "already yet not yet no because in the"
      },
      {
        "start": 441.24,
        "duration": 5.079,
        "text": "description the link is shrink so yeah"
      },
      {
        "start": 443.639,
        "duration": 5.081,
        "text": "in I need one more minute don't worry in"
      },
      {
        "start": 446.319,
        "duration": 5.401,
        "text": "the description link is a little bit"
      },
      {
        "start": 448.72,
        "duration": 6.84,
        "text": "outdated I would say I have to fix that"
      },
      {
        "start": 451.72,
        "duration": 7.24,
        "text": "but actually we have a newer link I will"
      },
      {
        "start": 455.56,
        "duration": 6.479,
        "text": "okay provid the proper link now done so"
      },
      {
        "start": 458.96,
        "duration": 6.239,
        "text": "it's going to be Academy everything is"
      },
      {
        "start": 462.039,
        "duration": 6.321,
        "text": "on datax Academy GitHub account yeah"
      },
      {
        "start": 465.199,
        "duration": 6.481,
        "text": "there you can see all the topic we have"
      },
      {
        "start": 468.36,
        "duration": 5.16,
        "text": "covered now we do have more than 50"
      },
      {
        "start": 471.68,
        "duration": 6.519,
        "text": "workshops now there for you yeah"
      },
      {
        "start": 473.52,
        "duration": 7.92,
        "text": "definitely a lot of things good so um"
      },
      {
        "start": 478.199,
        "duration": 5.241,
        "text": "and to do practice practical steps you"
      },
      {
        "start": 481.44,
        "duration": 6.08,
        "text": "will have to choose if you want to use"
      },
      {
        "start": 483.44,
        "duration": 6.439,
        "text": "your environment or our environment your"
      },
      {
        "start": 487.52,
        "duration": 4.28,
        "text": "environment whatever would it be"
      },
      {
        "start": 489.879,
        "duration": 4.801,
        "text": "requires only a couple of things you"
      },
      {
        "start": 491.8,
        "duration": 4.64,
        "text": "need to have Docker and Docker compos as"
      },
      {
        "start": 494.68,
        "duration": 4.359,
        "text": "long as you have Docker and Docker"
      },
      {
        "start": 496.44,
        "duration": 4.879,
        "text": "compose you can get clone or just"
      },
      {
        "start": 499.039,
        "duration": 5.0,
        "text": "download our assets from machine"
      },
      {
        "start": 501.319,
        "duration": 5.121,
        "text": "learning workshop online repository at"
      },
      {
        "start": 504.039,
        "duration": 5.88,
        "text": "github.com data stack Academy machine"
      },
      {
        "start": 506.44,
        "duration": 6.0,
        "text": "learning workshop online and then you"
      },
      {
        "start": 509.919,
        "duration": 5.401,
        "text": "can just doer compose uh pull doer"
      },
      {
        "start": 512.44,
        "duration": 5.279,
        "text": "compose up and you have all the required"
      },
      {
        "start": 515.32,
        "duration": 3.48,
        "text": "things running what is running there I"
      },
      {
        "start": 517.719,
        "duration": 4.601,
        "text": "will show"
      },
      {
        "start": 518.8,
        "duration": 6.0,
        "text": "you later on during this Workshop but"
      },
      {
        "start": 522.32,
        "duration": 5.76,
        "text": "what I kindly ask you first please"
      },
      {
        "start": 524.8,
        "duration": 6.159,
        "text": "follow me and follow Cedric and do the"
      },
      {
        "start": 528.08,
        "duration": 5.6,
        "text": "Practical steps after the theoretical"
      },
      {
        "start": 530.959,
        "duration": 5.361,
        "text": "part of the workshop okay so it will it"
      },
      {
        "start": 533.68,
        "duration": 6.44,
        "text": "will make things much easier to you if"
      },
      {
        "start": 536.32,
        "duration": 6.36,
        "text": "you listen first true if uh by any"
      },
      {
        "start": 540.12,
        "duration": 4.88,
        "text": "reason you can't have Docker and Docker"
      },
      {
        "start": 542.68,
        "duration": 5.48,
        "text": "compos install it or your machine or"
      },
      {
        "start": 545.0,
        "duration": 5.24,
        "text": "maybe uh your laptop is not so powerful"
      },
      {
        "start": 548.16,
        "duration": 4.56,
        "text": "because well we are going to run pretty"
      },
      {
        "start": 550.24,
        "duration": 5.36,
        "text": "a lot of things to make the computations"
      },
      {
        "start": 552.72,
        "duration": 6.44,
        "text": "you have a second option you can contact"
      },
      {
        "start": 555.6,
        "duration": 6.919,
        "text": "me uh in LinkedIn or via"
      },
      {
        "start": 559.16,
        "duration": 5.28,
        "text": "email and I will uh create a cloud"
      },
      {
        "start": 562.519,
        "duration": 4.841,
        "text": "instance with all the requirements"
      },
      {
        "start": 564.44,
        "duration": 5.12,
        "text": "installed for you uh second option is"
      },
      {
        "start": 567.36,
        "duration": 4.599,
        "text": "maybe not so much comfortable because"
      },
      {
        "start": 569.56,
        "duration": 5.44,
        "text": "it's going to be temporary instance and"
      },
      {
        "start": 571.959,
        "duration": 4.921,
        "text": "we will terminate it pretty soon but for"
      },
      {
        "start": 575.0,
        "duration": 5.24,
        "text": "uh some hours two three hours is"
      },
      {
        "start": 576.88,
        "duration": 6.56,
        "text": "definitely can be granted to"
      },
      {
        "start": 580.24,
        "duration": 7.56,
        "text": "you well"
      },
      {
        "start": 583.44,
        "duration": 6.36,
        "text": "so let's start then machine learning"
      },
      {
        "start": 587.8,
        "duration": 3.96,
        "text": "machine learning is a field of study"
      },
      {
        "start": 589.8,
        "duration": 4.76,
        "text": "what gives computers the ability to"
      },
      {
        "start": 591.76,
        "duration": 6.8,
        "text": "learn without being explicitly"
      },
      {
        "start": 594.56,
        "duration": 7.24,
        "text": "programmed sounds great computers learn"
      },
      {
        "start": 598.56,
        "duration": 4.8,
        "text": "without explicit L program it but how it"
      },
      {
        "start": 601.8,
        "duration": 4.24,
        "text": "works in real"
      },
      {
        "start": 603.36,
        "duration": 4.0,
        "text": "life yeah I have copy pasted here"
      },
      {
        "start": 606.04,
        "duration": 4.4,
        "text": "definition from"
      },
      {
        "start": 607.36,
        "duration": 5.0,
        "text": "Wikipedia and that's as much as usual"
      },
      {
        "start": 610.44,
        "duration": 4.72,
        "text": "mostly useless if you know what's"
      },
      {
        "start": 612.36,
        "duration": 4.919,
        "text": "already you don't need that and if you"
      },
      {
        "start": 615.16,
        "duration": 4.16,
        "text": "know that and if you don't know it will"
      },
      {
        "start": 617.279,
        "duration": 4.841,
        "text": "not help because all of those"
      },
      {
        "start": 619.32,
        "duration": 6.44,
        "text": "definitions are too big and too"
      },
      {
        "start": 622.12,
        "duration": 6.44,
        "text": "complicated I prefer uh to use another"
      },
      {
        "start": 625.76,
        "duration": 5.16,
        "text": "definition which is much shorter machine"
      },
      {
        "start": 628.56,
        "duration": 5.0,
        "text": "learning is science of drawing cir"
      },
      {
        "start": 630.92,
        "duration": 5.719,
        "text": "circles and colorizing them it still"
      },
      {
        "start": 633.56,
        "duration": 5.519,
        "text": "explains nothing but at least it's short"
      },
      {
        "start": 636.639,
        "duration": 6.88,
        "text": "so it's already much easier to"
      },
      {
        "start": 639.079,
        "duration": 7.801,
        "text": "learn so we better will think of how it"
      },
      {
        "start": 643.519,
        "duration": 5.56,
        "text": "works first and then you will find which"
      },
      {
        "start": 646.88,
        "duration": 4.84,
        "text": "definition is better better works for"
      },
      {
        "start": 649.079,
        "duration": 7.121,
        "text": "you machine learning is a scientific way"
      },
      {
        "start": 651.72,
        "duration": 7.6,
        "text": "to process row data using algorithms to"
      },
      {
        "start": 656.2,
        "duration": 5.72,
        "text": "make better decisions in general it"
      },
      {
        "start": 659.32,
        "duration": 5.0,
        "text": "Works in a very simple way you have uh"
      },
      {
        "start": 661.92,
        "duration": 4.8,
        "text": "accumulated some data for example of"
      },
      {
        "start": 664.32,
        "duration": 5.16,
        "text": "your customers Behavior what they're"
      },
      {
        "start": 666.72,
        "duration": 4.88,
        "text": "liking what we are not liking or maybe"
      },
      {
        "start": 669.48,
        "duration": 5.799,
        "text": "data from the medical point of view in"
      },
      {
        "start": 671.6,
        "duration": 6.6,
        "text": "you if you work in the uh medicine any"
      },
      {
        "start": 675.279,
        "duration": 5.321,
        "text": "kind of data people may be interested in"
      },
      {
        "start": 678.2,
        "duration": 3.639,
        "text": "and then you process those data with"
      },
      {
        "start": 680.6,
        "duration": 3.799,
        "text": "some"
      },
      {
        "start": 681.839,
        "duration": 5.201,
        "text": "algorithms helping you to make bit"
      },
      {
        "start": 684.399,
        "duration": 5.281,
        "text": "better decisions in the end and there is"
      },
      {
        "start": 687.04,
        "duration": 5.599,
        "text": "no magic whatever machine learn learning"
      },
      {
        "start": 689.68,
        "duration": 5.04,
        "text": "does is the same thing as people could"
      },
      {
        "start": 692.639,
        "duration": 5.121,
        "text": "do but you know what computers are"
      },
      {
        "start": 694.72,
        "duration": 5.16,
        "text": "Computing much faster than humans so"
      },
      {
        "start": 697.76,
        "duration": 4.519,
        "text": "basically whatever computer machine"
      },
      {
        "start": 699.88,
        "duration": 5.44,
        "text": "learning can do you can do as well but"
      },
      {
        "start": 702.279,
        "duration": 5.281,
        "text": "in some cases it may take pretty long of"
      },
      {
        "start": 705.32,
        "duration": 5.0,
        "text": "time pretty long"
      },
      {
        "start": 707.56,
        "duration": 5.399,
        "text": "time what are the use cases for the"
      },
      {
        "start": 710.32,
        "duration": 5.84,
        "text": "machine learning you will see some of"
      },
      {
        "start": 712.959,
        "duration": 5.88,
        "text": "them soon but in general that's very"
      },
      {
        "start": 716.16,
        "duration": 5.76,
        "text": "often about forecasts what would be"
      },
      {
        "start": 718.839,
        "duration": 5.721,
        "text": "expect Ed Price or the best price for"
      },
      {
        "start": 721.92,
        "duration": 5.0,
        "text": "this product you are going to release uh"
      },
      {
        "start": 724.56,
        "duration": 4.279,
        "text": "what are the possible ratings for I"
      },
      {
        "start": 726.92,
        "duration": 4.159,
        "text": "don't know for example for a movie you"
      },
      {
        "start": 728.839,
        "duration": 6.481,
        "text": "are going to release or something"
      },
      {
        "start": 731.079,
        "duration": 6.681,
        "text": "whatever possible we uh in next Monday"
      },
      {
        "start": 735.32,
        "duration": 4.8,
        "text": "will you stay at home with us or will"
      },
      {
        "start": 737.76,
        "duration": 4.759,
        "text": "you go for a walk instead I recommend"
      },
      {
        "start": 740.12,
        "duration": 5.36,
        "text": "you to stay with us because well data"
      },
      {
        "start": 742.519,
        "duration": 5.841,
        "text": "Stacks Monday learning is a great thing"
      },
      {
        "start": 745.48,
        "duration": 6.56,
        "text": "then another Point aberation detection"
      },
      {
        "start": 748.36,
        "duration": 6.68,
        "text": "whatever un usual Behavior or unusual"
      },
      {
        "start": 752.04,
        "duration": 5.44,
        "text": "incident in the workflow it can be about"
      },
      {
        "start": 755.04,
        "duration": 5.88,
        "text": "fra detection in the banking very often"
      },
      {
        "start": 757.48,
        "duration": 5.52,
        "text": "use case intrusion detection as well uh"
      },
      {
        "start": 760.92,
        "duration": 5.479,
        "text": "any kind of again getting back to"
      },
      {
        "start": 763.0,
        "duration": 7.68,
        "text": "Medicine about the disease detection as"
      },
      {
        "start": 766.399,
        "duration": 7.44,
        "text": "well many others uh typical cases for"
      },
      {
        "start": 770.68,
        "duration": 5.599,
        "text": "classification face recognition image"
      },
      {
        "start": 773.839,
        "duration": 4.761,
        "text": "recognition categorization of the images"
      },
      {
        "start": 776.279,
        "duration": 5.0,
        "text": "but not only images of course spam"
      },
      {
        "start": 778.6,
        "duration": 4.84,
        "text": "detection one of the most favorite usage"
      },
      {
        "start": 781.279,
        "duration": 3.321,
        "text": "of machine learning in real life is the"
      },
      {
        "start": 783.44,
        "duration": 3.72,
        "text": "spam"
      },
      {
        "start": 784.6,
        "duration": 5.479,
        "text": "detection we will investigate it deeper"
      },
      {
        "start": 787.16,
        "duration": 4.84,
        "text": "today and also recommendation techniques"
      },
      {
        "start": 790.079,
        "duration": 5.481,
        "text": "navigation and many others machine"
      },
      {
        "start": 792.0,
        "duration": 6.6,
        "text": "learning is not more like uh just a"
      },
      {
        "start": 795.56,
        "duration": 6.0,
        "text": "fairy tale but it's a real thing which"
      },
      {
        "start": 798.6,
        "duration": 6.599,
        "text": "which got into every part of our"
      },
      {
        "start": 801.56,
        "duration": 7.12,
        "text": "lives and we saw uh What uh that's about"
      },
      {
        "start": 805.199,
        "duration": 5.961,
        "text": "applying algorithms to data to get some"
      },
      {
        "start": 808.68,
        "duration": 5.12,
        "text": "results to get better decisions to to"
      },
      {
        "start": 811.16,
        "duration": 5.119,
        "text": "get some highlights over this data what"
      },
      {
        "start": 813.8,
        "duration": 6.039,
        "text": "are those algorithms there are a lot of"
      },
      {
        "start": 816.279,
        "duration": 6.481,
        "text": "them we will take a closer look and um"
      },
      {
        "start": 819.839,
        "duration": 4.521,
        "text": "something uh we will cover today but in"
      },
      {
        "start": 822.76,
        "duration": 4.28,
        "text": "general you may think of those"
      },
      {
        "start": 824.36,
        "duration": 4.479,
        "text": "algorithms kind of as of mathematical"
      },
      {
        "start": 827.04,
        "duration": 3.799,
        "text": "functions as you give some data you"
      },
      {
        "start": 828.839,
        "duration": 4.521,
        "text": "receive some result if you have a"
      },
      {
        "start": 830.839,
        "duration": 5.24,
        "text": "function which multiplies everything by"
      },
      {
        "start": 833.36,
        "duration": 4.8,
        "text": "free and you give some data some number"
      },
      {
        "start": 836.079,
        "duration": 5.361,
        "text": "to this uh function you will have a"
      },
      {
        "start": 838.16,
        "duration": 5.599,
        "text": "result of an digit number you gave"
      },
      {
        "start": 841.44,
        "duration": 6.24,
        "text": "multiplied by three and so on so in"
      },
      {
        "start": 843.759,
        "duration": 6.921,
        "text": "general algorithm is some simple defined"
      },
      {
        "start": 847.68,
        "duration": 6.36,
        "text": "way to execute some operations with the"
      },
      {
        "start": 850.68,
        "duration": 5.279,
        "text": "data you give so nothing complex and you"
      },
      {
        "start": 854.04,
        "duration": 4.88,
        "text": "will see it very soon in real life"
      },
      {
        "start": 855.959,
        "duration": 6.521,
        "text": "examples on how they work"
      },
      {
        "start": 858.92,
        "duration": 6.64,
        "text": "and out of those algorithms two main"
      },
      {
        "start": 862.48,
        "duration": 7.039,
        "text": "groups we may discuss or two main cases"
      },
      {
        "start": 865.56,
        "duration": 6.44,
        "text": "supervis it and unsupervised first of"
      },
      {
        "start": 869.519,
        "duration": 5.481,
        "text": "there are more cases and more groups we"
      },
      {
        "start": 872.0,
        "duration": 4.6,
        "text": "may have um kind of half supervised"
      },
      {
        "start": 875.0,
        "duration": 4.959,
        "text": "approach and there are some more"
      },
      {
        "start": 876.6,
        "duration": 5.64,
        "text": "advanced things but that's introduction"
      },
      {
        "start": 879.959,
        "duration": 5.041,
        "text": "not a deep dive so we start"
      },
      {
        "start": 882.24,
        "duration": 6.36,
        "text": "simple in general all of the"
      },
      {
        "start": 885.0,
        "duration": 6.44,
        "text": "applications of um those algorithms can"
      },
      {
        "start": 888.6,
        "duration": 6.2,
        "text": "be separated into two different groups"
      },
      {
        "start": 891.44,
        "duration": 5.759,
        "text": "supervised or unsupervised what's the"
      },
      {
        "start": 894.8,
        "duration": 6.8,
        "text": "difference difference is very simple"
      },
      {
        "start": 897.199,
        "duration": 6.841,
        "text": "data is label it or not if data is"
      },
      {
        "start": 901.6,
        "duration": 4.2,
        "text": "labeled or must be labeled as a result"
      },
      {
        "start": 904.04,
        "duration": 5.12,
        "text": "it's the kind of a"
      },
      {
        "start": 905.8,
        "duration": 7.24,
        "text": "supervised um algorithm what does that"
      },
      {
        "start": 909.16,
        "duration": 7.119,
        "text": "mean very simple uh we"
      },
      {
        "start": 913.04,
        "duration": 6.0,
        "text": "have we know already we have some data"
      },
      {
        "start": 916.279,
        "duration": 5.92,
        "text": "or we have to classify it this email is"
      },
      {
        "start": 919.04,
        "duration": 6.4,
        "text": "a spam or not this operation this"
      },
      {
        "start": 922.199,
        "duration": 6.32,
        "text": "banking operation was fra subscription"
      },
      {
        "start": 925.44,
        "duration": 6.48,
        "text": "is canceled or not so that everything we"
      },
      {
        "start": 928.519,
        "duration": 5.201,
        "text": "can clear say okay this operation is uh"
      },
      {
        "start": 931.92,
        "duration": 5.279,
        "text": "fair this operation is fair this"
      },
      {
        "start": 933.72,
        "duration": 5.679,
        "text": "operation is froud this email is Spam"
      },
      {
        "start": 937.199,
        "duration": 4.801,
        "text": "this email is Spam this email is not"
      },
      {
        "start": 939.399,
        "duration": 5.0,
        "text": "spam we had this data already and now we"
      },
      {
        "start": 942.0,
        "duration": 6.279,
        "text": "are getting newa emails and now we have"
      },
      {
        "start": 944.399,
        "duration": 6.521,
        "text": "to classify them or label them speaking"
      },
      {
        "start": 948.279,
        "duration": 4.521,
        "text": "more scientifically so data is labeled"
      },
      {
        "start": 950.92,
        "duration": 5.64,
        "text": "or must be labeled and that's the"
      },
      {
        "start": 952.8,
        "duration": 6.839,
        "text": "purpose of a supervisor groups um"
      },
      {
        "start": 956.56,
        "duration": 6.32,
        "text": "typical cases uh is a CL speci ification"
      },
      {
        "start": 959.639,
        "duration": 4.921,
        "text": "as said so when you have to um say this"
      },
      {
        "start": 962.88,
        "duration": 4.319,
        "text": "this is a picture of a dock and this is"
      },
      {
        "start": 964.56,
        "duration": 6.92,
        "text": "a picture of the uh traffic"
      },
      {
        "start": 967.199,
        "duration": 8.08,
        "text": "light classification it's supervised"
      },
      {
        "start": 971.48,
        "duration": 7.2,
        "text": "then uh best site of a supervised"
      },
      {
        "start": 975.279,
        "duration": 7.0,
        "text": "algorithms uh and they are easy to test"
      },
      {
        "start": 978.68,
        "duration": 6.12,
        "text": "we will cover testing later during the"
      },
      {
        "start": 982.279,
        "duration": 7.881,
        "text": "making the steps how exactly it"
      },
      {
        "start": 984.8,
        "duration": 7.12,
        "text": "works but um uh in general uh like a"
      },
      {
        "start": 990.16,
        "duration": 4.52,
        "text": "little highlight of what we are going to"
      },
      {
        "start": 991.92,
        "duration": 5.359,
        "text": "do we split some data and we use part of"
      },
      {
        "start": 994.68,
        "duration": 5.12,
        "text": "the data we have to train the model you"
      },
      {
        "start": 997.279,
        "duration": 5.161,
        "text": "will see how it works and then we use"
      },
      {
        "start": 999.8,
        "duration": 7.8,
        "text": "second part of the data smaller part to"
      },
      {
        "start": 1002.44,
        "duration": 8.319,
        "text": "test if it works correctly and um that's"
      },
      {
        "start": 1007.6,
        "duration": 6.32,
        "text": "uh kind of uh this supervisor thing is"
      },
      {
        "start": 1010.759,
        "duration": 5.0,
        "text": "easy to test because for example uh"
      },
      {
        "start": 1013.92,
        "duration": 5.08,
        "text": "millions and millions and millions of"
      },
      {
        "start": 1015.759,
        "duration": 6.041,
        "text": "people getting emails over their life uh"
      },
      {
        "start": 1019.0,
        "duration": 5.24,
        "text": "sending some of those emails to spam and"
      },
      {
        "start": 1021.8,
        "duration": 5.759,
        "text": "that spam spam not spam not spam spam"
      },
      {
        "start": 1024.24,
        "duration": 6.76,
        "text": "spam that the job what we did what what"
      },
      {
        "start": 1027.559,
        "duration": 8.4,
        "text": "I did and you I think too as"
      },
      {
        "start": 1031.0,
        "duration": 7.16,
        "text": "well and uh because of that when like um"
      },
      {
        "start": 1035.959,
        "duration": 4.88,
        "text": "when I receive emails"
      },
      {
        "start": 1038.16,
        "duration": 6.519,
        "text": "nowadays uh and we are I'm using uh"
      },
      {
        "start": 1040.839,
        "duration": 6.2,
        "text": "Google account for email both work and"
      },
      {
        "start": 1044.679,
        "duration": 5.481,
        "text": "private you know what they're really"
      },
      {
        "start": 1047.039,
        "duration": 6.201,
        "text": "very good in the detecting which email"
      },
      {
        "start": 1050.16,
        "duration": 4.96,
        "text": "is Spam and which is not why because all"
      },
      {
        "start": 1053.24,
        "duration": 5.319,
        "text": "the millions of the people were clicking"
      },
      {
        "start": 1055.12,
        "duration": 6.88,
        "text": "spam or not spam all the years"
      },
      {
        "start": 1058.559,
        "duration": 5.961,
        "text": "before okay and then it's easy to test"
      },
      {
        "start": 1062.0,
        "duration": 5.039,
        "text": "unsupervised algorithms unsupervised"
      },
      {
        "start": 1064.52,
        "duration": 5.72,
        "text": "approach is different data is not"
      },
      {
        "start": 1067.039,
        "duration": 5.441,
        "text": "labeled and we don't care about if it's"
      },
      {
        "start": 1070.24,
        "duration": 6.04,
        "text": "labeled or not that's not the thing for"
      },
      {
        "start": 1072.48,
        "duration": 7.28,
        "text": "us uh that's a different approach which"
      },
      {
        "start": 1076.28,
        "duration": 7.24,
        "text": "helps us to find patterns and data uh"
      },
      {
        "start": 1079.76,
        "duration": 6.2,
        "text": "helps us to Cluster data so to separate"
      },
      {
        "start": 1083.52,
        "duration": 5.36,
        "text": "um data we have into different groups to"
      },
      {
        "start": 1085.96,
        "duration": 5.68,
        "text": "find a groups and find dependencies"
      },
      {
        "start": 1088.88,
        "duration": 5.08,
        "text": "between them that belongs to uh animal"
      },
      {
        "start": 1091.64,
        "duration": 4.84,
        "text": "detection that belongs to any kind of a"
      },
      {
        "start": 1093.96,
        "duration": 4.959,
        "text": "grouping of the data we have that helps"
      },
      {
        "start": 1096.48,
        "duration": 4.76,
        "text": "us to create associations between data"
      },
      {
        "start": 1098.919,
        "duration": 4.321,
        "text": "pieces we have very useful in"
      },
      {
        "start": 1101.24,
        "duration": 4.36,
        "text": "exploratory analysis when we don't"
      },
      {
        "start": 1103.24,
        "duration": 5.679,
        "text": "really understand what data we have and"
      },
      {
        "start": 1105.6,
        "duration": 6.68,
        "text": "want to get better knowledge of that and"
      },
      {
        "start": 1108.919,
        "duration": 5.921,
        "text": "another problem uh so it's harder to"
      },
      {
        "start": 1112.28,
        "duration": 5.0,
        "text": "test because we cannot be really sure"
      },
      {
        "start": 1114.84,
        "duration": 4.6,
        "text": "what that's the final result we want to"
      },
      {
        "start": 1117.28,
        "duration": 5.8,
        "text": "have is it spam or not we cannot say in"
      },
      {
        "start": 1119.44,
        "duration": 7.479,
        "text": "this day it's unsupervised we don't have"
      },
      {
        "start": 1123.08,
        "duration": 6.2,
        "text": "labels yeah and speaking of spam I just"
      },
      {
        "start": 1126.919,
        "duration": 3.841,
        "text": "um you know working with the marketing"
      },
      {
        "start": 1129.28,
        "duration": 5.16,
        "text": "team now we"
      },
      {
        "start": 1130.76,
        "duration": 6.72,
        "text": "are also using some kind of machine"
      },
      {
        "start": 1134.44,
        "duration": 5.16,
        "text": "learning to to shape the email not to"
      },
      {
        "start": 1137.48,
        "duration": 4.0,
        "text": "look like a spam so you do have a"
      },
      {
        "start": 1139.6,
        "duration": 4.0,
        "text": "machine learning trying to avoid you to"
      },
      {
        "start": 1141.48,
        "duration": 4.52,
        "text": "get spam and at the marketing side we do"
      },
      {
        "start": 1143.6,
        "duration": 4.84,
        "text": "have machine learning to push you email"
      },
      {
        "start": 1146.0,
        "duration": 5.36,
        "text": "and make look it does not look spam"
      },
      {
        "start": 1148.44,
        "duration": 6.04,
        "text": "that's funny yeah someone said some time"
      },
      {
        "start": 1151.36,
        "duration": 5.88,
        "text": "ago what in the 21st century every"
      },
      {
        "start": 1154.48,
        "duration": 6.319,
        "text": "company has to become has to become a"
      },
      {
        "start": 1157.24,
        "duration": 5.72,
        "text": "data company or die and well that's not"
      },
      {
        "start": 1160.799,
        "duration": 4.801,
        "text": "about just trying to collect as much"
      },
      {
        "start": 1162.96,
        "duration": 5.48,
        "text": "data uh you may have but that's about"
      },
      {
        "start": 1165.6,
        "duration": 5.12,
        "text": "also to process that properly yeah and"
      },
      {
        "start": 1168.44,
        "duration": 6.0,
        "text": "that's very interesting so now we have"
      },
      {
        "start": 1170.72,
        "duration": 8.8,
        "text": "machine learnings from all the sides of"
      },
      {
        "start": 1174.44,
        "duration": 7.8,
        "text": "this um field let's say Okay so let's"
      },
      {
        "start": 1179.52,
        "duration": 5.24,
        "text": "take a look before we get a deeper dive"
      },
      {
        "start": 1182.24,
        "duration": 5.36,
        "text": "into how it works let's take a look a"
      },
      {
        "start": 1184.76,
        "duration": 5.0,
        "text": "little demo I want to show you I want to"
      },
      {
        "start": 1187.6,
        "duration": 4.92,
        "text": "show you a very simple thing those"
      },
      {
        "start": 1189.76,
        "duration": 5.08,
        "text": "algorithms are in general simple to"
      },
      {
        "start": 1192.52,
        "duration": 4.56,
        "text": "understand maybe hard to master that's"
      },
      {
        "start": 1194.84,
        "duration": 5.6,
        "text": "okay for me but they're simple to"
      },
      {
        "start": 1197.08,
        "duration": 6.24,
        "text": "understand and first thing will do is K"
      },
      {
        "start": 1200.44,
        "duration": 8.239,
        "text": "means algorithm one of the algorithms"
      },
      {
        "start": 1203.32,
        "duration": 9.359,
        "text": "will we will use today there is a great"
      },
      {
        "start": 1208.679,
        "duration": 5.961,
        "text": "um tool to play with kin clustering"
      },
      {
        "start": 1212.679,
        "duration": 5.921,
        "text": "algorithm I"
      },
      {
        "start": 1214.64,
        "duration": 6.36,
        "text": "will send a link to the chat but please"
      },
      {
        "start": 1218.6,
        "duration": 4.52,
        "text": "don't do it right now first listen to me"
      },
      {
        "start": 1221.0,
        "duration": 4.64,
        "text": "otherwise you will miss the explanations"
      },
      {
        "start": 1223.12,
        "duration": 6.4,
        "text": "and then ask the things in the chat we"
      },
      {
        "start": 1225.64,
        "duration": 8.44,
        "text": "which we cover it already so what's the"
      },
      {
        "start": 1229.52,
        "duration": 7.24,
        "text": "uh clustering thing very simple"
      },
      {
        "start": 1234.08,
        "duration": 7.839,
        "text": "oops"
      },
      {
        "start": 1236.76,
        "duration": 5.159,
        "text": "okay I will clean it up a little"
      },
      {
        "start": 1242.52,
        "duration": 7.96,
        "text": "bit good so"
      },
      {
        "start": 1245.919,
        "duration": 7.161,
        "text": "imagine that field is a city map there"
      },
      {
        "start": 1250.48,
        "duration": 4.8,
        "text": "are some streets and buildings all the"
      },
      {
        "start": 1253.08,
        "duration": 5.16,
        "text": "things like that and you know what we"
      },
      {
        "start": 1255.28,
        "duration": 5.72,
        "text": "are going to create and deliver best"
      },
      {
        "start": 1258.24,
        "duration": 5.16,
        "text": "pizza in the world like everyone loves"
      },
      {
        "start": 1261.0,
        "duration": 7.76,
        "text": "pizza and we are going to bring it to a"
      },
      {
        "start": 1263.4,
        "duration": 7.399,
        "text": "new level so and uh we want we have we"
      },
      {
        "start": 1268.76,
        "duration": 7.08,
        "text": "are limited in budget so we want to"
      },
      {
        "start": 1270.799,
        "duration": 7.441,
        "text": "establish our uh centers uh Pizza houses"
      },
      {
        "start": 1275.84,
        "duration": 4.959,
        "text": "in the middle of the area with the Pizza"
      },
      {
        "start": 1278.24,
        "duration": 5.559,
        "text": "Lovers of this city leave so we want to"
      },
      {
        "start": 1280.799,
        "duration": 7.961,
        "text": "be geographically convenient for them to"
      },
      {
        "start": 1283.799,
        "duration": 8.36,
        "text": "visit and also we want to um uh keep it"
      },
      {
        "start": 1288.76,
        "duration": 5.519,
        "text": "easier for our careers to deliver pizza"
      },
      {
        "start": 1292.159,
        "duration": 4.801,
        "text": "on very short time and you know what in"
      },
      {
        "start": 1294.279,
        "duration": 5.361,
        "text": "the city there are different areas some"
      },
      {
        "start": 1296.96,
        "duration": 6.16,
        "text": "of them use and buy pizza a lot and some"
      },
      {
        "start": 1299.64,
        "duration": 6.96,
        "text": "of them are not so first thing I want to"
      },
      {
        "start": 1303.12,
        "duration": 5.799,
        "text": "do as I'm setting somehow we got data I"
      },
      {
        "start": 1306.6,
        "duration": 5.079,
        "text": "don't know there are many ways to get"
      },
      {
        "start": 1308.919,
        "duration": 8.081,
        "text": "data of the people living in different"
      },
      {
        "start": 1311.679,
        "duration": 8.721,
        "text": "areas of the city and those will be uh"
      },
      {
        "start": 1317.0,
        "duration": 7.0,
        "text": "areas that uh people who buy pizza Leaf"
      },
      {
        "start": 1320.4,
        "duration": 6.68,
        "text": "so I'm just making all the previous"
      },
      {
        "start": 1324.0,
        "duration": 6.48,
        "text": "buys uh like"
      },
      {
        "start": 1327.08,
        "duration": 6.28,
        "text": "that and now let's say Let's uh take a"
      },
      {
        "start": 1330.48,
        "duration": 6.319,
        "text": "look at what the k means algorithm is"
      },
      {
        "start": 1333.36,
        "duration": 6.799,
        "text": "it's unsupervised algorithm the data I"
      },
      {
        "start": 1336.799,
        "duration": 5.841,
        "text": "have is not labeled they all are the"
      },
      {
        "start": 1340.159,
        "duration": 4.321,
        "text": "same just only cordinates for example"
      },
      {
        "start": 1342.64,
        "duration": 6.399,
        "text": "are different"
      },
      {
        "start": 1344.48,
        "duration": 9.4,
        "text": "that's uh story of some orders of pizza"
      },
      {
        "start": 1349.039,
        "duration": 7.441,
        "text": "I want to cover key means is uh not to"
      },
      {
        "start": 1353.88,
        "duration": 6.279,
        "text": "categorize but to help me explore the"
      },
      {
        "start": 1356.48,
        "duration": 5.72,
        "text": "data and find uh how to group them or"
      },
      {
        "start": 1360.159,
        "duration": 5.041,
        "text": "how to Cluster them it's a clustering"
      },
      {
        "start": 1362.2,
        "duration": 6.16,
        "text": "demo so we are going to build some glass"
      },
      {
        "start": 1365.2,
        "duration": 5.24,
        "text": "clusters to group them and as I have"
      },
      {
        "start": 1368.36,
        "duration": 4.72,
        "text": "some data here"
      },
      {
        "start": 1370.44,
        "duration": 5.56,
        "text": "already uh and I will use theault"
      },
      {
        "start": 1373.08,
        "duration": 6.479,
        "text": "setting of two clusters uh to be fix it"
      },
      {
        "start": 1376.0,
        "duration": 8.279,
        "text": "in the future B one may work not best"
      },
      {
        "start": 1379.559,
        "duration": 7.441,
        "text": "how this kin algorithm works first it"
      },
      {
        "start": 1384.279,
        "duration": 6.241,
        "text": "takes all the field I have here"
      },
      {
        "start": 1387.0,
        "duration": 7.279,
        "text": "specified and randomly allocates"
      },
      {
        "start": 1390.52,
        "duration": 7.24,
        "text": "absolutely randomly allocates um cluster"
      },
      {
        "start": 1394.279,
        "duration": 6.4,
        "text": "centers somewhere on the field it may"
      },
      {
        "start": 1397.76,
        "duration": 5.84,
        "text": "sound pretty stupid I mean like I want"
      },
      {
        "start": 1400.679,
        "duration": 5.24,
        "text": "to have more or less uh correct data not"
      },
      {
        "start": 1403.6,
        "duration": 5.16,
        "text": "some random allocation but let's take a"
      },
      {
        "start": 1405.919,
        "duration": 5.041,
        "text": "look how it works in the end after some"
      },
      {
        "start": 1408.76,
        "duration": 3.96,
        "text": "steps of these algorithms you will find"
      },
      {
        "start": 1410.96,
        "duration": 6.24,
        "text": "out you will see what it works pretty"
      },
      {
        "start": 1412.72,
        "duration": 7.72,
        "text": "good after those uh centers are"
      },
      {
        "start": 1417.2,
        "duration": 7.32,
        "text": "allocated it calculates the difference"
      },
      {
        "start": 1420.44,
        "duration": 7.08,
        "text": "uh from all of the points to the current"
      },
      {
        "start": 1424.52,
        "duration": 4.44,
        "text": "Center and tries to find the best"
      },
      {
        "start": 1427.52,
        "duration": 4.399,
        "text": "direction to"
      },
      {
        "start": 1428.96,
        "duration": 6.959,
        "text": "move uh the way which will decrease"
      },
      {
        "start": 1431.919,
        "duration": 7.081,
        "text": "Delta which will decrease difference of"
      },
      {
        "start": 1435.919,
        "duration": 6.281,
        "text": "uh lengths of all the lengths uh from"
      },
      {
        "start": 1439.0,
        "duration": 7.32,
        "text": "the points allocated to the center and I"
      },
      {
        "start": 1442.2,
        "duration": 7.04,
        "text": "can push the step button one and use it"
      },
      {
        "start": 1446.32,
        "duration": 4.04,
        "text": "for calculated steps it moved them to"
      },
      {
        "start": 1449.24,
        "duration": 5.4,
        "text": "the"
      },
      {
        "start": 1450.36,
        "duration": 6.6,
        "text": "center okay and it looks like Delta now"
      },
      {
        "start": 1454.64,
        "duration": 5.96,
        "text": "is uh already getting better with just"
      },
      {
        "start": 1456.96,
        "duration": 6.12,
        "text": "one step calculating all the lengths and"
      },
      {
        "start": 1460.6,
        "duration": 4.84,
        "text": "moving in the uh Center of mass"
      },
      {
        "start": 1463.08,
        "duration": 4.8,
        "text": "Direction it's getting better and"
      },
      {
        "start": 1465.44,
        "duration": 5.239,
        "text": "actually only one step was enough to"
      },
      {
        "start": 1467.88,
        "duration": 5.08,
        "text": "allocate f for us like that but what"
      },
      {
        "start": 1470.679,
        "duration": 5.36,
        "text": "will happen if I"
      },
      {
        "start": 1472.96,
        "duration": 5.839,
        "text": "move Center to a new position it will"
      },
      {
        "start": 1476.039,
        "duration": 6.201,
        "text": "restarts with everything and I do the"
      },
      {
        "start": 1478.799,
        "duration": 8.201,
        "text": "step again so first thing algorithm does"
      },
      {
        "start": 1482.24,
        "duration": 7.36,
        "text": "is calculates to length of all the lines"
      },
      {
        "start": 1487.0,
        "duration": 6.399,
        "text": "we have here and then tries to calculate"
      },
      {
        "start": 1489.6,
        "duration": 6.199,
        "text": "in which direction we should move the um"
      },
      {
        "start": 1493.399,
        "duration": 6.201,
        "text": "Center uh so the groups will be"
      },
      {
        "start": 1495.799,
        "duration": 6.681,
        "text": "identified in a better way"
      },
      {
        "start": 1499.6,
        "duration": 4.959,
        "text": "okay and this was identification like"
      },
      {
        "start": 1502.48,
        "duration": 4.48,
        "text": "you see we have pretty good situation"
      },
      {
        "start": 1504.559,
        "duration": 4.921,
        "text": "here already we are grouping them but"
      },
      {
        "start": 1506.96,
        "duration": 4.839,
        "text": "now some points belong to the uh red"
      },
      {
        "start": 1509.48,
        "duration": 5.199,
        "text": "Center which is maybe not perfect in"
      },
      {
        "start": 1511.799,
        "duration": 5.841,
        "text": "this case and after a couple of more"
      },
      {
        "start": 1514.679,
        "duration": 6.041,
        "text": "steps okay vice versa we are moving in"
      },
      {
        "start": 1517.64,
        "duration": 5.759,
        "text": "another Direction uh red Center gets"
      },
      {
        "start": 1520.72,
        "duration": 4.959,
        "text": "points those are closer to the red"
      },
      {
        "start": 1523.399,
        "duration": 4.601,
        "text": "Center then to the blue Center using"
      },
      {
        "start": 1525.679,
        "duration": 4.641,
        "text": "exactly the same approach after every"
      },
      {
        "start": 1528.0,
        "duration": 4.72,
        "text": "step they're trying to calculate which"
      },
      {
        "start": 1530.32,
        "duration": 5.599,
        "text": "is may be closer to me and may should be"
      },
      {
        "start": 1532.72,
        "duration": 5.199,
        "text": "consumed by one of the centers and which"
      },
      {
        "start": 1535.919,
        "duration": 5.24,
        "text": "one is any another Center is not"
      },
      {
        "start": 1537.919,
        "duration": 5.601,
        "text": "interested we when after a few"
      },
      {
        "start": 1541.159,
        "duration": 6.161,
        "text": "steps with every next step we are"
      },
      {
        "start": 1543.52,
        "duration": 5.879,
        "text": "getting more and more uh better grouping"
      },
      {
        "start": 1547.32,
        "duration": 5.599,
        "text": "for those and in the end we have Delta"
      },
      {
        "start": 1549.399,
        "duration": 6.28,
        "text": "position zero so it means what K means"
      },
      {
        "start": 1552.919,
        "duration": 6.041,
        "text": "algorithm doesn't want to move anything"
      },
      {
        "start": 1555.679,
        "duration": 6.681,
        "text": "it's fine and now"
      },
      {
        "start": 1558.96,
        "duration": 6.0,
        "text": "why it's called it K means K means"
      },
      {
        "start": 1562.36,
        "duration": 5.64,
        "text": "number of clusters we are going to have"
      },
      {
        "start": 1564.96,
        "duration": 5.68,
        "text": "and why that's one of the let's say"
      },
      {
        "start": 1568.0,
        "duration": 3.44,
        "text": "biggest possibilities and problems of"
      },
      {
        "start": 1570.64,
        "duration": 4.68,
        "text": "these"
      },
      {
        "start": 1571.44,
        "duration": 6.68,
        "text": "algorithms um from one point of view uh"
      },
      {
        "start": 1575.32,
        "duration": 5.16,
        "text": "we may have limited amount of clusters"
      },
      {
        "start": 1578.12,
        "duration": 5.039,
        "text": "right now we have only two but maybe"
      },
      {
        "start": 1580.48,
        "duration": 5.6,
        "text": "these it will look better if we have uh"
      },
      {
        "start": 1583.159,
        "duration": 5.481,
        "text": "if we may have more clusters and doing"
      },
      {
        "start": 1586.08,
        "duration": 5.199,
        "text": "some steps"
      },
      {
        "start": 1588.64,
        "duration": 5.2,
        "text": "and doing some steps we find out what"
      },
      {
        "start": 1591.279,
        "duration": 7.161,
        "text": "with free clusters it works"
      },
      {
        "start": 1593.84,
        "duration": 4.6,
        "text": "better will it work better with four"
      },
      {
        "start": 1601.0,
        "duration": 6.399,
        "text": "clusters well"
      },
      {
        "start": 1602.84,
        "duration": 4.559,
        "text": "maybe will it work better with five"
      },
      {
        "start": 1609.039,
        "duration": 6.64,
        "text": "clusters maybe it's too much for us so"
      },
      {
        "start": 1613.12,
        "duration": 5.679,
        "text": "uh playing with amount of clusters and"
      },
      {
        "start": 1615.679,
        "duration": 6.841,
        "text": "our way to group those um"
      },
      {
        "start": 1618.799,
        "duration": 5.961,
        "text": "um uh cluster those data pieces we have"
      },
      {
        "start": 1622.52,
        "duration": 4.759,
        "text": "to try to group them and find the"
      },
      {
        "start": 1624.76,
        "duration": 6.56,
        "text": "centers of groups may work pretty good"
      },
      {
        "start": 1627.279,
        "duration": 6.481,
        "text": "for us one important point to understand"
      },
      {
        "start": 1631.32,
        "duration": 5.959,
        "text": "here is amount of clusters is for humans"
      },
      {
        "start": 1633.76,
        "duration": 5.799,
        "text": "to decide we cannot just um maybe you"
      },
      {
        "start": 1637.279,
        "duration": 5.12,
        "text": "have some limited possible amount of"
      },
      {
        "start": 1639.559,
        "duration": 4.681,
        "text": "things maybe uh it depends on what"
      },
      {
        "start": 1642.399,
        "duration": 3.721,
        "text": "exactly do you have to find out we"
      },
      {
        "start": 1644.24,
        "duration": 5.84,
        "text": "discuss it on the next"
      },
      {
        "start": 1646.12,
        "duration": 8.0,
        "text": "steps in this example I can put centers"
      },
      {
        "start": 1650.08,
        "duration": 6.719,
        "text": "uh Rand On My Own by default uh K means"
      },
      {
        "start": 1654.12,
        "duration": 5.36,
        "text": "put them randomly as I said and then"
      },
      {
        "start": 1656.799,
        "duration": 5.48,
        "text": "after every next step we see how it"
      },
      {
        "start": 1659.48,
        "duration": 4.72,
        "text": "changes and how key means tries to find"
      },
      {
        "start": 1662.279,
        "duration": 5.28,
        "text": "the geographical"
      },
      {
        "start": 1664.2,
        "duration": 6.0,
        "text": "center so again process is very simple"
      },
      {
        "start": 1667.559,
        "duration": 5.881,
        "text": "you have this line you have the set of"
      },
      {
        "start": 1670.2,
        "duration": 5.599,
        "text": "lines sorry and you calculate uh"
      },
      {
        "start": 1673.44,
        "duration": 5.0,
        "text": "Direction and the length of every of"
      },
      {
        "start": 1675.799,
        "duration": 5.401,
        "text": "them and it looks like oh it looks like"
      },
      {
        "start": 1678.44,
        "duration": 5.56,
        "text": "I have a very big Delta here difference"
      },
      {
        "start": 1681.2,
        "duration": 5.44,
        "text": "between my center and other Center and"
      },
      {
        "start": 1684.0,
        "duration": 6.519,
        "text": "the points of data is too high and then"
      },
      {
        "start": 1686.64,
        "duration": 8.32,
        "text": "obviously I'm c will move V Center more"
      },
      {
        "start": 1690.519,
        "duration": 7.0,
        "text": "to the U Southeast let's say boom of"
      },
      {
        "start": 1694.96,
        "duration": 4.92,
        "text": "course because now it's for Center and"
      },
      {
        "start": 1697.519,
        "duration": 4.64,
        "text": "now playing next step we will find how"
      },
      {
        "start": 1699.88,
        "duration": 4.0,
        "text": "it will reallocate and recalculate"
      },
      {
        "start": 1702.159,
        "duration": 3.12,
        "text": "everything depending on the amount of"
      },
      {
        "start": 1703.88,
        "duration": 6.039,
        "text": "clusters you"
      },
      {
        "start": 1705.279,
        "duration": 7.561,
        "text": "have so basically that was a very simple"
      },
      {
        "start": 1709.919,
        "duration": 6.841,
        "text": "example yeah so question in the chat try"
      },
      {
        "start": 1712.84,
        "duration": 8.12,
        "text": "to answer but um so how do you set this"
      },
      {
        "start": 1716.76,
        "duration": 8.68,
        "text": "K do you try and learn so my first"
      },
      {
        "start": 1720.96,
        "duration": 6.88,
        "text": "answer is this K is really tied to your"
      },
      {
        "start": 1725.44,
        "duration": 5.92,
        "text": "own business so if you talk about the"
      },
      {
        "start": 1727.84,
        "duration": 5.64,
        "text": "bus the pizza house you have a limited"
      },
      {
        "start": 1731.36,
        "duration": 5.28,
        "text": "amount of budget so you know you can"
      },
      {
        "start": 1733.48,
        "duration": 5.28,
        "text": "have three to four Pizza House and so"
      },
      {
        "start": 1736.64,
        "duration": 4.159,
        "text": "you will compute for each"
      },
      {
        "start": 1738.76,
        "duration": 3.919,
        "text": "what is the distance between the houses"
      },
      {
        "start": 1740.799,
        "duration": 6.561,
        "text": "and and and and the data point and see"
      },
      {
        "start": 1742.679,
        "duration": 8.521,
        "text": "if it's if it's worth adding a new uh"
      },
      {
        "start": 1747.36,
        "duration": 6.6,
        "text": "Pizza House um but I think you know you"
      },
      {
        "start": 1751.2,
        "duration": 4.28,
        "text": "should try and"
      },
      {
        "start": 1753.96,
        "duration": 7.92,
        "text": "learn"
      },
      {
        "start": 1755.48,
        "duration": 9.24,
        "text": "yep uh okay then so what comes next now"
      },
      {
        "start": 1761.88,
        "duration": 6.24,
        "text": "okay we just uh have seen one of the"
      },
      {
        "start": 1764.72,
        "duration": 5.48,
        "text": "algorithms in the Wild on how it works"
      },
      {
        "start": 1768.12,
        "duration": 4.64,
        "text": "how it measures distances how it"
      },
      {
        "start": 1770.2,
        "duration": 5.4,
        "text": "calculates vectors and moves the center"
      },
      {
        "start": 1772.76,
        "duration": 5.6,
        "text": "to the best possible"
      },
      {
        "start": 1775.6,
        "duration": 5.88,
        "text": "Direction how it works in real life and"
      },
      {
        "start": 1778.36,
        "duration": 7.28,
        "text": "how do we apply data to"
      },
      {
        "start": 1781.48,
        "duration": 7.0,
        "text": "the algorithm we are going to use how"
      },
      {
        "start": 1785.64,
        "duration": 7.279,
        "text": "goes the learning workflow it consists"
      },
      {
        "start": 1788.48,
        "duration": 7.64,
        "text": "of the uh few steps at first we have to"
      },
      {
        "start": 1792.919,
        "duration": 5.961,
        "text": "prepare data because row data is very"
      },
      {
        "start": 1796.12,
        "duration": 6.12,
        "text": "often useless for learning you will see"
      },
      {
        "start": 1798.88,
        "duration": 7.32,
        "text": "it in the Practical part and first we"
      },
      {
        "start": 1802.24,
        "duration": 5.96,
        "text": "prepare data when we split if the work"
      },
      {
        "start": 1806.2,
        "duration": 5.719,
        "text": "in this case we discuss supervisor"
      },
      {
        "start": 1808.2,
        "duration": 6.599,
        "text": "learning so we can test uh we split"
      },
      {
        "start": 1811.919,
        "duration": 6.081,
        "text": "things uh into training set validating"
      },
      {
        "start": 1814.799,
        "duration": 6.681,
        "text": "set and testing set we will"
      },
      {
        "start": 1818.0,
        "duration": 6.12,
        "text": "need um then there is a training phase"
      },
      {
        "start": 1821.48,
        "duration": 5.039,
        "text": "when we train when we train our model"
      },
      {
        "start": 1824.12,
        "duration": 5.2,
        "text": "with a training set and use validating"
      },
      {
        "start": 1826.519,
        "duration": 5.76,
        "text": "set to tune that there are some um"
      },
      {
        "start": 1829.32,
        "duration": 4.68,
        "text": "things like K we can adjust and some"
      },
      {
        "start": 1832.279,
        "duration": 4.52,
        "text": "others for another"
      },
      {
        "start": 1834.0,
        "duration": 5.24,
        "text": "algorithms and testing set we use"
      },
      {
        "start": 1836.799,
        "duration": 5.24,
        "text": "finally to estimate our model if it's"
      },
      {
        "start": 1839.24,
        "duration": 5.439,
        "text": "good or not and finally as if we are"
      },
      {
        "start": 1842.039,
        "duration": 5.64,
        "text": "satisfied with our model we can use it"
      },
      {
        "start": 1844.679,
        "duration": 4.6,
        "text": "to work with a new data if we speak of a"
      },
      {
        "start": 1847.679,
        "duration": 3.48,
        "text": "Spam"
      },
      {
        "start": 1849.279,
        "duration": 5.961,
        "text": "example"
      },
      {
        "start": 1851.159,
        "duration": 7.76,
        "text": "here first example preparation we have"
      },
      {
        "start": 1855.24,
        "duration": 6.48,
        "text": "to get some emails and label them if"
      },
      {
        "start": 1858.919,
        "duration": 6.441,
        "text": "it's spam or not let's say it's done for"
      },
      {
        "start": 1861.72,
        "duration": 6.0,
        "text": "us already when we split uh given emails"
      },
      {
        "start": 1865.36,
        "duration": 4.919,
        "text": "into training validating and"
      },
      {
        "start": 1867.72,
        "duration": 5.28,
        "text": "testing and we use training set which is"
      },
      {
        "start": 1870.279,
        "duration": 4.601,
        "text": "usually biggest one like around 80% of"
      },
      {
        "start": 1873.0,
        "duration": 6.519,
        "text": "the data we have it depends on your"
      },
      {
        "start": 1874.88,
        "duration": 8.639,
        "text": "strategy of course um to train the model"
      },
      {
        "start": 1879.519,
        "duration": 7.76,
        "text": "we use validating set um to tune the"
      },
      {
        "start": 1883.519,
        "duration": 5.801,
        "text": "model and find out uh if we can make it"
      },
      {
        "start": 1887.279,
        "duration": 5.721,
        "text": "better if we we can reset up it maybe"
      },
      {
        "start": 1889.32,
        "duration": 6.199,
        "text": "anyhow and finally we use testing set to"
      },
      {
        "start": 1893.0,
        "duration": 5.32,
        "text": "estimate the model and if model is good"
      },
      {
        "start": 1895.519,
        "duration": 5.441,
        "text": "we release the final model which now is"
      },
      {
        "start": 1898.32,
        "duration": 5.56,
        "text": "going to process the new data we have or"
      },
      {
        "start": 1900.96,
        "duration": 5.679,
        "text": "new emails we have and set if it's maybe"
      },
      {
        "start": 1903.88,
        "duration": 2.759,
        "text": "spam or"
      },
      {
        "start": 1907.36,
        "duration": 8.039,
        "text": "not yeah good now uh you may be want to"
      },
      {
        "start": 1911.559,
        "duration": 5.84,
        "text": "jump inter actions but inter action uh"
      },
      {
        "start": 1915.399,
        "duration": 3.041,
        "text": "but before that we have to discuss one"
      },
      {
        "start": 1917.399,
        "duration": 3.441,
        "text": "more thing"
      },
      {
        "start": 1918.44,
        "duration": 4.839,
        "text": "so we are very close to"
      },
      {
        "start": 1920.84,
        "duration": 5.839,
        "text": "practical you cannot control what you"
      },
      {
        "start": 1923.279,
        "duration": 6.52,
        "text": "can't measure so we want to speak about"
      },
      {
        "start": 1926.679,
        "duration": 5.72,
        "text": "Matrix as we work with a supervisor"
      },
      {
        "start": 1929.799,
        "duration": 5.441,
        "text": "algorithm now we can test and we can"
      },
      {
        "start": 1932.399,
        "duration": 6.361,
        "text": "compare and we can assess the model if"
      },
      {
        "start": 1935.24,
        "duration": 6.039,
        "text": "it's good or not so what kind of metric"
      },
      {
        "start": 1938.76,
        "duration": 5.36,
        "text": "matters let's take a look and let's talk"
      },
      {
        "start": 1941.279,
        "duration": 5.961,
        "text": "a little bit about the example we have"
      },
      {
        "start": 1944.12,
        "duration": 5.48,
        "text": "that's year 2020 and all the pandemic is"
      },
      {
        "start": 1947.24,
        "duration": 5.12,
        "text": "going over over and I'm sorry to touch"
      },
      {
        "start": 1949.6,
        "duration": 7.319,
        "text": "this topic but I'm going to get uh into"
      },
      {
        "start": 1952.36,
        "duration": 7.159,
        "text": "some uh medical things right now for uh"
      },
      {
        "start": 1956.919,
        "duration": 4.12,
        "text": "estimation and metrix part we will talk"
      },
      {
        "start": 1959.519,
        "duration": 5.16,
        "text": "about"
      },
      {
        "start": 1961.039,
        "duration": 6.801,
        "text": "tumor and in this example we have 100"
      },
      {
        "start": 1964.679,
        "duration": 6.521,
        "text": "patients 100 people nine of them have"
      },
      {
        "start": 1967.84,
        "duration": 7.12,
        "text": "malan tumor which is very bad and kind"
      },
      {
        "start": 1971.2,
        "duration": 7.24,
        "text": "of deadly and um 91 of them have a"
      },
      {
        "start": 1974.96,
        "duration": 5.28,
        "text": "banine tumor which is well also but not"
      },
      {
        "start": 1978.44,
        "duration": 6.04,
        "text": "so"
      },
      {
        "start": 1980.24,
        "duration": 7.039,
        "text": "bad and uh our model model we prepar it"
      },
      {
        "start": 1984.48,
        "duration": 6.199,
        "text": "and model which we are going to assess"
      },
      {
        "start": 1987.279,
        "duration": 7.76,
        "text": "in The Next Step uh gave the following"
      },
      {
        "start": 1990.679,
        "duration": 7.921,
        "text": "results out of 100 people 9 malan tumor"
      },
      {
        "start": 1995.039,
        "duration": 7.721,
        "text": "91 benine tumor we detected"
      },
      {
        "start": 1998.6,
        "duration": 7.4,
        "text": "successfully uh 90 uh true negative"
      },
      {
        "start": 2002.76,
        "duration": 6.879,
        "text": "results so we have theing tumor not the"
      },
      {
        "start": 2006.0,
        "duration": 7.76,
        "text": "um malan and there are 90 of them and we"
      },
      {
        "start": 2009.639,
        "duration": 5.121,
        "text": "found out 90 of 91 of them which looks"
      },
      {
        "start": 2013.76,
        "duration": 5.96,
        "text": "not so"
      },
      {
        "start": 2014.76,
        "duration": 8.84,
        "text": "bad then uh false positive results we"
      },
      {
        "start": 2019.72,
        "duration": 5.0,
        "text": "identified uh tumor as B but actually it"
      },
      {
        "start": 2023.6,
        "duration": 3.84,
        "text": "been"
      },
      {
        "start": 2024.72,
        "duration": 6.199,
        "text": "malan and false positive we have only"
      },
      {
        "start": 2027.44,
        "duration": 8.079,
        "text": "one result so one person had a benine"
      },
      {
        "start": 2030.919,
        "duration": 8.0,
        "text": "tumor but we identified is as malan as a"
      },
      {
        "start": 2035.519,
        "duration": 6.16,
        "text": "bad one then we have all Al false"
      },
      {
        "start": 2038.919,
        "duration": 6.6,
        "text": "negative in reality people had the bad"
      },
      {
        "start": 2041.679,
        "duration": 4.801,
        "text": "tumor but we predicted it as a light"
      },
      {
        "start": 2045.519,
        "duration": 3.84,
        "text": "kind of"
      },
      {
        "start": 2046.48,
        "duration": 5.76,
        "text": "tumor eight results false"
      },
      {
        "start": 2049.359,
        "duration": 5.28,
        "text": "negatives and finally one true positive"
      },
      {
        "start": 2052.24,
        "duration": 5.2,
        "text": "it was very bad tumor and we identified"
      },
      {
        "start": 2054.639,
        "duration": 5.321,
        "text": "it as a very bad tumor number of true"
      },
      {
        "start": 2057.44,
        "duration": 4.919,
        "text": "positive results again one that's for"
      },
      {
        "start": 2059.96,
        "duration": 6.919,
        "text": "example we will look we will work with"
      },
      {
        "start": 2062.359,
        "duration": 6.841,
        "text": "now first metric we talk about the"
      },
      {
        "start": 2066.879,
        "duration": 5.081,
        "text": "machine learning algorithms is the"
      },
      {
        "start": 2069.2,
        "duration": 5.159,
        "text": "accuracy accuracy is a classification"
      },
      {
        "start": 2071.96,
        "duration": 6.8,
        "text": "model metric it's the fraction of a"
      },
      {
        "start": 2074.359,
        "duration": 6.681,
        "text": "prediction model identified correctly so"
      },
      {
        "start": 2078.76,
        "duration": 4.359,
        "text": "accuracy easily speaking briefly"
      },
      {
        "start": 2081.04,
        "duration": 5.079,
        "text": "speaking is a amount of correct"
      },
      {
        "start": 2083.119,
        "duration": 6.441,
        "text": "predictions divided by total"
      },
      {
        "start": 2086.119,
        "duration": 5.641,
        "text": "predictions in this example we have"
      },
      {
        "start": 2089.56,
        "duration": 7.559,
        "text": "accuracy of"
      },
      {
        "start": 2091.76,
        "duration": 10.64,
        "text": "0.91 because 91 predictions were true we"
      },
      {
        "start": 2097.119,
        "duration": 8.881,
        "text": "have true positive 1 to 90 it total 91"
      },
      {
        "start": 2102.4,
        "duration": 8.92,
        "text": "divided by 100 so accuracy"
      },
      {
        "start": 2106.0,
        "duration": 9.96,
        "text": "0.91 it's pretty high is that model"
      },
      {
        "start": 2111.32,
        "duration": 7.72,
        "text": "good now wait for a second and try to"
      },
      {
        "start": 2115.96,
        "duration": 8.08,
        "text": "think because uh"
      },
      {
        "start": 2119.04,
        "duration": 5.0,
        "text": "well where is a flow we didn't discuss"
      },
      {
        "start": 2124.28,
        "duration": 5.799,
        "text": "yet we just sent back home eight people"
      },
      {
        "start": 2127.92,
        "duration": 5.96,
        "text": "without proper treatment because of a"
      },
      {
        "start": 2130.079,
        "duration": 6.961,
        "text": "high level of false negatives out of"
      },
      {
        "start": 2133.88,
        "duration": 6.4,
        "text": "nine people with malan tumor we got"
      },
      {
        "start": 2137.04,
        "duration": 5.88,
        "text": "false negative on eight of them we could"
      },
      {
        "start": 2140.28,
        "duration": 6.72,
        "text": "have better results literally by"
      },
      {
        "start": 2142.92,
        "duration": 6.28,
        "text": "throwing a coin I mean literally in this"
      },
      {
        "start": 2147.0,
        "duration": 5.28,
        "text": "case we send back home eight people out"
      },
      {
        "start": 2149.2,
        "duration": 6.52,
        "text": "of nine and if you would throw a coin"
      },
      {
        "start": 2152.28,
        "duration": 8.839,
        "text": "this amount would be much lesser mostly"
      },
      {
        "start": 2155.72,
        "duration": 7.04,
        "text": "probably so um is this model um good or"
      },
      {
        "start": 2161.119,
        "duration": 5.96,
        "text": "not so"
      },
      {
        "start": 2162.76,
        "duration": 7.4,
        "text": "good well maybe not so good and we have"
      },
      {
        "start": 2167.079,
        "duration": 5.161,
        "text": "to work on that so accuracy is an"
      },
      {
        "start": 2170.16,
        "duration": 4.28,
        "text": "interesting thing from one point of view"
      },
      {
        "start": 2172.24,
        "duration": 4.72,
        "text": "that's important to understand accuracy"
      },
      {
        "start": 2174.44,
        "duration": 6.36,
        "text": "from another point of view you see like"
      },
      {
        "start": 2176.96,
        "duration": 5.52,
        "text": "that's very clear is uh not about it's"
      },
      {
        "start": 2180.8,
        "duration": 4.039,
        "text": "sometimes not the best thing we have"
      },
      {
        "start": 2182.48,
        "duration": 6.28,
        "text": "high accuracy highest possible accuracy"
      },
      {
        "start": 2184.839,
        "duration": 7.48,
        "text": "is one and we have accuracy zero .9 very"
      },
      {
        "start": 2188.76,
        "duration": 6.28,
        "text": "close but the modu is still very bad so"
      },
      {
        "start": 2192.319,
        "duration": 5.441,
        "text": "let's take a look if we have something"
      },
      {
        "start": 2195.04,
        "duration": 5.6,
        "text": "better another kind of metrics we have"
      },
      {
        "start": 2197.76,
        "duration": 6.839,
        "text": "to discuss is the precision versus"
      },
      {
        "start": 2200.64,
        "duration": 7.88,
        "text": "recall uh Precision means uh positive"
      },
      {
        "start": 2204.599,
        "duration": 7.041,
        "text": "predictive valuee uh Precision"
      },
      {
        "start": 2208.52,
        "duration": 6.079,
        "text": "means uh amount of true positives"
      },
      {
        "start": 2211.64,
        "duration": 6.64,
        "text": "divided by amount of all positives both"
      },
      {
        "start": 2214.599,
        "duration": 7.281,
        "text": "true and false and for our"
      },
      {
        "start": 2218.28,
        "duration": 6.44,
        "text": "um example for for our example with the"
      },
      {
        "start": 2221.88,
        "duration": 5.84,
        "text": "tumor Precision is only"
      },
      {
        "start": 2224.72,
        "duration": 5.76,
        "text": "0.5 which is not so high so we see what"
      },
      {
        "start": 2227.72,
        "duration": 5.359,
        "text": "it has like kind of very medium"
      },
      {
        "start": 2230.48,
        "duration": 5.28,
        "text": "Precision but if it goes to the second"
      },
      {
        "start": 2233.079,
        "duration": 4.161,
        "text": "side of a slide which is recall also"
      },
      {
        "start": 2235.76,
        "duration": 4.0,
        "text": "known as"
      },
      {
        "start": 2237.24,
        "duration": 4.8,
        "text": "sensitivity uh recall or sensitivity you"
      },
      {
        "start": 2239.76,
        "duration": 5.2,
        "text": "can use both recall is maybe a more"
      },
      {
        "start": 2242.04,
        "duration": 6.48,
        "text": "official name recall counts correctly"
      },
      {
        "start": 2244.96,
        "duration": 6.399,
        "text": "identified positives out of all real"
      },
      {
        "start": 2248.52,
        "duration": 6.68,
        "text": "positives and recall is amount of true"
      },
      {
        "start": 2251.359,
        "duration": 8.081,
        "text": "positives divided by all real positives"
      },
      {
        "start": 2255.2,
        "duration": 8.28,
        "text": "and for a Tor example recall is"
      },
      {
        "start": 2259.44,
        "duration": 8.2,
        "text": "0.11 so extremely"
      },
      {
        "start": 2263.48,
        "duration": 8.72,
        "text": "low now uh well when we have a lot of uh"
      },
      {
        "start": 2267.64,
        "duration": 6.479,
        "text": "metrics uh some more also coming uh what"
      },
      {
        "start": 2272.2,
        "duration": 4.08,
        "text": "people are doing in the real life"
      },
      {
        "start": 2274.119,
        "duration": 4.561,
        "text": "because yes we need metrix but now we"
      },
      {
        "start": 2276.28,
        "duration": 6.24,
        "text": "see what accuracy is maybe not so"
      },
      {
        "start": 2278.68,
        "duration": 6.32,
        "text": "relevant uh and precision recall uh they"
      },
      {
        "start": 2282.52,
        "duration": 4.599,
        "text": "are great but they kind of contradict to"
      },
      {
        "start": 2285.0,
        "duration": 4.8,
        "text": "each other then you start to tune your"
      },
      {
        "start": 2287.119,
        "duration": 5.361,
        "text": "model to be more precise you start to"
      },
      {
        "start": 2289.8,
        "duration": 6.16,
        "text": "use recall that's kind of a mathematic"
      },
      {
        "start": 2292.48,
        "duration": 6.52,
        "text": "simple uh mathematic thing higher your"
      },
      {
        "start": 2295.96,
        "duration": 6.24,
        "text": "Precision lower your recall and vice"
      },
      {
        "start": 2299.0,
        "duration": 5.68,
        "text": "versa then people start to use um"
      },
      {
        "start": 2302.2,
        "duration": 5.32,
        "text": "scientic metrics which calculate which"
      },
      {
        "start": 2304.68,
        "duration": 5.72,
        "text": "use all of them as accuracy and"
      },
      {
        "start": 2307.52,
        "duration": 5.0,
        "text": "precision and recall like F1 metric"
      },
      {
        "start": 2310.4,
        "duration": 4.04,
        "text": "which is synthetical consisting of"
      },
      {
        "start": 2312.52,
        "duration": 5.68,
        "text": "multiple of the values like precision"
      },
      {
        "start": 2314.44,
        "duration": 6.8,
        "text": "and recall and in general that's a long"
      },
      {
        "start": 2318.2,
        "duration": 4.8,
        "text": "story it doesn't matter if you uh don't"
      },
      {
        "start": 2321.24,
        "duration": 3.96,
        "text": "get it too deep for now because that's"
      },
      {
        "start": 2323.0,
        "duration": 5.079,
        "text": "not the purpose of this Workshop the"
      },
      {
        "start": 2325.2,
        "duration": 5.76,
        "text": "purpose of this workshop for you is to"
      },
      {
        "start": 2328.079,
        "duration": 5.601,
        "text": "understand the basics and in general"
      },
      {
        "start": 2330.96,
        "duration": 5.119,
        "text": "it's very short we have we can measure"
      },
      {
        "start": 2333.68,
        "duration": 3.96,
        "text": "efficiency of algorithms at least for"
      },
      {
        "start": 2336.079,
        "duration": 4.441,
        "text": "supervised"
      },
      {
        "start": 2337.64,
        "duration": 6.52,
        "text": "and uh not all of the m and Matrix may"
      },
      {
        "start": 2340.52,
        "duration": 6.079,
        "text": "have like say different relevancy for"
      },
      {
        "start": 2344.16,
        "duration": 5.84,
        "text": "your use"
      },
      {
        "start": 2346.599,
        "duration": 5.52,
        "text": "case and one last thing before we go"
      },
      {
        "start": 2350.0,
        "duration": 5.839,
        "text": "practical is I want to discuss"
      },
      {
        "start": 2352.119,
        "duration": 5.801,
        "text": "underfitted and overfitted model in this"
      },
      {
        "start": 2355.839,
        "duration": 6.841,
        "text": "case we have"
      },
      {
        "start": 2357.92,
        "duration": 7.52,
        "text": "uh the H same set of data process it"
      },
      {
        "start": 2362.68,
        "duration": 5.679,
        "text": "with uh differently configur it or maybe"
      },
      {
        "start": 2365.44,
        "duration": 6.679,
        "text": "different algorithms we we are trying to"
      },
      {
        "start": 2368.359,
        "duration": 6.441,
        "text": "predict some values on those things and"
      },
      {
        "start": 2372.119,
        "duration": 6.401,
        "text": "we have uh three kind of"
      },
      {
        "start": 2374.8,
        "duration": 6.4,
        "text": "models uh left Center and on the right"
      },
      {
        "start": 2378.52,
        "duration": 5.48,
        "text": "and uh let's take at the let's take a"
      },
      {
        "start": 2381.2,
        "duration": 5.96,
        "text": "look at the left example we have pieces"
      },
      {
        "start": 2384.0,
        "duration": 6.839,
        "text": "of data our circles black circles here"
      },
      {
        "start": 2387.16,
        "duration": 6.56,
        "text": "and we have this uh dotted line dotted"
      },
      {
        "start": 2390.839,
        "duration": 6.841,
        "text": "line is the prediction is how our model"
      },
      {
        "start": 2393.72,
        "duration": 7.48,
        "text": "works and in this case they see these"
      },
      {
        "start": 2397.68,
        "duration": 6.32,
        "text": "result of this model aren't so good it's"
      },
      {
        "start": 2401.2,
        "duration": 4.6,
        "text": "uh maybe wrong algorithm or not well"
      },
      {
        "start": 2404.0,
        "duration": 4.359,
        "text": "configured"
      },
      {
        "start": 2405.8,
        "duration": 5.12,
        "text": "algorithm and we see what this"
      },
      {
        "start": 2408.359,
        "duration": 7.121,
        "text": "underfitted model is not accurate it's"
      },
      {
        "start": 2410.92,
        "duration": 6.6,
        "text": "just too simple we have more complex um"
      },
      {
        "start": 2415.48,
        "duration": 4.52,
        "text": "set of data and we have just one"
      },
      {
        "start": 2417.52,
        "duration": 5.0,
        "text": "straight line so that's a bad"
      },
      {
        "start": 2420.0,
        "duration": 5.839,
        "text": "example in the center we have a good"
      },
      {
        "start": 2422.52,
        "duration": 5.76,
        "text": "feed or robust model which is well"
      },
      {
        "start": 2425.839,
        "duration": 7.161,
        "text": "generalized model should not try to"
      },
      {
        "start": 2428.28,
        "duration": 8.44,
        "text": "catch um and be perfectly uh precise on"
      },
      {
        "start": 2433.0,
        "duration": 6.52,
        "text": "for every dot we have but in general it"
      },
      {
        "start": 2436.72,
        "duration": 7.08,
        "text": "should find in this case the general"
      },
      {
        "start": 2439.52,
        "duration": 7.16,
        "text": "Trend the main idea of the data we have"
      },
      {
        "start": 2443.8,
        "duration": 5.799,
        "text": "and on the right side we have overfeed"
      },
      {
        "start": 2446.68,
        "duration": 5.76,
        "text": "model that's exactly overtrained model"
      },
      {
        "start": 2449.599,
        "duration": 4.921,
        "text": "which tries to Feit into every piece of"
      },
      {
        "start": 2452.44,
        "duration": 5.0,
        "text": "data you have and as a result it's"
      },
      {
        "start": 2454.52,
        "duration": 5.319,
        "text": "trying to be too much precise it gives"
      },
      {
        "start": 2457.44,
        "duration": 5.6,
        "text": "bad result over a roll it's overfitted"
      },
      {
        "start": 2459.839,
        "duration": 5.28,
        "text": "model it works perfect on the train data"
      },
      {
        "start": 2463.04,
        "duration": 5.039,
        "text": "because it fits literally into every"
      },
      {
        "start": 2465.119,
        "duration": 5.681,
        "text": "point of the uh train data you give but"
      },
      {
        "start": 2468.079,
        "duration": 5.801,
        "text": "then as soon as you start test and it"
      },
      {
        "start": 2470.8,
        "duration": 6.6,
        "text": "found outs like what something is not"
      },
      {
        "start": 2473.88,
        "duration": 5.8,
        "text": "perfect um then it works not so good"
      },
      {
        "start": 2477.4,
        "duration": 5.32,
        "text": "important for us we want to keep our"
      },
      {
        "start": 2479.68,
        "duration": 5.919,
        "text": "models General enough and we don't want"
      },
      {
        "start": 2482.72,
        "duration": 6.92,
        "text": "them to be too precise we will discuss"
      },
      {
        "start": 2485.599,
        "duration": 8.081,
        "text": "it uh later more practical on one of the"
      },
      {
        "start": 2489.64,
        "duration": 6.52,
        "text": "models well practice is golden talk talk"
      },
      {
        "start": 2493.68,
        "duration": 5.0,
        "text": "is cheap show me the code show me how it"
      },
      {
        "start": 2496.16,
        "duration": 5.919,
        "text": "works very"
      },
      {
        "start": 2498.68,
        "duration": 6.48,
        "text": "simple um before we start few words"
      },
      {
        "start": 2502.079,
        "duration": 5.081,
        "text": "about the tools we are going to use uh"
      },
      {
        "start": 2505.16,
        "duration": 4.84,
        "text": "luckily those aren't the tools on the"
      },
      {
        "start": 2507.16,
        "duration": 5.84,
        "text": "right but more the tools on the"
      },
      {
        "start": 2510.0,
        "duration": 5.76,
        "text": "left I mean well it's still uh almost"
      },
      {
        "start": 2513.0,
        "duration": 6.56,
        "text": "two months in year 2020 so we still have"
      },
      {
        "start": 2515.76,
        "duration": 8.92,
        "text": "a chance yeah yeah yeah oh man that's"
      },
      {
        "start": 2519.56,
        "duration": 7.88,
        "text": "you so what we are going to use first uh"
      },
      {
        "start": 2524.68,
        "duration": 3.8,
        "text": "tool we are going to work with is the"
      },
      {
        "start": 2527.44,
        "duration": 4.56,
        "text": "apach"
      },
      {
        "start": 2528.48,
        "duration": 5.839,
        "text": "spark um full title is an open source"
      },
      {
        "start": 2532.0,
        "duration": 5.119,
        "text": "distributed general purpose cluster"
      },
      {
        "start": 2534.319,
        "duration": 6.641,
        "text": "Computing framework my God that's even"
      },
      {
        "start": 2537.119,
        "duration": 6.921,
        "text": "sounds awful but uh explain explanation"
      },
      {
        "start": 2540.96,
        "duration": 6.76,
        "text": "is very simple do you remember our ke"
      },
      {
        "start": 2544.04,
        "duration": 7.0,
        "text": "means example we had like around 100 of"
      },
      {
        "start": 2547.72,
        "duration": 6.48,
        "text": "dots and for every Center of mass let's"
      },
      {
        "start": 2551.04,
        "duration": 7.16,
        "text": "say k means algorithm should have"
      },
      {
        "start": 2554.2,
        "duration": 6.399,
        "text": "calculated the length and the vector and"
      },
      {
        "start": 2558.2,
        "duration": 5.08,
        "text": "if I should move in this direction or"
      },
      {
        "start": 2560.599,
        "duration": 4.681,
        "text": "maybe move in that direction so it's"
      },
      {
        "start": 2563.28,
        "duration": 4.16,
        "text": "spread to a lot of computations but in"
      },
      {
        "start": 2565.28,
        "duration": 5.72,
        "text": "the real world you are going to work"
      },
      {
        "start": 2567.44,
        "duration": 7.08,
        "text": "with maybe billions of rows of"
      },
      {
        "start": 2571.0,
        "duration": 6.16,
        "text": "data in explaining very simply spark"
      },
      {
        "start": 2574.52,
        "duration": 5.039,
        "text": "helps you to run those computations on M"
      },
      {
        "start": 2577.16,
        "duration": 5.64,
        "text": "multiple computers at once usually"
      },
      {
        "start": 2579.559,
        "duration": 5.841,
        "text": "powerful servers so whatever we do today"
      },
      {
        "start": 2582.8,
        "duration": 5.279,
        "text": "on this example you can calculate on"
      },
      {
        "start": 2585.4,
        "duration": 5.08,
        "text": "your laptop because we work with data"
      },
      {
        "start": 2588.079,
        "duration": 5.081,
        "text": "sets of some thousands but when you"
      },
      {
        "start": 2590.48,
        "duration": 4.8,
        "text": "start to work with real big data your"
      },
      {
        "start": 2593.16,
        "duration": 4.76,
        "text": "laptop is mostly Pro probably going to"
      },
      {
        "start": 2595.28,
        "duration": 6.76,
        "text": "melt after an hour or maybe"
      },
      {
        "start": 2597.92,
        "duration": 7.04,
        "text": "sooner so for this we in real world we"
      },
      {
        "start": 2602.04,
        "duration": 6.44,
        "text": "use spark which helps us to distribute"
      },
      {
        "start": 2604.96,
        "duration": 6.72,
        "text": "calculations over multiple servers"
      },
      {
        "start": 2608.48,
        "duration": 5.76,
        "text": "uh spark is a great open- source tool"
      },
      {
        "start": 2611.68,
        "duration": 5.32,
        "text": "and it works very well with the Apache"
      },
      {
        "start": 2614.24,
        "duration": 4.96,
        "text": "Cassandra which is a second tool for us"
      },
      {
        "start": 2617.0,
        "duration": 4.96,
        "text": "what is the Apache Cassandra and why do"
      },
      {
        "start": 2619.2,
        "duration": 5.28,
        "text": "we care Apache Cassandra is a free open-"
      },
      {
        "start": 2621.96,
        "duration": 6.04,
        "text": "source distributed decentralized noise"
      },
      {
        "start": 2624.48,
        "duration": 6.16,
        "text": "Quil database in short it's a database"
      },
      {
        "start": 2628.0,
        "duration": 4.8,
        "text": "which is a big data ready it ready to"
      },
      {
        "start": 2630.64,
        "duration": 5.679,
        "text": "handle dos petabytes and hundreds"
      },
      {
        "start": 2632.8,
        "duration": 5.559,
        "text": "petabytes of data over the world and"
      },
      {
        "start": 2636.319,
        "duration": 4.601,
        "text": "that's one of the most powerful"
      },
      {
        "start": 2638.359,
        "duration": 4.561,
        "text": "databases we have right now for example"
      },
      {
        "start": 2640.92,
        "duration": 4.84,
        "text": "for a long time we were sure what the"
      },
      {
        "start": 2642.92,
        "duration": 5.08,
        "text": "biggest Cassandra deployment uh was done"
      },
      {
        "start": 2645.76,
        "duration": 5.04,
        "text": "by Apple you maybe have heard something"
      },
      {
        "start": 2648.0,
        "duration": 6.64,
        "text": "about Apple they released those uh"
      },
      {
        "start": 2650.8,
        "duration": 6.6,
        "text": "mobile phones with apple on the back"
      },
      {
        "start": 2654.64,
        "duration": 4.84,
        "text": "doesn't matter so their deployment was"
      },
      {
        "start": 2657.4,
        "duration": 5.52,
        "text": "around 100,000"
      },
      {
        "start": 2659.48,
        "duration": 5.8,
        "text": "notes but funny point we were wrong"
      },
      {
        "start": 2662.92,
        "duration": 4.84,
        "text": "because we found out what uh there is a"
      },
      {
        "start": 2665.28,
        "duration": 6.96,
        "text": "company which has even higher number"
      },
      {
        "start": 2667.76,
        "duration": 7.839,
        "text": "uh with Huawei uh China has around"
      },
      {
        "start": 2672.24,
        "duration": 6.92,
        "text": "160,000 servers dedicated to work with"
      },
      {
        "start": 2675.599,
        "duration": 6.76,
        "text": "Cassandra 160,000 servers to uh handle"
      },
      {
        "start": 2679.16,
        "duration": 6.32,
        "text": "data so that's something I I call Big"
      },
      {
        "start": 2682.359,
        "duration": 4.801,
        "text": "Data really and also there are guys like"
      },
      {
        "start": 2685.48,
        "duration": 5.639,
        "text": "Netflix"
      },
      {
        "start": 2687.16,
        "duration": 6.52,
        "text": "Instagram and so on and so forth good so"
      },
      {
        "start": 2691.119,
        "duration": 6.2,
        "text": "Cassandra is a database to store Big"
      },
      {
        "start": 2693.68,
        "duration": 5.96,
        "text": "Data I need to make good decisions uh in"
      },
      {
        "start": 2697.319,
        "duration": 6.0,
        "text": "my business for"
      },
      {
        "start": 2699.64,
        "duration": 7.88,
        "text": "example then Jupiter and data stack"
      },
      {
        "start": 2703.319,
        "duration": 7.401,
        "text": "studio in our case they are very uh"
      },
      {
        "start": 2707.52,
        "duration": 6.799,
        "text": "similar by the idea I use Jupiter to"
      },
      {
        "start": 2710.72,
        "duration": 5.879,
        "text": "work uh with apach spark it's for me it"
      },
      {
        "start": 2714.319,
        "duration": 5.441,
        "text": "will be just like a weap interface to"
      },
      {
        "start": 2716.599,
        "duration": 6.201,
        "text": "work with spark simplifying that and I"
      },
      {
        "start": 2719.76,
        "duration": 5.079,
        "text": "will use data stock Studio to work with"
      },
      {
        "start": 2722.8,
        "duration": 4.36,
        "text": "papach Cassandra can you can consider"
      },
      {
        "start": 2724.839,
        "duration": 3.561,
        "text": "data stack Studio as a web interface for"
      },
      {
        "start": 2727.16,
        "duration": 5.199,
        "text": "apach"
      },
      {
        "start": 2728.4,
        "duration": 5.8,
        "text": "candra then uh python well I will not"
      },
      {
        "start": 2732.359,
        "duration": 6.121,
        "text": "spend too much time explaining what the"
      },
      {
        "start": 2734.2,
        "duration": 6.96,
        "text": "python is uh and but well you may want"
      },
      {
        "start": 2738.48,
        "duration": 5.92,
        "text": "to know what python is very widely used"
      },
      {
        "start": 2741.16,
        "duration": 6.56,
        "text": "in the machine"
      },
      {
        "start": 2744.4,
        "duration": 6.84,
        "text": "learning yeah uh when we have some"
      },
      {
        "start": 2747.72,
        "duration": 7.119,
        "text": "libraries for python uh we will need to"
      },
      {
        "start": 2751.24,
        "duration": 6.319,
        "text": "use today those a pandas pandas uh is"
      },
      {
        "start": 2754.839,
        "duration": 6.321,
        "text": "the uh package providing all tools you"
      },
      {
        "start": 2757.559,
        "duration": 5.881,
        "text": "need to work uh with the data for"
      },
      {
        "start": 2761.16,
        "duration": 5.0,
        "text": "machine learning analysis in"
      },
      {
        "start": 2763.44,
        "duration": 5.08,
        "text": "Python uh then p park is a simple"
      },
      {
        "start": 2766.16,
        "duration": 5.32,
        "text": "integration Library which helps python"
      },
      {
        "start": 2768.52,
        "duration": 5.72,
        "text": "to work with Apaches spark you will see"
      },
      {
        "start": 2771.48,
        "duration": 6.359,
        "text": "uh NPI is a package for scientifical"
      },
      {
        "start": 2774.24,
        "duration": 4.68,
        "text": "Computing with all the array objects uh"
      },
      {
        "start": 2777.839,
        "duration": 4.28,
        "text": "linear"
      },
      {
        "start": 2778.92,
        "duration": 6.36,
        "text": "algebra uh for transform and so on and"
      },
      {
        "start": 2782.119,
        "duration": 6.72,
        "text": "so forth and then finally psychic learn"
      },
      {
        "start": 2785.28,
        "duration": 5.799,
        "text": "psychic learn is again uh set of tools I"
      },
      {
        "start": 2788.839,
        "duration": 6.401,
        "text": "would say big package including many"
      },
      {
        "start": 2791.079,
        "duration": 7.28,
        "text": "many different things um to help you not"
      },
      {
        "start": 2795.24,
        "duration": 4.72,
        "text": "only um work with data and run the"
      },
      {
        "start": 2798.359,
        "duration": 3.081,
        "text": "machine learning algorithms and"
      },
      {
        "start": 2799.96,
        "duration": 4.44,
        "text": "calculate something and predict"
      },
      {
        "start": 2801.44,
        "duration": 6.0,
        "text": "something but also visualize that"
      },
      {
        "start": 2804.4,
        "duration": 5.6,
        "text": "because well humans aren't computers we"
      },
      {
        "start": 2807.44,
        "duration": 6.2,
        "text": "prefer to see"
      },
      {
        "start": 2810.0,
        "duration": 5.92,
        "text": "first and how it works all together just"
      },
      {
        "start": 2813.64,
        "duration": 3.84,
        "text": "to so everything what we are doing you"
      },
      {
        "start": 2815.92,
        "duration": 4.56,
        "text": "can completely do"
      },
      {
        "start": 2817.48,
        "duration": 5.879,
        "text": "with Apache Cassandra and apach Spark in"
      },
      {
        "start": 2820.48,
        "duration": 5.24,
        "text": "our case to simplify setup we are using"
      },
      {
        "start": 2823.359,
        "duration": 4.641,
        "text": "them packet together already by data"
      },
      {
        "start": 2825.72,
        "duration": 5.359,
        "text": "stocks that's a package called a data"
      },
      {
        "start": 2828.0,
        "duration": 5.359,
        "text": "stocks Enterprise it's uh free for"
      },
      {
        "start": 2831.079,
        "duration": 5.161,
        "text": "non-commercial use like mean like that"
      },
      {
        "start": 2833.359,
        "duration": 4.801,
        "text": "for educational purposes basically"
      },
      {
        "start": 2836.24,
        "duration": 4.319,
        "text": "that's Cassandra spark and some more"
      },
      {
        "start": 2838.16,
        "duration": 4.84,
        "text": "secret things uh bound"
      },
      {
        "start": 2840.559,
        "duration": 5.201,
        "text": "together and on the left side we see"
      },
      {
        "start": 2843.0,
        "duration": 6.359,
        "text": "data stack Studio to work with Cassandra"
      },
      {
        "start": 2845.76,
        "duration": 7.28,
        "text": "where Ro data and on the right side we"
      },
      {
        "start": 2849.359,
        "duration": 8.0,
        "text": "see Jupiter notebook to work with"
      },
      {
        "start": 2853.04,
        "duration": 9.079,
        "text": "already our uh machine learning uh code"
      },
      {
        "start": 2857.359,
        "duration": 7.321,
        "text": "we will use so uh that's how you work"
      },
      {
        "start": 2862.119,
        "duration": 7.161,
        "text": "with a local environment doesn't matter"
      },
      {
        "start": 2864.68,
        "duration": 7.28,
        "text": "but at first I say ask you to follow me"
      },
      {
        "start": 2869.28,
        "duration": 6.36,
        "text": "and then do those steps on your own"
      },
      {
        "start": 2871.96,
        "duration": 7.44,
        "text": "today we are going going to cover two"
      },
      {
        "start": 2875.64,
        "duration": 7.679,
        "text": "steps and and um we you will have three"
      },
      {
        "start": 2879.4,
        "duration": 7.28,
        "text": "more tasks to do on your own uh via"
      },
      {
        "start": 2883.319,
        "duration": 4.081,
        "text": "Cloud instance or on your own laptop as"
      },
      {
        "start": 2886.68,
        "duration": 3.72,
        "text": "you"
      },
      {
        "start": 2887.4,
        "duration": 5.8,
        "text": "prefer first algorithm we will cover in"
      },
      {
        "start": 2890.4,
        "duration": 6.04,
        "text": "the Practical step is a naive bias"
      },
      {
        "start": 2893.2,
        "duration": 5.84,
        "text": "supervised classification algorithm it's"
      },
      {
        "start": 2896.44,
        "duration": 4.6,
        "text": "kind of very old algorithm and very well"
      },
      {
        "start": 2899.04,
        "duration": 6.36,
        "text": "known in the machine learning"
      },
      {
        "start": 2901.04,
        "duration": 5.88,
        "text": "field uh watch that and how it works as"
      },
      {
        "start": 2905.4,
        "duration": 4.28,
        "text": "usual"
      },
      {
        "start": 2906.92,
        "duration": 5.28,
        "text": "Wikipedia definitions aren't so much"
      },
      {
        "start": 2909.68,
        "duration": 4.2,
        "text": "helpful like with all this naive bias"
      },
      {
        "start": 2912.2,
        "duration": 4.119,
        "text": "classifiers are a family of simple"
      },
      {
        "start": 2913.88,
        "duration": 4.36,
        "text": "probabilistic classifiers basic on the"
      },
      {
        "start": 2916.319,
        "duration": 5.121,
        "text": "applying bias theorem with strong knife"
      },
      {
        "start": 2918.24,
        "duration": 7.24,
        "text": "and I don't like that let's move on and"
      },
      {
        "start": 2921.44,
        "duration": 8.04,
        "text": "let's uh see how it's uh how to explain"
      },
      {
        "start": 2925.48,
        "duration": 6.599,
        "text": "that easier for humans and funny enough"
      },
      {
        "start": 2929.48,
        "duration": 6.119,
        "text": "this comic is the best possible"
      },
      {
        "start": 2932.079,
        "duration": 6.201,
        "text": "explanation of the knife bias simple as"
      },
      {
        "start": 2935.599,
        "duration": 5.041,
        "text": "that uh um it's written in the"
      },
      {
        "start": 2938.28,
        "duration": 5.64,
        "text": "scientifical way I will explain in a"
      },
      {
        "start": 2940.64,
        "duration": 6.88,
        "text": "moment but uh in general the idea is"
      },
      {
        "start": 2943.92,
        "duration": 6.84,
        "text": "very short if you pick up a sea shell"
      },
      {
        "start": 2947.52,
        "duration": 7.0,
        "text": "fact number one and if you don't hold it"
      },
      {
        "start": 2950.76,
        "duration": 8.079,
        "text": "to your air fact number two you can"
      },
      {
        "start": 2954.52,
        "duration": 5.72,
        "text": "mostly probably hear the ocean where is"
      },
      {
        "start": 2958.839,
        "duration": 4.081,
        "text": "the trick of the chain of the"
      },
      {
        "start": 2960.24,
        "duration": 6.559,
        "text": "dependencies we will we will work deeper"
      },
      {
        "start": 2962.92,
        "duration": 6.159,
        "text": "on the next slide but uh really the"
      },
      {
        "start": 2966.799,
        "duration": 5.121,
        "text": "that's the uh best possible explanation"
      },
      {
        "start": 2969.079,
        "duration": 5.04,
        "text": "of a naive bias if you want to make a"
      },
      {
        "start": 2971.92,
        "duration": 6.04,
        "text": "deeper dive follow"
      },
      {
        "start": 2974.119,
        "duration": 5.321,
        "text": "me so I'm going to apply naive bias"
      },
      {
        "start": 2977.96,
        "duration": 5.159,
        "text": "algorithm"
      },
      {
        "start": 2979.44,
        "duration": 6.28,
        "text": "now uh first thing uh we have to prepare"
      },
      {
        "start": 2983.119,
        "duration": 6.68,
        "text": "and label data and we will use very"
      },
      {
        "start": 2985.72,
        "duration": 6.04,
        "text": "traditional spam problem so there are I"
      },
      {
        "start": 2989.799,
        "duration": 4.601,
        "text": "don't know how many emails on the"
      },
      {
        "start": 2991.76,
        "duration": 5.16,
        "text": "internet happen to be every day but"
      },
      {
        "start": 2994.4,
        "duration": 5.719,
        "text": "amount is tremendous"
      },
      {
        "start": 2996.92,
        "duration": 6.8,
        "text": "and every second even yeah yeah every"
      },
      {
        "start": 3000.119,
        "duration": 5.68,
        "text": "even second every second and problem of"
      },
      {
        "start": 3003.72,
        "duration": 3.839,
        "text": "most of them you don't want to read"
      },
      {
        "start": 3005.799,
        "duration": 4.481,
        "text": "because they are trying to steal your"
      },
      {
        "start": 3007.559,
        "duration": 4.721,
        "text": "money or steal your credentials or steal"
      },
      {
        "start": 3010.28,
        "duration": 6.68,
        "text": "your something I don't"
      },
      {
        "start": 3012.28,
        "duration": 7.279,
        "text": "know and uh we want to get rid of them"
      },
      {
        "start": 3016.96,
        "duration": 4.68,
        "text": "so first as it's the supervisor"
      },
      {
        "start": 3019.559,
        "duration": 6.201,
        "text": "mechanism we discussed before we are"
      },
      {
        "start": 3021.64,
        "duration": 5.88,
        "text": "going to prepare and label our data what"
      },
      {
        "start": 3025.76,
        "duration": 4.559,
        "text": "does that mean"
      },
      {
        "start": 3027.52,
        "duration": 5.68,
        "text": "three million per second okay yeah yeah"
      },
      {
        "start": 3030.319,
        "duration": 5.321,
        "text": "so that's why uh your laptop will be not"
      },
      {
        "start": 3033.2,
        "duration": 4.359,
        "text": "enough although it's a good laptop but"
      },
      {
        "start": 3035.64,
        "duration": 4.76,
        "text": "we still will need spark to run"
      },
      {
        "start": 3037.559,
        "duration": 7.8,
        "text": "computations on multiple of"
      },
      {
        "start": 3040.4,
        "duration": 10.04,
        "text": "servers yeah so well"
      },
      {
        "start": 3045.359,
        "duration": 8.96,
        "text": "crazy um in this example we have one two"
      },
      {
        "start": 3050.44,
        "duration": 8.08,
        "text": "3 four five six seven"
      },
      {
        "start": 3054.319,
        "duration": 6.8,
        "text": "emails very is very small small data set"
      },
      {
        "start": 3058.52,
        "duration": 6.24,
        "text": "we agree like the amount is in billions"
      },
      {
        "start": 3061.119,
        "duration": 5.48,
        "text": "and billions and billions usually uh but"
      },
      {
        "start": 3064.76,
        "duration": 4.72,
        "text": "you will be surprised at how good this"
      },
      {
        "start": 3066.599,
        "duration": 5.72,
        "text": "algorithm works even based on those"
      },
      {
        "start": 3069.48,
        "duration": 6.52,
        "text": "seven of emails so what's the first"
      },
      {
        "start": 3072.319,
        "duration": 7.52,
        "text": "preparation we do we work with the"
      },
      {
        "start": 3076.0,
        "duration": 6.64,
        "text": "topics uh of emails subjects of emails"
      },
      {
        "start": 3079.839,
        "duration": 7.0,
        "text": "and we have to label them and we have to"
      },
      {
        "start": 3082.64,
        "duration": 6.919,
        "text": "identify if the email is Spam or not uh"
      },
      {
        "start": 3086.839,
        "duration": 5.76,
        "text": "say as a result of those emails we have"
      },
      {
        "start": 3089.559,
        "duration": 5.921,
        "text": "this little table we have three emails"
      },
      {
        "start": 3092.599,
        "duration": 8.801,
        "text": "identified as spam money transfer receiv"
      },
      {
        "start": 3095.48,
        "duration": 11.119,
        "text": "it get cash easy win money now and we"
      },
      {
        "start": 3101.4,
        "duration": 7.52,
        "text": "have um five emails those are not spam"
      },
      {
        "start": 3106.599,
        "duration": 6.161,
        "text": "uh greetings from Dad could you lend me"
      },
      {
        "start": 3108.92,
        "duration": 7.08,
        "text": "money it was easy I miss you check your"
      },
      {
        "start": 3112.76,
        "duration": 4.799,
        "text": "trip itinerary like uh should be more or"
      },
      {
        "start": 3116.0,
        "duration": 3.839,
        "text": "less familiar to"
      },
      {
        "start": 3117.559,
        "duration": 4.8,
        "text": "everyone some of them are spam some of"
      },
      {
        "start": 3119.839,
        "duration": 5.081,
        "text": "them are not spam what we did right now"
      },
      {
        "start": 3122.359,
        "duration": 3.401,
        "text": "we prepared our data and we label at"
      },
      {
        "start": 3124.92,
        "duration": 3.96,
        "text": "this"
      },
      {
        "start": 3125.76,
        "duration": 6.319,
        "text": "data very good now we know which email"
      },
      {
        "start": 3128.88,
        "duration": 5.88,
        "text": "is Spam and which email is not spam"
      },
      {
        "start": 3132.079,
        "duration": 5.561,
        "text": "first step we can do and we will need"
      },
      {
        "start": 3134.76,
        "duration": 6.359,
        "text": "that later is we calculate the probab"
      },
      {
        "start": 3137.64,
        "duration": 4.959,
        "text": "the chance of email to be spam just"
      },
      {
        "start": 3141.119,
        "duration": 4.761,
        "text": "based on the"
      },
      {
        "start": 3142.599,
        "duration": 7.681,
        "text": "numbers and the uh chance is pretty"
      },
      {
        "start": 3145.88,
        "duration": 7.6,
        "text": "simple it's three of eight of email"
      },
      {
        "start": 3150.28,
        "duration": 5.68,
        "text": "being spam in this example and five of"
      },
      {
        "start": 3153.48,
        "duration": 6.72,
        "text": "eight email is not"
      },
      {
        "start": 3155.96,
        "duration": 6.72,
        "text": "spam uh based on those numbers we have"
      },
      {
        "start": 3160.2,
        "duration": 3.359,
        "text": "can we improve this knowledge let's take"
      },
      {
        "start": 3162.68,
        "duration": 2.76,
        "text": "a"
      },
      {
        "start": 3163.559,
        "duration": 6.28,
        "text": "look"
      },
      {
        "start": 3165.44,
        "duration": 7.08,
        "text": "so um our database small database our"
      },
      {
        "start": 3169.839,
        "duration": 6.841,
        "text": "data set small data set on the left and"
      },
      {
        "start": 3172.52,
        "duration": 7.48,
        "text": "on the right we have a little story"
      },
      {
        "start": 3176.68,
        "duration": 8.04,
        "text": "I received a new email with the subject"
      },
      {
        "start": 3180.0,
        "duration": 8.0,
        "text": "easy money is it spam or not how human"
      },
      {
        "start": 3184.72,
        "duration": 7.119,
        "text": "say that what is the chance it spam if a"
      },
      {
        "start": 3188.0,
        "duration": 6.559,
        "text": "subject is Easy Money how scientists say"
      },
      {
        "start": 3191.839,
        "duration": 3.681,
        "text": "the same idea that's the formula you've"
      },
      {
        "start": 3194.559,
        "duration": 5.24,
        "text": "seen"
      },
      {
        "start": 3195.52,
        "duration": 9.839,
        "text": "already probability of this uh email is"
      },
      {
        "start": 3199.799,
        "duration": 7.241,
        "text": "Spam given it contains easy and money in"
      },
      {
        "start": 3205.359,
        "duration": 4.72,
        "text": "the subject"
      },
      {
        "start": 3207.04,
        "duration": 5.559,
        "text": "what will it be so this statement what"
      },
      {
        "start": 3210.079,
        "duration": 5.76,
        "text": "is the chance of it spam if it has easy"
      },
      {
        "start": 3212.599,
        "duration": 5.48,
        "text": "money and this uh formula let's say this"
      },
      {
        "start": 3215.839,
        "duration": 4.52,
        "text": "statement they are exactly the same but"
      },
      {
        "start": 3218.079,
        "duration": 4.121,
        "text": "second looks more scientifical so now"
      },
      {
        "start": 3220.359,
        "duration": 3.921,
        "text": "you can write everything like that then"
      },
      {
        "start": 3222.2,
        "duration": 5.28,
        "text": "you are calculating probabilities and"
      },
      {
        "start": 3224.28,
        "duration": 6.0,
        "text": "now you will look like a data"
      },
      {
        "start": 3227.48,
        "duration": 5.92,
        "text": "scientist um"
      },
      {
        "start": 3230.28,
        "duration": 5.64,
        "text": "so and now we start to think of the"
      },
      {
        "start": 3233.4,
        "duration": 6.0,
        "text": "topics subjects this email we are"
      },
      {
        "start": 3235.92,
        "duration": 7.8,
        "text": "working with right now has Easy Money"
      },
      {
        "start": 3239.4,
        "duration": 6.84,
        "text": "subject so uh we analyze that step by"
      },
      {
        "start": 3243.72,
        "duration": 7.119,
        "text": "step uh we"
      },
      {
        "start": 3246.24,
        "duration": 7.559,
        "text": "have uh money word money in two out of"
      },
      {
        "start": 3250.839,
        "duration": 5.441,
        "text": "three spam emails so take a look that's"
      },
      {
        "start": 3253.799,
        "duration": 5.441,
        "text": "our spam data set very small money"
      },
      {
        "start": 3256.28,
        "duration": 5.839,
        "text": "transfer reive it win money now in two"
      },
      {
        "start": 3259.24,
        "duration": 5.879,
        "text": "out of three spam emails we have had"
      },
      {
        "start": 3262.119,
        "duration": 8.281,
        "text": "this uh word so"
      },
      {
        "start": 3265.119,
        "duration": 9.601,
        "text": "probability of this um email uh will"
      },
      {
        "start": 3270.4,
        "duration": 6.52,
        "text": "contain now not notice we have here spam"
      },
      {
        "start": 3274.72,
        "duration": 4.96,
        "text": "and easy money on the right side we have"
      },
      {
        "start": 3276.92,
        "duration": 6.04,
        "text": "facts on the left side we have uh what"
      },
      {
        "start": 3279.68,
        "duration": 6.24,
        "text": "do we want to know and now out of this"
      },
      {
        "start": 3282.96,
        "duration": 5.359,
        "text": "money two out of three spam has word V"
      },
      {
        "start": 3285.92,
        "duration": 6.52,
        "text": "money we can calculate what's the"
      },
      {
        "start": 3288.319,
        "duration": 8.201,
        "text": "probability of this email contains word"
      },
      {
        "start": 3292.44,
        "duration": 6.56,
        "text": "money in the subject given its spam know"
      },
      {
        "start": 3296.52,
        "duration": 5.76,
        "text": "it's spam it was labeled before we know"
      },
      {
        "start": 3299.0,
        "duration": 6.48,
        "text": "what probability is two out of three and"
      },
      {
        "start": 3302.28,
        "duration": 5.36,
        "text": "working with not spam we know what only"
      },
      {
        "start": 3305.48,
        "duration": 6.4,
        "text": "one email out of"
      },
      {
        "start": 3307.64,
        "duration": 6.919,
        "text": "five uh got this word money so we see"
      },
      {
        "start": 3311.88,
        "duration": 5.919,
        "text": "probability what word will contain what"
      },
      {
        "start": 3314.559,
        "duration": 6.76,
        "text": "email will contain money if it's uh not"
      },
      {
        "start": 3317.799,
        "duration": 7.081,
        "text": "spam is one uh divided by"
      },
      {
        "start": 3321.319,
        "duration": 6.641,
        "text": "five then we do the same job for easy"
      },
      {
        "start": 3324.88,
        "duration": 6.199,
        "text": "word easy was once in spam and once in"
      },
      {
        "start": 3327.96,
        "duration": 5.839,
        "text": "not spam one out of three spam so"
      },
      {
        "start": 3331.079,
        "duration": 5.52,
        "text": "probability word contains easy sorry"
      },
      {
        "start": 3333.799,
        "duration": 6.161,
        "text": "there is a type of uh in spam is 1"
      },
      {
        "start": 3336.599,
        "duration": 6.2,
        "text": "divided by three and 1 out of five 1"
      },
      {
        "start": 3339.96,
        "duration": 6.2,
        "text": "divided by five now where is a lot of"
      },
      {
        "start": 3342.799,
        "duration": 5.401,
        "text": "numers so maybe you dizzy a little bit"
      },
      {
        "start": 3346.16,
        "duration": 5.84,
        "text": "uh so okay now we have a set of"
      },
      {
        "start": 3348.2,
        "duration": 6.839,
        "text": "probabilities how does that help us very"
      },
      {
        "start": 3352.0,
        "duration": 6.0,
        "text": "simple and very cool feature conditional"
      },
      {
        "start": 3355.039,
        "duration": 7.76,
        "text": "probability the chance what this email"
      },
      {
        "start": 3358.0,
        "duration": 7.24,
        "text": "is Spam or not spam always equals one"
      },
      {
        "start": 3362.799,
        "duration": 5.201,
        "text": "because email cannot be half spam well"
      },
      {
        "start": 3365.24,
        "duration": 4.96,
        "text": "let's say it can be in some chances in"
      },
      {
        "start": 3368.0,
        "duration": 4.88,
        "text": "some cases but we are discussing like"
      },
      {
        "start": 3370.2,
        "duration": 7.08,
        "text": "the simple scenario okay so we know what"
      },
      {
        "start": 3372.88,
        "duration": 6.8,
        "text": "email is or not or spam or not these"
      },
      {
        "start": 3377.28,
        "duration": 6.44,
        "text": "probabilities counted together will or"
      },
      {
        "start": 3379.68,
        "duration": 7.48,
        "text": "always will be equal one and now uh"
      },
      {
        "start": 3383.72,
        "duration": 6.839,
        "text": "that's the uh heart of the naive bias"
      },
      {
        "start": 3387.16,
        "duration": 7.199,
        "text": "algorithm we calculating"
      },
      {
        "start": 3390.559,
        "duration": 5.121,
        "text": "probabilities uh of this uh based on the"
      },
      {
        "start": 3394.359,
        "duration": 5.881,
        "text": "data set we"
      },
      {
        "start": 3395.68,
        "duration": 7.0,
        "text": "have and that's uh very long thing and"
      },
      {
        "start": 3400.24,
        "duration": 4.079,
        "text": "notice we are working of a very simple"
      },
      {
        "start": 3402.68,
        "duration": 3.6,
        "text": "data set like how much more"
      },
      {
        "start": 3404.319,
        "duration": 3.961,
        "text": "computational power you may need to"
      },
      {
        "start": 3406.28,
        "duration": 2.92,
        "text": "calculate similar things on the real"
      },
      {
        "start": 3408.28,
        "duration": 7.2,
        "text": "data"
      },
      {
        "start": 3409.2,
        "duration": 7.56,
        "text": "set uh so we can uh cover that um in"
      },
      {
        "start": 3415.48,
        "duration": 4.92,
        "text": "this way"
      },
      {
        "start": 3416.76,
        "duration": 7.12,
        "text": "that's uh and downstairs we have it with"
      },
      {
        "start": 3420.4,
        "duration": 7.8,
        "text": "real numbers and here with"
      },
      {
        "start": 3423.88,
        "duration": 7.84,
        "text": "explanations uh probability of the email"
      },
      {
        "start": 3428.2,
        "duration": 7.96,
        "text": "is Spam given it has words easy in money"
      },
      {
        "start": 3431.72,
        "duration": 7.48,
        "text": "in subject is the result of all of the"
      },
      {
        "start": 3436.16,
        "duration": 6.52,
        "text": "probabilities we calculated already"
      },
      {
        "start": 3439.2,
        "duration": 5.72,
        "text": "first is uh what's the probability of"
      },
      {
        "start": 3442.68,
        "duration": 4.28,
        "text": "this email to be spam in"
      },
      {
        "start": 3444.92,
        "duration": 4.04,
        "text": "general um"
      },
      {
        "start": 3446.96,
        "duration": 5.079,
        "text": "when uh what it contains"
      },
      {
        "start": 3448.96,
        "duration": 5.68,
        "text": "easy uh and what it contains"
      },
      {
        "start": 3452.039,
        "duration": 6.52,
        "text": "money and intersection of first"
      },
      {
        "start": 3454.64,
        "duration": 5.88,
        "text": "probability is going to be 1 ided by 12"
      },
      {
        "start": 3458.559,
        "duration": 5.921,
        "text": "or as a final result when we are"
      },
      {
        "start": 3460.52,
        "duration": 7.0,
        "text": "bringing them together 10 divided by 13"
      },
      {
        "start": 3464.48,
        "duration": 6.119,
        "text": "because we know what the overall"
      },
      {
        "start": 3467.52,
        "duration": 5.72,
        "text": "probability can always can be only"
      },
      {
        "start": 3470.599,
        "duration": 5.081,
        "text": "one and in the second example"
      },
      {
        "start": 3473.24,
        "duration": 5.0,
        "text": "probability what is not spam will be the"
      },
      {
        "start": 3475.68,
        "duration": 7.439,
        "text": "same thing but just apply data set from"
      },
      {
        "start": 3478.24,
        "duration": 9.0,
        "text": "the not spam field uh data and we see"
      },
      {
        "start": 3483.119,
        "duration": 5.761,
        "text": "what we have after processing very very"
      },
      {
        "start": 3487.24,
        "duration": 4.4,
        "text": "simple uh"
      },
      {
        "start": 3488.88,
        "duration": 5.32,
        "text": "flow which is very easy to distribute"
      },
      {
        "start": 3491.64,
        "duration": 4.84,
        "text": "and calculate on multiple machines we"
      },
      {
        "start": 3494.2,
        "duration": 5.44,
        "text": "have based on this data set of eight"
      },
      {
        "start": 3496.48,
        "duration": 6.119,
        "text": "emails new email with subject easy easy"
      },
      {
        "start": 3499.64,
        "duration": 7.12,
        "text": "money has probability to be spam over"
      },
      {
        "start": 3502.599,
        "duration": 7.281,
        "text": "almost 77 persons and that's where"
      },
      {
        "start": 3506.76,
        "duration": 6.079,
        "text": "a result of a very simple work uh on the"
      },
      {
        "start": 3509.88,
        "duration": 6.679,
        "text": "eight emails we have right now and"
      },
      {
        "start": 3512.839,
        "duration": 8.24,
        "text": "that's already pretty accurate I would"
      },
      {
        "start": 3516.559,
        "duration": 7.841,
        "text": "say so um getting a little bit back how"
      },
      {
        "start": 3521.079,
        "duration": 5.081,
        "text": "it works uh it's a"
      },
      {
        "start": 3524.4,
        "duration": 5.0,
        "text": "reversed uh"
      },
      {
        "start": 3526.16,
        "duration": 5.639,
        "text": "dependency first we uh calculate these"
      },
      {
        "start": 3529.4,
        "duration": 7.24,
        "text": "data on the simple way so we have"
      },
      {
        "start": 3531.799,
        "duration": 7.04,
        "text": "labeled emails we know what um money uh"
      },
      {
        "start": 3536.64,
        "duration": 5.24,
        "text": "What uh probability the email will"
      },
      {
        "start": 3538.839,
        "duration": 5.28,
        "text": "contain um so we trying to calculate"
      },
      {
        "start": 3541.88,
        "duration": 3.8,
        "text": "probability this email will be spam"
      },
      {
        "start": 3544.119,
        "duration": 4.401,
        "text": "based on the"
      },
      {
        "start": 3545.68,
        "duration": 6.919,
        "text": "subject and then they are using reversed"
      },
      {
        "start": 3548.52,
        "duration": 5.839,
        "text": "think probability this email will"
      },
      {
        "start": 3552.599,
        "duration": 6.121,
        "text": "contain one of the key words we are"
      },
      {
        "start": 3554.359,
        "duration": 7.361,
        "text": "looking for given its uh spam or not so"
      },
      {
        "start": 3558.72,
        "duration": 6.48,
        "text": "these numbers like two divided by three"
      },
      {
        "start": 3561.72,
        "duration": 6.44,
        "text": "comes from uh this data set of labeled"
      },
      {
        "start": 3565.2,
        "duration": 5.76,
        "text": "emails man transfer re it get cash easy"
      },
      {
        "start": 3568.16,
        "duration": 6.0,
        "text": "win money now two out of three and we"
      },
      {
        "start": 3570.96,
        "duration": 3.2,
        "text": "are working only with"
      },
      {
        "start": 3575.119,
        "duration": 7.161,
        "text": "subjects okay then bias algorithm we see"
      },
      {
        "start": 3579.799,
        "duration": 4.481,
        "text": "but why it's called it naive"
      },
      {
        "start": 3582.28,
        "duration": 6.039,
        "text": "bias how it"
      },
      {
        "start": 3584.28,
        "duration": 7.4,
        "text": "comes uh very simple naive bias doesn't"
      },
      {
        "start": 3588.319,
        "duration": 6.72,
        "text": "consider relation between facts for"
      },
      {
        "start": 3591.68,
        "duration": 6.2,
        "text": "example if I write a word happy"
      },
      {
        "start": 3595.039,
        "duration": 5.921,
        "text": "probability of the next word to be"
      },
      {
        "start": 3597.88,
        "duration": 5.32,
        "text": "birthday is kind of significantly higher"
      },
      {
        "start": 3600.96,
        "duration": 3.599,
        "text": "than the probability of the next word to"
      },
      {
        "start": 3603.2,
        "duration": 5.08,
        "text": "be"
      },
      {
        "start": 3604.559,
        "duration": 5.881,
        "text": "funerals and if I say long long ago"
      },
      {
        "start": 3608.28,
        "duration": 5.92,
        "text": "chance what person next to me will"
      },
      {
        "start": 3610.44,
        "duration": 7.72,
        "text": "proceed in a galaxy far far away is"
      },
      {
        "start": 3614.2,
        "duration": 7.839,
        "text": "higher than any another phrase I don't"
      },
      {
        "start": 3618.16,
        "duration": 7.0,
        "text": "know um this algorithm does not consider"
      },
      {
        "start": 3622.039,
        "duration": 5.401,
        "text": "those dependencies uh it's all isolated"
      },
      {
        "start": 3625.16,
        "duration": 5.639,
        "text": "facts um"
      },
      {
        "start": 3627.44,
        "duration": 6.96,
        "text": "uh for this algorithm it may uh look"
      },
      {
        "start": 3630.799,
        "duration": 7.401,
        "text": "like pretty stupid but surprisingly it's"
      },
      {
        "start": 3634.4,
        "duration": 6.08,
        "text": "not uh on the uh big data sets it's at"
      },
      {
        "start": 3638.2,
        "duration": 4.28,
        "text": "some point doesn't matter after all"
      },
      {
        "start": 3640.48,
        "duration": 4.72,
        "text": "because usually you work with a data set"
      },
      {
        "start": 3642.48,
        "duration": 6.079,
        "text": "not of eight emails but more like 8"
      },
      {
        "start": 3645.2,
        "duration": 6.839,
        "text": "billion emails at this size at this"
      },
      {
        "start": 3648.559,
        "duration": 5.76,
        "text": "scale it doesn't matter after all and"
      },
      {
        "start": 3652.039,
        "duration": 5.401,
        "text": "all what I say now is very easily"
      },
      {
        "start": 3654.319,
        "duration": 7.081,
        "text": "explained on the right side of screen uh"
      },
      {
        "start": 3657.44,
        "duration": 7.0,
        "text": "close to Cedric uh from the human point"
      },
      {
        "start": 3661.4,
        "duration": 6.159,
        "text": "of view it can be or cold or warm"
      },
      {
        "start": 3664.44,
        "duration": 5.8,
        "text": "outside for from the knif bias"
      },
      {
        "start": 3667.559,
        "duration": 4.881,
        "text": "algorithm those are isolated facts and"
      },
      {
        "start": 3670.24,
        "duration": 7.079,
        "text": "it can"
      },
      {
        "start": 3672.44,
        "duration": 7.119,
        "text": "be sorry uh it's always ready to answer"
      },
      {
        "start": 3677.319,
        "duration": 5.0,
        "text": "without considering the dependencies"
      },
      {
        "start": 3679.559,
        "duration": 6.161,
        "text": "between facts we are"
      },
      {
        "start": 3682.319,
        "duration": 4.841,
        "text": "taking now let's take a look how it"
      },
      {
        "start": 3685.72,
        "duration": 5.04,
        "text": "works"
      },
      {
        "start": 3687.16,
        "duration": 6.679,
        "text": "works so you will do it on your own we"
      },
      {
        "start": 3690.76,
        "duration": 6.64,
        "text": "have a bunch of uh exercises to"
      },
      {
        "start": 3693.839,
        "duration": 7.561,
        "text": "do now I'm at my Jupiter"
      },
      {
        "start": 3697.4,
        "duration": 6.639,
        "text": "instance and uh here I work with uh"
      },
      {
        "start": 3701.4,
        "duration": 5.24,
        "text": "Jupiter with I work with apach Park via"
      },
      {
        "start": 3704.039,
        "duration": 5.481,
        "text": "Jupiter and with Cassandra as"
      },
      {
        "start": 3706.64,
        "duration": 7.28,
        "text": "well yes so to get the Jupiter you can"
      },
      {
        "start": 3709.52,
        "duration": 8.12,
        "text": "go um you know the compos upd as written"
      },
      {
        "start": 3713.92,
        "duration": 6.24,
        "text": "in the Ry but hey please follow Alex uh"
      },
      {
        "start": 3717.64,
        "duration": 5.36,
        "text": "and you can do the exercise later with"
      },
      {
        "start": 3720.16,
        "duration": 5.76,
        "text": "your data set on your own yeah actually"
      },
      {
        "start": 3723.0,
        "duration": 6.2,
        "text": "I know why people always uh run to do"
      },
      {
        "start": 3725.92,
        "duration": 5.679,
        "text": "exercises uh during the workshop uh"
      },
      {
        "start": 3729.2,
        "duration": 5.159,
        "text": "because um people use it to as soon as"
      },
      {
        "start": 3731.599,
        "duration": 5.041,
        "text": "Workshop is done everyone quits and"
      },
      {
        "start": 3734.359,
        "duration": 4.841,
        "text": "there will be no answer ever that's"
      },
      {
        "start": 3736.64,
        "duration": 5.399,
        "text": "wrong we stay here for you even when"
      },
      {
        "start": 3739.2,
        "duration": 6.72,
        "text": "Workshop is done we have our Discord"
      },
      {
        "start": 3742.039,
        "duration": 7.401,
        "text": "server so you can it's you can"
      },
      {
        "start": 3745.92,
        "duration": 4.72,
        "text": "completely go to our uh main chat uh in"
      },
      {
        "start": 3749.44,
        "duration": 4.96,
        "text": "our"
      },
      {
        "start": 3750.64,
        "duration": 5.52,
        "text": "Discord and work with us and ask us our"
      },
      {
        "start": 3754.4,
        "duration": 5.639,
        "text": "questions and we will"
      },
      {
        "start": 3756.16,
        "duration": 6.919,
        "text": "answer yes yes you can even create some"
      },
      {
        "start": 3760.039,
        "duration": 7.401,
        "text": "dedicated rooms you know for topics if"
      },
      {
        "start": 3763.079,
        "duration": 8.081,
        "text": "you want please ask we are 6,000 people"
      },
      {
        "start": 3767.44,
        "duration": 5.839,
        "text": "in the Discord yeah definitely so um"
      },
      {
        "start": 3771.16,
        "duration": 4.8,
        "text": "Workshop is not over as long as you"
      },
      {
        "start": 3773.279,
        "duration": 5.681,
        "text": "don't want it to be over okay and and"
      },
      {
        "start": 3775.96,
        "duration": 5.76,
        "text": "now there is no uh need to hurry and try"
      },
      {
        "start": 3778.96,
        "duration": 5.119,
        "text": "to do everything with me you can do it"
      },
      {
        "start": 3781.72,
        "duration": 5.44,
        "text": "alone and then ask questions via"
      },
      {
        "start": 3784.079,
        "duration": 4.801,
        "text": "Discord and yeah as said you can clone"
      },
      {
        "start": 3787.16,
        "duration": 6.639,
        "text": "this data Stacks Academy machine"
      },
      {
        "start": 3788.88,
        "duration": 8.64,
        "text": "learning workshop online repa or you can"
      },
      {
        "start": 3793.799,
        "duration": 7.28,
        "text": "um grab a cloud instance uh contacting"
      },
      {
        "start": 3797.52,
        "duration": 7.48,
        "text": "me so as a result you anyway going to"
      },
      {
        "start": 3801.079,
        "duration": 7.2,
        "text": "have two web interfaces one is um"
      },
      {
        "start": 3805.0,
        "duration": 4.599,
        "text": "Jupiter and one is data stack studio and"
      },
      {
        "start": 3808.279,
        "duration": 6.441,
        "text": "we start with"
      },
      {
        "start": 3809.599,
        "duration": 10.561,
        "text": "Jupiter uh now I want to work with naive"
      },
      {
        "start": 3814.72,
        "duration": 8.16,
        "text": "bias and this example was developed um"
      },
      {
        "start": 3820.16,
        "duration": 5.119,
        "text": "hey there I just clicked that this"
      },
      {
        "start": 3822.88,
        "duration": 4.56,
        "text": "example was developed by our former"
      },
      {
        "start": 3825.279,
        "duration": 6.08,
        "text": "colleague uh"
      },
      {
        "start": 3827.44,
        "duration": 7.399,
        "text": "Amanda and uh she's great she now works"
      },
      {
        "start": 3831.359,
        "duration": 6.561,
        "text": "uh at Apple I believe and we miss her a"
      },
      {
        "start": 3834.839,
        "duration": 5.76,
        "text": "lot but in your memory at data stocks"
      },
      {
        "start": 3837.92,
        "duration": 6.28,
        "text": "let's say we will run this"
      },
      {
        "start": 3840.599,
        "duration": 7.281,
        "text": "example and this example operates wines"
      },
      {
        "start": 3844.2,
        "duration": 5.119,
        "text": "and wine qualities why because we can"
      },
      {
        "start": 3847.88,
        "duration": 3.959,
        "text": "well you know I'm Russian because it's"
      },
      {
        "start": 3849.319,
        "duration": 5.921,
        "text": "important as well oh okay you know I'm"
      },
      {
        "start": 3851.839,
        "duration": 5.801,
        "text": "Russian so I'm not so much into Vines I"
      },
      {
        "start": 3855.24,
        "duration": 5.16,
        "text": "cannot analyze them but maybe cedic will"
      },
      {
        "start": 3857.64,
        "duration": 7.52,
        "text": "help us yeah basic I wouldn't trust"
      },
      {
        "start": 3860.4,
        "duration": 7.159,
        "text": "Narin to to judge a wine so we will see"
      },
      {
        "start": 3865.16,
        "duration": 5.439,
        "text": "uh if it algorithm works good or not so"
      },
      {
        "start": 3867.559,
        "duration": 4.76,
        "text": "good we will see maybe it's not the best"
      },
      {
        "start": 3870.599,
        "duration": 5.161,
        "text": "way and you know what that's always"
      },
      {
        "start": 3872.319,
        "duration": 6.121,
        "text": "about iterational Improvement you try"
      },
      {
        "start": 3875.76,
        "duration": 5.0,
        "text": "this one uh you train the model you get"
      },
      {
        "start": 3878.44,
        "duration": 5.2,
        "text": "the results you assess the results and"
      },
      {
        "start": 3880.76,
        "duration": 4.519,
        "text": "you see if you are satisfied or you are"
      },
      {
        "start": 3883.64,
        "duration": 4.04,
        "text": "not satisfied and there is something to"
      },
      {
        "start": 3885.279,
        "duration": 6.0,
        "text": "change so I don't know maybe this uh"
      },
      {
        "start": 3887.68,
        "duration": 7.28,
        "text": "algorithm will work not so good for us"
      },
      {
        "start": 3891.279,
        "duration": 7.641,
        "text": "okay yeah so um what we are trying to"
      },
      {
        "start": 3894.96,
        "duration": 6.639,
        "text": "learn from this data set question can"
      },
      {
        "start": 3898.92,
        "duration": 6.6,
        "text": "naive buyers be used to classify a wine"
      },
      {
        "start": 3901.599,
        "duration": 7.72,
        "text": "rating score by its attributes so we"
      },
      {
        "start": 3905.52,
        "duration": 7.519,
        "text": "have a set of wines uh people some"
      },
      {
        "start": 3909.319,
        "duration": 6.04,
        "text": "experts uh try them and set some ratings"
      },
      {
        "start": 3913.039,
        "duration": 5.361,
        "text": "like that's a great wine this one wine"
      },
      {
        "start": 3915.359,
        "duration": 5.161,
        "text": "is not so great and what we want to try"
      },
      {
        "start": 3918.4,
        "duration": 5.08,
        "text": "with a machine learning in this example"
      },
      {
        "start": 3920.52,
        "duration": 7.72,
        "text": "we want to try to predict will those"
      },
      {
        "start": 3923.48,
        "duration": 7.599,
        "text": "experts like our new V let's say or not"
      },
      {
        "start": 3928.24,
        "duration": 5.119,
        "text": "and which kind of data we have first of"
      },
      {
        "start": 3931.079,
        "duration": 6.52,
        "text": "all we have some wines with ratings"
      },
      {
        "start": 3933.359,
        "duration": 6.041,
        "text": "already and we also know chemical um how"
      },
      {
        "start": 3937.599,
        "duration": 5.041,
        "text": "it's called it in English"
      },
      {
        "start": 3939.4,
        "duration": 6.159,
        "text": "chemical uh yeah chemical it's chemicals"
      },
      {
        "start": 3942.64,
        "duration": 6.28,
        "text": "yeah yeah yeah uh those chemicals it"
      },
      {
        "start": 3945.559,
        "duration": 6.081,
        "text": "contains and can it work together uh"
      },
      {
        "start": 3948.92,
        "duration": 6.24,
        "text": "using naive bias or maybe not so"
      },
      {
        "start": 3951.64,
        "duration": 4.56,
        "text": "much so uh how do you use Jupiter"
      },
      {
        "start": 3955.16,
        "duration": 3.36,
        "text": "notebook"
      },
      {
        "start": 3956.2,
        "duration": 5.2,
        "text": "this uh you will have exactly the same"
      },
      {
        "start": 3958.52,
        "duration": 6.92,
        "text": "thing as I have right here you see what"
      },
      {
        "start": 3961.4,
        "duration": 6.36,
        "text": "I've activated naive bias uh notebook uh"
      },
      {
        "start": 3965.44,
        "duration": 4.72,
        "text": "by the way it's important every notebook"
      },
      {
        "start": 3967.76,
        "duration": 5.359,
        "text": "is a pretty uh big thing it doesn't look"
      },
      {
        "start": 3970.16,
        "duration": 5.679,
        "text": "like big thing but it's a big thing so"
      },
      {
        "start": 3973.119,
        "duration": 4.68,
        "text": "uh if you have all of them running uh"
      },
      {
        "start": 3975.839,
        "duration": 5.48,
        "text": "memory of your machine was probably"
      },
      {
        "start": 3977.799,
        "duration": 7.961,
        "text": "going to be very busy so what you want"
      },
      {
        "start": 3981.319,
        "duration": 6.561,
        "text": "to do as soon as your notebook is done I"
      },
      {
        "start": 3985.76,
        "duration": 4.799,
        "text": "L suggest to shut it down otherwise if"
      },
      {
        "start": 3987.88,
        "duration": 6.0,
        "text": "you have five of notebooks are running"
      },
      {
        "start": 3990.559,
        "duration": 6.04,
        "text": "it will be too tight for them to work"
      },
      {
        "start": 3993.88,
        "duration": 4.84,
        "text": "efficiently okay so there are some text"
      },
      {
        "start": 3996.599,
        "duration": 5.161,
        "text": "Fields I will not touch and there are"
      },
      {
        "start": 3998.72,
        "duration": 5.96,
        "text": "some executable lines I'm going to touch"
      },
      {
        "start": 4001.76,
        "duration": 5.519,
        "text": "to execute a line I set my cursor on it"
      },
      {
        "start": 4004.68,
        "duration": 4.399,
        "text": "so it's highlighted in green I will try"
      },
      {
        "start": 4007.279,
        "duration": 5.641,
        "text": "to make it a little bit bigger yeah"
      },
      {
        "start": 4009.079,
        "duration": 7.0,
        "text": "looks good I think it looks good mhm"
      },
      {
        "start": 4012.92,
        "duration": 6.199,
        "text": "good and it's huge okay"
      },
      {
        "start": 4016.079,
        "duration": 7.96,
        "text": "even better and I will do it full"
      },
      {
        "start": 4019.119,
        "duration": 8.081,
        "text": "screen yeah great and I push the Run"
      },
      {
        "start": 4024.039,
        "duration": 5.52,
        "text": "button to execute this statement and"
      },
      {
        "start": 4027.2,
        "duration": 4.8,
        "text": "first one is very simple first two"
      },
      {
        "start": 4029.559,
        "duration": 5.8,
        "text": "actually are very simple I'm in"
      },
      {
        "start": 4032.0,
        "duration": 5.559,
        "text": "importing dependencies I will need and"
      },
      {
        "start": 4035.359,
        "duration": 5.081,
        "text": "you may see some familiar depend"
      },
      {
        "start": 4037.559,
        "duration": 5.401,
        "text": "dependencies here first like pandas we"
      },
      {
        "start": 4040.44,
        "duration": 4.8,
        "text": "discussed it some minutes ago then P"
      },
      {
        "start": 4042.96,
        "duration": 4.839,
        "text": "spark we used to connect to python to"
      },
      {
        "start": 4045.24,
        "duration": 3.72,
        "text": "spark Park and Cassandra we use to"
      },
      {
        "start": 4047.799,
        "duration": 3.52,
        "text": "connect to"
      },
      {
        "start": 4048.96,
        "duration": 7.079,
        "text": "Cassandra we will need some random"
      },
      {
        "start": 4051.319,
        "duration": 6.76,
        "text": "things and from P spark we uh import the"
      },
      {
        "start": 4056.039,
        "duration": 5.08,
        "text": "most important thing for us machine"
      },
      {
        "start": 4058.079,
        "duration": 6.48,
        "text": "learning classification we import naive"
      },
      {
        "start": 4061.119,
        "duration": 5.641,
        "text": "bias algorithm and we will need some uh"
      },
      {
        "start": 4064.559,
        "duration": 7.56,
        "text": "vectors vector assemblers and string"
      },
      {
        "start": 4066.76,
        "duration": 8.44,
        "text": "indexers to prepare data uh for to be"
      },
      {
        "start": 4072.119,
        "duration": 7.041,
        "text": "processed then next step I want to do is"
      },
      {
        "start": 4075.2,
        "duration": 5.0,
        "text": "just a little helper function I run this"
      },
      {
        "start": 4079.16,
        "duration": 4.04,
        "text": "uh"
      },
      {
        "start": 4080.2,
        "duration": 6.119,
        "text": "string not string cell cell is a better"
      },
      {
        "start": 4083.2,
        "duration": 5.04,
        "text": "name I run this cell to Define uh"
      },
      {
        "start": 4086.319,
        "duration": 4.28,
        "text": "function I will need if you are into"
      },
      {
        "start": 4088.24,
        "duration": 6.0,
        "text": "python you know what that's the way how"
      },
      {
        "start": 4090.599,
        "duration": 5.961,
        "text": "we Define uh functions if you are not"
      },
      {
        "start": 4094.24,
        "duration": 5.959,
        "text": "well you can just trust me it's good"
      },
      {
        "start": 4096.56,
        "duration": 6.48,
        "text": "enough for today uh that's nothing big"
      },
      {
        "start": 4100.199,
        "duration": 6.16,
        "text": "just helps us to display lines of"
      },
      {
        "start": 4103.04,
        "duration": 6.4,
        "text": "code and then we start to load data"
      },
      {
        "start": 4106.359,
        "duration": 6.36,
        "text": "first to work with data we will use"
      },
      {
        "start": 4109.44,
        "duration": 6.279,
        "text": "Cassandra um you can do the same things"
      },
      {
        "start": 4112.719,
        "duration": 4.921,
        "text": "uh loading data directly from the files"
      },
      {
        "start": 4115.719,
        "duration": 5.161,
        "text": "but that's not how it works in real"
      },
      {
        "start": 4117.64,
        "duration": 7.079,
        "text": "world so at first we connect to"
      },
      {
        "start": 4120.88,
        "duration": 6.879,
        "text": "Cassandra and we let first we connect to"
      },
      {
        "start": 4124.719,
        "duration": 6.161,
        "text": "Cassandra connected and we are going to"
      },
      {
        "start": 4127.759,
        "duration": 5.52,
        "text": "uh create a key space we will store our"
      },
      {
        "start": 4130.88,
        "duration": 4.6,
        "text": "data if you attended one of our"
      },
      {
        "start": 4133.279,
        "duration": 4.361,
        "text": "Cassandra workshops before you know what"
      },
      {
        "start": 4135.48,
        "duration": 4.12,
        "text": "what does that mean if you didn't and"
      },
      {
        "start": 4137.64,
        "duration": 4.159,
        "text": "you don't know how Cassandra Works"
      },
      {
        "start": 4139.6,
        "duration": 5.96,
        "text": "doesn't matter Cassandra is just"
      },
      {
        "start": 4141.799,
        "duration": 6.121,
        "text": "Cassandra's key space is just a group of"
      },
      {
        "start": 4145.56,
        "duration": 5.4,
        "text": "tables we are going to use"
      },
      {
        "start": 4147.92,
        "duration": 5.759,
        "text": "together so here I'm creating keyspace"
      },
      {
        "start": 4150.96,
        "duration": 2.719,
        "text": "to store my"
      },
      {
        "start": 4153.759,
        "duration": 6.641,
        "text": "data good and I set these key space"
      },
      {
        "start": 4157.799,
        "duration": 7.0,
        "text": "accelerate to be the default key"
      },
      {
        "start": 4160.4,
        "duration": 6.48,
        "text": "space for me and I create table create"
      },
      {
        "start": 4164.799,
        "duration": 5.96,
        "text": "table if not exist"
      },
      {
        "start": 4166.88,
        "duration": 7.04,
        "text": "wine and that's what we have uh we are"
      },
      {
        "start": 4170.759,
        "duration": 9.361,
        "text": "going to have in this table at first"
      },
      {
        "start": 4173.92,
        "duration": 9.0,
        "text": "every vne has 11 chemical values acidity"
      },
      {
        "start": 4180.12,
        "duration": 8.8,
        "text": "volatile acidity citric acid and so on"
      },
      {
        "start": 4182.92,
        "duration": 8.759,
        "text": "and so forth and uh uh alcohol like so"
      },
      {
        "start": 4188.92,
        "duration": 7.96,
        "text": "how much alcohol it has oops and finally"
      },
      {
        "start": 4191.679,
        "duration": 8.441,
        "text": "the quality uh quality is uh um the"
      },
      {
        "start": 4196.88,
        "duration": 6.359,
        "text": "result of this Vine being assessed by"
      },
      {
        "start": 4200.12,
        "duration": 4.72,
        "text": "Vine experts uh maybe Cedric was one of"
      },
      {
        "start": 4203.239,
        "duration": 6.241,
        "text": "them I don't"
      },
      {
        "start": 4204.84,
        "duration": 6.68,
        "text": "know I wish I would well uh you still"
      },
      {
        "start": 4209.48,
        "duration": 5.759,
        "text": "have enough time okay so we created with"
      },
      {
        "start": 4211.52,
        "duration": 7.84,
        "text": "stable we can double check that by going"
      },
      {
        "start": 4215.239,
        "duration": 6.041,
        "text": "to our data stock studio uh open our"
      },
      {
        "start": 4219.36,
        "duration": 4.72,
        "text": "naive bias"
      },
      {
        "start": 4221.28,
        "duration": 5.16,
        "text": "classification and at first I may ask to"
      },
      {
        "start": 4224.08,
        "duration": 4.88,
        "text": "describe keyspace accelerate I have to"
      },
      {
        "start": 4226.44,
        "duration": 7.239,
        "text": "make it a little bit bigger"
      },
      {
        "start": 4228.96,
        "duration": 6.48,
        "text": "again yes please good so yeah it's here"
      },
      {
        "start": 4233.679,
        "duration": 4.961,
        "text": "we have keyspace"
      },
      {
        "start": 4235.44,
        "duration": 6.32,
        "text": "accelerate and we have uh table vines"
      },
      {
        "start": 4238.64,
        "duration": 6.4,
        "text": "with all the values we discuss it and by"
      },
      {
        "start": 4241.76,
        "duration": 5.6,
        "text": "the way you see there is a lot of lines"
      },
      {
        "start": 4245.04,
        "duration": 4.76,
        "text": "and properties we haven't defined"
      },
      {
        "start": 4247.36,
        "duration": 5.799,
        "text": "predefined properties for Cassandra"
      },
      {
        "start": 4249.8,
        "duration": 5.84,
        "text": "Cassandra is the best tool to manage uh"
      },
      {
        "start": 4253.159,
        "duration": 6.08,
        "text": "petabytes of data and dispatch from"
      },
      {
        "start": 4255.64,
        "duration": 6.8,
        "text": "within very tiny milliseconds so if you"
      },
      {
        "start": 4259.239,
        "duration": 5.121,
        "text": "work with high LS like that you"
      },
      {
        "start": 4262.44,
        "duration": 4.68,
        "text": "definitely want to attend one of our"
      },
      {
        "start": 4264.36,
        "duration": 5.0,
        "text": "Cassandra workshops uh closest intro to"
      },
      {
        "start": 4267.12,
        "duration": 5.32,
        "text": "Cassandra Workshop happens to be this"
      },
      {
        "start": 4269.36,
        "duration": 6.319,
        "text": "week I believe yep exactly this wedes"
      },
      {
        "start": 4272.44,
        "duration": 6.4,
        "text": "day and Thursday two times yes yes yes"
      },
      {
        "start": 4275.679,
        "duration": 6.121,
        "text": "yes yes and you know what I feel like"
      },
      {
        "start": 4278.84,
        "duration": 5.96,
        "text": "you know having Cassandra to help uh"
      },
      {
        "start": 4281.8,
        "duration": 4.12,
        "text": "spark to train the model is uh pretty"
      },
      {
        "start": 4284.8,
        "duration": 3.2,
        "text": "relevant"
      },
      {
        "start": 4285.92,
        "duration": 4.56,
        "text": "because you may want to use a"
      },
      {
        "start": 4288.0,
        "duration": 4.04,
        "text": "distributed uh algorithm to train"
      },
      {
        "start": 4290.48,
        "duration": 5.12,
        "text": "because it's a lot of"
      },
      {
        "start": 4292.04,
        "duration": 5.599,
        "text": "data and Spark is distributed C is"
      },
      {
        "start": 4295.6,
        "duration": 4.84,
        "text": "distributed I think it's working well"
      },
      {
        "start": 4297.639,
        "duration": 5.961,
        "text": "together and it's not only using CSV"
      },
      {
        "start": 4300.44,
        "duration": 4.96,
        "text": "files as you may uh tends to do uh when"
      },
      {
        "start": 4303.6,
        "duration": 5.32,
        "text": "you're working with machine"
      },
      {
        "start": 4305.4,
        "duration": 7.239,
        "text": "learning good okay so we have uh it"
      },
      {
        "start": 4308.92,
        "duration": 5.799,
        "text": "prepared it now we have to load data set"
      },
      {
        "start": 4312.639,
        "duration": 5.161,
        "text": "love the pictures yeah well that's"
      },
      {
        "start": 4314.719,
        "duration": 4.721,
        "text": "Amanda I would set I still want cheese"
      },
      {
        "start": 4317.8,
        "duration": 6.28,
        "text": "now you"
      },
      {
        "start": 4319.44,
        "duration": 7.96,
        "text": "know oh yeah good so uh we are loading"
      },
      {
        "start": 4324.08,
        "duration": 6.4,
        "text": "wine data sets from CSV files uh we have"
      },
      {
        "start": 4327.4,
        "duration": 5.72,
        "text": "two CSV files prepared one for red and"
      },
      {
        "start": 4330.48,
        "duration": 6.44,
        "text": "one for white uh"
      },
      {
        "start": 4333.12,
        "duration": 6.72,
        "text": "wines uh so I simply execute this"
      },
      {
        "start": 4336.92,
        "duration": 5.2,
        "text": "cell and it will take some time because"
      },
      {
        "start": 4339.84,
        "duration": 6.12,
        "text": "we are reading from two"
      },
      {
        "start": 4342.12,
        "duration": 7.28,
        "text": "files and uh inserting data okay it's"
      },
      {
        "start": 4345.96,
        "duration": 4.759,
        "text": "done very well so now we can again open"
      },
      {
        "start": 4349.4,
        "duration": 6.319,
        "text": "data stack"
      },
      {
        "start": 4350.719,
        "duration": 8.52,
        "text": "studio and ask to show those"
      },
      {
        "start": 4355.719,
        "duration": 6.52,
        "text": "values good and we see the data we have"
      },
      {
        "start": 4359.239,
        "duration": 6.161,
        "text": "we've all disc discussed"
      },
      {
        "start": 4362.239,
        "duration": 7.281,
        "text": "qualities very"
      },
      {
        "start": 4365.4,
        "duration": 7.799,
        "text": "well then finally we are getting closer"
      },
      {
        "start": 4369.52,
        "duration": 6.199,
        "text": "to spark so Cassandra is very good when"
      },
      {
        "start": 4373.199,
        "duration": 4.721,
        "text": "you have to store data and disp tou it"
      },
      {
        "start": 4375.719,
        "duration": 4.96,
        "text": "on the production uh real production"
      },
      {
        "start": 4377.92,
        "duration": 5.12,
        "text": "workloads to not make your customers"
      },
      {
        "start": 4380.679,
        "duration": 5.401,
        "text": "waiting candre is very"
      },
      {
        "start": 4383.04,
        "duration": 5.159,
        "text": "quick and now we need spark to connect"
      },
      {
        "start": 4386.08,
        "duration": 4.72,
        "text": "to Cassandra and load this data to"
      },
      {
        "start": 4388.199,
        "duration": 5.04,
        "text": "execute machine learning operations so"
      },
      {
        "start": 4390.8,
        "duration": 5.879,
        "text": "let's take a look what's going on I'm"
      },
      {
        "start": 4393.239,
        "duration": 6.081,
        "text": "using previously imported spark session"
      },
      {
        "start": 4396.679,
        "duration": 5.56,
        "text": "Builder um with application named demo"
      },
      {
        "start": 4399.32,
        "duration": 6.16,
        "text": "doesn't matter master so Master of the"
      },
      {
        "start": 4402.239,
        "duration": 6.521,
        "text": "spark cluster will be local"
      },
      {
        "start": 4405.48,
        "duration": 6.6,
        "text": "that's a uh educational cluster not the"
      },
      {
        "start": 4408.76,
        "duration": 7.28,
        "text": "real big one and I get or create the"
      },
      {
        "start": 4412.08,
        "duration": 6.28,
        "text": "spark when I um I will execute it right"
      },
      {
        "start": 4416.04,
        "duration": 5.48,
        "text": "now because it will take some time so we"
      },
      {
        "start": 4418.36,
        "duration": 8.2,
        "text": "can walk when I have to define a wine"
      },
      {
        "start": 4421.52,
        "duration": 8.76,
        "text": "data frame to do so I ask spark to read"
      },
      {
        "start": 4426.56,
        "duration": 6.84,
        "text": "data in the format uh"
      },
      {
        "start": 4430.28,
        "duration": 6.48,
        "text": "Cassandra with options what I'm going to"
      },
      {
        "start": 4433.4,
        "duration": 6.72,
        "text": "read table wine keyspace accelerate and"
      },
      {
        "start": 4436.76,
        "duration": 6.04,
        "text": "I need to load this data after that I'm"
      },
      {
        "start": 4440.12,
        "duration": 6.44,
        "text": "printing output what's the count of the"
      },
      {
        "start": 4442.8,
        "duration": 5.6,
        "text": "wine data frame I've downloaded data"
      },
      {
        "start": 4446.56,
        "duration": 4.119,
        "text": "frame is a spark definition not the"
      },
      {
        "start": 4448.4,
        "duration": 4.64,
        "text": "Cassandra one because here we are using"
      },
      {
        "start": 4450.679,
        "duration": 4.04,
        "text": "spark as you could see it only loads"
      },
      {
        "start": 4453.04,
        "duration": 7.159,
        "text": "data from"
      },
      {
        "start": 4454.719,
        "duration": 8.081,
        "text": "Cassandra and we see what we have almost"
      },
      {
        "start": 4460.199,
        "duration": 5.681,
        "text": "6,500 wines and their"
      },
      {
        "start": 4462.8,
        "duration": 6.48,
        "text": "estimations W yeah"
      },
      {
        "start": 4465.88,
        "duration": 6.64,
        "text": "um why do you need more than two wines"
      },
      {
        "start": 4469.28,
        "duration": 7.04,
        "text": "Cedric I mean white and red should"
      },
      {
        "start": 4472.52,
        "duration": 6.88,
        "text": "because we are not Russian and drinking"
      },
      {
        "start": 4476.32,
        "duration": 5.56,
        "text": "vodka oh no it's too complicated for me"
      },
      {
        "start": 4479.4,
        "duration": 6.279,
        "text": "but whatever some flavors you"
      },
      {
        "start": 4481.88,
        "duration": 5.6,
        "text": "know uh so we have show data frame"
      },
      {
        "start": 4485.679,
        "duration": 5.361,
        "text": "that's the function we defined it in the"
      },
      {
        "start": 4487.48,
        "duration": 6.159,
        "text": "beginning just to keep it like uh nice"
      },
      {
        "start": 4491.04,
        "duration": 5.56,
        "text": "and we see what every wine has ID"
      },
      {
        "start": 4493.639,
        "duration": 9.281,
        "text": "alcohol some chem IAL"
      },
      {
        "start": 4496.6,
        "duration": 10.2,
        "text": "values and uh quality as well now next"
      },
      {
        "start": 4502.92,
        "duration": 6.92,
        "text": "thing we want our wines to be the best"
      },
      {
        "start": 4506.8,
        "duration": 8.76,
        "text": "so we are going to filter out all vnes"
      },
      {
        "start": 4509.84,
        "duration": 8.08,
        "text": "with quality lower when uh five uh first"
      },
      {
        "start": 4515.56,
        "duration": 5.639,
        "text": "we are using the spark feature called it"
      },
      {
        "start": 4517.92,
        "duration": 6.64,
        "text": "filter so we are doing qu data frame."
      },
      {
        "start": 4521.199,
        "duration": 6.121,
        "text": "filter quality bigger than five we"
      },
      {
        "start": 4524.56,
        "duration": 6.76,
        "text": "Define new data frame which is will be"
      },
      {
        "start": 4527.32,
        "duration": 6.64,
        "text": "Vine six data frame with all the vines"
      },
      {
        "start": 4531.32,
        "duration": 5.28,
        "text": "quality higher than five and we show"
      },
      {
        "start": 4533.96,
        "duration": 2.64,
        "text": "this data"
      },
      {
        "start": 4536.639,
        "duration": 6.921,
        "text": "frame boom so now you see what I have"
      },
      {
        "start": 4540.76,
        "duration": 5.879,
        "text": "all the vines in this list uh with"
      },
      {
        "start": 4543.56,
        "duration": 3.079,
        "text": "quality six or"
      },
      {
        "start": 4547.44,
        "duration": 9.84,
        "text": "higher good then we have to prepare uh"
      },
      {
        "start": 4553.28,
        "duration": 6.959,
        "text": "data to be properly Pro assess it so as"
      },
      {
        "start": 4557.28,
        "duration": 4.6,
        "text": "we are using naive bias first everything"
      },
      {
        "start": 4560.239,
        "duration": 7.201,
        "text": "has to be a"
      },
      {
        "start": 4561.88,
        "duration": 8.6,
        "text": "vectors um to uh prepare that things we"
      },
      {
        "start": 4567.44,
        "duration": 6.32,
        "text": "are using Vector assembler and as an"
      },
      {
        "start": 4570.48,
        "duration": 7.0,
        "text": "input colum colums we are using alcohol"
      },
      {
        "start": 4573.76,
        "duration": 6.64,
        "text": "chlorides um free sulfur and so on and"
      },
      {
        "start": 4577.48,
        "duration": 6.28,
        "text": "so forth so all the chemical values we"
      },
      {
        "start": 4580.4,
        "duration": 8.799,
        "text": "have uh preparing"
      },
      {
        "start": 4583.76,
        "duration": 8.879,
        "text": "these uh uh vectors needed for um oh my"
      },
      {
        "start": 4589.199,
        "duration": 6.561,
        "text": "god um for the naive bias to be uh"
      },
      {
        "start": 4592.639,
        "duration": 5.841,
        "text": "processed and for us it will be just"
      },
      {
        "start": 4595.76,
        "duration": 7.56,
        "text": "features as an output columns we"
      },
      {
        "start": 4598.48,
        "duration": 8.04,
        "text": "need and then uh we uh prepare training"
      },
      {
        "start": 4603.32,
        "duration": 7.56,
        "text": "data we will use to train with this"
      },
      {
        "start": 4606.52,
        "duration": 6.92,
        "text": "assembler we transform WI six data frame"
      },
      {
        "start": 4610.88,
        "duration": 5.92,
        "text": "and training data as a result of his"
      },
      {
        "start": 4613.44,
        "duration": 6.44,
        "text": "data processing of wine six data frame"
      },
      {
        "start": 4616.8,
        "duration": 6.28,
        "text": "with all the high quality wines we have"
      },
      {
        "start": 4619.88,
        "duration": 8.08,
        "text": "uh prepared for the training few more"
      },
      {
        "start": 4623.08,
        "duration": 7.44,
        "text": "things we need to do first one we uh"
      },
      {
        "start": 4627.96,
        "duration": 4.64,
        "text": "need to set the labels as discussed"
      },
      {
        "start": 4630.52,
        "duration": 5.44,
        "text": "that's a supervised learning so we need"
      },
      {
        "start": 4632.6,
        "duration": 5.84,
        "text": "labels in this case labels will be built"
      },
      {
        "start": 4635.96,
        "duration": 5.52,
        "text": "on the quality because we are going to"
      },
      {
        "start": 4638.44,
        "duration": 4.44,
        "text": "work with quality and output colume will"
      },
      {
        "start": 4641.48,
        "duration": 5.6,
        "text": "be just"
      },
      {
        "start": 4642.88,
        "duration": 6.2,
        "text": "label and as a result we have uh here"
      },
      {
        "start": 4647.08,
        "duration": 6.04,
        "text": "training data"
      },
      {
        "start": 4649.08,
        "duration": 6.76,
        "text": "one using the values we prepared for us"
      },
      {
        "start": 4653.12,
        "duration": 5.32,
        "text": "so we get our label indexer which is a"
      },
      {
        "start": 4655.84,
        "duration": 5.319,
        "text": "St St string indexer based on the"
      },
      {
        "start": 4658.44,
        "duration": 5.56,
        "text": "quality we are trying to classify those"
      },
      {
        "start": 4661.159,
        "duration": 4.841,
        "text": "vnes we have into multiple groups uh"
      },
      {
        "start": 4664.0,
        "duration": 4.96,
        "text": "based on their chemical values we are"
      },
      {
        "start": 4666.0,
        "duration": 6.199,
        "text": "having here we are fitting these"
      },
      {
        "start": 4668.96,
        "duration": 7.759,
        "text": "training data with indexer and finally"
      },
      {
        "start": 4672.199,
        "duration": 4.52,
        "text": "uh transform with training data"
      },
      {
        "start": 4676.92,
        "duration": 5.56,
        "text": "and I'm launching these and we receive"
      },
      {
        "start": 4679.32,
        "duration": 6.44,
        "text": "the results we are creating the"
      },
      {
        "start": 4682.48,
        "duration": 6.52,
        "text": "vectors with all the elements of wine in"
      },
      {
        "start": 4685.76,
        "duration": 6.959,
        "text": "this case everything is already prepared"
      },
      {
        "start": 4689.0,
        "duration": 7.44,
        "text": "and we have count of training data we"
      },
      {
        "start": 4692.719,
        "duration": 8.121,
        "text": "have is uh 4,000 so we separated that"
      },
      {
        "start": 4696.44,
        "duration": 7.52,
        "text": "and prepar it um so we uh have 4,000 and"
      },
      {
        "start": 4700.84,
        "duration": 5.6,
        "text": "something wines of quality high enough"
      },
      {
        "start": 4703.96,
        "duration": 4.759,
        "text": "to participate in our learning and now"
      },
      {
        "start": 4706.44,
        "duration": 4.52,
        "text": "all the data is prepared and we finish"
      },
      {
        "start": 4708.719,
        "duration": 5.241,
        "text": "it with preparational"
      },
      {
        "start": 4710.96,
        "duration": 5.88,
        "text": "step and we need to split up our data"
      },
      {
        "start": 4713.96,
        "duration": 5.6,
        "text": "set into training and set usually it"
      },
      {
        "start": 4716.84,
        "duration": 5.64,
        "text": "works a little bit uh more complicated"
      },
      {
        "start": 4719.56,
        "duration": 5.52,
        "text": "so we need training validating and test"
      },
      {
        "start": 4722.48,
        "duration": 5.239,
        "text": "set for cross validation as that's a"
      },
      {
        "start": 4725.08,
        "duration": 5.2,
        "text": "simpler example and starting from Basics"
      },
      {
        "start": 4727.719,
        "duration": 6.241,
        "text": "we will have just training and test set"
      },
      {
        "start": 4730.28,
        "duration": 6.84,
        "text": "and we will split 80 to 20 so first we"
      },
      {
        "start": 4733.96,
        "duration": 5.239,
        "text": "just split we use training data with a"
      },
      {
        "start": 4737.12,
        "duration": 4.68,
        "text": "random split so way will be splited"
      },
      {
        "start": 4739.199,
        "duration": 5.681,
        "text": "randomly some goes to first set some"
      },
      {
        "start": 4741.8,
        "duration": 4.0,
        "text": "goes to second set and proportion will"
      },
      {
        "start": 4744.88,
        "duration": 3.24,
        "text": "be"
      },
      {
        "start": 4745.8,
        "duration": 6.04,
        "text": "0.8"
      },
      {
        "start": 4748.12,
        "duration": 7.96,
        "text": "0.2 uh and we have as a result two sets"
      },
      {
        "start": 4751.84,
        "duration": 6.319,
        "text": "here train and tests I'm executing this"
      },
      {
        "start": 4756.08,
        "duration": 5.24,
        "text": "one it's going to be pretty quick"
      },
      {
        "start": 4758.159,
        "duration": 5.921,
        "text": "because we aren't uh doing learning yet"
      },
      {
        "start": 4761.32,
        "duration": 4.919,
        "text": "we just doing the uh separation so we"
      },
      {
        "start": 4764.08,
        "duration": 6.04,
        "text": "have three"
      },
      {
        "start": 4766.239,
        "duration": 5.721,
        "text": "3,366 uh in the training set and 747 in"
      },
      {
        "start": 4770.12,
        "duration": 5.8,
        "text": "the test data"
      },
      {
        "start": 4771.96,
        "duration": 7.8,
        "text": "frame now it's finally time to launch"
      },
      {
        "start": 4775.92,
        "duration": 6.92,
        "text": "that uh so uh we are launching naive"
      },
      {
        "start": 4779.76,
        "duration": 8.12,
        "text": "bias we Define that"
      },
      {
        "start": 4782.84,
        "duration": 8.28,
        "text": "first um we here train the model we do"
      },
      {
        "start": 4787.88,
        "duration": 7.48,
        "text": "with train data from the previous"
      },
      {
        "start": 4791.12,
        "duration": 7.28,
        "text": "step we calculate our predictions"
      },
      {
        "start": 4795.36,
        "duration": 7.48,
        "text": "uh based on the test data using the same"
      },
      {
        "start": 4798.4,
        "duration": 9.319,
        "text": "model so here learning comes here we are"
      },
      {
        "start": 4802.84,
        "duration": 4.879,
        "text": "doing our predictions I'm launching"
      },
      {
        "start": 4808.44,
        "duration": 6.48,
        "text": "that okay so we are showing results of"
      },
      {
        "start": 4811.56,
        "duration": 7.28,
        "text": "our predictions in this case quality is"
      },
      {
        "start": 4814.92,
        "duration": 6.0,
        "text": "the new field predicted uh by our model"
      },
      {
        "start": 4818.84,
        "duration": 7.0,
        "text": "that's uh this field"
      },
      {
        "start": 4820.92,
        "duration": 8.759,
        "text": "is not available and um"
      },
      {
        "start": 4825.84,
        "duration": 6.52,
        "text": "we can run these uh predictions to show"
      },
      {
        "start": 4829.679,
        "duration": 6.361,
        "text": "the most important thing for us"
      },
      {
        "start": 4832.36,
        "duration": 6.839,
        "text": "quality um and uh label predictions and"
      },
      {
        "start": 4836.04,
        "duration": 6.84,
        "text": "probability so the fields required here"
      },
      {
        "start": 4839.199,
        "duration": 6.081,
        "text": "and now uh we uh train it our model we"
      },
      {
        "start": 4842.88,
        "duration": 5.52,
        "text": "process it test data that's important to"
      },
      {
        "start": 4845.28,
        "duration": 5.64,
        "text": "remember test data goes to model without"
      },
      {
        "start": 4848.4,
        "duration": 4.799,
        "text": "quality so the quality of that will be"
      },
      {
        "start": 4850.92,
        "duration": 5.319,
        "text": "not available that's our predictions"
      },
      {
        "start": 4853.199,
        "duration": 6.48,
        "text": "already not the the values from the data"
      },
      {
        "start": 4856.239,
        "duration": 6.201,
        "text": "set we have and finally we use"
      },
      {
        "start": 4859.679,
        "duration": 5.801,
        "text": "multiclass classification evaluator to"
      },
      {
        "start": 4862.44,
        "duration": 6.64,
        "text": "evaluate the accuracy of our predictions"
      },
      {
        "start": 4865.48,
        "duration": 6.44,
        "text": "so we did predictions are they good or"
      },
      {
        "start": 4869.08,
        "duration": 7.44,
        "text": "not so all the previous lines are"
      },
      {
        "start": 4871.92,
        "duration": 8.08,
        "text": "executed and now we can try to execute"
      },
      {
        "start": 4876.52,
        "duration": 4.719,
        "text": "that and we see what test set accuracy"
      },
      {
        "start": 4880.0,
        "duration": 4.4,
        "text": "is"
      },
      {
        "start": 4881.239,
        "duration": 6.081,
        "text": "0.6 so uh Cedric it looks like you were"
      },
      {
        "start": 4884.4,
        "duration": 5.68,
        "text": "right right and machine learning or at"
      },
      {
        "start": 4887.32,
        "duration": 4.76,
        "text": "least knife bias algorithm in this case"
      },
      {
        "start": 4890.08,
        "duration": 5.76,
        "text": "is not the best way"
      },
      {
        "start": 4892.08,
        "duration": 6.32,
        "text": "to uh try to predict the quality of wine"
      },
      {
        "start": 4895.84,
        "duration": 5.12,
        "text": "maybe we should simply ask you next"
      },
      {
        "start": 4898.4,
        "duration": 5.52,
        "text": "time I'm really maybe they need more"
      },
      {
        "start": 4900.96,
        "duration": 6.6,
        "text": "data set I'm happy to enter those"
      },
      {
        "start": 4903.92,
        "duration": 6.04,
        "text": "data I need to test the wi though good"
      },
      {
        "start": 4907.56,
        "duration": 4.48,
        "text": "but that's not the end because we have"
      },
      {
        "start": 4909.96,
        "duration": 4.719,
        "text": "uh some more things to cover so we will"
      },
      {
        "start": 4912.04,
        "duration": 6.159,
        "text": "get back to this example very soon the"
      },
      {
        "start": 4914.679,
        "duration": 6.52,
        "text": "only thing I want to tell you is I want"
      },
      {
        "start": 4918.199,
        "duration": 4.921,
        "text": "to shut down this notebook otherwise I"
      },
      {
        "start": 4921.199,
        "duration": 3.841,
        "text": "will have too much of the running uh"
      },
      {
        "start": 4923.12,
        "duration": 7.519,
        "text": "notebooks in the"
      },
      {
        "start": 4925.04,
        "duration": 9.0,
        "text": "end good okay so let me get"
      },
      {
        "start": 4930.639,
        "duration": 5.761,
        "text": "back and now I want to take at take a"
      },
      {
        "start": 4934.04,
        "duration": 5.72,
        "text": "look at the another algorithm we may"
      },
      {
        "start": 4936.4,
        "duration": 6.839,
        "text": "need to use today to get better"
      },
      {
        "start": 4939.76,
        "duration": 6.6,
        "text": "prediction on the uh data set we were"
      },
      {
        "start": 4943.239,
        "duration": 6.601,
        "text": "working with random Forest is a"
      },
      {
        "start": 4946.36,
        "duration": 6.12,
        "text": "supervised classification emble method"
      },
      {
        "start": 4949.84,
        "duration": 6.76,
        "text": "and notice that's not an algorithm but"
      },
      {
        "start": 4952.48,
        "duration": 6.4,
        "text": "the Ensemble method I was talking about"
      },
      {
        "start": 4956.6,
        "duration": 5.119,
        "text": "algorithms and now there is an ensemble"
      },
      {
        "start": 4958.88,
        "duration": 6.92,
        "text": "method what does that mean let's take a"
      },
      {
        "start": 4961.719,
        "duration": 7.44,
        "text": "look first it all comes from a decision"
      },
      {
        "start": 4965.8,
        "duration": 5.48,
        "text": "tree um uh on the left you as always"
      },
      {
        "start": 4969.159,
        "duration": 5.961,
        "text": "have the definition from Wiki which"
      },
      {
        "start": 4971.28,
        "duration": 7.12,
        "text": "never helps and I want to um explain"
      },
      {
        "start": 4975.12,
        "duration": 7.16,
        "text": "that on the simple example on the right"
      },
      {
        "start": 4978.4,
        "duration": 6.56,
        "text": "decision tree is a simple uh"
      },
      {
        "start": 4982.28,
        "duration": 5.399,
        "text": "way very simple maybe one of the most"
      },
      {
        "start": 4984.96,
        "duration": 5.719,
        "text": "simple uh algorithms possible decision"
      },
      {
        "start": 4987.679,
        "duration": 6.52,
        "text": "Tre is an algorithm which basic which"
      },
      {
        "start": 4990.679,
        "duration": 7.56,
        "text": "kind of answers questions uh yes no"
      },
      {
        "start": 4994.199,
        "duration": 6.641,
        "text": "higher lower equals not equals and uh"
      },
      {
        "start": 4998.239,
        "duration": 5.281,
        "text": "calculates things uh based on the"
      },
      {
        "start": 5000.84,
        "duration": 5.44,
        "text": "answers trying to combine different"
      },
      {
        "start": 5003.52,
        "duration": 5.4,
        "text": "questions and ANW"
      },
      {
        "start": 5006.28,
        "duration": 6.0,
        "text": "um decision three for Titanic Survival"
      },
      {
        "start": 5008.92,
        "duration": 6.44,
        "text": "on this case is at first level based on"
      },
      {
        "start": 5012.28,
        "duration": 6.879,
        "text": "the gender at the second level based on"
      },
      {
        "start": 5015.36,
        "duration": 6.12,
        "text": "the age and in the third layer based on"
      },
      {
        "start": 5019.159,
        "duration": 5.08,
        "text": "the siblings count amount of brothers"
      },
      {
        "start": 5021.48,
        "duration": 5.159,
        "text": "and sisters so here with the decision"
      },
      {
        "start": 5024.239,
        "duration": 4.681,
        "text": "Tre we are calculating what's the"
      },
      {
        "start": 5026.639,
        "duration": 5.321,
        "text": "probability what were the probability to"
      },
      {
        "start": 5028.92,
        "duration": 8.16,
        "text": "survive survive in the Titanic"
      },
      {
        "start": 5031.96,
        "duration": 7.96,
        "text": "disaster um back in in the last century"
      },
      {
        "start": 5037.08,
        "duration": 4.88,
        "text": "so and that's a very simple decision Tre"
      },
      {
        "start": 5039.92,
        "duration": 5.16,
        "text": "because yes they are"
      },
      {
        "start": 5041.96,
        "duration": 5.56,
        "text": "simple um decision Tre algorithm tries"
      },
      {
        "start": 5045.08,
        "duration": 5.44,
        "text": "to calculate the best possible decision"
      },
      {
        "start": 5047.52,
        "duration": 6.32,
        "text": "tree uh based on the labels you are"
      },
      {
        "start": 5050.52,
        "duration": 6.44,
        "text": "giving and we see how in this case uh"
      },
      {
        "start": 5053.84,
        "duration": 6.68,
        "text": "answering first uh gender allows us"
      },
      {
        "start": 5056.96,
        "duration": 6.44,
        "text": "answering first question allows us to uh"
      },
      {
        "start": 5060.52,
        "duration": 5.719,
        "text": "Define the probability to survive and if"
      },
      {
        "start": 5063.4,
        "duration": 5.08,
        "text": "it's situation is is more complicated"
      },
      {
        "start": 5066.239,
        "duration": 5.44,
        "text": "then it tries to add more questions to"
      },
      {
        "start": 5068.48,
        "duration": 6.28,
        "text": "answer with different values uh if H is"
      },
      {
        "start": 5071.679,
        "duration": 5.401,
        "text": "more than 9.5 years probability to die"
      },
      {
        "start": 5074.76,
        "duration": 5.72,
        "text": "for a gender male was"
      },
      {
        "start": 5077.08,
        "duration": 5.96,
        "text": "61% and depend if age was smaller than"
      },
      {
        "start": 5080.48,
        "duration": 5.639,
        "text": "9.5 then it depends of amount of"
      },
      {
        "start": 5083.04,
        "duration": 6.4,
        "text": "siblings this kind of decision trees are"
      },
      {
        "start": 5086.119,
        "duration": 6.681,
        "text": "generated easily by the"
      },
      {
        "start": 5089.44,
        "duration": 7.279,
        "text": "algorithms and they have all a big"
      },
      {
        "start": 5092.8,
        "duration": 6.359,
        "text": "problem uh by it is a single decision"
      },
      {
        "start": 5096.719,
        "duration": 4.641,
        "text": "tree has a strong tendency to be"
      },
      {
        "start": 5099.159,
        "duration": 4.48,
        "text": "overfeed it works"
      },
      {
        "start": 5101.36,
        "duration": 5.4,
        "text": "perfectly with the data you're giving"
      },
      {
        "start": 5103.639,
        "duration": 6.04,
        "text": "training data so giving generating those"
      },
      {
        "start": 5106.76,
        "duration": 6.2,
        "text": "questions and answers and answering"
      },
      {
        "start": 5109.679,
        "duration": 5.721,
        "text": "them uh it behaves very good on the"
      },
      {
        "start": 5112.96,
        "duration": 4.8,
        "text": "training data but as soon as you give"
      },
      {
        "start": 5115.4,
        "duration": 5.719,
        "text": "test data which was not available on the"
      },
      {
        "start": 5117.76,
        "duration": 5.68,
        "text": "training time it immediately uh start to"
      },
      {
        "start": 5121.119,
        "duration": 5.961,
        "text": "give very wrong answers because it's"
      },
      {
        "start": 5123.44,
        "duration": 6.679,
        "text": "overfeed not General enough to solve"
      },
      {
        "start": 5127.08,
        "duration": 6.4,
        "text": "this problem we use Ensemble method"
      },
      {
        "start": 5130.119,
        "duration": 6.361,
        "text": "random Forest random Forest is a a"
      },
      {
        "start": 5133.48,
        "duration": 6.199,
        "text": "method uh which unites multiple decision"
      },
      {
        "start": 5136.48,
        "duration": 6.239,
        "text": "trees and as those decision"
      },
      {
        "start": 5139.679,
        "duration": 6.52,
        "text": "trees uh answer ask and answer different"
      },
      {
        "start": 5142.719,
        "duration": 7.241,
        "text": "questions they as a result give good"
      },
      {
        "start": 5146.199,
        "duration": 6.48,
        "text": "General enough uh method uh and although"
      },
      {
        "start": 5149.96,
        "duration": 5.48,
        "text": "every decision tree is very simple by it"
      },
      {
        "start": 5152.679,
        "duration": 6.201,
        "text": "is they are also"
      },
      {
        "start": 5155.44,
        "duration": 6.92,
        "text": "uh very uh good and reasonable United by"
      },
      {
        "start": 5158.88,
        "duration": 6.04,
        "text": "random Forest method um my random Forest"
      },
      {
        "start": 5162.36,
        "duration": 5.2,
        "text": "by uh it is also has some configurable"
      },
      {
        "start": 5164.92,
        "duration": 5.12,
        "text": "parameters for example you may say what"
      },
      {
        "start": 5167.56,
        "duration": 5.159,
        "text": "every decision tree has the same weight"
      },
      {
        "start": 5170.04,
        "duration": 6.44,
        "text": "of the answer or you may say what the"
      },
      {
        "start": 5172.719,
        "duration": 7.121,
        "text": "decision tree based on these values has"
      },
      {
        "start": 5176.48,
        "duration": 6.159,
        "text": "higher uh weight uh for the following"
      },
      {
        "start": 5179.84,
        "duration": 5.64,
        "text": "answer um in this case we will use the"
      },
      {
        "start": 5182.639,
        "duration": 4.881,
        "text": "very simple approach so let's take a"
      },
      {
        "start": 5185.48,
        "duration": 4.84,
        "text": "look Maybe random Forest will work"
      },
      {
        "start": 5187.52,
        "duration": 6.48,
        "text": "better for us and cedc Has Cedric has"
      },
      {
        "start": 5190.32,
        "duration": 5.28,
        "text": "something to be afraid of I don't know I"
      },
      {
        "start": 5194.0,
        "duration": 7.08,
        "text": "have no"
      },
      {
        "start": 5195.6,
        "duration": 7.559,
        "text": "fear good so I'm launching uh my random"
      },
      {
        "start": 5201.08,
        "duration": 5.36,
        "text": "Forest"
      },
      {
        "start": 5203.159,
        "duration": 4.881,
        "text": "notebook and in Data stock Studio I will"
      },
      {
        "start": 5206.44,
        "duration": 6.799,
        "text": "jump back to"
      },
      {
        "start": 5208.04,
        "duration": 9.32,
        "text": "notebooks and switch to random Forest"
      },
      {
        "start": 5213.239,
        "duration": 9.321,
        "text": "notebook good so same data"
      },
      {
        "start": 5217.36,
        "duration": 5.2,
        "text": "set um I may"
      },
      {
        "start": 5222.76,
        "duration": 7.8,
        "text": "need to do a little clean up on data"
      },
      {
        "start": 5225.76,
        "duration": 7.359,
        "text": "maybe but we will see so run run first"
      },
      {
        "start": 5230.56,
        "duration": 7.079,
        "text": "two steps uh should be very familiar to"
      },
      {
        "start": 5233.119,
        "duration": 6.801,
        "text": "you so I'm loading new um I'm loading"
      },
      {
        "start": 5237.639,
        "duration": 4.441,
        "text": "dependencies uh in this case it will be"
      },
      {
        "start": 5239.92,
        "duration": 5.16,
        "text": "a little bit different because I'm going"
      },
      {
        "start": 5242.08,
        "duration": 5.96,
        "text": "to use uh python americ classification"
      },
      {
        "start": 5245.08,
        "duration": 7.0,
        "text": "algorithm random Forest classifier which"
      },
      {
        "start": 5248.04,
        "duration": 8.24,
        "text": "is again not an algorithm but emble"
      },
      {
        "start": 5252.08,
        "duration": 6.88,
        "text": "method good I'm defining the uh so"
      },
      {
        "start": 5256.28,
        "duration": 5.24,
        "text": "that's a new notebook and therefore it's"
      },
      {
        "start": 5258.96,
        "duration": 5.12,
        "text": "a new environment so I have to redefine"
      },
      {
        "start": 5261.52,
        "duration": 6.199,
        "text": "things I'm us it already I'm defining"
      },
      {
        "start": 5264.08,
        "duration": 7.28,
        "text": "the same show DF uh function for pretty"
      },
      {
        "start": 5267.719,
        "duration": 8.4,
        "text": "formatting of a data we work to I has to"
      },
      {
        "start": 5271.36,
        "duration": 4.759,
        "text": "contact my Cassandra cluster"
      },
      {
        "start": 5276.239,
        "duration": 7.92,
        "text": "and I will use the same uh key space it"
      },
      {
        "start": 5280.84,
        "duration": 5.76,
        "text": "exist anyway and I will use that for all"
      },
      {
        "start": 5284.159,
        "duration": 4.48,
        "text": "my data"
      },
      {
        "start": 5286.6,
        "duration": 5.28,
        "text": "good"
      },
      {
        "start": 5288.639,
        "duration": 6.921,
        "text": "so I want to kill this table and load"
      },
      {
        "start": 5291.88,
        "duration": 6.0,
        "text": "the data again but actually it should"
      },
      {
        "start": 5295.56,
        "duration": 4.559,
        "text": "has the same data as far as I remember"
      },
      {
        "start": 5297.88,
        "duration": 4.72,
        "text": "so we can simply proceed to The Next"
      },
      {
        "start": 5300.119,
        "duration": 6.161,
        "text": "Step so table is"
      },
      {
        "start": 5302.6,
        "duration": 8.16,
        "text": "available data is loaded and we can"
      },
      {
        "start": 5306.28,
        "duration": 4.48,
        "text": "start to work with spark"
      },
      {
        "start": 5318.76,
        "duration": 7.56,
        "text": "directly okay so we have the data"
      },
      {
        "start": 5322.44,
        "duration": 6.0,
        "text": "here and we see all the values we"
      },
      {
        "start": 5326.32,
        "duration": 5.399,
        "text": "process it already now we will apply"
      },
      {
        "start": 5328.44,
        "duration": 5.279,
        "text": "another approach so that's always about"
      },
      {
        "start": 5331.719,
        "duration": 5.041,
        "text": "iterative and trying to find something"
      },
      {
        "start": 5333.719,
        "duration": 7.321,
        "text": "what will works better so I'm creating"
      },
      {
        "start": 5336.76,
        "duration": 4.28,
        "text": "data frame with one of higher"
      },
      {
        "start": 5343.239,
        "duration": 8.641,
        "text": "qualities good and uh now I'm uh"
      },
      {
        "start": 5347.239,
        "duration": 7.841,
        "text": "vectoring Vector fying um data I'm going"
      },
      {
        "start": 5351.88,
        "duration": 6.359,
        "text": "to work with so that's the steps we did"
      },
      {
        "start": 5355.08,
        "duration": 7.159,
        "text": "in the previous step uh we will need"
      },
      {
        "start": 5358.239,
        "duration": 6.4,
        "text": "indexers um and vectors to prepare all"
      },
      {
        "start": 5362.239,
        "duration": 5.041,
        "text": "the data uh to be"
      },
      {
        "start": 5364.639,
        "duration": 7.241,
        "text": "strongly strongly mathematical for the"
      },
      {
        "start": 5367.28,
        "duration": 4.6,
        "text": "random Forest to answer in the simple"
      },
      {
        "start": 5376.08,
        "duration": 6.76,
        "text": "way very"
      },
      {
        "start": 5378.239,
        "duration": 5.521,
        "text": "well and now we have to split our data"
      },
      {
        "start": 5382.84,
        "duration": 4.96,
        "text": "again"
      },
      {
        "start": 5383.76,
        "duration": 6.16,
        "text": "into training set and test set so you've"
      },
      {
        "start": 5387.8,
        "duration": 4.839,
        "text": "seen that"
      },
      {
        "start": 5389.92,
        "duration": 5.44,
        "text": "already we will use train set to train"
      },
      {
        "start": 5392.639,
        "duration": 6.281,
        "text": "model and we will use test Set uh to"
      },
      {
        "start": 5395.36,
        "duration": 7.48,
        "text": "evaluate model if it's good or"
      },
      {
        "start": 5398.92,
        "duration": 6.56,
        "text": "not and now that's interesting uh thing"
      },
      {
        "start": 5402.84,
        "duration": 6.12,
        "text": "happens so we will use random Forest"
      },
      {
        "start": 5405.48,
        "duration": 7.36,
        "text": "classifier uh from uh spark"
      },
      {
        "start": 5408.96,
        "duration": 6.96,
        "text": "Library um label column so the label we"
      },
      {
        "start": 5412.84,
        "duration": 5.24,
        "text": "want to give will be label uh features"
      },
      {
        "start": 5415.92,
        "duration": 5.04,
        "text": "column is the features so that's the"
      },
      {
        "start": 5418.08,
        "duration": 5.88,
        "text": "think we prepared it in this previous"
      },
      {
        "start": 5420.96,
        "duration": 3.0,
        "text": "step"
      },
      {
        "start": 5424.4,
        "duration": 7.16,
        "text": "and finally number of trees do we want"
      },
      {
        "start": 5426.76,
        "duration": 7.8,
        "text": "to have will be equal 10 m uh here we go"
      },
      {
        "start": 5431.56,
        "duration": 6.159,
        "text": "with this step uh so we are running this"
      },
      {
        "start": 5434.56,
        "duration": 5.159,
        "text": "random forest classifier and train that"
      },
      {
        "start": 5437.719,
        "duration": 4.641,
        "text": "and when we do predictions one more time"
      },
      {
        "start": 5439.719,
        "duration": 5.081,
        "text": "don't forget on the train data with a"
      },
      {
        "start": 5442.36,
        "duration": 5.64,
        "text": "predictions our model will not have"
      },
      {
        "start": 5444.8,
        "duration": 5.76,
        "text": "access to we quality estimated assessed"
      },
      {
        "start": 5448.0,
        "duration": 6.679,
        "text": "by the experts but it will be result of"
      },
      {
        "start": 5450.56,
        "duration": 4.119,
        "text": "the our model to work"
      },
      {
        "start": 5456.719,
        "duration": 6.121,
        "text": "good so we done with training based on"
      },
      {
        "start": 5460.56,
        "duration": 6.639,
        "text": "the 10 trees in this"
      },
      {
        "start": 5462.84,
        "duration": 7.72,
        "text": "method and we can run predictions and"
      },
      {
        "start": 5467.199,
        "duration": 7.561,
        "text": "show results uh show predictions uh"
      },
      {
        "start": 5470.56,
        "duration": 7.0,
        "text": "based on the training we did before and"
      },
      {
        "start": 5474.76,
        "duration": 5.2,
        "text": "now we can use multiclass classification"
      },
      {
        "start": 5477.56,
        "duration": 5.92,
        "text": "evaluator to evaluate the accuracy of"
      },
      {
        "start": 5479.96,
        "duration": 6.56,
        "text": "our prediction so this evaluator we need"
      },
      {
        "start": 5483.48,
        "duration": 6.8,
        "text": "to estimate how it works if it's good or"
      },
      {
        "start": 5486.52,
        "duration": 7.96,
        "text": "not label column will be label so the uh"
      },
      {
        "start": 5490.28,
        "duration": 6.879,
        "text": "prediction so the quality for us is and"
      },
      {
        "start": 5494.48,
        "duration": 4.6,
        "text": "um metric name is accuracy so we want to"
      },
      {
        "start": 5497.159,
        "duration": 5.401,
        "text": "measure"
      },
      {
        "start": 5499.08,
        "duration": 7.079,
        "text": "accuracy I'm running this one and we see"
      },
      {
        "start": 5502.56,
        "duration": 5.88,
        "text": "what accuracy just jumped up from"
      },
      {
        "start": 5506.159,
        "duration": 5.0,
        "text": "0.61 to"
      },
      {
        "start": 5508.44,
        "duration": 4.279,
        "text": "0.7 so it looks like we are moving in"
      },
      {
        "start": 5511.159,
        "duration": 4.96,
        "text": "the right"
      },
      {
        "start": 5512.719,
        "duration": 6.281,
        "text": "direction uh um I see the question"
      },
      {
        "start": 5516.119,
        "duration": 6.321,
        "text": "aren't we overfeeding the data if we"
      },
      {
        "start": 5519.0,
        "duration": 7.0,
        "text": "would go into the smaller amount of"
      },
      {
        "start": 5522.44,
        "duration": 7.64,
        "text": "trees when yes but you know what I would"
      },
      {
        "start": 5526.0,
        "duration": 7.679,
        "text": "ask uh you in this case uh to try to"
      },
      {
        "start": 5530.08,
        "duration": 7.48,
        "text": "play with the amount of uh trees and see"
      },
      {
        "start": 5533.679,
        "duration": 7.56,
        "text": "if it if it will work better or not and"
      },
      {
        "start": 5537.56,
        "duration": 3.679,
        "text": "when we can talk about that in"
      },
      {
        "start": 5542.84,
        "duration": 5.96,
        "text": "Discord"
      },
      {
        "start": 5545.8,
        "duration": 3.0,
        "text": "so"
      },
      {
        "start": 5555.0,
        "duration": 6.84,
        "text": "uh and we have to say thank you because"
      },
      {
        "start": 5559.32,
        "duration": 3.96,
        "text": "it was a great time together more than"
      },
      {
        "start": 5561.84,
        "duration": 4.2,
        "text": "one and a half an"
      },
      {
        "start": 5563.28,
        "duration": 5.839,
        "text": "hour and we are ready to try to answer"
      },
      {
        "start": 5566.04,
        "duration": 6.48,
        "text": "some of your questions in General Life"
      },
      {
        "start": 5569.119,
        "duration": 7.12,
        "text": "part of the workshop is done and we will"
      },
      {
        "start": 5572.52,
        "duration": 5.599,
        "text": "be happy to see you again on all of our"
      },
      {
        "start": 5576.239,
        "duration": 5.641,
        "text": "upcoming"
      },
      {
        "start": 5578.119,
        "duration": 6.161,
        "text": "events yes so we just demo two"
      },
      {
        "start": 5581.88,
        "duration": 7.839,
        "text": "algorithms with our Nave bins and random"
      },
      {
        "start": 5584.28,
        "duration": 8.52,
        "text": "Forest if you see uh on you know Jupiter"
      },
      {
        "start": 5589.719,
        "duration": 6.281,
        "text": "you can also try some FP growth and"
      },
      {
        "start": 5592.8,
        "duration": 5.48,
        "text": "collaborating filterings which are more"
      },
      {
        "start": 5596.0,
        "duration": 5.52,
        "text": "Deep dive but as usual everything is"
      },
      {
        "start": 5598.28,
        "duration": 7.68,
        "text": "pretty well designed and written for you"
      },
      {
        "start": 5601.52,
        "duration": 8.199,
        "text": "so yep so uh that's an intra very int"
      },
      {
        "start": 5605.96,
        "duration": 6.56,
        "text": "level Workshop it's a big field uh and I"
      },
      {
        "start": 5609.719,
        "duration": 5.801,
        "text": "want yeah it's a very big field so if"
      },
      {
        "start": 5612.52,
        "duration": 6.679,
        "text": "you want to get a deeper di into that"
      },
      {
        "start": 5615.52,
        "duration": 6.599,
        "text": "now you know uh at least how it works in"
      },
      {
        "start": 5619.199,
        "duration": 6.201,
        "text": "general and uh it was a very good place"
      },
      {
        "start": 5622.119,
        "duration": 5.321,
        "text": "to start but if you want to master that"
      },
      {
        "start": 5625.4,
        "duration": 4.68,
        "text": "if you want to become a data scientist"
      },
      {
        "start": 5627.44,
        "duration": 5.16,
        "text": "you definitely going to plan some time"
      },
      {
        "start": 5630.08,
        "duration": 5.559,
        "text": "accordingly to learn all the required"
      },
      {
        "start": 5632.6,
        "duration": 6.92,
        "text": "things uh uh thank you"
      },
      {
        "start": 5635.639,
        "duration": 7.361,
        "text": "everyone uh for I see a question can we"
      },
      {
        "start": 5639.52,
        "duration": 7.119,
        "text": "apply K means alga to this problem uh"
      },
      {
        "start": 5643.0,
        "duration": 7.56,
        "text": "good question simple answer we could try"
      },
      {
        "start": 5646.639,
        "duration": 8.961,
        "text": "but uh it will not work so in this case"
      },
      {
        "start": 5650.56,
        "duration": 8.28,
        "text": "we work with um labels we understand"
      },
      {
        "start": 5655.6,
        "duration": 6.88,
        "text": "what quality of this wine is five or six"
      },
      {
        "start": 5658.84,
        "duration": 7.44,
        "text": "or seven or eight and so on and we want"
      },
      {
        "start": 5662.48,
        "duration": 8.92,
        "text": "to see where our new estimation"
      },
      {
        "start": 5666.28,
        "duration": 8.8,
        "text": "gets and uh K means is a good thing uh"
      },
      {
        "start": 5671.4,
        "duration": 6.68,
        "text": "but um doubt if it will work so much uh"
      },
      {
        "start": 5675.08,
        "duration": 5.36,
        "text": "for this example because well it's about"
      },
      {
        "start": 5678.08,
        "duration": 6.559,
        "text": "different thing it's about grouping"
      },
      {
        "start": 5680.44,
        "duration": 6.36,
        "text": "things things for example and yeah I"
      },
      {
        "start": 5684.639,
        "duration": 4.08,
        "text": "wouldn't go with K means for this"
      },
      {
        "start": 5686.8,
        "duration": 5.68,
        "text": "example"
      },
      {
        "start": 5688.719,
        "duration": 7.161,
        "text": "definitely last thing I want to say for"
      },
      {
        "start": 5692.48,
        "duration": 6.6,
        "text": "today we we are preparing something"
      },
      {
        "start": 5695.88,
        "duration": 6.6,
        "text": "special for you but before it's"
      },
      {
        "start": 5699.08,
        "duration": 7.159,
        "text": "ready we still have announcements of all"
      },
      {
        "start": 5702.48,
        "duration": 7.639,
        "text": "of our upcoming events on event bride uh"
      },
      {
        "start": 5706.239,
        "duration": 6.681,
        "text": "with data Stacks first we have an action"
      },
      {
        "start": 5710.119,
        "duration": 6.161,
        "text": "certification exam preparation Workshop"
      },
      {
        "start": 5712.92,
        "duration": 7.6,
        "text": "now data Stacks has great special"
      },
      {
        "start": 5716.28,
        "duration": 7.56,
        "text": "project uh so you can become a certified"
      },
      {
        "start": 5720.52,
        "duration": 6.44,
        "text": "kapach Cassandra expert absolutely for"
      },
      {
        "start": 5723.84,
        "duration": 5.879,
        "text": "free zero expenses you only need to put"
      },
      {
        "start": 5726.96,
        "duration": 4.84,
        "text": "your time into e and efforts into effort"
      },
      {
        "start": 5729.719,
        "duration": 3.201,
        "text": "yeah efforts yeah there is no free meal"
      },
      {
        "start": 5731.8,
        "duration": 5.64,
        "text": "you still have"
      },
      {
        "start": 5732.92,
        "duration": 7.88,
        "text": "to but no money at all yeah so uh that's"
      },
      {
        "start": 5737.44,
        "duration": 5.4,
        "text": "an associate level exam and uh even if"
      },
      {
        "start": 5740.8,
        "duration": 5.319,
        "text": "you are beginner developer if you know"
      },
      {
        "start": 5742.84,
        "duration": 5.839,
        "text": "how to write code uh you can handle this"
      },
      {
        "start": 5746.119,
        "duration": 6.0,
        "text": "with our video courses video courses are"
      },
      {
        "start": 5748.679,
        "duration": 5.361,
        "text": "available at the academy. dat.com and"
      },
      {
        "start": 5752.119,
        "duration": 4.641,
        "text": "how to do and how to prepare for the"
      },
      {
        "start": 5754.04,
        "duration": 5.96,
        "text": "certification completely explain it in"
      },
      {
        "start": 5756.76,
        "duration": 5.0,
        "text": "this exam now uh Monday learning"
      },
      {
        "start": 5760.0,
        "duration": 4.96,
        "text": "introduction to machine learning just"
      },
      {
        "start": 5761.76,
        "duration": 5.68,
        "text": "finish it uh Cloud native Cassandra"
      },
      {
        "start": 5764.96,
        "duration": 6.56,
        "text": "introduction to Cassandra this wedness"
      },
      {
        "start": 5767.44,
        "duration": 5.04,
        "text": "day and this Thursday um so hope to see"
      },
      {
        "start": 5771.52,
        "duration": 4.76,
        "text": "you"
      },
      {
        "start": 5772.48,
        "duration": 9.32,
        "text": "soon next Monday we have kubernetes"
      },
      {
        "start": 5776.28,
        "duration": 10.04,
        "text": "native applications so uh it's not easy"
      },
      {
        "start": 5781.8,
        "duration": 6.919,
        "text": "now uh okay Cloud development and cloud"
      },
      {
        "start": 5786.32,
        "duration": 5.56,
        "text": "cloud ecosystem and containerization"
      },
      {
        "start": 5788.719,
        "duration": 6.641,
        "text": "kubernetes helps to develop and deliver"
      },
      {
        "start": 5791.88,
        "duration": 5.839,
        "text": "applications a lot but that's uh still"
      },
      {
        "start": 5795.36,
        "duration": 5.08,
        "text": "making your application efficient is a"
      },
      {
        "start": 5797.719,
        "duration": 5.561,
        "text": "sh shared responsibility it's not only"
      },
      {
        "start": 5800.44,
        "duration": 5.799,
        "text": "for operations guys to run it into the"
      },
      {
        "start": 5803.28,
        "duration": 5.2,
        "text": "kubernetes but also for developers to"
      },
      {
        "start": 5806.239,
        "duration": 5.4,
        "text": "understand some requirements in this"
      },
      {
        "start": 5808.48,
        "duration": 5.239,
        "text": "Workshop we cover exactly the point how"
      },
      {
        "start": 5811.639,
        "duration": 5.801,
        "text": "do you design and write your applic"
      },
      {
        "start": 5813.719,
        "duration": 6.48,
        "text": "ation so way will be uh efficient uh in"
      },
      {
        "start": 5817.44,
        "duration": 4.64,
        "text": "the operations time on the production I"
      },
      {
        "start": 5820.199,
        "duration": 6.361,
        "text": "strongly recommend this"
      },
      {
        "start": 5822.08,
        "duration": 6.92,
        "text": "one and uh finally upcoming next week we"
      },
      {
        "start": 5826.56,
        "duration": 4.48,
        "text": "will have putting Apache Cassandra on"
      },
      {
        "start": 5829.0,
        "duration": 5.679,
        "text": "automatic with"
      },
      {
        "start": 5831.04,
        "duration": 5.92,
        "text": "kubernetes and um that's how we run"
      },
      {
        "start": 5834.679,
        "duration": 4.881,
        "text": "Cassandra in kubernetes that's for those"
      },
      {
        "start": 5836.96,
        "duration": 6.88,
        "text": "who already into Cassandra a little bit"
      },
      {
        "start": 5839.56,
        "duration": 7.24,
        "text": "and one more thing I wanted to announce"
      },
      {
        "start": 5843.84,
        "duration": 6.48,
        "text": "I hope Cedric will forgive me for"
      },
      {
        "start": 5846.8,
        "duration": 6.839,
        "text": "announcing a little bit external event"
      },
      {
        "start": 5850.32,
        "duration": 6.799,
        "text": "but I speak there so I hope it's a"
      },
      {
        "start": 5853.639,
        "duration": 7.48,
        "text": "reason good enough to find that give me"
      },
      {
        "start": 5857.119,
        "duration": 6.0,
        "text": "a moment oh you know um any content we"
      },
      {
        "start": 5861.119,
        "duration": 5.08,
        "text": "provide of course we should promote it"
      },
      {
        "start": 5863.119,
        "duration": 6.52,
        "text": "more um if you are not subscribed to the"
      },
      {
        "start": 5866.199,
        "duration": 7.52,
        "text": "channel you should I mean we are live"
      },
      {
        "start": 5869.639,
        "duration": 6.361,
        "text": "multiple times a week so twice on Monday"
      },
      {
        "start": 5873.719,
        "duration": 5.321,
        "text": "uh this week is machine"
      },
      {
        "start": 5876.0,
        "duration": 7.199,
        "text": "learning Wednesday Thursday it will be"
      },
      {
        "start": 5879.04,
        "duration": 6.679,
        "text": "in TR candra and next week it will be a"
      },
      {
        "start": 5883.199,
        "duration": 5.281,
        "text": "lot of kubernetes Monday"
      },
      {
        "start": 5885.719,
        "duration": 5.281,
        "text": "Thursday and Wednesday will be on"
      },
      {
        "start": 5888.48,
        "duration": 6.48,
        "text": "kubernetes pretty exciting stuff with a"
      },
      {
        "start": 5891.0,
        "duration": 5.0,
        "text": "single Elm recipe you will get ton of"
      },
      {
        "start": 5894.96,
        "duration": 4.679,
        "text": "things"
      },
      {
        "start": 5896.0,
        "duration": 5.52,
        "text": "running yep uh so and last announcement"
      },
      {
        "start": 5899.639,
        "duration": 7.6,
        "text": "so it's going to"
      },
      {
        "start": 5901.52,
        "duration": 9.04,
        "text": "be uh Tuesday November 10th at 6:30"
      },
      {
        "start": 5907.239,
        "duration": 6.48,
        "text": "e so for European people it's going to"
      },
      {
        "start": 5910.56,
        "duration": 5.48,
        "text": "be a deep night my God but yeah can you"
      },
      {
        "start": 5913.719,
        "duration": 6.601,
        "text": "copy paste the link this this link on"
      },
      {
        "start": 5916.04,
        "duration": 7.96,
        "text": "the chat absolutely you are very"
      },
      {
        "start": 5920.32,
        "duration": 7.72,
        "text": "right good so"
      },
      {
        "start": 5924.0,
        "duration": 7.719,
        "text": "um that's about uh designing CR silent"
      },
      {
        "start": 5928.04,
        "duration": 6.36,
        "text": "systems based on Apachi Cassandra ideas"
      },
      {
        "start": 5931.719,
        "duration": 4.681,
        "text": "I would say it this way uh so Apachi"
      },
      {
        "start": 5934.4,
        "duration": 5.04,
        "text": "Cassandra is one of the most powerful"
      },
      {
        "start": 5936.4,
        "duration": 6.12,
        "text": "distributed systems which is used by"
      },
      {
        "start": 5939.44,
        "duration": 6.52,
        "text": "nearly all of the companies uh on top of"
      },
      {
        "start": 5942.52,
        "duration": 5.52,
        "text": "a world who works with big data spread"
      },
      {
        "start": 5945.96,
        "duration": 5.6,
        "text": "it over the"
      },
      {
        "start": 5948.04,
        "duration": 7.48,
        "text": "world and I'm analyzing the general"
      },
      {
        "start": 5951.56,
        "duration": 6.96,
        "text": "principles of this um system and what"
      },
      {
        "start": 5955.52,
        "duration": 5.599,
        "text": "makes Apachi Cassandra so Rec silent and"
      },
      {
        "start": 5958.52,
        "duration": 5.24,
        "text": "so powerful in the question of keeping"
      },
      {
        "start": 5961.119,
        "duration": 5.04,
        "text": "data and being disaster tolerant and"
      },
      {
        "start": 5963.76,
        "duration": 4.879,
        "text": "highly available and be able to answer"
      },
      {
        "start": 5966.159,
        "duration": 4.641,
        "text": "your question within milliseconds in any"
      },
      {
        "start": 5968.639,
        "duration": 5.52,
        "text": "moment of the time that's not a"
      },
      {
        "start": 5970.8,
        "duration": 5.399,
        "text": "particular how to that's not a tutorial"
      },
      {
        "start": 5974.159,
        "duration": 5.0,
        "text": "but more discussion of a general"
      },
      {
        "start": 5976.199,
        "duration": 5.52,
        "text": "principles what makes application more"
      },
      {
        "start": 5979.159,
        "duration": 5.361,
        "text": "efficient and able to survive any"
      },
      {
        "start": 5981.719,
        "duration": 4.721,
        "text": "problems and be deployed in every part"
      },
      {
        "start": 5984.52,
        "duration": 9.119,
        "text": "of the world at the same"
      },
      {
        "start": 5986.44,
        "duration": 9.92,
        "text": "time yep good so that was Cedric LAN"
      },
      {
        "start": 5993.639,
        "duration": 8.0,
        "text": "director of developer advocacy at data"
      },
      {
        "start": 5996.36,
        "duration": 8.279,
        "text": "stacks and that was yeah Alex Al"
      },
      {
        "start": 6001.639,
        "duration": 3.0,
        "text": "yeah"
      },
      {
        "start": 6005.92,
        "duration": 5.56,
        "text": "and and we are very happy what you were"
      },
      {
        "start": 6008.88,
        "duration": 6.48,
        "text": "here with us and we can't wait to see"
      },
      {
        "start": 6011.48,
        "duration": 7.679,
        "text": "you on our events now we can meet you"
      },
      {
        "start": 6015.36,
        "duration": 7.12,
        "text": "only virtually hope at some point this"
      },
      {
        "start": 6019.159,
        "duration": 5.401,
        "text": "pandemic will disappear and we will meet"
      },
      {
        "start": 6022.48,
        "duration": 4.239,
        "text": "again all all on all of the events"
      },
      {
        "start": 6024.56,
        "duration": 6.36,
        "text": "around the world so far it's the dream"
      },
      {
        "start": 6026.719,
        "duration": 6.681,
        "text": "only and for today uh we are done and"
      },
      {
        "start": 6030.92,
        "duration": 7.6,
        "text": "happy to see you again on the next event"
      },
      {
        "start": 6033.4,
        "duration": 5.12,
        "text": "thank you see you soon bye"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T21:31:14.731524+00:00"
}