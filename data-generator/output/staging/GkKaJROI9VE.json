{
  "video_id": "GkKaJROI9VE",
  "title": "Distributed Data Show Episode 19: Data Modeling Horror Stories",
  "description": "Patrick McFadin, Luke Tillman and Jeff Carpenter sit around the campfire telling Cassandra data modeling horror stories, dad jokes and the occasional spooky noise.\n\nABOUT DATASTAX ENTERPRISE 5.1\nDataStax Enterprise 5.1, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.1 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax EnterpriseÂ©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-10-31T15:00:01Z",
  "thumbnail": "https://i.ytimg.com/vi/GkKaJROI9VE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "data_modeling",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=GkKaJROI9VE",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by native Stax Academy where we bring you the latest news and interview technical experts to help you succeed in building large-scale distributed systems hello everyone and welcome to a special Halloween edition of the distributed data show we will clearly be doing dad jokes and kind of creepy sound effects for this entire show maniacal laugh so I am joined in the studio here in San Francisco by Patrick McFadden hello Patrick hello Luke it's good to see you your body yes it's good to be here I'm wearing my Bengals shirt in honor of what a horror story I'm sure the Bengals season it was kind of a gag joke I'm also joined in the studio by Jeff carpenter hello Jeff hey how are you I am doing wonderful so we thought it would be fun in honor of Halloween to maybe tell some Cassandra Cassandra horror stories and Cassandra data modelling horror stories something along those lines and I don't know maybe we should kind of throw a little bit of a disclaimer out there first this is not suitable for scared children or DBAs both will be scared out of their way oh my goodness yeah they won't stay in bed they keep coming into your room and waking you up so I was thinking disclaimer along the lines of we are you know we share these kind of things like sometimes these are fun stories to share just not only mistakes that we've seen other people make but also mistakes we personally have made believe it or not we are fallible yes you know constant learners so none of this has meant in any sort of a mean-spirited fashion or anything like that this is like it's kind of actually a really good tool when you can you know we tell people a lot of times this is what you should do you know like this is how you should do it but sometimes it can be instructive to to say hey this is what you shouldn't do you know like this is some common right sort of stuff and how did how exactly did we figure out that you shouldn't do it that way yes usually the case is you don't know just theoretically the bad thing that you can do until you see it yeah and you're like oh that's that's a bad idea yep and experiences that I experienced the teacher of experience is harsh so harsh your story really yes okay so Jeff I think you're gonna start us out tell us tell us a scary campfire Cassandra Horror Story nice well one of the great features of Cassandra that allows you to kind of take advantage of this denormalized design and get a really wide row is the use of collections so I encountered a case where there was one particular let's say consumer of this data model and this was a data model that was bees or pricing information so not understanding how every single hotel is going to price their rooms you know there's a particular group of hotels that created a different price for every possible combination of things day of the week let's say discount levels and so pretty soon if I have a collection what I'm using to store all these rates differentiated by different criteria I have an explosion how many like kind of accommodations of things were there reduction items we're not in the millions it wasn't it wasn't as if that we were like sort of hitting the theoretical limit of the collection size it was more like hey I keep getting these large batch warnings in the log but does this mean I'm actually responsible for that I wrote that the jury yeah yeah I put the warning in their large batches and the unfailing of a batch because and this is just a very common stories and what was for a long time is especially back from Cassandra 1.11 not to is his hey batch seems like a great idea because you're and I think to no fault I did the same thing no fault of anyone is because they worked really good in a relational database because you're in one server a batch works really good in there but man you throw a batch of the distributed system it's a different problem and it will don't just blow up in your face yeah the moral of the story for me on that one was anytime you you have a situation where there's flexibility in terms of different people are going to interpret your data model in different ways and they may decide to kind of throw something in in a way that you didn't expect how are you gonna stay in front of that be able to detect it that's that's a bit of a challenge so I have a similar like this was probably a good segue because you talked about batches and so I have a kind of similar story to that where it's a sort of a bachelor story where and I was working with with some customers and one thing that I've seen and I'm thinking of one incidence in particular we were working on and sort of a time series data model where there was it was sort of the classic time series case where there would be this big batch of records pretty you know like multiple basically multiple records in a single second and you know they might get 60 seconds or cover 120 seconds worth of this time series data kind of streaming into the system and they were kind of investigating using Cassandra and wanted to do a proof of concept and so they wrote just some kind of simple early on code and they they were running this that you know they had test data where they had these you know kind of millions of points that they would get or hundreds of thousands of points that they would get within a single minute or two of data and they were kind of looping over this data and every time that they would loop over this piece of data to put it into Cassandra they were doing and execute with our with our driver and this was execute like the like the synchronous execute method right so so basically you know if you've used now if any of you used our drivers before you'll know that we have synchronous and asynchronous versions in mode and to think in all the languages I'm not for node no it doesn't know it has a synchronous has promised returning and callback callback convinced off so so they were basically doing you know a single single call blocking the thread you know to execute a record at a time and and then would loop take the next data point and stuff it in and whatnot and you know and of course the question was well and this is really slow like why is this like I thought you said cos here was like really good at adjusting data that kind of thing and and so as we're kind of trying to walk through the code and figure out what's good you know kind of what was going on they at the same time sort of discovered over there's batching and most people's reaction you know if you're coming from a relational world is well yeah that's exactly what I should use because I got all this all these data points I've got this big chunk of data why don't you say so before right why didn't you just say we should use batches right and so and so you know now then it was okay loop through the records collect them into batches and we'll make the batch size configurable so we can try and find out you know sort of what the optimum batch size is that you know works well with the cluster and but again execute sync the whole time so we basically do a whole batch execute saying wait so now you're waiting on this huge chunk of records to great over and yeah that felt but you know as you're looking at sort of the metric server on the Cassandra side you can see the Cassandra node because this was only just on it they were only just testing on a single node at this point you'd see the do this like a wave I could do a waveform where all the sudden you know get this huge chunk of work to do and you know and then go down to almost nothing and so finally after some cajoling and whatnot when we started talking about the async api's and and they still wanted to use batches which actually it was okay in this case you know a lot of times we say that the batching is an anti-pattern for loading data in this case because of their data model all of the data like the the batches of data were for a single partition and so this is one where they could actually because all the data that was in the batch was for a single partition they could use unlogged batches which is sort of like the the use case for unlogged batches and and but then we got them to start using the async api and try to get the system and this was really key like you want to get the system to a steady state so you don't have this wave of you know you're just crushing your Cassandra server with batch after you know you kind of want to have a bunch of these in flight at once and figure out okay what's you know how many of these inflate at once can I have going kind of thing but man it took us a while to get there and you know the batch thing like particularly once we made it configurable you know it was like well let's try you know let's try five thousand or ten thousand you know data points in a single batch and then of course your your warning started showing up like what does this mean why is it telling you the batches to large that's the that's the little guideposts it says don't drive off a cliff yeah sounds like some sometimes the bottleneck is your data model and sometimes it's your threading model yeah yeah and I think the takeaway for me would be well really two things so one there is actually like a legit use case for using batches when you've got big chunks of data and and that is unlogged batches when everything's going to a single partition and then also you know you want to especially in your when you're in these scenarios where your bulk loading a bunch of data you want to try and get it to a steady state you don't want to be sending over these just dumping these a big batch wait for that to finish another big batch because if you're gonna maximize throughput you want to have multiple of these in flight at one time so take advantage of those async api's most of the time most of the code at least in my experience that I've ever written is almost always using the ACE and KP is like I haven't really seen a great use case for why you would want to use the synchronous API so oh they think is the best yeah it is the secret sauce yeah you they think you'll be pretty happy and I bet you after that it was Holland wasn't uh it was yeah and you know what the async experience I just want to throw this out there to troll your Java folks a little bit but the async experience is a little bit better depending on what I was about to stand up for synchronous depending on what language you're using you know like that can be that could be a better experience you know so like what would your great language c-sharp actually has really and actually new versions of nodejs also got the async and await keywords which are which make which make writing that imperative style of async code a lot it's a lot better than callback hell is what we used to call it in yeah letting on wha yeah call back that kind of sounds spooky right pretty spooky for Halloween it's not that there's a trick in the treat yes so I was gonna talk about that time that I was helping somebody that made the decision to upload their entire relational database model phone I think was my secret they just took it verbatim changed the type so that it wouldn't blow up when it loaded the data model through it all into Cassandra - the foreign key constraints and anything else indexing just basic data model all the tables which required joins to work because it was a relational data model so their solution was to do all that in the application I'm not but you're not gonna talk I'm not gonna talk about that story no that's that is not gonna happen here this is your way of getting to isn't it yeah always one not playing by the ground is ya wheels breaker go ahead all right fine - mine is actually something that a prompted a lot of discussions and a lot of webinars and a lot of talks about how to do the primary key properly and it was it was pretty innocent use case and I asked it took me a while even kind of notice what was going on but it was this group that was they had a six node cluster so plenty of power and they had around a terabyte of data so not a lot of data yeah but not for six nodes no no but you've got a replication doctor all the maps worked out great Oh that'll you know that should fly you know but they but what had happened was that they had nodes that were just crashing horribly and they they were really frustrated and I was thinking well maybe there's a hardware problem and there's some set up in the operating system I was looking way too low down finally and this is my owning experiences I didn't look at the data model first when I took a peek at the data model I realized oh the way that the data model was structured was that there were only four partition keys first as the report knows when partition keys yeah there's more nodes of partition gift and I mean it's a perfectly logical mistake to make but the way it was just the way that they had done the data model at first it looked fine but then use you when you look at the data that's gonna represent or that's gonna be represented by the data model the village there's only four date for partition keys so they had these massive partitions just getting hyper loaded and I think one of the most like you know it's like 500 gigs or something it was really big so yeah and these are in the days this is like 1.2 days when cql is pretty new and Cassandra's partition sizes were not as good as they are now or will be with with deep stacks of enterprise 6 and that of course was just a huge problem because just burned down their nodes and yeah after we got through the purchase we did some work with the partition keys got the cluster in column set up right it worked wonderfully amazing so that horror story luckily how's a nice little and has at the end so we get to treat at the end right is that so was that the Silver Bullet could have been Halloween joke yeah yeah and showed the the database vampire the mirror look at this exactly oh wait a minute you can't see itself right I'm blowing all the dead badger yeah you're overthinking this yeah yeah yeah picking a partition key is tough like especially you're not used to doing it can be really hard it can be really easy to screw that up like I've screwed it up yeah particularly when dealing with time-series stuff and potentially unbounded yeah yeah like potentially unbounded partitions like yeah it can be really easy that we've all made that mistake yeah well that's and that's like I said it prompted with lots of talks for me I had a blog post the primary keeps the most important thing you need to know about database or Cassandra data modelling yeah because that'll make or break it everything else is I mean let's use collections but that's another problem but partition key is so critical for a lot of their just understanding oh this is what just you meets my data around the cluster dot that's a really good concept to grok oh yeah yeah okay well gentlemen thank you for sharing your stories still scared this has been fun I feel like we could do three more episodes in this not only Halloween came three times a year how the 2018 stay tuned well thank you guys and thank you to everyone who is listening and/or watching we will be back with another terrifying episode of the distributed data show we will see you next time thank you thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on Davis tax Academy and tell us what you think you can also find us on the data stacks Academy YouTube channel or find our podcast on iTunes Google Play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 3.869,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.1,
        "duration": 3.96,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 3.899,
        "duration": 4.261,
        "text": "native Stax Academy where we bring you"
      },
      {
        "start": 6.06,
        "duration": 4.11,
        "text": "the latest news and interview technical"
      },
      {
        "start": 8.16,
        "duration": 5.37,
        "text": "experts to help you succeed in building"
      },
      {
        "start": 10.17,
        "duration": 5.49,
        "text": "large-scale distributed systems hello"
      },
      {
        "start": 13.53,
        "duration": 4.38,
        "text": "everyone and welcome to a special"
      },
      {
        "start": 15.66,
        "duration": 9.15,
        "text": "Halloween edition of the distributed"
      },
      {
        "start": 17.91,
        "duration": 9.359,
        "text": "data show we will clearly be doing dad"
      },
      {
        "start": 24.81,
        "duration": 8.159,
        "text": "jokes and kind of creepy sound effects"
      },
      {
        "start": 27.269,
        "duration": 7.56,
        "text": "for this entire show maniacal laugh so I"
      },
      {
        "start": 32.969,
        "duration": 2.461,
        "text": "am joined in the studio here in San"
      },
      {
        "start": 34.829,
        "duration": 3.091,
        "text": "Francisco"
      },
      {
        "start": 35.43,
        "duration": 5.67,
        "text": "by Patrick McFadden hello Patrick hello"
      },
      {
        "start": 37.92,
        "duration": 4.62,
        "text": "Luke it's good to see you your body yes"
      },
      {
        "start": 41.1,
        "duration": 3.33,
        "text": "it's good to be here I'm wearing my"
      },
      {
        "start": 42.54,
        "duration": 8.01,
        "text": "Bengals shirt in honor of what a horror"
      },
      {
        "start": 44.43,
        "duration": 9.3,
        "text": "story I'm sure the Bengals season it was"
      },
      {
        "start": 50.55,
        "duration": 5.64,
        "text": "kind of a gag joke I'm also joined in"
      },
      {
        "start": 53.73,
        "duration": 6.27,
        "text": "the studio by Jeff carpenter hello Jeff"
      },
      {
        "start": 56.19,
        "duration": 6.66,
        "text": "hey how are you I am doing wonderful so"
      },
      {
        "start": 60.0,
        "duration": 5.46,
        "text": "we thought it would be fun in honor of"
      },
      {
        "start": 62.85,
        "duration": 5.25,
        "text": "Halloween to maybe tell some Cassandra"
      },
      {
        "start": 65.46,
        "duration": 5.07,
        "text": "Cassandra horror stories and Cassandra"
      },
      {
        "start": 68.1,
        "duration": 5.76,
        "text": "data modelling horror stories something"
      },
      {
        "start": 70.53,
        "duration": 4.68,
        "text": "along those lines and I don't know maybe"
      },
      {
        "start": 73.86,
        "duration": 3.99,
        "text": "we should kind of throw a little bit of"
      },
      {
        "start": 75.21,
        "duration": 7.94,
        "text": "a disclaimer out there first this is not"
      },
      {
        "start": 77.85,
        "duration": 8.01,
        "text": "suitable for scared children or DBAs"
      },
      {
        "start": 83.15,
        "duration": 4.75,
        "text": "both will be scared out of their way"
      },
      {
        "start": 85.86,
        "duration": 3.63,
        "text": "oh my goodness yeah they won't stay in"
      },
      {
        "start": 87.9,
        "duration": 4.07,
        "text": "bed they keep coming into your room and"
      },
      {
        "start": 89.49,
        "duration": 2.48,
        "text": "waking you up"
      },
      {
        "start": 92.939,
        "duration": 5.851,
        "text": "so I was thinking disclaimer along the"
      },
      {
        "start": 95.64,
        "duration": 4.71,
        "text": "lines of we are you know we share these"
      },
      {
        "start": 98.79,
        "duration": 3.509,
        "text": "kind of things like sometimes these are"
      },
      {
        "start": 100.35,
        "duration": 3.299,
        "text": "fun stories to share just not only"
      },
      {
        "start": 102.299,
        "duration": 3.151,
        "text": "mistakes that we've seen other people"
      },
      {
        "start": 103.649,
        "duration": 2.97,
        "text": "make but also mistakes we personally"
      },
      {
        "start": 105.45,
        "duration": 5.01,
        "text": "have made believe it or not we are"
      },
      {
        "start": 106.619,
        "duration": 6.601,
        "text": "fallible yes"
      },
      {
        "start": 110.46,
        "duration": 4.26,
        "text": "you know constant learners so none of"
      },
      {
        "start": 113.22,
        "duration": 3.03,
        "text": "this has meant in any sort of a"
      },
      {
        "start": 114.72,
        "duration": 2.939,
        "text": "mean-spirited fashion or anything like"
      },
      {
        "start": 116.25,
        "duration": 3.42,
        "text": "that this is like it's kind of actually"
      },
      {
        "start": 117.659,
        "duration": 3.75,
        "text": "a really good tool when you can you know"
      },
      {
        "start": 119.67,
        "duration": 3.839,
        "text": "we tell people a lot of times this is"
      },
      {
        "start": 121.409,
        "duration": 3.75,
        "text": "what you should do you know like this is"
      },
      {
        "start": 123.509,
        "duration": 3.811,
        "text": "how you should do it but sometimes it"
      },
      {
        "start": 125.159,
        "duration": 3.69,
        "text": "can be instructive to to say hey this is"
      },
      {
        "start": 127.32,
        "duration": 3.63,
        "text": "what you shouldn't do you know like this"
      },
      {
        "start": 128.849,
        "duration": 4.381,
        "text": "is some common right sort of stuff"
      },
      {
        "start": 130.95,
        "duration": 3.57,
        "text": "and how did how exactly did we figure"
      },
      {
        "start": 133.23,
        "duration": 3.99,
        "text": "out that you shouldn't do it that way"
      },
      {
        "start": 134.52,
        "duration": 4.53,
        "text": "yes usually the case is you don't know"
      },
      {
        "start": 137.22,
        "duration": 4.14,
        "text": "just theoretically the bad thing that"
      },
      {
        "start": 139.05,
        "duration": 4.14,
        "text": "you can do until you see it yeah and"
      },
      {
        "start": 141.36,
        "duration": 4.68,
        "text": "you're like oh that's that's a bad idea"
      },
      {
        "start": 143.19,
        "duration": 6.48,
        "text": "yep and experiences that I experienced"
      },
      {
        "start": 146.04,
        "duration": 5.85,
        "text": "the teacher of experience is harsh so"
      },
      {
        "start": 149.67,
        "duration": 4.74,
        "text": "harsh your story really yes"
      },
      {
        "start": 151.89,
        "duration": 6.179,
        "text": "okay so Jeff I think you're gonna start"
      },
      {
        "start": 154.41,
        "duration": 6.389,
        "text": "us out tell us tell us a scary campfire"
      },
      {
        "start": 158.069,
        "duration": 5.131,
        "text": "Cassandra Horror Story nice well one of"
      },
      {
        "start": 160.799,
        "duration": 4.02,
        "text": "the great features of Cassandra that"
      },
      {
        "start": 163.2,
        "duration": 3.84,
        "text": "allows you to kind of take advantage of"
      },
      {
        "start": 164.819,
        "duration": 3.931,
        "text": "this denormalized design and get a"
      },
      {
        "start": 167.04,
        "duration": 4.68,
        "text": "really wide row is the use of"
      },
      {
        "start": 168.75,
        "duration": 6.06,
        "text": "collections so I encountered a case"
      },
      {
        "start": 171.72,
        "duration": 5.489,
        "text": "where there was one particular let's say"
      },
      {
        "start": 174.81,
        "duration": 4.53,
        "text": "consumer of this data model and this was"
      },
      {
        "start": 177.209,
        "duration": 6.301,
        "text": "a data model that was bees or pricing"
      },
      {
        "start": 179.34,
        "duration": 7.05,
        "text": "information so not understanding how"
      },
      {
        "start": 183.51,
        "duration": 5.43,
        "text": "every single hotel is going to price"
      },
      {
        "start": 186.39,
        "duration": 5.099,
        "text": "their rooms you know there's a"
      },
      {
        "start": 188.94,
        "duration": 4.92,
        "text": "particular group of hotels that created"
      },
      {
        "start": 191.489,
        "duration": 4.381,
        "text": "a different price for every possible"
      },
      {
        "start": 193.86,
        "duration": 5.099,
        "text": "combination of things day of the week"
      },
      {
        "start": 195.87,
        "duration": 5.339,
        "text": "let's say discount levels and so pretty"
      },
      {
        "start": 198.959,
        "duration": 3.511,
        "text": "soon if I have a collection what I'm"
      },
      {
        "start": 201.209,
        "duration": 3.421,
        "text": "using to store all these rates"
      },
      {
        "start": 202.47,
        "duration": 4.799,
        "text": "differentiated by different criteria I"
      },
      {
        "start": 204.63,
        "duration": 4.82,
        "text": "have an explosion how many like kind of"
      },
      {
        "start": 207.269,
        "duration": 3.991,
        "text": "accommodations of things were there"
      },
      {
        "start": 209.45,
        "duration": 3.7,
        "text": "reduction items we're not in the"
      },
      {
        "start": 211.26,
        "duration": 2.91,
        "text": "millions it wasn't it wasn't as if that"
      },
      {
        "start": 213.15,
        "duration": 3.0,
        "text": "we were like sort of hitting the"
      },
      {
        "start": 214.17,
        "duration": 4.95,
        "text": "theoretical limit of the collection size"
      },
      {
        "start": 216.15,
        "duration": 5.459,
        "text": "it was more like hey I keep getting"
      },
      {
        "start": 219.12,
        "duration": 5.16,
        "text": "these large batch warnings in the log"
      },
      {
        "start": 221.609,
        "duration": 6.361,
        "text": "but does this mean I'm actually"
      },
      {
        "start": 224.28,
        "duration": 5.549,
        "text": "responsible for that I wrote that the"
      },
      {
        "start": 227.97,
        "duration": 4.56,
        "text": "jury yeah yeah I put the warning in"
      },
      {
        "start": 229.829,
        "duration": 5.13,
        "text": "their large batches and the unfailing of"
      },
      {
        "start": 232.53,
        "duration": 4.5,
        "text": "a batch because and this is just a very"
      },
      {
        "start": 234.959,
        "duration": 3.9,
        "text": "common stories and what was for a long"
      },
      {
        "start": 237.03,
        "duration": 5.88,
        "text": "time is especially back from Cassandra"
      },
      {
        "start": 238.859,
        "duration": 7.021,
        "text": "1.11 not to is his hey batch seems like"
      },
      {
        "start": 242.91,
        "duration": 5.28,
        "text": "a great idea because you're and I think"
      },
      {
        "start": 245.88,
        "duration": 4.169,
        "text": "to no fault I did the same thing no"
      },
      {
        "start": 248.19,
        "duration": 3.74,
        "text": "fault of anyone is because they worked"
      },
      {
        "start": 250.049,
        "duration": 4.8,
        "text": "really good in a relational database"
      },
      {
        "start": 251.93,
        "duration": 4.779,
        "text": "because you're in one server a batch"
      },
      {
        "start": 254.849,
        "duration": 3.271,
        "text": "works really good in there but man you"
      },
      {
        "start": 256.709,
        "duration": 3.941,
        "text": "throw a batch of the distributed system"
      },
      {
        "start": 258.12,
        "duration": 4.69,
        "text": "it's a different problem"
      },
      {
        "start": 260.65,
        "duration": 4.38,
        "text": "and it will don't just blow up in your"
      },
      {
        "start": 262.81,
        "duration": 5.22,
        "text": "face yeah the moral of the story for me"
      },
      {
        "start": 265.03,
        "duration": 5.37,
        "text": "on that one was anytime you you have a"
      },
      {
        "start": 268.03,
        "duration": 4.02,
        "text": "situation where there's flexibility in"
      },
      {
        "start": 270.4,
        "duration": 3.9,
        "text": "terms of different people are going to"
      },
      {
        "start": 272.05,
        "duration": 4.47,
        "text": "interpret your data model in different"
      },
      {
        "start": 274.3,
        "duration": 5.04,
        "text": "ways and they may decide to kind of"
      },
      {
        "start": 276.52,
        "duration": 5.01,
        "text": "throw something in in a way that you"
      },
      {
        "start": 279.34,
        "duration": 3.72,
        "text": "didn't expect how are you gonna stay in"
      },
      {
        "start": 281.53,
        "duration": 5.669,
        "text": "front of that be able to detect it"
      },
      {
        "start": 283.06,
        "duration": 6.03,
        "text": "that's that's a bit of a challenge so I"
      },
      {
        "start": 287.199,
        "duration": 3.451,
        "text": "have a similar like this was probably a"
      },
      {
        "start": 289.09,
        "duration": 3.78,
        "text": "good segue because you talked about"
      },
      {
        "start": 290.65,
        "duration": 4.2,
        "text": "batches and so I have a kind of similar"
      },
      {
        "start": 292.87,
        "duration": 4.71,
        "text": "story to that where it's a sort of a"
      },
      {
        "start": 294.85,
        "duration": 6.42,
        "text": "bachelor story where and I was working"
      },
      {
        "start": 297.58,
        "duration": 5.88,
        "text": "with with some customers and one thing"
      },
      {
        "start": 301.27,
        "duration": 4.11,
        "text": "that I've seen and I'm thinking of one"
      },
      {
        "start": 303.46,
        "duration": 3.63,
        "text": "incidence in particular we were working"
      },
      {
        "start": 305.38,
        "duration": 5.25,
        "text": "on and sort of a time series data model"
      },
      {
        "start": 307.09,
        "duration": 4.68,
        "text": "where there was it was sort of the"
      },
      {
        "start": 310.63,
        "duration": 3.09,
        "text": "classic time series case where there"
      },
      {
        "start": 311.77,
        "duration": 5.91,
        "text": "would be this big batch of records"
      },
      {
        "start": 313.72,
        "duration": 5.669,
        "text": "pretty you know like multiple basically"
      },
      {
        "start": 317.68,
        "duration": 3.63,
        "text": "multiple records in a single second and"
      },
      {
        "start": 319.389,
        "duration": 4.411,
        "text": "you know they might get 60 seconds or"
      },
      {
        "start": 321.31,
        "duration": 3.99,
        "text": "cover 120 seconds worth of this time"
      },
      {
        "start": 323.8,
        "duration": 4.23,
        "text": "series data kind of streaming into the"
      },
      {
        "start": 325.3,
        "duration": 5.79,
        "text": "system and they were kind of"
      },
      {
        "start": 328.03,
        "duration": 4.62,
        "text": "investigating using Cassandra and wanted"
      },
      {
        "start": 331.09,
        "duration": 3.15,
        "text": "to do a proof of concept and so they"
      },
      {
        "start": 332.65,
        "duration": 4.53,
        "text": "wrote just some kind of simple early on"
      },
      {
        "start": 334.24,
        "duration": 4.35,
        "text": "code and they they were running this"
      },
      {
        "start": 337.18,
        "duration": 2.76,
        "text": "that you know they had test data where"
      },
      {
        "start": 338.59,
        "duration": 2.82,
        "text": "they had these you know kind of millions"
      },
      {
        "start": 339.94,
        "duration": 2.789,
        "text": "of points that they would get or"
      },
      {
        "start": 341.41,
        "duration": 4.11,
        "text": "hundreds of thousands of points that"
      },
      {
        "start": 342.729,
        "duration": 5.431,
        "text": "they would get within a single minute or"
      },
      {
        "start": 345.52,
        "duration": 5.07,
        "text": "two of data and they were kind of"
      },
      {
        "start": 348.16,
        "duration": 3.689,
        "text": "looping over this data and every time"
      },
      {
        "start": 350.59,
        "duration": 2.579,
        "text": "that they would loop over this piece of"
      },
      {
        "start": 351.849,
        "duration": 3.391,
        "text": "data to put it into Cassandra they were"
      },
      {
        "start": 353.169,
        "duration": 4.201,
        "text": "doing and execute with our with our"
      },
      {
        "start": 355.24,
        "duration": 4.08,
        "text": "driver and this was execute like the"
      },
      {
        "start": 357.37,
        "duration": 5.64,
        "text": "like the synchronous execute method"
      },
      {
        "start": 359.32,
        "duration": 5.31,
        "text": "right so so basically you know if you've"
      },
      {
        "start": 363.01,
        "duration": 3.21,
        "text": "used now if any of you used our drivers"
      },
      {
        "start": 364.63,
        "duration": 3.509,
        "text": "before you'll know that we have"
      },
      {
        "start": 366.22,
        "duration": 3.33,
        "text": "synchronous and asynchronous versions in"
      },
      {
        "start": 368.139,
        "duration": 5.551,
        "text": "mode and to think in all the languages"
      },
      {
        "start": 369.55,
        "duration": 5.97,
        "text": "I'm not for node no it doesn't know it"
      },
      {
        "start": 373.69,
        "duration": 4.099,
        "text": "has a synchronous has promised returning"
      },
      {
        "start": 375.52,
        "duration": 5.1,
        "text": "and callback callback convinced off so"
      },
      {
        "start": 377.789,
        "duration": 4.841,
        "text": "so they were basically doing you know a"
      },
      {
        "start": 380.62,
        "duration": 3.78,
        "text": "single single call blocking the thread"
      },
      {
        "start": 382.63,
        "duration": 4.15,
        "text": "you know to execute a record at a time"
      },
      {
        "start": 384.4,
        "duration": 4.9,
        "text": "and and then would loop"
      },
      {
        "start": 386.78,
        "duration": 5.25,
        "text": "take the next data point and stuff it in"
      },
      {
        "start": 389.3,
        "duration": 4.77,
        "text": "and whatnot and you know and of course"
      },
      {
        "start": 392.03,
        "duration": 3.6,
        "text": "the question was well and this is really"
      },
      {
        "start": 394.07,
        "duration": 3.03,
        "text": "slow like why is this like I thought you"
      },
      {
        "start": 395.63,
        "duration": 3.21,
        "text": "said cos here was like really good at"
      },
      {
        "start": 397.1,
        "duration": 4.35,
        "text": "adjusting data that kind of thing and"
      },
      {
        "start": 398.84,
        "duration": 3.78,
        "text": "and so as we're kind of trying to walk"
      },
      {
        "start": 401.45,
        "duration": 2.4,
        "text": "through the code and figure out what's"
      },
      {
        "start": 402.62,
        "duration": 3.81,
        "text": "good you know kind of what was going on"
      },
      {
        "start": 403.85,
        "duration": 4.8,
        "text": "they at the same time sort of discovered"
      },
      {
        "start": 406.43,
        "duration": 3.989,
        "text": "over there's batching and most people's"
      },
      {
        "start": 408.65,
        "duration": 4.29,
        "text": "reaction you know if you're coming from"
      },
      {
        "start": 410.419,
        "duration": 4.231,
        "text": "a relational world is well yeah that's"
      },
      {
        "start": 412.94,
        "duration": 3.24,
        "text": "exactly what I should use because I got"
      },
      {
        "start": 414.65,
        "duration": 3.09,
        "text": "all this all these data points I've got"
      },
      {
        "start": 416.18,
        "duration": 2.97,
        "text": "this big chunk of data why don't you say"
      },
      {
        "start": 417.74,
        "duration": 4.5,
        "text": "so before right why didn't you just say"
      },
      {
        "start": 419.15,
        "duration": 5.16,
        "text": "we should use batches right and so and"
      },
      {
        "start": 422.24,
        "duration": 4.02,
        "text": "so you know now then it was okay loop"
      },
      {
        "start": 424.31,
        "duration": 3.27,
        "text": "through the records collect them into"
      },
      {
        "start": 426.26,
        "duration": 2.97,
        "text": "batches and we'll make the batch size"
      },
      {
        "start": 427.58,
        "duration": 2.94,
        "text": "configurable so we can try and find out"
      },
      {
        "start": 429.23,
        "duration": 3.12,
        "text": "you know sort of what the optimum batch"
      },
      {
        "start": 430.52,
        "duration": 6.03,
        "text": "size is that you know works well with"
      },
      {
        "start": 432.35,
        "duration": 6.54,
        "text": "the cluster and but again execute sync"
      },
      {
        "start": 436.55,
        "duration": 4.17,
        "text": "the whole time so we basically do a"
      },
      {
        "start": 438.89,
        "duration": 3.39,
        "text": "whole batch execute saying wait so now"
      },
      {
        "start": 440.72,
        "duration": 3.81,
        "text": "you're waiting on this huge chunk of"
      },
      {
        "start": 442.28,
        "duration": 4.5,
        "text": "records to great over and yeah that felt"
      },
      {
        "start": 444.53,
        "duration": 3.359,
        "text": "but you know as you're looking at sort"
      },
      {
        "start": 446.78,
        "duration": 2.97,
        "text": "of the metric server on the Cassandra"
      },
      {
        "start": 447.889,
        "duration": 3.541,
        "text": "side you can see the Cassandra node"
      },
      {
        "start": 449.75,
        "duration": 2.85,
        "text": "because this was only just on it they"
      },
      {
        "start": 451.43,
        "duration": 3.84,
        "text": "were only just testing on a single node"
      },
      {
        "start": 452.6,
        "duration": 5.31,
        "text": "at this point you'd see the do this like"
      },
      {
        "start": 455.27,
        "duration": 4.53,
        "text": "a wave I could do a waveform where all"
      },
      {
        "start": 457.91,
        "duration": 4.68,
        "text": "the sudden you know get this huge chunk"
      },
      {
        "start": 459.8,
        "duration": 5.76,
        "text": "of work to do and you know and then go"
      },
      {
        "start": 462.59,
        "duration": 6.24,
        "text": "down to almost nothing and so finally"
      },
      {
        "start": 465.56,
        "duration": 5.31,
        "text": "after some cajoling and whatnot when we"
      },
      {
        "start": 468.83,
        "duration": 4.68,
        "text": "started talking about the async api's"
      },
      {
        "start": 470.87,
        "duration": 4.23,
        "text": "and and they still wanted to use batches"
      },
      {
        "start": 473.51,
        "duration": 3.54,
        "text": "which actually it was okay in this case"
      },
      {
        "start": 475.1,
        "duration": 3.48,
        "text": "you know a lot of times we say that the"
      },
      {
        "start": 477.05,
        "duration": 3.39,
        "text": "batching is an anti-pattern for loading"
      },
      {
        "start": 478.58,
        "duration": 4.41,
        "text": "data in this case because of their data"
      },
      {
        "start": 480.44,
        "duration": 3.96,
        "text": "model all of the data like the the"
      },
      {
        "start": 482.99,
        "duration": 4.08,
        "text": "batches of data were for a single"
      },
      {
        "start": 484.4,
        "duration": 5.1,
        "text": "partition and so this is one where they"
      },
      {
        "start": 487.07,
        "duration": 3.599,
        "text": "could actually because all the data that"
      },
      {
        "start": 489.5,
        "duration": 2.37,
        "text": "was in the batch was for a single"
      },
      {
        "start": 490.669,
        "duration": 3.091,
        "text": "partition they could use unlogged"
      },
      {
        "start": 491.87,
        "duration": 5.13,
        "text": "batches which is sort of like the the"
      },
      {
        "start": 493.76,
        "duration": 5.159,
        "text": "use case for unlogged batches and and"
      },
      {
        "start": 497.0,
        "duration": 4.14,
        "text": "but then we got them to start using the"
      },
      {
        "start": 498.919,
        "duration": 3.511,
        "text": "async api and try to get the system and"
      },
      {
        "start": 501.14,
        "duration": 2.88,
        "text": "this was really key like you want to get"
      },
      {
        "start": 502.43,
        "duration": 4.23,
        "text": "the system to a steady state so you"
      },
      {
        "start": 504.02,
        "duration": 4.56,
        "text": "don't have this wave of you know you're"
      },
      {
        "start": 506.66,
        "duration": 3.69,
        "text": "just crushing your Cassandra server with"
      },
      {
        "start": 508.58,
        "duration": 3.57,
        "text": "batch after you know you kind of want to"
      },
      {
        "start": 510.35,
        "duration": 3.39,
        "text": "have a bunch of these in flight at once"
      },
      {
        "start": 512.15,
        "duration": 3.15,
        "text": "and figure out okay what's you know how"
      },
      {
        "start": 513.74,
        "duration": 2.06,
        "text": "many of these inflate at once can I have"
      },
      {
        "start": 515.3,
        "duration": 2.389,
        "text": "going"
      },
      {
        "start": 515.8,
        "duration": 3.539,
        "text": "kind of thing but man it took us a while"
      },
      {
        "start": 517.689,
        "duration": 3.9,
        "text": "to get there and you know"
      },
      {
        "start": 519.339,
        "duration": 4.29,
        "text": "the batch thing like particularly once"
      },
      {
        "start": 521.589,
        "duration": 3.84,
        "text": "we made it configurable you know it was"
      },
      {
        "start": 523.629,
        "duration": 4.05,
        "text": "like well let's try you know let's try"
      },
      {
        "start": 525.429,
        "duration": 3.81,
        "text": "five thousand or ten thousand you know"
      },
      {
        "start": 527.679,
        "duration": 3.81,
        "text": "data points in a single batch and then"
      },
      {
        "start": 529.239,
        "duration": 6.54,
        "text": "of course your your warning started"
      },
      {
        "start": 531.489,
        "duration": 5.671,
        "text": "showing up like what does this mean why"
      },
      {
        "start": 535.779,
        "duration": 4.02,
        "text": "is it telling you the batches to large"
      },
      {
        "start": 537.16,
        "duration": 7.159,
        "text": "that's the that's the little guideposts"
      },
      {
        "start": 539.799,
        "duration": 4.52,
        "text": "it says don't drive off a cliff yeah"
      },
      {
        "start": 544.799,
        "duration": 3.73,
        "text": "sounds like some sometimes the"
      },
      {
        "start": 546.819,
        "duration": 4.2,
        "text": "bottleneck is your data model and"
      },
      {
        "start": 548.529,
        "duration": 4.41,
        "text": "sometimes it's your threading model yeah"
      },
      {
        "start": 551.019,
        "duration": 4.56,
        "text": "yeah and I think the takeaway for me"
      },
      {
        "start": 552.939,
        "duration": 5.01,
        "text": "would be well really two things so one"
      },
      {
        "start": 555.579,
        "duration": 3.66,
        "text": "there is actually like a legit use case"
      },
      {
        "start": 557.949,
        "duration": 3.63,
        "text": "for using batches when you've got big"
      },
      {
        "start": 559.239,
        "duration": 3.63,
        "text": "chunks of data and and that is unlogged"
      },
      {
        "start": 561.579,
        "duration": 3.45,
        "text": "batches when everything's going to a"
      },
      {
        "start": 562.869,
        "duration": 3.601,
        "text": "single partition and then also you know"
      },
      {
        "start": 565.029,
        "duration": 2.28,
        "text": "you want to especially in your when"
      },
      {
        "start": 566.47,
        "duration": 2.549,
        "text": "you're in these scenarios where your"
      },
      {
        "start": 567.309,
        "duration": 2.97,
        "text": "bulk loading a bunch of data you want to"
      },
      {
        "start": 569.019,
        "duration": 2.76,
        "text": "try and get it to a steady state you"
      },
      {
        "start": 570.279,
        "duration": 3.42,
        "text": "don't want to be sending over these just"
      },
      {
        "start": 571.779,
        "duration": 3.9,
        "text": "dumping these a big batch wait for that"
      },
      {
        "start": 573.699,
        "duration": 3.031,
        "text": "to finish another big batch because if"
      },
      {
        "start": 575.679,
        "duration": 2.91,
        "text": "you're gonna maximize throughput you"
      },
      {
        "start": 576.73,
        "duration": 3.63,
        "text": "want to have multiple of these in flight"
      },
      {
        "start": 578.589,
        "duration": 3.84,
        "text": "at one time so take advantage of those"
      },
      {
        "start": 580.36,
        "duration": 3.449,
        "text": "async api's most of the time most of the"
      },
      {
        "start": 582.429,
        "duration": 3.69,
        "text": "code at least in my experience that I've"
      },
      {
        "start": 583.809,
        "duration": 4.291,
        "text": "ever written is almost always using the"
      },
      {
        "start": 586.119,
        "duration": 4.801,
        "text": "ACE and KP is like I haven't really seen"
      },
      {
        "start": 588.1,
        "duration": 5.729,
        "text": "a great use case for why you would want"
      },
      {
        "start": 590.92,
        "duration": 5.909,
        "text": "to use the synchronous API so oh they"
      },
      {
        "start": 593.829,
        "duration": 5.341,
        "text": "think is the best yeah it is the secret"
      },
      {
        "start": 596.829,
        "duration": 4.56,
        "text": "sauce yeah you they think you'll be"
      },
      {
        "start": 599.17,
        "duration": 5.07,
        "text": "pretty happy and I bet you after that it"
      },
      {
        "start": 601.389,
        "duration": 4.771,
        "text": "was Holland wasn't uh it was yeah and"
      },
      {
        "start": 604.24,
        "duration": 2.939,
        "text": "you know what the async experience I"
      },
      {
        "start": 606.16,
        "duration": 2.729,
        "text": "just want to throw this out there to"
      },
      {
        "start": 607.179,
        "duration": 3.09,
        "text": "troll your Java folks a little bit but"
      },
      {
        "start": 608.889,
        "duration": 4.081,
        "text": "the async experience is a little bit"
      },
      {
        "start": 610.269,
        "duration": 6.66,
        "text": "better depending on what I was about to"
      },
      {
        "start": 612.97,
        "duration": 5.549,
        "text": "stand up for synchronous depending on"
      },
      {
        "start": 616.929,
        "duration": 2.82,
        "text": "what language you're using you know like"
      },
      {
        "start": 618.519,
        "duration": 3.87,
        "text": "that can be that could be a better"
      },
      {
        "start": 619.749,
        "duration": 4.92,
        "text": "experience you know so like what would"
      },
      {
        "start": 622.389,
        "duration": 4.711,
        "text": "your great language c-sharp actually has"
      },
      {
        "start": 624.669,
        "duration": 4.14,
        "text": "really and actually new versions of"
      },
      {
        "start": 627.1,
        "duration": 4.169,
        "text": "nodejs also got the async and await"
      },
      {
        "start": 628.809,
        "duration": 5.64,
        "text": "keywords which are which make which make"
      },
      {
        "start": 631.269,
        "duration": 4.65,
        "text": "writing that imperative style of async"
      },
      {
        "start": 634.449,
        "duration": 3.06,
        "text": "code a lot it's a lot better than"
      },
      {
        "start": 635.919,
        "duration": 3.741,
        "text": "callback hell is what we used to call it"
      },
      {
        "start": 637.509,
        "duration": 2.151,
        "text": "in"
      },
      {
        "start": 639.81,
        "duration": 13.5,
        "text": "yeah letting on wha yeah call back that"
      },
      {
        "start": 651.66,
        "duration": 3.119,
        "text": "kind of sounds spooky right pretty"
      },
      {
        "start": 653.31,
        "duration": 5.519,
        "text": "spooky for Halloween it's not that"
      },
      {
        "start": 654.779,
        "duration": 6.691,
        "text": "there's a trick in the treat yes so I"
      },
      {
        "start": 658.829,
        "duration": 4.74,
        "text": "was gonna talk about that time that I"
      },
      {
        "start": 661.47,
        "duration": 4.349,
        "text": "was helping somebody that made the"
      },
      {
        "start": 663.569,
        "duration": 3.93,
        "text": "decision to upload their entire"
      },
      {
        "start": 665.819,
        "duration": 4.13,
        "text": "relational database model phone I think"
      },
      {
        "start": 667.499,
        "duration": 4.56,
        "text": "was my secret they just took it verbatim"
      },
      {
        "start": 669.949,
        "duration": 4.3,
        "text": "changed the type so that it wouldn't"
      },
      {
        "start": 672.059,
        "duration": 6.03,
        "text": "blow up when it loaded the data model"
      },
      {
        "start": 674.249,
        "duration": 5.52,
        "text": "through it all into Cassandra - the"
      },
      {
        "start": 678.089,
        "duration": 2.131,
        "text": "foreign key constraints and anything"
      },
      {
        "start": 679.769,
        "duration": 3.18,
        "text": "else"
      },
      {
        "start": 680.22,
        "duration": 6.119,
        "text": "indexing just basic data model all the"
      },
      {
        "start": 682.949,
        "duration": 4.74,
        "text": "tables which required joins to work"
      },
      {
        "start": 686.339,
        "duration": 5.22,
        "text": "because it was a relational data model"
      },
      {
        "start": 687.689,
        "duration": 6.991,
        "text": "so their solution was to do all that in"
      },
      {
        "start": 691.559,
        "duration": 4.561,
        "text": "the application I'm not but you're not"
      },
      {
        "start": 694.68,
        "duration": 3.509,
        "text": "gonna talk I'm not gonna talk about that"
      },
      {
        "start": 696.12,
        "duration": 4.439,
        "text": "story no that's that is not gonna happen"
      },
      {
        "start": 698.189,
        "duration": 6.991,
        "text": "here this is your way of getting to"
      },
      {
        "start": 700.559,
        "duration": 7.28,
        "text": "isn't it yeah always one not playing by"
      },
      {
        "start": 705.18,
        "duration": 5.959,
        "text": "the ground is ya wheels breaker"
      },
      {
        "start": 707.839,
        "duration": 7.0,
        "text": "go ahead all right fine - mine is"
      },
      {
        "start": 711.139,
        "duration": 5.711,
        "text": "actually something that a prompted a lot"
      },
      {
        "start": 714.839,
        "duration": 5.521,
        "text": "of discussions and a lot of webinars and"
      },
      {
        "start": 716.85,
        "duration": 4.89,
        "text": "a lot of talks about how to do the"
      },
      {
        "start": 720.36,
        "duration": 4.89,
        "text": "primary key properly"
      },
      {
        "start": 721.74,
        "duration": 5.37,
        "text": "and it was it was pretty innocent use"
      },
      {
        "start": 725.25,
        "duration": 4.92,
        "text": "case and I asked it took me a while even"
      },
      {
        "start": 727.11,
        "duration": 4.979,
        "text": "kind of notice what was going on but it"
      },
      {
        "start": 730.17,
        "duration": 4.859,
        "text": "was this group that was they had a six"
      },
      {
        "start": 732.089,
        "duration": 5.641,
        "text": "node cluster so plenty of power and they"
      },
      {
        "start": 735.029,
        "duration": 5.61,
        "text": "had around a terabyte of data so not a"
      },
      {
        "start": 737.73,
        "duration": 4.349,
        "text": "lot of data yeah but not for six nodes"
      },
      {
        "start": 740.639,
        "duration": 3.45,
        "text": "no no but you've got a replication"
      },
      {
        "start": 742.079,
        "duration": 4.38,
        "text": "doctor all the maps worked out great"
      },
      {
        "start": 744.089,
        "duration": 5.581,
        "text": "Oh that'll you know that should fly you"
      },
      {
        "start": 746.459,
        "duration": 4.32,
        "text": "know but they but what had happened was"
      },
      {
        "start": 749.67,
        "duration": 3.87,
        "text": "that they had nodes that were just"
      },
      {
        "start": 750.779,
        "duration": 4.261,
        "text": "crashing horribly and they they were"
      },
      {
        "start": 753.54,
        "duration": 2.76,
        "text": "really frustrated and I was thinking"
      },
      {
        "start": 755.04,
        "duration": 2.729,
        "text": "well maybe there's a hardware problem"
      },
      {
        "start": 756.3,
        "duration": 1.829,
        "text": "and there's some set up in the operating"
      },
      {
        "start": 757.769,
        "duration": 2.441,
        "text": "system"
      },
      {
        "start": 758.129,
        "duration": 4.061,
        "text": "I was looking way too low down"
      },
      {
        "start": 760.21,
        "duration": 3.629,
        "text": "finally and this is my owning"
      },
      {
        "start": 762.19,
        "duration": 4.38,
        "text": "experiences I didn't look at the data"
      },
      {
        "start": 763.839,
        "duration": 5.31,
        "text": "model first when I took a peek at the"
      },
      {
        "start": 766.57,
        "duration": 4.86,
        "text": "data model I realized oh the way that"
      },
      {
        "start": 769.149,
        "duration": 5.301,
        "text": "the data model was structured was that"
      },
      {
        "start": 771.43,
        "duration": 7.08,
        "text": "there were only four partition keys"
      },
      {
        "start": 774.45,
        "duration": 5.35,
        "text": "first as the report knows when partition"
      },
      {
        "start": 778.51,
        "duration": 3.329,
        "text": "keys yeah there's more nodes of"
      },
      {
        "start": 779.8,
        "duration": 4.05,
        "text": "partition gift and I mean it's a"
      },
      {
        "start": 781.839,
        "duration": 3.961,
        "text": "perfectly logical mistake to make but"
      },
      {
        "start": 783.85,
        "duration": 4.26,
        "text": "the way it was just the way that they"
      },
      {
        "start": 785.8,
        "duration": 4.289,
        "text": "had done the data model at first it"
      },
      {
        "start": 788.11,
        "duration": 3.81,
        "text": "looked fine but then use you when you"
      },
      {
        "start": 790.089,
        "duration": 3.931,
        "text": "look at the data that's gonna represent"
      },
      {
        "start": 791.92,
        "duration": 3.75,
        "text": "or that's gonna be represented by the"
      },
      {
        "start": 794.02,
        "duration": 4.23,
        "text": "data model the village there's only four"
      },
      {
        "start": 795.67,
        "duration": 4.979,
        "text": "date for partition keys so they had"
      },
      {
        "start": 798.25,
        "duration": 4.77,
        "text": "these massive partitions just getting"
      },
      {
        "start": 800.649,
        "duration": 4.56,
        "text": "hyper loaded and I think one of the most"
      },
      {
        "start": 803.02,
        "duration": 4.95,
        "text": "like you know it's like 500 gigs or"
      },
      {
        "start": 805.209,
        "duration": 4.5,
        "text": "something it was really big so yeah and"
      },
      {
        "start": 807.97,
        "duration": 5.21,
        "text": "these are in the days this is like 1.2"
      },
      {
        "start": 809.709,
        "duration": 6.841,
        "text": "days when cql is pretty new and"
      },
      {
        "start": 813.18,
        "duration": 5.32,
        "text": "Cassandra's partition sizes were not as"
      },
      {
        "start": 816.55,
        "duration": 4.43,
        "text": "good as they are now or will be with"
      },
      {
        "start": 818.5,
        "duration": 5.43,
        "text": "with deep stacks of enterprise 6 and"
      },
      {
        "start": 820.98,
        "duration": 5.22,
        "text": "that of course was just a huge problem"
      },
      {
        "start": 823.93,
        "duration": 5.46,
        "text": "because just burned down their nodes and"
      },
      {
        "start": 826.2,
        "duration": 5.2,
        "text": "yeah after we got through the purchase"
      },
      {
        "start": 829.39,
        "duration": 3.6,
        "text": "we did some work with the partition keys"
      },
      {
        "start": 831.4,
        "duration": 4.83,
        "text": "got the cluster in column set up right"
      },
      {
        "start": 832.99,
        "duration": 3.93,
        "text": "it worked wonderfully amazing so that"
      },
      {
        "start": 836.23,
        "duration": 3.6,
        "text": "horror story"
      },
      {
        "start": 836.92,
        "duration": 5.31,
        "text": "luckily how's a nice little and has at"
      },
      {
        "start": 839.83,
        "duration": 4.199,
        "text": "the end so we get to treat at the end"
      },
      {
        "start": 842.23,
        "duration": 5.13,
        "text": "right is that so was that the Silver"
      },
      {
        "start": 844.029,
        "duration": 6.18,
        "text": "Bullet could have been Halloween joke"
      },
      {
        "start": 847.36,
        "duration": 5.4,
        "text": "yeah yeah and showed the the database"
      },
      {
        "start": 850.209,
        "duration": 4.111,
        "text": "vampire the mirror look at this exactly"
      },
      {
        "start": 852.76,
        "duration": 3.769,
        "text": "oh wait a minute you can't see itself"
      },
      {
        "start": 854.32,
        "duration": 4.35,
        "text": "right I'm blowing all the dead badger"
      },
      {
        "start": 856.529,
        "duration": 3.791,
        "text": "yeah you're overthinking this"
      },
      {
        "start": 858.67,
        "duration": 3.21,
        "text": "yeah yeah yeah picking a partition key"
      },
      {
        "start": 860.32,
        "duration": 2.91,
        "text": "is tough like especially you're not used"
      },
      {
        "start": 861.88,
        "duration": 2.579,
        "text": "to doing it can be really hard it can be"
      },
      {
        "start": 863.23,
        "duration": 2.729,
        "text": "really easy to screw that up like I've"
      },
      {
        "start": 864.459,
        "duration": 2.731,
        "text": "screwed it up yeah particularly when"
      },
      {
        "start": 865.959,
        "duration": 3.241,
        "text": "dealing with time-series stuff and"
      },
      {
        "start": 867.19,
        "duration": 4.23,
        "text": "potentially unbounded yeah yeah like"
      },
      {
        "start": 869.2,
        "duration": 4.23,
        "text": "potentially unbounded partitions like"
      },
      {
        "start": 871.42,
        "duration": 3.27,
        "text": "yeah it can be really easy that we've"
      },
      {
        "start": 873.43,
        "duration": 3.149,
        "text": "all made that mistake"
      },
      {
        "start": 874.69,
        "duration": 3.72,
        "text": "yeah well that's and that's like I said"
      },
      {
        "start": 876.579,
        "duration": 3.721,
        "text": "it prompted with lots of talks for me I"
      },
      {
        "start": 878.41,
        "duration": 3.03,
        "text": "had a blog post the primary keeps the"
      },
      {
        "start": 880.3,
        "duration": 2.849,
        "text": "most important thing you need to know"
      },
      {
        "start": 881.44,
        "duration": 2.58,
        "text": "about database or Cassandra data"
      },
      {
        "start": 883.149,
        "duration": 2.551,
        "text": "modelling yeah"
      },
      {
        "start": 884.02,
        "duration": 4.319,
        "text": "because that'll make or break it"
      },
      {
        "start": 885.7,
        "duration": 4.41,
        "text": "everything else is I mean let's use"
      },
      {
        "start": 888.339,
        "duration": 5.071,
        "text": "collections but that's another problem"
      },
      {
        "start": 890.11,
        "duration": 4.829,
        "text": "but partition key is so critical for a"
      },
      {
        "start": 893.41,
        "duration": 3.06,
        "text": "lot of their just understanding oh this"
      },
      {
        "start": 894.939,
        "duration": 4.681,
        "text": "is what just you meets my data around"
      },
      {
        "start": 896.47,
        "duration": 7.859,
        "text": "the cluster dot that's a really good"
      },
      {
        "start": 899.62,
        "duration": 6.509,
        "text": "concept to grok oh yeah yeah okay well"
      },
      {
        "start": 904.329,
        "duration": 4.291,
        "text": "gentlemen thank you for sharing your"
      },
      {
        "start": 906.129,
        "duration": 3.51,
        "text": "stories still scared this has been fun I"
      },
      {
        "start": 908.62,
        "duration": 4.319,
        "text": "feel like we could do three more"
      },
      {
        "start": 909.639,
        "duration": 5.67,
        "text": "episodes in this not only Halloween came"
      },
      {
        "start": 912.939,
        "duration": 4.161,
        "text": "three times a year how the 2018 stay"
      },
      {
        "start": 915.309,
        "duration": 4.801,
        "text": "tuned"
      },
      {
        "start": 917.1,
        "duration": 5.26,
        "text": "well thank you guys and thank you to"
      },
      {
        "start": 920.11,
        "duration": 4.32,
        "text": "everyone who is listening and/or"
      },
      {
        "start": 922.36,
        "duration": 5.459,
        "text": "watching we will be back with another"
      },
      {
        "start": 924.43,
        "duration": 7.889,
        "text": "terrifying episode of the distributed"
      },
      {
        "start": 927.819,
        "duration": 7.77,
        "text": "data show we will see you next time"
      },
      {
        "start": 932.319,
        "duration": 5.52,
        "text": "thank you thank you for joining us again"
      },
      {
        "start": 935.589,
        "duration": 3.961,
        "text": "for the distributed data show we love"
      },
      {
        "start": 937.839,
        "duration": 3.72,
        "text": "your feedback so go to the distributed"
      },
      {
        "start": 939.55,
        "duration": 4.11,
        "text": "data show page on Davis tax Academy and"
      },
      {
        "start": 941.559,
        "duration": 3.601,
        "text": "tell us what you think you can also find"
      },
      {
        "start": 943.66,
        "duration": 4.38,
        "text": "us on the data stacks Academy YouTube"
      },
      {
        "start": 945.16,
        "duration": 4.89,
        "text": "channel or find our podcast on iTunes"
      },
      {
        "start": 948.04,
        "duration": 4.5,
        "text": "Google Play or wherever you get great"
      },
      {
        "start": 950.05,
        "duration": 3.93,
        "text": "podcast while you're there make sure and"
      },
      {
        "start": 952.54,
        "duration": 2.57,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 953.98,
        "duration": 4.25,
        "text": "episode"
      },
      {
        "start": 955.11,
        "duration": 3.12,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:09:37.384529+00:00"
}