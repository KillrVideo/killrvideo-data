{
  "video_id": "J68OeDJNgbo",
  "title": "DS320.10 Connecting Spark: Reading Data From Cassandra | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.10 Connecting Spark: Reading Data From Cassandra\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:26:38Z",
  "thumbnail": "https://i.ytimg.com/vi/J68OeDJNgbo/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=J68OeDJNgbo",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] now that we've got a feel for how rdds work it would be a good idea to explore the integration between cassandra and spark what we're going to do is we're going to look at a particular table in our killer video database remember killer video is our fictional video sharing site and it's got a little bit of a special data model for movies here we have a table called movies by actor let's look quickly at the schema it's got a column called actor in fact if you go to the second to the last line of that create table statement you'll see that actor is the partition key that's that first column in the primary key there following that we've got release year that's an integer and movie id that's a uuid those are both clustering keys so together actor release here and movie id uniquely define a movie by actor and then we've got title which is a string genre which is a set of strings and rating which is a float so you can see all that in the schema it's a good idea to get this in your head because this is the table we're going to be playing with as we look at how cassandra and spark work together the essence of that integration is the cassandra row object we're going to explore a few different things we can do with cassandra row we'll start very simple and then add a little bit of complexity to it our first challenge here is to get information from this table that has the five most recent films released after 2010 that had johnny depp as an actor once we have that we're only going to be interested in displaying the movie title and the release here and they should be displayed in descending order of release here now if you know your cassandra basics you know this would be easy enough to express with the cassandra query language however our goal is to express the same thing through the spark cassandra api so that the data becomes available in spark as an rdd to be processed in whatever further analysis we might dream up and the tools we get on the table here will be extensible to other kinds of analytics problems that maybe are a little bit more sophisticated than this but we're going to start with a simple example since all this stuff is new let me show you just a few api methods in order to meet the challenge that i've laid out we need to know a few things about how to interact with cassandra we're going to look at one method on the spark context object that lets us read data out of cassandra and then a few methods that let us play around with that a little bit the cassandra table method which we call on the spark context we pass it a key space and a table and that's going to return an rdd that contains all of the rows of that table and if we just call that method nakedly just as cassandra table that will literally return all of those rows and give them back us records in an rdd might be a little heavyweight so we've got options we can chain method calls it's a fluent api so we can call on the cassandra table method right after that we can call select and select certain columns to return we can call fortunately the where method which is going to be very helpful look at some examples of that but that lets us essentially give a where clause in this query that we're building up we can also set ordering and limit in ways that are fairly predictable let's take one more look at that and see how these pieces map together here on the right you'll see a cql query select columns from key space table where condition order by limit and so forth and on the left you'll see the components of the spark api that correspond to those now you'll notice the order in which we express those things in cql the grammar of cql the things go in a certain order you start with select well in the spark api we're going to start with calling cassandra table and then chain the select call on top of that so the order here that i'm showing you is sort of privileged by cql order but you can see the mapping of api calls onto cql it's really pretty straightforward and if you know cql which you probably do it's a pretty easy api to pick up and here's a solution to that challenge remember i said we wanted five movies released since 2010 with johnny depp in them let's take a look at the code how we might do that first we call the cassandra table method on the spark context we say we want to query the movies by actor table in the killer video key space we want to select only title and release here and then on the third line where actor is johnny depp and release year is greater than 2010 and that's all going to take place at the cassandra level there that's all getting pushed into the cql query so cassandra gets to do effectively the filtering the limiting of that data before it comes into spark then we'll tweak the sort order we'll set a limit we'll collect them which is actually kicking off that computation and bringing those records back into the driver program and iterating over them with print lines so printing the records out and if you look on the bottom of the slide you'll see that those cassandra row objects have a fairly polite conversion into string format they'll show the column names and the column values that they contain which makes them pretty easy to debug in this simplistic way here's another way we could do this now it's so obvious that i actually want to show it to you and point out that this is not how we ought to do it there are a few things that come up as we walk through this spark api that seem like they might be correct and might seem easy to do and i want to say explicitly let's not do those so take a look at the slide here we just did a naive query of movies by actor give them all to me now there could be potentially tens of thousands of movies in there by actor and if we expanded that in the world of killer video to be all of the videos that were uploaded wow there could be billions so we don't want to do that that naive query brings back all of those records and then uses a filter transformation which if you went through the rdd section you know how to do to limit the the data in that set that creates a new rdd that has the correct filtering then does the mapping then does the sorting and the taking and so forth much better to push as much of that into cassandra as possible let's just get the data we want into spark and then work on it in spark if it's efficient to do the limiting in cassandra we definitely want to now spark exists because sometimes it's not efficient to do that filtering in cassandra and you do need to bring a big data set into an rdd so it's not as if that's some kind of comprehensive anti-pattern but it's something you should avoid if you can you",
    "segments": [
      {
        "start": 0.09,
        "duration": 8.23,
        "text": "[Music]"
      },
      {
        "start": 6.72,
        "duration": 3.2,
        "text": "now that we've got a feel for how rdds"
      },
      {
        "start": 8.32,
        "duration": 3.279,
        "text": "work it would be a good idea to explore"
      },
      {
        "start": 9.92,
        "duration": 2.96,
        "text": "the integration between cassandra and"
      },
      {
        "start": 11.599,
        "duration": 2.801,
        "text": "spark what we're going to do is we're"
      },
      {
        "start": 12.88,
        "duration": 3.44,
        "text": "going to look at a particular table"
      },
      {
        "start": 14.4,
        "duration": 4.0,
        "text": "in our killer video database remember"
      },
      {
        "start": 16.32,
        "duration": 2.879,
        "text": "killer video is our fictional video"
      },
      {
        "start": 18.4,
        "duration": 2.16,
        "text": "sharing site"
      },
      {
        "start": 19.199,
        "duration": 3.041,
        "text": "and it's got a little bit of a special"
      },
      {
        "start": 20.56,
        "duration": 3.12,
        "text": "data model for movies here we have a"
      },
      {
        "start": 22.24,
        "duration": 3.76,
        "text": "table called movies by"
      },
      {
        "start": 23.68,
        "duration": 3.919,
        "text": "actor let's look quickly at the schema"
      },
      {
        "start": 26.0,
        "duration": 3.039,
        "text": "it's got a column called actor in fact"
      },
      {
        "start": 27.599,
        "duration": 2.801,
        "text": "if you go to the second to the last line"
      },
      {
        "start": 29.039,
        "duration": 3.281,
        "text": "of that create table statement"
      },
      {
        "start": 30.4,
        "duration": 3.36,
        "text": "you'll see that actor is the partition"
      },
      {
        "start": 32.32,
        "duration": 3.28,
        "text": "key that's that first"
      },
      {
        "start": 33.76,
        "duration": 3.2,
        "text": "column in the primary key there"
      },
      {
        "start": 35.6,
        "duration": 3.76,
        "text": "following that we've got"
      },
      {
        "start": 36.96,
        "duration": 3.759,
        "text": "release year that's an integer and movie"
      },
      {
        "start": 39.36,
        "duration": 3.28,
        "text": "id that's a uuid"
      },
      {
        "start": 40.719,
        "duration": 4.16,
        "text": "those are both clustering keys so"
      },
      {
        "start": 42.64,
        "duration": 5.12,
        "text": "together actor release here and movie id"
      },
      {
        "start": 44.879,
        "duration": 4.961,
        "text": "uniquely define a movie by actor and"
      },
      {
        "start": 47.76,
        "duration": 4.08,
        "text": "then we've got title which is a string"
      },
      {
        "start": 49.84,
        "duration": 3.84,
        "text": "genre which is a set of strings and"
      },
      {
        "start": 51.84,
        "duration": 3.6,
        "text": "rating which is a float"
      },
      {
        "start": 53.68,
        "duration": 2.879,
        "text": "so you can see all that in the schema"
      },
      {
        "start": 55.44,
        "duration": 2.16,
        "text": "it's a good idea to get this in your"
      },
      {
        "start": 56.559,
        "duration": 2.081,
        "text": "head because this is the table we're"
      },
      {
        "start": 57.6,
        "duration": 3.68,
        "text": "going to be playing with"
      },
      {
        "start": 58.64,
        "duration": 3.84,
        "text": "as we look at how cassandra and spark"
      },
      {
        "start": 61.28,
        "duration": 3.599,
        "text": "work together"
      },
      {
        "start": 62.48,
        "duration": 3.52,
        "text": "the essence of that integration is the"
      },
      {
        "start": 64.879,
        "duration": 2.641,
        "text": "cassandra row"
      },
      {
        "start": 66.0,
        "duration": 2.32,
        "text": "object we're going to explore a few"
      },
      {
        "start": 67.52,
        "duration": 2.639,
        "text": "different things we can do with"
      },
      {
        "start": 68.32,
        "duration": 3.44,
        "text": "cassandra row we'll start very simple"
      },
      {
        "start": 70.159,
        "duration": 4.161,
        "text": "and then add a little bit of complexity"
      },
      {
        "start": 71.76,
        "duration": 5.6,
        "text": "to it our first challenge here is to get"
      },
      {
        "start": 74.32,
        "duration": 5.68,
        "text": "information from this table that has the"
      },
      {
        "start": 77.36,
        "duration": 3.52,
        "text": "five most recent films released after"
      },
      {
        "start": 80.0,
        "duration": 3.2,
        "text": "2010"
      },
      {
        "start": 80.88,
        "duration": 3.599,
        "text": "that had johnny depp as an actor once we"
      },
      {
        "start": 83.2,
        "duration": 2.8,
        "text": "have that we're only going to be"
      },
      {
        "start": 84.479,
        "duration": 3.201,
        "text": "interested in displaying the movie title"
      },
      {
        "start": 86.0,
        "duration": 3.68,
        "text": "and the release here and they should be"
      },
      {
        "start": 87.68,
        "duration": 2.72,
        "text": "displayed in descending order of release"
      },
      {
        "start": 89.68,
        "duration": 2.32,
        "text": "here"
      },
      {
        "start": 90.4,
        "duration": 3.12,
        "text": "now if you know your cassandra basics"
      },
      {
        "start": 92.0,
        "duration": 3.119,
        "text": "you know this would be easy enough to"
      },
      {
        "start": 93.52,
        "duration": 2.16,
        "text": "express with the cassandra query"
      },
      {
        "start": 95.119,
        "duration": 2.801,
        "text": "language"
      },
      {
        "start": 95.68,
        "duration": 3.84,
        "text": "however our goal is to express the same"
      },
      {
        "start": 97.92,
        "duration": 3.92,
        "text": "thing through the spark cassandra"
      },
      {
        "start": 99.52,
        "duration": 3.04,
        "text": "api so that the data becomes available"
      },
      {
        "start": 101.84,
        "duration": 3.44,
        "text": "in spark"
      },
      {
        "start": 102.56,
        "duration": 4.4,
        "text": "as an rdd to be processed in whatever"
      },
      {
        "start": 105.28,
        "duration": 3.36,
        "text": "further analysis we might dream up"
      },
      {
        "start": 106.96,
        "duration": 3.28,
        "text": "and the tools we get on the table here"
      },
      {
        "start": 108.64,
        "duration": 3.2,
        "text": "will be extensible to"
      },
      {
        "start": 110.24,
        "duration": 2.8,
        "text": "other kinds of analytics problems that"
      },
      {
        "start": 111.84,
        "duration": 2.4,
        "text": "maybe are a little bit more"
      },
      {
        "start": 113.04,
        "duration": 2.8,
        "text": "sophisticated than this but we're going"
      },
      {
        "start": 114.24,
        "duration": 2.559,
        "text": "to start with a simple example since all"
      },
      {
        "start": 115.84,
        "duration": 3.52,
        "text": "this stuff is new"
      },
      {
        "start": 116.799,
        "duration": 4.32,
        "text": "let me show you just a few api methods"
      },
      {
        "start": 119.36,
        "duration": 2.32,
        "text": "in order to meet the challenge that i've"
      },
      {
        "start": 121.119,
        "duration": 2.721,
        "text": "laid out"
      },
      {
        "start": 121.68,
        "duration": 3.119,
        "text": "we need to know a few things about how"
      },
      {
        "start": 123.84,
        "duration": 2.239,
        "text": "to interact"
      },
      {
        "start": 124.799,
        "duration": 3.361,
        "text": "with cassandra we're going to look at"
      },
      {
        "start": 126.079,
        "duration": 3.921,
        "text": "one method on the spark context object"
      },
      {
        "start": 128.16,
        "duration": 3.2,
        "text": "that lets us read data out of cassandra"
      },
      {
        "start": 130.0,
        "duration": 2.4,
        "text": "and then a few methods that let us play"
      },
      {
        "start": 131.36,
        "duration": 3.44,
        "text": "around with that a little bit"
      },
      {
        "start": 132.4,
        "duration": 4.24,
        "text": "the cassandra table method which we call"
      },
      {
        "start": 134.8,
        "duration": 2.4,
        "text": "on the spark context we pass it a key"
      },
      {
        "start": 136.64,
        "duration": 2.959,
        "text": "space"
      },
      {
        "start": 137.2,
        "duration": 4.32,
        "text": "and a table and that's going to return"
      },
      {
        "start": 139.599,
        "duration": 3.761,
        "text": "an rdd that contains"
      },
      {
        "start": 141.52,
        "duration": 3.439,
        "text": "all of the rows of that table and if we"
      },
      {
        "start": 143.36,
        "duration": 2.64,
        "text": "just call that method nakedly just as"
      },
      {
        "start": 144.959,
        "duration": 3.121,
        "text": "cassandra table"
      },
      {
        "start": 146.0,
        "duration": 3.92,
        "text": "that will literally return all of those"
      },
      {
        "start": 148.08,
        "duration": 3.92,
        "text": "rows and give them back us records"
      },
      {
        "start": 149.92,
        "duration": 3.84,
        "text": "in an rdd might be a little heavyweight"
      },
      {
        "start": 152.0,
        "duration": 3.84,
        "text": "so we've got options"
      },
      {
        "start": 153.76,
        "duration": 3.04,
        "text": "we can chain method calls it's a fluent"
      },
      {
        "start": 155.84,
        "duration": 2.8,
        "text": "api so"
      },
      {
        "start": 156.8,
        "duration": 3.28,
        "text": "we can call on the cassandra table"
      },
      {
        "start": 158.64,
        "duration": 3.84,
        "text": "method right after that"
      },
      {
        "start": 160.08,
        "duration": 3.519,
        "text": "we can call select and select certain"
      },
      {
        "start": 162.48,
        "duration": 4.16,
        "text": "columns to return"
      },
      {
        "start": 163.599,
        "duration": 4.401,
        "text": "we can call fortunately the where method"
      },
      {
        "start": 166.64,
        "duration": 2.64,
        "text": "which is going to be very helpful look"
      },
      {
        "start": 168.0,
        "duration": 2.16,
        "text": "at some examples of that but that lets"
      },
      {
        "start": 169.28,
        "duration": 2.64,
        "text": "us essentially give"
      },
      {
        "start": 170.16,
        "duration": 4.079,
        "text": "a where clause in this query that we're"
      },
      {
        "start": 171.92,
        "duration": 4.16,
        "text": "building up we can also set ordering"
      },
      {
        "start": 174.239,
        "duration": 3.761,
        "text": "and limit in ways that are fairly"
      },
      {
        "start": 176.08,
        "duration": 3.519,
        "text": "predictable let's take one more"
      },
      {
        "start": 178.0,
        "duration": 3.44,
        "text": "look at that and see how these pieces"
      },
      {
        "start": 179.599,
        "duration": 4.881,
        "text": "map together here on the right"
      },
      {
        "start": 181.44,
        "duration": 4.64,
        "text": "you'll see a cql query select columns"
      },
      {
        "start": 184.48,
        "duration": 3.2,
        "text": "from key space table where condition"
      },
      {
        "start": 186.08,
        "duration": 3.68,
        "text": "order by limit and so forth"
      },
      {
        "start": 187.68,
        "duration": 4.08,
        "text": "and on the left you'll see the"
      },
      {
        "start": 189.76,
        "duration": 3.04,
        "text": "components of the spark api that"
      },
      {
        "start": 191.76,
        "duration": 3.04,
        "text": "correspond to those"
      },
      {
        "start": 192.8,
        "duration": 4.0,
        "text": "now you'll notice the order in which we"
      },
      {
        "start": 194.8,
        "duration": 2.799,
        "text": "express those things in cql the grammar"
      },
      {
        "start": 196.8,
        "duration": 2.159,
        "text": "of cql"
      },
      {
        "start": 197.599,
        "duration": 3.36,
        "text": "the things go in a certain order you"
      },
      {
        "start": 198.959,
        "duration": 3.841,
        "text": "start with select well in the"
      },
      {
        "start": 200.959,
        "duration": 3.36,
        "text": "spark api we're going to start with"
      },
      {
        "start": 202.8,
        "duration": 3.999,
        "text": "calling cassandra table"
      },
      {
        "start": 204.319,
        "duration": 3.92,
        "text": "and then chain the select call on top of"
      },
      {
        "start": 206.799,
        "duration": 1.761,
        "text": "that so the order here that i'm showing"
      },
      {
        "start": 208.239,
        "duration": 2.881,
        "text": "you"
      },
      {
        "start": 208.56,
        "duration": 4.399,
        "text": "is sort of privileged by cql order but"
      },
      {
        "start": 211.12,
        "duration": 3.119,
        "text": "you can see the mapping of api calls"
      },
      {
        "start": 212.959,
        "duration": 3.441,
        "text": "onto cql it's really pretty"
      },
      {
        "start": 214.239,
        "duration": 4.241,
        "text": "straightforward and if you know cql"
      },
      {
        "start": 216.4,
        "duration": 3.28,
        "text": "which you probably do it's a pretty easy"
      },
      {
        "start": 218.48,
        "duration": 2.8,
        "text": "api to pick up"
      },
      {
        "start": 219.68,
        "duration": 3.68,
        "text": "and here's a solution to that challenge"
      },
      {
        "start": 221.28,
        "duration": 5.2,
        "text": "remember i said we wanted five"
      },
      {
        "start": 223.36,
        "duration": 4.64,
        "text": "movies released since 2010 with johnny"
      },
      {
        "start": 226.48,
        "duration": 3.039,
        "text": "depp in them let's take a look at the"
      },
      {
        "start": 228.0,
        "duration": 4.159,
        "text": "code how we might do that"
      },
      {
        "start": 229.519,
        "duration": 4.161,
        "text": "first we call the cassandra table method"
      },
      {
        "start": 232.159,
        "duration": 3.44,
        "text": "on the spark context"
      },
      {
        "start": 233.68,
        "duration": 3.44,
        "text": "we say we want to query the movies by"
      },
      {
        "start": 235.599,
        "duration": 2.161,
        "text": "actor table in the killer video key"
      },
      {
        "start": 237.12,
        "duration": 2.64,
        "text": "space"
      },
      {
        "start": 237.76,
        "duration": 3.119,
        "text": "we want to select only title and release"
      },
      {
        "start": 239.76,
        "duration": 2.72,
        "text": "here"
      },
      {
        "start": 240.879,
        "duration": 3.041,
        "text": "and then on the third line where actor"
      },
      {
        "start": 242.48,
        "duration": 2.64,
        "text": "is johnny depp and release year is"
      },
      {
        "start": 243.92,
        "duration": 2.48,
        "text": "greater than 2010"
      },
      {
        "start": 245.12,
        "duration": 2.56,
        "text": "and that's all going to take place at"
      },
      {
        "start": 246.4,
        "duration": 3.119,
        "text": "the cassandra level there that's all"
      },
      {
        "start": 247.68,
        "duration": 4.16,
        "text": "getting pushed into the cql query"
      },
      {
        "start": 249.519,
        "duration": 4.321,
        "text": "so cassandra gets to do effectively the"
      },
      {
        "start": 251.84,
        "duration": 3.84,
        "text": "filtering the limiting of that data"
      },
      {
        "start": 253.84,
        "duration": 4.32,
        "text": "before it comes into spark"
      },
      {
        "start": 255.68,
        "duration": 3.279,
        "text": "then we'll tweak the sort order we'll"
      },
      {
        "start": 258.16,
        "duration": 2.72,
        "text": "set a limit"
      },
      {
        "start": 258.959,
        "duration": 3.601,
        "text": "we'll collect them which is actually"
      },
      {
        "start": 260.88,
        "duration": 4.56,
        "text": "kicking off that computation"
      },
      {
        "start": 262.56,
        "duration": 4.0,
        "text": "and bringing those records back into the"
      },
      {
        "start": 265.44,
        "duration": 3.52,
        "text": "driver program"
      },
      {
        "start": 266.56,
        "duration": 4.079,
        "text": "and iterating over them with print lines"
      },
      {
        "start": 268.96,
        "duration": 2.88,
        "text": "so printing the records out"
      },
      {
        "start": 270.639,
        "duration": 3.681,
        "text": "and if you look on the bottom of the"
      },
      {
        "start": 271.84,
        "duration": 5.28,
        "text": "slide you'll see that those cassandra"
      },
      {
        "start": 274.32,
        "duration": 5.52,
        "text": "row objects have a fairly polite"
      },
      {
        "start": 277.12,
        "duration": 3.12,
        "text": "conversion into string format they'll"
      },
      {
        "start": 279.84,
        "duration": 2.88,
        "text": "show"
      },
      {
        "start": 280.24,
        "duration": 3.6,
        "text": "the column names and the column values"
      },
      {
        "start": 282.72,
        "duration": 2.72,
        "text": "that they contain"
      },
      {
        "start": 283.84,
        "duration": 3.84,
        "text": "which makes them pretty easy to debug in"
      },
      {
        "start": 285.44,
        "duration": 3.199,
        "text": "this simplistic way here's another way"
      },
      {
        "start": 287.68,
        "duration": 3.36,
        "text": "we could do this"
      },
      {
        "start": 288.639,
        "duration": 3.601,
        "text": "now it's so obvious that i actually want"
      },
      {
        "start": 291.04,
        "duration": 3.04,
        "text": "to show it to you"
      },
      {
        "start": 292.24,
        "duration": 3.28,
        "text": "and point out that this is not how we"
      },
      {
        "start": 294.08,
        "duration": 2.88,
        "text": "ought to do it there are a few things"
      },
      {
        "start": 295.52,
        "duration": 3.76,
        "text": "that come up as we walk through this"
      },
      {
        "start": 296.96,
        "duration": 3.92,
        "text": "spark api that seem like they might be"
      },
      {
        "start": 299.28,
        "duration": 3.68,
        "text": "correct and might seem easy to do"
      },
      {
        "start": 300.88,
        "duration": 3.92,
        "text": "and i want to say explicitly let's not"
      },
      {
        "start": 302.96,
        "duration": 4.88,
        "text": "do those so take a look at the slide"
      },
      {
        "start": 304.8,
        "duration": 4.72,
        "text": "here we just did a naive query of movies"
      },
      {
        "start": 307.84,
        "duration": 4.079,
        "text": "by actor give them all to me"
      },
      {
        "start": 309.52,
        "duration": 4.16,
        "text": "now there could be potentially tens of"
      },
      {
        "start": 311.919,
        "duration": 4.241,
        "text": "thousands of movies"
      },
      {
        "start": 313.68,
        "duration": 4.16,
        "text": "in there by actor and if we expanded"
      },
      {
        "start": 316.16,
        "duration": 3.36,
        "text": "that in the world of killer video to be"
      },
      {
        "start": 317.84,
        "duration": 3.04,
        "text": "all of the videos that were uploaded wow"
      },
      {
        "start": 319.52,
        "duration": 3.76,
        "text": "there could be billions"
      },
      {
        "start": 320.88,
        "duration": 3.36,
        "text": "so we don't want to do that that naive"
      },
      {
        "start": 323.28,
        "duration": 2.88,
        "text": "query brings back"
      },
      {
        "start": 324.24,
        "duration": 3.36,
        "text": "all of those records and then uses a"
      },
      {
        "start": 326.16,
        "duration": 2.8,
        "text": "filter transformation"
      },
      {
        "start": 327.6,
        "duration": 3.28,
        "text": "which if you went through the rdd"
      },
      {
        "start": 328.96,
        "duration": 3.92,
        "text": "section you know how to do to"
      },
      {
        "start": 330.88,
        "duration": 4.159,
        "text": "limit the the data in that set that"
      },
      {
        "start": 332.88,
        "duration": 2.879,
        "text": "creates a new rdd that has the correct"
      },
      {
        "start": 335.039,
        "duration": 2.16,
        "text": "filtering"
      },
      {
        "start": 335.759,
        "duration": 3.121,
        "text": "then does the mapping then does the"
      },
      {
        "start": 337.199,
        "duration": 3.681,
        "text": "sorting and the taking and so forth"
      },
      {
        "start": 338.88,
        "duration": 3.12,
        "text": "much better to push as much of that into"
      },
      {
        "start": 340.88,
        "duration": 2.96,
        "text": "cassandra as possible"
      },
      {
        "start": 342.0,
        "duration": 4.08,
        "text": "let's just get the data we want into"
      },
      {
        "start": 343.84,
        "duration": 2.56,
        "text": "spark and then work on it in spark if"
      },
      {
        "start": 346.08,
        "duration": 2.16,
        "text": "it's"
      },
      {
        "start": 346.4,
        "duration": 3.68,
        "text": "efficient to do the limiting in"
      },
      {
        "start": 348.24,
        "duration": 3.6,
        "text": "cassandra we definitely want to"
      },
      {
        "start": 350.08,
        "duration": 3.6,
        "text": "now spark exists because sometimes it's"
      },
      {
        "start": 351.84,
        "duration": 3.68,
        "text": "not efficient to do that filtering in"
      },
      {
        "start": 353.68,
        "duration": 2.639,
        "text": "cassandra and you do need to bring a big"
      },
      {
        "start": 355.52,
        "duration": 2.64,
        "text": "data set"
      },
      {
        "start": 356.319,
        "duration": 3.6,
        "text": "into an rdd so it's not as if that's"
      },
      {
        "start": 358.16,
        "duration": 3.039,
        "text": "some kind of comprehensive anti-pattern"
      },
      {
        "start": 359.919,
        "duration": 7.921,
        "text": "but it's something you should avoid if"
      },
      {
        "start": 361.199,
        "duration": 6.641,
        "text": "you can"
      },
      {
        "start": 368.0,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:48:36.425855+00:00"
}