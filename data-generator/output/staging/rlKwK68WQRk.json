{
  "video_id": "rlKwK68WQRk",
  "title": "Analyzing Cassandra Data with GPUs",
  "description": "Join us as we welcome special guests Nvidia as we walk you through analyzing data from Cassandra using the power of GPUs!\n\nGithub: https://github.com/datastax/sstable-to-arrow/blob/main/client/README.md#getting-started",
  "published_at": "2021-08-16T16:22:32Z",
  "thumbnail": "https://i.ytimg.com/vi/rlKwK68WQRk/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=rlKwK68WQRk",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] hello everyone and welcome to monday learning uh we are uh doing a workshop webinar on analyzing apache cassandra data with gpus and we are joined by some fantastic colleagues of mine and a special guest so it's without further ado if you guys can hear us and see us just fine why don't you give us a thumbs up in the chat just want to make sure that the stream is working well um but as we do that let me introduce you to some of our presenters all right let me make some make it smaller as well all right we have with us uh some of my uh colleagues here at datastax alex kai why don't you introduce yourself alex sure um so hi everyone i'm alex kai um i'm a software development intern here at data stacks i've been working here over the summer and yeah i'm pretty excited to show a little bit about what i've been working on hopefully you guys will find it exciting as well all right thanks alex and then we also have sebastian estevez hello sebastian how are you today hey folks how's everybody doing um yeah alice has been doing some great work for us and um yeah i've been with datastax a little bit longer than alex about uh seven to eight years great to spend some time today with you guys talking about analytics that'll be really fun and we have our special guest from nvidia welcome justin how are you doing great thanks everybody i'm really excited uh we've worked with alex and seb here to kind of integrate rapids uh to kind of show the full utility of what rapids can offer and i'm really excited to see what alex has done or at least have him show it so great work all right thanks so we have some thumbs up in the chat means we are coming through loud and clear all right let's get to some just a little bit of housekeeping i won't take too much uh time so we are streaming on youtube uh but if youtube has any issues like uh stream quality or latency or whatnot um we also have a backup stream on twitch now we don't monitor the chat on twitch so if you have questions make sure to use the youtube chat or if you would like to join our discord channel we have a a community growing community i think we're close to 20 000 members now which is crazy i'll put some links in the chat for that you can join our discord you can also ask questions there you can ask more long-term questions maybe about cassandra specifically and we're pretty active in there as well uh today we are going to do some hands-on we're also going to do a uh a quiz at the end where you have an opportunity to win some prizes some swag uh so we'll be doing a kind of a game at the end there so stick around for that we'll have more information on on how to do that but we'll be using a online tool called mentee it's really easy to use and we'll walk you through that when we get to it all right so for the hands-on a few things to note uh we will be using a github repo i'll put the link in the uh in the chat uh for you right now everything that you need is is there and and when uh when we go through the hands-on we'll kind of walk through um that you will need docker uh in order to run the hands-on if you don't have docker feel free to either just sit back and watch and learn or if you'd like to uh install docker while we're going through some of the content it shouldn't take too long so you can do that as well but you do need docker to uh do the hands-on all right without further ado it's probably a good idea if you if you are gonna do the hands-on to pull up uh the readme that ryan shared and actually run that docker pull command because it's going to take a few minutes to pull depending on your internet connection so if you want to start on that while alex gets us started that's a good idea yeah that's a good point it's a little bit it's a pretty big docker so uh if you are interested in doing the hands-on go to that github link and uh get it started to download now so that you'll be ready all right with that without further ado let me hand it over to alex who's gonna present our content today sweet okay all right so take it away hi everyone um yeah i'm alex um and yeah today i'll be talking a little bit about gpu accelerated analytic queries on cassandra with rapids so if there's words there that you don't recognize um don't worry we'll go through them throughout this presentation and hopefully by the end you'll have a good sense of what it is exactly that we've been working on um so today we're gonna have sort of four main sections so first off i'll talk a little bit about ss table to arrow um what it sort of does what problems it solves um then we'll talk a little bit about rapids um which is um or what it is we'll get to it in a bit um but it's essentially some open source python libraries that can help you run data analytics on a gpu finally um or not finally sorry thirdly we will go ahead do the hands-on demo with ss table to arrow so make sure yeah you start pulling that docker container or the docker image because it is pretty big my apologies um and then finally we'll do a little um demo and um of how asus table to arrow works with rapids um and so since this only works on machines that have cuda support so with a gpu um i'm guessing that most of you will probably not be able to follow along unfortunately um so this will just be a sort of demo uh to show what esses staple to arrow is capable of all right let's go ahead and get started with um introducing asus table to arrow so first off hopefully you guys are all here because of how awesome cassandra is um and if you guys haven't heard of it before now is a great time to get started um because cassandra 4.0 has just released which is pretty exciting and i'll talk a bit about what that means so cassandra just to recap is an open source nosql distributed database and because it's distributed and that means the data is replicated across many nodes it has massive horizontal scalability it's extremely reliable and also very false tolerant so if you're building really large applications cassandra is a great choice because it can make sure your data is always available and really easy to access we here at datastax have been really closely connected with cassandra um we're sort of one of the leading cassandra experts and we also offer serverless cassandra as a service through datastax astra um and yeah like i just mentioned 4.0 just released so if you're just getting started with cassandra now is a great time to check it out okay so cassandra is great for transactional queries so those are queries that essentially um look at maybe one row or a couple rows inside the database for example if you wanted to ask i have this user id can you get me their username for example that would be an example of a transactional query and cassandra is really good at those it can search through the table get you the information that you need really really quickly um but what if um let's say you already have a lot of data collected in your cassandra table and you decide that you want to do analytics on it so this could include things like statistics it could include things like machine learning so what if you want to do analytics like machine learning on that data so since cassandra itself isn't really natively really good at this there are a couple external sort of tools you could use to get that working so one tool that a lot of people use already is apache spark and apache spark is a parallel processing framework for doing distributed computing so it's essentially very similar to cassandra it's distributed so it takes place across many nodes and allows you to do those sorts of big data operations effectively however in case you haven't used spark before it can take some effort to set up and also what if you have an existing analytics workflow using python libraries that you want to run on cassandra data so nowadays python is sort of the de facto standard for doing machine learning and things like that um so you're probably familiar with names like pandas numpy maybe scikit-learn what if you already have code using these libraries that you want to run on data from cassandra so in that case you can fetch the data from your cassandra table using a driver and then run analytics on that data so you can see here on the screen we have a little example of what that looks like you can essentially use python connect to that cluster transform the data into a pandas data frame and then do whatever analytics you want on it and this is a pretty small example getting like the mean of a couple columns um but you can imagine this would integrate right away with things like scikit-learn numpy other libraries that you might need however using uh that second approach using the cassandra driver does have some drawbacks so for large data sets if you want if you're querying the entire data set it can be expensive and we don't want to slow down our transactional operations imagine you're some big company and your users are using for example some real-time application that queries your cassandra table well if while they're querying their cassandra table in that real-time application if you're sort of asking the database to do this really really big operation it's going to slow down that sort of real-time experience and we don't really want that right because that's bad user experience um so how can we extract data from cassandra without using our main cassandra cluster because remember we don't really want to put a load on our cassandra database our cassandra cluster so we want to extract the data directly somehow so how to do this let's take a look at how cassandra manages data under the hood so cassandra um it stores most of its data inside memory so memory tables um when you actually query the database that's what it uses but when you save the file um or when you save the data to the disk if you want to persist it for long-term storage um it stores it in the form of ss tables or sorted string tables and you can see here on the left an ss table is essentially this big collection of a bunch of different files you can see we have some compression info we have the actual data some statistics about the data all of that is stored in these ss tables and cassandra what it does is parse the ss tables to get that data and then um send it to you whether you're using sql or you're using a cassandra driver but like we said earlier we don't want to put load on our cassandra database so the question is can we fetch data directly from the asset tables without using cassandra and this is what i've been spending most of the summer working on because it's not so easy um so here's a few diagrams of what ss table files kind of look like internally um this is all binary data so sort of ones and zeros um so i sort of read through the documentation figured out how to um parse everything out um but even though it's difficult of course it's possible right because how else would cassandra work so this is kind of what s's table to arrow is for so ss table to arrow is a tool that parses data directly from ss tables and i have here a little example of the docker command don't worry about it we'll get to that in a second during the hands-on demo um and it's open source so you can go ahead um find it on github um look at my source code if you if you if you're so inclined um and yeah so essentially that's the essence of what sstable to arrow is for it can read those ss tables directly without having to go through cassandra and then it transforms the data into this format called arrow which we'll talk about in a second so um oh i missed the recap so just to recap let's say you have a lot of data stored in cassandra inside a cassandra table and everything has been going well for your transactional needs so for example real-time applications that are querying that table all of that's going great but one day you ask how can i extract insights from this data using analytics and previously or you still have these but of course s's table to arrow is a different option so you have two sort of main options firstly if you're using data stocks enterprise or cassandra open source also works too you can use apache spark which is once again a distributed framework for computation so distributes your computation across many different nodes and that allows you to scale and do that sort of analytics really efficiently but this does require a lot of setup and you would need to migrate existing analytics code that isn't written with spark excuse me so if you have existing python code for example using things like numpy or scikit-learn you would need to migrate that into spark code the other option is you could fetch all of the data using a driver and then run analytics on it using your framework of choice but this requires querying the cassandra cluster which will slow down your transactional operations which once again we don't we don't want we need those transactional operations to be lightning fast but now with ss table to arrow as long as you have access to the underlying ss tables you can easily query for that data without burdening your instance of cassandra and you can easily migrate existing python analytics code using rapids okay so um now let's take a look at what is rapids and why should i use it or why should you use it um and yeah this will be a look into gpu analytics using the rapids ecosystem so rapids is a suite of open source software libraries um and it enables end-to-end data science and analytics pipelines entirely on gpus and under the hood it uses nvidia cuda to optimize low level compute so cuda is essentially a programming toolkit language that allows you to write code for the gpu and make the most use out of its power and as you can see here here's a couple of the more widely used rapids libraries and one of the most important ones here is qdf so if you're familiar with python and you've used pandas before which is a library for essentially managing your data in the form of data frames cody f is kind of the equivalent of pandas in the rapids ecosystem and it allows many of the same operations um like storing data or querying for data or um all of the notation you're probably familiar with that's all stuff you can do with qdf as well except it works on the gpu instead of the cpu um okay so uh why are we so concerned about using gpus anyways what's the big deal um so as you can see in this diagram from rapids it is a pretty big deal because um gpus are able to do these analytics processes and machine learning training for example much much much much faster than current cpus can and the reason for this is that gpus are essentially able to multitask very very efficiently you can run um like lots lots more different threads on a gpu than you can on a cpu and since data science and machine learning requires a lot of parallel computations um gpus are much better suited for this task so as you can see here they're very very performant when it comes to doing things like machine learning and data science which is why we want to use them for what they're good at so if we're doing data science and you have some code that's already written for example with pandas scikit-learn maybe matplotlib all of these have respective equivalents in rapids and that makes migrating your existing code really really easy so as you can see here we have cody f is essentially the equivalent of pandas we have qml which is essentially the equivalent of scikit-learn and we have a bunch of other libraries that can help with all of your data science needs and enable you to run data science from end to end on a gpu so i'll go back to take a look between these slides and you'll know this and you'll notice sorry one other difference between these two sort of pipelines is the type of memory that they use so currently these familiar python apis are running mostly on your cpu right so that's the memory that you sort of have inside your computer but with rapids it allows you to interface with gpu memory and like i mentioned earlier the the format that this memory is that your data is stored in is known as apache aero and apache aero is a really really cool project um and now i'll hand it over to uh seb and justin to talk a little bit about apache arrow um all right go ahead yeah so i guess i'll take this off so arrow is a project uh it's been around a few years uh in the uh apache um open source um governance model and uh basically the main thing that it does is it's an in-memory a data structure that's called based and so it's designed for a couple of main things most columnar video formats in general are are designed for analytics this makes sense because the kinds of things you might want to do in analytics is compute statistics for a particular column and so you may want to fetch an entire column's worth of data to be able to aggregate it at a time without looking at or going through other columns in your table so that's kind of one of the main one of the main purposes the second kind of more important thing that makes apache area unique is is across language in memory implementation and so it comes with a set of tools for whatever programming language you may fathom write your favorite language uh to be able to you know parse and manipulate and create these arrow um these arrow data structures and so the folks that built rapids have pretty heavily piggybacked on this arrow technology i think justin's going to go deeper into a little bit a little bit of that on the analytics side um arrow is a really interesting project from for folks that are maybe running cassandra or other databases or are interested in kind of the transactional side of the house just because of that capability of going from language to language or even going over the wire without having to serialize or deserialize the data right so traditionally let's say that you know you're building an app and you have some some some data in an object format in your particular programming language when you want to send it over the wire or send it into the database you serialize that into a format that you that you can send over the wire then you again deserialize this utilize again it very basically at every step to turn it into objects um in your code whether whether that's the code inside of the database like like cassandra that's going to stick stuff in what we call mem tables which is the cassandra memory format or whether that's the code inside the the driver that you're using to to either persist or read the data you're serializing and deserializing constantly right and so if ecosystems like for example the cassandra ecosystem adopted and leveraged arrow it's possible to do that throughout like that entire stack so you know there's a potential future in which everything's arrow starting at your driver application uh and going over the wire to the database uh you know it's in and there would be literally zero zero copies made of the data zero serialization deserialization which actually takes up like a chunk of the compute um inside of systems like cassandra right both at the driver level and at the database level so this is a really interesting technology um i think you know we've been watching it for a while and the guy that came up with the name he actually uh works at data stack so there's yeah there's it's a pretty interesting technology from from just a compute database perspective in general but really it's optimized and designed for analytics and i'll shoot it over to justin there to chat a little bit about that i think yeah it's it's an opportunity to have a shared data object between a variety of different apis but also different types of hardware so when when most users are coming into data science the the first kind of structural component that they are introduced to is the data frame and inherently with the data frame they're using with the uh with data science is often appended data frame and with most cases with that you know when that was first created there wasn't really a lot of options so in most cases you were dealing with a lot of structured data uh this is maybe 12 13 years ago and coming just doing your initial data etl wrangling data exploration um doing a lot of your model development using psychic learn things like that but building it on top of the the pandas data frame and then generating some type of analysis and at that point moving on to the next step or swapping out different types of samples for your model as we've seen growth within the data science community the different types of tools that have come up one of the things that at least was generated was that there were some inherent shortcomings associated with pandas and apache arrow looks to at least address some of those shortcomings and then have any other apis or applications that are developed on top of it to be able to avoid some of those pain points that users kind of face right now and whether that's in memory computing whether it's running out of data sets or shortcoming data just based on what's available in your cpu but when rapids was first created but the core component that was recognized that we needed to understand to at least develop and understand how to create a gpu specific data frame was one understanding that users are familiar with pandas in the painters api but also we need to evaluate the same polynomial structured style that would run on a gpu and therefore be able to process all this data without having to pass data from or do all the wrangling on a cpu and then pass it to a gpu for any type of accelerated computing hence the qdf functionality where you can essentially take your data data query from the ss table put it into a qdf with the backbone of it being apache arrow in this case a pyro functionality with a python api and then start to do your data wrangling and accelerate all this process of feature analysis uh data prep so on and so forth and then before you push it into a deep learning specific type of process or a more classical machine learning type process using our qml so these are the types of things that we see are more more of an evolutionary growth in terms of what other components are out there within the the field that offer assisting components or assisted compute as well as additional functionality and efficiency for a lot of data science users yeah so i guess one of the things to point out here is if you want to do if you want to take advantage of gpus for things like analytics like there's not a ton of cuda developers out there right that's a very specific niche like knowledge set you're writing c plus and you need to be familiar with the specific cuda apis and it's hard right uh and so one of the like huge benefits of rapids and arrow is that if you're able to get something an arrow like getting that data vectorized and loaded into gpu memory uh etc is is basically free exactly extract it from the user and so all users have to know is just that a familiarity with the apis that are similar to pandas and the functionality then mirror is mirrored in qdf so the same types of steps that you would do in a pandas data frame can be done in a qdf data frame therefore the learning curve is black yeah awesome so thanks so much seven justin and i'm gonna skip ahead because i think i miss ordered my slides a little bit but just to follow up with what someone's talking about yeah that's that's um um was we got this tweet and saying weird that um the title of the post is about doing things with gpu and the gpu part is kind of like a to-do at the bottom and what makes arrow so great is that um that's kind of exactly the point is that for most users who um don't need to worry most users sorry let me back up most users now don't need to worry about the actual process of getting data onto the gpu because the rapids ecosystem and codif and qml and all of these libraries do all of that work for you so really on our end with ss table to arrow the main idea is to read those as tables and get them into arrow format because once they're in arrow format we can use them on the cpu we can use them on the gpu and it's just a very flexible format we can use also across languages okay yeah awesome so i'll just back up uh to those two slides there um so yeah here's just a sort of brief look at what we're talking about so if you already have some code using pandas for example we're just reading a csv printing the mean of each of the columns pretty basic stuff um if you want to run this code on a gpu all you really need to do is switch out pandas with qdf um so now instead of import pandas we just have import qdf and then all of the other um all the rest of the api um we can essentially use it in basically the same way um so rapids is a really really great project highly encourage checking it out in case you want to do data analytics on a gpu okay so um now let's move on to part three so this is going to be um the hands-on section um where you can try out this tool on your own cassandra data um and in case you don't have an ss table um or ss tables available don't worry um we first of all we have some sample data bundled in the repository that you can use um and we also have this s3 bucket uh with some sample internet of things generated data um in case you want to use that in a bit um so the s3 bucket is called ss table to arrow but for today i think we're mostly going to be using the sample data inside the repository but just know that s's table to arrow is able to read um ss tables from an s3 bucket so if you have data maybe in s3 um i've heard rumors that that's maybe where cassandra will be going in the future too or astra yeah so s3 that's where our data is stored you can go ahead and use that as sample data if you want okay so um here's a brief overview of currently how you can use ss table to arrow so keep in mind this is alpha level software um i'm currently actually working on some python bindings that you can call straight from python um so i guess stay in touch keep our or keep updated about that in case it ever comes out but currently um how it works is we have these ss tables on the disk so we have our data file statistics file etc and that gets read by the actual asset table to library our asses table to arrow library which is written in c plus um and which you can run through a docker container um to avoid any like installation panes and essentially that tool will take those esses tables transform them into arrow tables and then it'll listen on a network socket that you can connect to to actually grab that data so then on the client side um we have a sample python script which you can grab from the repository that we sent out earlier and that script will essentially go and ask for the data from that server and the server will send that data back but as an arrow table instead of access tables which are harder to parse um and once we have that data as an arrow table we can do like we said data analytics or anything we want with it basically using the rapids ecosystem so um here's a brief overview of the steps um i also just realized i haven't updated this url for the python script so um this is essentially identical to uh what's on the github repository so um right now if you want to go ahead hop on that link that was sent earlier to the github repository um and just follow along with the getting started um we'll basically go ahead and walk through that so unfortunately i can't read the chat so i'm not sure how much time this will take um but i'll head i'll hand it over to sub right now for a sort of live demo of how this is going to work because unfortunately my computer is having some technical difficulties all right uh seb do you want to go ahead and share your screen yeah absolutely all right okay let's see the screen button over here i'll jump out of the youtube there okay so this is the section that we want to do for hands-on if somebody's right if someone if you're watching the um the chat and some questions come in just go ahead and break in and we can answer those um but until then i just kind of walk through the steps on how to run this and talk a little bit about what it does so um the first thing was you want to pull the container that has the accessible arrow program um sstable to arrow i'll show you guys quickly the repo is written in c plus this is alex's work for the last few months um and so there's the compiled binary in this docker container to make things easy you don't have to go build anything from source or anything like that um but yeah this is the project where it lives um and basically what it does is you point it at some ss tables and it makes them available in arrow format now in the example here what we're doing is we're starting up the container telling it which of the stables we're interested in and having it start and having it open up a network socket and the second section here this python part is a python client application that's going to hit sstable arrow via that socket ask it for the data in the ss tables that data is going to be sent in arrow format over the wire so this not only shows off the ability to read the essays table data stick it in arrow format but also send sending arrow format without serializing the serializing over the wire and then it gets turned in directly like red as arrow directly in in python without any serialization deserialization and at that point this script does some simple analytics on it so so that's what we're doing um the first thing is to pull that container which hopefully you guys have already done um the next thing is to pull the python script it's going to be the client you can do that with this very simple curl command i already did that on my machine then you want to create a virtual environment just to make sure that we have our own you know python installation here that doesn't interfere with your operating system python it's just a clean way of doing things and making sure that we don't interfere with your host environment we activate that virtual environment in python and install a couple of dependencies it's just pandas and pi arrow in this case there's another version of this that does the actual gpu stuff and that will also install the qdf libraries and then we kick off the container which gets those ss tables read and into memory and arrow and we run the python program that pulls that arrow data over the wire does some analytics on it so let's actually do that live here this is the docker run command uh for those of you not super familiar with docker you may be wondering what this dash p thing is well actually i'll break down the whole command so we already pulled that means that on this machine i've got this image sitting sitting here now i want to run that image dash dash rm means that once this process is completed i don't want to hang on to that docker run i actually want to delete it from my docker environment [Music] then it is passing a command which in this case is dash s and this dash p is telling our docker to map the port 9143 inside the container with the port 9143 outside the container in my host machine and so that's what's going to allow the client program in python to hit the container through the network so once i kick this off you can see that it found some ss tables and then it created a socket on port 9143 so let me pull up another window here if i that's f dash i 90 43 we said it's the port 9143 sorry 143. oh uh i think you might need a space touch i space 9143 i space colon 9143 oh you know what i need to do this as root yeah so here you go um docker is here there's a docker process it's listening to all interfaces on all interfaces on the port 9143 um so this is just a way to validate that um we can also say docker ps which shows you that docker is listening and it's got ports then on my host machine i can see it listening on the port so these are just kind of some free troubleshooting steps in case folks get stuck this validates that your docker section is part is running correctly if you're able to do both of these things um and then i'm gonna actually go ahead and kick off this cuda code now before running the script maybe let's take a look at it so it's got a couple of variables here for localhost and the port that we're going to be listening then we're going to be uh reaching out to the socket on there's some functions that are defined and let's see so there's no cuda um but we're going to go through and open up the stream and once we've got the data it's going to be in a data frame and we're going to basically print it out print the mean of a column called sensor value so this is the simple analytics stuff that we're talking about and then this ipc open stream read all two pandas reaches out to the c plus pulse program gets the data over the wire and sticks it into pandas data frame um so so the the interoperability with arrow is also showing here so we're going from arrow to pandas very easily um in the gpu code we go from arrow to qdf very easily same deal right to pandas to qdf uh you'll be able to see that if you take a look at the with gpu code so that's what the program does let's go ahead and run it all right so i loaded the table and we spat out some columns in this case we have a partition key which is a uuid type we have some row likeness and we have some times and you can see here that we calculated the mean of sensor value of a few rows i think there's a thousand rows right they got red in this example ss table if you have your own ss tables then you want that you want to parse and manipulate you can pass the directory with those ss tables to this program there's more information and github on how to do it and we'd also be happy to you know help out there if you want to reach out to us um yeah awesome yeah this is what it does i guess i'll add a couple of other a couple of other points that might be interesting to cassandra folks if there's no questions at this point um one of them is the liveness so one of the interesting things about a cassandra table from a data storage perspective and alex was mentioning data as data goes into the cassandra goes into event table and a commit log before we acknowledge to the client the data got written it's going to be stored in um it's going to be persistent on disk and the commit log and then it'll also be in memory and event table those map tables fill up and they get flushed into ss tables and ss tables are what we're looking at so one from a kind of caveats perspective of the project um if you were doing this against all the ss tables in your cassandra cluster uh one you wouldn't be getting the real-time data that's in mem tables as of that point so based on the the software that's been developed up to now um this it's going to be very useful for performing analytics on cassandra data based of kind of a snapshot but not like the latest data another thing that that's kind of a caveat to keep in mind is a cassandra table is going to be is going to result in lots of ss tables on disk and not only lots of excess tables on disk in one place but lots of ss tables on disk across lots of machines and so you do need kind of a way to consolidate all of those and hit them with as a stable arrow to get useful data secondly um cassandra uses a lot a lot of structured merge right so uh yes so that's what ss tables are there data it's a data storage format that's basically a log and ss tables are immutable which means that if you have updates in your data you may have values for the same you know unique key across a couple different ss tables and cassandra on reading will basically pick the latest using last right-wing semantics and so ss table to arrow doesn't do that right winston antics for you yet what it does is it exposes the internal timestamps of all the cells in the arrow in the in the arrow in memory structure and then as a user you can write some sql to say i would like to get you know the latest time stamp throws or the last time perhaps it's time to have cells for the rows that i care about um so so that's kind of the stage the stages that the process is on um again it's very useful in kind of first first few steps first lots of steps into this kind of journey of getting of making cassandra data available in gpus uh but there's certainly lots of work to be done as well and you know whether we continue to do that and invest i think hinges on how interested folks are right so we're very excited to hear from people about you know what they think about this and whether they want to pursue it for you know their real use cases and you know we'd love to hear from you and chat more about it and see how we take this into the future yeah awesome okay thanks so much sub um all right i'm going to go back to sharing my screen um questions at this point in the chat at all or folks trying it i can't see the chat so uh i guess if you guys have any questions um sub if you can like i guess redirect them if they're specifically for me so uh real quick i just wanted to i'm popping back in uh we do have a few questions though i i know justin has been uh in the chat answering a lot of them i was wondering justin if you wanted to i know you answered the question about um the analytics on gpu versus otherwise uh you had kind of had a longer answer i don't know if you wanted to talk about that more to the yeah everyone one of the things we want one of the things we want to convey is that you know what alex has done at least from the ss table to aero is that you know you can you can analyze the data on cpu but also a gpu now say you are an analyst data scientist who is attempting to do some code on a smaller data set you access the data and asset table you go through your your or your data science order of operations essentially you know the data expiration component identifying you know which features are correlated or decorated putting it into essentially a more uh data subset that you then run a smaller model on maybe just a standard tree based model random forest or something like that but now understanding that because your code has a specific logic you don't necessarily now have to worry about converting it to pi spark code or something like that to perform additional analysis to scale up or scale out you can essentially take your code using the apis similar to the example that alex showed previously where it's just a minor syntax change it's just literally changing importing one package versus another and then that code will essentially now run on a gpu so then you can take your process and now if you want to automate this process or have it run it in a cloud-based uh orchestration or have this process run you know on a gpu on the cloud you can know that it's going to follow your logic and you won't have to necessarily worry about any other types of of logic adjustments that you'd have to make by converting it from running on a cpu to a gpu so there's a interchangeability available there between the two api awesome okay it doesn't look like there are any other uh specific questions and for those for the viewers give us your questions please uh we'll we have plenty of time today so if you have any questions um stick them in chat and we'll uh we'll answer them on on stream as well all right back to you alex okay sure so yeah now we'll sort of um go through so you guys have hopefully gotten a chance to try out ss table to arrow on your own machines but in case you don't have a machine that um is compatible with cuda which is once again the sort of framework that allows you to interact with the gpu um here's um we're going to do a little brief demo of how ss table to arrow can help get data onto the gpu using rapids so if i go ahead and share my screen here and open this up so we're unable to sort of see that okay sub is it visible on the stream yeah it was good okay awesome so yeah um like we sort of mentioned earlier um rapids allows you to sort of take existing code um that you might have with python or popular libraries and easily run that on the gpu instead so what we have here is i've taken the iris data set so um hopefully those of you who have tinkered a little bit with machine learning you might have encountered the data set before it's essentially a data set of iris flowers and has data about i think it's their pedal length pedal width simple length sepal width and then their species and so there's three different species and it's a pretty classic sort of classification problem which is where you ask the computer to look at a bunch of data and then try to classify new data um into being you know a member of a certain class so scikit-learn which is a python library for the cpu mostly um that does machine learning um it already has a couple examples of using the iris data set for some simple classification and i was thinking we could use as a stapled arrow to show how you might if you had that data in a cassandra table for example how you might take that data and load it onto the gpu using rapids so here i'm this isn't my local machine i'm logged into a remote computer um and yeah so we're importing a bunch of libraries um and then this is the same command that gets run in the no qdf version um so it'll basically fetch the data from um ss table to arrow so if i go ahead open up my command line here zoom in really close um if i go ahead and let me close that up run this function so as is table to arrow that's the same thing you're running from your docker container um i just have it installed on this computer um so i'm just running it from the command line um so s is table to arrow and then i have this flag dash c um oh by the way i should probably mention that so if you want to see more options about how to use sstable to arrow you can also pass the help flag and it'll print out a bunch of like different flags it's a really big help message um yeah so some other things you can do you can also write to a parquet file so parquet is another file for um storing analytics columnar data you can also do a dry run so turn off the listening on the network part if you want to just like print out what the asus table looks like um and then anyways this one i'm using right here c um just doesn't include the metadata so um all of the time snaps and stuff it just doesn't include those so um as i mentioned earlier as the table to arrow doesn't do any of the deduplication stuff for you as of yet unfortunately we're working on it um but so for this table um it's just some sample data that i've imported it doesn't have any additional writes and things like that um okay so if i go ahead and run as a staple to arrow and i've passed the path to my iris data set here you can see blah blah blah there's a bunch of asus table files and this is also compressed by the way so asses table to arrow works fine with compressed ss tables so if we go ahead and run that you can see uh there we go it'll read that's this table um listen on the port and now in my code if i go ahead and fetch the data awesome so it receives that table and if i want to sort of print it out um table zero yeah yeah awesome so we can see here we get um all of that data and if we want to load it into qdf we just call qdf.dataframe.fromarrow and then i'm passing that one table that we loaded and i'm just renaming some of the columns here to make it a little bit nicer and woohoo you can see we've grabbed the data from our assets table and parsed it into um kudif so once again qdf is sort of the equivalent of pandas that holds all that stuff on the gpu okay so next up i've taken this scikit-learn example from um the scikit-learn website and uh like we mentioned earlier i've just exchanged sklearn um with qml um and that's i was like wow this is kind of magic um so sklearn exchange it with qml um there's a couple minor changes um with the qdf sort of syntax um and i'm also using matplotlib to plot it which requires numpy arrays so there's a couple minor sort of changes tweaks i have in here but essentially you can see here we take that cuda data frame um grab the data so here i'm taking some of the features and then i'm also taking the target if you guys are familiar with machine learning um it's probably pretty clear what i'm doing um here we're using the qml logistic regression um model so we're creating that classifier fitting it to the data and then this is a bunch of sort of setup code just to get the plot to look kind of nice um and then if i go ahead and run this um do to do that loop gives me a warning and you can see here it's running it takes a couple seconds i feel like the time is also maybe because of connection to the remote but you can see here we're able to sort of classify those data points that iris data set so blue is one species um brownish is another species and then yellow is another species and all of this is sort of done on the gpu um so yeah hopefully that gives a sense of what rapids is sort of used for um and what esses table to arrow is used for and like seb mentioned earlier um in in practice a lot of the time you're going to have not just one ss table but a whole bunch of access tables that correspond to a single cassandra table so unfortunately s's table to arrow doesn't support the deduplication step but you can sort of do it manually using sql on the client side so one really helpful uh tool also um i believe associated with rapids for doing this is called blazing sql or blazing sql um and so this is a python library that allows you to essentially run sql queries using the gpu um so here i'm sort of importing that library um let me see if i have my sample data here yet no okay give me one second i'm going to grab my sample data copy that over here do i already have it okay i might already have it um but it's empty okay um to give me one second to copy over this data set i'm just gonna stick it in here um okay cool so if we go ahead and um use asus table to arrow again to read that data set i'm gonna copy the path pass it to sstable to arrow listening on port awesome and i'm going to go back up here to fetch the data again and um read all of those as tables so you can see this time i have actually three asset tables in here and if you take a look at the numbers um you can see there's a table one two three um and essentially if you want to take a look at what these look like they're all corresponding to the same sort of sample key value data um let me see i think i could show a visualization of what it looks like give me one second table oh dot two pandas four table in tables um and it'll take some time to run my computer is slowing down a little bit um okay so here's a look at what the data looks like so you can see here in our first esses table this is one where i sort of wrote the data so there's no updates or deletes so it contains all the data in this second access table i've updated a couple of the cells and you'll notice that except for the partition key um the row liveness data is mostly empty and then for that specific cell we have a timestamp when it gets updated and then along with the value that it has um and then finally i've deleted a couple of rows here and you can see here it also has the partition key um and it also has the row deletion time and this sort of once again um includes all of the metadata from cassandra so that you can do the deduplication um on your own so if i scroll down all the way to the bottom here um i'm gonna use blazing sql um to um uh read those assets tables um or sorry let me back up a little bit and explain this process from the start so we have the ss tables and those contain all the metadata that you need to reconstruct um like the current version of your data and what blazing sql does is it can um take those ss tables or sorry assets table to arrow transform those tables into error format and then we are able to use qdf to get those arrow tables into qdf data frames and then blazing sql is able to take those data frames and load them into its own internal sort of represent representation so that we can do sql queries on it so i'm going to go ahead and create this new blazing context um oh dear um [Music] let me take a look at what's going on here okay so if we go ahead and read that key value data okay um so that gets loaded into our program and then we're going to use qdf to create a table from each of those arrow tables okay i'm worried it might be some issues with compatibility here um so we might need to skip this part of the demo for now but essentially once those tables are loaded into blazing sql you can write a sql query to essentially um look for all of the rows that have not been deleted and you can also if you wanted specify a certain um time for example um and then it will return to all of those rows and the updated versions of them but unfortunately um i'm not an expert with sql um so you might need to do some of those steps manually on your own but since all of that metadata is provided to you you can go ahead and write sql queries to rebuild the sort of current version of your data okay well i guess that's it for my presentation today so that's a sort of brief demo of how you can use rapids so thanks so much for listening and i guess now we'll open it up for any questions right yeah i think we have a couple questions there was a question i know it's been answered in the chat but just for the benefit of the rest of the viewers about kind of a question around speed differences uh for with the gpu versus the cpu and how the data size or data set size affects that yeah and i want to say that uh seb and had a great response to that too because in most cases it's not necessarily about the data and but in most cases you'll see improved performance the larger uh the data that you're running through especially for data transformation data wrangling that you'd be doing in pandas the larger the data sets then you'll be able to process it and do a lot of these transformations much faster on a gpu using something like qdf but when we actually start moving into kind of the more classical machine learning where you're running a random forest or something like that and you're kind of iterating through all these different variations of the decision tree in that case you'll definitely see improved performance running with the qml library versus something like psychic learn or spark ml just by either the nature of how the pro the data is being processed and iterated through or in terms of for example spark ml just the distributed nature of the algorithm and how it has to go back and collect all the different components before it iterates again so you'll see just improve performance across the board just by the compute that's necessary to achieve the results faster by some of these particular algorithms that have mentioned yeah so so to summarize data volume matters but algorithm complexity matters as well and yes with bigger data sets also with bigger algorithm complexity you're going to get you're gonna get big savings from going on the gpu um something that hasn't come up that i kind of expected to come up and maybe we should spend a couple minutes chatting on is um like how do we how do we do rapids in a distributed setting um all the folks that you know our cassandra users are kind of used to everything you know running on a cluster uh and so maybe people just take this for granted uh so rapids is a you know distributed clusterable you know enabled technology um they leverage you maybe just you can dive into the desk a little bit more uh but so yeah so so uh things to think about like you you have device memory um all these tools support kind of streaming into and out of the device memory in case your data set is larger than memory and they also support via desk uh distributing across of lots across lots of machines with gpus uh to handle large tasks indeed yes and and in some cases so if your data is pretty it's pretty large that we see the memory associated with a single gpu we we use something called uh qdf which essentially is allows us to use the das framework to distribute our qdf uh data frame across multiple gpus in the cluster and so it allows at that point it follows a similar process where now we have also data distribution to run a parallel task but in a a serial in a concurrent fashion it allows us to scale out to additional gpus to then harness and enhance a lot of that functional power that we get with gpus not necessarily just a single one but multiple and in some cases though even though if you're running on multiple gpus it'd be an order of magnitude smaller than uh just uh hundreds of cpus or 50 cpus or something like that that you would have to spin up separately so in this case you'd still be looking at improved performance in terms of compute but also in terms of efficiency and and how quickly a particular process executes and then is completed before you can then spin up another process to run um and that's not to say that you know you can't necessarily even this is all just kind of batch processing as well you know we have a series of kind of streaming components where we have things like cue streams that we're able to connect to kind of existing uh message queues to then be able to capture data in a somewhat real-time component that would then be able to then essentially gather new data and then put it into a data frame for additional execution and then also while we have qml we've touched on qml quite a bit additional other types of libraries that are more familiar for cpus are things like uh graph analytics in this case for particularly with python you have network x whereas we also have a q graph functionality which allows you to essentially do all your graph analytics and graph processing put on a gtu and scale it out to millions of vertices and millions and millions of edges as well as q spatial for geospatial analysis and q signal for kind of digital signal processing and time series analysis there's a question just came in here about do we expect metrics to be added to cassandra for analytics in the future um so just to clarify like the stuff that we're showing here i mean that's a staple to arrow it's not it's not a utility that that is in the cassandra project itself right so this is kind of an external third-party utility it's kind of alpha software experimental that you can use to take your ss tables and do analytics on those separately from cassandra in fact cassandra doesn't know anything about this so no you won't see any metrics in cassandra about analytics when you use these tools i mean you know there's potential to do kind of more any more uh like tighter integrations with things in the future but yeah just to be clear like this functionality the rapids ecosystem that's this table that arrow uh software is completely separate from cassandra it just knows how to read cassandra ss tables and that's the that's the integration point and and we like that being separate because again we talked there was a there was a question a little bit earlier about kind of co-location versus isolation so like in some cases a lot of folks think hey if i co-locate um you know my analytics in my transactional i may get some performance boosts because hey the data is already there uh you know on those same machines but at the same time when you do that you contend against the same system resources when you know those two very different workloads run right like you don't want your analytics in your transactional workflows to use the same disks to use the same to hit the same cpus because they will basically fight over those resources and um the loser will be the the transactional workflow that has tight slas right so you never want to impact that like real-time injustice and cassandra by hitting it with a with a with an analytics workload so this is what happens when folks use spark and this is why folks kind of do a separate data center in cassandra when they have spark workloads and even then you know separate data centers and cassandra can still impact each other you know kind of in extreme circumstances when you're running something big like a like an analytics app um so yeah um i think so i think what you really want is isolation instead of um co-location and that's kind of what we get by by making a system that just reads success tables and cassandra doesn't even know about it i just said we thought i just saw another question but before i answer i just wanted to to agree with you that so i want i want everybody to see that with cassandra and the work that we're doing that these are complements like there is it's essentially taking the ability and capability of what uh cassandra does and writing the data particularly to a ss table but there was a bit of a barrier between what you could do and do take that data and then directly process it and push it into rapids before alex came up with this kind of solution that now has been able to kind of integrate these two components and have them complement each other from the transactional side and then move it quickly to the machine learning side and then i've seen your question this most recent question where in the chat where it says does rapids avoid the data transfer between cpu and gpu memory that's exactly what it does and that's what that's what apache aero is offering now is that we can actually now take this data and then push it into a gpu without having to load it to a cpu which essentially would be the bottleneck and then before you push it into a gpu for additional functional uh processing so that's that's then the whole goal is to then be able to then now keep all your analytics on uh the gpu and essentially the start from everything from the etl data wrangling all the way to your model training and iterative processing before you actually write it out to a particular uh destination is to keep it on on the gpu without having to rely on the cpu for any additional uh functionality unless it's absolutely necessary yeah hey you made a really good point on complementary that i really liked justin like we should have put a slide in here that just has like rapids ecosystem and cassandra ecosystem and like a little heart you know because that's because really what this is is about bringing those two communities together there's a ton of rapid users out there right now that that know how to take advantage of gpus and their power and they're reading data that's in json or csv or parquet format probably mostly parquet and to get that data in parque there's a lot of work that's getting done and for a lot of large enterprises the original source of that data is a cassandra cluster somewhere and somebody's reading data from less cassandra clusters the slow way through cql and they're manipulating it with like some different tools to get it into that parquet format so that they can go loaded into a gpus somewhere and so the stuff that alex has built here is a huge shortcut to that kind of long to that long process and so we hope that you know the two communities i think there's a lot of folks definitely a lot of large organizations that have both a big rapid footprint that's using gpus for analytics and a big cassandra footprint where a lot of their transactional data is sitting in cassandra and so you know the idea is to bring those together uh can you make a separate cassandra replicated cluster i think what you mean there maybe is a replicated data center within the same cluster that has the same data to get the data to a certain snapshot state and then get cassandra to stop replicating and flush the data ss tables yeah so operationally you can tell cassandra to flush at any point like there's there's an old tool command for that um and so you can or yeah so you could you know flush or take snapshots and kind of work off of those um yeah these there's there's i think there's different options that we can kind of operationalize or productionalize these tools um if this is something that's interesting to you we'd you know love to chat more about it so you know please do reach out um yeah like if somebody's actually you know wanting to use this for real um i'm sad that data stacks i'd love to chat with you that's just seb of data stacks uh another question do do analytics in one batch and then switch to cassandra back in full replication so it catches up i guess there are different ways um but yeah i don't i don't think you you might not need to do like cassandra level replication to get the data out like you may like the whole kind of one of the advantages of this is you can just rsync the ss tables and you're done right um yeah you may be able to just rsync those ss tables um you might not you wouldn't need to you know use cassandra to stream the data across to another location so it may be simpler than what you're thinking there uh let's give us two thousand all right uh well it looks like that is most of the questions so i think we can uh move on uh was there anything else alex that you wanted to uh to talk about no that was it um yeah thanks so much to seven justin for answering those questions um yeah and just keeping an eye on the chat yeah that's it for me all right well i think uh then we can move on to our quiz there's nothing else let me uh switch over here all right so for those of you who are still with us looks like we still have most people which is great uh we're gonna do a short little quiz here uh where you can win some prizes uh at the end um and get some swag sent to you now uh we are going to be using mentee.com so you can see at the top of the page actually i'm going to break up a bigger slide so you go to menti.com you can use it on your phone uh you can scan that qr code if that's easy you also open a new tab and you can enter the code that you see on the screen also put it in the chat uh and you can join our quiz here it's gonna be a few questions it won't be very long um but the top three scorers uh will be eligible to win some swag and we ship the the prizes um all around the world so no matter where you are uh we can get it to you um so go ahead and go to mentee.com uh once you're there you can hit the there's like a little thumbs up if you want to hit that um we can see how many people are in let me go ahead and switch back all right we've got some people it's coming out of justin's head which is cool um all right we'll give a little bit of time make sure that everyone has an opportunity uh to join um i was going to mention something else and i'm blanking on it right now um set mentioned that uh that you can reach out to us i want to plug uh just briefly again our discord uh community i'll put that link in the chat as well um this is a place that you can kind of reach out to us and uh and ask more questions and stay in contact so that's a good place to join if you're interested in talking more about this topic or other topics cassandra specific topics be great all right it looks like we have most people in uh so let's get started with this quiz now something to note is that speed in answering the questions matters so the faster you answer uh correctly uh the more points you get so uh keep that in mind uh all right so there's only gonna be four questions and remember the top three scorers will win all right first question oops way too fast answer fast to get more points so what is the rapid equivalent of pandas qdf 2ml kugraf or qsignal remember to uh to watch your phone or the the tab that you're in because um there's a little bit of a latency on the stream as well all right most people got that correct it is qdf awesome let's see what our leaderboard looks like see the fastest answer was looks like bastian was the fastest this time awesome job all right question number two why are gpus more effective at data science than cpus they have better algorithms they have a larger ecosystem of libraries they can run many parallel operations simultaneously or they have more memory all right awesome yes they can run many parallel operations simultaneously and that makes them more effective all right let's see where our leaderboard looks like all right looks like g was the fastest this time sash takes the lead bastion is in second and skivvis is in third all right question three which one of the following is not the benefit of using sstable to arrow it reads data directly from files freeing up cassandra it helps you migrate existing python code using rapids it doesn't support all cassandra features it can read files from amazon s3 and from disk remember this is not a benefit which is which of the following is not the benefit all right yes it does not support currently all cassandra features it is definitely early in its development but it's very promising i think all right let's see what that does to our scores all right looks like we had a tie for fastest which is interesting g now takes the lead and d is in seconds give us maintains third place all right final question this is for all the marbles how does cassandra save data to the disk arrow ipc file format sorted string table files parquet files or json files all right yes sorted string table files or ss tables is the correct answer and let's see what that does for our score and remember if you are the top three winners uh take a screenshot of your uh of your screen where it says that you have um where you are in the top three and uh congratulations g to our overall winner and then d is in second and see this is in third make sure to take a screenshot of this page right here um and you're going to email jack.friar at datasacks.com i will put that in the uh if i can type in the in the chat and you can email uh jackdawfry your screen here your screenshot and uh you will be able to get some some swag sent to you he'll reach out to you for all the details that you need for that so awesome congratulations thank you all for uh joining us uh for this uh for this workshop and this webinar um and for participating in our little quiz here uh we really uh appreciate you uh joining us and uh unless there are any other questions uh i'll uh hand it back to our presenters for closing us out and we'll uh give you back the rest of your day great stuff thanks so much for coming everyone thank you so much alex's fearlessness and doing live coding good job it's not every day that somebody uh yeah goes for it like that yeah some courage for sure yeah well done well done everyone all right thanks everyone for joining us uh we hope you have a great evening really appreciate it man thank you yeah thanks for a special guest justin from nvidia uh have a great rest of your week everyone see it and as always don't forget to click that subscribe button and ring that bell to get notifications for all of our future upcoming workshops imagine a being gifted with powers from the goddess of cassandra who grew those powers until she could multiply it will move with limitless speed and unmask hidden knowledge with those powers she was able to fully understand the connectedness of the world what she saw was a world in need of understanding from that day forward she sought to bestow her powers on all who came into contact with her empowering them to achieve wondrous feats",
    "segments": [
      {
        "start": 24.29,
        "duration": 3.14,
        "text": "[Music]"
      },
      {
        "start": 36.82,
        "duration": 3.399,
        "text": "[Music]"
      },
      {
        "start": 86.37,
        "duration": 3.14,
        "text": "[Music]"
      },
      {
        "start": 98.9,
        "duration": 3.399,
        "text": "[Music]"
      },
      {
        "start": 112.14,
        "duration": 3.06,
        "text": "[Music]"
      },
      {
        "start": 148.45,
        "duration": 3.13,
        "text": "[Music]"
      },
      {
        "start": 160.98,
        "duration": 3.4,
        "text": "[Music]"
      },
      {
        "start": 210.53,
        "duration": 3.129,
        "text": "[Music]"
      },
      {
        "start": 223.22,
        "duration": 3.3,
        "text": "[Music]"
      },
      {
        "start": 236.36,
        "duration": 3.059,
        "text": "[Music]"
      },
      {
        "start": 286.4,
        "duration": 6.079,
        "text": "hello everyone and welcome to monday"
      },
      {
        "start": 289.759,
        "duration": 5.041,
        "text": "learning uh we are uh doing a workshop"
      },
      {
        "start": 292.479,
        "duration": 5.28,
        "text": "webinar on analyzing apache cassandra"
      },
      {
        "start": 294.8,
        "duration": 4.399,
        "text": "data with gpus and we are joined by some"
      },
      {
        "start": 297.759,
        "duration": 3.28,
        "text": "fantastic colleagues of mine and a"
      },
      {
        "start": 299.199,
        "duration": 2.641,
        "text": "special guest"
      },
      {
        "start": 301.039,
        "duration": 2.561,
        "text": "so"
      },
      {
        "start": 301.84,
        "duration": 3.52,
        "text": "it's without further ado if you guys can"
      },
      {
        "start": 303.6,
        "duration": 3.36,
        "text": "hear us and see us just fine why don't"
      },
      {
        "start": 305.36,
        "duration": 2.72,
        "text": "you give us a thumbs up in the chat just"
      },
      {
        "start": 306.96,
        "duration": 2.079,
        "text": "want to make sure that the stream is"
      },
      {
        "start": 308.08,
        "duration": 2.399,
        "text": "working"
      },
      {
        "start": 309.039,
        "duration": 3.921,
        "text": "well"
      },
      {
        "start": 310.479,
        "duration": 5.28,
        "text": "um but as we do that let me introduce"
      },
      {
        "start": 312.96,
        "duration": 4.16,
        "text": "you to some of our presenters"
      },
      {
        "start": 315.759,
        "duration": 3.201,
        "text": "all right let me make some make it"
      },
      {
        "start": 317.12,
        "duration": 4.0,
        "text": "smaller as well all right"
      },
      {
        "start": 318.96,
        "duration": 4.239,
        "text": "we have with us uh some of my uh"
      },
      {
        "start": 321.12,
        "duration": 3.68,
        "text": "colleagues here at datastax alex"
      },
      {
        "start": 323.199,
        "duration": 2.881,
        "text": "kai why don't you introduce yourself"
      },
      {
        "start": 324.8,
        "duration": 4.56,
        "text": "alex"
      },
      {
        "start": 326.08,
        "duration": 5.839,
        "text": "sure um so hi everyone i'm alex kai"
      },
      {
        "start": 329.36,
        "duration": 3.92,
        "text": "um i'm a software development intern"
      },
      {
        "start": 331.919,
        "duration": 3.361,
        "text": "here at data stacks i've been working"
      },
      {
        "start": 333.28,
        "duration": 4.24,
        "text": "here over the summer and yeah i'm pretty"
      },
      {
        "start": 335.28,
        "duration": 3.84,
        "text": "excited to show a little bit about what"
      },
      {
        "start": 337.52,
        "duration": 4.399,
        "text": "i've been working on hopefully you guys"
      },
      {
        "start": 339.12,
        "duration": 4.24,
        "text": "will find it exciting as well"
      },
      {
        "start": 341.919,
        "duration": 3.361,
        "text": "all right thanks alex and then we also"
      },
      {
        "start": 343.36,
        "duration": 4.88,
        "text": "have sebastian estevez"
      },
      {
        "start": 345.28,
        "duration": 5.68,
        "text": "hello sebastian how are you today"
      },
      {
        "start": 348.24,
        "duration": 4.88,
        "text": "hey folks how's everybody doing"
      },
      {
        "start": 350.96,
        "duration": 4.079,
        "text": "um yeah alice has been doing some great"
      },
      {
        "start": 353.12,
        "duration": 3.68,
        "text": "work for us and um"
      },
      {
        "start": 355.039,
        "duration": 3.521,
        "text": "yeah i've been with datastax a little"
      },
      {
        "start": 356.8,
        "duration": 3.92,
        "text": "bit longer than alex about"
      },
      {
        "start": 358.56,
        "duration": 3.28,
        "text": "uh seven to eight years"
      },
      {
        "start": 360.72,
        "duration": 3.44,
        "text": "great to spend some time today with you"
      },
      {
        "start": 361.84,
        "duration": 3.84,
        "text": "guys talking about analytics"
      },
      {
        "start": 364.16,
        "duration": 4.319,
        "text": "that'll be really fun and we have our"
      },
      {
        "start": 365.68,
        "duration": 4.32,
        "text": "special guest from nvidia welcome justin"
      },
      {
        "start": 368.479,
        "duration": 3.361,
        "text": "how are you"
      },
      {
        "start": 370.0,
        "duration": 4.08,
        "text": "doing great thanks everybody i'm really"
      },
      {
        "start": 371.84,
        "duration": 5.12,
        "text": "excited uh we've worked with alex and"
      },
      {
        "start": 374.08,
        "duration": 4.88,
        "text": "seb here to kind of integrate rapids"
      },
      {
        "start": 376.96,
        "duration": 3.76,
        "text": "uh to kind of show the full utility of"
      },
      {
        "start": 378.96,
        "duration": 3.92,
        "text": "what rapids can offer and i'm really"
      },
      {
        "start": 380.72,
        "duration": 4.4,
        "text": "excited to see what alex has done"
      },
      {
        "start": 382.88,
        "duration": 4.4,
        "text": "or at least have him show it so"
      },
      {
        "start": 385.12,
        "duration": 3.359,
        "text": "great work"
      },
      {
        "start": 387.28,
        "duration": 3.12,
        "text": "all right"
      },
      {
        "start": 388.479,
        "duration": 4.321,
        "text": "thanks so we have some thumbs up in the"
      },
      {
        "start": 390.4,
        "duration": 4.48,
        "text": "chat means we are coming through loud"
      },
      {
        "start": 392.8,
        "duration": 3.36,
        "text": "and clear all right let's get to some"
      },
      {
        "start": 394.88,
        "duration": 3.84,
        "text": "just a little bit of housekeeping i"
      },
      {
        "start": 396.16,
        "duration": 4.72,
        "text": "won't take too much uh time so we are"
      },
      {
        "start": 398.72,
        "duration": 4.64,
        "text": "streaming on youtube uh but if youtube"
      },
      {
        "start": 400.88,
        "duration": 4.48,
        "text": "has any issues like uh stream quality or"
      },
      {
        "start": 403.36,
        "duration": 3.92,
        "text": "latency or whatnot um we also have a"
      },
      {
        "start": 405.36,
        "duration": 3.52,
        "text": "backup stream on twitch now we don't"
      },
      {
        "start": 407.28,
        "duration": 3.68,
        "text": "monitor the chat on twitch so if you"
      },
      {
        "start": 408.88,
        "duration": 4.48,
        "text": "have questions make sure to use the"
      },
      {
        "start": 410.96,
        "duration": 5.359,
        "text": "youtube chat or if you would like to"
      },
      {
        "start": 413.36,
        "duration": 4.32,
        "text": "join our discord channel we have a a"
      },
      {
        "start": 416.319,
        "duration": 3.521,
        "text": "community growing community i think"
      },
      {
        "start": 417.68,
        "duration": 5.519,
        "text": "we're close to 20 000"
      },
      {
        "start": 419.84,
        "duration": 5.199,
        "text": "members now which is crazy i'll put some"
      },
      {
        "start": 423.199,
        "duration": 4.4,
        "text": "links in the chat for that you can join"
      },
      {
        "start": 425.039,
        "duration": 3.44,
        "text": "our discord you can also ask questions"
      },
      {
        "start": 427.599,
        "duration": 2.401,
        "text": "there"
      },
      {
        "start": 428.479,
        "duration": 3.521,
        "text": "you can ask more long-term questions"
      },
      {
        "start": 430.0,
        "duration": 4.96,
        "text": "maybe about cassandra specifically and"
      },
      {
        "start": 432.0,
        "duration": 4.479,
        "text": "we're pretty active in there as well"
      },
      {
        "start": 434.96,
        "duration": 4.16,
        "text": "uh today we are going to do some"
      },
      {
        "start": 436.479,
        "duration": 4.641,
        "text": "hands-on we're also going to do a uh a"
      },
      {
        "start": 439.12,
        "duration": 4.4,
        "text": "quiz at the end where you have an"
      },
      {
        "start": 441.12,
        "duration": 4.4,
        "text": "opportunity to win some prizes some swag"
      },
      {
        "start": 443.52,
        "duration": 3.519,
        "text": "uh so we'll be doing a kind of a game at"
      },
      {
        "start": 445.52,
        "duration": 4.079,
        "text": "the end there so stick around for that"
      },
      {
        "start": 447.039,
        "duration": 4.401,
        "text": "we'll have more information on on how to"
      },
      {
        "start": 449.599,
        "duration": 3.521,
        "text": "do that but we'll be using a online tool"
      },
      {
        "start": 451.44,
        "duration": 3.199,
        "text": "called mentee"
      },
      {
        "start": 453.12,
        "duration": 3.84,
        "text": "it's really easy to use and we'll walk"
      },
      {
        "start": 454.639,
        "duration": 5.12,
        "text": "you through that when we get to it"
      },
      {
        "start": 456.96,
        "duration": 5.679,
        "text": "all right so for the hands-on a few"
      },
      {
        "start": 459.759,
        "duration": 5.601,
        "text": "things to note uh we will be using a"
      },
      {
        "start": 462.639,
        "duration": 4.081,
        "text": "github repo i'll put the link in the uh"
      },
      {
        "start": 465.36,
        "duration": 3.92,
        "text": "in the chat"
      },
      {
        "start": 466.72,
        "duration": 4.479,
        "text": "uh for you right now"
      },
      {
        "start": 469.28,
        "duration": 3.44,
        "text": "everything that you need is is there and"
      },
      {
        "start": 471.199,
        "duration": 3.521,
        "text": "and when uh when we go through the"
      },
      {
        "start": 472.72,
        "duration": 5.44,
        "text": "hands-on we'll kind of walk through"
      },
      {
        "start": 474.72,
        "duration": 5.199,
        "text": "um that you will need docker uh in order"
      },
      {
        "start": 478.16,
        "duration": 3.599,
        "text": "to run the hands-on if you don't have"
      },
      {
        "start": 479.919,
        "duration": 4.56,
        "text": "docker feel free to either just sit back"
      },
      {
        "start": 481.759,
        "duration": 4.88,
        "text": "and watch and learn or if you'd like to"
      },
      {
        "start": 484.479,
        "duration": 2.961,
        "text": "uh install docker"
      },
      {
        "start": 486.639,
        "duration": 2.161,
        "text": "while we're going through some of the"
      },
      {
        "start": 487.44,
        "duration": 3.28,
        "text": "content it shouldn't take too long so"
      },
      {
        "start": 488.8,
        "duration": 5.04,
        "text": "you can do that as well but you do need"
      },
      {
        "start": 490.72,
        "duration": 4.479,
        "text": "docker to uh do the hands-on"
      },
      {
        "start": 493.84,
        "duration": 3.199,
        "text": "all right"
      },
      {
        "start": 495.199,
        "duration": 3.761,
        "text": "without further ado"
      },
      {
        "start": 497.039,
        "duration": 3.28,
        "text": "it's probably a good idea if you if you"
      },
      {
        "start": 498.96,
        "duration": 3.76,
        "text": "are gonna do the hands-on"
      },
      {
        "start": 500.319,
        "duration": 4.081,
        "text": "to pull up uh"
      },
      {
        "start": 502.72,
        "duration": 3.199,
        "text": "the readme that ryan shared and actually"
      },
      {
        "start": 504.4,
        "duration": 2.88,
        "text": "run that docker pull command because"
      },
      {
        "start": 505.919,
        "duration": 3.521,
        "text": "it's going to take a few minutes to pull"
      },
      {
        "start": 507.28,
        "duration": 4.24,
        "text": "depending on your internet connection"
      },
      {
        "start": 509.44,
        "duration": 3.839,
        "text": "so if you want to start on that"
      },
      {
        "start": 511.52,
        "duration": 3.04,
        "text": "while alex gets us started that's a good"
      },
      {
        "start": 513.279,
        "duration": 3.041,
        "text": "idea yeah that's a good point it's a"
      },
      {
        "start": 514.56,
        "duration": 3.039,
        "text": "little bit it's a pretty big docker so"
      },
      {
        "start": 516.32,
        "duration": 2.32,
        "text": "uh if you are interested in doing the"
      },
      {
        "start": 517.599,
        "duration": 3.841,
        "text": "hands-on"
      },
      {
        "start": 518.64,
        "duration": 3.92,
        "text": "go to that github link and uh get it"
      },
      {
        "start": 521.44,
        "duration": 2.64,
        "text": "started"
      },
      {
        "start": 522.56,
        "duration": 2.959,
        "text": "to download now"
      },
      {
        "start": 524.08,
        "duration": 3.28,
        "text": "so that you'll be ready"
      },
      {
        "start": 525.519,
        "duration": 3.681,
        "text": "all right"
      },
      {
        "start": 527.36,
        "duration": 3.44,
        "text": "with that without further ado let me"
      },
      {
        "start": 529.2,
        "duration": 3.92,
        "text": "hand it over to"
      },
      {
        "start": 530.8,
        "duration": 4.4,
        "text": "alex who's gonna present"
      },
      {
        "start": 533.12,
        "duration": 3.92,
        "text": "our content today"
      },
      {
        "start": 535.2,
        "duration": 2.8,
        "text": "sweet okay all right so take it away hi"
      },
      {
        "start": 537.04,
        "duration": 4.239,
        "text": "everyone"
      },
      {
        "start": 538.0,
        "duration": 5.839,
        "text": "um yeah i'm alex um and yeah today i'll"
      },
      {
        "start": 541.279,
        "duration": 4.961,
        "text": "be talking a little bit about gpu"
      },
      {
        "start": 543.839,
        "duration": 4.641,
        "text": "accelerated analytic queries on"
      },
      {
        "start": 546.24,
        "duration": 4.24,
        "text": "cassandra with rapids so if there's"
      },
      {
        "start": 548.48,
        "duration": 3.919,
        "text": "words there that you don't recognize um"
      },
      {
        "start": 550.48,
        "duration": 3.44,
        "text": "don't worry we'll go through them"
      },
      {
        "start": 552.399,
        "duration": 2.88,
        "text": "throughout this presentation and"
      },
      {
        "start": 553.92,
        "duration": 3.599,
        "text": "hopefully by the end you'll have a good"
      },
      {
        "start": 555.279,
        "duration": 3.521,
        "text": "sense of what it is exactly that we've"
      },
      {
        "start": 557.519,
        "duration": 3.521,
        "text": "been working on"
      },
      {
        "start": 558.8,
        "duration": 4.64,
        "text": "um so today we're gonna have sort of"
      },
      {
        "start": 561.04,
        "duration": 4.239,
        "text": "four main sections so first off i'll"
      },
      {
        "start": 563.44,
        "duration": 4.64,
        "text": "talk a little bit about ss table to"
      },
      {
        "start": 565.279,
        "duration": 5.12,
        "text": "arrow um what it sort of does what"
      },
      {
        "start": 568.08,
        "duration": 5.36,
        "text": "problems it solves um then we'll talk a"
      },
      {
        "start": 570.399,
        "duration": 5.201,
        "text": "little bit about rapids um which is um"
      },
      {
        "start": 573.44,
        "duration": 4.959,
        "text": "or what it is we'll get to it in a bit"
      },
      {
        "start": 575.6,
        "duration": 4.88,
        "text": "um but it's essentially some open source"
      },
      {
        "start": 578.399,
        "duration": 4.56,
        "text": "python libraries that can help you run"
      },
      {
        "start": 580.48,
        "duration": 5.68,
        "text": "data analytics on a gpu"
      },
      {
        "start": 582.959,
        "duration": 5.761,
        "text": "finally um or not finally sorry thirdly"
      },
      {
        "start": 586.16,
        "duration": 5.04,
        "text": "we will go ahead do the hands-on demo"
      },
      {
        "start": 588.72,
        "duration": 4.4,
        "text": "with ss table to arrow so make sure yeah"
      },
      {
        "start": 591.2,
        "duration": 3.52,
        "text": "you start pulling that docker container"
      },
      {
        "start": 593.12,
        "duration": 3.279,
        "text": "or the docker image because it is pretty"
      },
      {
        "start": 594.72,
        "duration": 4.16,
        "text": "big my apologies"
      },
      {
        "start": 596.399,
        "duration": 3.361,
        "text": "um and then finally we'll do a little um"
      },
      {
        "start": 598.88,
        "duration": 3.12,
        "text": "demo"
      },
      {
        "start": 599.76,
        "duration": 5.36,
        "text": "and um of how"
      },
      {
        "start": 602.0,
        "duration": 5.839,
        "text": "asus table to arrow works with rapids um"
      },
      {
        "start": 605.12,
        "duration": 5.839,
        "text": "and so since this only works on"
      },
      {
        "start": 607.839,
        "duration": 4.801,
        "text": "machines that have cuda support so with"
      },
      {
        "start": 610.959,
        "duration": 2.88,
        "text": "a gpu um"
      },
      {
        "start": 612.64,
        "duration": 3.36,
        "text": "i'm guessing that most of you will"
      },
      {
        "start": 613.839,
        "duration": 4.161,
        "text": "probably not be able to follow along"
      },
      {
        "start": 616.0,
        "duration": 4.64,
        "text": "unfortunately um so this will just be a"
      },
      {
        "start": 618.0,
        "duration": 5.44,
        "text": "sort of demo uh to show what esses"
      },
      {
        "start": 620.64,
        "duration": 3.84,
        "text": "staple to arrow is capable of"
      },
      {
        "start": 623.44,
        "duration": 3.36,
        "text": "all right"
      },
      {
        "start": 624.48,
        "duration": 5.44,
        "text": "let's go ahead and get started with"
      },
      {
        "start": 626.8,
        "duration": 5.36,
        "text": "um introducing asus table to arrow"
      },
      {
        "start": 629.92,
        "duration": 4.8,
        "text": "so first off hopefully you guys are all"
      },
      {
        "start": 632.16,
        "duration": 4.88,
        "text": "here because of how awesome cassandra is"
      },
      {
        "start": 634.72,
        "duration": 4.239,
        "text": "um and if you guys haven't heard of it"
      },
      {
        "start": 637.04,
        "duration": 4.96,
        "text": "before now is a great time to get"
      },
      {
        "start": 638.959,
        "duration": 4.241,
        "text": "started um because cassandra 4.0 has"
      },
      {
        "start": 642.0,
        "duration": 3.2,
        "text": "just released"
      },
      {
        "start": 643.2,
        "duration": 3.52,
        "text": "which is pretty exciting and i'll talk a"
      },
      {
        "start": 645.2,
        "duration": 4.639,
        "text": "bit about what that means"
      },
      {
        "start": 646.72,
        "duration": 6.08,
        "text": "so cassandra just to recap is an open"
      },
      {
        "start": 649.839,
        "duration": 4.881,
        "text": "source nosql distributed database and"
      },
      {
        "start": 652.8,
        "duration": 4.479,
        "text": "because it's distributed and that means"
      },
      {
        "start": 654.72,
        "duration": 5.119,
        "text": "the data is replicated across many nodes"
      },
      {
        "start": 657.279,
        "duration": 4.8,
        "text": "it has massive horizontal scalability"
      },
      {
        "start": 659.839,
        "duration": 4.56,
        "text": "it's extremely reliable and also very"
      },
      {
        "start": 662.079,
        "duration": 4.561,
        "text": "false tolerant so if you're building"
      },
      {
        "start": 664.399,
        "duration": 3.761,
        "text": "really large applications cassandra is a"
      },
      {
        "start": 666.64,
        "duration": 3.92,
        "text": "great choice because it can make sure"
      },
      {
        "start": 668.16,
        "duration": 4.08,
        "text": "your data is always available and really"
      },
      {
        "start": 670.56,
        "duration": 3.44,
        "text": "easy to access"
      },
      {
        "start": 672.24,
        "duration": 4.48,
        "text": "we here at datastax have been really"
      },
      {
        "start": 674.0,
        "duration": 4.079,
        "text": "closely connected with cassandra um"
      },
      {
        "start": 676.72,
        "duration": 4.239,
        "text": "we're sort of one of the leading"
      },
      {
        "start": 678.079,
        "duration": 4.721,
        "text": "cassandra experts and we also offer"
      },
      {
        "start": 680.959,
        "duration": 4.401,
        "text": "serverless cassandra as a service"
      },
      {
        "start": 682.8,
        "duration": 4.88,
        "text": "through datastax astra um and yeah like"
      },
      {
        "start": 685.36,
        "duration": 3.52,
        "text": "i just mentioned 4.0 just released so if"
      },
      {
        "start": 687.68,
        "duration": 3.599,
        "text": "you're just getting started with"
      },
      {
        "start": 688.88,
        "duration": 3.68,
        "text": "cassandra now is a great time to check"
      },
      {
        "start": 691.279,
        "duration": 2.161,
        "text": "it out"
      },
      {
        "start": 692.56,
        "duration": 3.12,
        "text": "okay"
      },
      {
        "start": 693.44,
        "duration": 4.079,
        "text": "so cassandra is great for transactional"
      },
      {
        "start": 695.68,
        "duration": 4.56,
        "text": "queries so those are queries that"
      },
      {
        "start": 697.519,
        "duration": 4.641,
        "text": "essentially um look at maybe one row or"
      },
      {
        "start": 700.24,
        "duration": 4.08,
        "text": "a couple rows inside the database for"
      },
      {
        "start": 702.16,
        "duration": 5.2,
        "text": "example if you wanted to ask"
      },
      {
        "start": 704.32,
        "duration": 5.12,
        "text": "i have this user id can you get me their"
      },
      {
        "start": 707.36,
        "duration": 4.0,
        "text": "username for example that would be an"
      },
      {
        "start": 709.44,
        "duration": 3.519,
        "text": "example of a transactional query and"
      },
      {
        "start": 711.36,
        "duration": 3.2,
        "text": "cassandra is really good at those it can"
      },
      {
        "start": 712.959,
        "duration": 3.201,
        "text": "search through the table get you the"
      },
      {
        "start": 714.56,
        "duration": 4.8,
        "text": "information that you need really really"
      },
      {
        "start": 716.16,
        "duration": 5.44,
        "text": "quickly um but what if um let's say you"
      },
      {
        "start": 719.36,
        "duration": 4.4,
        "text": "already have a lot of data collected in"
      },
      {
        "start": 721.6,
        "duration": 4.239,
        "text": "your cassandra table and you decide that"
      },
      {
        "start": 723.76,
        "duration": 4.079,
        "text": "you want to do analytics on it so this"
      },
      {
        "start": 725.839,
        "duration": 3.12,
        "text": "could include things like statistics it"
      },
      {
        "start": 727.839,
        "duration": 3.44,
        "text": "could include things like machine"
      },
      {
        "start": 728.959,
        "duration": 4.481,
        "text": "learning so what if you want to do"
      },
      {
        "start": 731.279,
        "duration": 3.921,
        "text": "analytics like machine learning on that"
      },
      {
        "start": 733.44,
        "duration": 2.72,
        "text": "data"
      },
      {
        "start": 735.2,
        "duration": 3.199,
        "text": "so"
      },
      {
        "start": 736.16,
        "duration": 4.479,
        "text": "since cassandra itself isn't really"
      },
      {
        "start": 738.399,
        "duration": 5.041,
        "text": "natively really good at this there are a"
      },
      {
        "start": 740.639,
        "duration": 5.281,
        "text": "couple external sort of tools you could"
      },
      {
        "start": 743.44,
        "duration": 4.8,
        "text": "use to get that working so one tool that"
      },
      {
        "start": 745.92,
        "duration": 5.599,
        "text": "a lot of people use already is apache"
      },
      {
        "start": 748.24,
        "duration": 4.88,
        "text": "spark and apache spark is a parallel"
      },
      {
        "start": 751.519,
        "duration": 3.12,
        "text": "processing framework for doing"
      },
      {
        "start": 753.12,
        "duration": 2.64,
        "text": "distributed computing so it's"
      },
      {
        "start": 754.639,
        "duration": 2.801,
        "text": "essentially"
      },
      {
        "start": 755.76,
        "duration": 3.44,
        "text": "very similar to cassandra it's"
      },
      {
        "start": 757.44,
        "duration": 3.839,
        "text": "distributed so it takes place across"
      },
      {
        "start": 759.2,
        "duration": 4.4,
        "text": "many nodes and allows you to do those"
      },
      {
        "start": 761.279,
        "duration": 3.441,
        "text": "sorts of big data operations"
      },
      {
        "start": 763.6,
        "duration": 2.239,
        "text": "effectively"
      },
      {
        "start": 764.72,
        "duration": 3.44,
        "text": "however"
      },
      {
        "start": 765.839,
        "duration": 5.601,
        "text": "in case you haven't used spark before it"
      },
      {
        "start": 768.16,
        "duration": 5.44,
        "text": "can take some effort to set up and also"
      },
      {
        "start": 771.44,
        "duration": 4.8,
        "text": "what if you have an existing analytics"
      },
      {
        "start": 773.6,
        "duration": 4.72,
        "text": "workflow using python libraries that you"
      },
      {
        "start": 776.24,
        "duration": 4.56,
        "text": "want to run on cassandra data so"
      },
      {
        "start": 778.32,
        "duration": 4.24,
        "text": "nowadays python is sort of the de facto"
      },
      {
        "start": 780.8,
        "duration": 3.92,
        "text": "standard for doing"
      },
      {
        "start": 782.56,
        "duration": 4.24,
        "text": "machine learning and things like that um"
      },
      {
        "start": 784.72,
        "duration": 5.84,
        "text": "so you're probably familiar with names"
      },
      {
        "start": 786.8,
        "duration": 5.68,
        "text": "like pandas numpy maybe scikit-learn"
      },
      {
        "start": 790.56,
        "duration": 4.56,
        "text": "what if you already have code using"
      },
      {
        "start": 792.48,
        "duration": 5.359,
        "text": "these libraries that you want to run on"
      },
      {
        "start": 795.12,
        "duration": 4.719,
        "text": "data from cassandra so in that case you"
      },
      {
        "start": 797.839,
        "duration": 4.401,
        "text": "can fetch the data from your cassandra"
      },
      {
        "start": 799.839,
        "duration": 4.481,
        "text": "table using a driver"
      },
      {
        "start": 802.24,
        "duration": 3.76,
        "text": "and then run analytics on that data so"
      },
      {
        "start": 804.32,
        "duration": 4.24,
        "text": "you can see here on the screen we have a"
      },
      {
        "start": 806.0,
        "duration": 5.12,
        "text": "little example of what that looks like"
      },
      {
        "start": 808.56,
        "duration": 4.24,
        "text": "you can essentially use python connect"
      },
      {
        "start": 811.12,
        "duration": 3.6,
        "text": "to that cluster"
      },
      {
        "start": 812.8,
        "duration": 4.56,
        "text": "transform the data into a pandas data"
      },
      {
        "start": 814.72,
        "duration": 4.88,
        "text": "frame and then do whatever analytics you"
      },
      {
        "start": 817.36,
        "duration": 4.479,
        "text": "want on it and this is a pretty small"
      },
      {
        "start": 819.6,
        "duration": 4.96,
        "text": "example getting like the mean of a"
      },
      {
        "start": 821.839,
        "duration": 4.56,
        "text": "couple columns um but you can imagine"
      },
      {
        "start": 824.56,
        "duration": 4.719,
        "text": "this would integrate right away with"
      },
      {
        "start": 826.399,
        "duration": 4.481,
        "text": "things like scikit-learn"
      },
      {
        "start": 829.279,
        "duration": 3.041,
        "text": "numpy other libraries that you might"
      },
      {
        "start": 830.88,
        "duration": 2.56,
        "text": "need"
      },
      {
        "start": 832.32,
        "duration": 3.759,
        "text": "however"
      },
      {
        "start": 833.44,
        "duration": 4.88,
        "text": "using uh that second approach using the"
      },
      {
        "start": 836.079,
        "duration": 5.12,
        "text": "cassandra driver does have some"
      },
      {
        "start": 838.32,
        "duration": 5.04,
        "text": "drawbacks so for large data sets"
      },
      {
        "start": 841.199,
        "duration": 3.681,
        "text": "if you want if you're querying the"
      },
      {
        "start": 843.36,
        "duration": 3.76,
        "text": "entire data set"
      },
      {
        "start": 844.88,
        "duration": 4.48,
        "text": "it can be expensive and we don't want to"
      },
      {
        "start": 847.12,
        "duration": 4.8,
        "text": "slow down our transactional operations"
      },
      {
        "start": 849.36,
        "duration": 4.56,
        "text": "imagine you're some big company and your"
      },
      {
        "start": 851.92,
        "duration": 3.76,
        "text": "users are using for example some"
      },
      {
        "start": 853.92,
        "duration": 4.56,
        "text": "real-time application that queries your"
      },
      {
        "start": 855.68,
        "duration": 3.839,
        "text": "cassandra table well if while they're"
      },
      {
        "start": 858.48,
        "duration": 2.96,
        "text": "querying"
      },
      {
        "start": 859.519,
        "duration": 4.56,
        "text": "their cassandra table in that real-time"
      },
      {
        "start": 861.44,
        "duration": 4.639,
        "text": "application if you're sort of asking the"
      },
      {
        "start": 864.079,
        "duration": 3.2,
        "text": "database to do this really really big"
      },
      {
        "start": 866.079,
        "duration": 3.041,
        "text": "operation"
      },
      {
        "start": 867.279,
        "duration": 3.601,
        "text": "it's going to slow down that sort of"
      },
      {
        "start": 869.12,
        "duration": 4.159,
        "text": "real-time experience and we don't really"
      },
      {
        "start": 870.88,
        "duration": 5.759,
        "text": "want that right because that's bad user"
      },
      {
        "start": 873.279,
        "duration": 5.521,
        "text": "experience um so how can we extract data"
      },
      {
        "start": 876.639,
        "duration": 4.241,
        "text": "from cassandra without"
      },
      {
        "start": 878.8,
        "duration": 3.92,
        "text": "using our main cassandra cluster because"
      },
      {
        "start": 880.88,
        "duration": 4.0,
        "text": "remember we don't really want to put a"
      },
      {
        "start": 882.72,
        "duration": 4.64,
        "text": "load on our cassandra database our"
      },
      {
        "start": 884.88,
        "duration": 5.12,
        "text": "cassandra cluster so we want to extract"
      },
      {
        "start": 887.36,
        "duration": 4.08,
        "text": "the data directly somehow"
      },
      {
        "start": 890.0,
        "duration": 3.04,
        "text": "so how to do this"
      },
      {
        "start": 891.44,
        "duration": 4.959,
        "text": "let's take a look at how cassandra"
      },
      {
        "start": 893.04,
        "duration": 5.84,
        "text": "manages data under the hood"
      },
      {
        "start": 896.399,
        "duration": 5.041,
        "text": "so cassandra um"
      },
      {
        "start": 898.88,
        "duration": 4.959,
        "text": "it stores most of its data inside memory"
      },
      {
        "start": 901.44,
        "duration": 4.56,
        "text": "so memory tables um when you actually"
      },
      {
        "start": 903.839,
        "duration": 5.201,
        "text": "query the database that's what it uses"
      },
      {
        "start": 906.0,
        "duration": 5.6,
        "text": "but when you save the file um or when"
      },
      {
        "start": 909.04,
        "duration": 5.359,
        "text": "you save the data to the disk if you"
      },
      {
        "start": 911.6,
        "duration": 6.08,
        "text": "want to persist it for long-term storage"
      },
      {
        "start": 914.399,
        "duration": 5.44,
        "text": "um it stores it in the form of ss tables"
      },
      {
        "start": 917.68,
        "duration": 4.32,
        "text": "or sorted string tables and you can see"
      },
      {
        "start": 919.839,
        "duration": 4.401,
        "text": "here on the left an ss table is"
      },
      {
        "start": 922.0,
        "duration": 3.92,
        "text": "essentially this big collection of a"
      },
      {
        "start": 924.24,
        "duration": 3.44,
        "text": "bunch of different files you can see we"
      },
      {
        "start": 925.92,
        "duration": 3.12,
        "text": "have some compression info we have the"
      },
      {
        "start": 927.68,
        "duration": 3.44,
        "text": "actual data"
      },
      {
        "start": 929.04,
        "duration": 4.56,
        "text": "some statistics about the data all of"
      },
      {
        "start": 931.12,
        "duration": 4.88,
        "text": "that is stored in these ss tables and"
      },
      {
        "start": 933.6,
        "duration": 5.359,
        "text": "cassandra what it does is parse the ss"
      },
      {
        "start": 936.0,
        "duration": 5.519,
        "text": "tables to get that data and then um send"
      },
      {
        "start": 938.959,
        "duration": 5.12,
        "text": "it to you whether you're using sql or"
      },
      {
        "start": 941.519,
        "duration": 4.641,
        "text": "you're using a cassandra driver"
      },
      {
        "start": 944.079,
        "duration": 4.721,
        "text": "but like we said earlier"
      },
      {
        "start": 946.16,
        "duration": 4.799,
        "text": "we don't want to put load on"
      },
      {
        "start": 948.8,
        "duration": 4.56,
        "text": "our cassandra database so the question"
      },
      {
        "start": 950.959,
        "duration": 5.521,
        "text": "is can we fetch data directly from the"
      },
      {
        "start": 953.36,
        "duration": 5.839,
        "text": "asset tables without using cassandra"
      },
      {
        "start": 956.48,
        "duration": 5.279,
        "text": "and this is what i've been spending most"
      },
      {
        "start": 959.199,
        "duration": 4.64,
        "text": "of the summer working on because"
      },
      {
        "start": 961.759,
        "duration": 4.801,
        "text": "it's not so easy um so here's a few"
      },
      {
        "start": 963.839,
        "duration": 5.041,
        "text": "diagrams of what ss table files kind of"
      },
      {
        "start": 966.56,
        "duration": 5.839,
        "text": "look like internally um this is all"
      },
      {
        "start": 968.88,
        "duration": 4.72,
        "text": "binary data so sort of ones and zeros um"
      },
      {
        "start": 972.399,
        "duration": 4.081,
        "text": "so i sort of read through the"
      },
      {
        "start": 973.6,
        "duration": 4.479,
        "text": "documentation figured out how to um"
      },
      {
        "start": 976.48,
        "duration": 2.64,
        "text": "parse everything out"
      },
      {
        "start": 978.079,
        "duration": 2.721,
        "text": "um"
      },
      {
        "start": 979.12,
        "duration": 3.519,
        "text": "but even though it's difficult of course"
      },
      {
        "start": 980.8,
        "duration": 3.599,
        "text": "it's possible right because how else"
      },
      {
        "start": 982.639,
        "duration": 2.721,
        "text": "would cassandra work"
      },
      {
        "start": 984.399,
        "duration": 3.521,
        "text": "so"
      },
      {
        "start": 985.36,
        "duration": 5.68,
        "text": "this is kind of what s's table to arrow"
      },
      {
        "start": 987.92,
        "duration": 6.64,
        "text": "is for so ss table to arrow is a tool"
      },
      {
        "start": 991.04,
        "duration": 4.32,
        "text": "that parses data directly from ss tables"
      },
      {
        "start": 994.56,
        "duration": 2.8,
        "text": "and"
      },
      {
        "start": 995.36,
        "duration": 3.599,
        "text": "i have here a little example of the"
      },
      {
        "start": 997.36,
        "duration": 3.039,
        "text": "docker command don't worry about it"
      },
      {
        "start": 998.959,
        "duration": 4.24,
        "text": "we'll get to that in a second during the"
      },
      {
        "start": 1000.399,
        "duration": 6.401,
        "text": "hands-on demo um and it's open source so"
      },
      {
        "start": 1003.199,
        "duration": 6.481,
        "text": "you can go ahead um find it on github um"
      },
      {
        "start": 1006.8,
        "duration": 4.32,
        "text": "look at my source code if you if you if"
      },
      {
        "start": 1009.68,
        "duration": 2.399,
        "text": "you're so inclined"
      },
      {
        "start": 1011.12,
        "duration": 3.6,
        "text": "um"
      },
      {
        "start": 1012.079,
        "duration": 4.721,
        "text": "and yeah so essentially that's the"
      },
      {
        "start": 1014.72,
        "duration": 4.239,
        "text": "essence of what sstable to arrow is for"
      },
      {
        "start": 1016.8,
        "duration": 4.24,
        "text": "it can read those ss tables directly"
      },
      {
        "start": 1018.959,
        "duration": 4.56,
        "text": "without having to go through cassandra"
      },
      {
        "start": 1021.04,
        "duration": 4.399,
        "text": "and then it transforms the data into"
      },
      {
        "start": 1023.519,
        "duration": 3.92,
        "text": "this format called arrow which we'll"
      },
      {
        "start": 1025.439,
        "duration": 3.12,
        "text": "talk about in a second"
      },
      {
        "start": 1027.439,
        "duration": 2.561,
        "text": "so"
      },
      {
        "start": 1028.559,
        "duration": 4.4,
        "text": "um"
      },
      {
        "start": 1030.0,
        "duration": 5.039,
        "text": "oh i missed the recap so just to recap"
      },
      {
        "start": 1032.959,
        "duration": 4.801,
        "text": "let's say you have a lot of data stored"
      },
      {
        "start": 1035.039,
        "duration": 4.64,
        "text": "in cassandra inside a cassandra table"
      },
      {
        "start": 1037.76,
        "duration": 4.4,
        "text": "and everything has been going well for"
      },
      {
        "start": 1039.679,
        "duration": 4.321,
        "text": "your transactional needs so for example"
      },
      {
        "start": 1042.16,
        "duration": 3.039,
        "text": "real-time applications that are querying"
      },
      {
        "start": 1044.0,
        "duration": 2.88,
        "text": "that table"
      },
      {
        "start": 1045.199,
        "duration": 4.241,
        "text": "all of that's going great"
      },
      {
        "start": 1046.88,
        "duration": 4.56,
        "text": "but one day you ask"
      },
      {
        "start": 1049.44,
        "duration": 4.56,
        "text": "how can i extract insights from this"
      },
      {
        "start": 1051.44,
        "duration": 5.52,
        "text": "data using analytics"
      },
      {
        "start": 1054.0,
        "duration": 4.96,
        "text": "and previously or you still have these"
      },
      {
        "start": 1056.96,
        "duration": 5.44,
        "text": "but of course s's table to arrow is a"
      },
      {
        "start": 1058.96,
        "duration": 5.599,
        "text": "different option so you have two sort of"
      },
      {
        "start": 1062.4,
        "duration": 3.76,
        "text": "main options firstly"
      },
      {
        "start": 1064.559,
        "duration": 2.401,
        "text": "if you're using data stocks enterprise"
      },
      {
        "start": 1066.16,
        "duration": 3.36,
        "text": "or"
      },
      {
        "start": 1066.96,
        "duration": 5.12,
        "text": "cassandra open source also works too"
      },
      {
        "start": 1069.52,
        "duration": 4.399,
        "text": "you can use apache spark which is once"
      },
      {
        "start": 1072.08,
        "duration": 3.04,
        "text": "again a distributed framework for"
      },
      {
        "start": 1073.919,
        "duration": 3.76,
        "text": "computation"
      },
      {
        "start": 1075.12,
        "duration": 4.64,
        "text": "so distributes your computation across"
      },
      {
        "start": 1077.679,
        "duration": 6.161,
        "text": "many different nodes and that allows you"
      },
      {
        "start": 1079.76,
        "duration": 5.52,
        "text": "to scale and do that sort of analytics"
      },
      {
        "start": 1083.84,
        "duration": 4.24,
        "text": "really efficiently"
      },
      {
        "start": 1085.28,
        "duration": 4.72,
        "text": "but this does require a lot of setup and"
      },
      {
        "start": 1088.08,
        "duration": 3.839,
        "text": "you would need to migrate existing"
      },
      {
        "start": 1090.0,
        "duration": 3.12,
        "text": "analytics code that isn't written with"
      },
      {
        "start": 1091.919,
        "duration": 2.721,
        "text": "spark"
      },
      {
        "start": 1093.12,
        "duration": 3.679,
        "text": "excuse me"
      },
      {
        "start": 1094.64,
        "duration": 3.279,
        "text": "so if you have existing python code for"
      },
      {
        "start": 1096.799,
        "duration": 3.841,
        "text": "example"
      },
      {
        "start": 1097.919,
        "duration": 5.12,
        "text": "using things like numpy or scikit-learn"
      },
      {
        "start": 1100.64,
        "duration": 5.039,
        "text": "you would need to migrate that into"
      },
      {
        "start": 1103.039,
        "duration": 4.721,
        "text": "spark code"
      },
      {
        "start": 1105.679,
        "duration": 4.24,
        "text": "the other option is you could fetch all"
      },
      {
        "start": 1107.76,
        "duration": 4.24,
        "text": "of the data using a driver and then run"
      },
      {
        "start": 1109.919,
        "duration": 2.961,
        "text": "analytics on it using your framework of"
      },
      {
        "start": 1112.0,
        "duration": 3.2,
        "text": "choice"
      },
      {
        "start": 1112.88,
        "duration": 4.72,
        "text": "but this requires querying the cassandra"
      },
      {
        "start": 1115.2,
        "duration": 4.24,
        "text": "cluster which will slow down your"
      },
      {
        "start": 1117.6,
        "duration": 3.439,
        "text": "transactional operations which once"
      },
      {
        "start": 1119.44,
        "duration": 3.599,
        "text": "again we don't we don't want we need"
      },
      {
        "start": 1121.039,
        "duration": 3.52,
        "text": "those transactional operations to be"
      },
      {
        "start": 1123.039,
        "duration": 4.161,
        "text": "lightning fast"
      },
      {
        "start": 1124.559,
        "duration": 4.48,
        "text": "but now with ss table to arrow as long"
      },
      {
        "start": 1127.2,
        "duration": 4.0,
        "text": "as you have access to the underlying ss"
      },
      {
        "start": 1129.039,
        "duration": 4.161,
        "text": "tables you can easily query for that"
      },
      {
        "start": 1131.2,
        "duration": 4.8,
        "text": "data without burdening your instance of"
      },
      {
        "start": 1133.2,
        "duration": 5.599,
        "text": "cassandra and you can easily migrate"
      },
      {
        "start": 1136.0,
        "duration": 4.72,
        "text": "existing python analytics code using"
      },
      {
        "start": 1138.799,
        "duration": 4.561,
        "text": "rapids okay so"
      },
      {
        "start": 1140.72,
        "duration": 5.6,
        "text": "um now let's take a look at what is"
      },
      {
        "start": 1143.36,
        "duration": 4.48,
        "text": "rapids and why should i use it or why"
      },
      {
        "start": 1146.32,
        "duration": 4.239,
        "text": "should you use it"
      },
      {
        "start": 1147.84,
        "duration": 6.64,
        "text": "um and yeah this will be a look into gpu"
      },
      {
        "start": 1150.559,
        "duration": 4.801,
        "text": "analytics using the rapids ecosystem"
      },
      {
        "start": 1154.48,
        "duration": 3.6,
        "text": "so"
      },
      {
        "start": 1155.36,
        "duration": 5.76,
        "text": "rapids is a suite of open source"
      },
      {
        "start": 1158.08,
        "duration": 5.68,
        "text": "software libraries um and it enables"
      },
      {
        "start": 1161.12,
        "duration": 3.76,
        "text": "end-to-end data science and analytics"
      },
      {
        "start": 1163.76,
        "duration": 3.76,
        "text": "pipelines"
      },
      {
        "start": 1164.88,
        "duration": 5.36,
        "text": "entirely on gpus"
      },
      {
        "start": 1167.52,
        "duration": 5.519,
        "text": "and under the hood it uses nvidia cuda"
      },
      {
        "start": 1170.24,
        "duration": 3.92,
        "text": "to optimize low level compute so cuda is"
      },
      {
        "start": 1173.039,
        "duration": 4.0,
        "text": "essentially"
      },
      {
        "start": 1174.16,
        "duration": 4.8,
        "text": "a programming toolkit language"
      },
      {
        "start": 1177.039,
        "duration": 4.481,
        "text": "that allows you to"
      },
      {
        "start": 1178.96,
        "duration": 4.719,
        "text": "write code for the gpu and make the most"
      },
      {
        "start": 1181.52,
        "duration": 4.08,
        "text": "use out of its power"
      },
      {
        "start": 1183.679,
        "duration": 3.36,
        "text": "and as you can see here here's a couple"
      },
      {
        "start": 1185.6,
        "duration": 2.24,
        "text": "of"
      },
      {
        "start": 1187.039,
        "duration": 4.0,
        "text": "the"
      },
      {
        "start": 1187.84,
        "duration": 4.959,
        "text": "more widely used rapids libraries"
      },
      {
        "start": 1191.039,
        "duration": 4.721,
        "text": "and one of the most important ones here"
      },
      {
        "start": 1192.799,
        "duration": 5.681,
        "text": "is qdf so if you're familiar with python"
      },
      {
        "start": 1195.76,
        "duration": 5.36,
        "text": "and you've used pandas before"
      },
      {
        "start": 1198.48,
        "duration": 4.559,
        "text": "which is a library for essentially"
      },
      {
        "start": 1201.12,
        "duration": 2.88,
        "text": "managing your data in the form of data"
      },
      {
        "start": 1203.039,
        "duration": 3.12,
        "text": "frames"
      },
      {
        "start": 1204.0,
        "duration": 4.96,
        "text": "cody f is kind of the equivalent of"
      },
      {
        "start": 1206.159,
        "duration": 5.76,
        "text": "pandas in the rapids ecosystem and it"
      },
      {
        "start": 1208.96,
        "duration": 5.52,
        "text": "allows many of the same operations um"
      },
      {
        "start": 1211.919,
        "duration": 4.401,
        "text": "like storing data or querying for data"
      },
      {
        "start": 1214.48,
        "duration": 3.28,
        "text": "or um"
      },
      {
        "start": 1216.32,
        "duration": 3.44,
        "text": "all of the notation you're probably"
      },
      {
        "start": 1217.76,
        "duration": 3.919,
        "text": "familiar with that's all stuff you can"
      },
      {
        "start": 1219.76,
        "duration": 4.08,
        "text": "do with qdf as well"
      },
      {
        "start": 1221.679,
        "duration": 3.441,
        "text": "except it works on the gpu instead of"
      },
      {
        "start": 1223.84,
        "duration": 3.68,
        "text": "the cpu"
      },
      {
        "start": 1225.12,
        "duration": 4.64,
        "text": "um okay so"
      },
      {
        "start": 1227.52,
        "duration": 5.36,
        "text": "uh why are we so concerned about using"
      },
      {
        "start": 1229.76,
        "duration": 4.88,
        "text": "gpus anyways what's the big deal um so"
      },
      {
        "start": 1232.88,
        "duration": 4.0,
        "text": "as you can see in this diagram from"
      },
      {
        "start": 1234.64,
        "duration": 4.0,
        "text": "rapids it is a pretty big deal because"
      },
      {
        "start": 1236.88,
        "duration": 5.279,
        "text": "um gpus"
      },
      {
        "start": 1238.64,
        "duration": 4.96,
        "text": "are able to do these analytics processes"
      },
      {
        "start": 1242.159,
        "duration": 4.241,
        "text": "and machine learning training for"
      },
      {
        "start": 1243.6,
        "duration": 5.439,
        "text": "example much much much much faster than"
      },
      {
        "start": 1246.4,
        "duration": 5.36,
        "text": "current cpus can and the reason for this"
      },
      {
        "start": 1249.039,
        "duration": 5.12,
        "text": "is that gpus are essentially able to"
      },
      {
        "start": 1251.76,
        "duration": 3.919,
        "text": "multitask very very efficiently you can"
      },
      {
        "start": 1254.159,
        "duration": 3.841,
        "text": "run um like"
      },
      {
        "start": 1255.679,
        "duration": 6.0,
        "text": "lots lots more different threads on a"
      },
      {
        "start": 1258.0,
        "duration": 6.64,
        "text": "gpu than you can on a cpu and since data"
      },
      {
        "start": 1261.679,
        "duration": 7.041,
        "text": "science and machine learning requires a"
      },
      {
        "start": 1264.64,
        "duration": 6.72,
        "text": "lot of parallel computations um gpus are"
      },
      {
        "start": 1268.72,
        "duration": 4.64,
        "text": "much better suited for this task so as"
      },
      {
        "start": 1271.36,
        "duration": 4.24,
        "text": "you can see here they're"
      },
      {
        "start": 1273.36,
        "duration": 3.76,
        "text": "very very performant when it comes to"
      },
      {
        "start": 1275.6,
        "duration": 2.88,
        "text": "doing things like machine learning and"
      },
      {
        "start": 1277.12,
        "duration": 4.0,
        "text": "data science"
      },
      {
        "start": 1278.48,
        "duration": 5.36,
        "text": "which is why we want to use them for"
      },
      {
        "start": 1281.12,
        "duration": 3.52,
        "text": "what they're good at"
      },
      {
        "start": 1283.84,
        "duration": 3.199,
        "text": "so"
      },
      {
        "start": 1284.64,
        "duration": 4.399,
        "text": "if we're doing data science and you have"
      },
      {
        "start": 1287.039,
        "duration": 4.64,
        "text": "some code that's already written for"
      },
      {
        "start": 1289.039,
        "duration": 4.0,
        "text": "example with pandas scikit-learn maybe"
      },
      {
        "start": 1291.679,
        "duration": 4.88,
        "text": "matplotlib"
      },
      {
        "start": 1293.039,
        "duration": 5.681,
        "text": "all of these have respective equivalents"
      },
      {
        "start": 1296.559,
        "duration": 4.641,
        "text": "in rapids and that makes migrating your"
      },
      {
        "start": 1298.72,
        "duration": 5.36,
        "text": "existing code really really easy"
      },
      {
        "start": 1301.2,
        "duration": 4.16,
        "text": "so as you can see here we have cody f is"
      },
      {
        "start": 1304.08,
        "duration": 4.079,
        "text": "essentially"
      },
      {
        "start": 1305.36,
        "duration": 4.88,
        "text": "the equivalent of pandas we have qml"
      },
      {
        "start": 1308.159,
        "duration": 4.161,
        "text": "which is essentially the equivalent of"
      },
      {
        "start": 1310.24,
        "duration": 3.76,
        "text": "scikit-learn and we have a bunch of"
      },
      {
        "start": 1312.32,
        "duration": 3.92,
        "text": "other libraries that can help with all"
      },
      {
        "start": 1314.0,
        "duration": 4.72,
        "text": "of your data science needs and enable"
      },
      {
        "start": 1316.24,
        "duration": 5.679,
        "text": "you to run data science from end to end"
      },
      {
        "start": 1318.72,
        "duration": 5.52,
        "text": "on a gpu so i'll go back to"
      },
      {
        "start": 1321.919,
        "duration": 4.561,
        "text": "take a look between these slides"
      },
      {
        "start": 1324.24,
        "duration": 3.12,
        "text": "and you'll know this and you'll notice"
      },
      {
        "start": 1326.48,
        "duration": 2.559,
        "text": "sorry"
      },
      {
        "start": 1327.36,
        "duration": 2.72,
        "text": "one other difference"
      },
      {
        "start": 1329.039,
        "duration": 3.441,
        "text": "between"
      },
      {
        "start": 1330.08,
        "duration": 4.88,
        "text": "these two sort of pipelines"
      },
      {
        "start": 1332.48,
        "duration": 4.24,
        "text": "is the type of memory that they use"
      },
      {
        "start": 1334.96,
        "duration": 4.0,
        "text": "so currently"
      },
      {
        "start": 1336.72,
        "duration": 4.959,
        "text": "these familiar python apis are running"
      },
      {
        "start": 1338.96,
        "duration": 4.959,
        "text": "mostly on your cpu right so that's the"
      },
      {
        "start": 1341.679,
        "duration": 3.281,
        "text": "memory that you sort of have inside your"
      },
      {
        "start": 1343.919,
        "duration": 2.88,
        "text": "computer"
      },
      {
        "start": 1344.96,
        "duration": 4.719,
        "text": "but with rapids it allows you to"
      },
      {
        "start": 1346.799,
        "duration": 5.281,
        "text": "interface with gpu memory and like i"
      },
      {
        "start": 1349.679,
        "duration": 3.841,
        "text": "mentioned earlier the the format that"
      },
      {
        "start": 1352.08,
        "duration": 3.76,
        "text": "this memory is"
      },
      {
        "start": 1353.52,
        "duration": 4.96,
        "text": "that your data is stored in is known as"
      },
      {
        "start": 1355.84,
        "duration": 4.88,
        "text": "apache aero and apache aero is a really"
      },
      {
        "start": 1358.48,
        "duration": 5.28,
        "text": "really cool project um and now i'll hand"
      },
      {
        "start": 1360.72,
        "duration": 6.16,
        "text": "it over to uh seb and justin to talk a"
      },
      {
        "start": 1363.76,
        "duration": 5.84,
        "text": "little bit about apache arrow um"
      },
      {
        "start": 1366.88,
        "duration": 2.72,
        "text": "all right go ahead"
      },
      {
        "start": 1372.159,
        "duration": 3.841,
        "text": "yeah so i guess i'll take this off so"
      },
      {
        "start": 1374.0,
        "duration": 3.12,
        "text": "arrow is a project uh it's been around a"
      },
      {
        "start": 1376.0,
        "duration": 3.44,
        "text": "few years"
      },
      {
        "start": 1377.12,
        "duration": 4.16,
        "text": "uh in the uh apache"
      },
      {
        "start": 1379.44,
        "duration": 4.479,
        "text": "um open source"
      },
      {
        "start": 1381.28,
        "duration": 4.16,
        "text": "um governance model and"
      },
      {
        "start": 1383.919,
        "duration": 4.561,
        "text": "uh basically the main thing that it does"
      },
      {
        "start": 1385.44,
        "duration": 5.2,
        "text": "is it's an in-memory a"
      },
      {
        "start": 1388.48,
        "duration": 3.76,
        "text": "data structure that's called based and"
      },
      {
        "start": 1390.64,
        "duration": 2.32,
        "text": "so it's designed for a couple of main"
      },
      {
        "start": 1392.24,
        "duration": 2.96,
        "text": "things"
      },
      {
        "start": 1392.96,
        "duration": 4.88,
        "text": "most columnar video formats in general"
      },
      {
        "start": 1395.2,
        "duration": 4.32,
        "text": "are are designed for analytics"
      },
      {
        "start": 1397.84,
        "duration": 3.12,
        "text": "this makes sense because the kinds of"
      },
      {
        "start": 1399.52,
        "duration": 3.2,
        "text": "things you might want to do in analytics"
      },
      {
        "start": 1400.96,
        "duration": 3.92,
        "text": "is compute statistics for a particular"
      },
      {
        "start": 1402.72,
        "duration": 4.319,
        "text": "column and so you may want to fetch an"
      },
      {
        "start": 1404.88,
        "duration": 4.08,
        "text": "entire column's worth of data to be able"
      },
      {
        "start": 1407.039,
        "duration": 3.76,
        "text": "to aggregate it at a time without"
      },
      {
        "start": 1408.96,
        "duration": 4.24,
        "text": "looking at or going through other"
      },
      {
        "start": 1410.799,
        "duration": 3.841,
        "text": "columns in your table"
      },
      {
        "start": 1413.2,
        "duration": 2.64,
        "text": "so that's kind of one of the main one of"
      },
      {
        "start": 1414.64,
        "duration": 3.039,
        "text": "the main purposes the second kind of"
      },
      {
        "start": 1415.84,
        "duration": 5.04,
        "text": "more important thing that makes apache"
      },
      {
        "start": 1417.679,
        "duration": 6.24,
        "text": "area unique is is across language in"
      },
      {
        "start": 1420.88,
        "duration": 5.52,
        "text": "memory implementation and so it comes"
      },
      {
        "start": 1423.919,
        "duration": 4.161,
        "text": "with a set of tools for whatever"
      },
      {
        "start": 1426.4,
        "duration": 3.84,
        "text": "programming language you may fathom"
      },
      {
        "start": 1428.08,
        "duration": 3.839,
        "text": "write your favorite language uh to be"
      },
      {
        "start": 1430.24,
        "duration": 5.28,
        "text": "able to you know parse and"
      },
      {
        "start": 1431.919,
        "duration": 6.24,
        "text": "manipulate and create these arrow um"
      },
      {
        "start": 1435.52,
        "duration": 5.44,
        "text": "these arrow data structures and so"
      },
      {
        "start": 1438.159,
        "duration": 5.361,
        "text": "the folks that built rapids have pretty"
      },
      {
        "start": 1440.96,
        "duration": 4.719,
        "text": "heavily piggybacked on"
      },
      {
        "start": 1443.52,
        "duration": 3.6,
        "text": "this arrow technology i think justin's"
      },
      {
        "start": 1445.679,
        "duration": 3.201,
        "text": "going to go deeper into a little bit a"
      },
      {
        "start": 1447.12,
        "duration": 3.12,
        "text": "little bit of that on the analytics side"
      },
      {
        "start": 1448.88,
        "duration": 3.36,
        "text": "um"
      },
      {
        "start": 1450.24,
        "duration": 3.039,
        "text": "arrow is a really interesting project"
      },
      {
        "start": 1452.24,
        "duration": 2.24,
        "text": "from"
      },
      {
        "start": 1453.279,
        "duration": 3.28,
        "text": "for folks that are maybe running"
      },
      {
        "start": 1454.48,
        "duration": 3.12,
        "text": "cassandra or other databases"
      },
      {
        "start": 1456.559,
        "duration": 3.041,
        "text": "or are interested in kind of the"
      },
      {
        "start": 1457.6,
        "duration": 4.72,
        "text": "transactional side of the house"
      },
      {
        "start": 1459.6,
        "duration": 4.959,
        "text": "just because of that capability of going"
      },
      {
        "start": 1462.32,
        "duration": 3.599,
        "text": "from language to language or even going"
      },
      {
        "start": 1464.559,
        "duration": 2.801,
        "text": "over the wire"
      },
      {
        "start": 1465.919,
        "duration": 3.36,
        "text": "without having to"
      },
      {
        "start": 1467.36,
        "duration": 4.4,
        "text": "serialize or deserialize the data right"
      },
      {
        "start": 1469.279,
        "duration": 3.921,
        "text": "so traditionally"
      },
      {
        "start": 1471.76,
        "duration": 4.24,
        "text": "let's say that you know you're building"
      },
      {
        "start": 1473.2,
        "duration": 4.719,
        "text": "an app and"
      },
      {
        "start": 1476.0,
        "duration": 3.6,
        "text": "you have some some some data in an"
      },
      {
        "start": 1477.919,
        "duration": 3.521,
        "text": "object format in your particular"
      },
      {
        "start": 1479.6,
        "duration": 3.28,
        "text": "programming language"
      },
      {
        "start": 1481.44,
        "duration": 3.92,
        "text": "when you want to send it over the wire"
      },
      {
        "start": 1482.88,
        "duration": 4.08,
        "text": "or send it into the database"
      },
      {
        "start": 1485.36,
        "duration": 3.52,
        "text": "you serialize"
      },
      {
        "start": 1486.96,
        "duration": 3.599,
        "text": "that into a format that you that you can"
      },
      {
        "start": 1488.88,
        "duration": 4.24,
        "text": "send over the wire then you again"
      },
      {
        "start": 1490.559,
        "duration": 4.321,
        "text": "deserialize this utilize again it very"
      },
      {
        "start": 1493.12,
        "duration": 4.159,
        "text": "basically at every step to turn it into"
      },
      {
        "start": 1494.88,
        "duration": 4.0,
        "text": "objects um in your code whether whether"
      },
      {
        "start": 1497.279,
        "duration": 3.201,
        "text": "that's the code inside of the database"
      },
      {
        "start": 1498.88,
        "duration": 3.44,
        "text": "like like cassandra"
      },
      {
        "start": 1500.48,
        "duration": 3.52,
        "text": "that's going to stick stuff in what we"
      },
      {
        "start": 1502.32,
        "duration": 3.2,
        "text": "call mem tables which is the cassandra"
      },
      {
        "start": 1504.0,
        "duration": 3.36,
        "text": "memory format"
      },
      {
        "start": 1505.52,
        "duration": 4.639,
        "text": "or whether that's the code inside the"
      },
      {
        "start": 1507.36,
        "duration": 4.799,
        "text": "the driver that you're using to to"
      },
      {
        "start": 1510.159,
        "duration": 4.241,
        "text": "either persist or read the data you're"
      },
      {
        "start": 1512.159,
        "duration": 4.561,
        "text": "serializing and deserializing constantly"
      },
      {
        "start": 1514.4,
        "duration": 5.68,
        "text": "right and so if ecosystems like for"
      },
      {
        "start": 1516.72,
        "duration": 3.36,
        "text": "example the cassandra ecosystem"
      },
      {
        "start": 1520.799,
        "duration": 4.961,
        "text": "adopted and leveraged arrow it's"
      },
      {
        "start": 1523.679,
        "duration": 3.36,
        "text": "possible to do that throughout like that"
      },
      {
        "start": 1525.76,
        "duration": 3.84,
        "text": "entire stack"
      },
      {
        "start": 1527.039,
        "duration": 3.841,
        "text": "so you know there's a potential future"
      },
      {
        "start": 1529.6,
        "duration": 2.88,
        "text": "in which"
      },
      {
        "start": 1530.88,
        "duration": 4.799,
        "text": "everything's arrow"
      },
      {
        "start": 1532.48,
        "duration": 6.4,
        "text": "starting at your driver application"
      },
      {
        "start": 1535.679,
        "duration": 5.36,
        "text": "uh and going over the wire to"
      },
      {
        "start": 1538.88,
        "duration": 3.84,
        "text": "the database uh"
      },
      {
        "start": 1541.039,
        "duration": 3.041,
        "text": "you know it's in and there would be"
      },
      {
        "start": 1542.72,
        "duration": 3.36,
        "text": "literally zero"
      },
      {
        "start": 1544.08,
        "duration": 4.479,
        "text": "zero copies made of the data zero"
      },
      {
        "start": 1546.08,
        "duration": 4.16,
        "text": "serialization deserialization which"
      },
      {
        "start": 1548.559,
        "duration": 4.48,
        "text": "actually takes up like a chunk of the"
      },
      {
        "start": 1550.24,
        "duration": 4.72,
        "text": "compute um inside of systems like"
      },
      {
        "start": 1553.039,
        "duration": 3.76,
        "text": "cassandra right both at the driver level"
      },
      {
        "start": 1554.96,
        "duration": 4.88,
        "text": "and at the database level so this is a"
      },
      {
        "start": 1556.799,
        "duration": 5.12,
        "text": "really interesting technology um"
      },
      {
        "start": 1559.84,
        "duration": 4.48,
        "text": "i think you know we've been watching it"
      },
      {
        "start": 1561.919,
        "duration": 4.561,
        "text": "for a while and the guy that came up"
      },
      {
        "start": 1564.32,
        "duration": 3.76,
        "text": "with the name he actually uh works at"
      },
      {
        "start": 1566.48,
        "duration": 2.96,
        "text": "data stack so there's yeah there's it's"
      },
      {
        "start": 1568.08,
        "duration": 4.079,
        "text": "a pretty interesting technology from"
      },
      {
        "start": 1569.44,
        "duration": 4.32,
        "text": "from just a compute database"
      },
      {
        "start": 1572.159,
        "duration": 3.52,
        "text": "perspective in general"
      },
      {
        "start": 1573.76,
        "duration": 3.44,
        "text": "but really it's optimized and designed"
      },
      {
        "start": 1575.679,
        "duration": 2.801,
        "text": "for analytics and i'll"
      },
      {
        "start": 1577.2,
        "duration": 2.64,
        "text": "shoot it over to justin there to chat a"
      },
      {
        "start": 1578.48,
        "duration": 3.6,
        "text": "little bit about that"
      },
      {
        "start": 1579.84,
        "duration": 4.079,
        "text": "i think yeah it's it's an opportunity to"
      },
      {
        "start": 1582.08,
        "duration": 3.28,
        "text": "have a shared data object between a"
      },
      {
        "start": 1583.919,
        "duration": 3.201,
        "text": "variety of different apis but also"
      },
      {
        "start": 1585.36,
        "duration": 3.28,
        "text": "different types of hardware"
      },
      {
        "start": 1587.12,
        "duration": 3.039,
        "text": "so when"
      },
      {
        "start": 1588.64,
        "duration": 3.919,
        "text": "when most users are coming into data"
      },
      {
        "start": 1590.159,
        "duration": 4.4,
        "text": "science the the first kind of"
      },
      {
        "start": 1592.559,
        "duration": 4.161,
        "text": "structural component that they are"
      },
      {
        "start": 1594.559,
        "duration": 3.521,
        "text": "introduced to is the data frame and"
      },
      {
        "start": 1596.72,
        "duration": 3.6,
        "text": "inherently with the data frame they're"
      },
      {
        "start": 1598.08,
        "duration": 5.28,
        "text": "using with the uh with data science is"
      },
      {
        "start": 1600.32,
        "duration": 4.719,
        "text": "often appended data frame and with most"
      },
      {
        "start": 1603.36,
        "duration": 3.04,
        "text": "cases with that you know when that was"
      },
      {
        "start": 1605.039,
        "duration": 2.721,
        "text": "first created there wasn't really a lot"
      },
      {
        "start": 1606.4,
        "duration": 3.36,
        "text": "of options so in most cases you were"
      },
      {
        "start": 1607.76,
        "duration": 5.2,
        "text": "dealing with a lot of structured data uh"
      },
      {
        "start": 1609.76,
        "duration": 5.279,
        "text": "this is maybe 12 13 years ago and coming"
      },
      {
        "start": 1612.96,
        "duration": 4.319,
        "text": "just doing your initial data etl"
      },
      {
        "start": 1615.039,
        "duration": 4.64,
        "text": "wrangling data exploration um doing a"
      },
      {
        "start": 1617.279,
        "duration": 4.081,
        "text": "lot of your model development"
      },
      {
        "start": 1619.679,
        "duration": 3.36,
        "text": "using psychic learn things like that but"
      },
      {
        "start": 1621.36,
        "duration": 3.76,
        "text": "building it on top of the the pandas"
      },
      {
        "start": 1623.039,
        "duration": 4.721,
        "text": "data frame and then generating some type"
      },
      {
        "start": 1625.12,
        "duration": 4.159,
        "text": "of analysis and at that point moving on"
      },
      {
        "start": 1627.76,
        "duration": 3.039,
        "text": "to the next step or"
      },
      {
        "start": 1629.279,
        "duration": 2.88,
        "text": "swapping out different types of samples"
      },
      {
        "start": 1630.799,
        "duration": 3.441,
        "text": "for your model"
      },
      {
        "start": 1632.159,
        "duration": 3.52,
        "text": "as we've seen growth within the data"
      },
      {
        "start": 1634.24,
        "duration": 3.039,
        "text": "science community the different types of"
      },
      {
        "start": 1635.679,
        "duration": 3.441,
        "text": "tools that have come up one of the"
      },
      {
        "start": 1637.279,
        "duration": 3.12,
        "text": "things that at least was generated was"
      },
      {
        "start": 1639.12,
        "duration": 3.12,
        "text": "that there were some inherent"
      },
      {
        "start": 1640.399,
        "duration": 4.241,
        "text": "shortcomings associated with pandas and"
      },
      {
        "start": 1642.24,
        "duration": 4.48,
        "text": "apache arrow looks to at least address"
      },
      {
        "start": 1644.64,
        "duration": 4.08,
        "text": "some of those shortcomings and then have"
      },
      {
        "start": 1646.72,
        "duration": 4.079,
        "text": "any other apis or applications that are"
      },
      {
        "start": 1648.72,
        "duration": 4.64,
        "text": "developed on top of it to be able to"
      },
      {
        "start": 1650.799,
        "duration": 4.48,
        "text": "avoid some of those pain points that"
      },
      {
        "start": 1653.36,
        "duration": 2.799,
        "text": "users kind of face right now"
      },
      {
        "start": 1655.279,
        "duration": 2.4,
        "text": "and"
      },
      {
        "start": 1656.159,
        "duration": 3.841,
        "text": "whether that's in memory computing"
      },
      {
        "start": 1657.679,
        "duration": 4.161,
        "text": "whether it's running out of data sets or"
      },
      {
        "start": 1660.0,
        "duration": 3.52,
        "text": "shortcoming data just based on what's"
      },
      {
        "start": 1661.84,
        "duration": 4.319,
        "text": "available in your cpu"
      },
      {
        "start": 1663.52,
        "duration": 5.039,
        "text": "but when rapids was first"
      },
      {
        "start": 1666.159,
        "duration": 4.0,
        "text": "created but the core component that was"
      },
      {
        "start": 1668.559,
        "duration": 3.6,
        "text": "recognized that we needed to understand"
      },
      {
        "start": 1670.159,
        "duration": 5.361,
        "text": "to at least develop and understand how"
      },
      {
        "start": 1672.159,
        "duration": 5.041,
        "text": "to create a gpu specific data frame was"
      },
      {
        "start": 1675.52,
        "duration": 3.92,
        "text": "one understanding that users are"
      },
      {
        "start": 1677.2,
        "duration": 4.0,
        "text": "familiar with pandas in the painters api"
      },
      {
        "start": 1679.44,
        "duration": 4.0,
        "text": "but also we need to evaluate the same"
      },
      {
        "start": 1681.2,
        "duration": 4.8,
        "text": "polynomial structured style that would"
      },
      {
        "start": 1683.44,
        "duration": 4.32,
        "text": "run on a gpu and therefore be able to"
      },
      {
        "start": 1686.0,
        "duration": 3.679,
        "text": "process all this data without having to"
      },
      {
        "start": 1687.76,
        "duration": 4.0,
        "text": "pass data from or do all the wrangling"
      },
      {
        "start": 1689.679,
        "duration": 4.321,
        "text": "on a cpu and then pass it to a gpu for"
      },
      {
        "start": 1691.76,
        "duration": 4.639,
        "text": "any type of accelerated computing hence"
      },
      {
        "start": 1694.0,
        "duration": 3.36,
        "text": "the qdf functionality where you can"
      },
      {
        "start": 1696.399,
        "duration": 4.0,
        "text": "essentially"
      },
      {
        "start": 1697.36,
        "duration": 5.36,
        "text": "take your data data query from the ss"
      },
      {
        "start": 1700.399,
        "duration": 4.16,
        "text": "table put it into a qdf with the"
      },
      {
        "start": 1702.72,
        "duration": 3.6,
        "text": "backbone of it being apache arrow in"
      },
      {
        "start": 1704.559,
        "duration": 3.12,
        "text": "this case a pyro functionality with a"
      },
      {
        "start": 1706.32,
        "duration": 3.04,
        "text": "python api"
      },
      {
        "start": 1707.679,
        "duration": 4.081,
        "text": "and then start to do your data wrangling"
      },
      {
        "start": 1709.36,
        "duration": 5.199,
        "text": "and accelerate all this process of"
      },
      {
        "start": 1711.76,
        "duration": 4.799,
        "text": "feature analysis uh data prep so on and"
      },
      {
        "start": 1714.559,
        "duration": 5.12,
        "text": "so forth and then before you push it"
      },
      {
        "start": 1716.559,
        "duration": 6.0,
        "text": "into a deep learning specific type"
      },
      {
        "start": 1719.679,
        "duration": 5.36,
        "text": "of process or a more classical machine"
      },
      {
        "start": 1722.559,
        "duration": 3.84,
        "text": "learning type process using our qml so"
      },
      {
        "start": 1725.039,
        "duration": 3.601,
        "text": "these are the types of things that we"
      },
      {
        "start": 1726.399,
        "duration": 4.88,
        "text": "see are more more of an evolutionary"
      },
      {
        "start": 1728.64,
        "duration": 4.399,
        "text": "growth in terms of what other components"
      },
      {
        "start": 1731.279,
        "duration": 4.081,
        "text": "are out there within the"
      },
      {
        "start": 1733.039,
        "duration": 4.24,
        "text": "the field that offer assisting"
      },
      {
        "start": 1735.36,
        "duration": 3.28,
        "text": "components or assisted compute as well"
      },
      {
        "start": 1737.279,
        "duration": 3.12,
        "text": "as additional functionality and"
      },
      {
        "start": 1738.64,
        "duration": 4.159,
        "text": "efficiency for a lot of data science"
      },
      {
        "start": 1740.399,
        "duration": 2.4,
        "text": "users"
      },
      {
        "start": 1743.2,
        "duration": 2.719,
        "text": "yeah so"
      },
      {
        "start": 1744.24,
        "duration": 3.2,
        "text": "i guess one of the things to point out"
      },
      {
        "start": 1745.919,
        "duration": 2.561,
        "text": "here is"
      },
      {
        "start": 1747.44,
        "duration": 2.239,
        "text": "if you want to do if you want to take"
      },
      {
        "start": 1748.48,
        "duration": 3.28,
        "text": "advantage of gpus for things like"
      },
      {
        "start": 1749.679,
        "duration": 3.36,
        "text": "analytics like there's not a ton of cuda"
      },
      {
        "start": 1751.76,
        "duration": 3.36,
        "text": "developers out there right that's a very"
      },
      {
        "start": 1753.039,
        "duration": 3.201,
        "text": "specific niche like"
      },
      {
        "start": 1755.12,
        "duration": 2.559,
        "text": "knowledge set"
      },
      {
        "start": 1756.24,
        "duration": 3.2,
        "text": "you're writing c plus and you need to be"
      },
      {
        "start": 1757.679,
        "duration": 4.081,
        "text": "familiar with the specific cuda apis and"
      },
      {
        "start": 1759.44,
        "duration": 5.28,
        "text": "it's hard right uh and so"
      },
      {
        "start": 1761.76,
        "duration": 5.84,
        "text": "one of the like huge benefits of"
      },
      {
        "start": 1764.72,
        "duration": 4.959,
        "text": "rapids and arrow is that if you're able"
      },
      {
        "start": 1767.6,
        "duration": 4.64,
        "text": "to get something an arrow like getting"
      },
      {
        "start": 1769.679,
        "duration": 5.761,
        "text": "that data vectorized and loaded into gpu"
      },
      {
        "start": 1772.24,
        "duration": 5.28,
        "text": "memory uh etc is is"
      },
      {
        "start": 1775.44,
        "duration": 5.04,
        "text": "basically free"
      },
      {
        "start": 1777.52,
        "duration": 5.039,
        "text": "exactly extract it from the user and so"
      },
      {
        "start": 1780.48,
        "duration": 4.4,
        "text": "all users have to know is just that a"
      },
      {
        "start": 1782.559,
        "duration": 5.041,
        "text": "familiarity with the apis that are"
      },
      {
        "start": 1784.88,
        "duration": 4.88,
        "text": "similar to pandas and the functionality"
      },
      {
        "start": 1787.6,
        "duration": 3.439,
        "text": "then mirror is mirrored in qdf so the"
      },
      {
        "start": 1789.76,
        "duration": 3.44,
        "text": "same types of steps that you would do in"
      },
      {
        "start": 1791.039,
        "duration": 4.321,
        "text": "a pandas data frame can be done in a qdf"
      },
      {
        "start": 1793.2,
        "duration": 4.4,
        "text": "data frame therefore the learning curve"
      },
      {
        "start": 1795.36,
        "duration": 4.559,
        "text": "is black"
      },
      {
        "start": 1797.6,
        "duration": 4.559,
        "text": "yeah awesome so thanks so much seven"
      },
      {
        "start": 1799.919,
        "duration": 4.0,
        "text": "justin and i'm gonna skip ahead because"
      },
      {
        "start": 1802.159,
        "duration": 3.76,
        "text": "i think i miss ordered my slides a"
      },
      {
        "start": 1803.919,
        "duration": 5.12,
        "text": "little bit but just to follow up with"
      },
      {
        "start": 1805.919,
        "duration": 6.0,
        "text": "what someone's talking about yeah that's"
      },
      {
        "start": 1809.039,
        "duration": 5.12,
        "text": "that's um um was we got this tweet and"
      },
      {
        "start": 1811.919,
        "duration": 4.561,
        "text": "saying weird that um the title of the"
      },
      {
        "start": 1814.159,
        "duration": 4.64,
        "text": "post is about doing things with gpu and"
      },
      {
        "start": 1816.48,
        "duration": 5.12,
        "text": "the gpu part is kind of like a to-do at"
      },
      {
        "start": 1818.799,
        "duration": 4.561,
        "text": "the bottom and what makes arrow so great"
      },
      {
        "start": 1821.6,
        "duration": 4.959,
        "text": "is that um that's kind of exactly the"
      },
      {
        "start": 1823.36,
        "duration": 5.52,
        "text": "point is that for most users who um"
      },
      {
        "start": 1826.559,
        "duration": 4.561,
        "text": "don't need to worry most users sorry let"
      },
      {
        "start": 1828.88,
        "duration": 4.24,
        "text": "me back up most users now don't need to"
      },
      {
        "start": 1831.12,
        "duration": 4.24,
        "text": "worry about the actual process of"
      },
      {
        "start": 1833.12,
        "duration": 5.36,
        "text": "getting data onto the gpu because the"
      },
      {
        "start": 1835.36,
        "duration": 4.559,
        "text": "rapids ecosystem and codif and qml and"
      },
      {
        "start": 1838.48,
        "duration": 4.48,
        "text": "all of these libraries"
      },
      {
        "start": 1839.919,
        "duration": 6.721,
        "text": "do all of that work for you so really"
      },
      {
        "start": 1842.96,
        "duration": 6.079,
        "text": "on our end with ss table to arrow"
      },
      {
        "start": 1846.64,
        "duration": 4.8,
        "text": "the main idea is to read those as tables"
      },
      {
        "start": 1849.039,
        "duration": 4.401,
        "text": "and get them into arrow format because"
      },
      {
        "start": 1851.44,
        "duration": 3.92,
        "text": "once they're in arrow format we can use"
      },
      {
        "start": 1853.44,
        "duration": 4.64,
        "text": "them on the cpu we can use them on the"
      },
      {
        "start": 1855.36,
        "duration": 5.6,
        "text": "gpu and it's just a very flexible format"
      },
      {
        "start": 1858.08,
        "duration": 6.319,
        "text": "we can use also across languages"
      },
      {
        "start": 1860.96,
        "duration": 6.16,
        "text": "okay yeah awesome so i'll just back up"
      },
      {
        "start": 1864.399,
        "duration": 4.801,
        "text": "uh to those two slides there um so yeah"
      },
      {
        "start": 1867.12,
        "duration": 4.399,
        "text": "here's just a sort of brief look at what"
      },
      {
        "start": 1869.2,
        "duration": 4.719,
        "text": "we're talking about so if you already"
      },
      {
        "start": 1871.519,
        "duration": 4.16,
        "text": "have some code using pandas for example"
      },
      {
        "start": 1873.919,
        "duration": 3.76,
        "text": "we're just reading a csv printing the"
      },
      {
        "start": 1875.679,
        "duration": 2.801,
        "text": "mean of each of the columns pretty basic"
      },
      {
        "start": 1877.679,
        "duration": 4.321,
        "text": "stuff"
      },
      {
        "start": 1878.48,
        "duration": 5.36,
        "text": "um if you want to run this code on a gpu"
      },
      {
        "start": 1882.0,
        "duration": 4.48,
        "text": "all you really need to do is switch out"
      },
      {
        "start": 1883.84,
        "duration": 5.12,
        "text": "pandas with qdf um so now instead of"
      },
      {
        "start": 1886.48,
        "duration": 4.72,
        "text": "import pandas we just have import qdf"
      },
      {
        "start": 1888.96,
        "duration": 5.04,
        "text": "and then all of the other um all the"
      },
      {
        "start": 1891.2,
        "duration": 5.839,
        "text": "rest of the api um we can essentially"
      },
      {
        "start": 1894.0,
        "duration": 5.44,
        "text": "use it in basically the same way um so"
      },
      {
        "start": 1897.039,
        "duration": 5.12,
        "text": "rapids is a really really great project"
      },
      {
        "start": 1899.44,
        "duration": 4.719,
        "text": "highly encourage checking it out"
      },
      {
        "start": 1902.159,
        "duration": 2.681,
        "text": "in case you want to do data analytics on"
      },
      {
        "start": 1904.159,
        "duration": 2.88,
        "text": "a"
      },
      {
        "start": 1904.84,
        "duration": 3.559,
        "text": "gpu okay"
      },
      {
        "start": 1907.039,
        "duration": 3.681,
        "text": "so"
      },
      {
        "start": 1908.399,
        "duration": 5.041,
        "text": "um now let's move on to part three so"
      },
      {
        "start": 1910.72,
        "duration": 4.799,
        "text": "this is going to be um the hands-on"
      },
      {
        "start": 1913.44,
        "duration": 4.8,
        "text": "section um where you can try out this"
      },
      {
        "start": 1915.519,
        "duration": 5.76,
        "text": "tool on your own cassandra data um and"
      },
      {
        "start": 1918.24,
        "duration": 6.72,
        "text": "in case you don't have an ss table um or"
      },
      {
        "start": 1921.279,
        "duration": 5.601,
        "text": "ss tables available don't worry um we"
      },
      {
        "start": 1924.96,
        "duration": 3.92,
        "text": "first of all we have some sample data"
      },
      {
        "start": 1926.88,
        "duration": 5.44,
        "text": "bundled in the repository that you can"
      },
      {
        "start": 1928.88,
        "duration": 5.279,
        "text": "use um and we also have this s3 bucket"
      },
      {
        "start": 1932.32,
        "duration": 4.479,
        "text": "uh with some"
      },
      {
        "start": 1934.159,
        "duration": 5.201,
        "text": "sample internet of things"
      },
      {
        "start": 1936.799,
        "duration": 5.441,
        "text": "generated data um in case you want to"
      },
      {
        "start": 1939.36,
        "duration": 5.919,
        "text": "use that in a bit um so the s3 bucket is"
      },
      {
        "start": 1942.24,
        "duration": 4.72,
        "text": "called ss table to arrow"
      },
      {
        "start": 1945.279,
        "duration": 3.52,
        "text": "but for today i think we're mostly going"
      },
      {
        "start": 1946.96,
        "duration": 4.24,
        "text": "to be using the sample data inside the"
      },
      {
        "start": 1948.799,
        "duration": 6.641,
        "text": "repository but just know that s's table"
      },
      {
        "start": 1951.2,
        "duration": 6.8,
        "text": "to arrow is able to read um ss tables"
      },
      {
        "start": 1955.44,
        "duration": 5.52,
        "text": "from an s3 bucket so if you have data"
      },
      {
        "start": 1958.0,
        "duration": 4.88,
        "text": "maybe in s3 um i've heard rumors that"
      },
      {
        "start": 1960.96,
        "duration": 3.599,
        "text": "that's maybe where cassandra will be"
      },
      {
        "start": 1962.88,
        "duration": 4.56,
        "text": "going in the future too"
      },
      {
        "start": 1964.559,
        "duration": 2.881,
        "text": "or astra"
      },
      {
        "start": 1967.6,
        "duration": 4.4,
        "text": "yeah so"
      },
      {
        "start": 1969.279,
        "duration": 4.481,
        "text": "s3 that's where our data is stored"
      },
      {
        "start": 1972.0,
        "duration": 3.12,
        "text": "you can go ahead and use that as sample"
      },
      {
        "start": 1973.76,
        "duration": 4.24,
        "text": "data if you want"
      },
      {
        "start": 1975.12,
        "duration": 5.679,
        "text": "okay so um here's a brief overview of"
      },
      {
        "start": 1978.0,
        "duration": 4.88,
        "text": "currently how you can use ss table to"
      },
      {
        "start": 1980.799,
        "duration": 4.48,
        "text": "arrow so keep in mind this is alpha"
      },
      {
        "start": 1982.88,
        "duration": 4.399,
        "text": "level software um i'm currently actually"
      },
      {
        "start": 1985.279,
        "duration": 4.88,
        "text": "working on some python bindings that you"
      },
      {
        "start": 1987.279,
        "duration": 5.041,
        "text": "can call straight from python um so i"
      },
      {
        "start": 1990.159,
        "duration": 4.321,
        "text": "guess stay in touch keep our or keep"
      },
      {
        "start": 1992.32,
        "duration": 3.04,
        "text": "updated about that in case it ever comes"
      },
      {
        "start": 1994.48,
        "duration": 4.16,
        "text": "out"
      },
      {
        "start": 1995.36,
        "duration": 5.36,
        "text": "but currently um how it works is we have"
      },
      {
        "start": 1998.64,
        "duration": 4.8,
        "text": "these ss tables on the disk so we have"
      },
      {
        "start": 2000.72,
        "duration": 5.439,
        "text": "our data file statistics file etc"
      },
      {
        "start": 2003.44,
        "duration": 5.2,
        "text": "and that gets read by the actual asset"
      },
      {
        "start": 2006.159,
        "duration": 5.921,
        "text": "table to library our asses table to"
      },
      {
        "start": 2008.64,
        "duration": 6.08,
        "text": "arrow library which is written in c plus"
      },
      {
        "start": 2012.08,
        "duration": 5.28,
        "text": "um and which you can run through a"
      },
      {
        "start": 2014.72,
        "duration": 4.4,
        "text": "docker container um to avoid any like"
      },
      {
        "start": 2017.36,
        "duration": 4.08,
        "text": "installation panes"
      },
      {
        "start": 2019.12,
        "duration": 4.559,
        "text": "and essentially that tool will take"
      },
      {
        "start": 2021.44,
        "duration": 4.56,
        "text": "those esses tables transform them into"
      },
      {
        "start": 2023.679,
        "duration": 4.24,
        "text": "arrow tables and then it'll listen on a"
      },
      {
        "start": 2026.0,
        "duration": 4.08,
        "text": "network socket that you can connect to"
      },
      {
        "start": 2027.919,
        "duration": 4.721,
        "text": "to actually grab that data so then on"
      },
      {
        "start": 2030.08,
        "duration": 4.88,
        "text": "the client side um we have a sample"
      },
      {
        "start": 2032.64,
        "duration": 5.2,
        "text": "python script which you can grab from"
      },
      {
        "start": 2034.96,
        "duration": 5.28,
        "text": "the repository that we sent out earlier"
      },
      {
        "start": 2037.84,
        "duration": 4.719,
        "text": "and that script will essentially go and"
      },
      {
        "start": 2040.24,
        "duration": 4.559,
        "text": "ask for the data from that server and"
      },
      {
        "start": 2042.559,
        "duration": 4.24,
        "text": "the server will send that data back but"
      },
      {
        "start": 2044.799,
        "duration": 4.961,
        "text": "as an arrow table instead of access"
      },
      {
        "start": 2046.799,
        "duration": 5.12,
        "text": "tables which are harder to parse um and"
      },
      {
        "start": 2049.76,
        "duration": 5.599,
        "text": "once we have that data as an arrow table"
      },
      {
        "start": 2051.919,
        "duration": 5.76,
        "text": "we can do like we said data analytics or"
      },
      {
        "start": 2055.359,
        "duration": 6.0,
        "text": "anything we want with it basically"
      },
      {
        "start": 2057.679,
        "duration": 6.96,
        "text": "using the rapids ecosystem so um here's"
      },
      {
        "start": 2061.359,
        "duration": 6.0,
        "text": "a brief overview of the steps um i also"
      },
      {
        "start": 2064.639,
        "duration": 5.601,
        "text": "just realized i haven't updated this url"
      },
      {
        "start": 2067.359,
        "duration": 5.52,
        "text": "for the python script so um this is"
      },
      {
        "start": 2070.24,
        "duration": 6.399,
        "text": "essentially identical to uh what's on"
      },
      {
        "start": 2072.879,
        "duration": 6.0,
        "text": "the github repository so um right now if"
      },
      {
        "start": 2076.639,
        "duration": 4.0,
        "text": "you want to go ahead hop on that link"
      },
      {
        "start": 2078.879,
        "duration": 4.321,
        "text": "that was sent earlier to the github"
      },
      {
        "start": 2080.639,
        "duration": 5.121,
        "text": "repository um and just follow along with"
      },
      {
        "start": 2083.2,
        "duration": 4.32,
        "text": "the getting started um"
      },
      {
        "start": 2085.76,
        "duration": 2.96,
        "text": "we'll basically go ahead and walk"
      },
      {
        "start": 2087.52,
        "duration": 3.04,
        "text": "through that"
      },
      {
        "start": 2088.72,
        "duration": 3.359,
        "text": "so unfortunately i can't read the chat"
      },
      {
        "start": 2090.56,
        "duration": 4.4,
        "text": "so i'm not sure"
      },
      {
        "start": 2092.079,
        "duration": 4.721,
        "text": "how much time this will take um but i'll"
      },
      {
        "start": 2094.96,
        "duration": 3.2,
        "text": "head i'll hand it over to sub right now"
      },
      {
        "start": 2096.8,
        "duration": 3.52,
        "text": "for"
      },
      {
        "start": 2098.16,
        "duration": 3.52,
        "text": "a sort of live demo of how this is going"
      },
      {
        "start": 2100.32,
        "duration": 3.36,
        "text": "to work"
      },
      {
        "start": 2101.68,
        "duration": 4.08,
        "text": "because unfortunately my computer is"
      },
      {
        "start": 2103.68,
        "duration": 3.76,
        "text": "having some technical difficulties all"
      },
      {
        "start": 2105.76,
        "duration": 4.319,
        "text": "right uh seb do you want to go ahead and"
      },
      {
        "start": 2107.44,
        "duration": 2.639,
        "text": "share your screen"
      },
      {
        "start": 2110.88,
        "duration": 5.36,
        "text": "yeah absolutely all right okay let's see"
      },
      {
        "start": 2112.96,
        "duration": 7.2,
        "text": "the screen button over here"
      },
      {
        "start": 2116.24,
        "duration": 3.92,
        "text": "i'll jump out of the youtube there"
      },
      {
        "start": 2120.64,
        "duration": 4.16,
        "text": "okay so"
      },
      {
        "start": 2122.64,
        "duration": 5.199,
        "text": "this is the section that"
      },
      {
        "start": 2124.8,
        "duration": 3.039,
        "text": "we want to do for hands-on"
      },
      {
        "start": 2128.079,
        "duration": 2.801,
        "text": "if somebody's"
      },
      {
        "start": 2129.68,
        "duration": 2.56,
        "text": "right if someone if you're watching the"
      },
      {
        "start": 2130.88,
        "duration": 2.959,
        "text": "um"
      },
      {
        "start": 2132.24,
        "duration": 3.839,
        "text": "the chat and some questions come in just"
      },
      {
        "start": 2133.839,
        "duration": 4.401,
        "text": "go ahead and"
      },
      {
        "start": 2136.079,
        "duration": 3.921,
        "text": "break in and we can answer those"
      },
      {
        "start": 2138.24,
        "duration": 3.28,
        "text": "um but until then i just kind of walk"
      },
      {
        "start": 2140.0,
        "duration": 3.44,
        "text": "through the steps on how to run this and"
      },
      {
        "start": 2141.52,
        "duration": 4.8,
        "text": "talk a little bit about what it does"
      },
      {
        "start": 2143.44,
        "duration": 4.639,
        "text": "so um the first thing was"
      },
      {
        "start": 2146.32,
        "duration": 4.32,
        "text": "you want to pull the container"
      },
      {
        "start": 2148.079,
        "duration": 3.681,
        "text": "that has the accessible arrow program"
      },
      {
        "start": 2150.64,
        "duration": 2.88,
        "text": "um"
      },
      {
        "start": 2151.76,
        "duration": 4.079,
        "text": "sstable to arrow"
      },
      {
        "start": 2153.52,
        "duration": 5.839,
        "text": "i'll show you guys quickly the repo is"
      },
      {
        "start": 2155.839,
        "duration": 5.121,
        "text": "written in c plus"
      },
      {
        "start": 2159.359,
        "duration": 3.361,
        "text": "this is alex's work for the last few"
      },
      {
        "start": 2160.96,
        "duration": 3.2,
        "text": "months"
      },
      {
        "start": 2162.72,
        "duration": 3.359,
        "text": "um"
      },
      {
        "start": 2164.16,
        "duration": 3.04,
        "text": "and so there's the compiled binary in"
      },
      {
        "start": 2166.079,
        "duration": 2.321,
        "text": "this docker container to make things"
      },
      {
        "start": 2167.2,
        "duration": 3.639,
        "text": "easy you don't have to go build anything"
      },
      {
        "start": 2168.4,
        "duration": 5.12,
        "text": "from source or anything like that"
      },
      {
        "start": 2170.839,
        "duration": 4.121,
        "text": "um but yeah this is the project where it"
      },
      {
        "start": 2173.52,
        "duration": 2.8,
        "text": "lives"
      },
      {
        "start": 2174.96,
        "duration": 3.04,
        "text": "um"
      },
      {
        "start": 2176.32,
        "duration": 4.56,
        "text": "and basically what it does is you point"
      },
      {
        "start": 2178.0,
        "duration": 3.92,
        "text": "it at some ss tables and it makes them"
      },
      {
        "start": 2180.88,
        "duration": 3.199,
        "text": "available"
      },
      {
        "start": 2181.92,
        "duration": 3.04,
        "text": "in arrow format"
      },
      {
        "start": 2184.079,
        "duration": 3.441,
        "text": "now"
      },
      {
        "start": 2184.96,
        "duration": 4.24,
        "text": "in the example here what we're doing is"
      },
      {
        "start": 2187.52,
        "duration": 2.96,
        "text": "we're starting up the container telling"
      },
      {
        "start": 2189.2,
        "duration": 2.0,
        "text": "it which of the stables we're interested"
      },
      {
        "start": 2190.48,
        "duration": 2.96,
        "text": "in"
      },
      {
        "start": 2191.2,
        "duration": 3.6,
        "text": "and having it start and having it open"
      },
      {
        "start": 2193.44,
        "duration": 3.36,
        "text": "up a"
      },
      {
        "start": 2194.8,
        "duration": 4.08,
        "text": "network socket"
      },
      {
        "start": 2196.8,
        "duration": 4.4,
        "text": "and the second section here"
      },
      {
        "start": 2198.88,
        "duration": 4.56,
        "text": "this python part"
      },
      {
        "start": 2201.2,
        "duration": 3.28,
        "text": "is a python client application that's"
      },
      {
        "start": 2203.44,
        "duration": 2.159,
        "text": "going to"
      },
      {
        "start": 2204.48,
        "duration": 5.119,
        "text": "hit"
      },
      {
        "start": 2205.599,
        "duration": 4.0,
        "text": "sstable arrow via that socket"
      },
      {
        "start": 2209.68,
        "duration": 3.76,
        "text": "ask it for the data in the ss tables"
      },
      {
        "start": 2212.0,
        "duration": 3.68,
        "text": "that data is going to be sent in arrow"
      },
      {
        "start": 2213.44,
        "duration": 3.679,
        "text": "format over the wire so this not only"
      },
      {
        "start": 2215.68,
        "duration": 3.36,
        "text": "shows off the ability to read the essays"
      },
      {
        "start": 2217.119,
        "duration": 3.841,
        "text": "table data stick it in arrow format but"
      },
      {
        "start": 2219.04,
        "duration": 3.6,
        "text": "also send sending arrow format without"
      },
      {
        "start": 2220.96,
        "duration": 3.44,
        "text": "serializing the serializing over the"
      },
      {
        "start": 2222.64,
        "duration": 2.88,
        "text": "wire"
      },
      {
        "start": 2224.4,
        "duration": 3.04,
        "text": "and then"
      },
      {
        "start": 2225.52,
        "duration": 4.16,
        "text": "it gets turned in directly like red as"
      },
      {
        "start": 2227.44,
        "duration": 4.56,
        "text": "arrow directly in in python without any"
      },
      {
        "start": 2229.68,
        "duration": 3.679,
        "text": "serialization deserialization"
      },
      {
        "start": 2232.0,
        "duration": 4.0,
        "text": "and at that point"
      },
      {
        "start": 2233.359,
        "duration": 4.641,
        "text": "this script does some simple analytics"
      },
      {
        "start": 2236.0,
        "duration": 3.2,
        "text": "on it"
      },
      {
        "start": 2238.0,
        "duration": 4.24,
        "text": "so"
      },
      {
        "start": 2239.2,
        "duration": 4.72,
        "text": "so that's what we're doing um the first"
      },
      {
        "start": 2242.24,
        "duration": 4.16,
        "text": "thing is to pull that container which"
      },
      {
        "start": 2243.92,
        "duration": 4.88,
        "text": "hopefully you guys have already done"
      },
      {
        "start": 2246.4,
        "duration": 4.64,
        "text": "um the next thing is to pull the python"
      },
      {
        "start": 2248.8,
        "duration": 3.76,
        "text": "script it's going to be the client"
      },
      {
        "start": 2251.04,
        "duration": 3.44,
        "text": "you can do that with this very simple"
      },
      {
        "start": 2252.56,
        "duration": 4.32,
        "text": "curl command i already did that on my"
      },
      {
        "start": 2254.48,
        "duration": 3.44,
        "text": "machine"
      },
      {
        "start": 2256.88,
        "duration": 2.56,
        "text": "then"
      },
      {
        "start": 2257.92,
        "duration": 3.28,
        "text": "you want to create a"
      },
      {
        "start": 2259.44,
        "duration": 4.399,
        "text": "virtual environment"
      },
      {
        "start": 2261.2,
        "duration": 4.08,
        "text": "just to make sure that we have our own"
      },
      {
        "start": 2263.839,
        "duration": 3.201,
        "text": "you know python installation here that"
      },
      {
        "start": 2265.28,
        "duration": 3.04,
        "text": "doesn't interfere with your operating"
      },
      {
        "start": 2267.04,
        "duration": 3.52,
        "text": "system python"
      },
      {
        "start": 2268.32,
        "duration": 3.36,
        "text": "it's just a clean way of doing things"
      },
      {
        "start": 2270.56,
        "duration": 2.88,
        "text": "and making sure that we don't interfere"
      },
      {
        "start": 2271.68,
        "duration": 3.439,
        "text": "with your host environment"
      },
      {
        "start": 2273.44,
        "duration": 3.44,
        "text": "we activate that virtual environment in"
      },
      {
        "start": 2275.119,
        "duration": 3.441,
        "text": "python and install a couple of"
      },
      {
        "start": 2276.88,
        "duration": 4.08,
        "text": "dependencies"
      },
      {
        "start": 2278.56,
        "duration": 4.0,
        "text": "it's just pandas and pi arrow"
      },
      {
        "start": 2280.96,
        "duration": 3.36,
        "text": "in this case"
      },
      {
        "start": 2282.56,
        "duration": 3.92,
        "text": "there's another version of this that"
      },
      {
        "start": 2284.32,
        "duration": 5.039,
        "text": "does the actual gpu stuff"
      },
      {
        "start": 2286.48,
        "duration": 5.84,
        "text": "and that will also install"
      },
      {
        "start": 2289.359,
        "duration": 4.161,
        "text": "the qdf libraries"
      },
      {
        "start": 2292.32,
        "duration": 4.16,
        "text": "and then"
      },
      {
        "start": 2293.52,
        "duration": 4.96,
        "text": "we kick off the container which"
      },
      {
        "start": 2296.48,
        "duration": 4.72,
        "text": "gets those ss tables read and into"
      },
      {
        "start": 2298.48,
        "duration": 5.52,
        "text": "memory and arrow and we run the python"
      },
      {
        "start": 2301.2,
        "duration": 4.0,
        "text": "program that pulls that arrow data over"
      },
      {
        "start": 2304.0,
        "duration": 3.44,
        "text": "the wire"
      },
      {
        "start": 2305.2,
        "duration": 3.2,
        "text": "does some analytics on it"
      },
      {
        "start": 2307.44,
        "duration": 4.159,
        "text": "so"
      },
      {
        "start": 2308.4,
        "duration": 5.679,
        "text": "let's actually do that live here"
      },
      {
        "start": 2311.599,
        "duration": 4.401,
        "text": "this is the docker run command uh for"
      },
      {
        "start": 2314.079,
        "duration": 4.161,
        "text": "those of you not super familiar with"
      },
      {
        "start": 2316.0,
        "duration": 4.32,
        "text": "docker you may be wondering what this"
      },
      {
        "start": 2318.24,
        "duration": 4.16,
        "text": "dash p thing is well actually i'll break"
      },
      {
        "start": 2320.32,
        "duration": 3.44,
        "text": "down the whole command so"
      },
      {
        "start": 2322.4,
        "duration": 3.52,
        "text": "we already pulled"
      },
      {
        "start": 2323.76,
        "duration": 4.079,
        "text": "that means that on this machine i've got"
      },
      {
        "start": 2325.92,
        "duration": 4.4,
        "text": "this image sitting"
      },
      {
        "start": 2327.839,
        "duration": 2.481,
        "text": "sitting here"
      },
      {
        "start": 2330.64,
        "duration": 4.08,
        "text": "now i want to run that image"
      },
      {
        "start": 2332.4,
        "duration": 4.8,
        "text": "dash dash rm means that"
      },
      {
        "start": 2334.72,
        "duration": 4.639,
        "text": "once this process is completed"
      },
      {
        "start": 2337.2,
        "duration": 4.48,
        "text": "i don't want to hang on to that docker"
      },
      {
        "start": 2339.359,
        "duration": 4.381,
        "text": "run i actually want to delete it"
      },
      {
        "start": 2341.68,
        "duration": 3.679,
        "text": "from my docker environment"
      },
      {
        "start": 2343.74,
        "duration": 2.58,
        "text": "[Music]"
      },
      {
        "start": 2345.359,
        "duration": 3.521,
        "text": "then"
      },
      {
        "start": 2346.32,
        "duration": 5.039,
        "text": "it is passing a command"
      },
      {
        "start": 2348.88,
        "duration": 6.0,
        "text": "which in this case is dash s"
      },
      {
        "start": 2351.359,
        "duration": 4.641,
        "text": "and this dash p is telling our docker to"
      },
      {
        "start": 2354.88,
        "duration": 3.68,
        "text": "map"
      },
      {
        "start": 2356.0,
        "duration": 5.76,
        "text": "the port 9143"
      },
      {
        "start": 2358.56,
        "duration": 5.279,
        "text": "inside the container with the port 9143"
      },
      {
        "start": 2361.76,
        "duration": 3.92,
        "text": "outside the container in my host machine"
      },
      {
        "start": 2363.839,
        "duration": 4.161,
        "text": "and so that's what's going to allow the"
      },
      {
        "start": 2365.68,
        "duration": 4.56,
        "text": "client program in python to hit the"
      },
      {
        "start": 2368.0,
        "duration": 4.96,
        "text": "container through the network"
      },
      {
        "start": 2370.24,
        "duration": 4.4,
        "text": "so once i kick this off"
      },
      {
        "start": 2372.96,
        "duration": 4.159,
        "text": "you can see that"
      },
      {
        "start": 2374.64,
        "duration": 4.08,
        "text": "it found some ss tables and then it"
      },
      {
        "start": 2377.119,
        "duration": 4.321,
        "text": "created a socket"
      },
      {
        "start": 2378.72,
        "duration": 6.32,
        "text": "on port 9143"
      },
      {
        "start": 2381.44,
        "duration": 4.96,
        "text": "so let me pull up another window here"
      },
      {
        "start": 2385.04,
        "duration": 3.319,
        "text": "if i"
      },
      {
        "start": 2386.4,
        "duration": 6.88,
        "text": "that's f dash i"
      },
      {
        "start": 2388.359,
        "duration": 6.76,
        "text": "90 43 we said it's the port 9143 sorry"
      },
      {
        "start": 2393.28,
        "duration": 6.559,
        "text": "143."
      },
      {
        "start": 2395.119,
        "duration": 4.72,
        "text": "oh uh i think you might need a space"
      },
      {
        "start": 2399.92,
        "duration": 3.84,
        "text": "touch i space 9143"
      },
      {
        "start": 2406.88,
        "duration": 4.36,
        "text": "i space colon 9143"
      },
      {
        "start": 2414.96,
        "duration": 4.08,
        "text": "oh you know what i need to do this as"
      },
      {
        "start": 2416.72,
        "duration": 2.32,
        "text": "root"
      },
      {
        "start": 2422.16,
        "duration": 4.24,
        "text": "yeah so here you go um"
      },
      {
        "start": 2425.44,
        "duration": 2.8,
        "text": "docker"
      },
      {
        "start": 2426.4,
        "duration": 3.28,
        "text": "is here there's a docker process it's"
      },
      {
        "start": 2428.24,
        "duration": 3.68,
        "text": "listening to"
      },
      {
        "start": 2429.68,
        "duration": 4.56,
        "text": "all interfaces on all interfaces on the"
      },
      {
        "start": 2431.92,
        "duration": 4.919,
        "text": "port 9143"
      },
      {
        "start": 2434.24,
        "duration": 4.72,
        "text": "um so this is just a way to validate"
      },
      {
        "start": 2436.839,
        "duration": 4.041,
        "text": "that um"
      },
      {
        "start": 2438.96,
        "duration": 3.04,
        "text": "we can also say docker ps which shows"
      },
      {
        "start": 2440.88,
        "duration": 2.88,
        "text": "you"
      },
      {
        "start": 2442.0,
        "duration": 3.92,
        "text": "that docker is listening and it's got"
      },
      {
        "start": 2443.76,
        "duration": 2.96,
        "text": "ports then on my host machine i can see"
      },
      {
        "start": 2445.92,
        "duration": 2.8,
        "text": "it"
      },
      {
        "start": 2446.72,
        "duration": 4.48,
        "text": "listening on the port so these are just"
      },
      {
        "start": 2448.72,
        "duration": 4.399,
        "text": "kind of some free troubleshooting steps"
      },
      {
        "start": 2451.2,
        "duration": 3.36,
        "text": "in case folks get stuck this validates"
      },
      {
        "start": 2453.119,
        "duration": 3.761,
        "text": "that your docker"
      },
      {
        "start": 2454.56,
        "duration": 4.559,
        "text": "section is part is running correctly if"
      },
      {
        "start": 2456.88,
        "duration": 3.28,
        "text": "you're able to do both of these things"
      },
      {
        "start": 2459.119,
        "duration": 2.641,
        "text": "um"
      },
      {
        "start": 2460.16,
        "duration": 3.52,
        "text": "and then i'm gonna actually go ahead and"
      },
      {
        "start": 2461.76,
        "duration": 4.16,
        "text": "kick off this cuda code now before"
      },
      {
        "start": 2463.68,
        "duration": 4.48,
        "text": "running the script maybe let's take a"
      },
      {
        "start": 2465.92,
        "duration": 4.399,
        "text": "look at it"
      },
      {
        "start": 2468.16,
        "duration": 4.159,
        "text": "so"
      },
      {
        "start": 2470.319,
        "duration": 3.681,
        "text": "it's got a couple of variables here for"
      },
      {
        "start": 2472.319,
        "duration": 2.8,
        "text": "localhost and the port that we're going"
      },
      {
        "start": 2474.0,
        "duration": 2.4,
        "text": "to be listening then we're going to be"
      },
      {
        "start": 2475.119,
        "duration": 4.0,
        "text": "uh"
      },
      {
        "start": 2476.4,
        "duration": 5.04,
        "text": "reaching out to the socket on"
      },
      {
        "start": 2479.119,
        "duration": 4.401,
        "text": "there's some functions that are defined"
      },
      {
        "start": 2481.44,
        "duration": 5.6,
        "text": "and"
      },
      {
        "start": 2483.52,
        "duration": 4.4,
        "text": "let's see so there's no cuda"
      },
      {
        "start": 2487.04,
        "duration": 2.559,
        "text": "um"
      },
      {
        "start": 2487.92,
        "duration": 4.56,
        "text": "but we're going to go through and open"
      },
      {
        "start": 2489.599,
        "duration": 2.881,
        "text": "up the stream"
      },
      {
        "start": 2493.2,
        "duration": 4.8,
        "text": "and once we've got the data it's going"
      },
      {
        "start": 2495.68,
        "duration": 4.56,
        "text": "to be in a data frame and we're going to"
      },
      {
        "start": 2498.0,
        "duration": 4.16,
        "text": "basically print it out print the mean of"
      },
      {
        "start": 2500.24,
        "duration": 3.44,
        "text": "a column called sensor value so this is"
      },
      {
        "start": 2502.16,
        "duration": 3.36,
        "text": "the simple analytics stuff that we're"
      },
      {
        "start": 2503.68,
        "duration": 3.6,
        "text": "talking about"
      },
      {
        "start": 2505.52,
        "duration": 5.839,
        "text": "and then this"
      },
      {
        "start": 2507.28,
        "duration": 5.92,
        "text": "ipc open stream read all two pandas"
      },
      {
        "start": 2511.359,
        "duration": 4.401,
        "text": "reaches out to the c plus pulse program"
      },
      {
        "start": 2513.2,
        "duration": 5.52,
        "text": "gets the data over the wire"
      },
      {
        "start": 2515.76,
        "duration": 5.52,
        "text": "and sticks it into pandas data frame"
      },
      {
        "start": 2518.72,
        "duration": 4.8,
        "text": "um so so the the interoperability with"
      },
      {
        "start": 2521.28,
        "duration": 3.68,
        "text": "arrow is also showing here so"
      },
      {
        "start": 2523.52,
        "duration": 2.559,
        "text": "we're going from arrow to pandas very"
      },
      {
        "start": 2524.96,
        "duration": 3.2,
        "text": "easily"
      },
      {
        "start": 2526.079,
        "duration": 4.721,
        "text": "um in the gpu code we go from arrow to"
      },
      {
        "start": 2528.16,
        "duration": 4.56,
        "text": "qdf very easily same deal right to"
      },
      {
        "start": 2530.8,
        "duration": 3.68,
        "text": "pandas to qdf uh you'll be able to see"
      },
      {
        "start": 2532.72,
        "duration": 4.16,
        "text": "that if you take a look at the"
      },
      {
        "start": 2534.48,
        "duration": 5.76,
        "text": "with gpu code so that's what the program"
      },
      {
        "start": 2536.88,
        "duration": 3.36,
        "text": "does let's go ahead and run it"
      },
      {
        "start": 2541.52,
        "duration": 4.0,
        "text": "all right so"
      },
      {
        "start": 2543.839,
        "duration": 4.48,
        "text": "i loaded the table"
      },
      {
        "start": 2545.52,
        "duration": 6.04,
        "text": "and we spat out"
      },
      {
        "start": 2548.319,
        "duration": 3.241,
        "text": "some columns"
      },
      {
        "start": 2551.68,
        "duration": 3.6,
        "text": "in this case we have a partition key"
      },
      {
        "start": 2553.44,
        "duration": 4.24,
        "text": "which is a uuid type"
      },
      {
        "start": 2555.28,
        "duration": 4.4,
        "text": "we have some row likeness"
      },
      {
        "start": 2557.68,
        "duration": 3.919,
        "text": "and we have some times"
      },
      {
        "start": 2559.68,
        "duration": 3.439,
        "text": "and you can see here that"
      },
      {
        "start": 2561.599,
        "duration": 3.921,
        "text": "we calculated"
      },
      {
        "start": 2563.119,
        "duration": 3.761,
        "text": "the mean of sensor value"
      },
      {
        "start": 2565.52,
        "duration": 2.96,
        "text": "of a few rows i think there's a thousand"
      },
      {
        "start": 2566.88,
        "duration": 3.92,
        "text": "rows right they got red"
      },
      {
        "start": 2568.48,
        "duration": 3.359,
        "text": "in this example ss table"
      },
      {
        "start": 2570.8,
        "duration": 3.2,
        "text": "if you have"
      },
      {
        "start": 2571.839,
        "duration": 3.921,
        "text": "your own ss tables"
      },
      {
        "start": 2574.0,
        "duration": 4.079,
        "text": "then you want that you want to parse and"
      },
      {
        "start": 2575.76,
        "duration": 4.0,
        "text": "manipulate you can pass the directory"
      },
      {
        "start": 2578.079,
        "duration": 4.401,
        "text": "with those ss tables to this program"
      },
      {
        "start": 2579.76,
        "duration": 4.4,
        "text": "there's more information and"
      },
      {
        "start": 2582.48,
        "duration": 4.16,
        "text": "github on how to do it"
      },
      {
        "start": 2584.16,
        "duration": 4.08,
        "text": "and we'd also be happy to you know"
      },
      {
        "start": 2586.64,
        "duration": 3.12,
        "text": "help out there if you want to reach out"
      },
      {
        "start": 2588.24,
        "duration": 3.2,
        "text": "to us"
      },
      {
        "start": 2589.76,
        "duration": 3.12,
        "text": "um"
      },
      {
        "start": 2591.44,
        "duration": 3.36,
        "text": "yeah awesome yeah this is what it does i"
      },
      {
        "start": 2592.88,
        "duration": 2.959,
        "text": "guess i'll add a couple of other a"
      },
      {
        "start": 2594.8,
        "duration": 2.0,
        "text": "couple of other points that might be"
      },
      {
        "start": 2595.839,
        "duration": 2.961,
        "text": "interesting to cassandra folks if"
      },
      {
        "start": 2596.8,
        "duration": 3.039,
        "text": "there's no questions at this point"
      },
      {
        "start": 2598.8,
        "duration": 3.36,
        "text": "um"
      },
      {
        "start": 2599.839,
        "duration": 4.561,
        "text": "one of them is the liveness"
      },
      {
        "start": 2602.16,
        "duration": 5.36,
        "text": "so one of the interesting things about a"
      },
      {
        "start": 2604.4,
        "duration": 4.16,
        "text": "cassandra table from a data storage"
      },
      {
        "start": 2607.52,
        "duration": 2.4,
        "text": "perspective"
      },
      {
        "start": 2608.56,
        "duration": 3.36,
        "text": "and"
      },
      {
        "start": 2609.92,
        "duration": 3.439,
        "text": "alex was mentioning data as data goes"
      },
      {
        "start": 2611.92,
        "duration": 3.36,
        "text": "into the cassandra goes into event table"
      },
      {
        "start": 2613.359,
        "duration": 3.201,
        "text": "and a commit log"
      },
      {
        "start": 2615.28,
        "duration": 3.44,
        "text": "before we acknowledge to the client the"
      },
      {
        "start": 2616.56,
        "duration": 4.48,
        "text": "data got written it's going to be stored"
      },
      {
        "start": 2618.72,
        "duration": 3.68,
        "text": "in um it's going to be"
      },
      {
        "start": 2621.04,
        "duration": 3.279,
        "text": "persistent on disk and the commit log"
      },
      {
        "start": 2622.4,
        "duration": 3.199,
        "text": "and then it'll also be in memory and"
      },
      {
        "start": 2624.319,
        "duration": 2.881,
        "text": "event table"
      },
      {
        "start": 2625.599,
        "duration": 3.361,
        "text": "those map tables fill up and they get"
      },
      {
        "start": 2627.2,
        "duration": 3.76,
        "text": "flushed into ss tables and ss tables are"
      },
      {
        "start": 2628.96,
        "duration": 3.6,
        "text": "what we're looking at so"
      },
      {
        "start": 2630.96,
        "duration": 4.159,
        "text": "one from a kind of caveats perspective"
      },
      {
        "start": 2632.56,
        "duration": 4.16,
        "text": "of the project um if you were doing this"
      },
      {
        "start": 2635.119,
        "duration": 3.121,
        "text": "against all the ss tables in your"
      },
      {
        "start": 2636.72,
        "duration": 2.879,
        "text": "cassandra cluster"
      },
      {
        "start": 2638.24,
        "duration": 3.28,
        "text": "uh"
      },
      {
        "start": 2639.599,
        "duration": 3.921,
        "text": "one you wouldn't be getting the"
      },
      {
        "start": 2641.52,
        "duration": 3.839,
        "text": "real-time data that's in mem tables as"
      },
      {
        "start": 2643.52,
        "duration": 2.96,
        "text": "of that point so"
      },
      {
        "start": 2645.359,
        "duration": 2.321,
        "text": "based on"
      },
      {
        "start": 2646.48,
        "duration": 2.4,
        "text": "the the software that's been developed"
      },
      {
        "start": 2647.68,
        "duration": 2.08,
        "text": "up to now"
      },
      {
        "start": 2648.88,
        "duration": 2.719,
        "text": "um"
      },
      {
        "start": 2649.76,
        "duration": 4.64,
        "text": "this it's going to be very useful for"
      },
      {
        "start": 2651.599,
        "duration": 4.561,
        "text": "performing analytics on cassandra data"
      },
      {
        "start": 2654.4,
        "duration": 4.24,
        "text": "based of kind of a snapshot"
      },
      {
        "start": 2656.16,
        "duration": 3.679,
        "text": "but not like the latest data"
      },
      {
        "start": 2658.64,
        "duration": 2.8,
        "text": "another thing that"
      },
      {
        "start": 2659.839,
        "duration": 2.641,
        "text": "that's kind of a caveat to keep in mind"
      },
      {
        "start": 2661.44,
        "duration": 2.72,
        "text": "is"
      },
      {
        "start": 2662.48,
        "duration": 3.2,
        "text": "a cassandra table"
      },
      {
        "start": 2664.16,
        "duration": 3.76,
        "text": "is going to be is going to result in"
      },
      {
        "start": 2665.68,
        "duration": 3.679,
        "text": "lots of ss tables on disk and not only"
      },
      {
        "start": 2667.92,
        "duration": 2.8,
        "text": "lots of excess tables on disk in one"
      },
      {
        "start": 2669.359,
        "duration": 2.881,
        "text": "place but lots of ss tables on disk"
      },
      {
        "start": 2670.72,
        "duration": 3.599,
        "text": "across lots of machines"
      },
      {
        "start": 2672.24,
        "duration": 4.0,
        "text": "and so you do need kind of a way to"
      },
      {
        "start": 2674.319,
        "duration": 3.921,
        "text": "consolidate all of those and hit them"
      },
      {
        "start": 2676.24,
        "duration": 3.04,
        "text": "with as a stable arrow to get useful"
      },
      {
        "start": 2678.24,
        "duration": 2.96,
        "text": "data"
      },
      {
        "start": 2679.28,
        "duration": 3.6,
        "text": "secondly um"
      },
      {
        "start": 2681.2,
        "duration": 4.399,
        "text": "cassandra uses a lot a lot of structured"
      },
      {
        "start": 2682.88,
        "duration": 4.16,
        "text": "merge right so uh yes so that's what ss"
      },
      {
        "start": 2685.599,
        "duration": 2.321,
        "text": "tables are there"
      },
      {
        "start": 2687.04,
        "duration": 2.559,
        "text": "data"
      },
      {
        "start": 2687.92,
        "duration": 3.12,
        "text": "it's a data storage format that's"
      },
      {
        "start": 2689.599,
        "duration": 3.841,
        "text": "basically a log"
      },
      {
        "start": 2691.04,
        "duration": 3.76,
        "text": "and ss tables are immutable which means"
      },
      {
        "start": 2693.44,
        "duration": 3.12,
        "text": "that if you have"
      },
      {
        "start": 2694.8,
        "duration": 3.12,
        "text": "updates in your data"
      },
      {
        "start": 2696.56,
        "duration": 3.92,
        "text": "you may have"
      },
      {
        "start": 2697.92,
        "duration": 4.56,
        "text": "values for the same you know unique key"
      },
      {
        "start": 2700.48,
        "duration": 4.48,
        "text": "across a couple different ss tables and"
      },
      {
        "start": 2702.48,
        "duration": 4.4,
        "text": "cassandra on reading will"
      },
      {
        "start": 2704.96,
        "duration": 3.68,
        "text": "basically pick the latest using last"
      },
      {
        "start": 2706.88,
        "duration": 2.719,
        "text": "right-wing semantics"
      },
      {
        "start": 2708.64,
        "duration": 2.24,
        "text": "and so"
      },
      {
        "start": 2709.599,
        "duration": 2.321,
        "text": "ss table to"
      },
      {
        "start": 2710.88,
        "duration": 2.719,
        "text": "arrow"
      },
      {
        "start": 2711.92,
        "duration": 3.199,
        "text": "doesn't do that right winston antics for"
      },
      {
        "start": 2713.599,
        "duration": 3.841,
        "text": "you yet"
      },
      {
        "start": 2715.119,
        "duration": 4.561,
        "text": "what it does is it exposes the internal"
      },
      {
        "start": 2717.44,
        "duration": 3.84,
        "text": "timestamps of all the cells"
      },
      {
        "start": 2719.68,
        "duration": 2.399,
        "text": "in the arrow"
      },
      {
        "start": 2721.28,
        "duration": 2.96,
        "text": "in the"
      },
      {
        "start": 2722.079,
        "duration": 3.04,
        "text": "in the arrow in memory structure and"
      },
      {
        "start": 2724.24,
        "duration": 4.079,
        "text": "then"
      },
      {
        "start": 2725.119,
        "duration": 4.48,
        "text": "as a user you can write some sql to say"
      },
      {
        "start": 2728.319,
        "duration": 3.121,
        "text": "i would like to get"
      },
      {
        "start": 2729.599,
        "duration": 3.121,
        "text": "you know the latest time stamp throws or"
      },
      {
        "start": 2731.44,
        "duration": 3.04,
        "text": "the last time perhaps it's time to have"
      },
      {
        "start": 2732.72,
        "duration": 4.16,
        "text": "cells for the rows that i care about"
      },
      {
        "start": 2734.48,
        "duration": 4.4,
        "text": "um so so that's kind of the stage"
      },
      {
        "start": 2736.88,
        "duration": 5.199,
        "text": "the stages that the process is on um"
      },
      {
        "start": 2738.88,
        "duration": 5.12,
        "text": "again it's very useful in"
      },
      {
        "start": 2742.079,
        "duration": 3.601,
        "text": "kind of first first few steps first lots"
      },
      {
        "start": 2744.0,
        "duration": 3.28,
        "text": "of steps into this kind of journey of"
      },
      {
        "start": 2745.68,
        "duration": 3.76,
        "text": "getting of making cassandra data"
      },
      {
        "start": 2747.28,
        "duration": 3.44,
        "text": "available in gpus uh but there's"
      },
      {
        "start": 2749.44,
        "duration": 2.159,
        "text": "certainly lots of work to be done as"
      },
      {
        "start": 2750.72,
        "duration": 2.56,
        "text": "well"
      },
      {
        "start": 2751.599,
        "duration": 3.841,
        "text": "and you know whether we continue to do"
      },
      {
        "start": 2753.28,
        "duration": 4.0,
        "text": "that and invest i think hinges on"
      },
      {
        "start": 2755.44,
        "duration": 4.24,
        "text": "how interested folks are right so we're"
      },
      {
        "start": 2757.28,
        "duration": 4.319,
        "text": "very excited to hear from people about"
      },
      {
        "start": 2759.68,
        "duration": 3.36,
        "text": "you know what they think about this and"
      },
      {
        "start": 2761.599,
        "duration": 3.281,
        "text": "whether they want to pursue it for you"
      },
      {
        "start": 2763.04,
        "duration": 3.279,
        "text": "know their real use cases"
      },
      {
        "start": 2764.88,
        "duration": 2.959,
        "text": "and you know we'd love to hear from you"
      },
      {
        "start": 2766.319,
        "duration": 4.401,
        "text": "and chat more about it and see how we"
      },
      {
        "start": 2767.839,
        "duration": 2.881,
        "text": "take this into the future"
      },
      {
        "start": 2770.88,
        "duration": 4.719,
        "text": "yeah awesome okay thanks so much sub um"
      },
      {
        "start": 2773.76,
        "duration": 3.839,
        "text": "all right i'm going to go back to"
      },
      {
        "start": 2775.599,
        "duration": 3.52,
        "text": "sharing my screen um"
      },
      {
        "start": 2777.599,
        "duration": 3.201,
        "text": "questions at this point in the chat at"
      },
      {
        "start": 2779.119,
        "duration": 4.161,
        "text": "all or folks trying it"
      },
      {
        "start": 2780.8,
        "duration": 4.88,
        "text": "i can't see the chat so uh i guess if"
      },
      {
        "start": 2783.28,
        "duration": 4.4,
        "text": "you guys have any questions um sub if"
      },
      {
        "start": 2785.68,
        "duration": 4.0,
        "text": "you can like i guess redirect them if"
      },
      {
        "start": 2787.68,
        "duration": 4.32,
        "text": "they're specifically for me"
      },
      {
        "start": 2789.68,
        "duration": 4.32,
        "text": "so uh real quick i just wanted to i'm"
      },
      {
        "start": 2792.0,
        "duration": 3.76,
        "text": "popping back in uh we do have a few"
      },
      {
        "start": 2794.0,
        "duration": 4.48,
        "text": "questions though i i know justin has"
      },
      {
        "start": 2795.76,
        "duration": 3.92,
        "text": "been uh in the chat answering a lot of"
      },
      {
        "start": 2798.48,
        "duration": 2.72,
        "text": "them i was wondering justin if you"
      },
      {
        "start": 2799.68,
        "duration": 4.88,
        "text": "wanted to i know you answered the"
      },
      {
        "start": 2801.2,
        "duration": 3.36,
        "text": "question about um"
      },
      {
        "start": 2804.64,
        "duration": 4.56,
        "text": "the analytics"
      },
      {
        "start": 2806.96,
        "duration": 4.24,
        "text": "on gpu versus"
      },
      {
        "start": 2809.2,
        "duration": 3.44,
        "text": "otherwise uh you had kind of had a"
      },
      {
        "start": 2811.2,
        "duration": 2.8,
        "text": "longer answer i don't know if you wanted"
      },
      {
        "start": 2812.64,
        "duration": 2.64,
        "text": "to talk about that"
      },
      {
        "start": 2814.0,
        "duration": 2.96,
        "text": "more"
      },
      {
        "start": 2815.28,
        "duration": 2.88,
        "text": "to the yeah everyone one of the things"
      },
      {
        "start": 2816.96,
        "duration": 3.28,
        "text": "we want one of the things we want to"
      },
      {
        "start": 2818.16,
        "duration": 4.24,
        "text": "convey is that you know what alex has"
      },
      {
        "start": 2820.24,
        "duration": 4.24,
        "text": "done at least from the ss table to aero"
      },
      {
        "start": 2822.4,
        "duration": 4.32,
        "text": "is that you know you can"
      },
      {
        "start": 2824.48,
        "duration": 6.08,
        "text": "you can analyze the data on cpu but also"
      },
      {
        "start": 2826.72,
        "duration": 6.56,
        "text": "a gpu now say you are an analyst data"
      },
      {
        "start": 2830.56,
        "duration": 4.64,
        "text": "scientist who is"
      },
      {
        "start": 2833.28,
        "duration": 4.799,
        "text": "attempting to do some code on a smaller"
      },
      {
        "start": 2835.2,
        "duration": 5.04,
        "text": "data set you access the data and asset"
      },
      {
        "start": 2838.079,
        "duration": 3.76,
        "text": "table you go through your your or your"
      },
      {
        "start": 2840.24,
        "duration": 3.599,
        "text": "data science order of operations"
      },
      {
        "start": 2841.839,
        "duration": 3.441,
        "text": "essentially you know the data expiration"
      },
      {
        "start": 2843.839,
        "duration": 3.681,
        "text": "component"
      },
      {
        "start": 2845.28,
        "duration": 4.48,
        "text": "identifying you know which features are"
      },
      {
        "start": 2847.52,
        "duration": 4.319,
        "text": "correlated or decorated"
      },
      {
        "start": 2849.76,
        "duration": 4.559,
        "text": "putting it into essentially a more uh"
      },
      {
        "start": 2851.839,
        "duration": 5.601,
        "text": "data subset that you then run a smaller"
      },
      {
        "start": 2854.319,
        "duration": 4.8,
        "text": "model on maybe just a standard tree"
      },
      {
        "start": 2857.44,
        "duration": 4.48,
        "text": "based model random forest or something"
      },
      {
        "start": 2859.119,
        "duration": 4.96,
        "text": "like that but now understanding that"
      },
      {
        "start": 2861.92,
        "duration": 3.679,
        "text": "because your code has a specific logic"
      },
      {
        "start": 2864.079,
        "duration": 3.28,
        "text": "you don't necessarily now have to worry"
      },
      {
        "start": 2865.599,
        "duration": 3.841,
        "text": "about"
      },
      {
        "start": 2867.359,
        "duration": 3.121,
        "text": "converting it to pi spark code or"
      },
      {
        "start": 2869.44,
        "duration": 3.36,
        "text": "something like that to perform"
      },
      {
        "start": 2870.48,
        "duration": 4.639,
        "text": "additional analysis to scale up or scale"
      },
      {
        "start": 2872.8,
        "duration": 4.72,
        "text": "out you can essentially take your code"
      },
      {
        "start": 2875.119,
        "duration": 5.601,
        "text": "using the apis similar to the example"
      },
      {
        "start": 2877.52,
        "duration": 5.92,
        "text": "that alex showed previously where it's"
      },
      {
        "start": 2880.72,
        "duration": 4.879,
        "text": "just a minor syntax change it's just"
      },
      {
        "start": 2883.44,
        "duration": 4.399,
        "text": "literally changing importing one package"
      },
      {
        "start": 2885.599,
        "duration": 4.801,
        "text": "versus another and then that code will"
      },
      {
        "start": 2887.839,
        "duration": 4.321,
        "text": "essentially now run on a gpu so then you"
      },
      {
        "start": 2890.4,
        "duration": 3.36,
        "text": "can take your process and now if you"
      },
      {
        "start": 2892.16,
        "duration": 3.199,
        "text": "want to automate this process or have it"
      },
      {
        "start": 2893.76,
        "duration": 3.839,
        "text": "run it in a cloud-based"
      },
      {
        "start": 2895.359,
        "duration": 5.121,
        "text": "uh orchestration or have this process"
      },
      {
        "start": 2897.599,
        "duration": 4.561,
        "text": "run you know on a gpu on the cloud"
      },
      {
        "start": 2900.48,
        "duration": 3.04,
        "text": "you can know that it's going to follow"
      },
      {
        "start": 2902.16,
        "duration": 3.36,
        "text": "your logic and you won't have to"
      },
      {
        "start": 2903.52,
        "duration": 3.76,
        "text": "necessarily worry about any other types"
      },
      {
        "start": 2905.52,
        "duration": 3.2,
        "text": "of of"
      },
      {
        "start": 2907.28,
        "duration": 3.039,
        "text": "logic adjustments that you'd have to"
      },
      {
        "start": 2908.72,
        "duration": 3.359,
        "text": "make by converting it from running on a"
      },
      {
        "start": 2910.319,
        "duration": 3.28,
        "text": "cpu to a gpu"
      },
      {
        "start": 2912.079,
        "duration": 3.04,
        "text": "so there's a"
      },
      {
        "start": 2913.599,
        "duration": 4.48,
        "text": "interchangeability available there"
      },
      {
        "start": 2915.119,
        "duration": 2.96,
        "text": "between the two api"
      },
      {
        "start": 2921.2,
        "duration": 2.48,
        "text": "awesome okay"
      },
      {
        "start": 2924.319,
        "duration": 3.681,
        "text": "it doesn't look like there are any other"
      },
      {
        "start": 2925.839,
        "duration": 3.361,
        "text": "uh specific questions and for those for"
      },
      {
        "start": 2928.0,
        "duration": 2.96,
        "text": "the viewers"
      },
      {
        "start": 2929.2,
        "duration": 2.72,
        "text": "give us your questions please uh we'll"
      },
      {
        "start": 2930.96,
        "duration": 2.56,
        "text": "we have"
      },
      {
        "start": 2931.92,
        "duration": 3.919,
        "text": "plenty of time today so if you have any"
      },
      {
        "start": 2933.52,
        "duration": 4.4,
        "text": "questions um stick them in chat and"
      },
      {
        "start": 2935.839,
        "duration": 4.72,
        "text": "we'll uh we'll answer them on on stream"
      },
      {
        "start": 2937.92,
        "duration": 6.159,
        "text": "as well all right back to you alex"
      },
      {
        "start": 2940.559,
        "duration": 5.121,
        "text": "okay sure so yeah now we'll sort of um"
      },
      {
        "start": 2944.079,
        "duration": 3.52,
        "text": "go through so you guys have hopefully"
      },
      {
        "start": 2945.68,
        "duration": 4.48,
        "text": "gotten a chance to try out ss table to"
      },
      {
        "start": 2947.599,
        "duration": 5.281,
        "text": "arrow on your own machines but in case"
      },
      {
        "start": 2950.16,
        "duration": 5.28,
        "text": "you don't have a machine that um is"
      },
      {
        "start": 2952.88,
        "duration": 4.4,
        "text": "compatible with cuda which is once again"
      },
      {
        "start": 2955.44,
        "duration": 3.6,
        "text": "the sort of framework that allows you to"
      },
      {
        "start": 2957.28,
        "duration": 4.24,
        "text": "interact with the gpu"
      },
      {
        "start": 2959.04,
        "duration": 5.12,
        "text": "um here's um we're going to do a little"
      },
      {
        "start": 2961.52,
        "duration": 6.0,
        "text": "brief demo of how ss table to arrow can"
      },
      {
        "start": 2964.16,
        "duration": 6.32,
        "text": "help get data onto the gpu using rapids"
      },
      {
        "start": 2967.52,
        "duration": 5.039,
        "text": "so if i go ahead and"
      },
      {
        "start": 2970.48,
        "duration": 5.119,
        "text": "share my screen here"
      },
      {
        "start": 2972.559,
        "duration": 6.881,
        "text": "and open this up"
      },
      {
        "start": 2975.599,
        "duration": 3.841,
        "text": "so we're unable to sort of see that okay"
      },
      {
        "start": 2980.72,
        "duration": 4.599,
        "text": "sub is it visible on the stream"
      },
      {
        "start": 2985.92,
        "duration": 7.52,
        "text": "yeah it was good okay awesome so yeah um"
      },
      {
        "start": 2990.24,
        "duration": 5.04,
        "text": "like we sort of mentioned earlier um"
      },
      {
        "start": 2993.44,
        "duration": 4.159,
        "text": "rapids allows you to sort of take"
      },
      {
        "start": 2995.28,
        "duration": 4.319,
        "text": "existing code um that you might have"
      },
      {
        "start": 2997.599,
        "duration": 4.561,
        "text": "with python or"
      },
      {
        "start": 2999.599,
        "duration": 5.52,
        "text": "popular libraries and easily run that on"
      },
      {
        "start": 3002.16,
        "duration": 4.159,
        "text": "the gpu instead so what we have here is"
      },
      {
        "start": 3005.119,
        "duration": 3.281,
        "text": "i've taken"
      },
      {
        "start": 3006.319,
        "duration": 3.681,
        "text": "the iris data set so"
      },
      {
        "start": 3008.4,
        "duration": 3.04,
        "text": "um hopefully those of you who have"
      },
      {
        "start": 3010.0,
        "duration": 3.28,
        "text": "tinkered a little bit with machine"
      },
      {
        "start": 3011.44,
        "duration": 4.0,
        "text": "learning you might have encountered the"
      },
      {
        "start": 3013.28,
        "duration": 3.279,
        "text": "data set before it's essentially a data"
      },
      {
        "start": 3015.44,
        "duration": 3.76,
        "text": "set of"
      },
      {
        "start": 3016.559,
        "duration": 3.841,
        "text": "iris flowers and has data about i think"
      },
      {
        "start": 3019.2,
        "duration": 3.2,
        "text": "it's their"
      },
      {
        "start": 3020.4,
        "duration": 4.24,
        "text": "pedal length pedal width simple length"
      },
      {
        "start": 3022.4,
        "duration": 3.76,
        "text": "sepal width and then their species and"
      },
      {
        "start": 3024.64,
        "duration": 3.199,
        "text": "so there's three different species and"
      },
      {
        "start": 3026.16,
        "duration": 3.52,
        "text": "it's a pretty classic sort of"
      },
      {
        "start": 3027.839,
        "duration": 3.76,
        "text": "classification problem which is where"
      },
      {
        "start": 3029.68,
        "duration": 4.48,
        "text": "you ask the computer to look at a bunch"
      },
      {
        "start": 3031.599,
        "duration": 3.441,
        "text": "of data and then try to classify new"
      },
      {
        "start": 3034.16,
        "duration": 3.12,
        "text": "data"
      },
      {
        "start": 3035.04,
        "duration": 3.6,
        "text": "um into being you know a member of a"
      },
      {
        "start": 3037.28,
        "duration": 3.12,
        "text": "certain class"
      },
      {
        "start": 3038.64,
        "duration": 4.56,
        "text": "so scikit-learn"
      },
      {
        "start": 3040.4,
        "duration": 5.76,
        "text": "which is a python library for the cpu"
      },
      {
        "start": 3043.2,
        "duration": 7.04,
        "text": "mostly um that does machine learning"
      },
      {
        "start": 3046.16,
        "duration": 5.919,
        "text": "um it already has a couple examples of"
      },
      {
        "start": 3050.24,
        "duration": 4.079,
        "text": "using the iris data set for some simple"
      },
      {
        "start": 3052.079,
        "duration": 5.121,
        "text": "classification and i was thinking we"
      },
      {
        "start": 3054.319,
        "duration": 4.24,
        "text": "could use as a stapled arrow to show how"
      },
      {
        "start": 3057.2,
        "duration": 2.879,
        "text": "you might"
      },
      {
        "start": 3058.559,
        "duration": 3.681,
        "text": "if you had that data in a cassandra"
      },
      {
        "start": 3060.079,
        "duration": 5.361,
        "text": "table for example how you might take"
      },
      {
        "start": 3062.24,
        "duration": 4.48,
        "text": "that data and load it onto the gpu using"
      },
      {
        "start": 3065.44,
        "duration": 3.44,
        "text": "rapids"
      },
      {
        "start": 3066.72,
        "duration": 5.28,
        "text": "so here i'm this isn't my local machine"
      },
      {
        "start": 3068.88,
        "duration": 4.8,
        "text": "i'm logged into a remote computer um and"
      },
      {
        "start": 3072.0,
        "duration": 4.0,
        "text": "yeah so we're importing a bunch of"
      },
      {
        "start": 3073.68,
        "duration": 5.2,
        "text": "libraries um and then this is the same"
      },
      {
        "start": 3076.0,
        "duration": 6.319,
        "text": "command that gets run in the"
      },
      {
        "start": 3078.88,
        "duration": 6.08,
        "text": "no qdf version um so it'll basically"
      },
      {
        "start": 3082.319,
        "duration": 4.881,
        "text": "fetch the data from"
      },
      {
        "start": 3084.96,
        "duration": 4.0,
        "text": "um ss table to arrow so if i go ahead"
      },
      {
        "start": 3087.2,
        "duration": 5.44,
        "text": "open up my command line here zoom in"
      },
      {
        "start": 3088.96,
        "duration": 5.76,
        "text": "really close um if i go ahead and"
      },
      {
        "start": 3092.64,
        "duration": 3.919,
        "text": "let me close that up run this function"
      },
      {
        "start": 3094.72,
        "duration": 2.96,
        "text": "so as is table to arrow that's the same"
      },
      {
        "start": 3096.559,
        "duration": 3.201,
        "text": "thing you're running from your docker"
      },
      {
        "start": 3097.68,
        "duration": 4.399,
        "text": "container um i just have it installed on"
      },
      {
        "start": 3099.76,
        "duration": 4.4,
        "text": "this computer um so i'm just running it"
      },
      {
        "start": 3102.079,
        "duration": 4.801,
        "text": "from the command line um so s is table"
      },
      {
        "start": 3104.16,
        "duration": 5.199,
        "text": "to arrow and then i have this flag dash"
      },
      {
        "start": 3106.88,
        "duration": 4.479,
        "text": "c um oh by the way i should probably"
      },
      {
        "start": 3109.359,
        "duration": 3.76,
        "text": "mention that so if you want to see more"
      },
      {
        "start": 3111.359,
        "duration": 4.801,
        "text": "options about how to use sstable to"
      },
      {
        "start": 3113.119,
        "duration": 5.121,
        "text": "arrow you can also pass the help flag"
      },
      {
        "start": 3116.16,
        "duration": 3.679,
        "text": "and it'll print out a bunch of"
      },
      {
        "start": 3118.24,
        "duration": 4.24,
        "text": "like different flags it's a really big"
      },
      {
        "start": 3119.839,
        "duration": 5.041,
        "text": "help message um yeah so some other"
      },
      {
        "start": 3122.48,
        "duration": 3.839,
        "text": "things you can do you can also write to"
      },
      {
        "start": 3124.88,
        "duration": 3.679,
        "text": "a parquet file"
      },
      {
        "start": 3126.319,
        "duration": 3.201,
        "text": "so parquet is another file for"
      },
      {
        "start": 3128.559,
        "duration": 4.481,
        "text": "um"
      },
      {
        "start": 3129.52,
        "duration": 5.039,
        "text": "storing analytics columnar data"
      },
      {
        "start": 3133.04,
        "duration": 3.68,
        "text": "you can also"
      },
      {
        "start": 3134.559,
        "duration": 3.681,
        "text": "do a dry run so turn off the listening"
      },
      {
        "start": 3136.72,
        "duration": 3.04,
        "text": "on the network part if you want to just"
      },
      {
        "start": 3138.24,
        "duration": 3.44,
        "text": "like print out what the asus table looks"
      },
      {
        "start": 3139.76,
        "duration": 3.68,
        "text": "like um"
      },
      {
        "start": 3141.68,
        "duration": 4.399,
        "text": "and then anyways this one i'm using"
      },
      {
        "start": 3143.44,
        "duration": 4.08,
        "text": "right here c um just doesn't include the"
      },
      {
        "start": 3146.079,
        "duration": 2.961,
        "text": "metadata so"
      },
      {
        "start": 3147.52,
        "duration": 3.039,
        "text": "um all of the"
      },
      {
        "start": 3149.04,
        "duration": 3.76,
        "text": "time snaps and stuff it just doesn't"
      },
      {
        "start": 3150.559,
        "duration": 4.56,
        "text": "include those so um"
      },
      {
        "start": 3152.8,
        "duration": 4.0,
        "text": "as i mentioned earlier as the table to"
      },
      {
        "start": 3155.119,
        "duration": 4.081,
        "text": "arrow doesn't do any of the"
      },
      {
        "start": 3156.8,
        "duration": 5.92,
        "text": "deduplication stuff for you as of yet"
      },
      {
        "start": 3159.2,
        "duration": 5.919,
        "text": "unfortunately we're working on it um but"
      },
      {
        "start": 3162.72,
        "duration": 4.24,
        "text": "so for this table um it's just"
      },
      {
        "start": 3165.119,
        "duration": 3.761,
        "text": "some sample data that i've imported it"
      },
      {
        "start": 3166.96,
        "duration": 3.119,
        "text": "doesn't have any additional writes and"
      },
      {
        "start": 3168.88,
        "duration": 4.08,
        "text": "things like that"
      },
      {
        "start": 3170.079,
        "duration": 6.0,
        "text": "um okay so if i go ahead and run as a"
      },
      {
        "start": 3172.96,
        "duration": 5.599,
        "text": "staple to arrow and i've passed the path"
      },
      {
        "start": 3176.079,
        "duration": 4.401,
        "text": "to my iris data set here you can see"
      },
      {
        "start": 3178.559,
        "duration": 3.681,
        "text": "blah blah blah there's a bunch of"
      },
      {
        "start": 3180.48,
        "duration": 3.68,
        "text": "asus table files and this is also"
      },
      {
        "start": 3182.24,
        "duration": 4.16,
        "text": "compressed by the way so"
      },
      {
        "start": 3184.16,
        "duration": 4.64,
        "text": "asses table to arrow works fine with"
      },
      {
        "start": 3186.4,
        "duration": 6.08,
        "text": "compressed ss tables"
      },
      {
        "start": 3188.8,
        "duration": 3.68,
        "text": "so if we go ahead and run that"
      },
      {
        "start": 3192.72,
        "duration": 5.119,
        "text": "you can see uh there we go it'll read"
      },
      {
        "start": 3194.72,
        "duration": 5.76,
        "text": "that's this table um listen on the port"
      },
      {
        "start": 3197.839,
        "duration": 4.72,
        "text": "and now in my code if i"
      },
      {
        "start": 3200.48,
        "duration": 4.16,
        "text": "go ahead and fetch the data awesome so"
      },
      {
        "start": 3202.559,
        "duration": 4.481,
        "text": "it receives that table and if i want to"
      },
      {
        "start": 3204.64,
        "duration": 5.04,
        "text": "sort of print it out"
      },
      {
        "start": 3207.04,
        "duration": 5.36,
        "text": "um"
      },
      {
        "start": 3209.68,
        "duration": 2.72,
        "text": "table zero"
      },
      {
        "start": 3214.88,
        "duration": 3.6,
        "text": "yeah yeah awesome so we can see here we"
      },
      {
        "start": 3217.04,
        "duration": 3.279,
        "text": "get um"
      },
      {
        "start": 3218.48,
        "duration": 4.76,
        "text": "all of that data and if we want to load"
      },
      {
        "start": 3220.319,
        "duration": 4.321,
        "text": "it into qdf we just call"
      },
      {
        "start": 3223.24,
        "duration": 4.28,
        "text": "qdf.dataframe.fromarrow and then i'm"
      },
      {
        "start": 3224.64,
        "duration": 4.24,
        "text": "passing that one table that we loaded"
      },
      {
        "start": 3227.52,
        "duration": 2.48,
        "text": "and i'm just renaming some of the"
      },
      {
        "start": 3228.88,
        "duration": 4.16,
        "text": "columns here to make it a little bit"
      },
      {
        "start": 3230.0,
        "duration": 5.44,
        "text": "nicer and woohoo you can see we've"
      },
      {
        "start": 3233.04,
        "duration": 5.279,
        "text": "grabbed the data from our assets table"
      },
      {
        "start": 3235.44,
        "duration": 6.56,
        "text": "and parsed it into um"
      },
      {
        "start": 3238.319,
        "duration": 5.841,
        "text": "kudif so once again qdf is sort of the"
      },
      {
        "start": 3242.0,
        "duration": 5.04,
        "text": "equivalent of pandas that"
      },
      {
        "start": 3244.16,
        "duration": 5.36,
        "text": "holds all that stuff on the gpu"
      },
      {
        "start": 3247.04,
        "duration": 5.279,
        "text": "okay so next up i've taken this"
      },
      {
        "start": 3249.52,
        "duration": 5.52,
        "text": "scikit-learn example from um"
      },
      {
        "start": 3252.319,
        "duration": 4.8,
        "text": "the scikit-learn website and uh like we"
      },
      {
        "start": 3255.04,
        "duration": 6.079,
        "text": "mentioned earlier i've just exchanged"
      },
      {
        "start": 3257.119,
        "duration": 6.561,
        "text": "sklearn um with qml um and that's i was"
      },
      {
        "start": 3261.119,
        "duration": 5.121,
        "text": "like wow this is kind of magic um so"
      },
      {
        "start": 3263.68,
        "duration": 5.76,
        "text": "sklearn exchange it with qml um there's"
      },
      {
        "start": 3266.24,
        "duration": 5.839,
        "text": "a couple minor changes um with the qdf"
      },
      {
        "start": 3269.44,
        "duration": 5.44,
        "text": "sort of syntax um and i'm also using"
      },
      {
        "start": 3272.079,
        "duration": 5.441,
        "text": "matplotlib to plot it which requires"
      },
      {
        "start": 3274.88,
        "duration": 4.959,
        "text": "numpy arrays so there's a couple minor"
      },
      {
        "start": 3277.52,
        "duration": 4.0,
        "text": "sort of changes tweaks i have in here"
      },
      {
        "start": 3279.839,
        "duration": 5.76,
        "text": "but essentially you can see here we take"
      },
      {
        "start": 3281.52,
        "duration": 5.36,
        "text": "that cuda data frame um grab the data so"
      },
      {
        "start": 3285.599,
        "duration": 2.72,
        "text": "here i'm taking"
      },
      {
        "start": 3286.88,
        "duration": 3.199,
        "text": "some of the features and then i'm also"
      },
      {
        "start": 3288.319,
        "duration": 3.601,
        "text": "taking the target if you guys are"
      },
      {
        "start": 3290.079,
        "duration": 3.76,
        "text": "familiar with machine learning um it's"
      },
      {
        "start": 3291.92,
        "duration": 4.0,
        "text": "probably pretty clear what i'm doing um"
      },
      {
        "start": 3293.839,
        "duration": 6.561,
        "text": "here we're using the"
      },
      {
        "start": 3295.92,
        "duration": 6.8,
        "text": "qml logistic regression um model"
      },
      {
        "start": 3300.4,
        "duration": 4.24,
        "text": "so we're creating that classifier"
      },
      {
        "start": 3302.72,
        "duration": 3.839,
        "text": "fitting it to the data and then this is"
      },
      {
        "start": 3304.64,
        "duration": 4.959,
        "text": "a bunch of sort of setup code just to"
      },
      {
        "start": 3306.559,
        "duration": 5.52,
        "text": "get the plot to look kind of nice um and"
      },
      {
        "start": 3309.599,
        "duration": 3.441,
        "text": "then if i go ahead and run this"
      },
      {
        "start": 3312.079,
        "duration": 3.841,
        "text": "um"
      },
      {
        "start": 3313.04,
        "duration": 4.64,
        "text": "do to do that loop gives me a warning"
      },
      {
        "start": 3315.92,
        "duration": 3.6,
        "text": "and you can see here it's running it"
      },
      {
        "start": 3317.68,
        "duration": 4.0,
        "text": "takes a couple seconds"
      },
      {
        "start": 3319.52,
        "duration": 4.24,
        "text": "i feel like the time is"
      },
      {
        "start": 3321.68,
        "duration": 3.919,
        "text": "also maybe because of"
      },
      {
        "start": 3323.76,
        "duration": 2.799,
        "text": "connection to the remote but you can see"
      },
      {
        "start": 3325.599,
        "duration": 4.081,
        "text": "here"
      },
      {
        "start": 3326.559,
        "duration": 5.76,
        "text": "we're able to sort of classify those"
      },
      {
        "start": 3329.68,
        "duration": 5.679,
        "text": "data points that iris data set"
      },
      {
        "start": 3332.319,
        "duration": 5.201,
        "text": "so blue is one species um"
      },
      {
        "start": 3335.359,
        "duration": 4.081,
        "text": "brownish is another species and then"
      },
      {
        "start": 3337.52,
        "duration": 5.599,
        "text": "yellow is another species and all of"
      },
      {
        "start": 3339.44,
        "duration": 5.28,
        "text": "this is sort of done on the gpu um so"
      },
      {
        "start": 3343.119,
        "duration": 5.68,
        "text": "yeah hopefully that gives a sense of"
      },
      {
        "start": 3344.72,
        "duration": 5.52,
        "text": "what rapids is sort of used for um"
      },
      {
        "start": 3348.799,
        "duration": 5.441,
        "text": "and what esses table to arrow is used"
      },
      {
        "start": 3350.24,
        "duration": 6.319,
        "text": "for and like seb mentioned earlier um"
      },
      {
        "start": 3354.24,
        "duration": 4.48,
        "text": "in in practice a lot of the time you're"
      },
      {
        "start": 3356.559,
        "duration": 4.24,
        "text": "going to have not just one ss table but"
      },
      {
        "start": 3358.72,
        "duration": 5.28,
        "text": "a whole bunch of access tables that"
      },
      {
        "start": 3360.799,
        "duration": 4.081,
        "text": "correspond to a single cassandra table"
      },
      {
        "start": 3364.0,
        "duration": 3.359,
        "text": "so"
      },
      {
        "start": 3364.88,
        "duration": 4.4,
        "text": "unfortunately s's table to arrow doesn't"
      },
      {
        "start": 3367.359,
        "duration": 4.48,
        "text": "support"
      },
      {
        "start": 3369.28,
        "duration": 4.079,
        "text": "the deduplication step but you can sort"
      },
      {
        "start": 3371.839,
        "duration": 2.48,
        "text": "of do it manually"
      },
      {
        "start": 3373.359,
        "duration": 4.0,
        "text": "using"
      },
      {
        "start": 3374.319,
        "duration": 6.561,
        "text": "sql on the client side so"
      },
      {
        "start": 3377.359,
        "duration": 5.2,
        "text": "one really helpful uh tool also um"
      },
      {
        "start": 3380.88,
        "duration": 3.919,
        "text": "i believe associated with rapids for"
      },
      {
        "start": 3382.559,
        "duration": 6.321,
        "text": "doing this is called blazing sql or"
      },
      {
        "start": 3384.799,
        "duration": 6.881,
        "text": "blazing sql um and so this is a python"
      },
      {
        "start": 3388.88,
        "duration": 6.0,
        "text": "library that allows you to essentially"
      },
      {
        "start": 3391.68,
        "duration": 4.159,
        "text": "run sql queries using the gpu"
      },
      {
        "start": 3394.88,
        "duration": 2.719,
        "text": "um"
      },
      {
        "start": 3395.839,
        "duration": 4.321,
        "text": "so here i'm sort of importing that"
      },
      {
        "start": 3397.599,
        "duration": 5.361,
        "text": "library um"
      },
      {
        "start": 3400.16,
        "duration": 5.28,
        "text": "let me see if i have my sample data here"
      },
      {
        "start": 3402.96,
        "duration": 3.28,
        "text": "yet no okay give me one second i'm going"
      },
      {
        "start": 3405.44,
        "duration": 2.399,
        "text": "to"
      },
      {
        "start": 3406.24,
        "duration": 4.24,
        "text": "grab my sample data"
      },
      {
        "start": 3407.839,
        "duration": 4.24,
        "text": "copy that over here"
      },
      {
        "start": 3410.48,
        "duration": 2.8,
        "text": "do i already have it okay i might"
      },
      {
        "start": 3412.079,
        "duration": 4.201,
        "text": "already have it"
      },
      {
        "start": 3413.28,
        "duration": 3.0,
        "text": "um"
      },
      {
        "start": 3418.0,
        "duration": 6.4,
        "text": "but it's empty okay um to give me"
      },
      {
        "start": 3421.68,
        "duration": 2.72,
        "text": "one second"
      },
      {
        "start": 3425.52,
        "duration": 2.88,
        "text": "to"
      },
      {
        "start": 3426.799,
        "duration": 2.401,
        "text": "copy over"
      },
      {
        "start": 3428.4,
        "duration": 2.64,
        "text": "this"
      },
      {
        "start": 3429.2,
        "duration": 5.28,
        "text": "data set"
      },
      {
        "start": 3431.04,
        "duration": 4.559,
        "text": "i'm just gonna stick it in here"
      },
      {
        "start": 3434.48,
        "duration": 4.879,
        "text": "um"
      },
      {
        "start": 3435.599,
        "duration": 4.881,
        "text": "okay cool so if we go ahead and"
      },
      {
        "start": 3439.359,
        "duration": 3.601,
        "text": "um"
      },
      {
        "start": 3440.48,
        "duration": 5.04,
        "text": "use asus table to arrow again to"
      },
      {
        "start": 3442.96,
        "duration": 3.44,
        "text": "read that data set i'm gonna copy the"
      },
      {
        "start": 3445.52,
        "duration": 3.12,
        "text": "path"
      },
      {
        "start": 3446.4,
        "duration": 3.76,
        "text": "pass it to sstable to arrow listening on"
      },
      {
        "start": 3448.64,
        "duration": 4.24,
        "text": "port awesome"
      },
      {
        "start": 3450.16,
        "duration": 5.679,
        "text": "and i'm going to go back up here to"
      },
      {
        "start": 3452.88,
        "duration": 5.919,
        "text": "fetch the data again and um read all of"
      },
      {
        "start": 3455.839,
        "duration": 4.881,
        "text": "those as tables so you can see this time"
      },
      {
        "start": 3458.799,
        "duration": 3.601,
        "text": "i have actually three asset tables in"
      },
      {
        "start": 3460.72,
        "duration": 3.76,
        "text": "here and if you take a look at the"
      },
      {
        "start": 3462.4,
        "duration": 3.52,
        "text": "numbers um you can see there's a table"
      },
      {
        "start": 3464.48,
        "duration": 3.68,
        "text": "one two three"
      },
      {
        "start": 3465.92,
        "duration": 3.439,
        "text": "um and essentially"
      },
      {
        "start": 3468.16,
        "duration": 2.399,
        "text": "if you want to take a look at what these"
      },
      {
        "start": 3469.359,
        "duration": 2.881,
        "text": "look like"
      },
      {
        "start": 3470.559,
        "duration": 5.201,
        "text": "they're all corresponding to the same"
      },
      {
        "start": 3472.24,
        "duration": 6.24,
        "text": "sort of sample key value data um let me"
      },
      {
        "start": 3475.76,
        "duration": 4.319,
        "text": "see i think i could"
      },
      {
        "start": 3478.48,
        "duration": 5.04,
        "text": "show a visualization of what it looks"
      },
      {
        "start": 3480.079,
        "duration": 3.441,
        "text": "like give me one second"
      },
      {
        "start": 3485.04,
        "duration": 2.48,
        "text": "table"
      },
      {
        "start": 3486.72,
        "duration": 3.68,
        "text": "oh"
      },
      {
        "start": 3487.52,
        "duration": 6.319,
        "text": "dot two pandas"
      },
      {
        "start": 3490.4,
        "duration": 7.12,
        "text": "four table in tables"
      },
      {
        "start": 3493.839,
        "duration": 3.681,
        "text": "um and it'll take some time to run"
      },
      {
        "start": 3498.96,
        "duration": 5.92,
        "text": "my computer is slowing down a little bit"
      },
      {
        "start": 3501.2,
        "duration": 5.68,
        "text": "um okay so here's a look at what"
      },
      {
        "start": 3504.88,
        "duration": 3.76,
        "text": "the data looks like so you can see here"
      },
      {
        "start": 3506.88,
        "duration": 3.6,
        "text": "in our first esses table this is one"
      },
      {
        "start": 3508.64,
        "duration": 4.24,
        "text": "where i sort of wrote the data so"
      },
      {
        "start": 3510.48,
        "duration": 4.56,
        "text": "there's no updates or deletes"
      },
      {
        "start": 3512.88,
        "duration": 4.4,
        "text": "so it contains all the data in this"
      },
      {
        "start": 3515.04,
        "duration": 4.0,
        "text": "second access table i've updated a"
      },
      {
        "start": 3517.28,
        "duration": 5.279,
        "text": "couple of the cells and you'll notice"
      },
      {
        "start": 3519.04,
        "duration": 4.72,
        "text": "that except for the partition key um"
      },
      {
        "start": 3522.559,
        "duration": 2.481,
        "text": "the"
      },
      {
        "start": 3523.76,
        "duration": 3.28,
        "text": "row liveness"
      },
      {
        "start": 3525.04,
        "duration": 4.079,
        "text": "data is mostly empty and then for that"
      },
      {
        "start": 3527.04,
        "duration": 4.319,
        "text": "specific cell we have a timestamp when"
      },
      {
        "start": 3529.119,
        "duration": 3.521,
        "text": "it gets updated and then along with the"
      },
      {
        "start": 3531.359,
        "duration": 3.2,
        "text": "value that it has"
      },
      {
        "start": 3532.64,
        "duration": 3.84,
        "text": "um and then finally i've deleted a"
      },
      {
        "start": 3534.559,
        "duration": 5.121,
        "text": "couple of rows here and you can see here"
      },
      {
        "start": 3536.48,
        "duration": 7.04,
        "text": "it also has the partition key um and it"
      },
      {
        "start": 3539.68,
        "duration": 7.2,
        "text": "also has the row deletion time"
      },
      {
        "start": 3543.52,
        "duration": 5.44,
        "text": "and this sort of once again um includes"
      },
      {
        "start": 3546.88,
        "duration": 4.64,
        "text": "all of the metadata from cassandra so"
      },
      {
        "start": 3548.96,
        "duration": 4.08,
        "text": "that you can do the deduplication um on"
      },
      {
        "start": 3551.52,
        "duration": 3.839,
        "text": "your own so if i scroll down all the way"
      },
      {
        "start": 3553.04,
        "duration": 6.72,
        "text": "to the bottom here um i'm gonna use"
      },
      {
        "start": 3555.359,
        "duration": 9.521,
        "text": "blazing sql um to um"
      },
      {
        "start": 3559.76,
        "duration": 6.799,
        "text": "uh read those assets tables um or sorry"
      },
      {
        "start": 3564.88,
        "duration": 4.16,
        "text": "let me back up a little bit and explain"
      },
      {
        "start": 3566.559,
        "duration": 5.04,
        "text": "this process from the start so we have"
      },
      {
        "start": 3569.04,
        "duration": 5.2,
        "text": "the ss tables and those contain all the"
      },
      {
        "start": 3571.599,
        "duration": 4.561,
        "text": "metadata that you need to reconstruct um"
      },
      {
        "start": 3574.24,
        "duration": 4.64,
        "text": "like the current version of your data"
      },
      {
        "start": 3576.16,
        "duration": 4.72,
        "text": "and what blazing sql does is it can um"
      },
      {
        "start": 3578.88,
        "duration": 4.4,
        "text": "take those ss tables"
      },
      {
        "start": 3580.88,
        "duration": 5.6,
        "text": "or sorry assets table to arrow"
      },
      {
        "start": 3583.28,
        "duration": 4.48,
        "text": "transform those tables into error format"
      },
      {
        "start": 3586.48,
        "duration": 3.52,
        "text": "and then"
      },
      {
        "start": 3587.76,
        "duration": 5.52,
        "text": "we are able to use qdf to get those"
      },
      {
        "start": 3590.0,
        "duration": 5.28,
        "text": "arrow tables into qdf data frames"
      },
      {
        "start": 3593.28,
        "duration": 5.519,
        "text": "and then blazing sql is able to take"
      },
      {
        "start": 3595.28,
        "duration": 5.519,
        "text": "those data frames and load them into"
      },
      {
        "start": 3598.799,
        "duration": 5.201,
        "text": "its own internal sort of represent"
      },
      {
        "start": 3600.799,
        "duration": 5.361,
        "text": "representation so that we can do"
      },
      {
        "start": 3604.0,
        "duration": 4.68,
        "text": "sql queries on it so i'm going to go"
      },
      {
        "start": 3606.16,
        "duration": 6.679,
        "text": "ahead and create this new blazing"
      },
      {
        "start": 3608.68,
        "duration": 4.159,
        "text": "context um"
      },
      {
        "start": 3614.079,
        "duration": 3.101,
        "text": "oh dear"
      },
      {
        "start": 3616.559,
        "duration": 3.441,
        "text": "um"
      },
      {
        "start": 3617.18,
        "duration": 4.74,
        "text": "[Music]"
      },
      {
        "start": 3620.0,
        "duration": 4.16,
        "text": "let me take a look at what's going on"
      },
      {
        "start": 3621.92,
        "duration": 2.24,
        "text": "here"
      },
      {
        "start": 3626.839,
        "duration": 4.121,
        "text": "okay"
      },
      {
        "start": 3628.72,
        "duration": 5.68,
        "text": "so if we go ahead and"
      },
      {
        "start": 3630.96,
        "duration": 3.44,
        "text": "read that key value data"
      },
      {
        "start": 3637.44,
        "duration": 5.04,
        "text": "okay"
      },
      {
        "start": 3638.319,
        "duration": 6.321,
        "text": "um so that gets loaded into our program"
      },
      {
        "start": 3642.48,
        "duration": 6.0,
        "text": "and then"
      },
      {
        "start": 3644.64,
        "duration": 6.159,
        "text": "we're going to use qdf to create"
      },
      {
        "start": 3648.48,
        "duration": 4.319,
        "text": "a table from"
      },
      {
        "start": 3650.799,
        "duration": 3.76,
        "text": "each of those arrow tables"
      },
      {
        "start": 3652.799,
        "duration": 4.881,
        "text": "okay i'm worried it might be"
      },
      {
        "start": 3654.559,
        "duration": 5.121,
        "text": "some issues with compatibility here um"
      },
      {
        "start": 3657.68,
        "duration": 3.679,
        "text": "so we might need to"
      },
      {
        "start": 3659.68,
        "duration": 3.6,
        "text": "skip this part of the demo for now but"
      },
      {
        "start": 3661.359,
        "duration": 4.48,
        "text": "essentially once those tables are loaded"
      },
      {
        "start": 3663.28,
        "duration": 5.519,
        "text": "into blazing sql you can write a sql"
      },
      {
        "start": 3665.839,
        "duration": 5.841,
        "text": "query to essentially um"
      },
      {
        "start": 3668.799,
        "duration": 4.881,
        "text": "look for all of the rows that have not"
      },
      {
        "start": 3671.68,
        "duration": 4.96,
        "text": "been deleted and you can also if you"
      },
      {
        "start": 3673.68,
        "duration": 6.639,
        "text": "wanted specify a certain um time for"
      },
      {
        "start": 3676.64,
        "duration": 5.76,
        "text": "example um and then it will return to"
      },
      {
        "start": 3680.319,
        "duration": 4.24,
        "text": "all of those rows and the updated"
      },
      {
        "start": 3682.4,
        "duration": 3.52,
        "text": "versions of them but unfortunately um"
      },
      {
        "start": 3684.559,
        "duration": 4.24,
        "text": "i'm not"
      },
      {
        "start": 3685.92,
        "duration": 5.04,
        "text": "an expert with sql um so you might need"
      },
      {
        "start": 3688.799,
        "duration": 3.681,
        "text": "to do some of those steps manually on"
      },
      {
        "start": 3690.96,
        "duration": 3.359,
        "text": "your own"
      },
      {
        "start": 3692.48,
        "duration": 3.28,
        "text": "but since all of that metadata is"
      },
      {
        "start": 3694.319,
        "duration": 3.76,
        "text": "provided to you"
      },
      {
        "start": 3695.76,
        "duration": 4.72,
        "text": "you can go ahead and write sql queries"
      },
      {
        "start": 3698.079,
        "duration": 3.76,
        "text": "to rebuild the sort of current version"
      },
      {
        "start": 3700.48,
        "duration": 2.48,
        "text": "of your data"
      },
      {
        "start": 3701.839,
        "duration": 3.681,
        "text": "okay"
      },
      {
        "start": 3702.96,
        "duration": 4.32,
        "text": "well i guess that's it for"
      },
      {
        "start": 3705.52,
        "duration": 4.559,
        "text": "my presentation today so that's a sort"
      },
      {
        "start": 3707.28,
        "duration": 4.72,
        "text": "of brief demo of how you can use rapids"
      },
      {
        "start": 3710.079,
        "duration": 3.681,
        "text": "so thanks so much for listening and i"
      },
      {
        "start": 3712.0,
        "duration": 4.16,
        "text": "guess now we'll open it up for any"
      },
      {
        "start": 3713.76,
        "duration": 2.4,
        "text": "questions"
      },
      {
        "start": 3719.839,
        "duration": 2.801,
        "text": "right yeah i think we have a couple"
      },
      {
        "start": 3721.2,
        "duration": 2.8,
        "text": "questions there was a question i know"
      },
      {
        "start": 3722.64,
        "duration": 3.52,
        "text": "it's been answered in the chat but just"
      },
      {
        "start": 3724.0,
        "duration": 6.319,
        "text": "for the benefit of the rest of the"
      },
      {
        "start": 3726.16,
        "duration": 6.639,
        "text": "viewers about kind of a question around"
      },
      {
        "start": 3730.319,
        "duration": 5.361,
        "text": "speed differences uh for with the gpu"
      },
      {
        "start": 3732.799,
        "duration": 6.56,
        "text": "versus the cpu and how the data size or"
      },
      {
        "start": 3735.68,
        "duration": 3.679,
        "text": "data set size affects that"
      },
      {
        "start": 3739.839,
        "duration": 4.081,
        "text": "yeah and i want to say that"
      },
      {
        "start": 3741.52,
        "duration": 4.0,
        "text": "uh seb and had a great response to that"
      },
      {
        "start": 3743.92,
        "duration": 3.119,
        "text": "too because in most cases it's not"
      },
      {
        "start": 3745.52,
        "duration": 3.68,
        "text": "necessarily about the data and but in"
      },
      {
        "start": 3747.039,
        "duration": 3.76,
        "text": "most cases you'll see improved"
      },
      {
        "start": 3749.2,
        "duration": 2.56,
        "text": "performance the larger"
      },
      {
        "start": 3750.799,
        "duration": 2.161,
        "text": "uh"
      },
      {
        "start": 3751.76,
        "duration": 3.039,
        "text": "the data that you're running through"
      },
      {
        "start": 3752.96,
        "duration": 3.92,
        "text": "especially for"
      },
      {
        "start": 3754.799,
        "duration": 4.32,
        "text": "data transformation data wrangling that"
      },
      {
        "start": 3756.88,
        "duration": 4.32,
        "text": "you'd be doing in pandas the larger the"
      },
      {
        "start": 3759.119,
        "duration": 3.841,
        "text": "data sets then you'll be able to process"
      },
      {
        "start": 3761.2,
        "duration": 4.08,
        "text": "it and do a lot of these transformations"
      },
      {
        "start": 3762.96,
        "duration": 4.32,
        "text": "much faster on a gpu using something"
      },
      {
        "start": 3765.28,
        "duration": 4.72,
        "text": "like qdf but when we actually start"
      },
      {
        "start": 3767.28,
        "duration": 4.48,
        "text": "moving into kind of the more classical"
      },
      {
        "start": 3770.0,
        "duration": 4.319,
        "text": "machine learning where you're running a"
      },
      {
        "start": 3771.76,
        "duration": 4.319,
        "text": "random forest or something like that and"
      },
      {
        "start": 3774.319,
        "duration": 3.361,
        "text": "you're kind of iterating through all"
      },
      {
        "start": 3776.079,
        "duration": 3.04,
        "text": "these different variations of the"
      },
      {
        "start": 3777.68,
        "duration": 3.52,
        "text": "decision tree"
      },
      {
        "start": 3779.119,
        "duration": 4.24,
        "text": "in that case you'll definitely see"
      },
      {
        "start": 3781.2,
        "duration": 3.76,
        "text": "improved performance running with the"
      },
      {
        "start": 3783.359,
        "duration": 4.72,
        "text": "qml library versus something like"
      },
      {
        "start": 3784.96,
        "duration": 4.879,
        "text": "psychic learn or spark ml just by either"
      },
      {
        "start": 3788.079,
        "duration": 4.0,
        "text": "the nature of how the pro the data is"
      },
      {
        "start": 3789.839,
        "duration": 4.401,
        "text": "being processed and iterated through or"
      },
      {
        "start": 3792.079,
        "duration": 4.161,
        "text": "in terms of for example spark ml just"
      },
      {
        "start": 3794.24,
        "duration": 3.359,
        "text": "the distributed nature of the algorithm"
      },
      {
        "start": 3796.24,
        "duration": 2.4,
        "text": "and how it has to go back and collect"
      },
      {
        "start": 3797.599,
        "duration": 2.321,
        "text": "all the different components before it"
      },
      {
        "start": 3798.64,
        "duration": 3.199,
        "text": "iterates again"
      },
      {
        "start": 3799.92,
        "duration": 3.84,
        "text": "so you'll see just improve performance"
      },
      {
        "start": 3801.839,
        "duration": 3.841,
        "text": "across the board just by the compute"
      },
      {
        "start": 3803.76,
        "duration": 4.16,
        "text": "that's necessary to achieve the results"
      },
      {
        "start": 3805.68,
        "duration": 4.96,
        "text": "faster by some of these particular"
      },
      {
        "start": 3807.92,
        "duration": 4.96,
        "text": "algorithms that have mentioned"
      },
      {
        "start": 3810.64,
        "duration": 4.24,
        "text": "yeah so so to summarize"
      },
      {
        "start": 3812.88,
        "duration": 4.56,
        "text": "data volume matters but"
      },
      {
        "start": 3814.88,
        "duration": 3.52,
        "text": "algorithm complexity matters as well"
      },
      {
        "start": 3817.44,
        "duration": 2.8,
        "text": "and"
      },
      {
        "start": 3818.4,
        "duration": 4.08,
        "text": "yes with bigger data sets also with"
      },
      {
        "start": 3820.24,
        "duration": 3.599,
        "text": "bigger algorithm complexity"
      },
      {
        "start": 3822.48,
        "duration": 4.96,
        "text": "you're going to get you're gonna get big"
      },
      {
        "start": 3823.839,
        "duration": 3.601,
        "text": "savings from going on the gpu"
      },
      {
        "start": 3828.96,
        "duration": 2.879,
        "text": "um something that hasn't come up that i"
      },
      {
        "start": 3830.64,
        "duration": 2.32,
        "text": "kind of expected to come up and maybe we"
      },
      {
        "start": 3831.839,
        "duration": 2.24,
        "text": "should spend a couple minutes chatting"
      },
      {
        "start": 3832.96,
        "duration": 2.879,
        "text": "on is"
      },
      {
        "start": 3834.079,
        "duration": 3.04,
        "text": "um"
      },
      {
        "start": 3835.839,
        "duration": 2.801,
        "text": "like"
      },
      {
        "start": 3837.119,
        "duration": 3.841,
        "text": "how do we how do we do rapids in a"
      },
      {
        "start": 3838.64,
        "duration": 3.84,
        "text": "distributed setting"
      },
      {
        "start": 3840.96,
        "duration": 3.2,
        "text": "um all the folks that you know our"
      },
      {
        "start": 3842.48,
        "duration": 3.68,
        "text": "cassandra users are kind of used to"
      },
      {
        "start": 3844.16,
        "duration": 3.919,
        "text": "everything you know running on a cluster"
      },
      {
        "start": 3846.16,
        "duration": 5.199,
        "text": "uh and so maybe people just take this"
      },
      {
        "start": 3848.079,
        "duration": 5.04,
        "text": "for granted uh so rapids is a"
      },
      {
        "start": 3851.359,
        "duration": 3.521,
        "text": "you know distributed clusterable you"
      },
      {
        "start": 3853.119,
        "duration": 4.321,
        "text": "know enabled technology"
      },
      {
        "start": 3854.88,
        "duration": 3.919,
        "text": "um they leverage"
      },
      {
        "start": 3857.44,
        "duration": 3.76,
        "text": "you maybe just you can dive into the"
      },
      {
        "start": 3858.799,
        "duration": 3.28,
        "text": "desk a little bit more uh but so yeah so"
      },
      {
        "start": 3861.2,
        "duration": 1.919,
        "text": "so"
      },
      {
        "start": 3862.079,
        "duration": 2.801,
        "text": "uh"
      },
      {
        "start": 3863.119,
        "duration": 4.641,
        "text": "things to think about like you you have"
      },
      {
        "start": 3864.88,
        "duration": 4.239,
        "text": "device memory um all these tools support"
      },
      {
        "start": 3867.76,
        "duration": 2.72,
        "text": "kind of streaming into and out of the"
      },
      {
        "start": 3869.119,
        "duration": 3.68,
        "text": "device memory in case your data set is"
      },
      {
        "start": 3870.48,
        "duration": 5.119,
        "text": "larger than memory and they also support"
      },
      {
        "start": 3872.799,
        "duration": 5.601,
        "text": "via desk uh distributing across of lots"
      },
      {
        "start": 3875.599,
        "duration": 5.601,
        "text": "across lots of machines with gpus uh to"
      },
      {
        "start": 3878.4,
        "duration": 6.32,
        "text": "handle large tasks"
      },
      {
        "start": 3881.2,
        "duration": 5.839,
        "text": "indeed yes and and in some cases so if"
      },
      {
        "start": 3884.72,
        "duration": 3.92,
        "text": "your data is pretty it's pretty large"
      },
      {
        "start": 3887.039,
        "duration": 5.601,
        "text": "that we see the memory associated with a"
      },
      {
        "start": 3888.64,
        "duration": 6.56,
        "text": "single gpu we we use something called uh"
      },
      {
        "start": 3892.64,
        "duration": 5.04,
        "text": "qdf which essentially is allows us to"
      },
      {
        "start": 3895.2,
        "duration": 5.52,
        "text": "use the das framework to distribute our"
      },
      {
        "start": 3897.68,
        "duration": 4.159,
        "text": "qdf uh data frame across multiple gpus"
      },
      {
        "start": 3900.72,
        "duration": 2.96,
        "text": "in the cluster"
      },
      {
        "start": 3901.839,
        "duration": 3.52,
        "text": "and so it allows at that point it"
      },
      {
        "start": 3903.68,
        "duration": 4.639,
        "text": "follows a similar process where now we"
      },
      {
        "start": 3905.359,
        "duration": 6.081,
        "text": "have also data distribution to run a"
      },
      {
        "start": 3908.319,
        "duration": 5.121,
        "text": "parallel task but in a a serial in a"
      },
      {
        "start": 3911.44,
        "duration": 4.159,
        "text": "concurrent fashion it allows us to scale"
      },
      {
        "start": 3913.44,
        "duration": 3.76,
        "text": "out to additional gpus to then harness"
      },
      {
        "start": 3915.599,
        "duration": 3.281,
        "text": "and enhance a lot of that functional"
      },
      {
        "start": 3917.2,
        "duration": 3.839,
        "text": "power that we get with gpus not"
      },
      {
        "start": 3918.88,
        "duration": 4.56,
        "text": "necessarily just a single one but"
      },
      {
        "start": 3921.039,
        "duration": 3.52,
        "text": "multiple and in some cases though even"
      },
      {
        "start": 3923.44,
        "duration": 3.599,
        "text": "though if you're running on multiple"
      },
      {
        "start": 3924.559,
        "duration": 6.401,
        "text": "gpus it'd be an order of magnitude"
      },
      {
        "start": 3927.039,
        "duration": 5.681,
        "text": "smaller than uh just uh hundreds of cpus"
      },
      {
        "start": 3930.96,
        "duration": 4.32,
        "text": "or 50 cpus or something like that that"
      },
      {
        "start": 3932.72,
        "duration": 4.399,
        "text": "you would have to spin up separately so"
      },
      {
        "start": 3935.28,
        "duration": 3.68,
        "text": "in this case you'd still be looking at"
      },
      {
        "start": 3937.119,
        "duration": 4.0,
        "text": "improved performance in terms of compute"
      },
      {
        "start": 3938.96,
        "duration": 4.24,
        "text": "but also in terms of efficiency and"
      },
      {
        "start": 3941.119,
        "duration": 4.161,
        "text": "and how quickly a particular process"
      },
      {
        "start": 3943.2,
        "duration": 4.24,
        "text": "executes and then is completed before"
      },
      {
        "start": 3945.28,
        "duration": 3.2,
        "text": "you can then spin up another process to"
      },
      {
        "start": 3947.44,
        "duration": 3.919,
        "text": "run"
      },
      {
        "start": 3948.48,
        "duration": 4.079,
        "text": "um and that's not to say that"
      },
      {
        "start": 3951.359,
        "duration": 3.281,
        "text": "you know"
      },
      {
        "start": 3952.559,
        "duration": 4.24,
        "text": "you can't necessarily even this is all"
      },
      {
        "start": 3954.64,
        "duration": 4.479,
        "text": "just kind of batch processing as well"
      },
      {
        "start": 3956.799,
        "duration": 3.76,
        "text": "you know we have a series of kind of"
      },
      {
        "start": 3959.119,
        "duration": 3.44,
        "text": "streaming components where we have"
      },
      {
        "start": 3960.559,
        "duration": 4.48,
        "text": "things like cue streams that we're able"
      },
      {
        "start": 3962.559,
        "duration": 3.921,
        "text": "to connect to kind of existing uh"
      },
      {
        "start": 3965.039,
        "duration": 3.121,
        "text": "message queues to then be able to"
      },
      {
        "start": 3966.48,
        "duration": 3.359,
        "text": "capture data in a somewhat real-time"
      },
      {
        "start": 3968.16,
        "duration": 3.28,
        "text": "component that would then be able to"
      },
      {
        "start": 3969.839,
        "duration": 3.441,
        "text": "then essentially gather new data and"
      },
      {
        "start": 3971.44,
        "duration": 4.56,
        "text": "then put it into a data frame for"
      },
      {
        "start": 3973.28,
        "duration": 4.559,
        "text": "additional execution and then also"
      },
      {
        "start": 3976.0,
        "duration": 4.0,
        "text": "while we have qml we've touched on qml"
      },
      {
        "start": 3977.839,
        "duration": 3.921,
        "text": "quite a bit additional other types of"
      },
      {
        "start": 3980.0,
        "duration": 4.319,
        "text": "libraries that are more familiar for"
      },
      {
        "start": 3981.76,
        "duration": 4.319,
        "text": "cpus are things like uh"
      },
      {
        "start": 3984.319,
        "duration": 3.361,
        "text": "graph analytics in this case for"
      },
      {
        "start": 3986.079,
        "duration": 3.681,
        "text": "particularly with python you have"
      },
      {
        "start": 3987.68,
        "duration": 3.439,
        "text": "network x whereas we also have a q graph"
      },
      {
        "start": 3989.76,
        "duration": 3.359,
        "text": "functionality which allows you to"
      },
      {
        "start": 3991.119,
        "duration": 4.24,
        "text": "essentially do all your graph analytics"
      },
      {
        "start": 3993.119,
        "duration": 4.881,
        "text": "and graph processing put on a gtu and"
      },
      {
        "start": 3995.359,
        "duration": 5.2,
        "text": "scale it out to millions of vertices and"
      },
      {
        "start": 3998.0,
        "duration": 4.88,
        "text": "millions and millions of edges"
      },
      {
        "start": 4000.559,
        "duration": 4.641,
        "text": "as well as q spatial for geospatial"
      },
      {
        "start": 4002.88,
        "duration": 4.239,
        "text": "analysis and q signal for kind of"
      },
      {
        "start": 4005.2,
        "duration": 4.639,
        "text": "digital signal processing and time"
      },
      {
        "start": 4007.119,
        "duration": 2.72,
        "text": "series analysis"
      },
      {
        "start": 4010.4,
        "duration": 2.32,
        "text": "there's a question just came in here"
      },
      {
        "start": 4011.839,
        "duration": 2.881,
        "text": "about"
      },
      {
        "start": 4012.72,
        "duration": 4.319,
        "text": "do we expect metrics to be added to"
      },
      {
        "start": 4014.72,
        "duration": 4.48,
        "text": "cassandra for analytics in the future um"
      },
      {
        "start": 4017.039,
        "duration": 3.841,
        "text": "so just to clarify like the stuff that"
      },
      {
        "start": 4019.2,
        "duration": 3.28,
        "text": "we're showing here i mean that's a"
      },
      {
        "start": 4020.88,
        "duration": 4.64,
        "text": "staple to arrow it's not"
      },
      {
        "start": 4022.48,
        "duration": 5.92,
        "text": "it's not a utility that"
      },
      {
        "start": 4025.52,
        "duration": 4.64,
        "text": "that is in the cassandra project itself"
      },
      {
        "start": 4028.4,
        "duration": 3.76,
        "text": "right so this is kind of an external"
      },
      {
        "start": 4030.16,
        "duration": 3.6,
        "text": "third-party utility it's kind of alpha"
      },
      {
        "start": 4032.16,
        "duration": 3.36,
        "text": "software experimental that you can use"
      },
      {
        "start": 4033.76,
        "duration": 4.16,
        "text": "to take your ss tables and do analytics"
      },
      {
        "start": 4035.52,
        "duration": 3.599,
        "text": "on those separately from cassandra"
      },
      {
        "start": 4037.92,
        "duration": 2.24,
        "text": "in fact cassandra doesn't know anything"
      },
      {
        "start": 4039.119,
        "duration": 2.801,
        "text": "about this"
      },
      {
        "start": 4040.16,
        "duration": 3.52,
        "text": "so no you won't see any metrics in"
      },
      {
        "start": 4041.92,
        "duration": 4.879,
        "text": "cassandra about"
      },
      {
        "start": 4043.68,
        "duration": 5.84,
        "text": "analytics when you use these tools"
      },
      {
        "start": 4046.799,
        "duration": 4.721,
        "text": "i mean you know there's potential to do"
      },
      {
        "start": 4049.52,
        "duration": 4.079,
        "text": "kind of more any more uh like tighter"
      },
      {
        "start": 4051.52,
        "duration": 4.4,
        "text": "integrations with things in the future"
      },
      {
        "start": 4053.599,
        "duration": 4.561,
        "text": "but yeah just to be clear like"
      },
      {
        "start": 4055.92,
        "duration": 4.0,
        "text": "this functionality the rapids ecosystem"
      },
      {
        "start": 4058.16,
        "duration": 4.399,
        "text": "that's this table that arrow"
      },
      {
        "start": 4059.92,
        "duration": 5.28,
        "text": "uh software is completely separate from"
      },
      {
        "start": 4062.559,
        "duration": 4.641,
        "text": "cassandra it just knows how to read"
      },
      {
        "start": 4065.2,
        "duration": 4.0,
        "text": "cassandra ss tables and that's the"
      },
      {
        "start": 4067.2,
        "duration": 3.44,
        "text": "that's the integration point and and we"
      },
      {
        "start": 4069.2,
        "duration": 2.399,
        "text": "like that being separate because again"
      },
      {
        "start": 4070.64,
        "duration": 2.8,
        "text": "we talked there was a there was a"
      },
      {
        "start": 4071.599,
        "duration": 3.681,
        "text": "question a little bit earlier about"
      },
      {
        "start": 4073.44,
        "duration": 3.52,
        "text": "kind of co-location"
      },
      {
        "start": 4075.28,
        "duration": 3.44,
        "text": "versus isolation"
      },
      {
        "start": 4076.96,
        "duration": 4.56,
        "text": "so like in some cases a lot of folks"
      },
      {
        "start": 4078.72,
        "duration": 3.76,
        "text": "think hey if i co-locate um"
      },
      {
        "start": 4081.52,
        "duration": 2.24,
        "text": "you know my analytics in my"
      },
      {
        "start": 4082.48,
        "duration": 2.639,
        "text": "transactional"
      },
      {
        "start": 4083.76,
        "duration": 3.76,
        "text": "i may get some performance boosts"
      },
      {
        "start": 4085.119,
        "duration": 4.081,
        "text": "because hey the data is already there uh"
      },
      {
        "start": 4087.52,
        "duration": 3.279,
        "text": "you know on those same machines"
      },
      {
        "start": 4089.2,
        "duration": 3.76,
        "text": "but at the same time when you do that"
      },
      {
        "start": 4090.799,
        "duration": 4.56,
        "text": "you contend against the same"
      },
      {
        "start": 4092.96,
        "duration": 4.64,
        "text": "system resources when you know those two"
      },
      {
        "start": 4095.359,
        "duration": 4.32,
        "text": "very different workloads run right like"
      },
      {
        "start": 4097.6,
        "duration": 4.159,
        "text": "you don't want your analytics in your"
      },
      {
        "start": 4099.679,
        "duration": 3.761,
        "text": "transactional workflows to use the same"
      },
      {
        "start": 4101.759,
        "duration": 2.801,
        "text": "disks to use the same to hit the same"
      },
      {
        "start": 4103.44,
        "duration": 2.799,
        "text": "cpus"
      },
      {
        "start": 4104.56,
        "duration": 3.44,
        "text": "because they will basically fight over"
      },
      {
        "start": 4106.239,
        "duration": 2.56,
        "text": "those resources and"
      },
      {
        "start": 4108.0,
        "duration": 2.64,
        "text": "um"
      },
      {
        "start": 4108.799,
        "duration": 3.841,
        "text": "the loser will be the the transactional"
      },
      {
        "start": 4110.64,
        "duration": 3.679,
        "text": "workflow that has tight slas"
      },
      {
        "start": 4112.64,
        "duration": 3.199,
        "text": "right so you never want to impact that"
      },
      {
        "start": 4114.319,
        "duration": 3.281,
        "text": "like real-time injustice and cassandra"
      },
      {
        "start": 4115.839,
        "duration": 3.041,
        "text": "by hitting it with a with a with an"
      },
      {
        "start": 4117.6,
        "duration": 2.639,
        "text": "analytics"
      },
      {
        "start": 4118.88,
        "duration": 3.439,
        "text": "workload so this is what happens when"
      },
      {
        "start": 4120.239,
        "duration": 3.6,
        "text": "folks use spark and this is why folks"
      },
      {
        "start": 4122.319,
        "duration": 3.121,
        "text": "kind of do a separate data center in"
      },
      {
        "start": 4123.839,
        "duration": 3.52,
        "text": "cassandra when they have spark workloads"
      },
      {
        "start": 4125.44,
        "duration": 4.0,
        "text": "and even then you know separate data"
      },
      {
        "start": 4127.359,
        "duration": 4.081,
        "text": "centers and cassandra can still impact"
      },
      {
        "start": 4129.44,
        "duration": 3.04,
        "text": "each other you know kind of in extreme"
      },
      {
        "start": 4131.44,
        "duration": 2.879,
        "text": "circumstances when you're running"
      },
      {
        "start": 4132.48,
        "duration": 2.64,
        "text": "something big like a like an analytics"
      },
      {
        "start": 4134.319,
        "duration": 1.601,
        "text": "app"
      },
      {
        "start": 4135.12,
        "duration": 2.639,
        "text": "um"
      },
      {
        "start": 4135.92,
        "duration": 3.359,
        "text": "so yeah um"
      },
      {
        "start": 4137.759,
        "duration": 4.641,
        "text": "i think so i think what you really want"
      },
      {
        "start": 4139.279,
        "duration": 5.04,
        "text": "is isolation instead of um co-location"
      },
      {
        "start": 4142.4,
        "duration": 4.319,
        "text": "and that's kind of what we get by by"
      },
      {
        "start": 4144.319,
        "duration": 3.601,
        "text": "making a system that just reads success"
      },
      {
        "start": 4146.719,
        "duration": 3.52,
        "text": "tables and cassandra doesn't even know"
      },
      {
        "start": 4147.92,
        "duration": 2.319,
        "text": "about it"
      },
      {
        "start": 4153.6,
        "duration": 2.639,
        "text": "i just said we thought i just saw"
      },
      {
        "start": 4154.96,
        "duration": 3.6,
        "text": "another question but before i answer i"
      },
      {
        "start": 4156.239,
        "duration": 5.201,
        "text": "just wanted to to"
      },
      {
        "start": 4158.56,
        "duration": 4.88,
        "text": "agree with you that so i want i want"
      },
      {
        "start": 4161.44,
        "duration": 3.2,
        "text": "everybody to see that with cassandra and"
      },
      {
        "start": 4163.44,
        "duration": 3.12,
        "text": "the work that we're doing that these are"
      },
      {
        "start": 4164.64,
        "duration": 3.679,
        "text": "complements like there is"
      },
      {
        "start": 4166.56,
        "duration": 4.239,
        "text": "it's essentially taking the ability and"
      },
      {
        "start": 4168.319,
        "duration": 4.241,
        "text": "capability of what uh cassandra does and"
      },
      {
        "start": 4170.799,
        "duration": 4.48,
        "text": "writing the data particularly to a ss"
      },
      {
        "start": 4172.56,
        "duration": 4.56,
        "text": "table but there was a bit of a barrier"
      },
      {
        "start": 4175.279,
        "duration": 4.0,
        "text": "between what you could do and do take"
      },
      {
        "start": 4177.12,
        "duration": 4.559,
        "text": "that data and then directly process it"
      },
      {
        "start": 4179.279,
        "duration": 3.92,
        "text": "and push it into rapids before alex came"
      },
      {
        "start": 4181.679,
        "duration": 3.441,
        "text": "up with this kind of solution that now"
      },
      {
        "start": 4183.199,
        "duration": 3.52,
        "text": "has been able to kind of integrate these"
      },
      {
        "start": 4185.12,
        "duration": 3.84,
        "text": "two components and have them complement"
      },
      {
        "start": 4186.719,
        "duration": 4.241,
        "text": "each other from the transactional side"
      },
      {
        "start": 4188.96,
        "duration": 3.92,
        "text": "and then move it quickly to the machine"
      },
      {
        "start": 4190.96,
        "duration": 3.6,
        "text": "learning side and then i've seen your"
      },
      {
        "start": 4192.88,
        "duration": 3.12,
        "text": "question this most recent question where"
      },
      {
        "start": 4194.56,
        "duration": 3.52,
        "text": "in the chat where it says does rapids"
      },
      {
        "start": 4196.0,
        "duration": 4.159,
        "text": "avoid the data transfer between cpu and"
      },
      {
        "start": 4198.08,
        "duration": 3.92,
        "text": "gpu memory that's exactly what it does"
      },
      {
        "start": 4200.159,
        "duration": 3.361,
        "text": "and that's what that's what apache aero"
      },
      {
        "start": 4202.0,
        "duration": 3.679,
        "text": "is offering now is that we can actually"
      },
      {
        "start": 4203.52,
        "duration": 4.719,
        "text": "now take this data and then push it into"
      },
      {
        "start": 4205.679,
        "duration": 3.52,
        "text": "a gpu without having to load it to a cpu"
      },
      {
        "start": 4208.239,
        "duration": 2.721,
        "text": "which essentially would be the"
      },
      {
        "start": 4209.199,
        "duration": 4.881,
        "text": "bottleneck and then before you push it"
      },
      {
        "start": 4210.96,
        "duration": 5.6,
        "text": "into a gpu for additional functional uh"
      },
      {
        "start": 4214.08,
        "duration": 4.24,
        "text": "processing so that's that's then the"
      },
      {
        "start": 4216.56,
        "duration": 4.72,
        "text": "whole goal is to then be able to then"
      },
      {
        "start": 4218.32,
        "duration": 5.52,
        "text": "now keep all your analytics on"
      },
      {
        "start": 4221.28,
        "duration": 4.24,
        "text": "uh the gpu and essentially the start"
      },
      {
        "start": 4223.84,
        "duration": 3.359,
        "text": "from everything from the etl data"
      },
      {
        "start": 4225.52,
        "duration": 4.159,
        "text": "wrangling all the way to your model"
      },
      {
        "start": 4227.199,
        "duration": 3.52,
        "text": "training and iterative processing before"
      },
      {
        "start": 4229.679,
        "duration": 3.921,
        "text": "you actually write it out to a"
      },
      {
        "start": 4230.719,
        "duration": 4.96,
        "text": "particular uh destination is to keep it"
      },
      {
        "start": 4233.6,
        "duration": 3.599,
        "text": "on on the gpu without having to rely on"
      },
      {
        "start": 4235.679,
        "duration": 3.921,
        "text": "the cpu for"
      },
      {
        "start": 4237.199,
        "duration": 4.401,
        "text": "any additional uh functionality unless"
      },
      {
        "start": 4239.6,
        "duration": 3.44,
        "text": "it's absolutely necessary"
      },
      {
        "start": 4241.6,
        "duration": 3.68,
        "text": "yeah hey you made a really good point on"
      },
      {
        "start": 4243.04,
        "duration": 3.679,
        "text": "complementary that i really liked justin"
      },
      {
        "start": 4245.28,
        "duration": 2.72,
        "text": "like we should have put a slide in here"
      },
      {
        "start": 4246.719,
        "duration": 3.361,
        "text": "that just has like"
      },
      {
        "start": 4248.0,
        "duration": 3.44,
        "text": "rapids ecosystem and cassandra ecosystem"
      },
      {
        "start": 4250.08,
        "duration": 3.36,
        "text": "and like a little heart"
      },
      {
        "start": 4251.44,
        "duration": 3.44,
        "text": "you know because that's because really"
      },
      {
        "start": 4253.44,
        "duration": 3.84,
        "text": "what this is is about bringing those two"
      },
      {
        "start": 4254.88,
        "duration": 4.4,
        "text": "communities together"
      },
      {
        "start": 4257.28,
        "duration": 3.36,
        "text": "there's a ton of rapid users out there"
      },
      {
        "start": 4259.28,
        "duration": 3.2,
        "text": "right now that that know how to take"
      },
      {
        "start": 4260.64,
        "duration": 4.24,
        "text": "advantage of gpus"
      },
      {
        "start": 4262.48,
        "duration": 3.44,
        "text": "and their power and they're reading data"
      },
      {
        "start": 4264.88,
        "duration": 4.0,
        "text": "that's"
      },
      {
        "start": 4265.92,
        "duration": 4.88,
        "text": "in json or csv or parquet format"
      },
      {
        "start": 4268.88,
        "duration": 3.68,
        "text": "probably mostly parquet"
      },
      {
        "start": 4270.8,
        "duration": 4.16,
        "text": "and to get that data in parque there's a"
      },
      {
        "start": 4272.56,
        "duration": 4.56,
        "text": "lot of work that's getting done and"
      },
      {
        "start": 4274.96,
        "duration": 3.52,
        "text": "for a lot of large enterprises the"
      },
      {
        "start": 4277.12,
        "duration": 2.72,
        "text": "original source of that data is a"
      },
      {
        "start": 4278.48,
        "duration": 2.88,
        "text": "cassandra cluster somewhere and"
      },
      {
        "start": 4279.84,
        "duration": 3.12,
        "text": "somebody's reading data from less"
      },
      {
        "start": 4281.36,
        "duration": 4.4,
        "text": "cassandra clusters the slow way through"
      },
      {
        "start": 4282.96,
        "duration": 4.239,
        "text": "cql and they're manipulating it with"
      },
      {
        "start": 4285.76,
        "duration": 3.12,
        "text": "like some different tools to get it into"
      },
      {
        "start": 4287.199,
        "duration": 4.321,
        "text": "that parquet format so that they can go"
      },
      {
        "start": 4288.88,
        "duration": 4.96,
        "text": "loaded into a gpus somewhere and"
      },
      {
        "start": 4291.52,
        "duration": 5.36,
        "text": "so the stuff that alex has built here is"
      },
      {
        "start": 4293.84,
        "duration": 6.24,
        "text": "a huge shortcut to that kind of long to"
      },
      {
        "start": 4296.88,
        "duration": 4.4,
        "text": "that long process and so we hope that"
      },
      {
        "start": 4300.08,
        "duration": 2.72,
        "text": "you know the two communities i think"
      },
      {
        "start": 4301.28,
        "duration": 3.2,
        "text": "there's a lot of folks"
      },
      {
        "start": 4302.8,
        "duration": 3.919,
        "text": "definitely a lot of large organizations"
      },
      {
        "start": 4304.48,
        "duration": 4.4,
        "text": "that have both a big rapid footprint"
      },
      {
        "start": 4306.719,
        "duration": 4.401,
        "text": "that's using gpus for analytics and a"
      },
      {
        "start": 4308.88,
        "duration": 3.68,
        "text": "big cassandra footprint where a lot of"
      },
      {
        "start": 4311.12,
        "duration": 3.44,
        "text": "their transactional data is sitting in"
      },
      {
        "start": 4312.56,
        "duration": 4.8,
        "text": "cassandra and so you know the idea is to"
      },
      {
        "start": 4314.56,
        "duration": 2.8,
        "text": "bring those together"
      },
      {
        "start": 4321.199,
        "duration": 3.601,
        "text": "uh can you make a separate cassandra"
      },
      {
        "start": 4322.88,
        "duration": 3.359,
        "text": "replicated cluster"
      },
      {
        "start": 4324.8,
        "duration": 3.2,
        "text": "i think what you mean there maybe is a"
      },
      {
        "start": 4326.239,
        "duration": 3.681,
        "text": "replicated data center within the same"
      },
      {
        "start": 4328.0,
        "duration": 4.08,
        "text": "cluster that has the same data to get"
      },
      {
        "start": 4329.92,
        "duration": 4.08,
        "text": "the data to a certain snapshot state and"
      },
      {
        "start": 4332.08,
        "duration": 3.76,
        "text": "then get cassandra to stop replicating"
      },
      {
        "start": 4334.0,
        "duration": 3.28,
        "text": "and flush the data ss tables"
      },
      {
        "start": 4335.84,
        "duration": 3.2,
        "text": "yeah so operationally you can tell"
      },
      {
        "start": 4337.28,
        "duration": 3.36,
        "text": "cassandra to flush at any point like"
      },
      {
        "start": 4339.04,
        "duration": 4.24,
        "text": "there's there's an old tool command for"
      },
      {
        "start": 4340.64,
        "duration": 4.72,
        "text": "that um and so you can or yeah so you"
      },
      {
        "start": 4343.28,
        "duration": 4.08,
        "text": "could you know flush or take snapshots"
      },
      {
        "start": 4345.36,
        "duration": 3.68,
        "text": "and kind of work off of those"
      },
      {
        "start": 4347.36,
        "duration": 3.28,
        "text": "um yeah these there's there's i think"
      },
      {
        "start": 4349.04,
        "duration": 2.8,
        "text": "there's different options that we can"
      },
      {
        "start": 4350.64,
        "duration": 3.2,
        "text": "kind of operationalize or"
      },
      {
        "start": 4351.84,
        "duration": 3.28,
        "text": "productionalize these tools"
      },
      {
        "start": 4353.84,
        "duration": 3.12,
        "text": "um if this is something that's"
      },
      {
        "start": 4355.12,
        "duration": 3.76,
        "text": "interesting to you we'd you know love to"
      },
      {
        "start": 4356.96,
        "duration": 3.68,
        "text": "chat more about it so you know please do"
      },
      {
        "start": 4358.88,
        "duration": 3.359,
        "text": "reach out um"
      },
      {
        "start": 4360.64,
        "duration": 3.44,
        "text": "yeah like if somebody's actually you"
      },
      {
        "start": 4362.239,
        "duration": 3.121,
        "text": "know wanting to use this for real um i'm"
      },
      {
        "start": 4364.08,
        "duration": 2.24,
        "text": "sad that data stacks i'd love to chat"
      },
      {
        "start": 4365.36,
        "duration": 3.04,
        "text": "with you"
      },
      {
        "start": 4366.32,
        "duration": 4.48,
        "text": "that's just seb of data stacks"
      },
      {
        "start": 4368.4,
        "duration": 4.16,
        "text": "uh another question do do analytics in"
      },
      {
        "start": 4370.8,
        "duration": 3.52,
        "text": "one batch and then switch to cassandra"
      },
      {
        "start": 4372.56,
        "duration": 2.72,
        "text": "back in full replication so it catches"
      },
      {
        "start": 4374.32,
        "duration": 2.96,
        "text": "up"
      },
      {
        "start": 4375.28,
        "duration": 3.68,
        "text": "i guess there are different ways um"
      },
      {
        "start": 4377.28,
        "duration": 3.76,
        "text": "but yeah i don't i don't think you you"
      },
      {
        "start": 4378.96,
        "duration": 4.719,
        "text": "might not need to do"
      },
      {
        "start": 4381.04,
        "duration": 4.639,
        "text": "like cassandra level replication"
      },
      {
        "start": 4383.679,
        "duration": 3.841,
        "text": "to get the data out like you may like"
      },
      {
        "start": 4385.679,
        "duration": 4.081,
        "text": "the whole kind of one of the advantages"
      },
      {
        "start": 4387.52,
        "duration": 5.04,
        "text": "of this is you can just rsync the ss"
      },
      {
        "start": 4389.76,
        "duration": 4.8,
        "text": "tables and you're done"
      },
      {
        "start": 4392.56,
        "duration": 4.56,
        "text": "right um yeah you may be able to just"
      },
      {
        "start": 4394.56,
        "duration": 4.159,
        "text": "rsync those ss tables um you might not"
      },
      {
        "start": 4397.12,
        "duration": 3.36,
        "text": "you wouldn't need to you know use"
      },
      {
        "start": 4398.719,
        "duration": 4.881,
        "text": "cassandra to stream the data across to"
      },
      {
        "start": 4400.48,
        "duration": 5.28,
        "text": "another location so it may be simpler"
      },
      {
        "start": 4403.6,
        "duration": 5.88,
        "text": "than what you're thinking there uh let's"
      },
      {
        "start": 4405.76,
        "duration": 3.72,
        "text": "give us two thousand"
      },
      {
        "start": 4413.52,
        "duration": 2.56,
        "text": "all right"
      },
      {
        "start": 4416.159,
        "duration": 4.481,
        "text": "uh well it looks like that is most of"
      },
      {
        "start": 4418.239,
        "duration": 5.041,
        "text": "the questions"
      },
      {
        "start": 4420.64,
        "duration": 4.4,
        "text": "so i think we can uh move on"
      },
      {
        "start": 4423.28,
        "duration": 3.36,
        "text": "uh was there anything else alex that you"
      },
      {
        "start": 4425.04,
        "duration": 2.72,
        "text": "wanted to uh"
      },
      {
        "start": 4426.64,
        "duration": 3.44,
        "text": "to talk about"
      },
      {
        "start": 4427.76,
        "duration": 4.08,
        "text": "no that was it um yeah thanks so much to"
      },
      {
        "start": 4430.08,
        "duration": 3.52,
        "text": "seven justin for answering those"
      },
      {
        "start": 4431.84,
        "duration": 4.399,
        "text": "questions um"
      },
      {
        "start": 4433.6,
        "duration": 5.52,
        "text": "yeah and just keeping an eye on the chat"
      },
      {
        "start": 4436.239,
        "duration": 2.881,
        "text": "yeah that's it for me"
      },
      {
        "start": 4439.36,
        "duration": 6.0,
        "text": "all right well i think uh then we can"
      },
      {
        "start": 4442.159,
        "duration": 5.601,
        "text": "move on to our quiz"
      },
      {
        "start": 4445.36,
        "duration": 3.92,
        "text": "there's nothing else"
      },
      {
        "start": 4447.76,
        "duration": 3.04,
        "text": "let me uh"
      },
      {
        "start": 4449.28,
        "duration": 2.64,
        "text": "switch over here"
      },
      {
        "start": 4450.8,
        "duration": 2.48,
        "text": "all right"
      },
      {
        "start": 4451.92,
        "duration": 2.72,
        "text": "so for those of you who are still with"
      },
      {
        "start": 4453.28,
        "duration": 3.52,
        "text": "us looks like we still have most people"
      },
      {
        "start": 4454.64,
        "duration": 4.48,
        "text": "which is great uh we're gonna do a short"
      },
      {
        "start": 4456.8,
        "duration": 5.919,
        "text": "little quiz here uh where you can"
      },
      {
        "start": 4459.12,
        "duration": 6.4,
        "text": "win some prizes uh at the end"
      },
      {
        "start": 4462.719,
        "duration": 5.601,
        "text": "um and get some swag sent to you now uh"
      },
      {
        "start": 4465.52,
        "duration": 3.84,
        "text": "we are going to be using mentee.com so"
      },
      {
        "start": 4468.32,
        "duration": 2.8,
        "text": "you can see at the top of the page"
      },
      {
        "start": 4469.36,
        "duration": 3.68,
        "text": "actually i'm going to break up a"
      },
      {
        "start": 4471.12,
        "duration": 3.76,
        "text": "bigger slide so you go to menti.com you"
      },
      {
        "start": 4473.04,
        "duration": 3.92,
        "text": "can use it on your phone uh you can scan"
      },
      {
        "start": 4474.88,
        "duration": 3.359,
        "text": "that qr code if that's easy you also"
      },
      {
        "start": 4476.96,
        "duration": 3.04,
        "text": "open a new tab"
      },
      {
        "start": 4478.239,
        "duration": 4.161,
        "text": "and you can enter the code that you see"
      },
      {
        "start": 4480.0,
        "duration": 5.92,
        "text": "on the screen also put it in the chat uh"
      },
      {
        "start": 4482.4,
        "duration": 3.52,
        "text": "and you can join our quiz here"
      },
      {
        "start": 4486.32,
        "duration": 4.72,
        "text": "it's gonna be a few questions it won't"
      },
      {
        "start": 4487.92,
        "duration": 6.4,
        "text": "be very long um but the top three"
      },
      {
        "start": 4491.04,
        "duration": 6.159,
        "text": "scorers uh will be eligible to win some"
      },
      {
        "start": 4494.32,
        "duration": 4.32,
        "text": "swag and we ship the the prizes um"
      },
      {
        "start": 4497.199,
        "duration": 3.52,
        "text": "all around the world so no matter where"
      },
      {
        "start": 4498.64,
        "duration": 4.88,
        "text": "you are uh we can get it to you"
      },
      {
        "start": 4500.719,
        "duration": 4.161,
        "text": "um so go ahead and go to mentee.com"
      },
      {
        "start": 4503.52,
        "duration": 2.639,
        "text": "uh once you're there you can hit the"
      },
      {
        "start": 4504.88,
        "duration": 3.2,
        "text": "there's like a little thumbs up if you"
      },
      {
        "start": 4506.159,
        "duration": 3.921,
        "text": "want to hit that um we can see how many"
      },
      {
        "start": 4508.08,
        "duration": 2.96,
        "text": "people are in let me go ahead and switch"
      },
      {
        "start": 4510.08,
        "duration": 2.24,
        "text": "back"
      },
      {
        "start": 4511.04,
        "duration": 2.32,
        "text": "all right we've got some people it's"
      },
      {
        "start": 4512.32,
        "duration": 4.96,
        "text": "coming out of justin's head which is"
      },
      {
        "start": 4513.36,
        "duration": 3.92,
        "text": "cool um all right"
      },
      {
        "start": 4519.04,
        "duration": 3.36,
        "text": "we'll give a little bit of time make"
      },
      {
        "start": 4520.08,
        "duration": 4.4,
        "text": "sure that everyone has an opportunity uh"
      },
      {
        "start": 4522.4,
        "duration": 4.4,
        "text": "to join"
      },
      {
        "start": 4524.48,
        "duration": 4.4,
        "text": "um i was going to mention something else"
      },
      {
        "start": 4526.8,
        "duration": 3.52,
        "text": "and i'm blanking on it right now"
      },
      {
        "start": 4528.88,
        "duration": 3.359,
        "text": "um"
      },
      {
        "start": 4530.32,
        "duration": 4.32,
        "text": "set mentioned that uh that you can reach"
      },
      {
        "start": 4532.239,
        "duration": 4.0,
        "text": "out to us i want to plug uh just briefly"
      },
      {
        "start": 4534.64,
        "duration": 3.92,
        "text": "again our discord"
      },
      {
        "start": 4536.239,
        "duration": 4.0,
        "text": "uh community i'll put that link in the"
      },
      {
        "start": 4538.56,
        "duration": 4.24,
        "text": "chat as well um this is a place that you"
      },
      {
        "start": 4540.239,
        "duration": 4.561,
        "text": "can kind of reach out to us and uh and"
      },
      {
        "start": 4542.8,
        "duration": 2.8,
        "text": "ask more questions and stay in contact"
      },
      {
        "start": 4544.8,
        "duration": 2.16,
        "text": "so"
      },
      {
        "start": 4545.6,
        "duration": 3.44,
        "text": "that's a good place"
      },
      {
        "start": 4546.96,
        "duration": 5.04,
        "text": "to join if you're interested in talking"
      },
      {
        "start": 4549.04,
        "duration": 4.88,
        "text": "more about this topic or other topics"
      },
      {
        "start": 4552.0,
        "duration": 3.36,
        "text": "cassandra specific topics"
      },
      {
        "start": 4553.92,
        "duration": 4.0,
        "text": "be great all right it looks like we have"
      },
      {
        "start": 4555.36,
        "duration": 4.64,
        "text": "most people in uh so let's get started"
      },
      {
        "start": 4557.92,
        "duration": 4.4,
        "text": "with this quiz now something to note is"
      },
      {
        "start": 4560.0,
        "duration": 4.239,
        "text": "that speed in answering the questions"
      },
      {
        "start": 4562.32,
        "duration": 4.48,
        "text": "matters so the faster you answer uh"
      },
      {
        "start": 4564.239,
        "duration": 3.44,
        "text": "correctly uh the more points you get"
      },
      {
        "start": 4566.8,
        "duration": 3.919,
        "text": "so"
      },
      {
        "start": 4567.679,
        "duration": 3.04,
        "text": "uh keep that in mind"
      },
      {
        "start": 4570.8,
        "duration": 4.399,
        "text": "uh all right"
      },
      {
        "start": 4573.6,
        "duration": 3.84,
        "text": "so there's only gonna be four questions"
      },
      {
        "start": 4575.199,
        "duration": 3.441,
        "text": "and remember the top three scorers will"
      },
      {
        "start": 4577.44,
        "duration": 4.239,
        "text": "win all right"
      },
      {
        "start": 4578.64,
        "duration": 3.92,
        "text": "first question"
      },
      {
        "start": 4581.679,
        "duration": 3.441,
        "text": "oops"
      },
      {
        "start": 4582.56,
        "duration": 2.56,
        "text": "way too fast"
      },
      {
        "start": 4586.159,
        "duration": 4.401,
        "text": "answer fast to get more points"
      },
      {
        "start": 4588.4,
        "duration": 5.16,
        "text": "so what is the rapid equivalent of"
      },
      {
        "start": 4590.56,
        "duration": 3.0,
        "text": "pandas"
      },
      {
        "start": 4594.08,
        "duration": 7.119,
        "text": "qdf 2ml kugraf or qsignal"
      },
      {
        "start": 4598.96,
        "duration": 4.88,
        "text": "remember to uh to watch your phone or"
      },
      {
        "start": 4601.199,
        "duration": 4.081,
        "text": "the the tab that you're in because um"
      },
      {
        "start": 4603.84,
        "duration": 3.6,
        "text": "there's a little bit of a latency on the"
      },
      {
        "start": 4605.28,
        "duration": 5.439,
        "text": "stream as well all right most people got"
      },
      {
        "start": 4607.44,
        "duration": 4.96,
        "text": "that correct it is qdf"
      },
      {
        "start": 4610.719,
        "duration": 3.041,
        "text": "awesome"
      },
      {
        "start": 4612.4,
        "duration": 5.759,
        "text": "let's see what our leaderboard looks"
      },
      {
        "start": 4613.76,
        "duration": 4.399,
        "text": "like see the fastest answer was"
      },
      {
        "start": 4619.76,
        "duration": 4.32,
        "text": "looks like bastian was the fastest this"
      },
      {
        "start": 4622.239,
        "duration": 3.44,
        "text": "time"
      },
      {
        "start": 4624.08,
        "duration": 5.44,
        "text": "awesome job"
      },
      {
        "start": 4625.679,
        "duration": 3.841,
        "text": "all right question number two"
      },
      {
        "start": 4632.239,
        "duration": 4.881,
        "text": "why are gpus more effective at data"
      },
      {
        "start": 4634.32,
        "duration": 5.04,
        "text": "science than cpus"
      },
      {
        "start": 4637.12,
        "duration": 4.64,
        "text": "they have better algorithms they have a"
      },
      {
        "start": 4639.36,
        "duration": 3.92,
        "text": "larger ecosystem of libraries they can"
      },
      {
        "start": 4641.76,
        "duration": 6.6,
        "text": "run many parallel operations"
      },
      {
        "start": 4643.28,
        "duration": 5.08,
        "text": "simultaneously or they have more memory"
      },
      {
        "start": 4651.28,
        "duration": 6.32,
        "text": "all right awesome yes they can run many"
      },
      {
        "start": 4654.0,
        "duration": 5.6,
        "text": "parallel operations simultaneously"
      },
      {
        "start": 4657.6,
        "duration": 4.48,
        "text": "and that makes them more effective all"
      },
      {
        "start": 4659.6,
        "duration": 5.72,
        "text": "right let's see where our leaderboard"
      },
      {
        "start": 4662.08,
        "duration": 3.24,
        "text": "looks like"
      },
      {
        "start": 4668.719,
        "duration": 2.721,
        "text": "all right looks like g was the fastest"
      },
      {
        "start": 4670.4,
        "duration": 3.2,
        "text": "this time"
      },
      {
        "start": 4671.44,
        "duration": 3.92,
        "text": "sash takes the lead bastion is in second"
      },
      {
        "start": 4673.6,
        "duration": 3.68,
        "text": "and skivvis is in"
      },
      {
        "start": 4675.36,
        "duration": 5.04,
        "text": "third"
      },
      {
        "start": 4677.28,
        "duration": 3.12,
        "text": "all right question three"
      },
      {
        "start": 4685.44,
        "duration": 3.92,
        "text": "which one of the following is not the"
      },
      {
        "start": 4686.88,
        "duration": 4.4,
        "text": "benefit of using sstable to arrow it"
      },
      {
        "start": 4689.36,
        "duration": 3.839,
        "text": "reads data directly from files freeing"
      },
      {
        "start": 4691.28,
        "duration": 4.56,
        "text": "up cassandra it helps you migrate"
      },
      {
        "start": 4693.199,
        "duration": 4.96,
        "text": "existing python code using rapids it"
      },
      {
        "start": 4695.84,
        "duration": 4.8,
        "text": "doesn't support all cassandra features"
      },
      {
        "start": 4698.159,
        "duration": 3.601,
        "text": "it can read files from amazon s3 and"
      },
      {
        "start": 4700.64,
        "duration": 3.039,
        "text": "from disk"
      },
      {
        "start": 4701.76,
        "duration": 3.36,
        "text": "remember this is not a benefit which is"
      },
      {
        "start": 4703.679,
        "duration": 4.161,
        "text": "which of the following is not the"
      },
      {
        "start": 4705.12,
        "duration": 2.72,
        "text": "benefit"
      },
      {
        "start": 4710.159,
        "duration": 4.161,
        "text": "all right yes it does not support"
      },
      {
        "start": 4711.92,
        "duration": 4.16,
        "text": "currently all cassandra features"
      },
      {
        "start": 4714.32,
        "duration": 3.12,
        "text": "it is definitely early in its"
      },
      {
        "start": 4716.08,
        "duration": 2.4,
        "text": "development but it's very promising i"
      },
      {
        "start": 4717.44,
        "duration": 4.64,
        "text": "think"
      },
      {
        "start": 4718.48,
        "duration": 3.6,
        "text": "all right let's see what that"
      },
      {
        "start": 4722.48,
        "duration": 2.88,
        "text": "does to our scores"
      },
      {
        "start": 4729.36,
        "duration": 2.48,
        "text": "all right looks like we had a tie for"
      },
      {
        "start": 4730.56,
        "duration": 4.08,
        "text": "fastest which is"
      },
      {
        "start": 4731.84,
        "duration": 4.399,
        "text": "interesting g now takes the lead and d"
      },
      {
        "start": 4734.64,
        "duration": 3.599,
        "text": "is in seconds give us"
      },
      {
        "start": 4736.239,
        "duration": 4.0,
        "text": "maintains third place all right final"
      },
      {
        "start": 4738.239,
        "duration": 5.601,
        "text": "question"
      },
      {
        "start": 4740.239,
        "duration": 3.601,
        "text": "this is for all the marbles"
      },
      {
        "start": 4745.52,
        "duration": 4.32,
        "text": "how does cassandra save data to the disk"
      },
      {
        "start": 4751.199,
        "duration": 4.081,
        "text": "arrow ipc file format sorted string"
      },
      {
        "start": 4754.0,
        "duration": 6.36,
        "text": "table files"
      },
      {
        "start": 4755.28,
        "duration": 5.08,
        "text": "parquet files or json files"
      },
      {
        "start": 4770.56,
        "duration": 4.159,
        "text": "all right yes sorted string table files"
      },
      {
        "start": 4773.12,
        "duration": 3.039,
        "text": "or ss tables"
      },
      {
        "start": 4774.719,
        "duration": 2.96,
        "text": "is the correct answer and let's see what"
      },
      {
        "start": 4776.159,
        "duration": 4.08,
        "text": "that does for our score and remember if"
      },
      {
        "start": 4777.679,
        "duration": 4.961,
        "text": "you are the top three winners uh"
      },
      {
        "start": 4780.239,
        "duration": 4.561,
        "text": "take a screenshot of your uh of your"
      },
      {
        "start": 4782.64,
        "duration": 3.28,
        "text": "screen where it says that you have"
      },
      {
        "start": 4784.8,
        "duration": 2.96,
        "text": "um"
      },
      {
        "start": 4785.92,
        "duration": 4.319,
        "text": "where you are in the top three"
      },
      {
        "start": 4787.76,
        "duration": 4.24,
        "text": "and uh congratulations g to our overall"
      },
      {
        "start": 4790.239,
        "duration": 3.201,
        "text": "winner and then d is in second and see"
      },
      {
        "start": 4792.0,
        "duration": 3.679,
        "text": "this is in third make sure to take a"
      },
      {
        "start": 4793.44,
        "duration": 6.48,
        "text": "screenshot of this page right here um"
      },
      {
        "start": 4795.679,
        "duration": 4.241,
        "text": "and you're going to email jack.friar"
      },
      {
        "start": 4800.08,
        "duration": 5.28,
        "text": "at datasacks.com i will put that"
      },
      {
        "start": 4802.8,
        "duration": 6.24,
        "text": "in the"
      },
      {
        "start": 4805.36,
        "duration": 6.48,
        "text": "uh if i can type in the in the chat"
      },
      {
        "start": 4809.04,
        "duration": 5.679,
        "text": "and you can email uh jackdawfry"
      },
      {
        "start": 4811.84,
        "duration": 4.08,
        "text": "your screen here your screenshot"
      },
      {
        "start": 4814.719,
        "duration": 2.96,
        "text": "and uh"
      },
      {
        "start": 4815.92,
        "duration": 3.84,
        "text": "you will be able to get some some swag"
      },
      {
        "start": 4817.679,
        "duration": 4.081,
        "text": "sent to you he'll reach out to you for"
      },
      {
        "start": 4819.76,
        "duration": 2.8,
        "text": "all the details that you need for that"
      },
      {
        "start": 4821.76,
        "duration": 3.36,
        "text": "so"
      },
      {
        "start": 4822.56,
        "duration": 3.36,
        "text": "awesome congratulations thank you all"
      },
      {
        "start": 4825.12,
        "duration": 3.84,
        "text": "for"
      },
      {
        "start": 4825.92,
        "duration": 4.56,
        "text": "uh joining us"
      },
      {
        "start": 4828.96,
        "duration": 4.48,
        "text": "uh for this uh for this workshop and"
      },
      {
        "start": 4830.48,
        "duration": 5.6,
        "text": "this webinar um and for participating in"
      },
      {
        "start": 4833.44,
        "duration": 5.199,
        "text": "our little quiz here uh we really uh"
      },
      {
        "start": 4836.08,
        "duration": 3.76,
        "text": "appreciate you uh joining us"
      },
      {
        "start": 4838.639,
        "duration": 3.6,
        "text": "and uh"
      },
      {
        "start": 4839.84,
        "duration": 4.0,
        "text": "unless there are any other questions"
      },
      {
        "start": 4842.239,
        "duration": 5.44,
        "text": "uh i'll uh hand it back to our"
      },
      {
        "start": 4843.84,
        "duration": 5.12,
        "text": "presenters for closing us out"
      },
      {
        "start": 4847.679,
        "duration": 4.0,
        "text": "and we'll uh"
      },
      {
        "start": 4848.96,
        "duration": 4.4,
        "text": "give you back the rest of your day"
      },
      {
        "start": 4851.679,
        "duration": 3.681,
        "text": "great stuff"
      },
      {
        "start": 4853.36,
        "duration": 4.56,
        "text": "thanks so much for coming everyone"
      },
      {
        "start": 4855.36,
        "duration": 2.56,
        "text": "thank you so much"
      },
      {
        "start": 4858.639,
        "duration": 3.841,
        "text": "alex's fearlessness and doing live"
      },
      {
        "start": 4860.639,
        "duration": 3.761,
        "text": "coding"
      },
      {
        "start": 4862.48,
        "duration": 4.0,
        "text": "good job it's not every day that"
      },
      {
        "start": 4864.4,
        "duration": 3.04,
        "text": "somebody uh"
      },
      {
        "start": 4866.48,
        "duration": 3.199,
        "text": "yeah"
      },
      {
        "start": 4867.44,
        "duration": 3.92,
        "text": "goes for it like that"
      },
      {
        "start": 4869.679,
        "duration": 4.321,
        "text": "yeah"
      },
      {
        "start": 4871.36,
        "duration": 3.92,
        "text": "some courage for sure"
      },
      {
        "start": 4874.0,
        "duration": 2.88,
        "text": "yeah well done"
      },
      {
        "start": 4875.28,
        "duration": 2.56,
        "text": "well done everyone"
      },
      {
        "start": 4876.88,
        "duration": 2.48,
        "text": "all right"
      },
      {
        "start": 4877.84,
        "duration": 2.799,
        "text": "thanks everyone for joining us uh we"
      },
      {
        "start": 4879.36,
        "duration": 2.64,
        "text": "hope you have a great evening really"
      },
      {
        "start": 4880.639,
        "duration": 2.881,
        "text": "appreciate it man"
      },
      {
        "start": 4882.0,
        "duration": 3.6,
        "text": "thank you yeah thanks for a special"
      },
      {
        "start": 4883.52,
        "duration": 5.6,
        "text": "guest justin from nvidia uh have a great"
      },
      {
        "start": 4885.6,
        "duration": 3.52,
        "text": "rest of your week everyone see it"
      },
      {
        "start": 4889.28,
        "duration": 4.24,
        "text": "and as always don't forget to click that"
      },
      {
        "start": 4891.36,
        "duration": 4.319,
        "text": "subscribe button and ring that bell to"
      },
      {
        "start": 4893.52,
        "duration": 4.8,
        "text": "get notifications for all of our future"
      },
      {
        "start": 4895.679,
        "duration": 5.281,
        "text": "upcoming workshops"
      },
      {
        "start": 4898.32,
        "duration": 5.28,
        "text": "imagine a being gifted with powers from"
      },
      {
        "start": 4900.96,
        "duration": 5.04,
        "text": "the goddess of cassandra who grew those"
      },
      {
        "start": 4903.6,
        "duration": 4.88,
        "text": "powers until she could multiply it will"
      },
      {
        "start": 4906.0,
        "duration": 5.04,
        "text": "move with limitless speed and unmask"
      },
      {
        "start": 4908.48,
        "duration": 4.159,
        "text": "hidden knowledge with those powers she"
      },
      {
        "start": 4911.04,
        "duration": 3.52,
        "text": "was able to fully understand the"
      },
      {
        "start": 4912.639,
        "duration": 4.401,
        "text": "connectedness of the world"
      },
      {
        "start": 4914.56,
        "duration": 5.36,
        "text": "what she saw was a world in need of"
      },
      {
        "start": 4917.04,
        "duration": 5.119,
        "text": "understanding from that day forward she"
      },
      {
        "start": 4919.92,
        "duration": 4.319,
        "text": "sought to bestow her powers on all who"
      },
      {
        "start": 4922.159,
        "duration": 6.761,
        "text": "came into contact with her empowering"
      },
      {
        "start": 4924.239,
        "duration": 4.681,
        "text": "them to achieve wondrous feats"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T20:06:52.075981+00:00"
}