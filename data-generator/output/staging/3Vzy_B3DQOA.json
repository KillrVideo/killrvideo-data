{
  "video_id": "3Vzy_B3DQOA",
  "title": "DS320.27 Spark/Cassandra Connector: Group By Key | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.27 Spark/Cassandra Connector: Group By Key\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:30:47Z",
  "thumbnail": "https://i.ytimg.com/vi/3Vzy_B3DQOA/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=3Vzy_B3DQOA",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] let's take a look at another cassandra query where we're doing something that seems intuitive and normal but is actually a little slower than it needs to be now here we're selecting actor release here and title from movies by actor we do a little mapping of that in the third line and then we call group by key that's going to group all of these movies by actor and year and then we perform some more operations on that there easy enough but group by key is going to incur a shuffle we're pulling the data out of cassandra then shuffling it then performing actions on it if we could avoid that shuffle we'd like to let's look at how we see we made actor and release year the key now if you look in the schema off to the right actor and release here are the partition key and one of the clustering columns this data is already grouped in cassandra we don't have to pull it out and have spark shuffle it so that it's grouped the way we want it we could get that out of cassandra pre-grouped for our convenience and we have two methods that can help us out here these are span by key and span by now span by key is a method we're going to use rather than the group by key transformation and it's going to push that grouping to be done in to cassandra it's going to assume that the key in the cassandra query is the key that we want to group by in our grouping span by is very similar except we can pass an anonymous function into it and specify what we want the key to be now for this to work as a cassandra optimization we still have to be picking columns that are in the cassandra key we don't get to pick from arbitrary columns in the table but if we don't want the default key structure of that table we want to do something to modify still picking from within the partition key and the clustering keys then span by is the thing we want let me stress again that these only work as optimization when we're grouping by columns that are a part of the partition key or our clustering keys we can't do this to group by arbitrary columns because then it wouldn't be a cassandra optimization because cassandra doesn't do that if you have to do that you can still group by key on any column in your cassandra query but then it will be spark doing that in the normal way so when you want to group by things that are cassandra primary key columns use the optimized methods and that work gets done in cassandra rather than in spark let's take a look at the code for a couple of different solutions here we have the same query getting actor release here and title from movies by actor we have the same key structure on the third line making actor and year the key and title the value and then we call span by key that's going to do the same thing as group by key would have it's going to make actor and release here the key and then a collection of titles will be the value you can see that down in the sample output below in the second example we do something similar but we use span by instead same query where we select actor release here and title from movies by actor but then we call span by and we say we want the key to be actor and year you'll notice that the output is different i'll go ahead and flip back quickly to the output we saw in the previous example where the key was simply a list of the values we see the tourist and alice in wonderland in 2010 into the woods transcendence and tusk in 2014. now we see those same things in the data here but all of the columns including the key columns in the output just a detail in the implementation of those two things that's a good idea to keep your eye on",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.319,
        "duration": 2.481,
        "text": "let's take a look"
      },
      {
        "start": 7.2,
        "duration": 3.68,
        "text": "at another cassandra query where we're"
      },
      {
        "start": 8.8,
        "duration": 2.799,
        "text": "doing something that seems intuitive and"
      },
      {
        "start": 10.88,
        "duration": 2.08,
        "text": "normal but"
      },
      {
        "start": 11.599,
        "duration": 2.96,
        "text": "is actually a little slower than it"
      },
      {
        "start": 12.96,
        "duration": 3.76,
        "text": "needs to be now here we're selecting"
      },
      {
        "start": 14.559,
        "duration": 2.56,
        "text": "actor release here and title from movies"
      },
      {
        "start": 16.72,
        "duration": 2.399,
        "text": "by"
      },
      {
        "start": 17.119,
        "duration": 3.761,
        "text": "actor we do a little mapping of that in"
      },
      {
        "start": 19.119,
        "duration": 4.24,
        "text": "the third line and then we call"
      },
      {
        "start": 20.88,
        "duration": 3.44,
        "text": "group by key that's going to group all"
      },
      {
        "start": 23.359,
        "duration": 3.281,
        "text": "of these movies"
      },
      {
        "start": 24.32,
        "duration": 4.08,
        "text": "by actor and year and then we perform"
      },
      {
        "start": 26.64,
        "duration": 4.719,
        "text": "some more operations on that there"
      },
      {
        "start": 28.4,
        "duration": 4.72,
        "text": "easy enough but group by key is going to"
      },
      {
        "start": 31.359,
        "duration": 2.88,
        "text": "incur a shuffle we're pulling the data"
      },
      {
        "start": 33.12,
        "duration": 2.72,
        "text": "out of cassandra"
      },
      {
        "start": 34.239,
        "duration": 2.961,
        "text": "then shuffling it then performing"
      },
      {
        "start": 35.84,
        "duration": 2.559,
        "text": "actions on it if we could avoid that"
      },
      {
        "start": 37.2,
        "duration": 3.44,
        "text": "shuffle we'd like to"
      },
      {
        "start": 38.399,
        "duration": 4.081,
        "text": "let's look at how we see we made actor"
      },
      {
        "start": 40.64,
        "duration": 3.68,
        "text": "and release year the key now if you look"
      },
      {
        "start": 42.48,
        "duration": 4.64,
        "text": "in the schema off to the right"
      },
      {
        "start": 44.32,
        "duration": 4.96,
        "text": "actor and release here are the partition"
      },
      {
        "start": 47.12,
        "duration": 3.84,
        "text": "key and one of the clustering columns"
      },
      {
        "start": 49.28,
        "duration": 3.599,
        "text": "this data is already grouped in"
      },
      {
        "start": 50.96,
        "duration": 3.919,
        "text": "cassandra we don't have to pull it out"
      },
      {
        "start": 52.879,
        "duration": 3.441,
        "text": "and have spark shuffle it so that it's"
      },
      {
        "start": 54.879,
        "duration": 3.041,
        "text": "grouped the way we want it"
      },
      {
        "start": 56.32,
        "duration": 3.36,
        "text": "we could get that out of cassandra"
      },
      {
        "start": 57.92,
        "duration": 4.159,
        "text": "pre-grouped for our convenience"
      },
      {
        "start": 59.68,
        "duration": 3.039,
        "text": "and we have two methods that can help us"
      },
      {
        "start": 62.079,
        "duration": 3.841,
        "text": "out here"
      },
      {
        "start": 62.719,
        "duration": 5.681,
        "text": "these are span by key and span"
      },
      {
        "start": 65.92,
        "duration": 3.12,
        "text": "by now span by key is a method we're"
      },
      {
        "start": 68.4,
        "duration": 3.28,
        "text": "going to use"
      },
      {
        "start": 69.04,
        "duration": 4.079,
        "text": "rather than the group by key"
      },
      {
        "start": 71.68,
        "duration": 2.88,
        "text": "transformation and it's going to push"
      },
      {
        "start": 73.119,
        "duration": 4.081,
        "text": "that grouping to be done"
      },
      {
        "start": 74.56,
        "duration": 3.68,
        "text": "in to cassandra it's going to assume"
      },
      {
        "start": 77.2,
        "duration": 3.76,
        "text": "that the key"
      },
      {
        "start": 78.24,
        "duration": 4.16,
        "text": "in the cassandra query is the key that"
      },
      {
        "start": 80.96,
        "duration": 4.24,
        "text": "we want to group by"
      },
      {
        "start": 82.4,
        "duration": 4.64,
        "text": "in our grouping span by is very similar"
      },
      {
        "start": 85.2,
        "duration": 4.72,
        "text": "except we can pass an anonymous function"
      },
      {
        "start": 87.04,
        "duration": 4.8,
        "text": "into it and specify what we want the key"
      },
      {
        "start": 89.92,
        "duration": 3.36,
        "text": "to be now for this to work as a"
      },
      {
        "start": 91.84,
        "duration": 3.84,
        "text": "cassandra optimization"
      },
      {
        "start": 93.28,
        "duration": 4.56,
        "text": "we still have to be picking columns that"
      },
      {
        "start": 95.68,
        "duration": 4.32,
        "text": "are in the cassandra key we don't get to"
      },
      {
        "start": 97.84,
        "duration": 4.319,
        "text": "pick from arbitrary columns in the table"
      },
      {
        "start": 100.0,
        "duration": 3.6,
        "text": "but if we don't want the default key"
      },
      {
        "start": 102.159,
        "duration": 2.881,
        "text": "structure of that table we want to do"
      },
      {
        "start": 103.6,
        "duration": 3.199,
        "text": "something to modify"
      },
      {
        "start": 105.04,
        "duration": 3.52,
        "text": "still picking from within the partition"
      },
      {
        "start": 106.799,
        "duration": 4.401,
        "text": "key and the clustering keys"
      },
      {
        "start": 108.56,
        "duration": 4.16,
        "text": "then span by is the thing we want let me"
      },
      {
        "start": 111.2,
        "duration": 2.48,
        "text": "stress again that these only work as"
      },
      {
        "start": 112.72,
        "duration": 3.039,
        "text": "optimization"
      },
      {
        "start": 113.68,
        "duration": 3.68,
        "text": "when we're grouping by columns that are"
      },
      {
        "start": 115.759,
        "duration": 4.64,
        "text": "a part of the partition key"
      },
      {
        "start": 117.36,
        "duration": 5.039,
        "text": "or our clustering keys we can't do this"
      },
      {
        "start": 120.399,
        "duration": 3.121,
        "text": "to group by arbitrary columns because"
      },
      {
        "start": 122.399,
        "duration": 2.801,
        "text": "then it wouldn't be a cassandra"
      },
      {
        "start": 123.52,
        "duration": 2.4,
        "text": "optimization because cassandra doesn't"
      },
      {
        "start": 125.2,
        "duration": 2.48,
        "text": "do that"
      },
      {
        "start": 125.92,
        "duration": 3.6,
        "text": "if you have to do that you can still"
      },
      {
        "start": 127.68,
        "duration": 2.799,
        "text": "group by key on any column in your"
      },
      {
        "start": 129.52,
        "duration": 2.96,
        "text": "cassandra query"
      },
      {
        "start": 130.479,
        "duration": 3.041,
        "text": "but then it will be spark doing that in"
      },
      {
        "start": 132.48,
        "duration": 2.56,
        "text": "the normal way"
      },
      {
        "start": 133.52,
        "duration": 4.16,
        "text": "so when you want to group by things that"
      },
      {
        "start": 135.04,
        "duration": 5.04,
        "text": "are cassandra primary key columns"
      },
      {
        "start": 137.68,
        "duration": 3.76,
        "text": "use the optimized methods and that work"
      },
      {
        "start": 140.08,
        "duration": 3.12,
        "text": "gets done in cassandra"
      },
      {
        "start": 141.44,
        "duration": 3.76,
        "text": "rather than in spark let's take a look"
      },
      {
        "start": 143.2,
        "duration": 2.8,
        "text": "at the code for a couple of different"
      },
      {
        "start": 145.2,
        "duration": 2.96,
        "text": "solutions"
      },
      {
        "start": 146.0,
        "duration": 3.52,
        "text": "here we have the same query getting"
      },
      {
        "start": 148.16,
        "duration": 3.84,
        "text": "actor release here and title"
      },
      {
        "start": 149.52,
        "duration": 4.32,
        "text": "from movies by actor we have the same"
      },
      {
        "start": 152.0,
        "duration": 3.28,
        "text": "key structure on the third line making"
      },
      {
        "start": 153.84,
        "duration": 3.92,
        "text": "actor and year the key"
      },
      {
        "start": 155.28,
        "duration": 3.36,
        "text": "and title the value and then we call"
      },
      {
        "start": 157.76,
        "duration": 2.8,
        "text": "span by"
      },
      {
        "start": 158.64,
        "duration": 3.92,
        "text": "key that's going to do the same thing as"
      },
      {
        "start": 160.56,
        "duration": 2.56,
        "text": "group by key would have it's going to"
      },
      {
        "start": 162.56,
        "duration": 3.92,
        "text": "make"
      },
      {
        "start": 163.12,
        "duration": 5.68,
        "text": "actor and release here the key and"
      },
      {
        "start": 166.48,
        "duration": 4.16,
        "text": "then a collection of titles will be the"
      },
      {
        "start": 168.8,
        "duration": 3.12,
        "text": "value you can see that down in the"
      },
      {
        "start": 170.64,
        "duration": 2.72,
        "text": "sample output below"
      },
      {
        "start": 171.92,
        "duration": 3.039,
        "text": "in the second example we do something"
      },
      {
        "start": 173.36,
        "duration": 4.08,
        "text": "similar but we use"
      },
      {
        "start": 174.959,
        "duration": 4.161,
        "text": "span by instead same query where we"
      },
      {
        "start": 177.44,
        "duration": 2.96,
        "text": "select actor release here and title from"
      },
      {
        "start": 179.12,
        "duration": 4.08,
        "text": "movies by actor"
      },
      {
        "start": 180.4,
        "duration": 3.6,
        "text": "but then we call span by and we say we"
      },
      {
        "start": 183.2,
        "duration": 3.92,
        "text": "want the key"
      },
      {
        "start": 184.0,
        "duration": 3.44,
        "text": "to be actor and year you'll notice that"
      },
      {
        "start": 187.12,
        "duration": 2.16,
        "text": "the"
      },
      {
        "start": 187.44,
        "duration": 3.84,
        "text": "output is different i'll go ahead and"
      },
      {
        "start": 189.28,
        "duration": 3.36,
        "text": "flip back quickly to the output we saw"
      },
      {
        "start": 191.28,
        "duration": 4.48,
        "text": "in the previous example"
      },
      {
        "start": 192.64,
        "duration": 5.36,
        "text": "where the key was simply a list of"
      },
      {
        "start": 195.76,
        "duration": 4.08,
        "text": "the values we see the tourist and alice"
      },
      {
        "start": 198.0,
        "duration": 3.68,
        "text": "in wonderland in 2010"
      },
      {
        "start": 199.84,
        "duration": 3.679,
        "text": "into the woods transcendence and tusk in"
      },
      {
        "start": 201.68,
        "duration": 5.199,
        "text": "2014. now we see"
      },
      {
        "start": 203.519,
        "duration": 5.761,
        "text": "those same things in the data here"
      },
      {
        "start": 206.879,
        "duration": 3.841,
        "text": "but all of the columns including the key"
      },
      {
        "start": 209.28,
        "duration": 3.12,
        "text": "columns in the output"
      },
      {
        "start": 210.72,
        "duration": 3.68,
        "text": "just a detail in the implementation of"
      },
      {
        "start": 212.4,
        "duration": 11.199,
        "text": "those two things that's a good idea to"
      },
      {
        "start": 214.4,
        "duration": 9.199,
        "text": "keep your eye on"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:29:28.626268+00:00"
}