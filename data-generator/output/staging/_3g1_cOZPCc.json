{
  "video_id": "_3g1_cOZPCc",
  "title": "Build Production GenAI Chat with Vertex ai, LangChain and Astra DB Vector Search",
  "description": "How can you build LLM based Gen AI apps with your own production customer data? \n\nJoin Google Cloud, LangChain and DataStax in this deep-dive into Generative AI agent architecture.  We’ll build an enterprise customer service chatbot that uses Vertex.ai embedding and RAG (Retrieval Augmented Generation) with LangChain and Astra DB vector search.   \n\nWe demo and discuss: \nCreating memory for LLMs with Vertex AI embeddings and Astra vector search\nBest practices for data pre-processing and chunking documentation for vectors\nReal-world Prompt Engineering and testing for Production AI apps? \nThinking through security and data protection  \n\nResources:\n--Sign up for Astra DB: https://astra.datastax.com/signup\n--Colab: https://colab.research.google.com/drive/1T4GnfRaMX5BijlnQp-hqRp38-FO926UQ#scrollTo=23REe3Z91Tjl\n--LangChain - Unstructured URL Loader: https://integrations.langchain.com/?integration_name=UnstructuredURLLoader\n--Deconstructing RAG: https://blog.langchain.dev/deconstructing-rag/\n\n\nAbout DataStax:\nDataStax is the company behind the massively scalable, highly available, cloud-native NoSQL data platform built on Apache Cassandra™. DataStax gives developers and enterprises the freedom to run data in any cloud, Kubernetes, hybrid or bare metal at global scale with zero downtime and zero lock-in. More than 450 of the world’s leading enterprises including Capital One, Cisco, Comcast, Delta Airlines, Macy’s, McDonald’s, Safeway, Sony, and Walmart use DataStax to build transformational data architectures for real-world outcomes. For more, visit DataStax.com and @DataStax.\n\nAbout DataStax Developer:\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache Cassandra©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2023-12-22T18:08:33Z",
  "thumbnail": "https://i.ytimg.com/vi/_3g1_cOZPCc/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "scalable",
    "demo",
    "workshop",
    "cassandra",
    "search",
    "tutorial",
    "apache_cassandra",
    "vector",
    "nosql",
    "astra",
    "architecture",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=_3g1_cOZPCc",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "everyone for joining we've got a super exciting session today where we'll talk through how to build MTI apps with protic AI and our friend of Lan chain um so before we get started a little bit of housekeeping um on the right hand side of the screen you'll see an area to ask questions in chat um at the very end we'll save 15 minutes to answer any of your questions the police keep asking them we'll answer all them at the very end um this session will be recorded we'll send out the recording to everyone who registered I'm so no need to ask for the recording we'll happily share that and this session is 45 minutes um so we have about 30 minutes 30 minutes of content um and 15 minutes for questions um so very excited to get going awesome um so agenda for today um Yi will talk through the basics of rag right what is rag why is it important um what's rag versus multimodal rag um we'll discuss the unique opportunity ities and challenges with multimodal rag um we'll do a demo of how to build a basic rag app with vertex Ling chain in ASB um we'll discuss um things to think about before you deploy a multim rag after production and then we'll have plenty of time to answer any questions um so to kick it off um yumy it'd be great if we could do a quick round of intros thei so my name is yummy fak I work for Google cloud and I'm part of the global partner engineering team uh Google we have um Center of Excellence that deals primarily with AI and ml um and obviously throughout this year I know folks have been talking about generative AI so I work with data stacks on um we leverage uh Google Cloud technology for generative AI solution pleas to meet you all yep um I'm Lance I'm one of the software engineers at Lang chain I've been at Lang chain um for about six months now um I work a lot in the open source library and some work on Langs Smith which is kind of our our platform for observability and monitoring uh I've done quite a bit of work on multimodal rag recently uh so looking forward to the discussion and I'm Alex um I'm on the datax team focused on Partner Integrations I'm working with folks like YY and L um so YY I'll let you take it away and talk a little bit about the basics of rag yeah I mean as I kind of mention it alone I mean a lot of folks now it's all about generative AI we know these models are trained on a large cpose of data but obviously what we also know is that you know they only as aware of the information that they were trained on uh we know that um chances are even if you are using some of these Foundation models right they're not really trained on the specific business information that you have within your Enterprise and you know they don't necessarily have real time um access to information that you maybe need uh for the some of the use cases that you're trying to solve for so the the the key piece is you know as as part of that workflow of um solving that that use case you want to be able to get access to real time information when you need it so you can create the relevant context that you can then use for that gen task and really what you see there is just a schematic of um how that works you know you need to create embeddings because we right now we're talking about doing semantic search to get those um uh um responses you then use to then drive the Gen task whether it's summarization Q&A um creativity whatever that gen task is and then obviously with this um uh seminar webinar that we're doing uh you know we have the embeddings that you create Vector search which um data Stacks have an astro TV that you can use to store those embeddings you can then use that at run time uh to to search and get the responses and then obviously send the the actual contact itself to the llm uh to get your final answer and then on down there is a link that that you folks can click on that will give you um access to a Blog and I think there's probably some notebooks out there as well and how you use you know things like data Stacks lank chain and some of the offerings we have at Google Cloud to implement your rag use case next slide please Alex so I think I've covered a little bit of this so why you know why why Rag and why it's basically I talked about the hallucinations right um it's just reducing hallucination leveraging your Enterprise data that I talked about and also if you're doing you know some folks would say okay you can do a supervised tuning well there's a there's an expense to that right and and it's not even Dynamic information there's only so much you can tune at any point in time even when you tune you tune to a certain period in time so that's why it's also cost effective and it doesn't Inc some of those expensive um training that you would do if you were supervised tun in a land language model and and just to the summary there is just retrieving factual information from data stacks data store in this case data stacks and then using that as part your prompt to send into the language model to then get that final answer from to over to you Alex awesome um so we talk through some of the basics of rag um I I'd love your guys thoughts on what we what folks should think about um you know what are the unique opportunities and challenges of moving from rag to multi to multimodal rag um Lance it' be great to get your thoughts first yeah oh one of the most important things I've found when think about multimodal rag is how are you indexing the images and there's kind of two major approaches one is use multimodal embeddings the other is do something like image captioning like summarize every image and then just embed those text summaries and retrieve based on text similarity so again in most these applications you're trying to kind of start with a question retrieve an image based on that question and then answer the question using the image and that retrieval step can use one of those two approaches um there may be a diagram of those two here in the slides um I'm not sure if that was added which is fine if it's not uh but just in words those are kind of the two major threads and there's a bunch of trade-offs between those which we could talk about but maybe I'll I'll leave it there to to kind of get your reaction that makes sense and I think we'll look at that diagram a little bit later and I guess what have you seen with how does multimodal rag work with more complex images um are there is is it more difficult to embed more complex images how how do you how does that work performance F yeah yes so I've done some benchmarking on this so maybe the way I think about it is this what kinds of content do you want to work with I've done some demos with multimodal rag over like slide decks which are like figures tables very dense very kind of dense images what I've observed is that multimodal embeddings do not do particularly well there for example like I have one demo that's like a an investor presentation slide deck that has lots of similar quantitative slides if you ask a very particular quantitative question that requires retrieval of like one particular slide with a table multimodal embeddings won't necessarily be able to like easily differentiate between two different tables but the text captioning is very good at that from what I've seen text caption can give you here's a summary of the table here's what's in it and then when you do retrieval you can pretty effectively retrieve the right table given the question however multimod embeddings are very good if you have like lots of just like semantically differentiated objects um photos things like that so I think the the differences in approach depend a lot on the kinds of images that you want to be able to retrieve and I have found that for like dense content tables graphs figures like R rag over slide decks for example uh captioning is actually from what I've seen a lot better now of course I've only used open clip multimodel embeddings uh I think there are indeed better embedding models vertex I'm actually very curious to play with um and of course if open a I were to release multimodal embedding I'm sure could be very very good but from what I've seen currently captioning is really good for things that are kind of very dense images that are not that easily retrieved using kind of a multimodal edting space that makes sense and YY did you have any thoughts here yeah probably just double click on some of the challenges I mean I think yes unique challenges but it's I don't know if it's just applicable to mul to mod rag you still have the as Lance talked about the different images right you still have the challenges of of making sure when you're creating your indexes you're creating indexes with the right um similar set of images and the right indexes so when you're doing searches you still have the challenges now that you're dealing with images which meet even larger um bites of data you still have the challenges of you know do I have a an historical index versus a realtime index or more frequent index how do I partition my indexes what's my reindexing strategy we'll talk a little bit about that when we you know talk about some of the some of the production aspects of taking the r to production but you still some of those challenges but um then going back to what Lance said about um captioning and doing the the the actual multimodel embeddings I think folks know I think it was on the 13th where we announced Gemini and Gemini provision Gemini PR and Gemini provision and Gemini provision allows you to do um obviously create uh text from text from image or text from video we also have um our multimodel embeddings as well that you can use to create those text and image embeddings and store them in a vector database like um Astra so so we have that and and I think um with the tooling that we have the folks on the call should be able to take those images create the multim embeddings that they want create the caption from those Abed using something like a Gemini provision that allows you to get a text from image and then use that to drive the the semantic search when they send in those are prompt um to get the responses to to what the the customers are trying to ask for using images or even using text as the prompt okay absolutely and and we'll give a good demo of that exact where F in a little bit um so Lance and one other question for you so so Lance you touched a little bit on um you're seeing users in the wild use multimodal to do Q&A over PDFs um what other kind of Enterprise use cases have you guys seen so far I know it's super early so it is a little bit early I actually will be honest and say that if I look for example like if you go by Twitter activity I have not seen as much related to multimodal rag in like the Twitter Sphere not that that really necessarily matters um what I have heard from talking to companies is slide decks are a really good use case companies have lots of slides they tend to be visual um documents are an interesting one there are definitely many cases of documents that contain a mixture of text and images and I think that is also of Interest I think kind of slidex and presentation is probably of highest interest because it's so obvious that it's a very kind of good visual kind of QA use case that's Enterprise relevant um and I I think kind of uh multimodal rag on like mixed documents of images and text is is also of Interest there's a lot of good use cases we've done a little bit on this with like extraction so like extracting and this is a classic task of kind of ocrs obviously done this for a very long time but like kind of extracting extraction of important properties from images like that could be like tables forms so that's obviously a really big area but it's like not new at all um and that remains of interest from what I've seen I haven't done careful benchmarking on OCR in particular but I will say when I've seen the multimodel the high the the high the close Source highly performed multimodel models like Gemini gbd4 V are very strong at kind of extraction from from tables uh so I think that's another good use case so I would say like multimodal rag for like slide decks definitely interesting use case for mixed mix type documents definitely interesting extraction is another really good one classic task been around for a while I would say those three are like three that really come to mind um but I yeah those are the three I've really seen But curious you have y you've seen others as well or Alex you you as well yeah I mean I'll I'll double it down on the extraction piece um so think about extracting text from images for example you might have folks that maybe just draw out what a form could look like what a UI could look like and you can upload that to something like a Gemini provision and say create the HTML for this image you know something like that right and then even if you if the um the system understands the language understands your your structure of your HTML within your own platform it it can actually create it to that structure so it's almost executable so that's that's an example of extract text from images you can do things like Q&A images um you said you can do things like um taking an image and then converting to Json so you can do follow on postprocessing maybe you take an image and you write a story from an image for example depending on what what um platform you're trying to build for so for example a marketing platform that's probably writing a Blog writing a you know a Twitter feed something something like that they can just put an image on and then the marketer can say write me a story based on this image and they can use that as a starting point to actually create the um the material that they want to publishes right then also I think we talked about images as well but there's also video as well you know can you create an ad copy from a video can you do Q&A on a video those are some of the things that you can do with gini provision you know can you even describe this video content and use that data to do some f postprocessing and a lot of these sample prompts that we have on vertex AI that folks can look at to actually get started and then obviously taking that they can build on top of that for their own particular use case okay Lance I think this is the diagram you mentioned you're for too earlier walk through this yeah this this is the diagram that I was referencing and this is just showing at least the two approaches that I've kind of used and seen pretty commonly again we don't need to belabor it but yeah multimodal embeddings is one approach vertex is really good option here the other is this like image captioning idea where you take every image you summarize it you index then those text summaries which is easy right you can use any text embedding you want link every text like cap embedded caption to the raw image retrieve based on the the text embeddings U that capture the captions but then return the raw images to the llm in the end for final synthesis that those are kind of the two approaches I've seen and I kind of spoke to the tradeoffs we can talk about it more later if there's more interest awesome and the demo we're about to show we'll walk through kind of this first approach that that Lance is showing here cool so I thought that was super interesting now we are going to walk you through just a basic demo of how you can build a multimetal rag app with for L chain um but before we get into it um we're just going to quickly walk through the architecture um so there are really two processes here um to think about the first process is the data ingestion process that's number one at the very top right I said before you can build a multimodal rag app um you need to process all your your content right so to do this you take all your documents all your images all your videos you feed them into the vertex AI embedding model and this will output uh an embedding right an embedding is just a numerical representation of the text image all that um and then you're storing this in a database that's designed to store vectors like as um so once you've done that um you're ready for the to build your rag app right and and the the other kind of core process is the query process right so user can then ask you question like what is this image um show me related images um we convert the user's question to an embedding again um and then we query the vector store to pull kind of the related content and feed this relevant content to the L um to then get a better response um so I'll walk through exactly how this works with code um so uh if you haven't seen it already we've shared this link on the right hand side of chat um so you can play with this notebook as well so this really is just a really basic app um where we show you how to use Gemini linkchain and rag to get Astra together building a rag app I'm so the first couple steps here just walking you through how to create the necessary credentials right you'll need an asure account we have links on the right to create an account once you've created your asra account you'll need to create a vector database um in poll some credentials we show you exactly where to pull them here um once you've done that right you'll also need to create a gcp account and and uh vertex AI enable the vertex AI API and pull your project ID this is super simple both these accounts start with free credit you can get started in minutes um there's some basic installation of the dependencies necessary for the project um here we're using here you can see we're installing rag stack and the Google Cloud AI platform Reep includes linkchain um we do some basic loading of credentials as environment variables um we do some basic configuration of the Google Cloud API and now we get into the interesting part um so uh my cooworker Scott sent just kind of this random picture of his uh espresso machine I'm just to sort of test how Gemini Pro works um this really was just kind of a random image we didn't know if it's going to work or not but it it worked really well we turned into this webinar content um so here's just kind of the a random part to this Express a machine and um we asked Gemini provision what is this image right you'll notice here um we're using Lane chain to interact with Gemini Pro um Lane chain makes it super easy to um interact with with all these models and the prompt here is what is this image share link to purchase replacement and was we were super impressed um ji provision was able to identify the exact model of the coffee machine and a link to purchaser replacement so as kind of YY mentioned before the LLS are trained right in the past they don't have access to realtime data so the only issue here is you know Amazon is constantly changing their links so this link here is out of date right so perfect use case for rag as kind of mentioned before um so here's the example of interacting with the Gemini provision model without rack I'm still like insanely impressive very cool I recommend you give a shot I'm so now we've done now we're sort of getting into the data ingestion process we took a parts catalog from uh breel right the maker of the espresso machine um we've done all the scraping for you so you don't need to do so um we take all these parts all these URLs um we embed them using the vertex AI Gemini multimodal embedding model um we feed them into astb right something important to to note here is um astb supports both Vector data and tabular data right so I can store my Vector embeddings generated from vertex Ai and I can also store raw information like name and price the URL here we're doing some basic loading and then we get into the Super interesting part so this is the actual example of multim rag with link chain and Gemini right so this looks very similar to the example above but this time in addition to asking what the item is and where to purchase it a replacement we feed the real time the product catalog that we the scripts right and because we've injected this relevant information from our ASB Vector store we get just a much more precise answer right um Gemini cision is able to identify the exact part it's able to share details it's able to share the price um and information on exactly where to to purchase um so really cool stuff really really simple to get started with Lang chain and verx AI um definitely give this a shot we're happy to answer any questions if you have a more sophisticated use case we're also happy to help you build that out um and we'll we'll we'll go on to the next item um so we've shown this example right you know you let's say you're now sold on using brag you're now sold on multimodal rag um what are the sort of things you should think about before deploying a rag application to production um maybe it'd be great if you keep this one your thoughts yeah I think one very important consideration for production well there there's maybe a few things what we've done in a lot of our kind of demos is is quite a bit of work on evaluation so you need some way to actually Benchmark performance before you actually ship something of course um we so so Lang chain has a platform called lsmith which is pretty useful for this and there's a bunch of resources that we can share on this topic um but it does allow you to kind of build evaluation sets pretty easily and then test your so say you in fact we did this with kind of comparing those two different multimodal rag approaches um and you can very easily kind of test your different rag change against your eval set and kind of build intuition about which approach is better or worse and I think this is obviously you know pretty fundamental but very important before you you know ship anything to production so I think that that's consideration one kind of the ability to run evaluations and kind of build an evaluation set that that's kind of obvious like table Stakes consideration two is cost so I would say that for the for the captioning approach one push back I've heard from people which is a very valid point is like well you have to produce these image captions for your whole kind of ppose that could be very expensive I completely agree with that concern I've become pretty interested in in potentially open open source llms to do this so there's a few there's lava uh fuyu out there um baklava so there's kind of a series of of Open Source that could be free to use multimodal LMS that you could do the captioning with and then still use a more higher powerered you know multimodal LM like Gemini in your application and production so I think that's another interesting point what's the cost of your of of the approach you're taking making for indexing uh and the captioning approach indeed could be quite a bit more costly because you're generating an IM an image caption or summary across your Corpus um so I think those are two important considerations cost of indexing uh kind of evaluation um other considerations in production are like just monitoring so like how's your app going where is it going haywire or when you getting bad responses Langs Smith is pretty useful for this um we have lots of tracing functionality so you can kind kind of go back you can look at every generation by your model in production you can inspect kind of outputs that don't meet your expectation you can build eal sets from it um and we have a bunch of documentation there as well so I would say yeah like in short um evaluation to start to gate what you're actually going to ship thinking about the cost of indexing for your decision um and maybe finding ways to mitigate the cost with open source llms for captioning uh and then three kind of monitoring up in production lsmith obviously has has kind of features for that as well I think those are the big three I would highlight but yeah cous get your guys take yeah I'll go next yeah plus 100 to the uh the three areas that Lun just highlighted what I'll probably out to that is I'll probably I'll start with edings management right we're creating embeddings we got to store them somewhere you know this Version Control we know you know as folks release new embeddings they get better at um creating embeddings faster creating embeddings but what does that mean for upgrades I think right now there still a challenge around backward compatibility so how do you maintain Version Control and make sure that as you're Building Solutions and you you upgrading the latest embedding models you still make sure that the embeddings you created are still working or do you do old migration which to Lance Point could be a cost challenge because folks have you know millions of data that they create embed out of and if you do the math on that you know that may be cost prohibitive for you to do a migration of embeddings when you when you have take a new version embedding so Version Control and upgr is important also multilingual a lot of the stuff we do we do in English but we got to recognize there are people in other parts of the world that want it in their own local language so what does that mean is that multilingual versus English only do we use a multilingual a bedding if we know that it create it Cates for that 10 different languages that we look for and it's maybe good at English or do we say okay we only do it English only so let's use an English embedding because that's what it's good at so those are some of the considerations that we we need to to look into and I think I talked about indexing and reindexing and strategies you know as you get new information are you partitioning your indexes such that you you you're reducing the amount of indexing that you're doing and reducing the cost of creating those indexing those are some of the things you need to look for on inen management as you build this application there's one thing building an application but you also have to maintain it and and and and and care and feed for it going forward um for for your customers then the other piece as well is the non-functional requirements what do I mean by that security there's a lot of challenges around data residency you know having been able to store data arrest you know so being able to call Regional URL whether it's in North America Europe or Asia pack and know that the data you the embeddings you created are stored in that location and they not going to a different part of the of of the world been been able to do that there's also uh encryption keys with our service we always encrypt by default we have Google U manage encryption keys but customers might want their own encryption keys keys for example in regulated Industries like Finance Healthcare where they want to have their own AC key so we support that with custom manage encryption Keys uh there's also the networking aspect of it you know I don't want this thing to be public facing I'm still being I mean even it's a gen application I'm still building an application within my Enterprise so I've got to be able to apply things like VPC controls and service controls to make sure there is no data going out to make sure there is no unauthorized access to make sure I'm protecting I'm building a perimeter around J resources and protecting them accordingly and then access transparency who has access to my system you know what kind of audit logs I might collecting if someone is fixing for example Google cloud is is um uh you know supporting respons support ticket what dat are they looking at to to uh resolve that issue for me access transparency is also a key one there as well then um when you look at uh you know production development to production how do you get to you've done a lot of development you you know Lance mention all of tools that you can use as part your development life cycle to make sure what you're building is f for purpose and you can obviously continually Monitor and manage it as you go forward but how do you migrate from uh you know your PC your development to production what is that test to production system that's where some of the tooling that Lance mentioned around LMI Astro DB having been able to create your development environment been able to load your data migrate your environment as you go to production having different um environments for your vertex able to OTE your uh your your um your code as well that's where you need to think about your what does your sdlc life cycle look like when you're building this gen apps and then one other final thing I mention is things around service terms you know we talked about images we talked about embeddings this language models are trained on data the provider that you're using how are you being indemnified on the output that you're generating from this language models do they provide the right level of Indemnity so that you can make sure that if you're using whether you're using text embeddings or multimodal whether you doing Q&A to get those captions you know whether you actually creating images as well you know are you indemnified and those are some of the stuff that Google Cloud we do with with emif service terms so I think I'll leave it at that um hopefully that helped some of the folks deploying looking to deploy rag into production okay it was super helpful and I'll just add um so we at datax run a production chat bot that uses Gemini um in production and really agree with lots of the points brought up what's been really important for us is um the testing aspect that Lance talked about right like making sure we get um the right responses from the LMS for commonly asked questions um and also you know yeah you talked a little bit about the software development life cycle right it's been super important um to really make sure we're we're using kind of the standard software development like life cycle with our prompts right so um we store all the versions of our prompts in in version control right so we can use to kind of you know measure keep track of kind of what's changed as we improve our body um so awesome guys that was really great I I think now we'll get into um questions okay cool um so first question um in the demo I noce you use Gemini provision is there any reason you couldn't use just Gemini Pro I'm see I mean that's probably a good question for you I guess what is the difference between yeah so so Gemini um Pro is more of a text um Foundation model I think what you saw in the demo was um Alex uploaded an image of a coffee filter I think and then uh you know ask questions of the and then then and then U was doing multim model so that's why he's using Gemini provision because that's what gem prision does it allows you to do things like text from image and text from video is the reason why it's doing that okay got it and you talked a little bit about um support from M engages does Gemini support uh multilanguage embeddings I I can't remember well the the the multilanguage embeddings comes from you using the the the API from and we have a multimodal embeddings API we also have an English only API uh and the I think the multimod embedding supports foreign languages and there's a P online there's there's at least maybe about 10 or so languages you have to look at the page but there's there's multiple languages that we support um with the multimod embeddings yeah got it very cool um what is the difference between Lang chain and Lang Smith that's probably a good question for you yeah so Lang chain is a an open source Library package that has support for JS as well as python uh that's kind of like a application development framework for llms and it integrates with like 700 different components astb being one uh different embedding models vertex for example like that PR is in progress right now um so um Lang chain is kind of like an open source app development framework that you can use to Stitch things together to build different LM applications lsmith is kind of an observability tool that does time with Lang chain but does not require Lang chain and lsmith basically allows for monitoring evaluation uh so in particular uh when you have an application uh it you can use it to monitor all the traces so like every time the LM is run what goes in what goes out what's called if you have like a complex chain every cheap in the St every step in the chain every input output from each step so it's um it's a very nice tool for what we call kind of monitoring and observability um it has a few other things supports valuations as mentioned it supports kind of building data sets um but that that's kind of Lang Smith so it it pairs very well with Lang chain but you actually don't need to use Lang chain in order to use Langs Smith makes sense um YY there was another question on Gemini I'm curious when there will be a way to load PDFs directly in the Gemini without the need to split documents into pages and load these Pages as images yeah so that may come when you have um supervised tuning of Gemini provision uh you know you know cuz right right now if you tune in a model right you typically have to create the JNL format which means chunking the data and all that stuff but I think the question is probably looking at when you will be able to supervise tune uh a a Gemini provision for example yeah and so so that when that comes that that would be probably when um folks able to do something like that got it and um Lance I gu question for you so we heavily use the um link CH recursive text splitter for for like text chunking is there any sort of text splitting functionality in linke chain for images or is that something you guys have thought about interesting what do you mean by that how do you think about like split what do you mean by splitting images I guess this kind of question here is there a way to does Ling Chan have a way to break a PDF into multiple pages okay so good point uh so yeah in in in a lot My Demo FS I we've not done integration but there are a number of different packages out there that take a PDF and split into a bunch of images uh I can look up what I use I think it's a uh let me check my code here L right now um we use um check the injust script here um [Music] um maybe go to the next question I will find it uh sounds good um what is the process to migrate from um Google models like text Bon to Gemini I can take that one actually um so we actually just did this at data tax for one of our production chat Bots um with tools like Lane chain it's very very simple to migrate models um it was as simple as kind of just switching the the model name and um like we were up and running very very quickly and I don't know if there's a there's a way to post links on the um on but there is a actual page that's TI entitled titled migrate from pal API to Gemini API on Vex AI so if you go online and just perhaps just put that search in Google it no pun inet you should you should land that page that gives you instructions and I think there's probably even code side by side code that shows you uh what changes are between pal and Gemini so yeah that's what there on the public Ducks yeah one F on the prior question look at pdfium that's one if you just Google there's a bunch of them but basically going from a PDF to a bunch of images there's a bunch of good stuff out there we haven't actually integrated with Lang chain it seems like kind of just like an unnecessary wrapper around like a very simple to use component although you know maybe it is worth just pulling it in so it's there's some consistency around how you call it um yeah that's one I use awesome cool um well that was all of the questions um thank you everyone oh actually one more just came in sorry are there any plans on Gemini timeline for assistance like opening eye has with that with Astro DB it would be interesting uh for assistance um I is um are there any plans for um Gemini to build some sort of kind of easy way to build assistance like uh open AI recently released this assistance API which is sort of like a very easy to configure kind of chatbot type thing I think the closest thing to what Google is doing is um like the vertex AI search um yeah no yeah so I get it I get it so we we have something called uh verix AI uh conversation conversation AI which if some of the folks are familiar you know they they used to read they still is a solution called dialog flow so the evolution of that um adding gen to that is now called conversation AI so that's a solution for building kind of a Enterprise grade chat Bots uh you know if you wanted a a manage Solution that's already got a lot of the bells and whistles and you just need to customize it maybe do some extensions for your particular use case then you can use that conversational AI um solution and and I think there'll be there probably notebooks out there that show you how to um build applications around there but but also recognize that the language model themselves also support the chat interface so you can use something like um and I think you use that in your code right you can use something like the Lang chain chat apis to make a call to the language model and then kind of have that multi-tone conversation going around your use case because most most likely if you're building chat you're probably going to embed into some kind of UI within your prise so you've got those options either you kind of um white label a conversational Ai and search solution if you looking for manage solution but if you think you want to roll your own then you can use something like Lan chain you can use our API course for a language model and kind of use our chat Foundation models and then you know kind of roll your own mul toone conversation around the chat application yeah awesome we actually just got a lot more questions also um this one is for you Lance do you this will be a fun question do you find it's a performance question do you find Lane chain to be slower for executing similar steps compared to custom code I haven't actually tested latency Lang Chain versus just like hitting raw for example open API so I can't honestly answer that um if if someone has links to documentation that's like looked into that I'd be curious It's not obvious to me that Lang chain add significant latency I think the bigger question is kind of like the latency typically more comes from for example hitting Vector DBS what Vector DB integration you're using um that's kind of where I've seen or most of the latency comes from like the API itself so it's not clear that kind of having Lang chain in the middle really adds significant latency to to a chain uh it's really kind of the retrieval step as well as the um you know the the the language model API itself but if there's some interesting like feel free to put in the chat if there's interesting like references you've seen or any like posts on that I'd be curious to sorry excuse me and and the last question is what is the best way to learn fundamental concepts of rag pattern and components in rag pattern like Factory DBS embeddings and things like this for a regular software developer um yeah so we can pull together some good links and also follow up with this as well Google has a lot of content this um linkchain has a lot of good content on this we also created a bunch of content it's way easier than you think to start building brag Ops with some of the awesome technology available today okay cool um well thank you everyone I'm really apprciate Alex there was a I think there was a question on the Q&A some gentleman by the name of Katic first time ktic asked the question will you be covering ey level architecture for Enterprise gen I mean while we don't have a diagram showing that right I think some of the content that we covered there you know talking about the unique challenges talking about you know some of the things you need to look at when you're deploying uh a rag application into production hopefully that gave you some of the content that you can use to build an high Lev architecture for for Enterprise gen so you know hopefully we were able to cover some of the content for that while while we didn't have a diagram to show you on on a high level architecture okay over to you Alex oh we just got another question I should stop saying this is our last question do you have recommendations for capturing embeddings from existing web- based Assets in an automated way um I think both Google and blank chain have good Solutions um for this um y do you maybe want to say yeah that's a great great question because that was one of that was the use case I mentioned about extracting um text from images ex exactly that you can use the uh Gemini provision uh you know the apis that you can call um you can actually start by just taking one of those um uh UI and upload them and just say extract the fields from this image or create me an HTML from this image you know and and you can see the response that comes out and then once you have that and once you figure out what prompts you need to get the right level of detail you're looking for then you can then probably look at some some of the notebooks we have and actually use that to actually build out the to automate that process so most likely you have a bucket of images and then you just each through that and and get the caption and then store it somewhere so so yes you can do that with Gemini provision for sure and also you can do that with um I know this has been a lot about Gemini but also Imagine to which you can also do for visual Q&A as well and captioning that actually has a captioning functionality that you can also use know you can do that to the UI just to test it but also you can also use the apis through a notebook um in python or whatever language of choice you have to to automate the process as well L did you also have some thoughts I know um link chain does a really nice job of some of that with like the document loaders that integrate with like scraping tools yeah there there's a definitely a large number of document loaders I can share kind of our Integrations Hub um uh I'll share that right now um and there are a good number of different uh document loaders for web content for sure I shared that oh we got see we're capturing embeddings from existing web base assets and automated way yeah um I'll maybe highlight one or two uh you know structured URL loader is pretty good um I like that one I'll share that um what else yep that's good for now I think awesome um well looks like we're out of time um thank you everyone for joining we'll definitely share all these resources we mentioned afterwards um and if you have any questions um send them our way um we'll continue en those be email awesome thanks everyone thank you and bye",
    "segments": [
      {
        "start": 2.8,
        "duration": 3.559,
        "text": "everyone for joining we've got a super"
      },
      {
        "start": 4.799,
        "duration": 4.76,
        "text": "exciting session today where we'll talk"
      },
      {
        "start": 6.359,
        "duration": 5.561,
        "text": "through how to build MTI apps with"
      },
      {
        "start": 9.559,
        "duration": 4.28,
        "text": "protic AI and our friend of Lan chain um"
      },
      {
        "start": 11.92,
        "duration": 4.279,
        "text": "so before we get started a little bit of"
      },
      {
        "start": 13.839,
        "duration": 4.241,
        "text": "housekeeping um on the right hand side"
      },
      {
        "start": 16.199,
        "duration": 4.481,
        "text": "of the screen you'll see an area to ask"
      },
      {
        "start": 18.08,
        "duration": 4.439,
        "text": "questions in chat um at the very end"
      },
      {
        "start": 20.68,
        "duration": 3.839,
        "text": "we'll save 15 minutes to answer any of"
      },
      {
        "start": 22.519,
        "duration": 3.361,
        "text": "your questions the police keep asking"
      },
      {
        "start": 24.519,
        "duration": 4.201,
        "text": "them we'll answer all them at the very"
      },
      {
        "start": 25.88,
        "duration": 4.479,
        "text": "end um this session will be recorded"
      },
      {
        "start": 28.72,
        "duration": 3.559,
        "text": "we'll send out the recording to everyone"
      },
      {
        "start": 30.359,
        "duration": 4.241,
        "text": "who registered I'm so no need to ask for"
      },
      {
        "start": 32.279,
        "duration": 4.921,
        "text": "the recording we'll happily share that"
      },
      {
        "start": 34.6,
        "duration": 5.119,
        "text": "and this session is 45 minutes um so we"
      },
      {
        "start": 37.2,
        "duration": 5.64,
        "text": "have about 30 minutes 30 minutes of"
      },
      {
        "start": 39.719,
        "duration": 5.761,
        "text": "content um and 15 minutes for questions"
      },
      {
        "start": 42.84,
        "duration": 6.559,
        "text": "um so very excited to get"
      },
      {
        "start": 45.48,
        "duration": 7.0,
        "text": "going awesome um so agenda for today um"
      },
      {
        "start": 49.399,
        "duration": 5.84,
        "text": "Yi will talk through the basics of rag"
      },
      {
        "start": 52.48,
        "duration": 5.239,
        "text": "right what is rag why is it important um"
      },
      {
        "start": 55.239,
        "duration": 4.761,
        "text": "what's rag versus multimodal rag um"
      },
      {
        "start": 57.719,
        "duration": 5.16,
        "text": "we'll discuss the unique opportunity"
      },
      {
        "start": 60.0,
        "duration": 5.64,
        "text": "ities and challenges with multimodal rag"
      },
      {
        "start": 62.879,
        "duration": 6.161,
        "text": "um we'll do a demo of how to build a"
      },
      {
        "start": 65.64,
        "duration": 6.64,
        "text": "basic rag app with vertex Ling chain in"
      },
      {
        "start": 69.04,
        "duration": 5.32,
        "text": "ASB um we'll discuss um things to think"
      },
      {
        "start": 72.28,
        "duration": 4.68,
        "text": "about before you deploy a multim rag"
      },
      {
        "start": 74.36,
        "duration": 5.0,
        "text": "after production and then we'll have"
      },
      {
        "start": 76.96,
        "duration": 4.68,
        "text": "plenty of time to answer any questions"
      },
      {
        "start": 79.36,
        "duration": 5.88,
        "text": "um so to kick it off um yumy it'd be"
      },
      {
        "start": 81.64,
        "duration": 3.6,
        "text": "great if we could do a quick round of"
      },
      {
        "start": 86.479,
        "duration": 5.64,
        "text": "intros thei so my name is yummy fak I"
      },
      {
        "start": 90.159,
        "duration": 4.24,
        "text": "work for Google cloud and I'm part of"
      },
      {
        "start": 92.119,
        "duration": 4.801,
        "text": "the global partner engineering team uh"
      },
      {
        "start": 94.399,
        "duration": 5.201,
        "text": "Google we have um Center of Excellence"
      },
      {
        "start": 96.92,
        "duration": 4.36,
        "text": "that deals primarily with AI and ml um"
      },
      {
        "start": 99.6,
        "duration": 2.839,
        "text": "and obviously throughout this year I"
      },
      {
        "start": 101.28,
        "duration": 4.199,
        "text": "know folks have been talking about"
      },
      {
        "start": 102.439,
        "duration": 5.561,
        "text": "generative AI so I work with data stacks"
      },
      {
        "start": 105.479,
        "duration": 4.121,
        "text": "on um we leverage uh Google Cloud"
      },
      {
        "start": 108.0,
        "duration": 4.159,
        "text": "technology for generative AI solution"
      },
      {
        "start": 109.6,
        "duration": 5.92,
        "text": "pleas to meet you"
      },
      {
        "start": 112.159,
        "duration": 4.841,
        "text": "all yep um I'm Lance I'm one of the"
      },
      {
        "start": 115.52,
        "duration": 3.639,
        "text": "software engineers at Lang chain I've"
      },
      {
        "start": 117.0,
        "duration": 3.479,
        "text": "been at Lang chain um for about six"
      },
      {
        "start": 119.159,
        "duration": 2.681,
        "text": "months now"
      },
      {
        "start": 120.479,
        "duration": 3.92,
        "text": "um I work a lot in the open source"
      },
      {
        "start": 121.84,
        "duration": 4.04,
        "text": "library and some work on Langs Smith"
      },
      {
        "start": 124.399,
        "duration": 4.0,
        "text": "which is kind of our our platform for"
      },
      {
        "start": 125.88,
        "duration": 3.879,
        "text": "observability and monitoring uh I've"
      },
      {
        "start": 128.399,
        "duration": 3.641,
        "text": "done quite a bit of work on multimodal"
      },
      {
        "start": 129.759,
        "duration": 4.161,
        "text": "rag recently uh so looking forward to"
      },
      {
        "start": 132.04,
        "duration": 4.279,
        "text": "the"
      },
      {
        "start": 133.92,
        "duration": 4.64,
        "text": "discussion and I'm Alex um I'm on the"
      },
      {
        "start": 136.319,
        "duration": 4.64,
        "text": "datax team focused on Partner"
      },
      {
        "start": 138.56,
        "duration": 5.56,
        "text": "Integrations I'm working with folks like"
      },
      {
        "start": 140.959,
        "duration": 4.92,
        "text": "YY and L um so YY I'll let you take it"
      },
      {
        "start": 144.12,
        "duration": 3.68,
        "text": "away and talk a little bit about the"
      },
      {
        "start": 145.879,
        "duration": 4.521,
        "text": "basics of"
      },
      {
        "start": 147.8,
        "duration": 4.96,
        "text": "rag yeah I mean as I kind of mention it"
      },
      {
        "start": 150.4,
        "duration": 4.32,
        "text": "alone I mean a lot of folks now it's all"
      },
      {
        "start": 152.76,
        "duration": 5.52,
        "text": "about generative AI we know these models"
      },
      {
        "start": 154.72,
        "duration": 5.4,
        "text": "are trained on a large cpose of data but"
      },
      {
        "start": 158.28,
        "duration": 3.599,
        "text": "obviously what we also know is that you"
      },
      {
        "start": 160.12,
        "duration": 4.24,
        "text": "know they only as aware of the"
      },
      {
        "start": 161.879,
        "duration": 5.201,
        "text": "information that they were trained on uh"
      },
      {
        "start": 164.36,
        "duration": 4.28,
        "text": "we know that um chances are even if you"
      },
      {
        "start": 167.08,
        "duration": 3.239,
        "text": "are using some of these Foundation"
      },
      {
        "start": 168.64,
        "duration": 3.64,
        "text": "models right they're not really trained"
      },
      {
        "start": 170.319,
        "duration": 4.121,
        "text": "on the specific business information"
      },
      {
        "start": 172.28,
        "duration": 3.319,
        "text": "that you have within your Enterprise and"
      },
      {
        "start": 174.44,
        "duration": 3.28,
        "text": "you know they don't necessarily have"
      },
      {
        "start": 175.599,
        "duration": 4.36,
        "text": "real time um access to information that"
      },
      {
        "start": 177.72,
        "duration": 3.72,
        "text": "you maybe need uh for the some of the"
      },
      {
        "start": 179.959,
        "duration": 4.56,
        "text": "use cases that you're trying to solve"
      },
      {
        "start": 181.44,
        "duration": 5.84,
        "text": "for so the the the key piece is you know"
      },
      {
        "start": 184.519,
        "duration": 4.72,
        "text": "as as part of that workflow of um"
      },
      {
        "start": 187.28,
        "duration": 4.2,
        "text": "solving that that use case you want to"
      },
      {
        "start": 189.239,
        "duration": 4.64,
        "text": "be able to get access to real time"
      },
      {
        "start": 191.48,
        "duration": 4.52,
        "text": "information when you need it so you can"
      },
      {
        "start": 193.879,
        "duration": 4.681,
        "text": "create the relevant context that you can"
      },
      {
        "start": 196.0,
        "duration": 4.08,
        "text": "then use for that gen task and really"
      },
      {
        "start": 198.56,
        "duration": 4.039,
        "text": "what you see there is just a schematic"
      },
      {
        "start": 200.08,
        "duration": 4.239,
        "text": "of um how that works you know you need"
      },
      {
        "start": 202.599,
        "duration": 3.28,
        "text": "to create embeddings because we right"
      },
      {
        "start": 204.319,
        "duration": 5.56,
        "text": "now we're talking about doing semantic"
      },
      {
        "start": 205.879,
        "duration": 7.401,
        "text": "search to get those um uh um responses"
      },
      {
        "start": 209.879,
        "duration": 4.481,
        "text": "you then use to then drive the Gen task"
      },
      {
        "start": 213.28,
        "duration": 4.64,
        "text": "whether it's"
      },
      {
        "start": 214.36,
        "duration": 5.68,
        "text": "summarization Q&A um creativity whatever"
      },
      {
        "start": 217.92,
        "duration": 4.2,
        "text": "that gen task is and then obviously with"
      },
      {
        "start": 220.04,
        "duration": 4.479,
        "text": "this um uh seminar webinar that we're"
      },
      {
        "start": 222.12,
        "duration": 5.28,
        "text": "doing uh you know we have the embeddings"
      },
      {
        "start": 224.519,
        "duration": 4.481,
        "text": "that you create Vector search which um"
      },
      {
        "start": 227.4,
        "duration": 3.64,
        "text": "data Stacks have an astro TV that you"
      },
      {
        "start": 229.0,
        "duration": 4.92,
        "text": "can use to store those embeddings you"
      },
      {
        "start": 231.04,
        "duration": 4.559,
        "text": "can then use that at run time uh to to"
      },
      {
        "start": 233.92,
        "duration": 3.28,
        "text": "search and get the responses and then"
      },
      {
        "start": 235.599,
        "duration": 3.761,
        "text": "obviously send the the actual contact"
      },
      {
        "start": 237.2,
        "duration": 3.119,
        "text": "itself to the llm uh to get your final"
      },
      {
        "start": 239.36,
        "duration": 3.32,
        "text": "answer"
      },
      {
        "start": 240.319,
        "duration": 3.681,
        "text": "and then on down there is a link that"
      },
      {
        "start": 242.68,
        "duration": 3.479,
        "text": "that you folks can click on that will"
      },
      {
        "start": 244.0,
        "duration": 3.36,
        "text": "give you um access to a Blog and I think"
      },
      {
        "start": 246.159,
        "duration": 3.44,
        "text": "there's probably some notebooks out"
      },
      {
        "start": 247.36,
        "duration": 4.36,
        "text": "there as well and how you use you know"
      },
      {
        "start": 249.599,
        "duration": 3.321,
        "text": "things like data Stacks lank chain and"
      },
      {
        "start": 251.72,
        "duration": 3.599,
        "text": "some of the offerings we have at Google"
      },
      {
        "start": 252.92,
        "duration": 5.2,
        "text": "Cloud to implement your rag use case"
      },
      {
        "start": 255.319,
        "duration": 2.801,
        "text": "next slide please"
      },
      {
        "start": 258.6,
        "duration": 5.039,
        "text": "Alex so I think I've covered a little"
      },
      {
        "start": 260.799,
        "duration": 4.641,
        "text": "bit of this so why you know why why Rag"
      },
      {
        "start": 263.639,
        "duration": 4.0,
        "text": "and why it's basically I talked about"
      },
      {
        "start": 265.44,
        "duration": 4.16,
        "text": "the hallucinations right um it's just"
      },
      {
        "start": 267.639,
        "duration": 3.601,
        "text": "reducing hallucination leveraging your"
      },
      {
        "start": 269.6,
        "duration": 3.52,
        "text": "Enterprise data that I talked about and"
      },
      {
        "start": 271.24,
        "duration": 3.519,
        "text": "also if you're doing you know some folks"
      },
      {
        "start": 273.12,
        "duration": 3.519,
        "text": "would say okay you can do a supervised"
      },
      {
        "start": 274.759,
        "duration": 4.081,
        "text": "tuning well there's a there's an expense"
      },
      {
        "start": 276.639,
        "duration": 4.161,
        "text": "to that right and and it's not even"
      },
      {
        "start": 278.84,
        "duration": 4.16,
        "text": "Dynamic information there's only so much"
      },
      {
        "start": 280.8,
        "duration": 3.679,
        "text": "you can tune at any point in time even"
      },
      {
        "start": 283.0,
        "duration": 3.52,
        "text": "when you tune you tune to a certain"
      },
      {
        "start": 284.479,
        "duration": 3.681,
        "text": "period in time so that's why it's also"
      },
      {
        "start": 286.52,
        "duration": 3.88,
        "text": "cost effective and it doesn't Inc some"
      },
      {
        "start": 288.16,
        "duration": 3.879,
        "text": "of those expensive um training that you"
      },
      {
        "start": 290.4,
        "duration": 3.88,
        "text": "would do if you were supervised tun in a"
      },
      {
        "start": 292.039,
        "duration": 5.0,
        "text": "land language model and and just to the"
      },
      {
        "start": 294.28,
        "duration": 5.84,
        "text": "summary there is just retrieving factual"
      },
      {
        "start": 297.039,
        "duration": 5.16,
        "text": "information from data stacks data store"
      },
      {
        "start": 300.12,
        "duration": 4.04,
        "text": "in this case data stacks and then using"
      },
      {
        "start": 302.199,
        "duration": 3.521,
        "text": "that as part your prompt to send into"
      },
      {
        "start": 304.16,
        "duration": 5.879,
        "text": "the language model to then get that"
      },
      {
        "start": 305.72,
        "duration": 4.319,
        "text": "final answer from to over to you"
      },
      {
        "start": 311.039,
        "duration": 5.681,
        "text": "Alex awesome um so we talk through some"
      },
      {
        "start": 313.6,
        "duration": 5.36,
        "text": "of the basics of rag um I I'd love your"
      },
      {
        "start": 316.72,
        "duration": 4.44,
        "text": "guys thoughts on what we what folks"
      },
      {
        "start": 318.96,
        "duration": 3.88,
        "text": "should think about um you know what are"
      },
      {
        "start": 321.16,
        "duration": 3.56,
        "text": "the unique opportunities and challenges"
      },
      {
        "start": 322.84,
        "duration": 4.199,
        "text": "of moving from rag to multi to"
      },
      {
        "start": 324.72,
        "duration": 3.599,
        "text": "multimodal rag um Lance it' be great to"
      },
      {
        "start": 327.039,
        "duration": 5.521,
        "text": "get your thoughts"
      },
      {
        "start": 328.319,
        "duration": 6.0,
        "text": "first yeah oh one of the most important"
      },
      {
        "start": 332.56,
        "duration": 5.04,
        "text": "things I've found when think about"
      },
      {
        "start": 334.319,
        "duration": 7.0,
        "text": "multimodal rag is how are you indexing"
      },
      {
        "start": 337.6,
        "duration": 6.4,
        "text": "the images and there's kind of two major"
      },
      {
        "start": 341.319,
        "duration": 4.641,
        "text": "approaches one is use multimodal"
      },
      {
        "start": 344.0,
        "duration": 3.759,
        "text": "embeddings the other is do something"
      },
      {
        "start": 345.96,
        "duration": 3.48,
        "text": "like image captioning like summarize"
      },
      {
        "start": 347.759,
        "duration": 4.44,
        "text": "every image and then just embed those"
      },
      {
        "start": 349.44,
        "duration": 5.479,
        "text": "text summaries and retrieve based on"
      },
      {
        "start": 352.199,
        "duration": 4.201,
        "text": "text similarity so again in most these"
      },
      {
        "start": 354.919,
        "duration": 4.241,
        "text": "applications you're trying to kind of"
      },
      {
        "start": 356.4,
        "duration": 4.56,
        "text": "start with a question retrieve an image"
      },
      {
        "start": 359.16,
        "duration": 4.12,
        "text": "based on that question and then answer"
      },
      {
        "start": 360.96,
        "duration": 4.799,
        "text": "the question using the image and that"
      },
      {
        "start": 363.28,
        "duration": 4.96,
        "text": "retrieval step can use one of those two"
      },
      {
        "start": 365.759,
        "duration": 5.041,
        "text": "approaches um there may be a diagram of"
      },
      {
        "start": 368.24,
        "duration": 4.16,
        "text": "those two here in the slides um I'm not"
      },
      {
        "start": 370.8,
        "duration": 4.44,
        "text": "sure if that was added which is fine if"
      },
      {
        "start": 372.4,
        "duration": 5.239,
        "text": "it's not uh but just in words those are"
      },
      {
        "start": 375.24,
        "duration": 3.64,
        "text": "kind of the two major threads and"
      },
      {
        "start": 377.639,
        "duration": 2.361,
        "text": "there's a bunch of trade-offs between"
      },
      {
        "start": 378.88,
        "duration": 3.0,
        "text": "those which we could talk about but"
      },
      {
        "start": 380.0,
        "duration": 4.44,
        "text": "maybe I'll I'll leave it there to to"
      },
      {
        "start": 381.88,
        "duration": 2.56,
        "text": "kind of get your"
      },
      {
        "start": 385.319,
        "duration": 6.081,
        "text": "reaction that makes sense and I think"
      },
      {
        "start": 387.52,
        "duration": 3.88,
        "text": "we'll look at that diagram a little bit"
      },
      {
        "start": 392.24,
        "duration": 7.239,
        "text": "later and I guess what have you seen"
      },
      {
        "start": 396.639,
        "duration": 6.321,
        "text": "with how does multimodal rag work with"
      },
      {
        "start": 399.479,
        "duration": 5.961,
        "text": "more complex images um are there is is"
      },
      {
        "start": 402.96,
        "duration": 4.28,
        "text": "it more difficult to embed more complex"
      },
      {
        "start": 405.44,
        "duration": 4.36,
        "text": "images how how do you how does that work"
      },
      {
        "start": 407.24,
        "duration": 5.239,
        "text": "performance F yeah yes so I've done some"
      },
      {
        "start": 409.8,
        "duration": 5.16,
        "text": "benchmarking on this so maybe the way I"
      },
      {
        "start": 412.479,
        "duration": 4.881,
        "text": "think about it is this what kinds of"
      },
      {
        "start": 414.96,
        "duration": 4.519,
        "text": "content do you want to work with I've"
      },
      {
        "start": 417.36,
        "duration": 5.519,
        "text": "done some demos with multimodal rag over"
      },
      {
        "start": 419.479,
        "duration": 6.961,
        "text": "like slide decks which are like figures"
      },
      {
        "start": 422.879,
        "duration": 6.72,
        "text": "tables very dense very kind of dense"
      },
      {
        "start": 426.44,
        "duration": 5.0,
        "text": "images what I've observed is that"
      },
      {
        "start": 429.599,
        "duration": 4.841,
        "text": "multimodal embeddings do not do"
      },
      {
        "start": 431.44,
        "duration": 4.92,
        "text": "particularly well there for example like"
      },
      {
        "start": 434.44,
        "duration": 4.28,
        "text": "I have one demo that's like a an"
      },
      {
        "start": 436.36,
        "duration": 4.6,
        "text": "investor presentation slide deck that"
      },
      {
        "start": 438.72,
        "duration": 3.56,
        "text": "has lots of similar quantitative slides"
      },
      {
        "start": 440.96,
        "duration": 3.4,
        "text": "if you ask a very particular"
      },
      {
        "start": 442.28,
        "duration": 4.08,
        "text": "quantitative question that requires"
      },
      {
        "start": 444.36,
        "duration": 5.119,
        "text": "retrieval of like one particular slide"
      },
      {
        "start": 446.36,
        "duration": 4.959,
        "text": "with a table multimodal embeddings won't"
      },
      {
        "start": 449.479,
        "duration": 3.961,
        "text": "necessarily be able to like easily"
      },
      {
        "start": 451.319,
        "duration": 6.041,
        "text": "differentiate between two different"
      },
      {
        "start": 453.44,
        "duration": 6.12,
        "text": "tables but the text captioning is very"
      },
      {
        "start": 457.36,
        "duration": 3.6,
        "text": "good at that from what I've seen text"
      },
      {
        "start": 459.56,
        "duration": 3.319,
        "text": "caption can give you here's a summary of"
      },
      {
        "start": 460.96,
        "duration": 4.12,
        "text": "the table here's what's in it and then"
      },
      {
        "start": 462.879,
        "duration": 4.081,
        "text": "when you do retrieval you can pretty"
      },
      {
        "start": 465.08,
        "duration": 2.92,
        "text": "effectively retrieve the right table"
      },
      {
        "start": 466.96,
        "duration": 3.4,
        "text": "given the"
      },
      {
        "start": 468.0,
        "duration": 4.599,
        "text": "question however multimod embeddings are"
      },
      {
        "start": 470.36,
        "duration": 5.0,
        "text": "very good if you have like lots of just"
      },
      {
        "start": 472.599,
        "duration": 6.361,
        "text": "like semantically differentiated objects"
      },
      {
        "start": 475.36,
        "duration": 5.559,
        "text": "um photos things like that so I think"
      },
      {
        "start": 478.96,
        "duration": 4.239,
        "text": "the the differences in approach depend a"
      },
      {
        "start": 480.919,
        "duration": 4.361,
        "text": "lot on the kinds of images that you want"
      },
      {
        "start": 483.199,
        "duration": 4.68,
        "text": "to be able to retrieve and I have found"
      },
      {
        "start": 485.28,
        "duration": 6.039,
        "text": "that for like dense content tables"
      },
      {
        "start": 487.879,
        "duration": 6.401,
        "text": "graphs figures like R rag over slide"
      },
      {
        "start": 491.319,
        "duration": 4.921,
        "text": "decks for example uh captioning is"
      },
      {
        "start": 494.28,
        "duration": 4.319,
        "text": "actually from what I've seen a lot"
      },
      {
        "start": 496.24,
        "duration": 4.72,
        "text": "better now of course I've only used open"
      },
      {
        "start": 498.599,
        "duration": 3.88,
        "text": "clip multimodel embeddings uh I think"
      },
      {
        "start": 500.96,
        "duration": 3.239,
        "text": "there are indeed better embedding models"
      },
      {
        "start": 502.479,
        "duration": 4.12,
        "text": "vertex I'm actually very curious to play"
      },
      {
        "start": 504.199,
        "duration": 3.72,
        "text": "with um and of course if open a I were"
      },
      {
        "start": 506.599,
        "duration": 2.88,
        "text": "to release multimodal embedding I'm sure"
      },
      {
        "start": 507.919,
        "duration": 4.281,
        "text": "could be very very good but from what"
      },
      {
        "start": 509.479,
        "duration": 4.521,
        "text": "I've seen currently captioning is really"
      },
      {
        "start": 512.2,
        "duration": 3.68,
        "text": "good for things that are kind of very"
      },
      {
        "start": 514.0,
        "duration": 3.64,
        "text": "dense images that are not that easily"
      },
      {
        "start": 515.88,
        "duration": 4.2,
        "text": "retrieved using kind of a multimodal"
      },
      {
        "start": 517.64,
        "duration": 2.44,
        "text": "edting"
      },
      {
        "start": 520.159,
        "duration": 6.001,
        "text": "space that makes sense and YY did you"
      },
      {
        "start": 523.399,
        "duration": 4.56,
        "text": "have any thoughts here yeah probably"
      },
      {
        "start": 526.16,
        "duration": 3.88,
        "text": "just double click on some of the"
      },
      {
        "start": 527.959,
        "duration": 4.361,
        "text": "challenges I mean I think yes unique"
      },
      {
        "start": 530.04,
        "duration": 4.799,
        "text": "challenges but it's I don't know if it's"
      },
      {
        "start": 532.32,
        "duration": 4.8,
        "text": "just applicable to mul to mod rag you"
      },
      {
        "start": 534.839,
        "duration": 3.601,
        "text": "still have the as Lance talked about the"
      },
      {
        "start": 537.12,
        "duration": 3.32,
        "text": "different images right you still have"
      },
      {
        "start": 538.44,
        "duration": 3.24,
        "text": "the challenges of of making sure when"
      },
      {
        "start": 540.44,
        "duration": 3.72,
        "text": "you're creating your indexes you're"
      },
      {
        "start": 541.68,
        "duration": 3.92,
        "text": "creating indexes with the right um"
      },
      {
        "start": 544.16,
        "duration": 3.04,
        "text": "similar set of images and the right"
      },
      {
        "start": 545.6,
        "duration": 2.84,
        "text": "indexes so when you're doing searches"
      },
      {
        "start": 547.2,
        "duration": 2.68,
        "text": "you still have the challenges now that"
      },
      {
        "start": 548.44,
        "duration": 4.639,
        "text": "you're dealing with images which meet"
      },
      {
        "start": 549.88,
        "duration": 4.6,
        "text": "even larger um bites of data you still"
      },
      {
        "start": 553.079,
        "duration": 4.401,
        "text": "have the challenges of you know do I"
      },
      {
        "start": 554.48,
        "duration": 4.96,
        "text": "have a an historical index versus a"
      },
      {
        "start": 557.48,
        "duration": 4.2,
        "text": "realtime index or more frequent index"
      },
      {
        "start": 559.44,
        "duration": 4.56,
        "text": "how do I partition my indexes what's my"
      },
      {
        "start": 561.68,
        "duration": 3.64,
        "text": "reindexing strategy we'll talk a little"
      },
      {
        "start": 564.0,
        "duration": 2.68,
        "text": "bit about that when we you know talk"
      },
      {
        "start": 565.32,
        "duration": 3.28,
        "text": "about some of the some of the production"
      },
      {
        "start": 566.68,
        "duration": 3.88,
        "text": "aspects of taking the r to production"
      },
      {
        "start": 568.6,
        "duration": 4.359,
        "text": "but you still some of those challenges"
      },
      {
        "start": 570.56,
        "duration": 5.279,
        "text": "but um then going back to what Lance"
      },
      {
        "start": 572.959,
        "duration": 5.32,
        "text": "said about um captioning and doing the"
      },
      {
        "start": 575.839,
        "duration": 3.801,
        "text": "the the actual multimodel embeddings I"
      },
      {
        "start": 578.279,
        "duration": 3.521,
        "text": "think folks know I think it was on the"
      },
      {
        "start": 579.64,
        "duration": 4.04,
        "text": "13th where we announced Gemini and"
      },
      {
        "start": 581.8,
        "duration": 3.84,
        "text": "Gemini provision Gemini PR and Gemini"
      },
      {
        "start": 583.68,
        "duration": 5.36,
        "text": "provision and Gemini provision allows"
      },
      {
        "start": 585.64,
        "duration": 6.12,
        "text": "you to do um obviously create uh text"
      },
      {
        "start": 589.04,
        "duration": 5.0,
        "text": "from text from image or text from video"
      },
      {
        "start": 591.76,
        "duration": 4.319,
        "text": "we also have um our multimodel"
      },
      {
        "start": 594.04,
        "duration": 4.2,
        "text": "embeddings as well that you can use to"
      },
      {
        "start": 596.079,
        "duration": 4.401,
        "text": "create those text and image embeddings"
      },
      {
        "start": 598.24,
        "duration": 5.4,
        "text": "and store them in a vector database like"
      },
      {
        "start": 600.48,
        "duration": 6.359,
        "text": "um Astra so so we have that and and I"
      },
      {
        "start": 603.64,
        "duration": 5.6,
        "text": "think um with the tooling that we"
      },
      {
        "start": 606.839,
        "duration": 5.481,
        "text": "have the folks on the call should be"
      },
      {
        "start": 609.24,
        "duration": 5.279,
        "text": "able to take those images create the"
      },
      {
        "start": 612.32,
        "duration": 4.079,
        "text": "multim embeddings that they want create"
      },
      {
        "start": 614.519,
        "duration": 3.88,
        "text": "the caption from those Abed using"
      },
      {
        "start": 616.399,
        "duration": 4.081,
        "text": "something like a Gemini provision that"
      },
      {
        "start": 618.399,
        "duration": 4.401,
        "text": "allows you to get a text from image and"
      },
      {
        "start": 620.48,
        "duration": 4.72,
        "text": "then use that to drive the the semantic"
      },
      {
        "start": 622.8,
        "duration": 4.64,
        "text": "search when they send in those are"
      },
      {
        "start": 625.2,
        "duration": 3.72,
        "text": "prompt um to get the responses to to"
      },
      {
        "start": 627.44,
        "duration": 3.92,
        "text": "what the the customers are trying to ask"
      },
      {
        "start": 628.92,
        "duration": 4.32,
        "text": "for using images or even using text as"
      },
      {
        "start": 631.36,
        "duration": 4.24,
        "text": "the prompt"
      },
      {
        "start": 633.24,
        "duration": 4.279,
        "text": "okay absolutely and and we'll give a"
      },
      {
        "start": 635.6,
        "duration": 5.56,
        "text": "good demo of that exact where F in a"
      },
      {
        "start": 637.519,
        "duration": 5.681,
        "text": "little bit um so Lance and one other"
      },
      {
        "start": 641.16,
        "duration": 5.52,
        "text": "question for you so so Lance you touched"
      },
      {
        "start": 643.2,
        "duration": 7.0,
        "text": "a little bit on um you're seeing users"
      },
      {
        "start": 646.68,
        "duration": 6.399,
        "text": "in the wild use multimodal to do Q&A"
      },
      {
        "start": 650.2,
        "duration": 5.48,
        "text": "over PDFs um what other kind of"
      },
      {
        "start": 653.079,
        "duration": 5.481,
        "text": "Enterprise use cases have you guys seen"
      },
      {
        "start": 655.68,
        "duration": 4.8,
        "text": "so far I know it's super early so it is"
      },
      {
        "start": 658.56,
        "duration": 3.76,
        "text": "a little bit early I actually will be"
      },
      {
        "start": 660.48,
        "duration": 3.4,
        "text": "honest and say that if I look for"
      },
      {
        "start": 662.32,
        "duration": 3.72,
        "text": "example like if you go by Twitter"
      },
      {
        "start": 663.88,
        "duration": 3.84,
        "text": "activity I have not seen as much related"
      },
      {
        "start": 666.04,
        "duration": 3.799,
        "text": "to multimodal rag in like the Twitter"
      },
      {
        "start": 667.72,
        "duration": 5.4,
        "text": "Sphere not that that really necessarily"
      },
      {
        "start": 669.839,
        "duration": 5.401,
        "text": "matters um what I have heard from"
      },
      {
        "start": 673.12,
        "duration": 3.92,
        "text": "talking to companies is slide decks are"
      },
      {
        "start": 675.24,
        "duration": 5.08,
        "text": "a really good use case companies have"
      },
      {
        "start": 677.04,
        "duration": 6.799,
        "text": "lots of slides they tend to be visual"
      },
      {
        "start": 680.32,
        "duration": 4.959,
        "text": "um documents are an interesting one"
      },
      {
        "start": 683.839,
        "duration": 3.081,
        "text": "there are definitely many cases of"
      },
      {
        "start": 685.279,
        "duration": 4.281,
        "text": "documents that contain a mixture of text"
      },
      {
        "start": 686.92,
        "duration": 4.64,
        "text": "and images and I think that is also of"
      },
      {
        "start": 689.56,
        "duration": 3.48,
        "text": "Interest I think kind of slidex and"
      },
      {
        "start": 691.56,
        "duration": 3.68,
        "text": "presentation is probably of highest"
      },
      {
        "start": 693.04,
        "duration": 4.2,
        "text": "interest because it's so obvious that"
      },
      {
        "start": 695.24,
        "duration": 5.36,
        "text": "it's a very kind of good visual kind of"
      },
      {
        "start": 697.24,
        "duration": 7.52,
        "text": "QA use case that's Enterprise relevant"
      },
      {
        "start": 700.6,
        "duration": 6.6,
        "text": "um and I I think kind of uh multimodal"
      },
      {
        "start": 704.76,
        "duration": 4.879,
        "text": "rag on like mixed documents of images"
      },
      {
        "start": 707.2,
        "duration": 4.0,
        "text": "and text is is also of Interest there's"
      },
      {
        "start": 709.639,
        "duration": 3.841,
        "text": "a lot of good use cases we've done a"
      },
      {
        "start": 711.2,
        "duration": 4.079,
        "text": "little bit on this with like extraction"
      },
      {
        "start": 713.48,
        "duration": 3.44,
        "text": "so like extracting and this is a classic"
      },
      {
        "start": 715.279,
        "duration": 3.721,
        "text": "task of kind of ocrs obviously done this"
      },
      {
        "start": 716.92,
        "duration": 3.719,
        "text": "for a very long time but like kind of"
      },
      {
        "start": 719.0,
        "duration": 3.16,
        "text": "extracting extraction of important"
      },
      {
        "start": 720.639,
        "duration": 4.281,
        "text": "properties from images like that could"
      },
      {
        "start": 722.16,
        "duration": 5.0,
        "text": "be like tables forms so that's obviously"
      },
      {
        "start": 724.92,
        "duration": 5.56,
        "text": "a really big area but it's like not new"
      },
      {
        "start": 727.16,
        "duration": 4.479,
        "text": "at all um and that remains of interest"
      },
      {
        "start": 730.48,
        "duration": 2.68,
        "text": "from what I've seen I haven't done"
      },
      {
        "start": 731.639,
        "duration": 4.081,
        "text": "careful benchmarking on OCR in"
      },
      {
        "start": 733.16,
        "duration": 5.799,
        "text": "particular but I will say when I've seen"
      },
      {
        "start": 735.72,
        "duration": 5.4,
        "text": "the multimodel the high the the high the"
      },
      {
        "start": 738.959,
        "duration": 4.361,
        "text": "close Source highly performed multimodel"
      },
      {
        "start": 741.12,
        "duration": 4.719,
        "text": "models like Gemini gbd4 V are very"
      },
      {
        "start": 743.32,
        "duration": 4.92,
        "text": "strong at kind of extraction from from"
      },
      {
        "start": 745.839,
        "duration": 4.44,
        "text": "tables uh so I think that's another good"
      },
      {
        "start": 748.24,
        "duration": 4.039,
        "text": "use case so I would say like multimodal"
      },
      {
        "start": 750.279,
        "duration": 4.881,
        "text": "rag for like slide decks definitely"
      },
      {
        "start": 752.279,
        "duration": 4.401,
        "text": "interesting use case for mixed mix type"
      },
      {
        "start": 755.16,
        "duration": 3.239,
        "text": "documents definitely interesting"
      },
      {
        "start": 756.68,
        "duration": 4.04,
        "text": "extraction is another really good one"
      },
      {
        "start": 758.399,
        "duration": 3.56,
        "text": "classic task been around for a while I"
      },
      {
        "start": 760.72,
        "duration": 4.32,
        "text": "would say those three are like three"
      },
      {
        "start": 761.959,
        "duration": 6.24,
        "text": "that really come to mind"
      },
      {
        "start": 765.04,
        "duration": 4.799,
        "text": "um but I yeah those are the three I've"
      },
      {
        "start": 768.199,
        "duration": 3.601,
        "text": "really seen But curious you have y"
      },
      {
        "start": 769.839,
        "duration": 3.0,
        "text": "you've seen others as well or Alex you"
      },
      {
        "start": 771.8,
        "duration": 3.64,
        "text": "you as"
      },
      {
        "start": 772.839,
        "duration": 5.36,
        "text": "well yeah I mean I'll I'll double it"
      },
      {
        "start": 775.44,
        "duration": 4.399,
        "text": "down on the extraction piece um so think"
      },
      {
        "start": 778.199,
        "duration": 3.88,
        "text": "about extracting text from images for"
      },
      {
        "start": 779.839,
        "duration": 4.161,
        "text": "example you might have folks that maybe"
      },
      {
        "start": 782.079,
        "duration": 4.161,
        "text": "just draw out what a form could look"
      },
      {
        "start": 784.0,
        "duration": 3.6,
        "text": "like what a UI could look like and you"
      },
      {
        "start": 786.24,
        "duration": 4.36,
        "text": "can upload that to something like a"
      },
      {
        "start": 787.6,
        "duration": 5.12,
        "text": "Gemini provision and say create the HTML"
      },
      {
        "start": 790.6,
        "duration": 4.52,
        "text": "for this image you know something like"
      },
      {
        "start": 792.72,
        "duration": 4.96,
        "text": "that right and then even if you if the"
      },
      {
        "start": 795.12,
        "duration": 4.12,
        "text": "um the system understands the language"
      },
      {
        "start": 797.68,
        "duration": 3.8,
        "text": "understands your your structure of your"
      },
      {
        "start": 799.24,
        "duration": 3.88,
        "text": "HTML within your own platform it it can"
      },
      {
        "start": 801.48,
        "duration": 3.64,
        "text": "actually create it to that structure so"
      },
      {
        "start": 803.12,
        "duration": 4.0,
        "text": "it's almost executable so that's that's"
      },
      {
        "start": 805.12,
        "duration": 5.88,
        "text": "an example of extract text from images"
      },
      {
        "start": 807.12,
        "duration": 6.32,
        "text": "you can do things like Q&A images um you"
      },
      {
        "start": 811.0,
        "duration": 4.519,
        "text": "said you can do things like um taking an"
      },
      {
        "start": 813.44,
        "duration": 4.8,
        "text": "image and then converting to Json so you"
      },
      {
        "start": 815.519,
        "duration": 4.241,
        "text": "can do follow on postprocessing maybe"
      },
      {
        "start": 818.24,
        "duration": 3.52,
        "text": "you take an image and you write a story"
      },
      {
        "start": 819.76,
        "duration": 4.0,
        "text": "from an image for example depending on"
      },
      {
        "start": 821.76,
        "duration": 4.16,
        "text": "what what um platform you're trying to"
      },
      {
        "start": 823.76,
        "duration": 4.199,
        "text": "build for so for example a marketing"
      },
      {
        "start": 825.92,
        "duration": 3.84,
        "text": "platform that's probably writing a Blog"
      },
      {
        "start": 827.959,
        "duration": 2.88,
        "text": "writing a you know a Twitter feed"
      },
      {
        "start": 829.76,
        "duration": 2.439,
        "text": "something something like that they can"
      },
      {
        "start": 830.839,
        "duration": 3.081,
        "text": "just put an image on and then the"
      },
      {
        "start": 832.199,
        "duration": 3.08,
        "text": "marketer can say write me a story based"
      },
      {
        "start": 833.92,
        "duration": 3.76,
        "text": "on this image and they can use that as a"
      },
      {
        "start": 835.279,
        "duration": 4.081,
        "text": "starting point to actually create the um"
      },
      {
        "start": 837.68,
        "duration": 3.599,
        "text": "the material that they want to publishes"
      },
      {
        "start": 839.36,
        "duration": 3.8,
        "text": "right then also I think we talked about"
      },
      {
        "start": 841.279,
        "duration": 4.0,
        "text": "images as well but there's also video as"
      },
      {
        "start": 843.16,
        "duration": 4.0,
        "text": "well you know can you create an ad copy"
      },
      {
        "start": 845.279,
        "duration": 2.761,
        "text": "from a video can you do Q&A on a video"
      },
      {
        "start": 847.16,
        "duration": 3.0,
        "text": "those are some of the things that you"
      },
      {
        "start": 848.04,
        "duration": 4.0,
        "text": "can do with gini provision you know can"
      },
      {
        "start": 850.16,
        "duration": 4.119,
        "text": "you even describe this video content and"
      },
      {
        "start": 852.04,
        "duration": 4.799,
        "text": "use that data to do some f"
      },
      {
        "start": 854.279,
        "duration": 5.441,
        "text": "postprocessing and a lot of these sample"
      },
      {
        "start": 856.839,
        "duration": 4.481,
        "text": "prompts that we have on vertex AI that"
      },
      {
        "start": 859.72,
        "duration": 3.6,
        "text": "folks can look at to actually get"
      },
      {
        "start": 861.32,
        "duration": 3.639,
        "text": "started and then obviously taking that"
      },
      {
        "start": 863.32,
        "duration": 4.36,
        "text": "they can build on top of that for their"
      },
      {
        "start": 864.959,
        "duration": 5.721,
        "text": "own particular use case"
      },
      {
        "start": 867.68,
        "duration": 3.0,
        "text": "okay"
      },
      {
        "start": 871.92,
        "duration": 4.08,
        "text": "Lance I think this is the diagram you"
      },
      {
        "start": 873.6,
        "duration": 3.72,
        "text": "mentioned you're for too earlier walk"
      },
      {
        "start": 876.0,
        "duration": 3.079,
        "text": "through this yeah this this is the"
      },
      {
        "start": 877.32,
        "duration": 2.92,
        "text": "diagram that I was referencing and this"
      },
      {
        "start": 879.079,
        "duration": 2.801,
        "text": "is just showing at least the two"
      },
      {
        "start": 880.24,
        "duration": 4.2,
        "text": "approaches that I've kind of used and"
      },
      {
        "start": 881.88,
        "duration": 4.199,
        "text": "seen pretty commonly again we don't need"
      },
      {
        "start": 884.44,
        "duration": 3.44,
        "text": "to belabor it but yeah multimodal"
      },
      {
        "start": 886.079,
        "duration": 3.521,
        "text": "embeddings is one approach vertex is"
      },
      {
        "start": 887.88,
        "duration": 3.6,
        "text": "really good option here the other is"
      },
      {
        "start": 889.6,
        "duration": 4.239,
        "text": "this like image captioning idea where"
      },
      {
        "start": 891.48,
        "duration": 5.88,
        "text": "you take every image you summarize it"
      },
      {
        "start": 893.839,
        "duration": 5.12,
        "text": "you index then those text summaries"
      },
      {
        "start": 897.36,
        "duration": 4.399,
        "text": "which is easy right you can use any text"
      },
      {
        "start": 898.959,
        "duration": 5.921,
        "text": "embedding you want link every text like"
      },
      {
        "start": 901.759,
        "duration": 4.921,
        "text": "cap embedded caption to the raw image"
      },
      {
        "start": 904.88,
        "duration": 4.319,
        "text": "retrieve based on the the text"
      },
      {
        "start": 906.68,
        "duration": 4.32,
        "text": "embeddings U that capture the captions"
      },
      {
        "start": 909.199,
        "duration": 3.88,
        "text": "but then return the raw images to the"
      },
      {
        "start": 911.0,
        "duration": 3.079,
        "text": "llm in the end for final synthesis that"
      },
      {
        "start": 913.079,
        "duration": 2.481,
        "text": "those are kind of the two approaches"
      },
      {
        "start": 914.079,
        "duration": 2.921,
        "text": "I've seen and I kind of spoke to the"
      },
      {
        "start": 915.56,
        "duration": 2.959,
        "text": "tradeoffs we can talk about it more"
      },
      {
        "start": 917.0,
        "duration": 3.8,
        "text": "later if there's more"
      },
      {
        "start": 918.519,
        "duration": 3.641,
        "text": "interest awesome and the demo we're"
      },
      {
        "start": 920.8,
        "duration": 3.56,
        "text": "about to show we'll walk through kind of"
      },
      {
        "start": 922.16,
        "duration": 3.599,
        "text": "this first approach that that Lance is"
      },
      {
        "start": 924.36,
        "duration": 3.52,
        "text": "showing"
      },
      {
        "start": 925.759,
        "duration": 4.401,
        "text": "here cool so I thought that was super"
      },
      {
        "start": 927.88,
        "duration": 4.48,
        "text": "interesting now we are going to walk you"
      },
      {
        "start": 930.16,
        "duration": 5.52,
        "text": "through just a basic demo of how you can"
      },
      {
        "start": 932.36,
        "duration": 6.64,
        "text": "build a multimetal rag app with for L"
      },
      {
        "start": 935.68,
        "duration": 5.159,
        "text": "chain um but before we get into it um"
      },
      {
        "start": 939.0,
        "duration": 4.44,
        "text": "we're just going to quickly walk through"
      },
      {
        "start": 940.839,
        "duration": 6.321,
        "text": "the architecture um so there are really"
      },
      {
        "start": 943.44,
        "duration": 6.16,
        "text": "two processes here um to think about the"
      },
      {
        "start": 947.16,
        "duration": 4.32,
        "text": "first process is the data ingestion"
      },
      {
        "start": 949.6,
        "duration": 3.64,
        "text": "process that's number one at the very"
      },
      {
        "start": 951.48,
        "duration": 4.24,
        "text": "top right I said before you can build a"
      },
      {
        "start": 953.24,
        "duration": 5.8,
        "text": "multimodal rag app um you need to"
      },
      {
        "start": 955.72,
        "duration": 5.919,
        "text": "process all your your content right so"
      },
      {
        "start": 959.04,
        "duration": 5.159,
        "text": "to do this you take all your documents"
      },
      {
        "start": 961.639,
        "duration": 6.0,
        "text": "all your images all your videos you feed"
      },
      {
        "start": 964.199,
        "duration": 6.44,
        "text": "them into the vertex AI embedding model"
      },
      {
        "start": 967.639,
        "duration": 4.68,
        "text": "and this will output uh an embedding"
      },
      {
        "start": 970.639,
        "duration": 3.481,
        "text": "right an embedding is just a numerical"
      },
      {
        "start": 972.319,
        "duration": 4.121,
        "text": "representation of the text image all"
      },
      {
        "start": 974.12,
        "duration": 4.68,
        "text": "that um and then you're storing this in"
      },
      {
        "start": 976.44,
        "duration": 3.36,
        "text": "a database that's designed to store"
      },
      {
        "start": 978.8,
        "duration": 4.08,
        "text": "vectors like"
      },
      {
        "start": 979.8,
        "duration": 6.32,
        "text": "as um so once you've done that um you're"
      },
      {
        "start": 982.88,
        "duration": 5.24,
        "text": "ready for the to build your rag app"
      },
      {
        "start": 986.12,
        "duration": 4.44,
        "text": "right and and the the other kind of core"
      },
      {
        "start": 988.12,
        "duration": 4.399,
        "text": "process is the query process right so"
      },
      {
        "start": 990.56,
        "duration": 5.44,
        "text": "user can then ask you question like what"
      },
      {
        "start": 992.519,
        "duration": 5.88,
        "text": "is this image um show me related images"
      },
      {
        "start": 996.0,
        "duration": 5.56,
        "text": "um we convert the user's question to an"
      },
      {
        "start": 998.399,
        "duration": 5.081,
        "text": "embedding again um and then we query the"
      },
      {
        "start": 1001.56,
        "duration": 5.12,
        "text": "vector store to pull kind of the related"
      },
      {
        "start": 1003.48,
        "duration": 6.719,
        "text": "content and feed this relevant content"
      },
      {
        "start": 1006.68,
        "duration": 6.04,
        "text": "to the L um to then get a better"
      },
      {
        "start": 1010.199,
        "duration": 6.2,
        "text": "response um so I'll walk through exactly"
      },
      {
        "start": 1012.72,
        "duration": 5.08,
        "text": "how this works with code um so uh if you"
      },
      {
        "start": 1016.399,
        "duration": 4.24,
        "text": "haven't seen it already we've shared"
      },
      {
        "start": 1017.8,
        "duration": 5.92,
        "text": "this link on the right hand side of chat"
      },
      {
        "start": 1020.639,
        "duration": 5.8,
        "text": "um so you can play with this notebook as"
      },
      {
        "start": 1023.72,
        "duration": 4.76,
        "text": "well so this really is just a really"
      },
      {
        "start": 1026.439,
        "duration": 4.841,
        "text": "basic app um where we show you how to"
      },
      {
        "start": 1028.48,
        "duration": 6.24,
        "text": "use Gemini linkchain and rag to get"
      },
      {
        "start": 1031.28,
        "duration": 5.12,
        "text": "Astra together building a rag app I'm so"
      },
      {
        "start": 1034.72,
        "duration": 3.719,
        "text": "the first couple steps here just walking"
      },
      {
        "start": 1036.4,
        "duration": 4.2,
        "text": "you through how to create the necessary"
      },
      {
        "start": 1038.439,
        "duration": 4.321,
        "text": "credentials right you'll need an asure"
      },
      {
        "start": 1040.6,
        "duration": 4.199,
        "text": "account we have links on the right to"
      },
      {
        "start": 1042.76,
        "duration": 3.52,
        "text": "create an account once you've created"
      },
      {
        "start": 1044.799,
        "duration": 4.081,
        "text": "your asra account you'll need to create"
      },
      {
        "start": 1046.28,
        "duration": 4.08,
        "text": "a vector database um in poll some"
      },
      {
        "start": 1048.88,
        "duration": 2.84,
        "text": "credentials we show you exactly where to"
      },
      {
        "start": 1050.36,
        "duration": 4.199,
        "text": "pull them"
      },
      {
        "start": 1051.72,
        "duration": 5.24,
        "text": "here um once you've done that right"
      },
      {
        "start": 1054.559,
        "duration": 5.161,
        "text": "you'll also need to create a gcp account"
      },
      {
        "start": 1056.96,
        "duration": 5.76,
        "text": "and and uh vertex AI enable the vertex"
      },
      {
        "start": 1059.72,
        "duration": 4.6,
        "text": "AI API and pull your project ID this is"
      },
      {
        "start": 1062.72,
        "duration": 4.0,
        "text": "super simple both these accounts start"
      },
      {
        "start": 1064.32,
        "duration": 5.32,
        "text": "with free credit you can get started in"
      },
      {
        "start": 1066.72,
        "duration": 4.64,
        "text": "minutes um there's some basic"
      },
      {
        "start": 1069.64,
        "duration": 3.6,
        "text": "installation of the dependencies"
      },
      {
        "start": 1071.36,
        "duration": 4.08,
        "text": "necessary for the project um here we're"
      },
      {
        "start": 1073.24,
        "duration": 5.6,
        "text": "using here you can see we're installing"
      },
      {
        "start": 1075.44,
        "duration": 6.76,
        "text": "rag stack and the Google Cloud AI"
      },
      {
        "start": 1078.84,
        "duration": 3.36,
        "text": "platform Reep includes linkchain"
      },
      {
        "start": 1084.559,
        "duration": 5.081,
        "text": "um we do some basic loading of"
      },
      {
        "start": 1087.64,
        "duration": 4.08,
        "text": "credentials as environment"
      },
      {
        "start": 1089.64,
        "duration": 5.76,
        "text": "variables um we do some basic"
      },
      {
        "start": 1091.72,
        "duration": 6.68,
        "text": "configuration of the Google Cloud API"
      },
      {
        "start": 1095.4,
        "duration": 5.68,
        "text": "and now we get into the interesting part"
      },
      {
        "start": 1098.4,
        "duration": 5.36,
        "text": "um so uh my cooworker Scott sent just"
      },
      {
        "start": 1101.08,
        "duration": 4.92,
        "text": "kind of this random picture of his uh"
      },
      {
        "start": 1103.76,
        "duration": 5.279,
        "text": "espresso machine I'm just to sort of"
      },
      {
        "start": 1106.0,
        "duration": 5.0,
        "text": "test how Gemini Pro works"
      },
      {
        "start": 1109.039,
        "duration": 3.12,
        "text": "um this really was just kind of a random"
      },
      {
        "start": 1111.0,
        "duration": 3.52,
        "text": "image we didn't know if it's going to"
      },
      {
        "start": 1112.159,
        "duration": 4.321,
        "text": "work or not but it it worked really well"
      },
      {
        "start": 1114.52,
        "duration": 3.6,
        "text": "we turned into this webinar content um"
      },
      {
        "start": 1116.48,
        "duration": 3.4,
        "text": "so here's just kind of the a random part"
      },
      {
        "start": 1118.12,
        "duration": 6.4,
        "text": "to this Express a"
      },
      {
        "start": 1119.88,
        "duration": 6.48,
        "text": "machine and um we asked Gemini provision"
      },
      {
        "start": 1124.52,
        "duration": 4.159,
        "text": "what is this image right you'll notice"
      },
      {
        "start": 1126.36,
        "duration": 5.16,
        "text": "here um we're using Lane chain to"
      },
      {
        "start": 1128.679,
        "duration": 6.081,
        "text": "interact with Gemini Pro um Lane chain"
      },
      {
        "start": 1131.52,
        "duration": 5.56,
        "text": "makes it super easy to um interact with"
      },
      {
        "start": 1134.76,
        "duration": 4.36,
        "text": "with all these models and the prompt"
      },
      {
        "start": 1137.08,
        "duration": 3.079,
        "text": "here is what is this image share link to"
      },
      {
        "start": 1139.12,
        "duration": 5.0,
        "text": "purchase"
      },
      {
        "start": 1140.159,
        "duration": 7.561,
        "text": "replacement and was we were super"
      },
      {
        "start": 1144.12,
        "duration": 5.96,
        "text": "impressed um ji provision was able to"
      },
      {
        "start": 1147.72,
        "duration": 6.52,
        "text": "identify the exact model of the coffee"
      },
      {
        "start": 1150.08,
        "duration": 6.599,
        "text": "machine and a link to purchaser"
      },
      {
        "start": 1154.24,
        "duration": 5.6,
        "text": "replacement so as kind of YY mentioned"
      },
      {
        "start": 1156.679,
        "duration": 4.48,
        "text": "before the LLS are trained right in the"
      },
      {
        "start": 1159.84,
        "duration": 4.12,
        "text": "past they don't have access to realtime"
      },
      {
        "start": 1161.159,
        "duration": 4.281,
        "text": "data so the only issue here is you know"
      },
      {
        "start": 1163.96,
        "duration": 3.88,
        "text": "Amazon is constantly changing their"
      },
      {
        "start": 1165.44,
        "duration": 5.44,
        "text": "links so this link here is out of date"
      },
      {
        "start": 1167.84,
        "duration": 6.839,
        "text": "right so perfect use case for rag as"
      },
      {
        "start": 1170.88,
        "duration": 6.0,
        "text": "kind of mentioned before um so here's"
      },
      {
        "start": 1174.679,
        "duration": 4.601,
        "text": "the example of interacting with the"
      },
      {
        "start": 1176.88,
        "duration": 5.12,
        "text": "Gemini provision model without rack I'm"
      },
      {
        "start": 1179.28,
        "duration": 5.759,
        "text": "still like insanely impressive very cool"
      },
      {
        "start": 1182.0,
        "duration": 4.76,
        "text": "I recommend you give a shot I'm so now"
      },
      {
        "start": 1185.039,
        "duration": 4.52,
        "text": "we've done now we're sort of getting"
      },
      {
        "start": 1186.76,
        "duration": 6.2,
        "text": "into the data ingestion process we took"
      },
      {
        "start": 1189.559,
        "duration": 5.561,
        "text": "a parts catalog from uh breel right the"
      },
      {
        "start": 1192.96,
        "duration": 3.48,
        "text": "maker of the espresso machine um we've"
      },
      {
        "start": 1195.12,
        "duration": 4.08,
        "text": "done all the scraping for you so you"
      },
      {
        "start": 1196.44,
        "duration": 4.04,
        "text": "don't need to do so um we take all these"
      },
      {
        "start": 1199.2,
        "duration": 5.88,
        "text": "parts all these"
      },
      {
        "start": 1200.48,
        "duration": 7.96,
        "text": "URLs um we embed them using the vertex"
      },
      {
        "start": 1205.08,
        "duration": 5.92,
        "text": "AI Gemini multimodal embedding model um"
      },
      {
        "start": 1208.44,
        "duration": 5.96,
        "text": "we feed them into astb right something"
      },
      {
        "start": 1211.0,
        "duration": 5.32,
        "text": "important to to note here is um astb"
      },
      {
        "start": 1214.4,
        "duration": 4.159,
        "text": "supports both Vector data and tabular"
      },
      {
        "start": 1216.32,
        "duration": 4.28,
        "text": "data right so I can store my Vector"
      },
      {
        "start": 1218.559,
        "duration": 4.721,
        "text": "embeddings generated from vertex Ai and"
      },
      {
        "start": 1220.6,
        "duration": 6.16,
        "text": "I can also store raw information like"
      },
      {
        "start": 1223.28,
        "duration": 6.879,
        "text": "name and price the URL here we're doing"
      },
      {
        "start": 1226.76,
        "duration": 3.399,
        "text": "some basic loading"
      },
      {
        "start": 1231.44,
        "duration": 3.88,
        "text": "and then we get into the Super"
      },
      {
        "start": 1233.159,
        "duration": 4.281,
        "text": "interesting part so this is the actual"
      },
      {
        "start": 1235.32,
        "duration": 4.64,
        "text": "example of multim rag with link chain"
      },
      {
        "start": 1237.44,
        "duration": 5.359,
        "text": "and Gemini right so this looks very"
      },
      {
        "start": 1239.96,
        "duration": 5.52,
        "text": "similar to the example above but this"
      },
      {
        "start": 1242.799,
        "duration": 4.041,
        "text": "time in addition to asking what the item"
      },
      {
        "start": 1245.48,
        "duration": 3.92,
        "text": "is and where to purchase it a"
      },
      {
        "start": 1246.84,
        "duration": 4.52,
        "text": "replacement we feed the real time the"
      },
      {
        "start": 1249.4,
        "duration": 4.639,
        "text": "product catalog that we the scripts"
      },
      {
        "start": 1251.36,
        "duration": 5.48,
        "text": "right and because we've injected this"
      },
      {
        "start": 1254.039,
        "duration": 5.12,
        "text": "relevant information from our ASB Vector"
      },
      {
        "start": 1256.84,
        "duration": 5.6,
        "text": "store we get just a much more precise"
      },
      {
        "start": 1259.159,
        "duration": 5.281,
        "text": "answer right um Gemini cision is able to"
      },
      {
        "start": 1262.44,
        "duration": 3.359,
        "text": "identify the exact part it's able to"
      },
      {
        "start": 1264.44,
        "duration": 3.64,
        "text": "share details it's able to share the"
      },
      {
        "start": 1265.799,
        "duration": 5.641,
        "text": "price um and information on exactly"
      },
      {
        "start": 1268.08,
        "duration": 5.199,
        "text": "where to to purchase um so really cool"
      },
      {
        "start": 1271.44,
        "duration": 4.839,
        "text": "stuff really really simple to get"
      },
      {
        "start": 1273.279,
        "duration": 5.121,
        "text": "started with Lang chain and verx AI um"
      },
      {
        "start": 1276.279,
        "duration": 3.441,
        "text": "definitely give this a shot we're happy"
      },
      {
        "start": 1278.4,
        "duration": 2.84,
        "text": "to answer any questions if you have a"
      },
      {
        "start": 1279.72,
        "duration": 2.959,
        "text": "more sophisticated use case we're also"
      },
      {
        "start": 1281.24,
        "duration": 4.679,
        "text": "happy to help you build that"
      },
      {
        "start": 1282.679,
        "duration": 6.041,
        "text": "out um and we'll we'll we'll go on to"
      },
      {
        "start": 1285.919,
        "duration": 5.161,
        "text": "the next item um so"
      },
      {
        "start": 1288.72,
        "duration": 5.24,
        "text": "we've shown this example"
      },
      {
        "start": 1291.08,
        "duration": 4.88,
        "text": "right you know you let's say you're now"
      },
      {
        "start": 1293.96,
        "duration": 4.8,
        "text": "sold on using brag you're now sold on"
      },
      {
        "start": 1295.96,
        "duration": 4.36,
        "text": "multimodal rag um what are the sort of"
      },
      {
        "start": 1298.76,
        "duration": 3.519,
        "text": "things you should think about before"
      },
      {
        "start": 1300.32,
        "duration": 4.92,
        "text": "deploying a rag application to"
      },
      {
        "start": 1302.279,
        "duration": 5.121,
        "text": "production um maybe it'd be great if you"
      },
      {
        "start": 1305.24,
        "duration": 5.319,
        "text": "keep this one your"
      },
      {
        "start": 1307.4,
        "duration": 5.92,
        "text": "thoughts yeah I think one very important"
      },
      {
        "start": 1310.559,
        "duration": 4.36,
        "text": "consideration for production well there"
      },
      {
        "start": 1313.32,
        "duration": 3.599,
        "text": "there's maybe a few"
      },
      {
        "start": 1314.919,
        "duration": 4.36,
        "text": "things what we've done in a lot of our"
      },
      {
        "start": 1316.919,
        "duration": 4.561,
        "text": "kind of demos is is quite a bit of work"
      },
      {
        "start": 1319.279,
        "duration": 3.721,
        "text": "on evaluation so you need some way to"
      },
      {
        "start": 1321.48,
        "duration": 5.0,
        "text": "actually Benchmark performance before"
      },
      {
        "start": 1323.0,
        "duration": 5.52,
        "text": "you actually ship something of course um"
      },
      {
        "start": 1326.48,
        "duration": 4.079,
        "text": "we so so Lang chain has a platform"
      },
      {
        "start": 1328.52,
        "duration": 3.6,
        "text": "called lsmith which is pretty useful for"
      },
      {
        "start": 1330.559,
        "duration": 4.72,
        "text": "this and there's a bunch of resources"
      },
      {
        "start": 1332.12,
        "duration": 4.679,
        "text": "that we can share on this topic um but"
      },
      {
        "start": 1335.279,
        "duration": 3.921,
        "text": "it does allow you to kind of build"
      },
      {
        "start": 1336.799,
        "duration": 5.0,
        "text": "evaluation sets pretty easily and then"
      },
      {
        "start": 1339.2,
        "duration": 3.76,
        "text": "test your so say you in fact we did this"
      },
      {
        "start": 1341.799,
        "duration": 4.441,
        "text": "with kind of comparing those two"
      },
      {
        "start": 1342.96,
        "duration": 4.48,
        "text": "different multimodal rag approaches um"
      },
      {
        "start": 1346.24,
        "duration": 2.36,
        "text": "and you can very easily kind of test"
      },
      {
        "start": 1347.44,
        "duration": 2.76,
        "text": "your different rag change against your"
      },
      {
        "start": 1348.6,
        "duration": 3.76,
        "text": "eval set and kind of build intuition"
      },
      {
        "start": 1350.2,
        "duration": 4.0,
        "text": "about which approach is better or worse"
      },
      {
        "start": 1352.36,
        "duration": 3.319,
        "text": "and I think this is obviously you know"
      },
      {
        "start": 1354.2,
        "duration": 2.92,
        "text": "pretty fundamental but very important"
      },
      {
        "start": 1355.679,
        "duration": 3.041,
        "text": "before you you know ship anything to"
      },
      {
        "start": 1357.12,
        "duration": 3.76,
        "text": "production so I think that that's"
      },
      {
        "start": 1358.72,
        "duration": 4.839,
        "text": "consideration one kind of the ability to"
      },
      {
        "start": 1360.88,
        "duration": 4.32,
        "text": "run evaluations and kind of build an"
      },
      {
        "start": 1363.559,
        "duration": 4.321,
        "text": "evaluation set that that's kind of"
      },
      {
        "start": 1365.2,
        "duration": 5.64,
        "text": "obvious like table Stakes consideration"
      },
      {
        "start": 1367.88,
        "duration": 4.88,
        "text": "two is cost so I would say that for the"
      },
      {
        "start": 1370.84,
        "duration": 3.12,
        "text": "for the captioning approach one push"
      },
      {
        "start": 1372.76,
        "duration": 2.88,
        "text": "back I've heard from people which is a"
      },
      {
        "start": 1373.96,
        "duration": 3.28,
        "text": "very valid point is like well you have"
      },
      {
        "start": 1375.64,
        "duration": 3.399,
        "text": "to produce these image captions for your"
      },
      {
        "start": 1377.24,
        "duration": 3.76,
        "text": "whole kind of ppose that could be very"
      },
      {
        "start": 1379.039,
        "duration": 4.321,
        "text": "expensive I completely agree with that"
      },
      {
        "start": 1381.0,
        "duration": 5.08,
        "text": "concern I've become pretty interested in"
      },
      {
        "start": 1383.36,
        "duration": 5.28,
        "text": "in potentially open open source llms to"
      },
      {
        "start": 1386.08,
        "duration": 5.52,
        "text": "do this so there's a few there's lava uh"
      },
      {
        "start": 1388.64,
        "duration": 4.8,
        "text": "fuyu out there um baklava so there's"
      },
      {
        "start": 1391.6,
        "duration": 4.24,
        "text": "kind of a series of of Open Source that"
      },
      {
        "start": 1393.44,
        "duration": 4.719,
        "text": "could be free to use multimodal LMS that"
      },
      {
        "start": 1395.84,
        "duration": 4.199,
        "text": "you could do the captioning with and"
      },
      {
        "start": 1398.159,
        "duration": 3.921,
        "text": "then still use a more higher powerered"
      },
      {
        "start": 1400.039,
        "duration": 4.12,
        "text": "you know multimodal LM like Gemini in"
      },
      {
        "start": 1402.08,
        "duration": 3.839,
        "text": "your application and production so I"
      },
      {
        "start": 1404.159,
        "duration": 3.201,
        "text": "think that's another interesting point"
      },
      {
        "start": 1405.919,
        "duration": 3.0,
        "text": "what's the cost of your of of the"
      },
      {
        "start": 1407.36,
        "duration": 3.64,
        "text": "approach you're taking making for"
      },
      {
        "start": 1408.919,
        "duration": 3.521,
        "text": "indexing uh and the captioning approach"
      },
      {
        "start": 1411.0,
        "duration": 2.919,
        "text": "indeed could be quite a bit more costly"
      },
      {
        "start": 1412.44,
        "duration": 4.64,
        "text": "because you're generating an IM an image"
      },
      {
        "start": 1413.919,
        "duration": 5.401,
        "text": "caption or summary across your Corpus um"
      },
      {
        "start": 1417.08,
        "duration": 5.079,
        "text": "so I think those are two important"
      },
      {
        "start": 1419.32,
        "duration": 3.92,
        "text": "considerations cost of indexing uh kind"
      },
      {
        "start": 1422.159,
        "duration": 4.241,
        "text": "of"
      },
      {
        "start": 1423.24,
        "duration": 5.52,
        "text": "evaluation um other considerations in"
      },
      {
        "start": 1426.4,
        "duration": 4.32,
        "text": "production are like just monitoring so"
      },
      {
        "start": 1428.76,
        "duration": 3.56,
        "text": "like how's your app going where is it"
      },
      {
        "start": 1430.72,
        "duration": 3.52,
        "text": "going haywire or when you getting bad"
      },
      {
        "start": 1432.32,
        "duration": 4.04,
        "text": "responses Langs Smith is pretty useful"
      },
      {
        "start": 1434.24,
        "duration": 4.0,
        "text": "for this um we have lots of tracing"
      },
      {
        "start": 1436.36,
        "duration": 4.319,
        "text": "functionality so you can kind kind of go"
      },
      {
        "start": 1438.24,
        "duration": 4.679,
        "text": "back you can look at every generation by"
      },
      {
        "start": 1440.679,
        "duration": 3.6,
        "text": "your model in production you can inspect"
      },
      {
        "start": 1442.919,
        "duration": 3.201,
        "text": "kind of outputs that don't meet your"
      },
      {
        "start": 1444.279,
        "duration": 3.321,
        "text": "expectation you can build eal sets from"
      },
      {
        "start": 1446.12,
        "duration": 3.559,
        "text": "it um and we have a bunch of"
      },
      {
        "start": 1447.6,
        "duration": 5.4,
        "text": "documentation there as well so I would"
      },
      {
        "start": 1449.679,
        "duration": 4.761,
        "text": "say yeah like in short um evaluation to"
      },
      {
        "start": 1453.0,
        "duration": 3.32,
        "text": "start to gate what you're actually going"
      },
      {
        "start": 1454.44,
        "duration": 4.28,
        "text": "to ship thinking about the cost of"
      },
      {
        "start": 1456.32,
        "duration": 3.8,
        "text": "indexing for your decision um and maybe"
      },
      {
        "start": 1458.72,
        "duration": 4.12,
        "text": "finding ways to mitigate the cost with"
      },
      {
        "start": 1460.12,
        "duration": 4.36,
        "text": "open source llms for captioning uh and"
      },
      {
        "start": 1462.84,
        "duration": 3.92,
        "text": "then three kind of monitoring up in"
      },
      {
        "start": 1464.48,
        "duration": 4.16,
        "text": "production lsmith obviously has has kind"
      },
      {
        "start": 1466.76,
        "duration": 3.039,
        "text": "of features for that as well"
      },
      {
        "start": 1468.64,
        "duration": 5.0,
        "text": "I think those are the big three I would"
      },
      {
        "start": 1469.799,
        "duration": 8.561,
        "text": "highlight but yeah cous get your guys"
      },
      {
        "start": 1473.64,
        "duration": 7.2,
        "text": "take yeah I'll go next yeah plus 100 to"
      },
      {
        "start": 1478.36,
        "duration": 3.96,
        "text": "the uh the three areas that Lun just"
      },
      {
        "start": 1480.84,
        "duration": 2.76,
        "text": "highlighted what I'll probably out to"
      },
      {
        "start": 1482.32,
        "duration": 3.0,
        "text": "that is I'll probably I'll start with"
      },
      {
        "start": 1483.6,
        "duration": 3.48,
        "text": "edings management right we're creating"
      },
      {
        "start": 1485.32,
        "duration": 4.12,
        "text": "embeddings we got to store them"
      },
      {
        "start": 1487.08,
        "duration": 4.28,
        "text": "somewhere you know this Version Control"
      },
      {
        "start": 1489.44,
        "duration": 4.28,
        "text": "we know you know as folks release new"
      },
      {
        "start": 1491.36,
        "duration": 4.08,
        "text": "embeddings they get better at um"
      },
      {
        "start": 1493.72,
        "duration": 3.48,
        "text": "creating embeddings faster creating"
      },
      {
        "start": 1495.44,
        "duration": 2.92,
        "text": "embeddings but what does that mean for"
      },
      {
        "start": 1497.2,
        "duration": 2.16,
        "text": "upgrades"
      },
      {
        "start": 1498.36,
        "duration": 2.84,
        "text": "I think right now there still a"
      },
      {
        "start": 1499.36,
        "duration": 4.64,
        "text": "challenge around backward compatibility"
      },
      {
        "start": 1501.2,
        "duration": 4.04,
        "text": "so how do you maintain Version Control"
      },
      {
        "start": 1504.0,
        "duration": 3.96,
        "text": "and make sure that as you're Building"
      },
      {
        "start": 1505.24,
        "duration": 4.64,
        "text": "Solutions and you you upgrading the"
      },
      {
        "start": 1507.96,
        "duration": 3.88,
        "text": "latest embedding models you still make"
      },
      {
        "start": 1509.88,
        "duration": 4.48,
        "text": "sure that the embeddings you created are"
      },
      {
        "start": 1511.84,
        "duration": 4.28,
        "text": "still working or do you do old migration"
      },
      {
        "start": 1514.36,
        "duration": 4.0,
        "text": "which to Lance Point could be a cost"
      },
      {
        "start": 1516.12,
        "duration": 4.84,
        "text": "challenge because folks have you know"
      },
      {
        "start": 1518.36,
        "duration": 4.199,
        "text": "millions of data that they create embed"
      },
      {
        "start": 1520.96,
        "duration": 3.16,
        "text": "out of and if you do the math on that"
      },
      {
        "start": 1522.559,
        "duration": 3.681,
        "text": "you know that may be cost prohibitive"
      },
      {
        "start": 1524.12,
        "duration": 3.2,
        "text": "for you to do a migration of embeddings"
      },
      {
        "start": 1526.24,
        "duration": 2.799,
        "text": "when you when you have take a new"
      },
      {
        "start": 1527.32,
        "duration": 4.8,
        "text": "version embedding so Version Control and"
      },
      {
        "start": 1529.039,
        "duration": 5.441,
        "text": "upgr is important also multilingual a"
      },
      {
        "start": 1532.12,
        "duration": 3.76,
        "text": "lot of the stuff we do we do in English"
      },
      {
        "start": 1534.48,
        "duration": 3.36,
        "text": "but we got to recognize there are people"
      },
      {
        "start": 1535.88,
        "duration": 4.039,
        "text": "in other parts of the world that want it"
      },
      {
        "start": 1537.84,
        "duration": 3.76,
        "text": "in their own local language so what does"
      },
      {
        "start": 1539.919,
        "duration": 3.88,
        "text": "that mean is that multilingual versus"
      },
      {
        "start": 1541.6,
        "duration": 4.72,
        "text": "English only do we use a multilingual a"
      },
      {
        "start": 1543.799,
        "duration": 4.201,
        "text": "bedding if we know that it create it"
      },
      {
        "start": 1546.32,
        "duration": 4.2,
        "text": "Cates for that 10 different languages"
      },
      {
        "start": 1548.0,
        "duration": 4.6,
        "text": "that we look for and it's maybe good at"
      },
      {
        "start": 1550.52,
        "duration": 3.519,
        "text": "English or do we say okay we only do it"
      },
      {
        "start": 1552.6,
        "duration": 2.92,
        "text": "English only so let's use an English"
      },
      {
        "start": 1554.039,
        "duration": 2.36,
        "text": "embedding because that's what it's good"
      },
      {
        "start": 1555.52,
        "duration": 2.24,
        "text": "at so those are some of the"
      },
      {
        "start": 1556.399,
        "duration": 2.601,
        "text": "considerations that we we need to to"
      },
      {
        "start": 1557.76,
        "duration": 3.639,
        "text": "look into and I think I talked about"
      },
      {
        "start": 1559.0,
        "duration": 4.52,
        "text": "indexing and reindexing and strategies"
      },
      {
        "start": 1561.399,
        "duration": 4.441,
        "text": "you know as you get new information are"
      },
      {
        "start": 1563.52,
        "duration": 4.32,
        "text": "you partitioning your indexes such that"
      },
      {
        "start": 1565.84,
        "duration": 3.439,
        "text": "you you you're reducing the amount of"
      },
      {
        "start": 1567.84,
        "duration": 3.28,
        "text": "indexing that you're doing and reducing"
      },
      {
        "start": 1569.279,
        "duration": 3.0,
        "text": "the cost of creating those indexing"
      },
      {
        "start": 1571.12,
        "duration": 3.559,
        "text": "those are some of the things you need to"
      },
      {
        "start": 1572.279,
        "duration": 3.721,
        "text": "look for on inen management as you build"
      },
      {
        "start": 1574.679,
        "duration": 3.321,
        "text": "this application there's one thing"
      },
      {
        "start": 1576.0,
        "duration": 4.679,
        "text": "building an application but you also"
      },
      {
        "start": 1578.0,
        "duration": 5.039,
        "text": "have to maintain it and and and and and"
      },
      {
        "start": 1580.679,
        "duration": 4.36,
        "text": "care and feed for it going forward um"
      },
      {
        "start": 1583.039,
        "duration": 3.481,
        "text": "for for your customers then the other"
      },
      {
        "start": 1585.039,
        "duration": 3.481,
        "text": "piece as well is the non-functional"
      },
      {
        "start": 1586.52,
        "duration": 4.039,
        "text": "requirements what do I mean by that"
      },
      {
        "start": 1588.52,
        "duration": 4.399,
        "text": "security there's a lot of challenges"
      },
      {
        "start": 1590.559,
        "duration": 4.24,
        "text": "around data residency you know having"
      },
      {
        "start": 1592.919,
        "duration": 3.64,
        "text": "been able to store data arrest you know"
      },
      {
        "start": 1594.799,
        "duration": 5.081,
        "text": "so being able to call Regional URL"
      },
      {
        "start": 1596.559,
        "duration": 5.521,
        "text": "whether it's in North America Europe or"
      },
      {
        "start": 1599.88,
        "duration": 3.84,
        "text": "Asia pack and know that the data you the"
      },
      {
        "start": 1602.08,
        "duration": 3.319,
        "text": "embeddings you created are stored in"
      },
      {
        "start": 1603.72,
        "duration": 3.6,
        "text": "that location and they not going to a"
      },
      {
        "start": 1605.399,
        "duration": 4.201,
        "text": "different part of the of of the world"
      },
      {
        "start": 1607.32,
        "duration": 4.68,
        "text": "been been able to do that there's also"
      },
      {
        "start": 1609.6,
        "duration": 4.64,
        "text": "uh encryption keys with our service we"
      },
      {
        "start": 1612.0,
        "duration": 4.2,
        "text": "always encrypt by default we have Google"
      },
      {
        "start": 1614.24,
        "duration": 3.36,
        "text": "U manage encryption keys but customers"
      },
      {
        "start": 1616.2,
        "duration": 3.479,
        "text": "might want their own encryption keys"
      },
      {
        "start": 1617.6,
        "duration": 4.24,
        "text": "keys for example in regulated Industries"
      },
      {
        "start": 1619.679,
        "duration": 5.201,
        "text": "like Finance Healthcare where they want"
      },
      {
        "start": 1621.84,
        "duration": 5.28,
        "text": "to have their own AC key so we support"
      },
      {
        "start": 1624.88,
        "duration": 5.0,
        "text": "that with custom manage encryption Keys"
      },
      {
        "start": 1627.12,
        "duration": 4.36,
        "text": "uh there's also the networking aspect of"
      },
      {
        "start": 1629.88,
        "duration": 3.76,
        "text": "it you know I don't want this thing to"
      },
      {
        "start": 1631.48,
        "duration": 4.0,
        "text": "be public facing I'm still being I mean"
      },
      {
        "start": 1633.64,
        "duration": 3.159,
        "text": "even it's a gen application I'm still"
      },
      {
        "start": 1635.48,
        "duration": 2.64,
        "text": "building an application within my"
      },
      {
        "start": 1636.799,
        "duration": 3.081,
        "text": "Enterprise so I've got to be able to"
      },
      {
        "start": 1638.12,
        "duration": 3.6,
        "text": "apply things like VPC controls and"
      },
      {
        "start": 1639.88,
        "duration": 3.96,
        "text": "service controls to make sure there is"
      },
      {
        "start": 1641.72,
        "duration": 4.04,
        "text": "no data going out to make sure there is"
      },
      {
        "start": 1643.84,
        "duration": 3.28,
        "text": "no unauthorized access to make sure I'm"
      },
      {
        "start": 1645.76,
        "duration": 4.279,
        "text": "protecting I'm building a perimeter"
      },
      {
        "start": 1647.12,
        "duration": 5.32,
        "text": "around J resources and protecting them"
      },
      {
        "start": 1650.039,
        "duration": 4.76,
        "text": "accordingly and then access transparency"
      },
      {
        "start": 1652.44,
        "duration": 3.68,
        "text": "who has access to my system you know"
      },
      {
        "start": 1654.799,
        "duration": 3.6,
        "text": "what kind of audit logs I might"
      },
      {
        "start": 1656.12,
        "duration": 4.679,
        "text": "collecting if someone is fixing for"
      },
      {
        "start": 1658.399,
        "duration": 4.841,
        "text": "example Google cloud is is um uh you"
      },
      {
        "start": 1660.799,
        "duration": 4.681,
        "text": "know supporting respons support ticket"
      },
      {
        "start": 1663.24,
        "duration": 3.72,
        "text": "what dat are they looking at to to uh"
      },
      {
        "start": 1665.48,
        "duration": 3.4,
        "text": "resolve that issue for me access"
      },
      {
        "start": 1666.96,
        "duration": 5.24,
        "text": "transparency is also a key one there as"
      },
      {
        "start": 1668.88,
        "duration": 4.919,
        "text": "well then um when you look at uh you"
      },
      {
        "start": 1672.2,
        "duration": 3.24,
        "text": "know production development to"
      },
      {
        "start": 1673.799,
        "duration": 4.36,
        "text": "production how do you get to you've done"
      },
      {
        "start": 1675.44,
        "duration": 4.28,
        "text": "a lot of development you you know Lance"
      },
      {
        "start": 1678.159,
        "duration": 3.201,
        "text": "mention all of tools that you can use as"
      },
      {
        "start": 1679.72,
        "duration": 3.0,
        "text": "part your development life cycle to make"
      },
      {
        "start": 1681.36,
        "duration": 2.76,
        "text": "sure what you're building is f for"
      },
      {
        "start": 1682.72,
        "duration": 3.679,
        "text": "purpose and you can obviously"
      },
      {
        "start": 1684.12,
        "duration": 5.12,
        "text": "continually Monitor and manage it as you"
      },
      {
        "start": 1686.399,
        "duration": 5.481,
        "text": "go forward but how do you migrate from"
      },
      {
        "start": 1689.24,
        "duration": 3.919,
        "text": "uh you know your PC your development to"
      },
      {
        "start": 1691.88,
        "duration": 2.679,
        "text": "production what is that test to"
      },
      {
        "start": 1693.159,
        "duration": 3.201,
        "text": "production system that's where some of"
      },
      {
        "start": 1694.559,
        "duration": 4.681,
        "text": "the tooling that Lance mentioned around"
      },
      {
        "start": 1696.36,
        "duration": 4.199,
        "text": "LMI Astro DB having been able to create"
      },
      {
        "start": 1699.24,
        "duration": 2.84,
        "text": "your development environment been able"
      },
      {
        "start": 1700.559,
        "duration": 3.48,
        "text": "to load your data migrate your"
      },
      {
        "start": 1702.08,
        "duration": 3.959,
        "text": "environment as you go to production"
      },
      {
        "start": 1704.039,
        "duration": 4.64,
        "text": "having different um environments for"
      },
      {
        "start": 1706.039,
        "duration": 4.841,
        "text": "your vertex able to OTE your uh your"
      },
      {
        "start": 1708.679,
        "duration": 3.521,
        "text": "your um your code as well that's where"
      },
      {
        "start": 1710.88,
        "duration": 3.48,
        "text": "you need to think about your what does"
      },
      {
        "start": 1712.2,
        "duration": 4.319,
        "text": "your sdlc life cycle look like when"
      },
      {
        "start": 1714.36,
        "duration": 3.6,
        "text": "you're building this gen apps and then"
      },
      {
        "start": 1716.519,
        "duration": 3.601,
        "text": "one other final thing I mention is"
      },
      {
        "start": 1717.96,
        "duration": 3.48,
        "text": "things around service terms you know we"
      },
      {
        "start": 1720.12,
        "duration": 2.88,
        "text": "talked about images we talked about"
      },
      {
        "start": 1721.44,
        "duration": 3.76,
        "text": "embeddings this language models are"
      },
      {
        "start": 1723.0,
        "duration": 5.039,
        "text": "trained on data the provider that you're"
      },
      {
        "start": 1725.2,
        "duration": 4.599,
        "text": "using how are you being indemnified on"
      },
      {
        "start": 1728.039,
        "duration": 3.52,
        "text": "the output that you're generating from"
      },
      {
        "start": 1729.799,
        "duration": 3.6,
        "text": "this language models do they provide the"
      },
      {
        "start": 1731.559,
        "duration": 3.12,
        "text": "right level of Indemnity so that you can"
      },
      {
        "start": 1733.399,
        "duration": 3.361,
        "text": "make sure that if you're using whether"
      },
      {
        "start": 1734.679,
        "duration": 4.961,
        "text": "you're using text embeddings or"
      },
      {
        "start": 1736.76,
        "duration": 5.0,
        "text": "multimodal whether you doing Q&A to get"
      },
      {
        "start": 1739.64,
        "duration": 4.36,
        "text": "those captions you know whether you"
      },
      {
        "start": 1741.76,
        "duration": 3.84,
        "text": "actually creating images as well you"
      },
      {
        "start": 1744.0,
        "duration": 3.2,
        "text": "know are you indemnified and those are"
      },
      {
        "start": 1745.6,
        "duration": 4.76,
        "text": "some of the stuff that Google Cloud we"
      },
      {
        "start": 1747.2,
        "duration": 5.56,
        "text": "do with with emif service terms so I"
      },
      {
        "start": 1750.36,
        "duration": 3.919,
        "text": "think I'll leave it at that um hopefully"
      },
      {
        "start": 1752.76,
        "duration": 3.96,
        "text": "that helped some of the folks deploying"
      },
      {
        "start": 1754.279,
        "duration": 5.201,
        "text": "looking to deploy rag into production"
      },
      {
        "start": 1756.72,
        "duration": 5.839,
        "text": "okay it was super helpful and I'll just"
      },
      {
        "start": 1759.48,
        "duration": 5.4,
        "text": "add um so we at datax run a production"
      },
      {
        "start": 1762.559,
        "duration": 6.041,
        "text": "chat bot that uses Gemini um in"
      },
      {
        "start": 1764.88,
        "duration": 5.08,
        "text": "production and really agree with lots of"
      },
      {
        "start": 1768.6,
        "duration": 4.0,
        "text": "the points brought up what's been really"
      },
      {
        "start": 1769.96,
        "duration": 4.839,
        "text": "important for us is um the testing"
      },
      {
        "start": 1772.6,
        "duration": 4.6,
        "text": "aspect that Lance talked about right"
      },
      {
        "start": 1774.799,
        "duration": 4.321,
        "text": "like making sure we get um the right"
      },
      {
        "start": 1777.2,
        "duration": 5.599,
        "text": "responses from the LMS for commonly"
      },
      {
        "start": 1779.12,
        "duration": 5.279,
        "text": "asked questions um and also you know"
      },
      {
        "start": 1782.799,
        "duration": 3.12,
        "text": "yeah you talked a little bit about the"
      },
      {
        "start": 1784.399,
        "duration": 4.0,
        "text": "software development life cycle right"
      },
      {
        "start": 1785.919,
        "duration": 3.88,
        "text": "it's been super important um to really"
      },
      {
        "start": 1788.399,
        "duration": 3.481,
        "text": "make sure we're we're using kind of the"
      },
      {
        "start": 1789.799,
        "duration": 4.401,
        "text": "standard software development like life"
      },
      {
        "start": 1791.88,
        "duration": 4.799,
        "text": "cycle with our prompts right so um we"
      },
      {
        "start": 1794.2,
        "duration": 4.24,
        "text": "store all the versions of our prompts in"
      },
      {
        "start": 1796.679,
        "duration": 5.401,
        "text": "in version control right so we can use"
      },
      {
        "start": 1798.44,
        "duration": 5.52,
        "text": "to kind of you know measure keep track"
      },
      {
        "start": 1802.08,
        "duration": 5.64,
        "text": "of kind of what's changed as we improve"
      },
      {
        "start": 1803.96,
        "duration": 5.719,
        "text": "our body um so awesome guys that was"
      },
      {
        "start": 1807.72,
        "duration": 4.92,
        "text": "really great I I think now we'll get"
      },
      {
        "start": 1809.679,
        "duration": 7.401,
        "text": "into um"
      },
      {
        "start": 1812.64,
        "duration": 8.0,
        "text": "questions okay cool um so first question"
      },
      {
        "start": 1817.08,
        "duration": 6.16,
        "text": "um in the demo I noce you use Gemini"
      },
      {
        "start": 1820.64,
        "duration": 5.44,
        "text": "provision is there any reason you"
      },
      {
        "start": 1823.24,
        "duration": 4.4,
        "text": "couldn't use just Gemini Pro I'm see I"
      },
      {
        "start": 1826.08,
        "duration": 5.0,
        "text": "mean that's probably a good question for"
      },
      {
        "start": 1827.64,
        "duration": 3.44,
        "text": "you I guess what is the difference"
      },
      {
        "start": 1831.919,
        "duration": 7.12,
        "text": "between yeah so so Gemini um Pro is more"
      },
      {
        "start": 1835.64,
        "duration": 5.2,
        "text": "of a text um Foundation model I think"
      },
      {
        "start": 1839.039,
        "duration": 3.801,
        "text": "what you saw in the demo was um Alex"
      },
      {
        "start": 1840.84,
        "duration": 4.4,
        "text": "uploaded an image of a coffee filter I"
      },
      {
        "start": 1842.84,
        "duration": 4.8,
        "text": "think and then uh you know ask questions"
      },
      {
        "start": 1845.24,
        "duration": 4.439,
        "text": "of the and then then and then U was"
      },
      {
        "start": 1847.64,
        "duration": 3.519,
        "text": "doing multim model so that's why he's"
      },
      {
        "start": 1849.679,
        "duration": 3.24,
        "text": "using Gemini provision because that's"
      },
      {
        "start": 1851.159,
        "duration": 4.12,
        "text": "what gem prision does it allows you to"
      },
      {
        "start": 1852.919,
        "duration": 4.0,
        "text": "do things like text from image and text"
      },
      {
        "start": 1855.279,
        "duration": 3.961,
        "text": "from video is the reason why it's doing"
      },
      {
        "start": 1856.919,
        "duration": 2.321,
        "text": "that"
      },
      {
        "start": 1859.279,
        "duration": 6.0,
        "text": "okay got it and you talked a little bit"
      },
      {
        "start": 1861.799,
        "duration": 6.281,
        "text": "about um support from M engages does"
      },
      {
        "start": 1865.279,
        "duration": 4.961,
        "text": "Gemini support uh multilanguage"
      },
      {
        "start": 1868.08,
        "duration": 4.92,
        "text": "embeddings I I can't"
      },
      {
        "start": 1870.24,
        "duration": 5.64,
        "text": "remember well the the the multilanguage"
      },
      {
        "start": 1873.0,
        "duration": 5.48,
        "text": "embeddings comes from you using the the"
      },
      {
        "start": 1875.88,
        "duration": 4.96,
        "text": "the API from and we have a multimodal"
      },
      {
        "start": 1878.48,
        "duration": 5.72,
        "text": "embeddings API we also have an English"
      },
      {
        "start": 1880.84,
        "duration": 5.92,
        "text": "only API uh and the I think the multimod"
      },
      {
        "start": 1884.2,
        "duration": 4.4,
        "text": "embedding supports foreign languages and"
      },
      {
        "start": 1886.76,
        "duration": 4.759,
        "text": "there's a P online there's there's at"
      },
      {
        "start": 1888.6,
        "duration": 4.12,
        "text": "least maybe about 10 or so languages you"
      },
      {
        "start": 1891.519,
        "duration": 2.561,
        "text": "have to look at the page but there's"
      },
      {
        "start": 1892.72,
        "duration": 5.04,
        "text": "there's multiple languages that we"
      },
      {
        "start": 1894.08,
        "duration": 8.16,
        "text": "support um with the multimod embeddings"
      },
      {
        "start": 1897.76,
        "duration": 7.12,
        "text": "yeah got it very cool um what is the"
      },
      {
        "start": 1902.24,
        "duration": 4.919,
        "text": "difference between Lang chain and Lang"
      },
      {
        "start": 1904.88,
        "duration": 6.32,
        "text": "Smith that's probably a good question"
      },
      {
        "start": 1907.159,
        "duration": 6.441,
        "text": "for you yeah so Lang chain is a an open"
      },
      {
        "start": 1911.2,
        "duration": 5.599,
        "text": "source Library package that has support"
      },
      {
        "start": 1913.6,
        "duration": 4.679,
        "text": "for JS as well as python uh that's kind"
      },
      {
        "start": 1916.799,
        "duration": 4.521,
        "text": "of like a application development"
      },
      {
        "start": 1918.279,
        "duration": 5.88,
        "text": "framework for llms and it integrates"
      },
      {
        "start": 1921.32,
        "duration": 4.64,
        "text": "with like 700 different components astb"
      },
      {
        "start": 1924.159,
        "duration": 3.801,
        "text": "being one uh different embedding models"
      },
      {
        "start": 1925.96,
        "duration": 6.199,
        "text": "vertex for example like that PR is in"
      },
      {
        "start": 1927.96,
        "duration": 5.839,
        "text": "progress right now um so um Lang chain"
      },
      {
        "start": 1932.159,
        "duration": 3.201,
        "text": "is kind of like an open source app"
      },
      {
        "start": 1933.799,
        "duration": 2.961,
        "text": "development framework that you can use"
      },
      {
        "start": 1935.36,
        "duration": 4.72,
        "text": "to Stitch things together to build"
      },
      {
        "start": 1936.76,
        "duration": 7.2,
        "text": "different LM applications lsmith is kind"
      },
      {
        "start": 1940.08,
        "duration": 5.88,
        "text": "of an observability tool that does time"
      },
      {
        "start": 1943.96,
        "duration": 4.719,
        "text": "with Lang chain but does not require"
      },
      {
        "start": 1945.96,
        "duration": 4.319,
        "text": "Lang chain and lsmith basically allows"
      },
      {
        "start": 1948.679,
        "duration": 4.84,
        "text": "for monitoring"
      },
      {
        "start": 1950.279,
        "duration": 6.0,
        "text": "evaluation uh so in particular uh when"
      },
      {
        "start": 1953.519,
        "duration": 5.241,
        "text": "you have an application uh it you can"
      },
      {
        "start": 1956.279,
        "duration": 4.081,
        "text": "use it to monitor all the traces so like"
      },
      {
        "start": 1958.76,
        "duration": 3.159,
        "text": "every time the LM is run what goes in"
      },
      {
        "start": 1960.36,
        "duration": 3.679,
        "text": "what goes out what's called if you have"
      },
      {
        "start": 1961.919,
        "duration": 3.921,
        "text": "like a complex chain every cheap in the"
      },
      {
        "start": 1964.039,
        "duration": 4.76,
        "text": "St every step in the chain every input"
      },
      {
        "start": 1965.84,
        "duration": 4.52,
        "text": "output from each step so it's um it's a"
      },
      {
        "start": 1968.799,
        "duration": 3.961,
        "text": "very nice tool for what we call kind of"
      },
      {
        "start": 1970.36,
        "duration": 4.279,
        "text": "monitoring and observability um it has a"
      },
      {
        "start": 1972.76,
        "duration": 3.44,
        "text": "few other things supports valuations as"
      },
      {
        "start": 1974.639,
        "duration": 4.241,
        "text": "mentioned it supports kind of building"
      },
      {
        "start": 1976.2,
        "duration": 4.8,
        "text": "data sets um but that that's kind of"
      },
      {
        "start": 1978.88,
        "duration": 3.84,
        "text": "Lang Smith so it it pairs very well with"
      },
      {
        "start": 1981.0,
        "duration": 4.679,
        "text": "Lang chain but you actually don't need"
      },
      {
        "start": 1982.72,
        "duration": 4.959,
        "text": "to use Lang chain in order to use Langs"
      },
      {
        "start": 1985.679,
        "duration": 4.6,
        "text": "Smith makes"
      },
      {
        "start": 1987.679,
        "duration": 4.761,
        "text": "sense um YY there was another question"
      },
      {
        "start": 1990.279,
        "duration": 4.041,
        "text": "on Gemini I'm curious when there will be"
      },
      {
        "start": 1992.44,
        "duration": 3.52,
        "text": "a way to load PDFs directly in the"
      },
      {
        "start": 1994.32,
        "duration": 3.92,
        "text": "Gemini without the need to split"
      },
      {
        "start": 1995.96,
        "duration": 4.88,
        "text": "documents into pages and load these"
      },
      {
        "start": 1998.24,
        "duration": 2.6,
        "text": "Pages as"
      },
      {
        "start": 2000.96,
        "duration": 7.16,
        "text": "images yeah so that may come when you"
      },
      {
        "start": 2004.679,
        "duration": 6.12,
        "text": "have um supervised tuning of Gemini"
      },
      {
        "start": 2008.12,
        "duration": 4.84,
        "text": "provision uh you know you know cuz right"
      },
      {
        "start": 2010.799,
        "duration": 3.921,
        "text": "right now if you tune in a model right"
      },
      {
        "start": 2012.96,
        "duration": 3.92,
        "text": "you typically have to create the JNL"
      },
      {
        "start": 2014.72,
        "duration": 3.959,
        "text": "format which means chunking the data and"
      },
      {
        "start": 2016.88,
        "duration": 3.799,
        "text": "all that stuff but I think the question"
      },
      {
        "start": 2018.679,
        "duration": 5.321,
        "text": "is probably looking at when you will be"
      },
      {
        "start": 2020.679,
        "duration": 5.801,
        "text": "able to supervise tune uh a a Gemini"
      },
      {
        "start": 2024.0,
        "duration": 3.799,
        "text": "provision for example yeah and so so"
      },
      {
        "start": 2026.48,
        "duration": 3.559,
        "text": "that when that comes that that would be"
      },
      {
        "start": 2027.799,
        "duration": 3.6,
        "text": "probably when um folks able to do"
      },
      {
        "start": 2030.039,
        "duration": 4.721,
        "text": "something like"
      },
      {
        "start": 2031.399,
        "duration": 5.801,
        "text": "that got it and um Lance I gu question"
      },
      {
        "start": 2034.76,
        "duration": 4.799,
        "text": "for you so we heavily use the um link CH"
      },
      {
        "start": 2037.2,
        "duration": 5.079,
        "text": "recursive text splitter for for like"
      },
      {
        "start": 2039.559,
        "duration": 4.761,
        "text": "text chunking is there any sort of text"
      },
      {
        "start": 2042.279,
        "duration": 3.36,
        "text": "splitting functionality in linke chain"
      },
      {
        "start": 2044.32,
        "duration": 3.16,
        "text": "for"
      },
      {
        "start": 2045.639,
        "duration": 3.28,
        "text": "images or is that something you guys"
      },
      {
        "start": 2047.48,
        "duration": 4.679,
        "text": "have thought"
      },
      {
        "start": 2048.919,
        "duration": 4.881,
        "text": "about interesting what do you mean by"
      },
      {
        "start": 2052.159,
        "duration": 3.121,
        "text": "that how do you think about like split"
      },
      {
        "start": 2053.8,
        "duration": 3.68,
        "text": "what do you mean by splitting"
      },
      {
        "start": 2055.28,
        "duration": 4.72,
        "text": "images I guess this kind of question"
      },
      {
        "start": 2057.48,
        "duration": 5.76,
        "text": "here is there a way to does Ling Chan"
      },
      {
        "start": 2060.0,
        "duration": 8.599,
        "text": "have a way to break a PDF into multiple"
      },
      {
        "start": 2063.24,
        "duration": 7.879,
        "text": "pages okay so good point uh so yeah in"
      },
      {
        "start": 2068.599,
        "duration": 4.32,
        "text": "in in a lot My Demo FS I we've not done"
      },
      {
        "start": 2071.119,
        "duration": 4.201,
        "text": "integration but there are a number of"
      },
      {
        "start": 2072.919,
        "duration": 5.081,
        "text": "different packages out there that take a"
      },
      {
        "start": 2075.32,
        "duration": 5.599,
        "text": "PDF and split into a bunch of images uh"
      },
      {
        "start": 2078.0,
        "duration": 6.119,
        "text": "I can look up what I use I think it's a"
      },
      {
        "start": 2080.919,
        "duration": 8.96,
        "text": "uh let me check my code here L right now"
      },
      {
        "start": 2084.119,
        "duration": 8.76,
        "text": "um we use um check the injust script"
      },
      {
        "start": 2089.879,
        "duration": 3.0,
        "text": "here"
      },
      {
        "start": 2095.879,
        "duration": 3.561,
        "text": "um"
      },
      {
        "start": 2097.53,
        "duration": 4.67,
        "text": "[Music]"
      },
      {
        "start": 2099.44,
        "duration": 5.679,
        "text": "um maybe go to the next question I will"
      },
      {
        "start": 2102.2,
        "duration": 6.36,
        "text": "find it"
      },
      {
        "start": 2105.119,
        "duration": 6.921,
        "text": "uh sounds good um what is the process to"
      },
      {
        "start": 2108.56,
        "duration": 6.08,
        "text": "migrate from um Google models like text"
      },
      {
        "start": 2112.04,
        "duration": 5.12,
        "text": "Bon to Gemini I can take that one"
      },
      {
        "start": 2114.64,
        "duration": 4.32,
        "text": "actually um so we actually just did this"
      },
      {
        "start": 2117.16,
        "duration": 4.48,
        "text": "at data tax for one of our production"
      },
      {
        "start": 2118.96,
        "duration": 6.08,
        "text": "chat Bots um with tools like Lane chain"
      },
      {
        "start": 2121.64,
        "duration": 5.4,
        "text": "it's very very simple to migrate models"
      },
      {
        "start": 2125.04,
        "duration": 6.4,
        "text": "um it was as simple as kind of just"
      },
      {
        "start": 2127.04,
        "duration": 7.0,
        "text": "switching the the model name and um like"
      },
      {
        "start": 2131.44,
        "duration": 4.639,
        "text": "we were up and running very very"
      },
      {
        "start": 2134.04,
        "duration": 4.16,
        "text": "quickly and I don't know if there's a"
      },
      {
        "start": 2136.079,
        "duration": 4.0,
        "text": "there's a way to post links on the um on"
      },
      {
        "start": 2138.2,
        "duration": 4.28,
        "text": "but there is a actual page that's TI"
      },
      {
        "start": 2140.079,
        "duration": 5.161,
        "text": "entitled titled migrate from pal API to"
      },
      {
        "start": 2142.48,
        "duration": 4.599,
        "text": "Gemini API on Vex AI so if you go online"
      },
      {
        "start": 2145.24,
        "duration": 4.2,
        "text": "and just perhaps just put that search in"
      },
      {
        "start": 2147.079,
        "duration": 3.801,
        "text": "Google it no pun inet you should you"
      },
      {
        "start": 2149.44,
        "duration": 2.56,
        "text": "should land that page that gives you"
      },
      {
        "start": 2150.88,
        "duration": 3.479,
        "text": "instructions and I think there's"
      },
      {
        "start": 2152.0,
        "duration": 4.2,
        "text": "probably even code side by side code"
      },
      {
        "start": 2154.359,
        "duration": 5.121,
        "text": "that shows you uh what changes are"
      },
      {
        "start": 2156.2,
        "duration": 5.08,
        "text": "between pal and Gemini so yeah that's"
      },
      {
        "start": 2159.48,
        "duration": 4.639,
        "text": "what there on the public"
      },
      {
        "start": 2161.28,
        "duration": 4.88,
        "text": "Ducks yeah one F on the prior question"
      },
      {
        "start": 2164.119,
        "duration": 4.681,
        "text": "look at"
      },
      {
        "start": 2166.16,
        "duration": 3.64,
        "text": "pdfium that's one if you just Google"
      },
      {
        "start": 2168.8,
        "duration": 2.44,
        "text": "there's a bunch of them but basically"
      },
      {
        "start": 2169.8,
        "duration": 2.799,
        "text": "going from a PDF to a bunch of images"
      },
      {
        "start": 2171.24,
        "duration": 2.56,
        "text": "there's a bunch of good stuff out there"
      },
      {
        "start": 2172.599,
        "duration": 2.441,
        "text": "we haven't actually integrated with Lang"
      },
      {
        "start": 2173.8,
        "duration": 2.76,
        "text": "chain it seems like kind of just like an"
      },
      {
        "start": 2175.04,
        "duration": 3.92,
        "text": "unnecessary wrapper around like a very"
      },
      {
        "start": 2176.56,
        "duration": 4.36,
        "text": "simple to use component although you"
      },
      {
        "start": 2178.96,
        "duration": 4.44,
        "text": "know maybe it is worth just pulling it"
      },
      {
        "start": 2180.92,
        "duration": 6.76,
        "text": "in so it's there's some consistency"
      },
      {
        "start": 2183.4,
        "duration": 5.76,
        "text": "around how you call it um yeah"
      },
      {
        "start": 2187.68,
        "duration": 3.28,
        "text": "that's one I"
      },
      {
        "start": 2189.16,
        "duration": 4.76,
        "text": "use"
      },
      {
        "start": 2190.96,
        "duration": 5.119,
        "text": "awesome cool um well that was all of the"
      },
      {
        "start": 2193.92,
        "duration": 5.439,
        "text": "questions um thank you everyone oh"
      },
      {
        "start": 2196.079,
        "duration": 5.801,
        "text": "actually one more just came in sorry are"
      },
      {
        "start": 2199.359,
        "duration": 5.361,
        "text": "there any plans on Gemini timeline for"
      },
      {
        "start": 2201.88,
        "duration": 6.199,
        "text": "assistance like opening eye has with"
      },
      {
        "start": 2204.72,
        "duration": 3.359,
        "text": "that with Astro DB it would be"
      },
      {
        "start": 2208.24,
        "duration": 5.4,
        "text": "interesting uh for"
      },
      {
        "start": 2210.64,
        "duration": 3.0,
        "text": "assistance"
      },
      {
        "start": 2215.079,
        "duration": 9.081,
        "text": "um I is"
      },
      {
        "start": 2218.52,
        "duration": 8.48,
        "text": "um are there any plans for um Gemini to"
      },
      {
        "start": 2224.16,
        "duration": 5.12,
        "text": "build some sort of kind of easy way to"
      },
      {
        "start": 2227.0,
        "duration": 4.119,
        "text": "build assistance like uh open AI"
      },
      {
        "start": 2229.28,
        "duration": 4.68,
        "text": "recently released this assistance API"
      },
      {
        "start": 2231.119,
        "duration": 6.801,
        "text": "which is sort of like a very easy to"
      },
      {
        "start": 2233.96,
        "duration": 5.68,
        "text": "configure kind of chatbot type thing I"
      },
      {
        "start": 2237.92,
        "duration": 5.64,
        "text": "think the closest thing to what Google"
      },
      {
        "start": 2239.64,
        "duration": 6.479,
        "text": "is doing is um like the vertex AI search"
      },
      {
        "start": 2243.56,
        "duration": 5.519,
        "text": "um yeah no yeah so I get it I get it so"
      },
      {
        "start": 2246.119,
        "duration": 5.561,
        "text": "we we have something called uh verix AI"
      },
      {
        "start": 2249.079,
        "duration": 4.24,
        "text": "uh conversation conversation AI which if"
      },
      {
        "start": 2251.68,
        "duration": 3.76,
        "text": "some of the folks are familiar you know"
      },
      {
        "start": 2253.319,
        "duration": 4.201,
        "text": "they they used to read they still is a"
      },
      {
        "start": 2255.44,
        "duration": 5.0,
        "text": "solution called dialog flow so the"
      },
      {
        "start": 2257.52,
        "duration": 4.68,
        "text": "evolution of that um adding gen to that"
      },
      {
        "start": 2260.44,
        "duration": 4.28,
        "text": "is now called conversation AI so that's"
      },
      {
        "start": 2262.2,
        "duration": 4.919,
        "text": "a solution for building kind of a"
      },
      {
        "start": 2264.72,
        "duration": 4.56,
        "text": "Enterprise grade chat Bots uh you know"
      },
      {
        "start": 2267.119,
        "duration": 3.881,
        "text": "if you wanted a a manage Solution that's"
      },
      {
        "start": 2269.28,
        "duration": 3.4,
        "text": "already got a lot of the bells and"
      },
      {
        "start": 2271.0,
        "duration": 4.0,
        "text": "whistles and you just need to customize"
      },
      {
        "start": 2272.68,
        "duration": 4.28,
        "text": "it maybe do some extensions for your"
      },
      {
        "start": 2275.0,
        "duration": 4.8,
        "text": "particular use case then you can use"
      },
      {
        "start": 2276.96,
        "duration": 4.08,
        "text": "that conversational AI um solution and"
      },
      {
        "start": 2279.8,
        "duration": 3.0,
        "text": "and I think there'll be there probably"
      },
      {
        "start": 2281.04,
        "duration": 4.4,
        "text": "notebooks out there that show you how to"
      },
      {
        "start": 2282.8,
        "duration": 4.519,
        "text": "um build applications around there but"
      },
      {
        "start": 2285.44,
        "duration": 3.84,
        "text": "but also recognize that the language"
      },
      {
        "start": 2287.319,
        "duration": 4.561,
        "text": "model themselves also support the chat"
      },
      {
        "start": 2289.28,
        "duration": 4.28,
        "text": "interface so you can use something like"
      },
      {
        "start": 2291.88,
        "duration": 3.0,
        "text": "um and I think you use that in your code"
      },
      {
        "start": 2293.56,
        "duration": 3.96,
        "text": "right you can use something like the"
      },
      {
        "start": 2294.88,
        "duration": 4.36,
        "text": "Lang chain chat apis to make a call to"
      },
      {
        "start": 2297.52,
        "duration": 3.839,
        "text": "the language model and then kind of have"
      },
      {
        "start": 2299.24,
        "duration": 3.68,
        "text": "that multi-tone conversation going"
      },
      {
        "start": 2301.359,
        "duration": 2.841,
        "text": "around your use case because most most"
      },
      {
        "start": 2302.92,
        "duration": 2.64,
        "text": "likely if you're building chat you're"
      },
      {
        "start": 2304.2,
        "duration": 4.0,
        "text": "probably going to embed into some kind"
      },
      {
        "start": 2305.56,
        "duration": 5.0,
        "text": "of UI within your prise so you've got"
      },
      {
        "start": 2308.2,
        "duration": 4.84,
        "text": "those options either you kind of um"
      },
      {
        "start": 2310.56,
        "duration": 4.36,
        "text": "white label a conversational Ai and"
      },
      {
        "start": 2313.04,
        "duration": 3.84,
        "text": "search solution if you looking for"
      },
      {
        "start": 2314.92,
        "duration": 3.439,
        "text": "manage solution but if you think you"
      },
      {
        "start": 2316.88,
        "duration": 3.4,
        "text": "want to roll your own then you can use"
      },
      {
        "start": 2318.359,
        "duration": 3.96,
        "text": "something like Lan chain you can use our"
      },
      {
        "start": 2320.28,
        "duration": 4.76,
        "text": "API course for a language model and kind"
      },
      {
        "start": 2322.319,
        "duration": 4.081,
        "text": "of use our chat Foundation models and"
      },
      {
        "start": 2325.04,
        "duration": 3.799,
        "text": "then you know kind of roll your own mul"
      },
      {
        "start": 2326.4,
        "duration": 4.16,
        "text": "toone conversation around the chat"
      },
      {
        "start": 2328.839,
        "duration": 4.401,
        "text": "application"
      },
      {
        "start": 2330.56,
        "duration": 6.36,
        "text": "yeah awesome we actually just got a lot"
      },
      {
        "start": 2333.24,
        "duration": 6.24,
        "text": "more questions also um this one is for"
      },
      {
        "start": 2336.92,
        "duration": 4.56,
        "text": "you Lance do you this will be a fun"
      },
      {
        "start": 2339.48,
        "duration": 3.44,
        "text": "question do you find it's a performance"
      },
      {
        "start": 2341.48,
        "duration": 3.72,
        "text": "question do you find Lane chain to be"
      },
      {
        "start": 2342.92,
        "duration": 5.12,
        "text": "slower for executing similar steps"
      },
      {
        "start": 2345.2,
        "duration": 2.84,
        "text": "compared to custom"
      },
      {
        "start": 2348.839,
        "duration": 4.681,
        "text": "code I haven't actually tested latency"
      },
      {
        "start": 2351.48,
        "duration": 5.359,
        "text": "Lang Chain versus just like hitting raw"
      },
      {
        "start": 2353.52,
        "duration": 5.16,
        "text": "for example open API so I can't honestly"
      },
      {
        "start": 2356.839,
        "duration": 4.721,
        "text": "answer that"
      },
      {
        "start": 2358.68,
        "duration": 4.32,
        "text": "um if if someone has links to"
      },
      {
        "start": 2361.56,
        "duration": 3.519,
        "text": "documentation that's like looked into"
      },
      {
        "start": 2363.0,
        "duration": 4.599,
        "text": "that I'd be curious It's not obvious to"
      },
      {
        "start": 2365.079,
        "duration": 4.681,
        "text": "me that Lang chain add significant"
      },
      {
        "start": 2367.599,
        "duration": 3.801,
        "text": "latency I think the bigger question is"
      },
      {
        "start": 2369.76,
        "duration": 3.04,
        "text": "kind of like the latency typically more"
      },
      {
        "start": 2371.4,
        "duration": 3.52,
        "text": "comes from for example hitting Vector"
      },
      {
        "start": 2372.8,
        "duration": 5.92,
        "text": "DBS what Vector DB integration you're"
      },
      {
        "start": 2374.92,
        "duration": 5.24,
        "text": "using um that's kind of where I've seen"
      },
      {
        "start": 2378.72,
        "duration": 3.72,
        "text": "or most of the latency comes from like"
      },
      {
        "start": 2380.16,
        "duration": 3.679,
        "text": "the API itself so it's not clear that"
      },
      {
        "start": 2382.44,
        "duration": 4.08,
        "text": "kind of having Lang chain in the middle"
      },
      {
        "start": 2383.839,
        "duration": 4.52,
        "text": "really adds significant latency to to a"
      },
      {
        "start": 2386.52,
        "duration": 4.799,
        "text": "chain uh it's really kind of the"
      },
      {
        "start": 2388.359,
        "duration": 5.801,
        "text": "retrieval step as well as the um you"
      },
      {
        "start": 2391.319,
        "duration": 5.241,
        "text": "know the the the language model API"
      },
      {
        "start": 2394.16,
        "duration": 3.76,
        "text": "itself but if there's some interesting"
      },
      {
        "start": 2396.56,
        "duration": 2.88,
        "text": "like feel free to put in the chat if"
      },
      {
        "start": 2397.92,
        "duration": 3.76,
        "text": "there's interesting like references"
      },
      {
        "start": 2399.44,
        "duration": 4.56,
        "text": "you've seen or any like posts on that"
      },
      {
        "start": 2401.68,
        "duration": 2.32,
        "text": "I'd be"
      },
      {
        "start": 2405.28,
        "duration": 4.64,
        "text": "curious"
      },
      {
        "start": 2407.4,
        "duration": 4.0,
        "text": "to sorry excuse me and and the last"
      },
      {
        "start": 2409.92,
        "duration": 3.88,
        "text": "question is what is the best way to"
      },
      {
        "start": 2411.4,
        "duration": 4.439,
        "text": "learn fundamental concepts of rag"
      },
      {
        "start": 2413.8,
        "duration": 4.16,
        "text": "pattern and components in rag pattern"
      },
      {
        "start": 2415.839,
        "duration": 3.841,
        "text": "like Factory DBS embeddings and things"
      },
      {
        "start": 2417.96,
        "duration": 4.2,
        "text": "like this for a regular software"
      },
      {
        "start": 2419.68,
        "duration": 4.32,
        "text": "developer um yeah so we can pull"
      },
      {
        "start": 2422.16,
        "duration": 3.8,
        "text": "together some good links and also follow"
      },
      {
        "start": 2424.0,
        "duration": 4.68,
        "text": "up with this as well Google has a lot of"
      },
      {
        "start": 2425.96,
        "duration": 4.28,
        "text": "content this um linkchain has a lot of"
      },
      {
        "start": 2428.68,
        "duration": 3.8,
        "text": "good content on this we also created a"
      },
      {
        "start": 2430.24,
        "duration": 4.4,
        "text": "bunch of content it's way easier than"
      },
      {
        "start": 2432.48,
        "duration": 3.52,
        "text": "you think to start building brag Ops"
      },
      {
        "start": 2434.64,
        "duration": 3.719,
        "text": "with some of the awesome technology"
      },
      {
        "start": 2436.0,
        "duration": 2.359,
        "text": "available"
      },
      {
        "start": 2439.92,
        "duration": 5.52,
        "text": "today okay cool um well thank you"
      },
      {
        "start": 2443.119,
        "duration": 3.96,
        "text": "everyone I'm really apprciate Alex there"
      },
      {
        "start": 2445.44,
        "duration": 4.639,
        "text": "was a I think there was a question on"
      },
      {
        "start": 2447.079,
        "duration": 5.04,
        "text": "the Q&A some gentleman by the name of"
      },
      {
        "start": 2450.079,
        "duration": 3.28,
        "text": "Katic first time ktic asked the question"
      },
      {
        "start": 2452.119,
        "duration": 3.881,
        "text": "will you be covering ey level"
      },
      {
        "start": 2453.359,
        "duration": 4.96,
        "text": "architecture for Enterprise gen I mean"
      },
      {
        "start": 2456.0,
        "duration": 4.079,
        "text": "while we don't have a diagram showing"
      },
      {
        "start": 2458.319,
        "duration": 3.561,
        "text": "that right I think some of the content"
      },
      {
        "start": 2460.079,
        "duration": 3.841,
        "text": "that we covered there you know talking"
      },
      {
        "start": 2461.88,
        "duration": 3.239,
        "text": "about the unique challenges talking"
      },
      {
        "start": 2463.92,
        "duration": 3.0,
        "text": "about you know some of the things you"
      },
      {
        "start": 2465.119,
        "duration": 3.361,
        "text": "need to look at when you're deploying uh"
      },
      {
        "start": 2466.92,
        "duration": 2.76,
        "text": "a rag application into production"
      },
      {
        "start": 2468.48,
        "duration": 3.48,
        "text": "hopefully that gave you some of the"
      },
      {
        "start": 2469.68,
        "duration": 4.2,
        "text": "content that you can use to build an"
      },
      {
        "start": 2471.96,
        "duration": 4.72,
        "text": "high Lev architecture for for Enterprise"
      },
      {
        "start": 2473.88,
        "duration": 4.32,
        "text": "gen so you know hopefully we were able"
      },
      {
        "start": 2476.68,
        "duration": 3.04,
        "text": "to cover some of the content for that"
      },
      {
        "start": 2478.2,
        "duration": 4.04,
        "text": "while while we didn't have a diagram to"
      },
      {
        "start": 2479.72,
        "duration": 5.52,
        "text": "show you on on a high level architecture"
      },
      {
        "start": 2482.24,
        "duration": 5.839,
        "text": "okay over to you"
      },
      {
        "start": 2485.24,
        "duration": 4.24,
        "text": "Alex oh we just got another question I"
      },
      {
        "start": 2488.079,
        "duration": 3.921,
        "text": "should stop saying this is our last"
      },
      {
        "start": 2489.48,
        "duration": 5.28,
        "text": "question do you have recommendations for"
      },
      {
        "start": 2492.0,
        "duration": 6.599,
        "text": "capturing embeddings from existing web-"
      },
      {
        "start": 2494.76,
        "duration": 5.64,
        "text": "based Assets in an automated way um I"
      },
      {
        "start": 2498.599,
        "duration": 4.401,
        "text": "think both Google and blank chain have"
      },
      {
        "start": 2500.4,
        "duration": 5.679,
        "text": "good Solutions um for this um y do you"
      },
      {
        "start": 2503.0,
        "duration": 4.28,
        "text": "maybe want to say yeah that's a great"
      },
      {
        "start": 2506.079,
        "duration": 2.921,
        "text": "great question because that was one of"
      },
      {
        "start": 2507.28,
        "duration": 5.2,
        "text": "that was the use case I mentioned about"
      },
      {
        "start": 2509.0,
        "duration": 5.92,
        "text": "extracting um text from images ex"
      },
      {
        "start": 2512.48,
        "duration": 5.0,
        "text": "exactly that you can use the uh Gemini"
      },
      {
        "start": 2514.92,
        "duration": 4.72,
        "text": "provision uh you know the apis that you"
      },
      {
        "start": 2517.48,
        "duration": 6.119,
        "text": "can call um you can actually start by"
      },
      {
        "start": 2519.64,
        "duration": 5.84,
        "text": "just taking one of those um uh UI and"
      },
      {
        "start": 2523.599,
        "duration": 4.281,
        "text": "upload them and just say extract the"
      },
      {
        "start": 2525.48,
        "duration": 4.76,
        "text": "fields from this image or create me an"
      },
      {
        "start": 2527.88,
        "duration": 4.16,
        "text": "HTML from this image you know and and"
      },
      {
        "start": 2530.24,
        "duration": 3.48,
        "text": "you can see the response that comes out"
      },
      {
        "start": 2532.04,
        "duration": 3.24,
        "text": "and then once you have that and once you"
      },
      {
        "start": 2533.72,
        "duration": 3.0,
        "text": "figure out what prompts you need to get"
      },
      {
        "start": 2535.28,
        "duration": 3.2,
        "text": "the right level of detail you're looking"
      },
      {
        "start": 2536.72,
        "duration": 3.28,
        "text": "for then you can then probably look at"
      },
      {
        "start": 2538.48,
        "duration": 3.079,
        "text": "some some of the notebooks we have and"
      },
      {
        "start": 2540.0,
        "duration": 3.88,
        "text": "actually use that to actually build out"
      },
      {
        "start": 2541.559,
        "duration": 4.0,
        "text": "the to automate that process so most"
      },
      {
        "start": 2543.88,
        "duration": 3.719,
        "text": "likely you have a bucket of images and"
      },
      {
        "start": 2545.559,
        "duration": 3.321,
        "text": "then you just each through that and and"
      },
      {
        "start": 2547.599,
        "duration": 3.121,
        "text": "get the caption and then store it"
      },
      {
        "start": 2548.88,
        "duration": 3.92,
        "text": "somewhere so so yes you can do that with"
      },
      {
        "start": 2550.72,
        "duration": 4.24,
        "text": "Gemini provision for sure and also you"
      },
      {
        "start": 2552.8,
        "duration": 4.72,
        "text": "can do that with um I know this has been"
      },
      {
        "start": 2554.96,
        "duration": 4.599,
        "text": "a lot about Gemini but also Imagine to"
      },
      {
        "start": 2557.52,
        "duration": 3.72,
        "text": "which you can also do for visual Q&A as"
      },
      {
        "start": 2559.559,
        "duration": 3.0,
        "text": "well and captioning that actually has a"
      },
      {
        "start": 2561.24,
        "duration": 3.44,
        "text": "captioning functionality that you can"
      },
      {
        "start": 2562.559,
        "duration": 4.04,
        "text": "also use know you can do that to the UI"
      },
      {
        "start": 2564.68,
        "duration": 4.679,
        "text": "just to test it but also you can also"
      },
      {
        "start": 2566.599,
        "duration": 4.081,
        "text": "use the apis through a notebook um in"
      },
      {
        "start": 2569.359,
        "duration": 5.401,
        "text": "python or whatever language of choice"
      },
      {
        "start": 2570.68,
        "duration": 4.08,
        "text": "you have to to automate the process as"
      },
      {
        "start": 2575.16,
        "duration": 4.679,
        "text": "well"
      },
      {
        "start": 2577.319,
        "duration": 4.681,
        "text": "L did you also have some thoughts I know"
      },
      {
        "start": 2579.839,
        "duration": 3.561,
        "text": "um link chain does a really nice job of"
      },
      {
        "start": 2582.0,
        "duration": 3.079,
        "text": "some of that with like the document"
      },
      {
        "start": 2583.4,
        "duration": 3.0,
        "text": "loaders that integrate with like"
      },
      {
        "start": 2585.079,
        "duration": 3.921,
        "text": "scraping"
      },
      {
        "start": 2586.4,
        "duration": 4.32,
        "text": "tools yeah there there's a definitely a"
      },
      {
        "start": 2589.0,
        "duration": 4.599,
        "text": "large number of document loaders I can"
      },
      {
        "start": 2590.72,
        "duration": 8.16,
        "text": "share kind of our Integrations Hub"
      },
      {
        "start": 2593.599,
        "duration": 8.921,
        "text": "um uh I'll share that right now um and"
      },
      {
        "start": 2598.88,
        "duration": 5.439,
        "text": "there are a good number of different uh"
      },
      {
        "start": 2602.52,
        "duration": 5.559,
        "text": "document loaders for web content for"
      },
      {
        "start": 2604.319,
        "duration": 3.76,
        "text": "sure I shared that"
      },
      {
        "start": 2608.72,
        "duration": 5.28,
        "text": "oh we got see we're capturing embeddings"
      },
      {
        "start": 2611.76,
        "duration": 6.599,
        "text": "from existing web base assets and"
      },
      {
        "start": 2614.0,
        "duration": 8.119,
        "text": "automated way yeah"
      },
      {
        "start": 2618.359,
        "duration": 5.441,
        "text": "um I'll maybe highlight one or two uh"
      },
      {
        "start": 2622.119,
        "duration": 6.641,
        "text": "you know structured URL loader is pretty"
      },
      {
        "start": 2623.8,
        "duration": 7.08,
        "text": "good um I like that one I'll share"
      },
      {
        "start": 2628.76,
        "duration": 5.28,
        "text": "that"
      },
      {
        "start": 2630.88,
        "duration": 3.16,
        "text": "um what"
      },
      {
        "start": 2635.079,
        "duration": 3.0,
        "text": "else"
      },
      {
        "start": 2645.76,
        "duration": 7.0,
        "text": "yep that's good for now I"
      },
      {
        "start": 2649.52,
        "duration": 5.88,
        "text": "think awesome um well looks like we're"
      },
      {
        "start": 2652.76,
        "duration": 4.0,
        "text": "out of time um thank you everyone for"
      },
      {
        "start": 2655.4,
        "duration": 3.719,
        "text": "joining we'll definitely share all these"
      },
      {
        "start": 2656.76,
        "duration": 4.2,
        "text": "resources we mentioned afterwards um and"
      },
      {
        "start": 2659.119,
        "duration": 4.0,
        "text": "if you have any questions um send them"
      },
      {
        "start": 2660.96,
        "duration": 5.76,
        "text": "our way um we'll continue en those be"
      },
      {
        "start": 2663.119,
        "duration": 7.081,
        "text": "email awesome thanks everyone"
      },
      {
        "start": 2666.72,
        "duration": 3.48,
        "text": "thank you and"
      },
      {
        "start": 2676.839,
        "duration": 3.0,
        "text": "bye"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T17:25:32.519972+00:00"
}