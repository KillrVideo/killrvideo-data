{
  "video_id": "6AT8lG8SOpE",
  "title": "GenAI 101: What is RAG?",
  "description": "Curious about RAG (retrieval augmented generation) and how to use it?\r\n\r\nJoin DataStax for a 45-minute deep dive livestream where we'll cover the fundamentals of RAG and show you how to integrate it into your next GenAI app. \r\n\r\nIn this session, we will discuss:\r\n--What RAG is and its benefits\r\n--Basic code examples to get started with RAG\r\n--Code snippets for utilizing RAG in a chatbot application\n\nRESOURCES:\nSign up for Astra: https://astra.datastax.com/signup\nSign up for Langflow: https://astra.datastax.com/signup?type=langflow\nColab GenAI: https://colab.research.google.com/drive/19O1MR_fvk8FoKAe_FszjKMEZDwbuR4pN\nChunking Blog Post: https://bit.ly/3YIXCTf\n\nAbout DataStax Developer:\r\nOn the DataStax Developers YouTube channel, you can find tutorials, workshops and much more to help you learn and stay updated with the latest information on Apache CassandraÂ©.  Visit https://datastax.com/dev for more free learning resources.",
  "published_at": "2024-08-14T06:06:36Z",
  "thumbnail": "https://i.ytimg.com/vi/6AT8lG8SOpE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "search",
    "workshop",
    "datastax",
    "astra",
    "tutorial",
    "cassandra",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=6AT8lG8SOpE",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "sorry I'm we're kind of laughing here on the call because the the folks in the chat here on crowdcast gave us the countdown yeah um like I might I might have been inclined to like start like a couple minutes late you know like let the stragglers show up for the stream but people here were like they were like literally like giving us like the 20 seconds the 10 seconds and go um so uh so yeah so thanks for that thanks for the motivation um awesome well uh look welcome welcome to uh to this live stream um welcome to all folks who are here on crowdcast uh and everyone who is watching um on Twitter uh I guess some people call it X but I'm going to call it Twitter uh or watching on LinkedIn um this is being multicast to a bunch of different plac places because we want to be wherever developers are and developers are kind of scattered all over the place uh so quick uh quick agenda um this this conversation and we'd love for this to be a conversation and I'll talk more about that in a little bit is just we're we're going to spend some time talking about what is what is rag um so this is a little bit of a rag 101 talk uh the if you are a if you're if you a developer and you don't feel like you you know what rag is um or you don't feel super grounded uh in in the topic uh this is a fantastic stream for you to uh to participate in um I want to be super clear that uh you don't need to have any machine learning or data science uh expertise or knowledge uh to to sort of get value um out of this conversation in fact that's we'll sort of learn about this later but one of the things that's awesome about rag is that it makes building AI applications accessible to all kinds of developers all kinds of full stack developers uh and it really removes the need to have deep deep uh expertise um or experience with machine learning or data science um so yeah so we're going to talk a little bit about what is rag um we're going to dive into uh llms like what it looks like to work programmatically with an llm uh without using rag uh and what it looks like to work with an llm when you do use Rag and like what's awesome about that uh then we're going to dive into rag specifically using um an open source product called langlow um which uh is a an awesome Tool uh it just makes it really fast and easy to build uh AI applications uh and then we're going to turn it over to Q&A um so uh a couple couple bits of bits of housekeeping um for folks that are here on crowdcast um if you haven't joined us on a crowdcast live stream welcome thank you for coming um if you've been here before then this will be old news to you uh but you'll notice that in the top right of your screen uh is a Q&A uh widget um so as we're going through through today's live stream um if you have any questions about what we're talking about or concepts that we're discussing um please ask ask those questions in that Q&A widget and we're going to monitor these questions as they come in um and you'll also notice that kind of like Reddit or Hacker News you can you can vote up uh questions um that you see so like if you go to the Q&A widget and somebody has asked a question that you think is a great question and you would also like to know the answer to that question please vote up that question um and we'll we'll kind of we'll kind of see how it goes like we may get to some of these questions like in real time as the live stream is happening um or and we will also have like a nice Q&A segment on the back end of this live stream so we make sure to get through folks uh questions um I wanted to remind everybody uh because this question comes up a lot like this is this live stream is being recorded um and it's going to be available for everybody publicly uh after the live stream is over um and we're going to send an email to everyone who Jo joined us uh with a link to this recorded to the recording of This live stream along with like links to resources that we're sharing like we're going to show you guys a bunch of uh you know code code uh code notebooks uh repos like all the resources that we review like in this live stream we'll make sure to share them um as an email after the fact so uh so who who is on this live stream so uh I'm uh we're going to go around the horn uh and and introduce ourselves uh and I have uh in addition to sort of the basics like you know what's your name where do you live uh what do you do um I I always ask everyone who's on on on one of these streams kind of like a fun personal question and David and Alex have not been have not been given access to this I've not told them what this question is so they're they're going to be as surprised as you when I ask it um I'm going to have uh so I'll go last um so so I'm going to start with David um so like obviously like tell us maybe where you're located what do you do and then um the uh the the fun getting to no David question for everybody is um are you a Marvel person or a DC person fun well well hello everybody and again thank you for joining um I'm David Jones gelardi I'm in Orlando Florida and the United States um so for those of you who are not familiar with it uh you or you may be familiar with you know Disney World or Universal like all of the parks and things like that are here um and I've been you know I'm a developer relation engineer um I've been coding in various languages and doing databases for off 30 years and in a lot of different uh areas and defense and things like that and these days I'm a gen nerd really um I'm I'm focusing on Python and I'm just you know uh having fun with all of the Gen stuff now to your question Carter uh man you know I gotta say Marvel I I would say though if you I I'm going to start with that but I'm going to preface it with when we're talking about the movies I think Marvel's really done a spectacular job compared to DC but when we're talking about the comics bit different and that's that's I don't have just a straight up I like this one better or the other I was always a fan of both but movies wise I go for Marvel all right fantastic okay so now we're gonna uh and by the way I'll explain why I'm asking this question later uh so I'm gonna turn turn it over to uh my friend Alex I'm Alex I am a Marvel gu um I'm based in Seattle and I lead our developer ecosystem team building geni Integrations that um we'll show you a little bit of in a bit or would you awesome thanks all right my name is Carter rasa uh I work with David on the developer relations team here at data stack uh like Alex I am located in Seattle Washington and the reason I asked the question was because I took uh my kids to go see Deadpool versus Wolverine this past weekend so this is sort of top of mind for me uh however uh I'm gonna cheat and say neither uh I'm a Darkhorse guy um that obviously that that that's a comment about the comics right um but it also applies to Fantastic movies that have been made based on Darkhorse material so sorry Tri trick question you're both wrong the answer is darkh okay so hey thanks for bearing by the way and also if you're in the chat feel free to share where you're ding in from it's Al it's always just amazing for us to see um all the different places uh that uh that developers uh live and and kind of uh and and sort of dial in from I'm sorry that I'm using the word dial in but I'm 46 years old and I remember modems and stuff uh all right so let let's dive into it uh we've got you know that was eight eight minutes eight minutes of Preamble and we're gonna we're gonna dive into code super fast so this is a rag 101 talk so the first thing that's worth talking about is uh what does rag even mean right uh so rag is an acronym uh it stands for retrieval augmented generation um we're going to go into more detail about specifically what this means and specifically how does it work um but I'd like to sort of I just I like to when I when I try to explain rag to someone who is unfamiliar with it um the way that I explain it is I go backwards so I say because you because just the words in This Acronym are not self-explanatory right it doesn't really tell you what what's happening right the way that I think about it is generation is what you get uh working with an L M uh with like with with no no tailoring um or no prompt engineering no nothing it's kind of a chat GPT style experience um where you simply ask an llm question questions um or you ask it to generate something so it's either generated an answer or Genera an image right that's what that's what generation means um to me augmentation is when you're working with an llm uh and you're giving it some instructions right like you're actually and this is this is sort of like this prompt engineer in universe that a lot of people live in right where like you're giving it some instructions you're telling it like what its job is what the boundaries are what it should how it should respond how it should not respond um that is generally how I think of augmentation um and retrieval uh is basically both of those two things but where you're actually fetching context and fetching data from some other place um so the augmentation you can think of as static if you're building an app like the augmentation could live statically like in your source code but the retrieval is like no no no no like we're getting information context uh from somewhere else perhaps a database you know perhaps some other sources uh and then in conjunction with the augmentation and conjunction with the generation like we're getting some really cool results so I hope that's helpful um like I said we're gonna go into way more detail um but that's kind of how I think about Rag and I kind of think about it backwards um why rag right um like why do why are we doing this live stream and why does anybody care um I I won't you you can look at that diagram um uh but at a super high level uh there are just llms are arguably one of the most important like technical innovations that have happened in the last two years I think that's kind of you people can argue about this but I think it's pretty like it's I don't think it's very arguable like they're they're one of the most impactive technical innovations that have happened in the last last couple years how however there are problems right like llms um we I talked about how you don't need to have machine learn learning experience to to to to build AI apps because of rag well the people who build llms have to have machine learning expertise right like llms are trained um offline on massive amounts of publicly available information um so there are incredibly knowledgeable uh experienced people who build all these llms and there are dozens maybe even hundreds of llms that application developers can build on um but once again they're trained off on this massive Corpus of data and then the training stops um so if you want to build applications uh that answer questions or can provide like intelligent experiences Based on data that the llm wasn't trained on like you're kind of out of luck because the llm simply doesn't have access to that information um this applies to the second bullet point to know your business's like proprietary or domain specific information right like whatever app You're Building like you know you're building a new Social Network or you're building a better version of good reads or like you know you're building uh you know a better version of kayak or something you're whatever whatever your app whatever data your app is built on top of by definition like the llms probably don't have access to that data right so they can't you if you want to build an an intelligent like assistant or advisor or something um that's built on top of your own proprietary data uh there's kind of an open question of like how you like how you would how the llm would even have access that information to be able to build the better experience for the user um and then this is related to the two things above like LMS just don't have access to realtime information um there are uh you know like there's a lot of incredibly incredible companies that are building smarter and smarter and smarter llms like an open AI anthropic I mean there's a a lot of money is being poured into this industry to build more and more capable llms um that have like more and more updated information um but ultimately it's not real time like even the absolute state-of-the-art best llms um are simply not going to have access to real time information um so so so these are problems that application developers have trying to think about like well look like I I want to build more intelligent experiences for the users of my applications but because of these three bullet points like I just I don't understand how to tie into like the capab tie like my application into the capabilities of llm and uh and rag is and so rag is not a product you don't go to the Walmart and buy a rag um rag is just a technique that Alex and David are gonna going to show you it's a technique that application developers can use to help the llm to provide context for llms and help it to sort of provide more relevant and like better answers to questions or better are um better are generation to prompts that users have um so rather than uh me continuing to talk um I'm gonna turn it over to Alex and he's gonna dive into some code examples of like what L what it looks like to work with an llm programmatically without Rag and then what it looks like to work with an llm programmatically with rag so that you get a real grounded experience on like what the what the difference looks like and like what the benefits are so I'm G to go ahead and turn it over to Alex all right cool um so I'm going to show a really basic example of why you need to use why rag is valuable um so I kind of made the questionable life decision of buying a oldland river um and I use rag to find replacement parts um so I'm just going to walk you through kind of the code of what life looks like before Rag and after Rag and all this will be shared so you can try it after this um so the first step here is we're instelling our dependencies for this example we're basically using Three core pieces of tech unstructured which is a popular uh gen ETL tool right you need to get kind of your your Corpus of documents into a vector database we're using instructure to do that um we're using Lane chain Lane chain is the popular orchestration framework right so rather than learning a bunch of different apis we interact directly with Lane chain which then kind of calls these apis in the background and then we're using open AI um for the LM and our edings um so this is pretty basic here I'm just installing all the dependencies um and here is just really basic example of what life looks like when you ask the LM a question without using red right at the top I'm setting up um open AI right I'm telling I'm plugging in my key I'm plugging the model and I'm just asking open AI a really basic automotive question about my car right what's the parts number for the tray on top of the dashboard and you can see right here um the answer doesn't make any sense right to provide the part number Alex can you zoom in a little bit can you make it bigger thank you there we go is that better cool um to provide the correct par number I'll need more information about your vehicle right such as make model all that um and that makes sense right because this is just the equivalent of plugging in a question in the chat GPT chat knows nothing about you right so it's unable to answer very specific questions um so this is where kind of rag comes in to help chat GPT gain the necessary context answer these questions well um so for this rag example I'm going to take just a couple basic PDF Parts manuals right so I have one just kind of manual on um like how to fix things um so this is a th page PDF right you can see 164 pages and then I have another PDF that shows all the parts for the car all the part numbers where to buy them all that I'm so using so right here all I'm doing is downloading these PDFs I'm here we can see they've been downloaded on the left hand side part um and this is where it starts getting interesting right so now now what I'm doing is I'm using unstructured technology um to read these P parsel these PDFs um chunk them and write them all to asdb right so inst structured makes it super easy to build these basic pipelines I I set up kind of the um the files I wanted to read I I configure the embedding model then I hit run and a couple minutes later unstructured has pars all these documents and ritten them to DB I'm so here you can see here now I'm on kind of the asdb dashboard I can scroll down and I can see that unstructured has read all these PDFs broken all the the text into chunks and written them all to the vector database right so I can see something here about removing Clips here's something about the front axle but all of this content from these PDFs I just showed has been read from unstructured and written to the database um this this is what we refer to as the ingestion the data ingestion set in Carter diagram before right in order to do rag you somehow need all your documents to be in a vector database like actually should be um so now that we've done that here's where it gets super interesting um so here I'm doing some basic configuration of Lane chain um I'm setting up the vector store I'm setting up the embedding model and I'm doing a basic similarity search right these two lines of code so I want to take the question I want to search in my Vector store for similar for documents related to that question and now I'm going to ask the LM the same I'm gonna enter the same exact prompt but I'm this time I'm going to include the relevant Vector sore results and here now you can see we get a super accurate answer right so the LM is able to find the exact part number right here and give like a really accurate response so if I plug that in right here you can see that it's found this coin tray right so previously without rag that would mean you know going through an 800 page PDF um so you could really see how this could be um just like a super efficient way to read your business's PDF or other type of content cool and I will hand it over to David um so walk through the next example Al righty let me go ahead and share my screen and then while while David is doing that um yeah uh we had a couple great questions uh come up in the chat um feel free to use the uh I've already like migrated some of those questions to the actual Q&A widget uh so uh so but feel free to ask the ask your questions like directly in the Q&A widget uh and we'll make sure to run through all of those um during the Q&A session uh thanks for the feedback about making things bigger um hopefully uh folks were able to to kind of like uh follow along with Alex um after he he upsized a little bit and then uh I I I made David promise to like uh zoom in as he's as he's sort of oh I'll Zoom don't you worry yeah yeah yeah no worries um awesome uh and awesome cool so yeah David take it take it away yeah so where you know what Alex was just shown you a moment ago you know a collab notebook using some python things like that you know pretty much in raw code right um you could absolutely do a r pipeline that way another potential option though is to use a tool like Lang flow so this display you're seeing here um this is this is a free open source tool called langlow um this is this is part of data stacks's gen stack now what you're seeing here on the screen is you know I've got some Flows In play and stuff but what I really want to show you is when you first build up like you start up llow right you're going to have like a blank canvas and llow allows you to visually construct gen workflows um so a lot of what Alex was just showing you there's a gen flow there but you kind of have to read the code and understand what's going on you're limited to python so and so forth so when I first started bling flow I might go to something like this new project here in the top rightand corner and I can pick from all these various templates now the one that we care about today right is this Vector store rag so what I've done is I have now I'm purposely zoomed out I will zoom in in just a moment David D not to not to interrupt your flow no nope no no pun intended uh for folks that are watching like you're showing off a really cool tool it looks like you're in a browser like how did you install this like what like how how do they we'll send instructions later but like what what are we looking at yeah so so llow itself is in Python so this would be like a pip install L flow kind of thing um you know so I am running this locally right you you can see right here um I don't think it's going to zoom that much but yeah you know I am running this locally you could do it let's say with the docker container you could deploy it on things like it's on hugging face spaces you can deploy to railway render all sorts of different options from that standpoint but it is just a pip install right at the end of the day because it is you know we are working with python in this case um yeah cool and and I I just wanted to kind of like level set for folks that are watching so like David David's showing off a tool that any one of you could pip install it's completely open source completely free um completely vendor agnostic um and then like the this uh this this uh sort of like visual editor that you're seeing is a web based application but it's running locally on his computer yes um awesome and then like conver conversely um what Alex was showing you uh with our Astro database um that is a that's a a hosted server lless database where um all of you can sign up for Astra uh for free like at no cost um as developers um but it is a a hosted serverless database um that you'd be that you'd be interacting with so just wanted to make sure everyone was kind of clear about the the difference between these two tools um sorry David I'll I'll let you get back to it yeah no worries no worries so um so from a rag pipeline right what Alex and um Carter have been talking about up into this point um we're we're really seeing that there's we're seeing that here implemented in this this visual flow um so why I'm zoomed out so this would be the vector rag template um you know before modifications or anything it looks like this and notice here there actually two different flows in here you have one that I'll call like the generative flow um so when Alex was talking about the data that he was showing you in the database and then structured and things like that there was some process that was actually iterating through PDFs it was chunking through the data storing you know converting the relevant mey parts the data and Vector embeddings you know putting it in a a version that the the Gen you know the llms can understand and the the vector shares can understand and then storing that in the database so that's this part of the flow now in this case in langlow um I have filled out some of the information you know I've actually got a database right over here in Astra I have a collection called langlow um so I filled out some of these details but the template itself so if I were to just go I'm just going to go back real quick and if I just said Vector store rag right it'll create a template that looks just like this um so you already have the logic and the and the like the flow of your gen your rag pipeline already kind of worked out for you all right so let me go back here to this the one I filled out um and then the top portion here is really the query portion right so this is the part where um we will take whatever query that we have um and I'm gonna I'm going to step through all these by the way in a second I'm not going to just you know Force you all to just understand exactly what's going on um but it allows me to perform some type the query get the data from my database so this is a really key part of the rag portion right the retrieval part so when we're going to augment the generation of our llm we need to be retrieve some data that we're going to inject into its context right and we're going to step through that here in a moment um so this is the portion that you're seeing right I can go I'm G to do some retrieval from my Vector store pull that data out I'm going to inject that into my context let's change that to uh hopefully I didn't just blow everybody's eyes out of their uh heads there by changing to the uh um to the dark the light mode but hopefully that renders a little better so here this context right um hopefully you can see that pretty well um this context here in langlow this is the part that when I am asking an llm a question um like if you were in a chat upt right now and you actually said given the above context and you gave it some context you could actually start to augment the analogy of the llm we're just doing that with a database here programmatically all right so let's back out just a little bit and let's look at some of the components here right because I jumped right into this flow um so you'll notice on the left hand side you'll see all these components so langlow has all sorts of components that you can use um to build flows like this right um You have some kind of input mechanism so you can interact with it and talk with it ask a query again similar if you were an anthropic or chat CHT and you're typing something into it um you have a prompt right where you can give it instructions it's essentially what a prompt is doing all right so I'm going to give um some instruction to the llm on what I wanted to do now something I want to point out here is notice these curly braces notice how I have this variable in these curly braces so I have curly brace context curly brace and down here curly brace question curly brace well a really neat feature of langlow is if I encapsulate any variable names like that in cly Braes I say check and save it will then expose those as inputs right so what this makes it you know what what this really does for me as a developer is it makes it super easy for me to just wire up my flow without having to do this programmatically right now for those of you who are core developers and things like that you're like but okay this is great I can this is so cool I can wire all this stuff up visually but can I get it the code absolutely right so underneath the hood of any of these if I click on one of these components and I go into the little code block part there it's all python right this is all python under the hood you can modify this stuff you can make custom components all sorts of things I'm not going to delve too far into that because I want to get back to the rag thing but I I'm kind of using this as a way to just kind of showcase some of the cool things you can do here visually and this allows you to focus on your gen stuff in your rag pipeline um and then you can wrap your application around uh the API all right so let's go ahead and take a look at uh first case what I've done here is similar to what Alex was showing you um I do have a collection but it's empty right so yes I have my rag pipeline hooked up but if I were to come in and by the way in my particular case um I happen to uh I'm going to feed it some information here in a second let's see so you know kind of going back to what Carter was talking about with rag in general if I just go to an llm any llm and I ask at something open-ended like this when did I start coding right it's not going to know anything about who I am or anything like that so you can tell by the answer hey I'm sorry I don't have any information about when you started coding provide me you know provide some details or something um so this is like the core of like rag this is what I want to get at so again my rag store is empty right so what I'm going to do with langlow is I have fed it a PDF this PDF just happens to be on my particular career all right and so we're going to go ahead and I'm just going to run this now let's step through what it's actually doing right so this is the generative portion so one I'm giving it some kind of input is it limited to a file no you could be a directory it could be a URL it could be API could be all sorts of things can I control the inputs programmatically absolutely right um so with the API that's available you can modify these types of inputs you're not like limited to a single file or something but for this case visually I've just fed at this PDF now what I need to do is I need to iterate through that PDF right so I'm going to iterate through it I'm going to chunk out the data and then I'm gonna essentially go say every thousand characters I'm going to take every thousand characters going to convert those with some embedding model in this case I'm using open AI embeddings but something I want to point out about langlow and Carter mentioned this earlier it's model agnostic right so if you take a look at all the models here on the left there's also AMA support if you have your own local models right there's all sorts of ways that you can kind of you know kind of match things up and and use whatever models you want to just using open AI in here uh for example um same thing on the embedding end right you'll see there's all sorts of options there and what's cool is if I want to bring something else in in let's say maybe I wanted to use mistol or something I could just drag that over and hook that up get my key and and go on all right so great so we've iterated through the data that's in the PDF we're using the openi embedding text embedding three small model right and then we're going to store that data in our Vector database um and again um Lang flow is pretty agnostic when it comes to Vector stores but in this case today we're using we're using astb so here's what I want to show you remember a moment ago um we had an empty collection right so what I did is now if Lang float notices by the way that you don't have a collection at least for Astro DB it will autogenerate it but I already had it there remember before this was empty but now I have the data right so what's super cool about this is not only do I have the data that I chunked through but then it's also generating those Vector embeddings the relevant Vector embeddings for for the data that we chunked by the way just let me know or how's the visibility on this you guys all able to see this okay it's okay I mean you you can people always love it when you make it slightly bigger um but I think I think people are getting the gist of things for the most part and you know for folks for folks who uh you know when especially when Alex was going through his uh his code notebook example like I'll just remind everybody like don't worry we're going to share the links to the code notebooks so right don't worry about trying to like you know copy copy the code like from from a from from a blurry video like you will have the actual um code itself shared out after the after the live stream awesome awesome okay so I ran again I'm doing this all within L flow notice that I'm not actually having to touch any code to do this this is like the main benefit right of of using something like low I it allows me to visually build and execute on my gen workflows and in this case it's a rag pipeline so great so now I've got some data you can see that the data that we chunked through right each one of these chunks of text has been converted into a vector embedding using the text embedding three small that's what we're seeing here in the database this is the vector coming out of each one of those chunks and now I have the query portion so if I pull back a little bit we're going to zoom into the top here there's a couple things going on here that are kind of important one the question whatever the query is in this case I'm asking when did I start coding I'm actually going to go ahead and run through run this while I'm talking here do that so I asked this question when did I start coding but I can't just I can't just say when did I start coding and somehow search that against Vector embeddings that are these huge end dimensional arrays right that won't make any sense so what I need to do is this query also needs to be converted into the same embedding space if you will so you'll see again that my search input I'm wiring this up to my search input of my database my Vector store in this case asro DB but then we also have the same tie-in the same embedding model and that's super key right notice that I'm also using text embedding three small from open AI the same thing we used down here when I generated the data and why is it important because the different embedding models are going to have they have different parameters and properties and stuff they're using to encode the semantic data from whatever in this case the you know my my text blobs into that into those vectors that you see so if I mix and match models especially from different providers you're probably not going to get matches right so you need to make sure you're using the same one um so again so this now this chat input is how I'm going to talk to it it's going to take this particular query it's going to convert it into the same embedding space is the data that we converted our rag data into it's then going to perform a search right so here's what's super cool remember a moment ago if I look back at my database it's not a a ton of data in this example but we do have three essentially three chunks of data now I just did a query when did I start coding and I did it against the database but notice it returned one of them right so this is actually super cool and for my particular question when did I start coding there are some key things that it it was able to pull out things like I was around eight years old um started on a commoner 64 so the vector search was able using this this essentially this semantic comparison right it was able to pull out the relevant results somebody asked the question earlier like you know what what are some of the benefits of rag and things like that like well one of the things imagine that you have thousands of documents or millions of documents or something like that it is a lot more cost-effective and efficient to go ahead and use something like a vector store to pull out the relevant results and then just put those relevant results into your context and that's what we're going to do here in a moment so great we get a result now I just you know in this case if you notice I have a file path and a text all I really want is this text that's what I want to put into my llm so I'm going to use this pars data component to pull out the text that you see here then here's the real fun one right I'm going to take that result from my Vector store I'm going to again wiring it right up remember those curly braces that I was talking about earlier we just wire up the output into the context and now check out what happened so this is the same prompt we had earlier but now it's got the context that's been programmatically added to the prompt right along with our question so yeah this being done visually but again underneath the hood it's it's all python you have access to this from your application right um so it is allowing us to build this as we go along so then when we give the prompt to the llm it now has all the information right now if I come back to the playground you can see that when I ran that before it asked the question again but now instead of saying hey I don't know who you are or I don't have any information about this it now says hey you started coding games on your Comer 64 when you're around eight which is correct correct right it was able to pull that information out of the data that I sent into it okay so I keep talking by the way about um you know wrapping your application around this and and such like that um so yes this is Implement in Python again there's code under the hood um but you're not limited to python at all and I think this another really powerful thing about linkflow um so whether you're using a JavaScript or if you're using Java or you know PHP or whatever um you have all sorts of options here um one you could treat this um as a pure API server right you can just call your API endpoint wherever you have L flow deployed um you can modify the inputs and outputs and that kind of deal so you can you can say you know obviously programmatically give it different questions or you can do a lot more complex examples than this um there is a full like if you really want to you know I actually find that when I use langlow for development um I really like using this kind of flow visually in my testing while I'm iterating because I can come over here if I wanted to I could say you know something maybe I want to experiment with anthropic or something like that right I can come in here and I can say all right well I'm gonna experiment with anthropic I'm gonna go ahead and I'm G to wire that up I'm gonna put a new chat output and I can just do that on the fly right so it allows me a lot of flexibility when I'm iterating and going through my code um and then you know both Python and JavaScript have you know kind of more uh capable API code that you can put in but there's a really interesting um capability with python um which is this right here this from llow load import um that allows you to just import a Json blob so any one of these flows you can export as a Json blob and why is that important because now if I want to I can detach the whole of this logic and embed it directly into my python app and I don't need to run this as an API server right so it's like a super cool piece of functionality I've had a lot of people in the past be like hey can I just get all the code like can you give me the code or something like that um and while yes you can go to the individual component you can pull out the code and everything like that the fact that I can just download the whole blob and then import that right into my app means that I don't really need to worry about the individual code if I don't want to right I can just get all the logic and everything put in my app and then focus on what my application is doing all right so with that let's see how are we doing on questions there we've got a ton of questions I think uh yeah if you're if you're ready like I think we should uh transition over to Q&A because we got a a ton of great questions okay awesome um so thanks for thanks for providing that run through um feel free to stop sharing your screen and we kind of get everyone uh all right let's get everyone back back on stage let's see and by the way I already see a really good question there at the bottom but I'll let you do your thing no it's all good like we've got a we got a ton of great questions awesome so David thank you so much for a whirlwind tour of like a really a really powerful tool for developers right um there's a ton of questions already uh about about Lang flow um that we can that we can start to start to get into um but I'm gonna we're going to use the remainder of our time to to get through your questions so uh keep feel free to keep adding questions to the Q&A widget and we're going to start start going through these um the first one that I want to tackle um is is uh a really important one right like why Rag and not fine tuning it comes up all the time you know it's like whether you know what fine-tuning is or whether or whether it's just like this word that you've heard you know um like buzz word that You' sort of read on the internet um uh I basically fine-tuning uh is the kind of thing that you do if you actually have like machine learning engineering expertise right like if you're a machine learning engineer or you work on a machine learning engineering team yeah like you you you might have the skill set and the desire and the inclination to take to either build your own llm um or to take an llm and to fine-tune it for for folks folks folks who don't know what I'm talking about the simplest explanation is like fine-tuning is taking an llm and then sort of tuning it to to provide to to provide like optimizations around the kinds of questions that you want to be able to answer for the app that you are building um the simplest thing that I can say is that um rag is a fantastic technique and tool for developers that don't have machine learning expertise um or don't want to take the time because fine tuning is a very incredibly like labor Capital time intensive process like you could spend weeks or months fine-tuning a model based on whatever your domain information is um rag is something that any full stack web developer can Implement in like a day or a weekend at least like as a as a prototype right um there's always a little bit more work that is required to to ship something to production but that's one of the that's probably arly one of the main benefits of rag um it doesn't require that kind of domain expertise um it's very fast to implement and it's very low cost to implement um Alex Alex or David do you have any other uh anything you want to kind of add on there no agreed on the cost comment right it seemly less expensive to play around with r and fine fing um so definitely plus one on that point yeah yeah I mean there are look there are use cases where funion is the correct decision but like all engineering decisions it's just about trade-offs like you know how fast you trying to come to Market what uh technical expertise do you have at your company like what are you trying to achieve like how much you willing to spend those those kinds of things um David you you said that you kind of identified a question immediately that you wanted to dive into which one was that oh yeah it is um Delante Lee best said wow can you experiment with multiple gpts at the same time yes absolutely um in Lane flow as a matter of fact I have a totally separate app from what we're talking about here that does real-time language translation and it has four different llms being used um because and that wasn't just like a showcase thing that was actually for what I was doing in that particular app different llms are actually really good at different things some are great at language translation some are great at code some are great at depends um so so yes that's actually I think one of my favorite features of Lang flow is the ability to just very quickly you can just drag and drop them you go get a key from the provider pop in your key and and wire it up right you're you're done in 30 seconds or something one thing I wanted to add very briefly a question came up I don't know if it's in the if it's in this list or not where someone just asked like very plainly like what why would I use this instead of L chain um I think um one of the ways that I think about it like much of Lang flow is built on top of Lang chain like if you're comfortable with Lang chain if you're familiar with Lang chain like I think it'll be really comfortable and familiar with using Lang flow um because a lot of what Lang flow is is you know sort of this goey built on top of these Lang chain components and Primitives um one of the reasons you might do it though is that Lang Lang chain is a pretty vast um vast like people call a Swiss army knife like there are like just th thousands of different like Lang chain methods um Lang flows is is uh highly curated right so like langlow is a subset of like the universe of functionality that Lang chain has um and it's curated with an optimization towards rag applications and an optim optim optimizations towards like using the parts of length chain that are actually like up to dat that aren't broken um so uh so if you're you know even if you're familiar with Len chain like you might uh I I definitely ask you to check out Len flow um to see if it's missing anything that you actually like use all the time from Lang chain so I I just sort of think of it as like an opinionated curated tool um that developers can use to build these AI flows um and also uh it is uh because it's built on top of Lang chain if you're if you want to use things like Lang Smith which is Lang Chain's uh observability uh Service uh you just get it for free like you just you build your AI flow using using Lang flow um you you flip on an environment variable for your your uh your Langs Smith key um and it like it just works uh with no extra added effort on your part um like add that Carter you know from you know with with using Lang chain compared to L flow um conceptually like yeah if if you're the person who's in the code you understand the Lang sh the L chain uh libraries and what's actually going in in the code logic that that's wonderful but conceptually especially as some of the workflows become more comp Lex they are much easier to visualize like conceptualize when you can see them visually and not only that it's much easier to then present them to somebody else right and say hey this is what this flow is doing and here's how the individual components can work could you do that in Lang chain absolutely right uh but especially if you're showing it to somebody who might be a non- coder uh or want their involvement then that's almost a non-starter where when you see it visually it it just makes it so much e i I find that in my own personal development it's just easier to reference because I can take look at it and I can see exactly what's going on in my flow um next we're gonna we're gonna fire through these because there's so many really great ones um I was actually hoping Alex could maybe take take a stab at this one um it's a really reasonable question where the the developer is like look like I want to I want to do rag um I want to do Vector search but I have other like criteria or like other attributes that like I want to factor into how these things are sorted um or how like how I build the query um like Alex do you have any any thoughts for like what what they could do this is this concept of like hybrid search right where you're doing uh a vector search and you're also filtering on certain columns um so maybe if you're a grocery store right like in your database table you'd have your vector embeddings then maybe like you know produce and uh chips and there's this concept of hybrid search where you could essentially like filter to only search you know your your produce items and then kind of look for and then do the similarity search so that would be my recommendation and that's fully supported in ASB yeah yeah I think um look developers have a lot of choice when it comes to uh Vector databases and Vector search um the two we don't have time to go into all of it um the two broad categories of uh like databases you're going to hear about are pretty much like vector only databases uh that just they store vectors they do Vector search um and that's that's pretty much what they're built and optimized for and then there are um there are like fully fledged application databases that also support Vector storage and Vector search so astrab is in the latter category of database and as a developer what that buys you is the ability to do what Alex said which is basically hybrid search so you can you can think of it as you're you're executing this filter you're executing this sort you're you're returning documents and you're sorting them but you can sort by multiple Fields one of those fields could be the ve the vector field the vector similarity field but then the other could be um these these other attributes uh that you want to sort on or that you want to filter for um and that's and that's something that you you makes it Astra makes it really easy to execute that kind of hybrid search so um that's like that's one way that you could that you could do that um all right uh David uh a question for you uh about uh about about chunking um this is this come this comes up all the time this is for Alex and David right I mean like yeah how how how should develop like once again this is a rag 101 talk like we don't need to go into crazy depths of detail but just like really high level like how should an application developer think about what their options are for chunking or like just stuff that they should consider when they're chunking in order to sort of improve the results of their application yeah I've got a I've got a couple things to say about that um one if you're talking about just pure chunking um part of that is going to dep be dependent on the embedding model that you're using um so I would look at that right um you know there's going to be slight differences between if you're using like nvidia's Nemo compared to uh open eyes text and Bing models or mistol or whatever right so it does take sometimes a little bit of research on the individual models and you it honestly you should experiment with them anyway and and kind of see what works for you but you'll find that for each of the individual models um they will have slightly different chunking strategies but the other thing see I see Alex you also post the link I I'll say something real quick um the other thing is there are whole different methodologies like there's there's something called culbert um where it's a completely different way of doing it it's not just grabbing like in example that I showed you know was just kind of doing this generic I'm gonna grab a thousand characters right and it doesn't matter what's in the text it doesn't matter if it's semantically similar or anything I'm just going to grab you know a thousand characters and I'm gonna Chunk on it um Colbert is a different method that is actually a bit smarter when it comes to context um and it doesn't actually do chunking in the same way at all it actually is is based off of tokens and you're saying hey I'm gonna grab a set of tokens but then I'm GNA get information about the surrounding tokens I'm going to vectorize that with a smaller essentially smaller Dimension amount like 128 but then I'm also going to set up something that allows me to slide in like kind of overlap data on purpose it's actually very good for maintaining context and everything so it's a totally different strategy than just straight up chunking um yeah so there's there's definitely multiple ways to do it I think experimentation a little bit of research on the models you're you're using goes a long way there yeah Alex you have anything to add there I I was just going to add we heavily use this Lane chain recursive text splitter um so might be interesting to take a look they have some good dots with recommendations some choke size and overlap um we also heavily used the unstructured for text splitting chunking um so they all have super good resources and we're also about to ship a blog or we did ship a Blog on chunking that we'll share after this as well on what some thoughts and and and I'll just say this like super high level stuff right like I all developers application developers that are starting to get into generative Ai and and and rag like you might find this frustrating but the amount the amount of time you spend writing code is going to be a lot less than the amount of time you spend like experimenting with these different things right David talked about David talked about swap swapping in and out llms we just talked about like different chunking strategies and try this and like I I think it's FR I think it will be it's frustrating for some developers who are accustomed to thinking of their productivity based on the number of lines of code that they're kind of writing per day but AI engineering is um often times uh more about like iterating right it's more about trying different things looking look looking at the results tweaking those tweaking some of those parameters and then trying it again this is true for prompt engineering true for chunking true true for llm choices um and frankly I think it's kind of I think it's it's overall a good thing right I mean like you know it's a it's definitely less about like writing code and more about like understanding how to like integrate these different tools and optimize the results for developers um someone asked a really great question about the the embedding part right um and there's a bunch of really cool stuff that we're doing to like make this part easier I thought Alex um could maybe uh dive in a little bit Yeah so um can you explain so the question is can you please explain the embedding part in more detail um so basically in order to perform a vector search you first need to take kind of your document Corpus and convert it into Vector embeddings um which are basically just arrays of numbers um so basically how you do that is you call an external API in my example I used open AI open AI will take that raw text convert it into this array of numbers and then you sort end of actually datab base like asra um so we recently introduced this feature called vectorize to make this entire process easier so rather than kind of playing around with a bunch of external apis you can now use the ACT be vectorized API with a single API call embed your data and also write to the DV so we can share more information on that um it's also super easy to embed your your your content with the link below that David showed a bit as well um is there a way to and this is a question just came in that's relevant is there a way to find out the quality of embeddings like how do we know embedding is good or not um there's a bunch of rankings online on like the best embedding models that you can take a look at um if you Google just like embedding model ranking hog and face is really good list yeah and I think um another thing another recommendation that i' I've seen people Implement and I I think yield good results like you like as developers like we're totally accustomed to building writing unit tests and like writing integration tests like there's you're basically going to do the same thing for these applications right like you're gonna you're gonna have you you should you can build a test harness and a test Suite that has a bunch of expected questions or expected prompts uh and then you can run those prompts through your application and you can actually use an lln and you can have like an expected output and you can actually use llms to compare the actual output to the expected output so even if it isn't character that's cool even if it isn't even if it isn't character for character identical like you can ask the LM like hey like is this is this like is this like 90% similar right um and I've seen people people do that um and you're gonna want to do that because once again like you know think why do we have unit tests like right we have unit tests because like you're constantly iterating iterating on your application making changes and you have to have confidence that when you make changes before you ship the changes to production you haven't created a regression or broken everything so this is AI engineering is just introducing it's taking a lot of things that we're used to but changing them into into sort of a new form of those things like for for these for this generative AI age that we're in um I wanted to get to this question because it it's um sorry we're because we're running low on time um because I think this is important right like someone this person's asking like hey like how do we how do we think about you know the r part of things like you know what how do we think about you know um leaking confidential information um to llms uh very quick comment for me um there are two kinds of llms that you can use uh there are open source llms and there are sort of close Source like you know uh service llms you know think of open AI is like an example of that right um if you're using an open source llm you don't need to worry about your data or your you know your your company's data or your customers data being leaked to anywhere right and that might be a consideration that you that you make when you're trying to decide what llm to use but conversely like if you want to use a service-based llm uh you simply like every other API or every other service or every other database that you might think of using for sensitive customer information you're going to have to pay attention to the you know to the to the sort of the terms of use and the terms of service right um uh so in the same way that you might ask the question like where can I store sensitive and customer data like ask those exact same questions in terms of the llm services that you might use so for instance um Astra Alex did you talk about uh vectorized as as part of asra yet yeah yeah yeah awesome so so as Alex mentioned like you know we natively support a bunch of uh uh providers uh and embedding models in as DB um and we support both open AI um and Azure open AI uh so for you know for developers that build as part of um Microsoft and azure's ecosystem and uh and sort of have uh a preference uh for storing data and using apis that are part of that ecosystem like we support Azure open AI um but that's just that's that's something that you would just sort of need to pay attention to um as you're building these applications um cool uh so we're running low on time um I wanted I wanted I wanted to I want to kind of maybe close to this right um and I'll just I'll pop this up right because I'm sorry we can't we can't get to everything but these questions have been awesome right and I think this is a good one to close with right like and I'll pose it to both David and Alex right like what is how would what's like the one or two sentence like explanation or just analogy that like you could use to explain rag to I don't know I people always use the stereotype of like your mom but I think that's kind of like you know let's not let's not be mean to moms in the world right maybe your kid right like you know like what is like how would you sort of describe it like I I'll go first right um I don't know if this is the best analogy right um but uh some there's a our chief product officer uh here at data Stacks um he has to do uh a lot of uh sort of um like U he has to have a lot of meetings and do a lot of interviews with like analysts uh in journalists um and there's there's there's sort of a a game that gets played where um you know because people can ask like any kind of question and you have to have like information like available like on hand to be able to intelligently answer answer those questions because you just never know what an analyst or a journalist is going to throw at you um and and and there are assistants like there are there people that work with Ed our chief product officer that like have that data like at their fingertips and they can sort of provide to Ed so that he can sort of answer the question um you know with with like with enough context to like help help the analyst or help the journalist sort of understand what the answer is and I think that's kind of like a a decent sort of metaphor for how rag works right where like the question or the prompt is just unknown in advance um but like you can use that question or that prompt to sort of like very quickly and efficiently like get some context and some information and then you provide it to you know someone like Ed um or someone else that like can sort take that context alongside the original question and provide like a really great like easy to understand answer you know for the person who asked the question in the first place so that's like I don't know that's like that's one thing that kind of came to mind for me but David I'm curious if you if you've got something better oh I don't know I'm I'm actually laughing at Hugh Brown's comment there um it's you know as you can tell it's actually really hard this is hard one put a short explanation but yeah I would say I would say it's almost like um having you know uh a your business domain expert following you around right um because the way I usually explain it in terms of domains whether it's my personal domain or my business domain the llms just aren't trained on that right so it's like you've got you've got your little business domain expert who's following you around and so when somebody asks a question they can immediately inject that context very similar to what carer was saying honestly um but uh that's that's my my shot at it I don't know Alex I'm not gonna put Alex on Alex do you have like a piffy sort of like fun analogy I can't come up with anything better don't want to disappoint you no worries but but look look I guess the other thing that I'll say um as and as we kind of close this out like actually it's not it's not really an analogy I think it's like a fact like if you are a full stack developer right and you have been writing you know sequel queries or like no SQL queries for the better part of a several years or several decades build full stack applications like honestly that's all this is right if you know how to build a crud app where like you know the user shows up to your app and it wants to you know it wants to view the the the the detailed description for some book that's in like your book database and like you know how to do the select query or you know how to do the the nosql query like if you know how to build crud applications I just think that you'll you'll be super comfortable with rag right because that's what it is right like rag is just sort of like the only the nuanced difference is that like when you build these cred applications usually you have these like fixed Properties or fixed columns and you're kind of composing a SQL query with a with a wear Clause right you know select from books where ID equals x right so that's that's what crud applications are and really just rag applications are like this really slight Nuance where it's like you know hey like you know like get all the documents like where the question matches you know matches the vector right but like conceptually like that's really what you're doing um um and then there's a little bit of detail on the other end but I think if you're a full stack application and application developer and you're comfortable with crud um I think you'll be really comfortable with rag you'll certainly be more comfortable with rag than you would be with fine tuning or some of the other techniques that require like radically different like domain expertise and knowledge okay well think I have I have a concise one it's having a natural conversation with your data right like because everything you were just talking about like for decades we've had to you know learn how to write SQL or do keywords or find all these different ways we can get at the data but now you can literally just have a natural conversation with your data that's my that's that's my take now aesome and that's and that's a perfect way to end it um so we're a couple minutes over but thanks for sticking around everybody this is super fun um we're gonna do a lot more of these things um it's a thanks for all the awesome questions thank you so much to David and thank you so much to Alex for joining us once again this is all being recorded uh you can we're going to post it it'll be online available immediately after this is over you can share it with your friends and colleagues uh and uh yeah and we'll uh we'll hopefully we'll we'll see you all soon for uh for our next stream uh so until then H take care everybody see you later thank youall see you",
    "segments": [
      {
        "start": 0.199,
        "duration": 4.16,
        "text": "sorry I'm we're kind of laughing here on"
      },
      {
        "start": 2.08,
        "duration": 4.08,
        "text": "the call because the the folks in the"
      },
      {
        "start": 4.359,
        "duration": 4.36,
        "text": "chat here on crowdcast gave us the"
      },
      {
        "start": 6.16,
        "duration": 4.599,
        "text": "countdown yeah um like I might I might"
      },
      {
        "start": 8.719,
        "duration": 3.8,
        "text": "have been inclined to like start like a"
      },
      {
        "start": 10.759,
        "duration": 4.0,
        "text": "couple minutes late you know like let"
      },
      {
        "start": 12.519,
        "duration": 4.881,
        "text": "the stragglers show up for the stream"
      },
      {
        "start": 14.759,
        "duration": 4.321,
        "text": "but people here were like they were like"
      },
      {
        "start": 17.4,
        "duration": 4.76,
        "text": "literally like giving us like the 20"
      },
      {
        "start": 19.08,
        "duration": 4.24,
        "text": "seconds the 10 seconds and go um so uh"
      },
      {
        "start": 22.16,
        "duration": 4.16,
        "text": "so yeah so thanks for that thanks for"
      },
      {
        "start": 23.32,
        "duration": 4.719,
        "text": "the motivation um awesome well uh look"
      },
      {
        "start": 26.32,
        "duration": 4.279,
        "text": "welcome welcome to uh to this live"
      },
      {
        "start": 28.039,
        "duration": 5.801,
        "text": "stream um welcome to all folks who are"
      },
      {
        "start": 30.599,
        "duration": 6.761,
        "text": "here on crowdcast uh and everyone who is"
      },
      {
        "start": 33.84,
        "duration": 4.719,
        "text": "watching um on Twitter uh I guess some"
      },
      {
        "start": 37.36,
        "duration": 3.96,
        "text": "people call it X but I'm going to call"
      },
      {
        "start": 38.559,
        "duration": 5.081,
        "text": "it Twitter uh or watching on LinkedIn um"
      },
      {
        "start": 41.32,
        "duration": 4.8,
        "text": "this is being multicast to a bunch of"
      },
      {
        "start": 43.64,
        "duration": 4.04,
        "text": "different plac places because we want to"
      },
      {
        "start": 46.12,
        "duration": 3.119,
        "text": "be wherever developers are and"
      },
      {
        "start": 47.68,
        "duration": 5.199,
        "text": "developers are kind of scattered all"
      },
      {
        "start": 49.239,
        "duration": 7.761,
        "text": "over the place uh so quick uh quick"
      },
      {
        "start": 52.879,
        "duration": 5.52,
        "text": "agenda um this this conversation and"
      },
      {
        "start": 57.0,
        "duration": 2.48,
        "text": "we'd love for this to be a conversation"
      },
      {
        "start": 58.399,
        "duration": 3.201,
        "text": "and I'll talk more about that in a"
      },
      {
        "start": 59.48,
        "duration": 3.64,
        "text": "little bit is just we're we're going to"
      },
      {
        "start": 61.6,
        "duration": 3.8,
        "text": "spend some time talking about what is"
      },
      {
        "start": 63.12,
        "duration": 7.359,
        "text": "what is rag um so this is a little bit"
      },
      {
        "start": 65.4,
        "duration": 8.399,
        "text": "of a rag 101 talk uh the if you are a if"
      },
      {
        "start": 70.479,
        "duration": 6.561,
        "text": "you're if you a developer and you don't"
      },
      {
        "start": 73.799,
        "duration": 5.36,
        "text": "feel like you you know what rag is um or"
      },
      {
        "start": 77.04,
        "duration": 5.24,
        "text": "you don't feel super grounded uh in in"
      },
      {
        "start": 79.159,
        "duration": 6.841,
        "text": "the topic uh this is a fantastic stream"
      },
      {
        "start": 82.28,
        "duration": 6.199,
        "text": "for you to uh to participate in um I"
      },
      {
        "start": 86.0,
        "duration": 5.32,
        "text": "want to be super clear that uh you don't"
      },
      {
        "start": 88.479,
        "duration": 5.841,
        "text": "need to have any machine learning or"
      },
      {
        "start": 91.32,
        "duration": 5.439,
        "text": "data science uh expertise or knowledge"
      },
      {
        "start": 94.32,
        "duration": 4.32,
        "text": "uh to to sort of get value um out of"
      },
      {
        "start": 96.759,
        "duration": 3.561,
        "text": "this conversation in fact that's we'll"
      },
      {
        "start": 98.64,
        "duration": 4.119,
        "text": "sort of learn about this later but one"
      },
      {
        "start": 100.32,
        "duration": 4.839,
        "text": "of the things that's awesome about rag"
      },
      {
        "start": 102.759,
        "duration": 5.161,
        "text": "is that it makes building AI"
      },
      {
        "start": 105.159,
        "duration": 5.24,
        "text": "applications accessible to all kinds of"
      },
      {
        "start": 107.92,
        "duration": 5.08,
        "text": "developers all kinds of full stack"
      },
      {
        "start": 110.399,
        "duration": 6.36,
        "text": "developers uh and it really removes the"
      },
      {
        "start": 113.0,
        "duration": 5.68,
        "text": "need to have deep deep uh expertise um"
      },
      {
        "start": 116.759,
        "duration": 3.921,
        "text": "or experience with machine learning or"
      },
      {
        "start": 118.68,
        "duration": 4.24,
        "text": "data science um so yeah so we're going"
      },
      {
        "start": 120.68,
        "duration": 5.399,
        "text": "to talk a little bit about what is rag"
      },
      {
        "start": 122.92,
        "duration": 5.959,
        "text": "um we're going to dive into uh llms like"
      },
      {
        "start": 126.079,
        "duration": 5.121,
        "text": "what it looks like to work"
      },
      {
        "start": 128.879,
        "duration": 5.0,
        "text": "programmatically with an llm uh without"
      },
      {
        "start": 131.2,
        "duration": 5.0,
        "text": "using rag uh and what it looks like to"
      },
      {
        "start": 133.879,
        "duration": 4.881,
        "text": "work with an llm when you do use Rag and"
      },
      {
        "start": 136.2,
        "duration": 4.24,
        "text": "like what's awesome about that uh then"
      },
      {
        "start": 138.76,
        "duration": 3.92,
        "text": "we're going to dive into rag"
      },
      {
        "start": 140.44,
        "duration": 3.32,
        "text": "specifically using um an open source"
      },
      {
        "start": 142.68,
        "duration": 5.0,
        "text": "product called"
      },
      {
        "start": 143.76,
        "duration": 5.64,
        "text": "langlow um which uh is a an awesome Tool"
      },
      {
        "start": 147.68,
        "duration": 5.32,
        "text": "uh it just makes it really fast and easy"
      },
      {
        "start": 149.4,
        "duration": 4.96,
        "text": "to build uh AI applications uh and then"
      },
      {
        "start": 153.0,
        "duration": 4.599,
        "text": "we're going to turn it over to"
      },
      {
        "start": 154.36,
        "duration": 5.959,
        "text": "Q&A um so uh a couple couple bits of"
      },
      {
        "start": 157.599,
        "duration": 5.681,
        "text": "bits of housekeeping um for folks that"
      },
      {
        "start": 160.319,
        "duration": 5.041,
        "text": "are here on crowdcast um if you haven't"
      },
      {
        "start": 163.28,
        "duration": 4.16,
        "text": "joined us on a crowdcast live stream"
      },
      {
        "start": 165.36,
        "duration": 3.56,
        "text": "welcome thank you for coming um if"
      },
      {
        "start": 167.44,
        "duration": 3.92,
        "text": "you've been here before then this will"
      },
      {
        "start": 168.92,
        "duration": 5.56,
        "text": "be old news to you uh but you'll notice"
      },
      {
        "start": 171.36,
        "duration": 8.159,
        "text": "that in the top right of your screen uh"
      },
      {
        "start": 174.48,
        "duration": 7.44,
        "text": "is a Q&A uh widget um so as we're going"
      },
      {
        "start": 179.519,
        "duration": 4.961,
        "text": "through through today's live stream um"
      },
      {
        "start": 181.92,
        "duration": 4.399,
        "text": "if you have any questions about what"
      },
      {
        "start": 184.48,
        "duration": 5.16,
        "text": "we're talking about or concepts that"
      },
      {
        "start": 186.319,
        "duration": 5.361,
        "text": "we're discussing um please ask ask those"
      },
      {
        "start": 189.64,
        "duration": 3.72,
        "text": "questions in that Q&A widget and we're"
      },
      {
        "start": 191.68,
        "duration": 4.96,
        "text": "going to monitor these questions as they"
      },
      {
        "start": 193.36,
        "duration": 5.519,
        "text": "come in um and you'll also notice that"
      },
      {
        "start": 196.64,
        "duration": 5.4,
        "text": "kind of like Reddit or Hacker News you"
      },
      {
        "start": 198.879,
        "duration": 5.0,
        "text": "can you can vote up uh questions um that"
      },
      {
        "start": 202.04,
        "duration": 3.68,
        "text": "you see so like if you go to the Q&A"
      },
      {
        "start": 203.879,
        "duration": 3.36,
        "text": "widget and somebody has asked a question"
      },
      {
        "start": 205.72,
        "duration": 2.799,
        "text": "that you think is a great question and"
      },
      {
        "start": 207.239,
        "duration": 3.56,
        "text": "you would also like to know the answer"
      },
      {
        "start": 208.519,
        "duration": 4.28,
        "text": "to that question please vote up that"
      },
      {
        "start": 210.799,
        "duration": 3.321,
        "text": "question um and we'll we'll kind of"
      },
      {
        "start": 212.799,
        "duration": 3.0,
        "text": "we'll kind of see how it goes like we"
      },
      {
        "start": 214.12,
        "duration": 3.199,
        "text": "may get to some of these questions like"
      },
      {
        "start": 215.799,
        "duration": 4.0,
        "text": "in real time as the live stream is"
      },
      {
        "start": 217.319,
        "duration": 4.881,
        "text": "happening um or and we will also have"
      },
      {
        "start": 219.799,
        "duration": 3.841,
        "text": "like a nice Q&A segment on the back end"
      },
      {
        "start": 222.2,
        "duration": 4.039,
        "text": "of this live stream so we make sure to"
      },
      {
        "start": 223.64,
        "duration": 4.4,
        "text": "get through folks uh questions um I"
      },
      {
        "start": 226.239,
        "duration": 3.401,
        "text": "wanted to remind everybody uh because"
      },
      {
        "start": 228.04,
        "duration": 3.6,
        "text": "this question comes up a lot like this"
      },
      {
        "start": 229.64,
        "duration": 3.56,
        "text": "is this live stream is being recorded um"
      },
      {
        "start": 231.64,
        "duration": 4.0,
        "text": "and it's going to be available for"
      },
      {
        "start": 233.2,
        "duration": 4.319,
        "text": "everybody publicly uh after the live"
      },
      {
        "start": 235.64,
        "duration": 4.48,
        "text": "stream is over um and we're going to"
      },
      {
        "start": 237.519,
        "duration": 5.401,
        "text": "send an email to everyone who Jo joined"
      },
      {
        "start": 240.12,
        "duration": 4.839,
        "text": "us uh with a link to this recorded to"
      },
      {
        "start": 242.92,
        "duration": 3.679,
        "text": "the recording of This live stream along"
      },
      {
        "start": 244.959,
        "duration": 2.92,
        "text": "with like links to resources that we're"
      },
      {
        "start": 246.599,
        "duration": 4.881,
        "text": "sharing like we're going to show you"
      },
      {
        "start": 247.879,
        "duration": 6.521,
        "text": "guys a bunch of uh you know code code uh"
      },
      {
        "start": 251.48,
        "duration": 4.84,
        "text": "code notebooks uh repos like all the"
      },
      {
        "start": 254.4,
        "duration": 3.399,
        "text": "resources that we review like in this"
      },
      {
        "start": 256.32,
        "duration": 5.72,
        "text": "live stream we'll make sure to share"
      },
      {
        "start": 257.799,
        "duration": 8.041,
        "text": "them um as an email after the fact so uh"
      },
      {
        "start": 262.04,
        "duration": 6.599,
        "text": "so who who is on this live stream so uh"
      },
      {
        "start": 265.84,
        "duration": 5.48,
        "text": "I'm uh we're going to go around the horn"
      },
      {
        "start": 268.639,
        "duration": 4.761,
        "text": "uh and and introduce ourselves uh and I"
      },
      {
        "start": 271.32,
        "duration": 4.0,
        "text": "have uh in addition to sort of the"
      },
      {
        "start": 273.4,
        "duration": 5.28,
        "text": "basics like you know what's your name"
      },
      {
        "start": 275.32,
        "duration": 5.76,
        "text": "where do you live uh what do you do um I"
      },
      {
        "start": 278.68,
        "duration": 3.88,
        "text": "I always ask everyone who's on on on one"
      },
      {
        "start": 281.08,
        "duration": 3.8,
        "text": "of these streams kind of like a fun"
      },
      {
        "start": 282.56,
        "duration": 3.32,
        "text": "personal question and David and Alex"
      },
      {
        "start": 284.88,
        "duration": 4.159,
        "text": "have not"
      },
      {
        "start": 285.88,
        "duration": 4.52,
        "text": "been have not been given access to this"
      },
      {
        "start": 289.039,
        "duration": 2.801,
        "text": "I've not told them what this question is"
      },
      {
        "start": 290.4,
        "duration": 3.799,
        "text": "so they're they're going to be as"
      },
      {
        "start": 291.84,
        "duration": 5.88,
        "text": "surprised as you when I ask it um I'm"
      },
      {
        "start": 294.199,
        "duration": 5.961,
        "text": "going to have uh so I'll go last um so"
      },
      {
        "start": 297.72,
        "duration": 4.319,
        "text": "so I'm going to start with David um so"
      },
      {
        "start": 300.16,
        "duration": 4.96,
        "text": "like obviously like tell us maybe where"
      },
      {
        "start": 302.039,
        "duration": 5.88,
        "text": "you're located what do you do and then"
      },
      {
        "start": 305.12,
        "duration": 4.84,
        "text": "um the uh the the fun getting to no"
      },
      {
        "start": 307.919,
        "duration": 5.361,
        "text": "David question for everybody is um are"
      },
      {
        "start": 309.96,
        "duration": 6.079,
        "text": "you a Marvel person or a DC"
      },
      {
        "start": 313.28,
        "duration": 4.72,
        "text": "person fun well well hello everybody and"
      },
      {
        "start": 316.039,
        "duration": 4.321,
        "text": "again thank you for joining um I'm David"
      },
      {
        "start": 318.0,
        "duration": 4.84,
        "text": "Jones gelardi I'm in Orlando Florida and"
      },
      {
        "start": 320.36,
        "duration": 5.0,
        "text": "the United States um so for those of you"
      },
      {
        "start": 322.84,
        "duration": 4.32,
        "text": "who are not familiar with it uh you or"
      },
      {
        "start": 325.36,
        "duration": 3.839,
        "text": "you may be familiar with you know Disney"
      },
      {
        "start": 327.16,
        "duration": 5.0,
        "text": "World or Universal like all of the parks"
      },
      {
        "start": 329.199,
        "duration": 4.081,
        "text": "and things like that are here um and"
      },
      {
        "start": 332.16,
        "duration": 4.56,
        "text": "I've been you know I'm a developer"
      },
      {
        "start": 333.28,
        "duration": 5.12,
        "text": "relation engineer um I've been coding in"
      },
      {
        "start": 336.72,
        "duration": 3.84,
        "text": "various languages and doing databases"
      },
      {
        "start": 338.4,
        "duration": 4.12,
        "text": "for off 30 years and in a lot of"
      },
      {
        "start": 340.56,
        "duration": 3.84,
        "text": "different uh areas and defense and"
      },
      {
        "start": 342.52,
        "duration": 4.44,
        "text": "things like that and these days I'm a"
      },
      {
        "start": 344.4,
        "duration": 5.32,
        "text": "gen nerd really um I'm I'm focusing on"
      },
      {
        "start": 346.96,
        "duration": 5.12,
        "text": "Python and I'm just you know uh having"
      },
      {
        "start": 349.72,
        "duration": 5.199,
        "text": "fun with all of the Gen stuff now to"
      },
      {
        "start": 352.08,
        "duration": 5.239,
        "text": "your question Carter uh man you know I"
      },
      {
        "start": 354.919,
        "duration": 4.881,
        "text": "gotta say Marvel I I would say though if"
      },
      {
        "start": 357.319,
        "duration": 4.281,
        "text": "you I I'm going to start with that but"
      },
      {
        "start": 359.8,
        "duration": 3.44,
        "text": "I'm going to preface it with when we're"
      },
      {
        "start": 361.6,
        "duration": 3.76,
        "text": "talking about the movies I think"
      },
      {
        "start": 363.24,
        "duration": 3.679,
        "text": "Marvel's really done a spectacular job"
      },
      {
        "start": 365.36,
        "duration": 4.279,
        "text": "compared to DC but when we're talking"
      },
      {
        "start": 366.919,
        "duration": 4.241,
        "text": "about the comics bit different and"
      },
      {
        "start": 369.639,
        "duration": 2.84,
        "text": "that's that's I don't have just a"
      },
      {
        "start": 371.16,
        "duration": 3.12,
        "text": "straight up I like this one better or"
      },
      {
        "start": 372.479,
        "duration": 4.361,
        "text": "the other I was always a fan of both but"
      },
      {
        "start": 374.28,
        "duration": 4.84,
        "text": "movies wise I go for"
      },
      {
        "start": 376.84,
        "duration": 4.0,
        "text": "Marvel all right fantastic okay so now"
      },
      {
        "start": 379.12,
        "duration": 2.96,
        "text": "we're gonna uh and by the way I'll"
      },
      {
        "start": 380.84,
        "duration": 3.479,
        "text": "explain why I'm asking this question"
      },
      {
        "start": 382.08,
        "duration": 4.679,
        "text": "later uh so I'm gonna turn turn it over"
      },
      {
        "start": 384.319,
        "duration": 6.32,
        "text": "to uh my friend"
      },
      {
        "start": 386.759,
        "duration": 5.921,
        "text": "Alex I'm Alex I am a Marvel gu um I'm"
      },
      {
        "start": 390.639,
        "duration": 4.481,
        "text": "based in Seattle and I lead our"
      },
      {
        "start": 392.68,
        "duration": 4.88,
        "text": "developer ecosystem team building geni"
      },
      {
        "start": 395.12,
        "duration": 4.88,
        "text": "Integrations that um we'll show you a"
      },
      {
        "start": 397.56,
        "duration": 4.68,
        "text": "little bit of in a bit or would you"
      },
      {
        "start": 400.0,
        "duration": 4.639,
        "text": "awesome thanks all right my name is"
      },
      {
        "start": 402.24,
        "duration": 4.04,
        "text": "Carter rasa uh I work with David on the"
      },
      {
        "start": 404.639,
        "duration": 4.361,
        "text": "developer relations team here at data"
      },
      {
        "start": 406.28,
        "duration": 4.759,
        "text": "stack uh like Alex I am located in"
      },
      {
        "start": 409.0,
        "duration": 4.28,
        "text": "Seattle Washington and the reason I"
      },
      {
        "start": 411.039,
        "duration": 4.201,
        "text": "asked the question was because I took uh"
      },
      {
        "start": 413.28,
        "duration": 4.199,
        "text": "my kids to go see Deadpool versus"
      },
      {
        "start": 415.24,
        "duration": 4.679,
        "text": "Wolverine this past weekend so this is"
      },
      {
        "start": 417.479,
        "duration": 4.881,
        "text": "sort of top of mind for me uh however uh"
      },
      {
        "start": 419.919,
        "duration": 5.68,
        "text": "I'm gonna cheat and say neither uh I'm a"
      },
      {
        "start": 422.36,
        "duration": 5.119,
        "text": "Darkhorse guy um that obviously that"
      },
      {
        "start": 425.599,
        "duration": 4.801,
        "text": "that that's a comment about the comics"
      },
      {
        "start": 427.479,
        "duration": 5.12,
        "text": "right um but it also applies to"
      },
      {
        "start": 430.4,
        "duration": 4.84,
        "text": "Fantastic movies that have been made"
      },
      {
        "start": 432.599,
        "duration": 4.6,
        "text": "based on Darkhorse material so sorry Tri"
      },
      {
        "start": 435.24,
        "duration": 3.399,
        "text": "trick question you're both wrong the"
      },
      {
        "start": 437.199,
        "duration": 3.84,
        "text": "answer is"
      },
      {
        "start": 438.639,
        "duration": 3.521,
        "text": "darkh okay so hey thanks for bearing by"
      },
      {
        "start": 441.039,
        "duration": 2.801,
        "text": "the way and also if you're in the chat"
      },
      {
        "start": 442.16,
        "duration": 3.479,
        "text": "feel free to share where you're ding in"
      },
      {
        "start": 443.84,
        "duration": 3.799,
        "text": "from it's Al it's always just amazing"
      },
      {
        "start": 445.639,
        "duration": 5.0,
        "text": "for us to see um all the different"
      },
      {
        "start": 447.639,
        "duration": 5.68,
        "text": "places uh that uh that developers uh"
      },
      {
        "start": 450.639,
        "duration": 4.201,
        "text": "live and and kind of uh and and sort of"
      },
      {
        "start": 453.319,
        "duration": 3.56,
        "text": "dial in from I'm sorry that I'm using"
      },
      {
        "start": 454.84,
        "duration": 4.759,
        "text": "the word dial in but I'm 46 years old"
      },
      {
        "start": 456.879,
        "duration": 4.921,
        "text": "and I remember modems and stuff uh all"
      },
      {
        "start": 459.599,
        "duration": 3.241,
        "text": "right so let let's dive into it uh we've"
      },
      {
        "start": 461.8,
        "duration": 2.76,
        "text": "got you know that was eight eight"
      },
      {
        "start": 462.84,
        "duration": 3.0,
        "text": "minutes eight minutes of Preamble and"
      },
      {
        "start": 464.56,
        "duration": 4.12,
        "text": "we're gonna we're gonna dive into code"
      },
      {
        "start": 465.84,
        "duration": 4.28,
        "text": "super fast so this is a rag 101 talk so"
      },
      {
        "start": 468.68,
        "duration": 3.4,
        "text": "the first thing that's worth talking"
      },
      {
        "start": 470.12,
        "duration": 5.079,
        "text": "about is uh what does rag even mean"
      },
      {
        "start": 472.08,
        "duration": 5.72,
        "text": "right uh so rag is an acronym uh it"
      },
      {
        "start": 475.199,
        "duration": 5.161,
        "text": "stands for retrieval augmented"
      },
      {
        "start": 477.8,
        "duration": 4.839,
        "text": "generation um we're going to go into"
      },
      {
        "start": 480.36,
        "duration": 4.88,
        "text": "more detail about specifically what this"
      },
      {
        "start": 482.639,
        "duration": 5.52,
        "text": "means and specifically how does it work"
      },
      {
        "start": 485.24,
        "duration": 5.12,
        "text": "um but I'd like to sort of I just I like"
      },
      {
        "start": 488.159,
        "duration": 5.121,
        "text": "to when I when I try to explain rag to"
      },
      {
        "start": 490.36,
        "duration": 6.559,
        "text": "someone who is unfamiliar with it um the"
      },
      {
        "start": 493.28,
        "duration": 6.08,
        "text": "way that I explain it is I go backwards"
      },
      {
        "start": 496.919,
        "duration": 4.201,
        "text": "so I say because you because just the"
      },
      {
        "start": 499.36,
        "duration": 3.32,
        "text": "words in This Acronym are not"
      },
      {
        "start": 501.12,
        "duration": 3.079,
        "text": "self-explanatory right it doesn't really"
      },
      {
        "start": 502.68,
        "duration": 3.84,
        "text": "tell you what what's happening right the"
      },
      {
        "start": 504.199,
        "duration": 6.201,
        "text": "way that I think about it is generation"
      },
      {
        "start": 506.52,
        "duration": 7.16,
        "text": "is what you get uh working with an L M"
      },
      {
        "start": 510.4,
        "duration": 5.519,
        "text": "uh with like with with no no tailoring"
      },
      {
        "start": 513.68,
        "duration": 4.96,
        "text": "um or no prompt engineering no nothing"
      },
      {
        "start": 515.919,
        "duration": 5.04,
        "text": "it's kind of a chat GPT style experience"
      },
      {
        "start": 518.64,
        "duration": 4.44,
        "text": "um where you simply ask an llm question"
      },
      {
        "start": 520.959,
        "duration": 3.521,
        "text": "questions um or you ask it to generate"
      },
      {
        "start": 523.08,
        "duration": 3.68,
        "text": "something so it's either generated an"
      },
      {
        "start": 524.48,
        "duration": 4.76,
        "text": "answer or Genera an image right that's"
      },
      {
        "start": 526.76,
        "duration": 5.68,
        "text": "what that's what generation means um to"
      },
      {
        "start": 529.24,
        "duration": 6.039,
        "text": "me augmentation is when you're working"
      },
      {
        "start": 532.44,
        "duration": 4.399,
        "text": "with an llm uh and you're giving it some"
      },
      {
        "start": 535.279,
        "duration": 3.481,
        "text": "instructions right like you're actually"
      },
      {
        "start": 536.839,
        "duration": 4.201,
        "text": "and this is this is sort of like this"
      },
      {
        "start": 538.76,
        "duration": 3.72,
        "text": "prompt engineer in universe that a lot"
      },
      {
        "start": 541.04,
        "duration": 3.039,
        "text": "of people live in right where like"
      },
      {
        "start": 542.48,
        "duration": 4.44,
        "text": "you're giving it some instructions"
      },
      {
        "start": 544.079,
        "duration": 5.241,
        "text": "you're telling it like what its job is"
      },
      {
        "start": 546.92,
        "duration": 3.919,
        "text": "what the boundaries are what it should"
      },
      {
        "start": 549.32,
        "duration": 4.079,
        "text": "how it should respond how it should not"
      },
      {
        "start": 550.839,
        "duration": 5.281,
        "text": "respond um that is generally how I think"
      },
      {
        "start": 553.399,
        "duration": 5.361,
        "text": "of augmentation um and"
      },
      {
        "start": 556.12,
        "duration": 4.56,
        "text": "retrieval uh is basically both of those"
      },
      {
        "start": 558.76,
        "duration": 4.28,
        "text": "two things but where you're actually"
      },
      {
        "start": 560.68,
        "duration": 4.839,
        "text": "fetching context and fetching data from"
      },
      {
        "start": 563.04,
        "duration": 3.88,
        "text": "some other place um so the augmentation"
      },
      {
        "start": 565.519,
        "duration": 3.56,
        "text": "you can think of as static if you're"
      },
      {
        "start": 566.92,
        "duration": 3.88,
        "text": "building an app like the augmentation"
      },
      {
        "start": 569.079,
        "duration": 3.961,
        "text": "could live statically like in your"
      },
      {
        "start": 570.8,
        "duration": 4.88,
        "text": "source code but the retrieval is like no"
      },
      {
        "start": 573.04,
        "duration": 5.76,
        "text": "no no no like we're getting information"
      },
      {
        "start": 575.68,
        "duration": 4.719,
        "text": "context uh from somewhere else perhaps a"
      },
      {
        "start": 578.8,
        "duration": 3.84,
        "text": "database you know perhaps some other"
      },
      {
        "start": 580.399,
        "duration": 4.081,
        "text": "sources uh and then in conjunction with"
      },
      {
        "start": 582.64,
        "duration": 3.6,
        "text": "the augmentation and conjunction with"
      },
      {
        "start": 584.48,
        "duration": 4.08,
        "text": "the generation like we're getting some"
      },
      {
        "start": 586.24,
        "duration": 5.159,
        "text": "really cool results so I hope that's"
      },
      {
        "start": 588.56,
        "duration": 4.959,
        "text": "helpful um like I said we're gonna go"
      },
      {
        "start": 591.399,
        "duration": 4.361,
        "text": "into way more detail um but that's kind"
      },
      {
        "start": 593.519,
        "duration": 3.56,
        "text": "of how I think about Rag and I kind of"
      },
      {
        "start": 595.76,
        "duration": 5.92,
        "text": "think about it"
      },
      {
        "start": 597.079,
        "duration": 6.44,
        "text": "backwards um why rag right um like why"
      },
      {
        "start": 601.68,
        "duration": 5.12,
        "text": "do why are we doing this live stream and"
      },
      {
        "start": 603.519,
        "duration": 5.88,
        "text": "why does anybody care um I I won't you"
      },
      {
        "start": 606.8,
        "duration": 5.4,
        "text": "you can look at that diagram um uh but"
      },
      {
        "start": 609.399,
        "duration": 4.761,
        "text": "at a super high level uh there are just"
      },
      {
        "start": 612.2,
        "duration": 4.079,
        "text": "llms are arguably one of the most"
      },
      {
        "start": 614.16,
        "duration": 3.88,
        "text": "important like technical innovations"
      },
      {
        "start": 616.279,
        "duration": 3.761,
        "text": "that have happened in the last two years"
      },
      {
        "start": 618.04,
        "duration": 4.84,
        "text": "I think that's kind of you people can"
      },
      {
        "start": 620.04,
        "duration": 4.479,
        "text": "argue about this but I think it's pretty"
      },
      {
        "start": 622.88,
        "duration": 3.399,
        "text": "like it's I don't think it's very"
      },
      {
        "start": 624.519,
        "duration": 3.681,
        "text": "arguable like they're they're one of the"
      },
      {
        "start": 626.279,
        "duration": 3.12,
        "text": "most impactive technical innovations"
      },
      {
        "start": 628.2,
        "duration": 3.319,
        "text": "that have happened in the last last"
      },
      {
        "start": 629.399,
        "duration": 5.12,
        "text": "couple years how however there are"
      },
      {
        "start": 631.519,
        "duration": 4.681,
        "text": "problems right like llms um we I talked"
      },
      {
        "start": 634.519,
        "duration": 4.56,
        "text": "about how you don't need to have machine"
      },
      {
        "start": 636.2,
        "duration": 5.16,
        "text": "learn learning experience to to to to"
      },
      {
        "start": 639.079,
        "duration": 3.961,
        "text": "build AI apps because of rag well the"
      },
      {
        "start": 641.36,
        "duration": 4.08,
        "text": "people who build llms have to have"
      },
      {
        "start": 643.04,
        "duration": 6.28,
        "text": "machine learning expertise right like"
      },
      {
        "start": 645.44,
        "duration": 5.959,
        "text": "llms are trained um offline on massive"
      },
      {
        "start": 649.32,
        "duration": 4.68,
        "text": "amounts of publicly available"
      },
      {
        "start": 651.399,
        "duration": 5.361,
        "text": "information um so there are incredibly"
      },
      {
        "start": 654.0,
        "duration": 4.72,
        "text": "knowledgeable uh experienced people who"
      },
      {
        "start": 656.76,
        "duration": 4.44,
        "text": "build all these llms and there are"
      },
      {
        "start": 658.72,
        "duration": 4.64,
        "text": "dozens maybe even hundreds of llms that"
      },
      {
        "start": 661.2,
        "duration": 3.96,
        "text": "application developers can build on um"
      },
      {
        "start": 663.36,
        "duration": 4.0,
        "text": "but once again they're trained off on"
      },
      {
        "start": 665.16,
        "duration": 6.16,
        "text": "this massive Corpus of data and then the"
      },
      {
        "start": 667.36,
        "duration": 7.08,
        "text": "training stops um so if you want to"
      },
      {
        "start": 671.32,
        "duration": 5.72,
        "text": "build applications uh that answer"
      },
      {
        "start": 674.44,
        "duration": 5.28,
        "text": "questions or can provide like"
      },
      {
        "start": 677.04,
        "duration": 5.4,
        "text": "intelligent experiences Based on data"
      },
      {
        "start": 679.72,
        "duration": 4.28,
        "text": "that the llm wasn't trained on like"
      },
      {
        "start": 682.44,
        "duration": 3.399,
        "text": "you're kind of out of luck because the"
      },
      {
        "start": 684.0,
        "duration": 3.959,
        "text": "llm simply doesn't have access to that"
      },
      {
        "start": 685.839,
        "duration": 3.841,
        "text": "information um this applies to the"
      },
      {
        "start": 687.959,
        "duration": 4.56,
        "text": "second bullet point to know your"
      },
      {
        "start": 689.68,
        "duration": 4.959,
        "text": "business's like proprietary or domain"
      },
      {
        "start": 692.519,
        "duration": 3.801,
        "text": "specific information right like whatever"
      },
      {
        "start": 694.639,
        "duration": 3.361,
        "text": "app You're Building like you know you're"
      },
      {
        "start": 696.32,
        "duration": 4.16,
        "text": "building a new Social Network or you're"
      },
      {
        "start": 698.0,
        "duration": 4.8,
        "text": "building a better version of good reads"
      },
      {
        "start": 700.48,
        "duration": 4.0,
        "text": "or like you know you're building uh you"
      },
      {
        "start": 702.8,
        "duration": 4.039,
        "text": "know a better version of kayak or"
      },
      {
        "start": 704.48,
        "duration": 4.76,
        "text": "something you're whatever whatever your"
      },
      {
        "start": 706.839,
        "duration": 4.881,
        "text": "app whatever data your app is built on"
      },
      {
        "start": 709.24,
        "duration": 4.48,
        "text": "top of by definition like the llms"
      },
      {
        "start": 711.72,
        "duration": 3.76,
        "text": "probably don't have access to that data"
      },
      {
        "start": 713.72,
        "duration": 3.6,
        "text": "right so they can't you if you want to"
      },
      {
        "start": 715.48,
        "duration": 4.4,
        "text": "build an an intelligent like assistant"
      },
      {
        "start": 717.32,
        "duration": 5.079,
        "text": "or advisor or something um that's built"
      },
      {
        "start": 719.88,
        "duration": 4.16,
        "text": "on top of your own proprietary data uh"
      },
      {
        "start": 722.399,
        "duration": 4.041,
        "text": "there's kind of an open question of like"
      },
      {
        "start": 724.04,
        "duration": 4.32,
        "text": "how you like how you would how the llm"
      },
      {
        "start": 726.44,
        "duration": 3.16,
        "text": "would even have access that information"
      },
      {
        "start": 728.36,
        "duration": 3.52,
        "text": "to be able to build the better"
      },
      {
        "start": 729.6,
        "duration": 4.28,
        "text": "experience for the user um and then this"
      },
      {
        "start": 731.88,
        "duration": 3.72,
        "text": "is related to the two things above like"
      },
      {
        "start": 733.88,
        "duration": 4.12,
        "text": "LMS just don't have access to realtime"
      },
      {
        "start": 735.6,
        "duration": 4.28,
        "text": "information um there are uh you know"
      },
      {
        "start": 738.0,
        "duration": 4.32,
        "text": "like there's a lot of incredibly"
      },
      {
        "start": 739.88,
        "duration": 4.56,
        "text": "incredible companies that are building"
      },
      {
        "start": 742.32,
        "duration": 4.079,
        "text": "smarter and smarter and smarter llms"
      },
      {
        "start": 744.44,
        "duration": 3.8,
        "text": "like an open AI anthropic I mean there's"
      },
      {
        "start": 746.399,
        "duration": 4.041,
        "text": "a a lot of money is being poured into"
      },
      {
        "start": 748.24,
        "duration": 5.88,
        "text": "this industry to build more and more"
      },
      {
        "start": 750.44,
        "duration": 6.28,
        "text": "capable llms um that have like more and"
      },
      {
        "start": 754.12,
        "duration": 4.399,
        "text": "more updated information um but"
      },
      {
        "start": 756.72,
        "duration": 4.679,
        "text": "ultimately it's not real time like even"
      },
      {
        "start": 758.519,
        "duration": 4.401,
        "text": "the absolute state-of-the-art best llms"
      },
      {
        "start": 761.399,
        "duration": 5.961,
        "text": "um are simply not going to have access"
      },
      {
        "start": 762.92,
        "duration": 6.159,
        "text": "to real time information um so so so"
      },
      {
        "start": 767.36,
        "duration": 3.68,
        "text": "these are problems that application"
      },
      {
        "start": 769.079,
        "duration": 4.281,
        "text": "developers have trying to think about"
      },
      {
        "start": 771.04,
        "duration": 5.239,
        "text": "like well look like I I want to build"
      },
      {
        "start": 773.36,
        "duration": 5.52,
        "text": "more intelligent experiences for the"
      },
      {
        "start": 776.279,
        "duration": 4.24,
        "text": "users of my applications but because of"
      },
      {
        "start": 778.88,
        "duration": 4.199,
        "text": "these three bullet points like I just I"
      },
      {
        "start": 780.519,
        "duration": 4.601,
        "text": "don't understand how to tie into like"
      },
      {
        "start": 783.079,
        "duration": 5.241,
        "text": "the capab tie like my application into"
      },
      {
        "start": 785.12,
        "duration": 5.04,
        "text": "the capabilities of llm and uh and rag"
      },
      {
        "start": 788.32,
        "duration": 4.4,
        "text": "is and so rag is not a product you don't"
      },
      {
        "start": 790.16,
        "duration": 4.6,
        "text": "go to the Walmart and buy a rag um rag"
      },
      {
        "start": 792.72,
        "duration": 4.52,
        "text": "is just a technique that Alex and David"
      },
      {
        "start": 794.76,
        "duration": 4.6,
        "text": "are gonna going to show you it's a"
      },
      {
        "start": 797.24,
        "duration": 3.719,
        "text": "technique that application developers"
      },
      {
        "start": 799.36,
        "duration": 5.32,
        "text": "can use"
      },
      {
        "start": 800.959,
        "duration": 6.841,
        "text": "to help the llm to provide context for"
      },
      {
        "start": 804.68,
        "duration": 5.0,
        "text": "llms and help it to sort of provide more"
      },
      {
        "start": 807.8,
        "duration": 4.0,
        "text": "relevant and like better answers to"
      },
      {
        "start": 809.68,
        "duration": 5.64,
        "text": "questions or better are um better are"
      },
      {
        "start": 811.8,
        "duration": 6.8,
        "text": "generation to prompts that users have um"
      },
      {
        "start": 815.32,
        "duration": 5.28,
        "text": "so rather than uh me continuing to talk"
      },
      {
        "start": 818.6,
        "duration": 4.84,
        "text": "um I'm gonna turn it over to Alex and"
      },
      {
        "start": 820.6,
        "duration": 5.32,
        "text": "he's gonna dive into some code examples"
      },
      {
        "start": 823.44,
        "duration": 4.68,
        "text": "of like what L what it looks like to"
      },
      {
        "start": 825.92,
        "duration": 4.359,
        "text": "work with an llm programmatically"
      },
      {
        "start": 828.12,
        "duration": 3.959,
        "text": "without Rag and then what it looks like"
      },
      {
        "start": 830.279,
        "duration": 3.881,
        "text": "to work with an llm programmatically"
      },
      {
        "start": 832.079,
        "duration": 3.641,
        "text": "with rag so that you get a real grounded"
      },
      {
        "start": 834.16,
        "duration": 2.88,
        "text": "experience on like what the what the"
      },
      {
        "start": 835.72,
        "duration": 3.479,
        "text": "difference looks like and like what the"
      },
      {
        "start": 837.04,
        "duration": 4.919,
        "text": "benefits are so I'm G to go ahead and"
      },
      {
        "start": 839.199,
        "duration": 2.76,
        "text": "turn it over to"
      },
      {
        "start": 842.88,
        "duration": 6.04,
        "text": "Alex all"
      },
      {
        "start": 845.519,
        "duration": 6.041,
        "text": "right cool um so I'm going to show a"
      },
      {
        "start": 848.92,
        "duration": 6.44,
        "text": "really basic example of why you need to"
      },
      {
        "start": 851.56,
        "duration": 5.839,
        "text": "use why rag is valuable um so I kind of"
      },
      {
        "start": 855.36,
        "duration": 5.68,
        "text": "made the questionable life decision of"
      },
      {
        "start": 857.399,
        "duration": 6.401,
        "text": "buying a oldland river um and I use rag"
      },
      {
        "start": 861.04,
        "duration": 4.08,
        "text": "to find replacement parts um so I'm just"
      },
      {
        "start": 863.8,
        "duration": 3.52,
        "text": "going to walk you through kind of the"
      },
      {
        "start": 865.12,
        "duration": 4.719,
        "text": "code of what life looks like before Rag"
      },
      {
        "start": 867.32,
        "duration": 5.079,
        "text": "and after Rag and all this will be"
      },
      {
        "start": 869.839,
        "duration": 4.36,
        "text": "shared so you can try it after this um"
      },
      {
        "start": 872.399,
        "duration": 3.721,
        "text": "so the first step here is we're"
      },
      {
        "start": 874.199,
        "duration": 5.44,
        "text": "instelling our dependencies for this"
      },
      {
        "start": 876.12,
        "duration": 6.24,
        "text": "example we're basically using Three core"
      },
      {
        "start": 879.639,
        "duration": 6.2,
        "text": "pieces of tech unstructured which is a"
      },
      {
        "start": 882.36,
        "duration": 5.279,
        "text": "popular uh gen ETL tool right you need"
      },
      {
        "start": 885.839,
        "duration": 3.281,
        "text": "to get kind of your your Corpus of"
      },
      {
        "start": 887.639,
        "duration": 3.601,
        "text": "documents into a vector database we're"
      },
      {
        "start": 889.12,
        "duration": 4.6,
        "text": "using instructure to do that um we're"
      },
      {
        "start": 891.24,
        "duration": 5.039,
        "text": "using Lane chain Lane chain is the"
      },
      {
        "start": 893.72,
        "duration": 3.679,
        "text": "popular orchestration framework right so"
      },
      {
        "start": 896.279,
        "duration": 3.48,
        "text": "rather than learning a bunch of"
      },
      {
        "start": 897.399,
        "duration": 4.281,
        "text": "different apis we interact directly with"
      },
      {
        "start": 899.759,
        "duration": 3.921,
        "text": "Lane chain which then kind of calls"
      },
      {
        "start": 901.68,
        "duration": 4.959,
        "text": "these apis in the background and then"
      },
      {
        "start": 903.68,
        "duration": 5.04,
        "text": "we're using open AI um for the LM and"
      },
      {
        "start": 906.639,
        "duration": 5.361,
        "text": "our edings um so this is pretty basic"
      },
      {
        "start": 908.72,
        "duration": 6.28,
        "text": "here I'm just installing all the"
      },
      {
        "start": 912.0,
        "duration": 5.88,
        "text": "dependencies um and here is just really"
      },
      {
        "start": 915.0,
        "duration": 4.8,
        "text": "basic example of what life looks like"
      },
      {
        "start": 917.88,
        "duration": 5.36,
        "text": "when you ask the LM a question without"
      },
      {
        "start": 919.8,
        "duration": 7.52,
        "text": "using red right at the top I'm setting"
      },
      {
        "start": 923.24,
        "duration": 6.079,
        "text": "up um open AI right I'm telling I'm"
      },
      {
        "start": 927.32,
        "duration": 4.959,
        "text": "plugging in my key I'm plugging the"
      },
      {
        "start": 929.319,
        "duration": 5.281,
        "text": "model and I'm just asking open AI a"
      },
      {
        "start": 932.279,
        "duration": 4.281,
        "text": "really basic automotive question about"
      },
      {
        "start": 934.6,
        "duration": 4.799,
        "text": "my car right what's the parts number for"
      },
      {
        "start": 936.56,
        "duration": 4.12,
        "text": "the tray on top of the dashboard and you"
      },
      {
        "start": 939.399,
        "duration": 3.761,
        "text": "can see right"
      },
      {
        "start": 940.68,
        "duration": 5.24,
        "text": "here um the answer doesn't make any"
      },
      {
        "start": 943.16,
        "duration": 4.119,
        "text": "sense right to provide the part number"
      },
      {
        "start": 945.92,
        "duration": 4.64,
        "text": "Alex can you zoom in a little bit can"
      },
      {
        "start": 947.279,
        "duration": 5.881,
        "text": "you make it bigger thank you there we"
      },
      {
        "start": 950.56,
        "duration": 5.6,
        "text": "go is that"
      },
      {
        "start": 953.16,
        "duration": 4.76,
        "text": "better cool um to provide the correct"
      },
      {
        "start": 956.16,
        "duration": 3.56,
        "text": "par number I'll need more information"
      },
      {
        "start": 957.92,
        "duration": 4.479,
        "text": "about your vehicle right such as make"
      },
      {
        "start": 959.72,
        "duration": 4.0,
        "text": "model all that um and that makes sense"
      },
      {
        "start": 962.399,
        "duration": 3.12,
        "text": "right because this is just the"
      },
      {
        "start": 963.72,
        "duration": 4.559,
        "text": "equivalent of plugging in a question in"
      },
      {
        "start": 965.519,
        "duration": 5.56,
        "text": "the chat GPT chat knows nothing about"
      },
      {
        "start": 968.279,
        "duration": 5.441,
        "text": "you right so it's unable to answer very"
      },
      {
        "start": 971.079,
        "duration": 5.32,
        "text": "specific questions um so this is where"
      },
      {
        "start": 973.72,
        "duration": 4.76,
        "text": "kind of rag comes in to help chat GPT"
      },
      {
        "start": 976.399,
        "duration": 5.401,
        "text": "gain the necessary context answer these"
      },
      {
        "start": 978.48,
        "duration": 6.919,
        "text": "questions well um so for this rag"
      },
      {
        "start": 981.8,
        "duration": 6.839,
        "text": "example I'm going to take just a couple"
      },
      {
        "start": 985.399,
        "duration": 6.56,
        "text": "basic PDF Parts manuals right so I have"
      },
      {
        "start": 988.639,
        "duration": 6.281,
        "text": "one just kind of manual on um like how"
      },
      {
        "start": 991.959,
        "duration": 6.24,
        "text": "to fix things um so this is a th page"
      },
      {
        "start": 994.92,
        "duration": 6.279,
        "text": "PDF right you can see 164 pages and then"
      },
      {
        "start": 998.199,
        "duration": 5.481,
        "text": "I have another PDF that shows all the"
      },
      {
        "start": 1001.199,
        "duration": 6.2,
        "text": "parts for the car all the part numbers"
      },
      {
        "start": 1003.68,
        "duration": 5.0,
        "text": "where to buy them all that I'm so using"
      },
      {
        "start": 1007.399,
        "duration": 4.12,
        "text": "so right here all I'm doing is"
      },
      {
        "start": 1008.68,
        "duration": 4.399,
        "text": "downloading these PDFs I'm here we can"
      },
      {
        "start": 1011.519,
        "duration": 3.201,
        "text": "see they've been downloaded on the left"
      },
      {
        "start": 1013.079,
        "duration": 3.68,
        "text": "hand side"
      },
      {
        "start": 1014.72,
        "duration": 4.28,
        "text": "part um and this is where it starts"
      },
      {
        "start": 1016.759,
        "duration": 4.76,
        "text": "getting interesting right so now now"
      },
      {
        "start": 1019.0,
        "duration": 5.0,
        "text": "what I'm doing is I'm using unstructured"
      },
      {
        "start": 1021.519,
        "duration": 7.121,
        "text": "technology um to read these P parsel"
      },
      {
        "start": 1024.0,
        "duration": 6.72,
        "text": "these PDFs um chunk them and write them"
      },
      {
        "start": 1028.64,
        "duration": 4.159,
        "text": "all to asdb right so inst structured"
      },
      {
        "start": 1030.72,
        "duration": 5.28,
        "text": "makes it super easy to build these basic"
      },
      {
        "start": 1032.799,
        "duration": 6.081,
        "text": "pipelines I I set up kind of the um the"
      },
      {
        "start": 1036.0,
        "duration": 6.88,
        "text": "files I wanted to read I I configure the"
      },
      {
        "start": 1038.88,
        "duration": 6.4,
        "text": "embedding model then I hit run and a"
      },
      {
        "start": 1042.88,
        "duration": 5.28,
        "text": "couple minutes later unstructured has"
      },
      {
        "start": 1045.28,
        "duration": 4.72,
        "text": "pars all these documents and ritten them"
      },
      {
        "start": 1048.16,
        "duration": 4.519,
        "text": "to"
      },
      {
        "start": 1050.0,
        "duration": 5.919,
        "text": "DB I'm so here you can see here now I'm"
      },
      {
        "start": 1052.679,
        "duration": 4.921,
        "text": "on kind of the asdb dashboard I can"
      },
      {
        "start": 1055.919,
        "duration": 4.561,
        "text": "scroll down and I can see that"
      },
      {
        "start": 1057.6,
        "duration": 6.439,
        "text": "unstructured has read all these PDFs"
      },
      {
        "start": 1060.48,
        "duration": 5.64,
        "text": "broken all the the text into chunks and"
      },
      {
        "start": 1064.039,
        "duration": 4.081,
        "text": "written them all to the vector database"
      },
      {
        "start": 1066.12,
        "duration": 4.559,
        "text": "right so I can see something here about"
      },
      {
        "start": 1068.12,
        "duration": 5.16,
        "text": "removing Clips here's something about"
      },
      {
        "start": 1070.679,
        "duration": 5.281,
        "text": "the front axle but all of this content"
      },
      {
        "start": 1073.28,
        "duration": 5.68,
        "text": "from these PDFs I just showed has been"
      },
      {
        "start": 1075.96,
        "duration": 3.719,
        "text": "read from unstructured and written to"
      },
      {
        "start": 1078.96,
        "duration": 3.16,
        "text": "the"
      },
      {
        "start": 1079.679,
        "duration": 4.721,
        "text": "database um this this is what we refer"
      },
      {
        "start": 1082.12,
        "duration": 4.24,
        "text": "to as the ingestion the data ingestion"
      },
      {
        "start": 1084.4,
        "duration": 3.88,
        "text": "set in Carter diagram before right in"
      },
      {
        "start": 1086.36,
        "duration": 3.559,
        "text": "order to do rag you somehow need all"
      },
      {
        "start": 1088.28,
        "duration": 3.48,
        "text": "your documents to be in a vector"
      },
      {
        "start": 1089.919,
        "duration": 5.161,
        "text": "database like actually should"
      },
      {
        "start": 1091.76,
        "duration": 4.64,
        "text": "be um so now that we've done that here's"
      },
      {
        "start": 1095.08,
        "duration": 3.64,
        "text": "where it gets super"
      },
      {
        "start": 1096.4,
        "duration": 4.68,
        "text": "interesting um so here I'm doing some"
      },
      {
        "start": 1098.72,
        "duration": 4.92,
        "text": "basic configuration of Lane"
      },
      {
        "start": 1101.08,
        "duration": 4.16,
        "text": "chain um I'm setting up the vector store"
      },
      {
        "start": 1103.64,
        "duration": 4.44,
        "text": "I'm setting up the embedding"
      },
      {
        "start": 1105.24,
        "duration": 5.24,
        "text": "model and I'm doing a basic similarity"
      },
      {
        "start": 1108.08,
        "duration": 4.8,
        "text": "search right these two lines of code so"
      },
      {
        "start": 1110.48,
        "duration": 4.559,
        "text": "I want to take the question I want to"
      },
      {
        "start": 1112.88,
        "duration": 4.52,
        "text": "search in my Vector store for similar"
      },
      {
        "start": 1115.039,
        "duration": 5.961,
        "text": "for documents related to that"
      },
      {
        "start": 1117.4,
        "duration": 5.8,
        "text": "question and now I'm going to ask the LM"
      },
      {
        "start": 1121.0,
        "duration": 4.4,
        "text": "the same I'm gonna enter the same exact"
      },
      {
        "start": 1123.2,
        "duration": 5.56,
        "text": "prompt but I'm this time I'm going to"
      },
      {
        "start": 1125.4,
        "duration": 5.72,
        "text": "include the relevant Vector sore"
      },
      {
        "start": 1128.76,
        "duration": 5.12,
        "text": "results and here now you can see we get"
      },
      {
        "start": 1131.12,
        "duration": 5.4,
        "text": "a super accurate answer right so the LM"
      },
      {
        "start": 1133.88,
        "duration": 6.56,
        "text": "is able to find the exact part"
      },
      {
        "start": 1136.52,
        "duration": 5.68,
        "text": "number right here and give like a really"
      },
      {
        "start": 1140.44,
        "duration": 4.16,
        "text": "accurate response so if I plug that in"
      },
      {
        "start": 1142.2,
        "duration": 2.4,
        "text": "right"
      },
      {
        "start": 1146.48,
        "duration": 5.72,
        "text": "here you can see that it's found this"
      },
      {
        "start": 1149.0,
        "duration": 5.76,
        "text": "coin tray right so previously without"
      },
      {
        "start": 1152.2,
        "duration": 5.12,
        "text": "rag that would mean you know going"
      },
      {
        "start": 1154.76,
        "duration": 5.399,
        "text": "through an 800 page PDF um so you could"
      },
      {
        "start": 1157.32,
        "duration": 4.44,
        "text": "really see how this could be um just"
      },
      {
        "start": 1160.159,
        "duration": 4.921,
        "text": "like a super efficient way to read your"
      },
      {
        "start": 1161.76,
        "duration": 7.32,
        "text": "business's PDF or other type of"
      },
      {
        "start": 1165.08,
        "duration": 4.0,
        "text": "content cool"
      },
      {
        "start": 1169.919,
        "duration": 6.041,
        "text": "and I will hand it over to David um so"
      },
      {
        "start": 1173.36,
        "duration": 2.6,
        "text": "walk through the next"
      },
      {
        "start": 1176.12,
        "duration": 6.76,
        "text": "example Al righty let me go ahead and"
      },
      {
        "start": 1180.159,
        "duration": 2.721,
        "text": "share my"
      },
      {
        "start": 1183.88,
        "duration": 4.36,
        "text": "screen and then while while David is"
      },
      {
        "start": 1185.96,
        "duration": 4.56,
        "text": "doing that um yeah uh we had a couple"
      },
      {
        "start": 1188.24,
        "duration": 4.88,
        "text": "great questions uh come up in the chat"
      },
      {
        "start": 1190.52,
        "duration": 5.08,
        "text": "um feel free to use the uh I've already"
      },
      {
        "start": 1193.12,
        "duration": 5.76,
        "text": "like migrated some of those questions to"
      },
      {
        "start": 1195.6,
        "duration": 5.28,
        "text": "the actual Q&A widget uh so uh so but"
      },
      {
        "start": 1198.88,
        "duration": 4.32,
        "text": "feel free to ask the ask your questions"
      },
      {
        "start": 1200.88,
        "duration": 4.36,
        "text": "like directly in the Q&A widget uh and"
      },
      {
        "start": 1203.2,
        "duration": 5.12,
        "text": "we'll make sure to run through all of"
      },
      {
        "start": 1205.24,
        "duration": 4.6,
        "text": "those um during the Q&A session uh"
      },
      {
        "start": 1208.32,
        "duration": 4.28,
        "text": "thanks for the feedback about making"
      },
      {
        "start": 1209.84,
        "duration": 5.6,
        "text": "things bigger um hopefully uh folks were"
      },
      {
        "start": 1212.6,
        "duration": 5.68,
        "text": "able to to kind of like uh follow along"
      },
      {
        "start": 1215.44,
        "duration": 5.92,
        "text": "with Alex um after he he upsized a"
      },
      {
        "start": 1218.28,
        "duration": 6.36,
        "text": "little bit and then uh I I I made David"
      },
      {
        "start": 1221.36,
        "duration": 4.84,
        "text": "promise to like uh zoom in as he's as"
      },
      {
        "start": 1224.64,
        "duration": 4.36,
        "text": "he's sort of oh I'll Zoom don't you"
      },
      {
        "start": 1226.2,
        "duration": 5.44,
        "text": "worry yeah yeah yeah no worries um"
      },
      {
        "start": 1229.0,
        "duration": 6.559,
        "text": "awesome uh and awesome cool so yeah"
      },
      {
        "start": 1231.64,
        "duration": 5.519,
        "text": "David take it take it away yeah so where"
      },
      {
        "start": 1235.559,
        "duration": 3.201,
        "text": "you know what Alex was just shown you a"
      },
      {
        "start": 1237.159,
        "duration": 3.361,
        "text": "moment ago you know a collab notebook"
      },
      {
        "start": 1238.76,
        "duration": 4.039,
        "text": "using some python things like that you"
      },
      {
        "start": 1240.52,
        "duration": 4.76,
        "text": "know pretty much in raw code right um"
      },
      {
        "start": 1242.799,
        "duration": 4.601,
        "text": "you could absolutely do a r pipeline"
      },
      {
        "start": 1245.28,
        "duration": 4.519,
        "text": "that way another potential option though"
      },
      {
        "start": 1247.4,
        "duration": 4.88,
        "text": "is to use a tool like Lang flow so this"
      },
      {
        "start": 1249.799,
        "duration": 5.0,
        "text": "display you're seeing here um this is"
      },
      {
        "start": 1252.28,
        "duration": 5.16,
        "text": "this is a free open source tool called"
      },
      {
        "start": 1254.799,
        "duration": 4.76,
        "text": "langlow um this is this is part of data"
      },
      {
        "start": 1257.44,
        "duration": 4.04,
        "text": "stacks's gen stack now what you're"
      },
      {
        "start": 1259.559,
        "duration": 3.521,
        "text": "seeing here on the screen is you know"
      },
      {
        "start": 1261.48,
        "duration": 3.28,
        "text": "I've got some Flows In play and stuff"
      },
      {
        "start": 1263.08,
        "duration": 4.04,
        "text": "but what I really want to show you is"
      },
      {
        "start": 1264.76,
        "duration": 4.12,
        "text": "when you first build up like you start"
      },
      {
        "start": 1267.12,
        "duration": 4.679,
        "text": "up llow right you're going to have like"
      },
      {
        "start": 1268.88,
        "duration": 6.2,
        "text": "a blank canvas and llow allows you to"
      },
      {
        "start": 1271.799,
        "duration": 5.321,
        "text": "visually construct gen workflows um so a"
      },
      {
        "start": 1275.08,
        "duration": 4.079,
        "text": "lot of what Alex was just showing you"
      },
      {
        "start": 1277.12,
        "duration": 3.32,
        "text": "there's a gen flow there but you kind of"
      },
      {
        "start": 1279.159,
        "duration": 3.081,
        "text": "have to read the code and understand"
      },
      {
        "start": 1280.44,
        "duration": 3.68,
        "text": "what's going on you're limited to python"
      },
      {
        "start": 1282.24,
        "duration": 3.64,
        "text": "so and so forth so when I first started"
      },
      {
        "start": 1284.12,
        "duration": 3.48,
        "text": "bling flow I might go to something like"
      },
      {
        "start": 1285.88,
        "duration": 3.799,
        "text": "this new project here in the top"
      },
      {
        "start": 1287.6,
        "duration": 3.84,
        "text": "rightand corner and I can pick from all"
      },
      {
        "start": 1289.679,
        "duration": 4.24,
        "text": "these various templates now the one that"
      },
      {
        "start": 1291.44,
        "duration": 5.4,
        "text": "we care about today right is this Vector"
      },
      {
        "start": 1293.919,
        "duration": 5.081,
        "text": "store rag so what I've done is I have"
      },
      {
        "start": 1296.84,
        "duration": 5.16,
        "text": "now I'm purposely zoomed out I will zoom"
      },
      {
        "start": 1299.0,
        "duration": 4.159,
        "text": "in in just a moment David D not to not"
      },
      {
        "start": 1302.0,
        "duration": 4.039,
        "text": "to interrupt your"
      },
      {
        "start": 1303.159,
        "duration": 4.281,
        "text": "flow no nope no no pun intended uh for"
      },
      {
        "start": 1306.039,
        "duration": 3.281,
        "text": "folks that are watching like you're"
      },
      {
        "start": 1307.44,
        "duration": 3.8,
        "text": "showing off a really cool tool it looks"
      },
      {
        "start": 1309.32,
        "duration": 3.839,
        "text": "like you're in a browser like how did"
      },
      {
        "start": 1311.24,
        "duration": 3.52,
        "text": "you install this like what like how how"
      },
      {
        "start": 1313.159,
        "duration": 3.88,
        "text": "do they we'll send instructions later"
      },
      {
        "start": 1314.76,
        "duration": 4.799,
        "text": "but like what what are we looking at"
      },
      {
        "start": 1317.039,
        "duration": 4.201,
        "text": "yeah so so llow itself is in Python so"
      },
      {
        "start": 1319.559,
        "duration": 3.921,
        "text": "this would be like a pip install L flow"
      },
      {
        "start": 1321.24,
        "duration": 3.96,
        "text": "kind of thing um you know so I am"
      },
      {
        "start": 1323.48,
        "duration": 4.72,
        "text": "running this locally right you you can"
      },
      {
        "start": 1325.2,
        "duration": 4.64,
        "text": "see right here um I don't think it's"
      },
      {
        "start": 1328.2,
        "duration": 3.079,
        "text": "going to zoom that much but yeah you"
      },
      {
        "start": 1329.84,
        "duration": 2.48,
        "text": "know I am running this locally you could"
      },
      {
        "start": 1331.279,
        "duration": 3.0,
        "text": "do it let's say with the docker"
      },
      {
        "start": 1332.32,
        "duration": 3.839,
        "text": "container you could deploy it on things"
      },
      {
        "start": 1334.279,
        "duration": 3.561,
        "text": "like it's on hugging face spaces you can"
      },
      {
        "start": 1336.159,
        "duration": 3.4,
        "text": "deploy to railway render all sorts of"
      },
      {
        "start": 1337.84,
        "duration": 3.6,
        "text": "different options from that standpoint"
      },
      {
        "start": 1339.559,
        "duration": 3.321,
        "text": "but it is just a pip install right at"
      },
      {
        "start": 1341.44,
        "duration": 3.719,
        "text": "the end of the day because it is you"
      },
      {
        "start": 1342.88,
        "duration": 4.64,
        "text": "know we are working with python in this"
      },
      {
        "start": 1345.159,
        "duration": 3.561,
        "text": "case um yeah cool and and I I just"
      },
      {
        "start": 1347.52,
        "duration": 2.519,
        "text": "wanted to kind of like level set for"
      },
      {
        "start": 1348.72,
        "duration": 3.079,
        "text": "folks that are watching so like David"
      },
      {
        "start": 1350.039,
        "duration": 3.961,
        "text": "David's showing off a tool that any one"
      },
      {
        "start": 1351.799,
        "duration": 4.841,
        "text": "of you could pip install it's completely"
      },
      {
        "start": 1354.0,
        "duration": 4.799,
        "text": "open source completely free um"
      },
      {
        "start": 1356.64,
        "duration": 5.159,
        "text": "completely vendor agnostic um and then"
      },
      {
        "start": 1358.799,
        "duration": 5.24,
        "text": "like the this uh this this uh sort of"
      },
      {
        "start": 1361.799,
        "duration": 3.841,
        "text": "like visual editor that you're seeing is"
      },
      {
        "start": 1364.039,
        "duration": 4.841,
        "text": "a web based application but it's running"
      },
      {
        "start": 1365.64,
        "duration": 5.639,
        "text": "locally on his computer yes um awesome"
      },
      {
        "start": 1368.88,
        "duration": 5.36,
        "text": "and then like conver conversely um what"
      },
      {
        "start": 1371.279,
        "duration": 5.88,
        "text": "Alex was showing you uh with our Astro"
      },
      {
        "start": 1374.24,
        "duration": 5.439,
        "text": "database um that is a that's a a hosted"
      },
      {
        "start": 1377.159,
        "duration": 5.0,
        "text": "server lless database where um all of"
      },
      {
        "start": 1379.679,
        "duration": 5.961,
        "text": "you can sign up for Astra uh for free"
      },
      {
        "start": 1382.159,
        "duration": 7.041,
        "text": "like at no cost um as developers um but"
      },
      {
        "start": 1385.64,
        "duration": 4.96,
        "text": "it is a a hosted serverless database um"
      },
      {
        "start": 1389.2,
        "duration": 2.959,
        "text": "that you'd be that you'd be interacting"
      },
      {
        "start": 1390.6,
        "duration": 3.12,
        "text": "with so just wanted to make sure"
      },
      {
        "start": 1392.159,
        "duration": 3.321,
        "text": "everyone was kind of clear about the the"
      },
      {
        "start": 1393.72,
        "duration": 3.24,
        "text": "difference between these two tools um"
      },
      {
        "start": 1395.48,
        "duration": 5.4,
        "text": "sorry David I'll I'll let you get back"
      },
      {
        "start": 1396.96,
        "duration": 6.56,
        "text": "to it yeah no worries no worries so um"
      },
      {
        "start": 1400.88,
        "duration": 4.72,
        "text": "so from a rag pipeline right what Alex"
      },
      {
        "start": 1403.52,
        "duration": 4.039,
        "text": "and um Carter have been talking about up"
      },
      {
        "start": 1405.6,
        "duration": 3.439,
        "text": "into this point um we're we're really"
      },
      {
        "start": 1407.559,
        "duration": 3.48,
        "text": "seeing that there's we're seeing that"
      },
      {
        "start": 1409.039,
        "duration": 4.201,
        "text": "here implemented in this this visual"
      },
      {
        "start": 1411.039,
        "duration": 4.76,
        "text": "flow um so why I'm zoomed out so this"
      },
      {
        "start": 1413.24,
        "duration": 4.16,
        "text": "would be the vector rag template um you"
      },
      {
        "start": 1415.799,
        "duration": 4.081,
        "text": "know before modifications or anything it"
      },
      {
        "start": 1417.4,
        "duration": 4.44,
        "text": "looks like this and notice here there"
      },
      {
        "start": 1419.88,
        "duration": 3.36,
        "text": "actually two different flows in here you"
      },
      {
        "start": 1421.84,
        "duration": 3.68,
        "text": "have one that I'll call like the"
      },
      {
        "start": 1423.24,
        "duration": 4.039,
        "text": "generative flow um so when Alex was"
      },
      {
        "start": 1425.52,
        "duration": 3.399,
        "text": "talking about the data that he was"
      },
      {
        "start": 1427.279,
        "duration": 2.76,
        "text": "showing you in the database and then"
      },
      {
        "start": 1428.919,
        "duration": 2.681,
        "text": "structured and things like that there"
      },
      {
        "start": 1430.039,
        "duration": 4.601,
        "text": "was some process that was actually"
      },
      {
        "start": 1431.6,
        "duration": 5.079,
        "text": "iterating through PDFs it was chunking"
      },
      {
        "start": 1434.64,
        "duration": 4.08,
        "text": "through the data storing you know"
      },
      {
        "start": 1436.679,
        "duration": 3.761,
        "text": "converting the relevant mey parts the"
      },
      {
        "start": 1438.72,
        "duration": 3.959,
        "text": "data and Vector embeddings you know"
      },
      {
        "start": 1440.44,
        "duration": 4.64,
        "text": "putting it in a a version that the the"
      },
      {
        "start": 1442.679,
        "duration": 4.201,
        "text": "Gen you know the llms can understand and"
      },
      {
        "start": 1445.08,
        "duration": 3.719,
        "text": "the the vector shares can understand and"
      },
      {
        "start": 1446.88,
        "duration": 4.52,
        "text": "then storing that in the database so"
      },
      {
        "start": 1448.799,
        "duration": 5.0,
        "text": "that's this part of the flow now in this"
      },
      {
        "start": 1451.4,
        "duration": 3.879,
        "text": "case in langlow um I have filled out"
      },
      {
        "start": 1453.799,
        "duration": 2.961,
        "text": "some of the information you know I've"
      },
      {
        "start": 1455.279,
        "duration": 3.081,
        "text": "actually got a database right over here"
      },
      {
        "start": 1456.76,
        "duration": 3.799,
        "text": "in Astra I have a collection called"
      },
      {
        "start": 1458.36,
        "duration": 4.08,
        "text": "langlow um so I filled out some of these"
      },
      {
        "start": 1460.559,
        "duration": 3.161,
        "text": "details but the template itself so if I"
      },
      {
        "start": 1462.44,
        "duration": 3.0,
        "text": "were to just go I'm just going to go"
      },
      {
        "start": 1463.72,
        "duration": 3.92,
        "text": "back real quick and if I just said"
      },
      {
        "start": 1465.44,
        "duration": 4.64,
        "text": "Vector store rag right it'll create a"
      },
      {
        "start": 1467.64,
        "duration": 4.56,
        "text": "template that looks just like this um so"
      },
      {
        "start": 1470.08,
        "duration": 5.68,
        "text": "you already have the logic and the and"
      },
      {
        "start": 1472.2,
        "duration": 4.88,
        "text": "the like the flow of your gen your rag"
      },
      {
        "start": 1475.76,
        "duration": 3.24,
        "text": "pipeline already kind of worked out for"
      },
      {
        "start": 1477.08,
        "duration": 4.24,
        "text": "you all right so let me go back here to"
      },
      {
        "start": 1479.0,
        "duration": 4.88,
        "text": "this the one I filled out um and then"
      },
      {
        "start": 1481.32,
        "duration": 5.2,
        "text": "the top portion here is really the query"
      },
      {
        "start": 1483.88,
        "duration": 5.24,
        "text": "portion right so this is the part"
      },
      {
        "start": 1486.52,
        "duration": 4.84,
        "text": "where um we will take whatever query"
      },
      {
        "start": 1489.12,
        "duration": 3.48,
        "text": "that we have um and I'm gonna I'm going"
      },
      {
        "start": 1491.36,
        "duration": 2.679,
        "text": "to step through all these by the way in"
      },
      {
        "start": 1492.6,
        "duration": 3.04,
        "text": "a second I'm not going to just you know"
      },
      {
        "start": 1494.039,
        "duration": 3.601,
        "text": "Force you all to just understand exactly"
      },
      {
        "start": 1495.64,
        "duration": 4.44,
        "text": "what's going on um but it allows me to"
      },
      {
        "start": 1497.64,
        "duration": 4.639,
        "text": "perform some type the query get the data"
      },
      {
        "start": 1500.08,
        "duration": 4.199,
        "text": "from my database so this is a really key"
      },
      {
        "start": 1502.279,
        "duration": 4.201,
        "text": "part of the rag portion right the"
      },
      {
        "start": 1504.279,
        "duration": 4.601,
        "text": "retrieval part so when we're going to"
      },
      {
        "start": 1506.48,
        "duration": 4.319,
        "text": "augment the generation of our llm we"
      },
      {
        "start": 1508.88,
        "duration": 3.72,
        "text": "need to be retrieve some data that we're"
      },
      {
        "start": 1510.799,
        "duration": 2.88,
        "text": "going to inject into its context right"
      },
      {
        "start": 1512.6,
        "duration": 3.799,
        "text": "and we're going to step through that"
      },
      {
        "start": 1513.679,
        "duration": 4.161,
        "text": "here in a moment um so this is the"
      },
      {
        "start": 1516.399,
        "duration": 3.88,
        "text": "portion that you're seeing right I can"
      },
      {
        "start": 1517.84,
        "duration": 5.16,
        "text": "go I'm G to do some retrieval from my"
      },
      {
        "start": 1520.279,
        "duration": 4.52,
        "text": "Vector store pull that data out I'm"
      },
      {
        "start": 1523.0,
        "duration": 4.12,
        "text": "going to inject that into my context"
      },
      {
        "start": 1524.799,
        "duration": 3.921,
        "text": "let's change that to uh hopefully I"
      },
      {
        "start": 1527.12,
        "duration": 3.84,
        "text": "didn't just blow everybody's eyes out of"
      },
      {
        "start": 1528.72,
        "duration": 4.64,
        "text": "their uh heads there by changing to the"
      },
      {
        "start": 1530.96,
        "duration": 3.839,
        "text": "uh um to the dark the light mode but"
      },
      {
        "start": 1533.36,
        "duration": 4.6,
        "text": "hopefully that renders a little better"
      },
      {
        "start": 1534.799,
        "duration": 5.281,
        "text": "so here this context right um hopefully"
      },
      {
        "start": 1537.96,
        "duration": 4.56,
        "text": "you can see that pretty well um this"
      },
      {
        "start": 1540.08,
        "duration": 5.319,
        "text": "context here in langlow this is the part"
      },
      {
        "start": 1542.52,
        "duration": 4.48,
        "text": "that when I am asking an llm a question"
      },
      {
        "start": 1545.399,
        "duration": 3.681,
        "text": "um like if you were in a chat upt right"
      },
      {
        "start": 1547.0,
        "duration": 3.72,
        "text": "now and you actually said given the"
      },
      {
        "start": 1549.08,
        "duration": 3.36,
        "text": "above context and you gave it some"
      },
      {
        "start": 1550.72,
        "duration": 3.24,
        "text": "context you could actually start to"
      },
      {
        "start": 1552.44,
        "duration": 3.88,
        "text": "augment the analogy of the llm we're"
      },
      {
        "start": 1553.96,
        "duration": 4.079,
        "text": "just doing that with a database here"
      },
      {
        "start": 1556.32,
        "duration": 3.44,
        "text": "programmatically all right so let's back"
      },
      {
        "start": 1558.039,
        "duration": 3.24,
        "text": "out just a little bit and let's look at"
      },
      {
        "start": 1559.76,
        "duration": 3.72,
        "text": "some of the components here right"
      },
      {
        "start": 1561.279,
        "duration": 3.76,
        "text": "because I jumped right into this flow um"
      },
      {
        "start": 1563.48,
        "duration": 3.24,
        "text": "so you'll notice on the left hand side"
      },
      {
        "start": 1565.039,
        "duration": 3.921,
        "text": "you'll see all these components so"
      },
      {
        "start": 1566.72,
        "duration": 4.839,
        "text": "langlow has all sorts of components that"
      },
      {
        "start": 1568.96,
        "duration": 4.56,
        "text": "you can use um to build flows like this"
      },
      {
        "start": 1571.559,
        "duration": 3.561,
        "text": "right um You have some kind of input"
      },
      {
        "start": 1573.52,
        "duration": 3.519,
        "text": "mechanism so you can interact with it"
      },
      {
        "start": 1575.12,
        "duration": 4.08,
        "text": "and talk with it ask a query again"
      },
      {
        "start": 1577.039,
        "duration": 4.441,
        "text": "similar if you were an anthropic or chat"
      },
      {
        "start": 1579.2,
        "duration": 4.92,
        "text": "CHT and you're typing something into it"
      },
      {
        "start": 1581.48,
        "duration": 4.079,
        "text": "um you have a prompt right where you can"
      },
      {
        "start": 1584.12,
        "duration": 3.4,
        "text": "give it instructions it's essentially"
      },
      {
        "start": 1585.559,
        "duration": 4.0,
        "text": "what a prompt is doing all right so I'm"
      },
      {
        "start": 1587.52,
        "duration": 4.8,
        "text": "going to give um some instruction to the"
      },
      {
        "start": 1589.559,
        "duration": 5.12,
        "text": "llm on what I wanted to do now something"
      },
      {
        "start": 1592.32,
        "duration": 4.079,
        "text": "I want to point out here is notice these"
      },
      {
        "start": 1594.679,
        "duration": 3.281,
        "text": "curly braces notice how I have this"
      },
      {
        "start": 1596.399,
        "duration": 3.921,
        "text": "variable in these curly braces so I have"
      },
      {
        "start": 1597.96,
        "duration": 4.76,
        "text": "curly brace context curly brace and down"
      },
      {
        "start": 1600.32,
        "duration": 4.44,
        "text": "here curly brace question curly brace"
      },
      {
        "start": 1602.72,
        "duration": 4.36,
        "text": "well a really neat feature of langlow is"
      },
      {
        "start": 1604.76,
        "duration": 5.56,
        "text": "if I encapsulate any variable names like"
      },
      {
        "start": 1607.08,
        "duration": 8.599,
        "text": "that in cly Braes I say check and save"
      },
      {
        "start": 1610.32,
        "duration": 7.719,
        "text": "it will then expose those as inputs"
      },
      {
        "start": 1615.679,
        "duration": 4.041,
        "text": "right so what this makes it you know"
      },
      {
        "start": 1618.039,
        "duration": 3.841,
        "text": "what what this really does for me as a"
      },
      {
        "start": 1619.72,
        "duration": 5.16,
        "text": "developer is it makes it super easy for"
      },
      {
        "start": 1621.88,
        "duration": 4.88,
        "text": "me to just wire up my flow without"
      },
      {
        "start": 1624.88,
        "duration": 3.44,
        "text": "having to do this programmatically right"
      },
      {
        "start": 1626.76,
        "duration": 2.799,
        "text": "now for those of you who are core"
      },
      {
        "start": 1628.32,
        "duration": 3.599,
        "text": "developers and things like that you're"
      },
      {
        "start": 1629.559,
        "duration": 4.641,
        "text": "like but okay this is great I can this"
      },
      {
        "start": 1631.919,
        "duration": 4.521,
        "text": "is so cool I can wire all this stuff up"
      },
      {
        "start": 1634.2,
        "duration": 3.839,
        "text": "visually but can I get it the code"
      },
      {
        "start": 1636.44,
        "duration": 2.88,
        "text": "absolutely right so underneath the hood"
      },
      {
        "start": 1638.039,
        "duration": 4.561,
        "text": "of any of these if I click on one of"
      },
      {
        "start": 1639.32,
        "duration": 4.959,
        "text": "these components and I go into the"
      },
      {
        "start": 1642.6,
        "duration": 3.799,
        "text": "little code block part there it's all"
      },
      {
        "start": 1644.279,
        "duration": 4.041,
        "text": "python right this is all python under"
      },
      {
        "start": 1646.399,
        "duration": 3.561,
        "text": "the hood you can modify this stuff you"
      },
      {
        "start": 1648.32,
        "duration": 3.239,
        "text": "can make custom components all sorts of"
      },
      {
        "start": 1649.96,
        "duration": 2.959,
        "text": "things I'm not going to delve too far"
      },
      {
        "start": 1651.559,
        "duration": 3.281,
        "text": "into that because I want to get back to"
      },
      {
        "start": 1652.919,
        "duration": 3.24,
        "text": "the rag thing but I I'm kind of using"
      },
      {
        "start": 1654.84,
        "duration": 2.88,
        "text": "this as a way to just kind of showcase"
      },
      {
        "start": 1656.159,
        "duration": 3.76,
        "text": "some of the cool things you can do here"
      },
      {
        "start": 1657.72,
        "duration": 4.72,
        "text": "visually and this allows you to focus on"
      },
      {
        "start": 1659.919,
        "duration": 3.921,
        "text": "your gen stuff in your rag pipeline um"
      },
      {
        "start": 1662.44,
        "duration": 4.68,
        "text": "and then you can wrap your application"
      },
      {
        "start": 1663.84,
        "duration": 5.04,
        "text": "around uh the API all right so let's go"
      },
      {
        "start": 1667.12,
        "duration": 4.24,
        "text": "ahead and take a look at uh first case"
      },
      {
        "start": 1668.88,
        "duration": 4.32,
        "text": "what I've done here is similar to what"
      },
      {
        "start": 1671.36,
        "duration": 4.88,
        "text": "Alex was showing you um I do have a"
      },
      {
        "start": 1673.2,
        "duration": 5.12,
        "text": "collection but it's empty right so yes I"
      },
      {
        "start": 1676.24,
        "duration": 3.24,
        "text": "have my rag pipeline hooked up but if I"
      },
      {
        "start": 1678.32,
        "duration": 5.32,
        "text": "were to come in and by the way in my"
      },
      {
        "start": 1679.48,
        "duration": 5.48,
        "text": "particular case um I happen to uh I'm"
      },
      {
        "start": 1683.64,
        "duration": 4.6,
        "text": "going to feed it some information here"
      },
      {
        "start": 1684.96,
        "duration": 4.52,
        "text": "in a second let's see so you know kind"
      },
      {
        "start": 1688.24,
        "duration": 3.039,
        "text": "of going back to what Carter was talking"
      },
      {
        "start": 1689.48,
        "duration": 5.0,
        "text": "about with rag in general if I just go"
      },
      {
        "start": 1691.279,
        "duration": 5.041,
        "text": "to an llm any llm and I ask at something"
      },
      {
        "start": 1694.48,
        "duration": 3.88,
        "text": "open-ended like this when did I start"
      },
      {
        "start": 1696.32,
        "duration": 3.8,
        "text": "coding right it's not going to know"
      },
      {
        "start": 1698.36,
        "duration": 4.0,
        "text": "anything about who I am or anything like"
      },
      {
        "start": 1700.12,
        "duration": 3.84,
        "text": "that so you can tell by the answer hey"
      },
      {
        "start": 1702.36,
        "duration": 3.6,
        "text": "I'm sorry I don't have any information"
      },
      {
        "start": 1703.96,
        "duration": 3.24,
        "text": "about when you started coding provide me"
      },
      {
        "start": 1705.96,
        "duration": 3.52,
        "text": "you know provide some details or"
      },
      {
        "start": 1707.2,
        "duration": 3.76,
        "text": "something um so this is like the core of"
      },
      {
        "start": 1709.48,
        "duration": 5.64,
        "text": "like rag this is what I want to get at"
      },
      {
        "start": 1710.96,
        "duration": 6.36,
        "text": "so again my rag store is empty right so"
      },
      {
        "start": 1715.12,
        "duration": 5.919,
        "text": "what I'm going to do with"
      },
      {
        "start": 1717.32,
        "duration": 5.92,
        "text": "langlow is I have fed it a PDF this PDF"
      },
      {
        "start": 1721.039,
        "duration": 4.441,
        "text": "just happens to be on my particular"
      },
      {
        "start": 1723.24,
        "duration": 4.2,
        "text": "career all right and so we're going to"
      },
      {
        "start": 1725.48,
        "duration": 3.0,
        "text": "go ahead and I'm just going to run this"
      },
      {
        "start": 1727.44,
        "duration": 2.28,
        "text": "now let's step through what it's"
      },
      {
        "start": 1728.48,
        "duration": 4.36,
        "text": "actually doing right so this is the"
      },
      {
        "start": 1729.72,
        "duration": 5.04,
        "text": "generative portion so one I'm giving it"
      },
      {
        "start": 1732.84,
        "duration": 4.079,
        "text": "some kind of input is it limited to a"
      },
      {
        "start": 1734.76,
        "duration": 4.08,
        "text": "file no you could be a directory it"
      },
      {
        "start": 1736.919,
        "duration": 4.36,
        "text": "could be a URL it could be API could be"
      },
      {
        "start": 1738.84,
        "duration": 5.559,
        "text": "all sorts of things can I control the"
      },
      {
        "start": 1741.279,
        "duration": 5.88,
        "text": "inputs programmatically absolutely right"
      },
      {
        "start": 1744.399,
        "duration": 5.0,
        "text": "um so with the API that's available you"
      },
      {
        "start": 1747.159,
        "duration": 3.681,
        "text": "can modify these types of inputs you're"
      },
      {
        "start": 1749.399,
        "duration": 3.52,
        "text": "not like limited to a single file or"
      },
      {
        "start": 1750.84,
        "duration": 4.439,
        "text": "something but for this case visually"
      },
      {
        "start": 1752.919,
        "duration": 3.76,
        "text": "I've just fed at this PDF now what I"
      },
      {
        "start": 1755.279,
        "duration": 3.441,
        "text": "need to do is I need to iterate through"
      },
      {
        "start": 1756.679,
        "duration": 4.281,
        "text": "that PDF right so I'm going to iterate"
      },
      {
        "start": 1758.72,
        "duration": 5.559,
        "text": "through it I'm going to chunk out the"
      },
      {
        "start": 1760.96,
        "duration": 5.199,
        "text": "data and then I'm gonna essentially go"
      },
      {
        "start": 1764.279,
        "duration": 4.4,
        "text": "say every thousand characters I'm going"
      },
      {
        "start": 1766.159,
        "duration": 3.921,
        "text": "to take every thousand characters"
      },
      {
        "start": 1768.679,
        "duration": 2.921,
        "text": "going to convert those with some"
      },
      {
        "start": 1770.08,
        "duration": 2.959,
        "text": "embedding model in this case I'm using"
      },
      {
        "start": 1771.6,
        "duration": 2.84,
        "text": "open AI embeddings but something I want"
      },
      {
        "start": 1773.039,
        "duration": 3.52,
        "text": "to point out about langlow and Carter"
      },
      {
        "start": 1774.44,
        "duration": 4.079,
        "text": "mentioned this earlier it's model"
      },
      {
        "start": 1776.559,
        "duration": 3.801,
        "text": "agnostic right so if you take a look at"
      },
      {
        "start": 1778.519,
        "duration": 3.64,
        "text": "all the models here on the left there's"
      },
      {
        "start": 1780.36,
        "duration": 3.919,
        "text": "also AMA support if you have your own"
      },
      {
        "start": 1782.159,
        "duration": 3.961,
        "text": "local models right there's all sorts of"
      },
      {
        "start": 1784.279,
        "duration": 3.721,
        "text": "ways that you can kind of you know kind"
      },
      {
        "start": 1786.12,
        "duration": 4.84,
        "text": "of match things up and and use whatever"
      },
      {
        "start": 1788.0,
        "duration": 5.399,
        "text": "models you want to just using open AI in"
      },
      {
        "start": 1790.96,
        "duration": 3.76,
        "text": "here uh for example um same thing on the"
      },
      {
        "start": 1793.399,
        "duration": 2.88,
        "text": "embedding end right you'll see there's"
      },
      {
        "start": 1794.72,
        "duration": 2.88,
        "text": "all sorts of options there and what's"
      },
      {
        "start": 1796.279,
        "duration": 3.441,
        "text": "cool is if I want to bring something"
      },
      {
        "start": 1797.6,
        "duration": 3.559,
        "text": "else in in let's say maybe I wanted to"
      },
      {
        "start": 1799.72,
        "duration": 3.48,
        "text": "use mistol or something I could just"
      },
      {
        "start": 1801.159,
        "duration": 5.64,
        "text": "drag that over and hook that up get my"
      },
      {
        "start": 1803.2,
        "duration": 5.44,
        "text": "key and and go on all right so great so"
      },
      {
        "start": 1806.799,
        "duration": 4.441,
        "text": "we've iterated through the data that's"
      },
      {
        "start": 1808.64,
        "duration": 4.399,
        "text": "in the PDF we're using the openi"
      },
      {
        "start": 1811.24,
        "duration": 3.48,
        "text": "embedding text embedding three small"
      },
      {
        "start": 1813.039,
        "duration": 4.36,
        "text": "model right and then we're going to"
      },
      {
        "start": 1814.72,
        "duration": 6.64,
        "text": "store that data in our Vector database"
      },
      {
        "start": 1817.399,
        "duration": 5.601,
        "text": "um and again um Lang flow is pretty"
      },
      {
        "start": 1821.36,
        "duration": 3.0,
        "text": "agnostic when it comes to Vector stores"
      },
      {
        "start": 1823.0,
        "duration": 3.519,
        "text": "but in this case today we're using we're"
      },
      {
        "start": 1824.36,
        "duration": 5.72,
        "text": "using astb so here's what I want to show"
      },
      {
        "start": 1826.519,
        "duration": 7.801,
        "text": "you remember a moment ago um we had an"
      },
      {
        "start": 1830.08,
        "duration": 5.76,
        "text": "empty collection right so what I did is"
      },
      {
        "start": 1834.32,
        "duration": 2.479,
        "text": "now if Lang float notices by the way"
      },
      {
        "start": 1835.84,
        "duration": 2.6,
        "text": "that you don't have a collection at"
      },
      {
        "start": 1836.799,
        "duration": 3.321,
        "text": "least for Astro DB it will autogenerate"
      },
      {
        "start": 1838.44,
        "duration": 4.359,
        "text": "it but I already had it there remember"
      },
      {
        "start": 1840.12,
        "duration": 4.88,
        "text": "before this was empty but now I have the"
      },
      {
        "start": 1842.799,
        "duration": 4.0,
        "text": "data right so what's super cool about"
      },
      {
        "start": 1845.0,
        "duration": 4.039,
        "text": "this is not only do I have the data that"
      },
      {
        "start": 1846.799,
        "duration": 3.72,
        "text": "I chunked through but then it's also"
      },
      {
        "start": 1849.039,
        "duration": 4.36,
        "text": "generating those Vector embeddings the"
      },
      {
        "start": 1850.519,
        "duration": 5.681,
        "text": "relevant Vector embeddings"
      },
      {
        "start": 1853.399,
        "duration": 4.64,
        "text": "for for the data that we chunked by the"
      },
      {
        "start": 1856.2,
        "duration": 3.199,
        "text": "way just let me know or how's the"
      },
      {
        "start": 1858.039,
        "duration": 3.841,
        "text": "visibility on this you guys all able to"
      },
      {
        "start": 1859.399,
        "duration": 2.481,
        "text": "see this"
      },
      {
        "start": 1862.639,
        "duration": 4.28,
        "text": "okay it's okay I mean you you can people"
      },
      {
        "start": 1865.6,
        "duration": 4.559,
        "text": "always love it when you make it slightly"
      },
      {
        "start": 1866.919,
        "duration": 5.24,
        "text": "bigger um but I think I think people are"
      },
      {
        "start": 1870.159,
        "duration": 4.0,
        "text": "getting the gist of things for the most"
      },
      {
        "start": 1872.159,
        "duration": 4.281,
        "text": "part and you know for folks for folks"
      },
      {
        "start": 1874.159,
        "duration": 4.48,
        "text": "who uh you know when especially when"
      },
      {
        "start": 1876.44,
        "duration": 3.959,
        "text": "Alex was going through his uh his code"
      },
      {
        "start": 1878.639,
        "duration": 2.92,
        "text": "notebook example like I'll just remind"
      },
      {
        "start": 1880.399,
        "duration": 2.76,
        "text": "everybody like don't worry we're going"
      },
      {
        "start": 1881.559,
        "duration": 3.161,
        "text": "to share the links to the code notebooks"
      },
      {
        "start": 1883.159,
        "duration": 3.841,
        "text": "so right don't worry about trying to"
      },
      {
        "start": 1884.72,
        "duration": 4.24,
        "text": "like you know copy copy the code like"
      },
      {
        "start": 1887.0,
        "duration": 3.919,
        "text": "from from a from from a blurry video"
      },
      {
        "start": 1888.96,
        "duration": 3.52,
        "text": "like you will have the actual um code"
      },
      {
        "start": 1890.919,
        "duration": 2.561,
        "text": "itself shared out after the after the"
      },
      {
        "start": 1892.48,
        "duration": 5.439,
        "text": "live"
      },
      {
        "start": 1893.48,
        "duration": 6.24,
        "text": "stream awesome awesome okay so I ran"
      },
      {
        "start": 1897.919,
        "duration": 3.24,
        "text": "again I'm doing this all within L flow"
      },
      {
        "start": 1899.72,
        "duration": 3.679,
        "text": "notice that I'm not actually having to"
      },
      {
        "start": 1901.159,
        "duration": 3.88,
        "text": "touch any code to do this this is like"
      },
      {
        "start": 1903.399,
        "duration": 3.481,
        "text": "the main benefit right of of using"
      },
      {
        "start": 1905.039,
        "duration": 5.0,
        "text": "something like low I it allows me to"
      },
      {
        "start": 1906.88,
        "duration": 4.519,
        "text": "visually build and execute on my gen"
      },
      {
        "start": 1910.039,
        "duration": 4.401,
        "text": "workflows and in this case it's a rag"
      },
      {
        "start": 1911.399,
        "duration": 5.481,
        "text": "pipeline so great so now I've got some"
      },
      {
        "start": 1914.44,
        "duration": 5.44,
        "text": "data you can see that the data that we"
      },
      {
        "start": 1916.88,
        "duration": 5.639,
        "text": "chunked through right each one of these"
      },
      {
        "start": 1919.88,
        "duration": 4.2,
        "text": "chunks of text has been converted into a"
      },
      {
        "start": 1922.519,
        "duration": 3.361,
        "text": "vector embedding using the text"
      },
      {
        "start": 1924.08,
        "duration": 3.76,
        "text": "embedding three small that's what we're"
      },
      {
        "start": 1925.88,
        "duration": 4.039,
        "text": "seeing here in the database this is the"
      },
      {
        "start": 1927.84,
        "duration": 4.439,
        "text": "vector coming out of each one of those"
      },
      {
        "start": 1929.919,
        "duration": 3.64,
        "text": "chunks and now I have the query portion"
      },
      {
        "start": 1932.279,
        "duration": 3.801,
        "text": "so if I pull back a little bit we're"
      },
      {
        "start": 1933.559,
        "duration": 3.801,
        "text": "going to zoom into the top here there's"
      },
      {
        "start": 1936.08,
        "duration": 3.88,
        "text": "a couple things going on here that are"
      },
      {
        "start": 1937.36,
        "duration": 4.36,
        "text": "kind of important one the question"
      },
      {
        "start": 1939.96,
        "duration": 3.559,
        "text": "whatever the query is in this case I'm"
      },
      {
        "start": 1941.72,
        "duration": 2.64,
        "text": "asking when did I start coding I'm"
      },
      {
        "start": 1943.519,
        "duration": 2.52,
        "text": "actually going to go ahead and run"
      },
      {
        "start": 1944.36,
        "duration": 4.24,
        "text": "through run this while I'm talking here"
      },
      {
        "start": 1946.039,
        "duration": 5.24,
        "text": "do that so I asked this question when"
      },
      {
        "start": 1948.6,
        "duration": 5.12,
        "text": "did I start coding but I can't"
      },
      {
        "start": 1951.279,
        "duration": 6.041,
        "text": "just I can't just say when did I start"
      },
      {
        "start": 1953.72,
        "duration": 5.079,
        "text": "coding and somehow search that against"
      },
      {
        "start": 1957.32,
        "duration": 2.959,
        "text": "Vector embeddings that are these huge"
      },
      {
        "start": 1958.799,
        "duration": 4.441,
        "text": "end dimensional arrays right that won't"
      },
      {
        "start": 1960.279,
        "duration": 5.52,
        "text": "make any sense so what I need to do is"
      },
      {
        "start": 1963.24,
        "duration": 4.559,
        "text": "this query also needs to be converted"
      },
      {
        "start": 1965.799,
        "duration": 4.76,
        "text": "into the same embedding space if you"
      },
      {
        "start": 1967.799,
        "duration": 4.201,
        "text": "will so you'll see again that my search"
      },
      {
        "start": 1970.559,
        "duration": 3.6,
        "text": "input I'm wiring this up to my search"
      },
      {
        "start": 1972.0,
        "duration": 4.76,
        "text": "input of my database my Vector store in"
      },
      {
        "start": 1974.159,
        "duration": 5.601,
        "text": "this case asro DB but then we also have"
      },
      {
        "start": 1976.76,
        "duration": 5.12,
        "text": "the same tie-in the same embedding model"
      },
      {
        "start": 1979.76,
        "duration": 3.759,
        "text": "and that's super key right notice that"
      },
      {
        "start": 1981.88,
        "duration": 3.799,
        "text": "I'm also using text embedding three"
      },
      {
        "start": 1983.519,
        "duration": 4.88,
        "text": "small from open AI the same thing we"
      },
      {
        "start": 1985.679,
        "duration": 4.441,
        "text": "used down here when I generated the data"
      },
      {
        "start": 1988.399,
        "duration": 3.681,
        "text": "and why is it important because the"
      },
      {
        "start": 1990.12,
        "duration": 3.919,
        "text": "different embedding models are going to"
      },
      {
        "start": 1992.08,
        "duration": 3.24,
        "text": "have they have different parameters and"
      },
      {
        "start": 1994.039,
        "duration": 5.041,
        "text": "properties and stuff they're using to"
      },
      {
        "start": 1995.32,
        "duration": 5.359,
        "text": "encode the semantic data from whatever"
      },
      {
        "start": 1999.08,
        "duration": 4.28,
        "text": "in this case the you know my my text"
      },
      {
        "start": 2000.679,
        "duration": 5.12,
        "text": "blobs into that into those vectors that"
      },
      {
        "start": 2003.36,
        "duration": 3.72,
        "text": "you see so if I mix and match models"
      },
      {
        "start": 2005.799,
        "duration": 3.0,
        "text": "especially from different providers"
      },
      {
        "start": 2007.08,
        "duration": 2.64,
        "text": "you're probably not going to get matches"
      },
      {
        "start": 2008.799,
        "duration": 3.88,
        "text": "right so you need to make sure you're"
      },
      {
        "start": 2009.72,
        "duration": 4.72,
        "text": "using the same one um so again so this"
      },
      {
        "start": 2012.679,
        "duration": 3.84,
        "text": "now this chat input is how I'm going to"
      },
      {
        "start": 2014.44,
        "duration": 4.079,
        "text": "talk to it it's going to take this"
      },
      {
        "start": 2016.519,
        "duration": 3.681,
        "text": "particular query it's going to convert"
      },
      {
        "start": 2018.519,
        "duration": 5.441,
        "text": "it into the same embedding space is the"
      },
      {
        "start": 2020.2,
        "duration": 6.16,
        "text": "data that we converted our rag data into"
      },
      {
        "start": 2023.96,
        "duration": 3.959,
        "text": "it's then going to perform a search"
      },
      {
        "start": 2026.36,
        "duration": 3.439,
        "text": "right so here's what's super cool"
      },
      {
        "start": 2027.919,
        "duration": 3.961,
        "text": "remember a moment ago if I look back at"
      },
      {
        "start": 2029.799,
        "duration": 4.36,
        "text": "my database it's not a a ton of data in"
      },
      {
        "start": 2031.88,
        "duration": 5.12,
        "text": "this example but we do have three"
      },
      {
        "start": 2034.159,
        "duration": 5.721,
        "text": "essentially three chunks of data now I"
      },
      {
        "start": 2037.0,
        "duration": 4.2,
        "text": "just did a query when did I start coding"
      },
      {
        "start": 2039.88,
        "duration": 4.08,
        "text": "and I did it against the database but"
      },
      {
        "start": 2041.2,
        "duration": 4.319,
        "text": "notice it returned one of them right so"
      },
      {
        "start": 2043.96,
        "duration": 3.719,
        "text": "this is actually super cool and for my"
      },
      {
        "start": 2045.519,
        "duration": 5.001,
        "text": "particular question when did I start"
      },
      {
        "start": 2047.679,
        "duration": 4.801,
        "text": "coding there are some key things that it"
      },
      {
        "start": 2050.52,
        "duration": 4.599,
        "text": "it was able to pull out things like I"
      },
      {
        "start": 2052.48,
        "duration": 5.56,
        "text": "was around eight years old um started on"
      },
      {
        "start": 2055.119,
        "duration": 4.921,
        "text": "a commoner 64 so the vector search was"
      },
      {
        "start": 2058.04,
        "duration": 4.68,
        "text": "able using this this essentially this"
      },
      {
        "start": 2060.04,
        "duration": 4.319,
        "text": "semantic comparison right it was able to"
      },
      {
        "start": 2062.72,
        "duration": 4.639,
        "text": "pull out the relevant results somebody"
      },
      {
        "start": 2064.359,
        "duration": 4.161,
        "text": "asked the question earlier like you know"
      },
      {
        "start": 2067.359,
        "duration": 2.641,
        "text": "what what are some of the benefits of"
      },
      {
        "start": 2068.52,
        "duration": 3.72,
        "text": "rag and things like that like well one"
      },
      {
        "start": 2070.0,
        "duration": 4.04,
        "text": "of the things imagine that you have"
      },
      {
        "start": 2072.24,
        "duration": 3.76,
        "text": "thousands of documents or millions of"
      },
      {
        "start": 2074.04,
        "duration": 4.52,
        "text": "documents or something like that it is a"
      },
      {
        "start": 2076.0,
        "duration": 4.359,
        "text": "lot more cost-effective and efficient to"
      },
      {
        "start": 2078.56,
        "duration": 3.88,
        "text": "go ahead and use something like a vector"
      },
      {
        "start": 2080.359,
        "duration": 3.641,
        "text": "store to pull out the relevant results"
      },
      {
        "start": 2082.44,
        "duration": 2.76,
        "text": "and then just put those relevant results"
      },
      {
        "start": 2084.0,
        "duration": 2.839,
        "text": "into your context and that's what we're"
      },
      {
        "start": 2085.2,
        "duration": 4.159,
        "text": "going to do here in a moment so great we"
      },
      {
        "start": 2086.839,
        "duration": 4.04,
        "text": "get a result now I just you know in this"
      },
      {
        "start": 2089.359,
        "duration": 3.0,
        "text": "case if you notice I have a file path"
      },
      {
        "start": 2090.879,
        "duration": 3.2,
        "text": "and a text all I really want is this"
      },
      {
        "start": 2092.359,
        "duration": 4.0,
        "text": "text that's what I want to put into my"
      },
      {
        "start": 2094.079,
        "duration": 4.481,
        "text": "llm so I'm going to use this pars data"
      },
      {
        "start": 2096.359,
        "duration": 3.681,
        "text": "component to pull out the text"
      },
      {
        "start": 2098.56,
        "duration": 4.559,
        "text": "that you see"
      },
      {
        "start": 2100.04,
        "duration": 5.36,
        "text": "here then here's the real fun one right"
      },
      {
        "start": 2103.119,
        "duration": 5.161,
        "text": "I'm going to take that result from my"
      },
      {
        "start": 2105.4,
        "duration": 4.56,
        "text": "Vector store I'm going to again wiring"
      },
      {
        "start": 2108.28,
        "duration": 2.92,
        "text": "it right up remember those curly braces"
      },
      {
        "start": 2109.96,
        "duration": 4.24,
        "text": "that I was talking about earlier we just"
      },
      {
        "start": 2111.2,
        "duration": 5.04,
        "text": "wire up the output into the context and"
      },
      {
        "start": 2114.2,
        "duration": 5.68,
        "text": "now check out what happened so this is"
      },
      {
        "start": 2116.24,
        "duration": 5.0,
        "text": "the same prompt we had earlier but now"
      },
      {
        "start": 2119.88,
        "duration": 4.56,
        "text": "it's got the context that's been"
      },
      {
        "start": 2121.24,
        "duration": 6.599,
        "text": "programmatically added to the prompt"
      },
      {
        "start": 2124.44,
        "duration": 4.6,
        "text": "right along with our question so yeah"
      },
      {
        "start": 2127.839,
        "duration": 3.201,
        "text": "this being done visually but again"
      },
      {
        "start": 2129.04,
        "duration": 3.24,
        "text": "underneath the hood it's it's all python"
      },
      {
        "start": 2131.04,
        "duration": 3.76,
        "text": "you have access to this from your"
      },
      {
        "start": 2132.28,
        "duration": 6.24,
        "text": "application right um so it is allowing"
      },
      {
        "start": 2134.8,
        "duration": 6.92,
        "text": "us to build this as we go along so then"
      },
      {
        "start": 2138.52,
        "duration": 5.44,
        "text": "when we give the prompt to the llm it"
      },
      {
        "start": 2141.72,
        "duration": 3.96,
        "text": "now has all the information right now if"
      },
      {
        "start": 2143.96,
        "duration": 3.52,
        "text": "I come back to the playground you can"
      },
      {
        "start": 2145.68,
        "duration": 3.639,
        "text": "see that when I ran that before it asked"
      },
      {
        "start": 2147.48,
        "duration": 4.0,
        "text": "the question again but now instead of"
      },
      {
        "start": 2149.319,
        "duration": 4.201,
        "text": "saying hey I don't know who you are or I"
      },
      {
        "start": 2151.48,
        "duration": 3.68,
        "text": "don't have any information about this it"
      },
      {
        "start": 2153.52,
        "duration": 3.64,
        "text": "now says hey you started coding games on"
      },
      {
        "start": 2155.16,
        "duration": 3.48,
        "text": "your Comer 64 when you're around eight"
      },
      {
        "start": 2157.16,
        "duration": 4.04,
        "text": "which is correct correct right it was"
      },
      {
        "start": 2158.64,
        "duration": 5.04,
        "text": "able to pull that information out of the"
      },
      {
        "start": 2161.2,
        "duration": 5.2,
        "text": "data that I sent into"
      },
      {
        "start": 2163.68,
        "duration": 4.32,
        "text": "it okay so I keep talking by the way"
      },
      {
        "start": 2166.4,
        "duration": 3.199,
        "text": "about um you know wrapping your"
      },
      {
        "start": 2168.0,
        "duration": 4.079,
        "text": "application around this and and such"
      },
      {
        "start": 2169.599,
        "duration": 4.641,
        "text": "like that um so yes this is Implement in"
      },
      {
        "start": 2172.079,
        "duration": 4.04,
        "text": "Python again there's code under the hood"
      },
      {
        "start": 2174.24,
        "duration": 3.28,
        "text": "um but you're not limited to python at"
      },
      {
        "start": 2176.119,
        "duration": 3.72,
        "text": "all and I think this another really"
      },
      {
        "start": 2177.52,
        "duration": 4.4,
        "text": "powerful thing about linkflow um so"
      },
      {
        "start": 2179.839,
        "duration": 4.28,
        "text": "whether you're using a JavaScript or if"
      },
      {
        "start": 2181.92,
        "duration": 3.88,
        "text": "you're using Java or you know PHP or"
      },
      {
        "start": 2184.119,
        "duration": 4.521,
        "text": "whatever um you have all sorts of"
      },
      {
        "start": 2185.8,
        "duration": 5.039,
        "text": "options here um one you could treat this"
      },
      {
        "start": 2188.64,
        "duration": 4.32,
        "text": "um as a pure API server right you can"
      },
      {
        "start": 2190.839,
        "duration": 4.641,
        "text": "just call your API endpoint wherever you"
      },
      {
        "start": 2192.96,
        "duration": 4.08,
        "text": "have L flow deployed um you can modify"
      },
      {
        "start": 2195.48,
        "duration": 3.639,
        "text": "the inputs and outputs and that kind of"
      },
      {
        "start": 2197.04,
        "duration": 3.52,
        "text": "deal so you can you can say you know"
      },
      {
        "start": 2199.119,
        "duration": 3.2,
        "text": "obviously programmatically give it"
      },
      {
        "start": 2200.56,
        "duration": 4.44,
        "text": "different questions or you can do a lot"
      },
      {
        "start": 2202.319,
        "duration": 4.921,
        "text": "more complex examples than this um there"
      },
      {
        "start": 2205.0,
        "duration": 4.64,
        "text": "is a full like if you really want to you"
      },
      {
        "start": 2207.24,
        "duration": 5.44,
        "text": "know I actually find that when I use"
      },
      {
        "start": 2209.64,
        "duration": 6.08,
        "text": "langlow for development um I really like"
      },
      {
        "start": 2212.68,
        "duration": 5.2,
        "text": "using this kind of flow visually in my"
      },
      {
        "start": 2215.72,
        "duration": 4.0,
        "text": "testing while I'm iterating because I"
      },
      {
        "start": 2217.88,
        "duration": 4.28,
        "text": "can come over here if I wanted to I"
      },
      {
        "start": 2219.72,
        "duration": 5.28,
        "text": "could say you know something maybe I"
      },
      {
        "start": 2222.16,
        "duration": 4.159,
        "text": "want to experiment with anthropic or"
      },
      {
        "start": 2225.0,
        "duration": 2.48,
        "text": "something like that right I can come in"
      },
      {
        "start": 2226.319,
        "duration": 2.52,
        "text": "here and I can say all right well I'm"
      },
      {
        "start": 2227.48,
        "duration": 4.119,
        "text": "gonna experiment with anthropic I'm"
      },
      {
        "start": 2228.839,
        "duration": 4.161,
        "text": "gonna go ahead and I'm G to wire that up"
      },
      {
        "start": 2231.599,
        "duration": 3.52,
        "text": "I'm gonna put a new chat output and I"
      },
      {
        "start": 2233.0,
        "duration": 4.24,
        "text": "can just do that on the fly right so it"
      },
      {
        "start": 2235.119,
        "duration": 5.361,
        "text": "allows me a lot of flexibility when I'm"
      },
      {
        "start": 2237.24,
        "duration": 4.92,
        "text": "iterating and going through my code um"
      },
      {
        "start": 2240.48,
        "duration": 4.08,
        "text": "and then you know both Python and"
      },
      {
        "start": 2242.16,
        "duration": 4.36,
        "text": "JavaScript have you know kind of more uh"
      },
      {
        "start": 2244.56,
        "duration": 3.64,
        "text": "capable API code that you can put in but"
      },
      {
        "start": 2246.52,
        "duration": 4.28,
        "text": "there's a really interesting"
      },
      {
        "start": 2248.2,
        "duration": 4.919,
        "text": "um capability with python um which is"
      },
      {
        "start": 2250.8,
        "duration": 6.319,
        "text": "this right here this from llow load"
      },
      {
        "start": 2253.119,
        "duration": 7.24,
        "text": "import um that allows you to just import"
      },
      {
        "start": 2257.119,
        "duration": 6.841,
        "text": "a Json blob so any one of these flows"
      },
      {
        "start": 2260.359,
        "duration": 6.921,
        "text": "you can export as a Json blob and why is"
      },
      {
        "start": 2263.96,
        "duration": 6.44,
        "text": "that important because now if I want to"
      },
      {
        "start": 2267.28,
        "duration": 6.16,
        "text": "I can detach the whole of this logic and"
      },
      {
        "start": 2270.4,
        "duration": 4.48,
        "text": "embed it directly into my python app and"
      },
      {
        "start": 2273.44,
        "duration": 3.679,
        "text": "I don't need to run this as an API"
      },
      {
        "start": 2274.88,
        "duration": 3.6,
        "text": "server right so it's like a super cool"
      },
      {
        "start": 2277.119,
        "duration": 2.801,
        "text": "piece of functionality I've had a lot of"
      },
      {
        "start": 2278.48,
        "duration": 2.68,
        "text": "people in the past be like hey can I"
      },
      {
        "start": 2279.92,
        "duration": 3.679,
        "text": "just get all the code like can you give"
      },
      {
        "start": 2281.16,
        "duration": 3.84,
        "text": "me the code or something like that um"
      },
      {
        "start": 2283.599,
        "duration": 2.72,
        "text": "and while yes you can go to the"
      },
      {
        "start": 2285.0,
        "duration": 2.48,
        "text": "individual component you can pull out"
      },
      {
        "start": 2286.319,
        "duration": 2.8,
        "text": "the code and everything like that the"
      },
      {
        "start": 2287.48,
        "duration": 4.599,
        "text": "fact that I can just download the whole"
      },
      {
        "start": 2289.119,
        "duration": 5.081,
        "text": "blob and then import that right into my"
      },
      {
        "start": 2292.079,
        "duration": 4.081,
        "text": "app means that I don't really need to"
      },
      {
        "start": 2294.2,
        "duration": 3.48,
        "text": "worry about the individual code if I"
      },
      {
        "start": 2296.16,
        "duration": 3.52,
        "text": "don't want to right I can just get all"
      },
      {
        "start": 2297.68,
        "duration": 4.96,
        "text": "the logic and everything put in my app"
      },
      {
        "start": 2299.68,
        "duration": 5.2,
        "text": "and then focus on what my application is"
      },
      {
        "start": 2302.64,
        "duration": 4.439,
        "text": "doing all right so with that let's see"
      },
      {
        "start": 2304.88,
        "duration": 4.08,
        "text": "how are we doing on questions there"
      },
      {
        "start": 2307.079,
        "duration": 3.28,
        "text": "we've got a ton of questions I think uh"
      },
      {
        "start": 2308.96,
        "duration": 3.119,
        "text": "yeah if you're if you're ready like I"
      },
      {
        "start": 2310.359,
        "duration": 5.361,
        "text": "think we should uh transition over to"
      },
      {
        "start": 2312.079,
        "duration": 7.081,
        "text": "Q&A because we got a a ton of great"
      },
      {
        "start": 2315.72,
        "duration": 6.599,
        "text": "questions okay awesome um so thanks for"
      },
      {
        "start": 2319.16,
        "duration": 5.199,
        "text": "thanks for providing that run through um"
      },
      {
        "start": 2322.319,
        "duration": 5.28,
        "text": "feel free to stop sharing your screen"
      },
      {
        "start": 2324.359,
        "duration": 5.72,
        "text": "and we kind of get everyone uh all right"
      },
      {
        "start": 2327.599,
        "duration": 4.881,
        "text": "let's get everyone back back on"
      },
      {
        "start": 2330.079,
        "duration": 3.52,
        "text": "stage let's see and by the way I already"
      },
      {
        "start": 2332.48,
        "duration": 3.839,
        "text": "see a really good question there at the"
      },
      {
        "start": 2333.599,
        "duration": 4.561,
        "text": "bottom but I'll let you do your thing no"
      },
      {
        "start": 2336.319,
        "duration": 3.721,
        "text": "it's all good like we've got a we got a"
      },
      {
        "start": 2338.16,
        "duration": 4.48,
        "text": "ton of great questions awesome so David"
      },
      {
        "start": 2340.04,
        "duration": 5.12,
        "text": "thank you so much for a whirlwind tour"
      },
      {
        "start": 2342.64,
        "duration": 4.92,
        "text": "of like a really a really powerful tool"
      },
      {
        "start": 2345.16,
        "duration": 4.64,
        "text": "for developers right um there's a ton of"
      },
      {
        "start": 2347.56,
        "duration": 5.36,
        "text": "questions already uh about about Lang"
      },
      {
        "start": 2349.8,
        "duration": 6.0,
        "text": "flow um that we can that we can start to"
      },
      {
        "start": 2352.92,
        "duration": 4.08,
        "text": "start to get into um but I'm gonna we're"
      },
      {
        "start": 2355.8,
        "duration": 3.24,
        "text": "going to use the remainder of our time"
      },
      {
        "start": 2357.0,
        "duration": 4.44,
        "text": "to to get through your questions so uh"
      },
      {
        "start": 2359.04,
        "duration": 3.96,
        "text": "keep feel free to keep adding questions"
      },
      {
        "start": 2361.44,
        "duration": 3.8,
        "text": "to the Q&A widget and we're going to"
      },
      {
        "start": 2363.0,
        "duration": 4.92,
        "text": "start start going through these um the"
      },
      {
        "start": 2365.24,
        "duration": 4.24,
        "text": "first one that I want to tackle um is is"
      },
      {
        "start": 2367.92,
        "duration": 3.72,
        "text": "uh a really important one right like why"
      },
      {
        "start": 2369.48,
        "duration": 4.32,
        "text": "Rag and not fine tuning it comes up all"
      },
      {
        "start": 2371.64,
        "duration": 3.719,
        "text": "the time you know it's like whether you"
      },
      {
        "start": 2373.8,
        "duration": 3.279,
        "text": "know what fine-tuning is or whether or"
      },
      {
        "start": 2375.359,
        "duration": 4.561,
        "text": "whether it's just like this word that"
      },
      {
        "start": 2377.079,
        "duration": 4.801,
        "text": "you've heard you know um like buzz word"
      },
      {
        "start": 2379.92,
        "duration": 5.08,
        "text": "that You' sort of read on the internet"
      },
      {
        "start": 2381.88,
        "duration": 5.8,
        "text": "um uh I basically"
      },
      {
        "start": 2385.0,
        "duration": 5.359,
        "text": "fine-tuning uh is the kind of thing that"
      },
      {
        "start": 2387.68,
        "duration": 5.36,
        "text": "you do if you actually have like machine"
      },
      {
        "start": 2390.359,
        "duration": 3.881,
        "text": "learning engineering expertise right"
      },
      {
        "start": 2393.04,
        "duration": 2.84,
        "text": "like if you're a machine learning"
      },
      {
        "start": 2394.24,
        "duration": 3.839,
        "text": "engineer or you work on a machine"
      },
      {
        "start": 2395.88,
        "duration": 4.32,
        "text": "learning engineering team"
      },
      {
        "start": 2398.079,
        "duration": 3.841,
        "text": "yeah like you you you might have the"
      },
      {
        "start": 2400.2,
        "duration": 4.52,
        "text": "skill set and the desire and the"
      },
      {
        "start": 2401.92,
        "duration": 5.24,
        "text": "inclination to take to either build your"
      },
      {
        "start": 2404.72,
        "duration": 4.76,
        "text": "own llm um or to take an llm and to"
      },
      {
        "start": 2407.16,
        "duration": 3.52,
        "text": "fine-tune it for for folks folks folks"
      },
      {
        "start": 2409.48,
        "duration": 3.359,
        "text": "who don't know what I'm talking about"
      },
      {
        "start": 2410.68,
        "duration": 5.04,
        "text": "the simplest explanation is like"
      },
      {
        "start": 2412.839,
        "duration": 6.441,
        "text": "fine-tuning is taking an llm and then"
      },
      {
        "start": 2415.72,
        "duration": 5.639,
        "text": "sort of tuning it to to provide to to"
      },
      {
        "start": 2419.28,
        "duration": 3.96,
        "text": "provide like optimizations around the"
      },
      {
        "start": 2421.359,
        "duration": 3.96,
        "text": "kinds of questions that you want to be"
      },
      {
        "start": 2423.24,
        "duration": 4.44,
        "text": "able to answer for the app that you are"
      },
      {
        "start": 2425.319,
        "duration": 6.201,
        "text": "building um the simplest thing that I"
      },
      {
        "start": 2427.68,
        "duration": 6.0,
        "text": "can say is that um rag is a fantastic"
      },
      {
        "start": 2431.52,
        "duration": 5.16,
        "text": "technique and tool for developers that"
      },
      {
        "start": 2433.68,
        "duration": 5.28,
        "text": "don't have machine learning expertise um"
      },
      {
        "start": 2436.68,
        "duration": 4.6,
        "text": "or don't want to take the time because"
      },
      {
        "start": 2438.96,
        "duration": 4.92,
        "text": "fine tuning is a very incredibly like"
      },
      {
        "start": 2441.28,
        "duration": 4.4,
        "text": "labor Capital time intensive process"
      },
      {
        "start": 2443.88,
        "duration": 4.08,
        "text": "like you could spend weeks or months"
      },
      {
        "start": 2445.68,
        "duration": 6.04,
        "text": "fine-tuning a model based on whatever"
      },
      {
        "start": 2447.96,
        "duration": 5.68,
        "text": "your domain information is um rag is"
      },
      {
        "start": 2451.72,
        "duration": 4.76,
        "text": "something that any full stack web"
      },
      {
        "start": 2453.64,
        "duration": 4.84,
        "text": "developer can Implement in like a day or"
      },
      {
        "start": 2456.48,
        "duration": 3.839,
        "text": "a weekend at least like as a as a"
      },
      {
        "start": 2458.48,
        "duration": 3.44,
        "text": "prototype right um there's always a"
      },
      {
        "start": 2460.319,
        "duration": 3.52,
        "text": "little bit more work that is required to"
      },
      {
        "start": 2461.92,
        "duration": 3.52,
        "text": "to ship something to production but"
      },
      {
        "start": 2463.839,
        "duration": 3.681,
        "text": "that's one of the that's probably arly"
      },
      {
        "start": 2465.44,
        "duration": 3.96,
        "text": "one of the main benefits of rag um it"
      },
      {
        "start": 2467.52,
        "duration": 4.68,
        "text": "doesn't require that kind of domain"
      },
      {
        "start": 2469.4,
        "duration": 6.679,
        "text": "expertise um it's very fast to implement"
      },
      {
        "start": 2472.2,
        "duration": 6.48,
        "text": "and it's very low cost to implement um"
      },
      {
        "start": 2476.079,
        "duration": 5.401,
        "text": "Alex Alex or David do you have any other"
      },
      {
        "start": 2478.68,
        "duration": 5.72,
        "text": "uh anything you want to kind of add on"
      },
      {
        "start": 2481.48,
        "duration": 5.32,
        "text": "there no agreed on the cost comment"
      },
      {
        "start": 2484.4,
        "duration": 6.24,
        "text": "right it seemly less expensive to play"
      },
      {
        "start": 2486.8,
        "duration": 6.6,
        "text": "around with r and fine fing um so"
      },
      {
        "start": 2490.64,
        "duration": 4.16,
        "text": "definitely plus one on that point yeah"
      },
      {
        "start": 2493.4,
        "duration": 3.48,
        "text": "yeah I mean there are look there are use"
      },
      {
        "start": 2494.8,
        "duration": 3.72,
        "text": "cases where funion is the correct"
      },
      {
        "start": 2496.88,
        "duration": 3.479,
        "text": "decision but like all engineering"
      },
      {
        "start": 2498.52,
        "duration": 3.2,
        "text": "decisions it's just about trade-offs"
      },
      {
        "start": 2500.359,
        "duration": 3.48,
        "text": "like you know how fast you trying to"
      },
      {
        "start": 2501.72,
        "duration": 3.8,
        "text": "come to Market what uh technical"
      },
      {
        "start": 2503.839,
        "duration": 3.561,
        "text": "expertise do you have at your company"
      },
      {
        "start": 2505.52,
        "duration": 3.52,
        "text": "like what are you trying to achieve like"
      },
      {
        "start": 2507.4,
        "duration": 3.64,
        "text": "how much you willing to spend those"
      },
      {
        "start": 2509.04,
        "duration": 3.2,
        "text": "those kinds of things um David you you"
      },
      {
        "start": 2511.04,
        "duration": 2.4,
        "text": "said that you kind of identified a"
      },
      {
        "start": 2512.24,
        "duration": 4.119,
        "text": "question immediately that you wanted to"
      },
      {
        "start": 2513.44,
        "duration": 6.48,
        "text": "dive into which one was that oh yeah it"
      },
      {
        "start": 2516.359,
        "duration": 5.081,
        "text": "is um Delante Lee best said wow can you"
      },
      {
        "start": 2519.92,
        "duration": 4.76,
        "text": "experiment with multiple gpts at the"
      },
      {
        "start": 2521.44,
        "duration": 5.0,
        "text": "same time yes absolutely um in Lane flow"
      },
      {
        "start": 2524.68,
        "duration": 2.84,
        "text": "as a matter of fact I have a totally"
      },
      {
        "start": 2526.44,
        "duration": 3.24,
        "text": "separate app from what we're talking"
      },
      {
        "start": 2527.52,
        "duration": 4.079,
        "text": "about here that does real-time language"
      },
      {
        "start": 2529.68,
        "duration": 5.52,
        "text": "translation and it has four different"
      },
      {
        "start": 2531.599,
        "duration": 5.121,
        "text": "llms being used um because and that"
      },
      {
        "start": 2535.2,
        "duration": 4.28,
        "text": "wasn't just like a showcase thing that"
      },
      {
        "start": 2536.72,
        "duration": 4.76,
        "text": "was actually for what I was doing in"
      },
      {
        "start": 2539.48,
        "duration": 3.2,
        "text": "that particular app different llms are"
      },
      {
        "start": 2541.48,
        "duration": 2.639,
        "text": "actually really good at different things"
      },
      {
        "start": 2542.68,
        "duration": 2.879,
        "text": "some are great at language translation"
      },
      {
        "start": 2544.119,
        "duration": 4.521,
        "text": "some are great at code some are great at"
      },
      {
        "start": 2545.559,
        "duration": 4.881,
        "text": "depends um so so yes that's actually I"
      },
      {
        "start": 2548.64,
        "duration": 3.84,
        "text": "think one of my favorite features of"
      },
      {
        "start": 2550.44,
        "duration": 3.6,
        "text": "Lang flow is the ability to just very"
      },
      {
        "start": 2552.48,
        "duration": 3.4,
        "text": "quickly you can just drag and drop them"
      },
      {
        "start": 2554.04,
        "duration": 4.48,
        "text": "you go get a key from the provider pop"
      },
      {
        "start": 2555.88,
        "duration": 4.88,
        "text": "in your key and and wire it up right"
      },
      {
        "start": 2558.52,
        "duration": 4.64,
        "text": "you're you're done in 30 seconds or"
      },
      {
        "start": 2560.76,
        "duration": 4.04,
        "text": "something one thing I wanted to add very"
      },
      {
        "start": 2563.16,
        "duration": 3.28,
        "text": "briefly a question came up I don't know"
      },
      {
        "start": 2564.8,
        "duration": 3.039,
        "text": "if it's in the if it's in this list or"
      },
      {
        "start": 2566.44,
        "duration": 3.399,
        "text": "not where someone just asked like very"
      },
      {
        "start": 2567.839,
        "duration": 5.841,
        "text": "plainly like what why would I use this"
      },
      {
        "start": 2569.839,
        "duration": 7.0,
        "text": "instead of L chain um I think um one of"
      },
      {
        "start": 2573.68,
        "duration": 5.6,
        "text": "the ways that I think about it like much"
      },
      {
        "start": 2576.839,
        "duration": 4.161,
        "text": "of Lang flow is built on top of Lang"
      },
      {
        "start": 2579.28,
        "duration": 3.2,
        "text": "chain like if you're comfortable with"
      },
      {
        "start": 2581.0,
        "duration": 3.04,
        "text": "Lang chain if you're familiar with Lang"
      },
      {
        "start": 2582.48,
        "duration": 3.4,
        "text": "chain like I think it'll be really"
      },
      {
        "start": 2584.04,
        "duration": 4.039,
        "text": "comfortable and familiar with using Lang"
      },
      {
        "start": 2585.88,
        "duration": 4.719,
        "text": "flow um because a lot of what Lang flow"
      },
      {
        "start": 2588.079,
        "duration": 4.641,
        "text": "is is you know sort of this goey built"
      },
      {
        "start": 2590.599,
        "duration": 4.48,
        "text": "on top of these Lang chain components"
      },
      {
        "start": 2592.72,
        "duration": 3.92,
        "text": "and Primitives um one of the reasons you"
      },
      {
        "start": 2595.079,
        "duration": 5.76,
        "text": "might do it though is that Lang Lang"
      },
      {
        "start": 2596.64,
        "duration": 5.56,
        "text": "chain is a pretty vast um vast like"
      },
      {
        "start": 2600.839,
        "duration": 3.121,
        "text": "people call a Swiss army knife like"
      },
      {
        "start": 2602.2,
        "duration": 4.0,
        "text": "there are like just th thousands of"
      },
      {
        "start": 2603.96,
        "duration": 5.28,
        "text": "different like Lang chain methods um"
      },
      {
        "start": 2606.2,
        "duration": 6.119,
        "text": "Lang flows is is uh highly curated right"
      },
      {
        "start": 2609.24,
        "duration": 5.48,
        "text": "so like langlow is a subset of like the"
      },
      {
        "start": 2612.319,
        "duration": 6.081,
        "text": "universe of functionality that Lang"
      },
      {
        "start": 2614.72,
        "duration": 6.56,
        "text": "chain has um and it's curated with an"
      },
      {
        "start": 2618.4,
        "duration": 5.159,
        "text": "optimization towards rag applications"
      },
      {
        "start": 2621.28,
        "duration": 3.64,
        "text": "and an optim optim optimizations towards"
      },
      {
        "start": 2623.559,
        "duration": 3.081,
        "text": "like using the parts of length chain"
      },
      {
        "start": 2624.92,
        "duration": 5.6,
        "text": "that are actually like up to dat that"
      },
      {
        "start": 2626.64,
        "duration": 5.24,
        "text": "aren't broken um so uh so if you're you"
      },
      {
        "start": 2630.52,
        "duration": 3.599,
        "text": "know even if you're familiar with Len"
      },
      {
        "start": 2631.88,
        "duration": 5.4,
        "text": "chain like you might uh I I definitely"
      },
      {
        "start": 2634.119,
        "duration": 4.72,
        "text": "ask you to check out Len flow um to see"
      },
      {
        "start": 2637.28,
        "duration": 4.16,
        "text": "if it's missing anything that you"
      },
      {
        "start": 2638.839,
        "duration": 4.601,
        "text": "actually like use all the time from Lang"
      },
      {
        "start": 2641.44,
        "duration": 5.28,
        "text": "chain so I I just sort of think of it as"
      },
      {
        "start": 2643.44,
        "duration": 5.32,
        "text": "like an opinionated curated tool um that"
      },
      {
        "start": 2646.72,
        "duration": 5.04,
        "text": "developers can use to build these AI"
      },
      {
        "start": 2648.76,
        "duration": 5.0,
        "text": "flows um and also uh it is uh because"
      },
      {
        "start": 2651.76,
        "duration": 3.92,
        "text": "it's built on top of Lang chain if"
      },
      {
        "start": 2653.76,
        "duration": 5.0,
        "text": "you're if you want to use things like"
      },
      {
        "start": 2655.68,
        "duration": 5.72,
        "text": "Lang Smith which is Lang Chain's uh"
      },
      {
        "start": 2658.76,
        "duration": 4.559,
        "text": "observability uh Service uh you just get"
      },
      {
        "start": 2661.4,
        "duration": 4.919,
        "text": "it for free like you just you build your"
      },
      {
        "start": 2663.319,
        "duration": 5.601,
        "text": "AI flow using using Lang flow um you you"
      },
      {
        "start": 2666.319,
        "duration": 4.841,
        "text": "flip on an environment variable for your"
      },
      {
        "start": 2668.92,
        "duration": 4.52,
        "text": "your uh your Langs Smith key um and it"
      },
      {
        "start": 2671.16,
        "duration": 6.12,
        "text": "like it just works uh with no extra"
      },
      {
        "start": 2673.44,
        "duration": 6.72,
        "text": "added effort on your part um like add"
      },
      {
        "start": 2677.28,
        "duration": 5.319,
        "text": "that Carter you know from you know with"
      },
      {
        "start": 2680.16,
        "duration": 5.32,
        "text": "with using Lang chain compared to L flow"
      },
      {
        "start": 2682.599,
        "duration": 4.321,
        "text": "um conceptually like yeah if if you're"
      },
      {
        "start": 2685.48,
        "duration": 3.879,
        "text": "the person who's in the code you"
      },
      {
        "start": 2686.92,
        "duration": 3.72,
        "text": "understand the Lang sh the L chain uh"
      },
      {
        "start": 2689.359,
        "duration": 3.281,
        "text": "libraries and what's actually going in"
      },
      {
        "start": 2690.64,
        "duration": 5.08,
        "text": "in the code logic that that's wonderful"
      },
      {
        "start": 2692.64,
        "duration": 5.24,
        "text": "but conceptually especially as some of"
      },
      {
        "start": 2695.72,
        "duration": 4.2,
        "text": "the workflows become more comp Lex they"
      },
      {
        "start": 2697.88,
        "duration": 3.6,
        "text": "are much easier to visualize like"
      },
      {
        "start": 2699.92,
        "duration": 3.639,
        "text": "conceptualize when you can see them"
      },
      {
        "start": 2701.48,
        "duration": 3.639,
        "text": "visually and not only that it's much"
      },
      {
        "start": 2703.559,
        "duration": 3.641,
        "text": "easier to then present them to somebody"
      },
      {
        "start": 2705.119,
        "duration": 3.281,
        "text": "else right and say hey this is what this"
      },
      {
        "start": 2707.2,
        "duration": 3.28,
        "text": "flow is doing and here's how the"
      },
      {
        "start": 2708.4,
        "duration": 4.52,
        "text": "individual components can work could you"
      },
      {
        "start": 2710.48,
        "duration": 3.56,
        "text": "do that in Lang chain absolutely right"
      },
      {
        "start": 2712.92,
        "duration": 3.12,
        "text": "uh but especially if you're showing it"
      },
      {
        "start": 2714.04,
        "duration": 3.6,
        "text": "to somebody who might be a non- coder uh"
      },
      {
        "start": 2716.04,
        "duration": 4.2,
        "text": "or want their involvement then that's"
      },
      {
        "start": 2717.64,
        "duration": 4.6,
        "text": "almost a non-starter where when you see"
      },
      {
        "start": 2720.24,
        "duration": 3.72,
        "text": "it visually it it just makes it so much"
      },
      {
        "start": 2722.24,
        "duration": 3.599,
        "text": "e i I find that in my own personal"
      },
      {
        "start": 2723.96,
        "duration": 3.52,
        "text": "development it's just easier to"
      },
      {
        "start": 2725.839,
        "duration": 3.041,
        "text": "reference because I can take look at it"
      },
      {
        "start": 2727.48,
        "duration": 2.28,
        "text": "and I can see exactly what's going on in"
      },
      {
        "start": 2728.88,
        "duration": 3.76,
        "text": "my"
      },
      {
        "start": 2729.76,
        "duration": 4.079,
        "text": "flow um next we're gonna we're gonna"
      },
      {
        "start": 2732.64,
        "duration": 3.04,
        "text": "fire through these because there's so"
      },
      {
        "start": 2733.839,
        "duration": 3.641,
        "text": "many really great ones um I was actually"
      },
      {
        "start": 2735.68,
        "duration": 3.639,
        "text": "hoping Alex could maybe take take a stab"
      },
      {
        "start": 2737.48,
        "duration": 3.92,
        "text": "at this one um it's a really reasonable"
      },
      {
        "start": 2739.319,
        "duration": 5.601,
        "text": "question where the the developer is like"
      },
      {
        "start": 2741.4,
        "duration": 6.32,
        "text": "look like I want to I want to do rag um"
      },
      {
        "start": 2744.92,
        "duration": 5.0,
        "text": "I want to do Vector search but I have"
      },
      {
        "start": 2747.72,
        "duration": 4.08,
        "text": "other like criteria or like other"
      },
      {
        "start": 2749.92,
        "duration": 4.72,
        "text": "attributes that like I want to factor"
      },
      {
        "start": 2751.8,
        "duration": 5.84,
        "text": "into how these things are sorted um or"
      },
      {
        "start": 2754.64,
        "duration": 4.479,
        "text": "how like how I build the query um like"
      },
      {
        "start": 2757.64,
        "duration": 3.56,
        "text": "Alex do you have any any thoughts for"
      },
      {
        "start": 2759.119,
        "duration": 4.601,
        "text": "like what what they could"
      },
      {
        "start": 2761.2,
        "duration": 4.879,
        "text": "do this is this concept of like hybrid"
      },
      {
        "start": 2763.72,
        "duration": 4.0,
        "text": "search right where you're doing uh a"
      },
      {
        "start": 2766.079,
        "duration": 4.321,
        "text": "vector search and you're also filtering"
      },
      {
        "start": 2767.72,
        "duration": 5.48,
        "text": "on certain columns um so maybe if you're"
      },
      {
        "start": 2770.4,
        "duration": 4.959,
        "text": "a grocery store right like in your"
      },
      {
        "start": 2773.2,
        "duration": 5.0,
        "text": "database table you'd have your vector"
      },
      {
        "start": 2775.359,
        "duration": 7.521,
        "text": "embeddings then maybe like you know"
      },
      {
        "start": 2778.2,
        "duration": 6.2,
        "text": "produce and uh chips and there's this"
      },
      {
        "start": 2782.88,
        "duration": 4.28,
        "text": "concept of hybrid search where you could"
      },
      {
        "start": 2784.4,
        "duration": 5.439,
        "text": "essentially like filter to only search"
      },
      {
        "start": 2787.16,
        "duration": 4.72,
        "text": "you know your your produce items and"
      },
      {
        "start": 2789.839,
        "duration": 4.161,
        "text": "then kind of look for and then do the"
      },
      {
        "start": 2791.88,
        "duration": 3.36,
        "text": "similarity search so that would be my"
      },
      {
        "start": 2794.0,
        "duration": 5.92,
        "text": "recommendation and that's fully"
      },
      {
        "start": 2795.24,
        "duration": 6.48,
        "text": "supported in ASB yeah yeah I think um"
      },
      {
        "start": 2799.92,
        "duration": 4.72,
        "text": "look developers have a lot of choice"
      },
      {
        "start": 2801.72,
        "duration": 5.119,
        "text": "when it comes to uh Vector databases and"
      },
      {
        "start": 2804.64,
        "duration": 4.16,
        "text": "Vector search um the two we don't have"
      },
      {
        "start": 2806.839,
        "duration": 4.76,
        "text": "time to go into all of it um the two"
      },
      {
        "start": 2808.8,
        "duration": 4.48,
        "text": "broad categories of uh like databases"
      },
      {
        "start": 2811.599,
        "duration": 4.121,
        "text": "you're going to hear about are pretty"
      },
      {
        "start": 2813.28,
        "duration": 4.24,
        "text": "much like vector only databases uh that"
      },
      {
        "start": 2815.72,
        "duration": 3.72,
        "text": "just they store vectors they do Vector"
      },
      {
        "start": 2817.52,
        "duration": 3.68,
        "text": "search um and that's that's pretty much"
      },
      {
        "start": 2819.44,
        "duration": 4.96,
        "text": "what they're built and optimized for and"
      },
      {
        "start": 2821.2,
        "duration": 5.96,
        "text": "then there are um there are like fully"
      },
      {
        "start": 2824.4,
        "duration": 5.04,
        "text": "fledged application databases that also"
      },
      {
        "start": 2827.16,
        "duration": 5.84,
        "text": "support Vector storage and Vector search"
      },
      {
        "start": 2829.44,
        "duration": 6.04,
        "text": "so astrab is in the latter category of"
      },
      {
        "start": 2833.0,
        "duration": 4.28,
        "text": "database and as a developer what that"
      },
      {
        "start": 2835.48,
        "duration": 3.92,
        "text": "buys you is the ability to do what Alex"
      },
      {
        "start": 2837.28,
        "duration": 3.92,
        "text": "said which is basically hybrid search so"
      },
      {
        "start": 2839.4,
        "duration": 3.719,
        "text": "you can you can think of it as you're"
      },
      {
        "start": 2841.2,
        "duration": 3.8,
        "text": "you're executing this filter you're"
      },
      {
        "start": 2843.119,
        "duration": 3.44,
        "text": "executing this sort you're you're"
      },
      {
        "start": 2845.0,
        "duration": 3.96,
        "text": "returning documents and you're sorting"
      },
      {
        "start": 2846.559,
        "duration": 4.121,
        "text": "them but you can sort by multiple Fields"
      },
      {
        "start": 2848.96,
        "duration": 4.159,
        "text": "one of those fields could be the ve the"
      },
      {
        "start": 2850.68,
        "duration": 4.439,
        "text": "vector field the vector similarity field"
      },
      {
        "start": 2853.119,
        "duration": 4.48,
        "text": "but then the other could be um these"
      },
      {
        "start": 2855.119,
        "duration": 4.281,
        "text": "these other attributes uh that you want"
      },
      {
        "start": 2857.599,
        "duration": 3.921,
        "text": "to sort on or that you want to filter"
      },
      {
        "start": 2859.4,
        "duration": 4.56,
        "text": "for um and that's and that's something"
      },
      {
        "start": 2861.52,
        "duration": 3.799,
        "text": "that you you makes it Astra makes it"
      },
      {
        "start": 2863.96,
        "duration": 3.84,
        "text": "really easy to execute that kind of"
      },
      {
        "start": 2865.319,
        "duration": 4.361,
        "text": "hybrid search so um that's like that's"
      },
      {
        "start": 2867.8,
        "duration": 5.519,
        "text": "one way that you could that you could do"
      },
      {
        "start": 2869.68,
        "duration": 7.48,
        "text": "that um all right uh David uh a question"
      },
      {
        "start": 2873.319,
        "duration": 5.52,
        "text": "for you uh about uh about about chunking"
      },
      {
        "start": 2877.16,
        "duration": 3.84,
        "text": "um this is this come this comes up all"
      },
      {
        "start": 2878.839,
        "duration": 4.601,
        "text": "the time this is for Alex and David"
      },
      {
        "start": 2881.0,
        "duration": 3.88,
        "text": "right I mean like yeah how how how"
      },
      {
        "start": 2883.44,
        "duration": 3.24,
        "text": "should develop like once again this is a"
      },
      {
        "start": 2884.88,
        "duration": 3.92,
        "text": "rag 101 talk like we don't need to go"
      },
      {
        "start": 2886.68,
        "duration": 3.8,
        "text": "into crazy depths of detail but just"
      },
      {
        "start": 2888.8,
        "duration": 3.72,
        "text": "like really high level like how should"
      },
      {
        "start": 2890.48,
        "duration": 3.96,
        "text": "an application developer think about"
      },
      {
        "start": 2892.52,
        "duration": 2.88,
        "text": "what their options are for chunking or"
      },
      {
        "start": 2894.44,
        "duration": 2.8,
        "text": "like just stuff that they should"
      },
      {
        "start": 2895.4,
        "duration": 5.439,
        "text": "consider when they're chunking in order"
      },
      {
        "start": 2897.24,
        "duration": 5.48,
        "text": "to sort of improve the results of their"
      },
      {
        "start": 2900.839,
        "duration": 3.441,
        "text": "application yeah I've got a I've got a"
      },
      {
        "start": 2902.72,
        "duration": 2.639,
        "text": "couple things to say about that um one"
      },
      {
        "start": 2904.28,
        "duration": 3.16,
        "text": "if you're talking about just pure"
      },
      {
        "start": 2905.359,
        "duration": 3.801,
        "text": "chunking um part of that is going to dep"
      },
      {
        "start": 2907.44,
        "duration": 4.84,
        "text": "be dependent on the embedding model that"
      },
      {
        "start": 2909.16,
        "duration": 4.72,
        "text": "you're using um so I would look at that"
      },
      {
        "start": 2912.28,
        "duration": 2.88,
        "text": "right um you know there's going to be"
      },
      {
        "start": 2913.88,
        "duration": 3.92,
        "text": "slight differences between if you're"
      },
      {
        "start": 2915.16,
        "duration": 4.8,
        "text": "using like nvidia's Nemo compared to uh"
      },
      {
        "start": 2917.8,
        "duration": 4.4,
        "text": "open eyes text and Bing models or mistol"
      },
      {
        "start": 2919.96,
        "duration": 4.44,
        "text": "or whatever right so it does take"
      },
      {
        "start": 2922.2,
        "duration": 3.639,
        "text": "sometimes a little bit of research on"
      },
      {
        "start": 2924.4,
        "duration": 3.199,
        "text": "the individual models and you it"
      },
      {
        "start": 2925.839,
        "duration": 3.321,
        "text": "honestly you should experiment with them"
      },
      {
        "start": 2927.599,
        "duration": 3.48,
        "text": "anyway and and kind of see what works"
      },
      {
        "start": 2929.16,
        "duration": 5.159,
        "text": "for you but you'll find that for each of"
      },
      {
        "start": 2931.079,
        "duration": 4.961,
        "text": "the individual models um they will have"
      },
      {
        "start": 2934.319,
        "duration": 3.361,
        "text": "slightly different chunking strategies"
      },
      {
        "start": 2936.04,
        "duration": 3.039,
        "text": "but the other thing see I see Alex you"
      },
      {
        "start": 2937.68,
        "duration": 3.84,
        "text": "also post the link I I'll say something"
      },
      {
        "start": 2939.079,
        "duration": 5.441,
        "text": "real quick um the other thing is there"
      },
      {
        "start": 2941.52,
        "duration": 5.52,
        "text": "are whole different methodologies like"
      },
      {
        "start": 2944.52,
        "duration": 5.279,
        "text": "there's there's something called culbert"
      },
      {
        "start": 2947.04,
        "duration": 5.24,
        "text": "um where it's a completely different way"
      },
      {
        "start": 2949.799,
        "duration": 4.681,
        "text": "of doing it it's not just grabbing like"
      },
      {
        "start": 2952.28,
        "duration": 3.36,
        "text": "in example that I showed you know was"
      },
      {
        "start": 2954.48,
        "duration": 3.2,
        "text": "just kind of doing this generic I'm"
      },
      {
        "start": 2955.64,
        "duration": 3.6,
        "text": "gonna grab a thousand characters right"
      },
      {
        "start": 2957.68,
        "duration": 3.08,
        "text": "and it doesn't matter what's in the text"
      },
      {
        "start": 2959.24,
        "duration": 2.64,
        "text": "it doesn't matter if it's semantically"
      },
      {
        "start": 2960.76,
        "duration": 3.16,
        "text": "similar or anything I'm just going to"
      },
      {
        "start": 2961.88,
        "duration": 3.959,
        "text": "grab you know a thousand characters and"
      },
      {
        "start": 2963.92,
        "duration": 4.28,
        "text": "I'm gonna Chunk on it um Colbert is a"
      },
      {
        "start": 2965.839,
        "duration": 4.641,
        "text": "different method that is actually a bit"
      },
      {
        "start": 2968.2,
        "duration": 4.119,
        "text": "smarter when it comes to context um and"
      },
      {
        "start": 2970.48,
        "duration": 3.96,
        "text": "it doesn't actually do chunking in the"
      },
      {
        "start": 2972.319,
        "duration": 4.721,
        "text": "same way at all it actually is is based"
      },
      {
        "start": 2974.44,
        "duration": 5.48,
        "text": "off of tokens and you're saying hey I'm"
      },
      {
        "start": 2977.04,
        "duration": 5.0,
        "text": "gonna grab a set of tokens but then I'm"
      },
      {
        "start": 2979.92,
        "duration": 3.52,
        "text": "GNA get information about the"
      },
      {
        "start": 2982.04,
        "duration": 3.319,
        "text": "surrounding tokens I'm going to"
      },
      {
        "start": 2983.44,
        "duration": 4.159,
        "text": "vectorize that with a smaller"
      },
      {
        "start": 2985.359,
        "duration": 5.561,
        "text": "essentially smaller Dimension amount"
      },
      {
        "start": 2987.599,
        "duration": 5.52,
        "text": "like 128 but then I'm also going to set"
      },
      {
        "start": 2990.92,
        "duration": 4.0,
        "text": "up something that allows me to slide in"
      },
      {
        "start": 2993.119,
        "duration": 4.841,
        "text": "like kind of overlap data on purpose"
      },
      {
        "start": 2994.92,
        "duration": 4.879,
        "text": "it's actually very good for maintaining"
      },
      {
        "start": 2997.96,
        "duration": 3.639,
        "text": "context and everything so it's a totally"
      },
      {
        "start": 2999.799,
        "duration": 4.081,
        "text": "different strategy than just straight up"
      },
      {
        "start": 3001.599,
        "duration": 3.841,
        "text": "chunking um yeah so there's there's"
      },
      {
        "start": 3003.88,
        "duration": 3.32,
        "text": "definitely multiple ways to do it I"
      },
      {
        "start": 3005.44,
        "duration": 3.32,
        "text": "think experimentation a little bit of"
      },
      {
        "start": 3007.2,
        "duration": 4.56,
        "text": "research on the models you're you're"
      },
      {
        "start": 3008.76,
        "duration": 5.72,
        "text": "using goes a long way there yeah Alex"
      },
      {
        "start": 3011.76,
        "duration": 4.0,
        "text": "you have anything to add there I I was"
      },
      {
        "start": 3014.48,
        "duration": 4.28,
        "text": "just going to add we heavily use this"
      },
      {
        "start": 3015.76,
        "duration": 4.559,
        "text": "Lane chain recursive text splitter um so"
      },
      {
        "start": 3018.76,
        "duration": 3.48,
        "text": "might be interesting to take a look they"
      },
      {
        "start": 3020.319,
        "duration": 4.881,
        "text": "have some good dots with recommendations"
      },
      {
        "start": 3022.24,
        "duration": 5.079,
        "text": "some choke size and overlap um we also"
      },
      {
        "start": 3025.2,
        "duration": 6.2,
        "text": "heavily used the unstructured"
      },
      {
        "start": 3027.319,
        "duration": 6.28,
        "text": "for text splitting chunking um so they"
      },
      {
        "start": 3031.4,
        "duration": 4.88,
        "text": "all have super good resources and we're"
      },
      {
        "start": 3033.599,
        "duration": 4.641,
        "text": "also about to ship a blog or we did ship"
      },
      {
        "start": 3036.28,
        "duration": 5.36,
        "text": "a Blog on chunking that we'll share"
      },
      {
        "start": 3038.24,
        "duration": 5.44,
        "text": "after this as well on what some thoughts"
      },
      {
        "start": 3041.64,
        "duration": 4.6,
        "text": "and and and I'll just say this like"
      },
      {
        "start": 3043.68,
        "duration": 5.679,
        "text": "super high level stuff right like"
      },
      {
        "start": 3046.24,
        "duration": 4.68,
        "text": "I all developers application developers"
      },
      {
        "start": 3049.359,
        "duration": 4.521,
        "text": "that are starting to get into generative"
      },
      {
        "start": 3050.92,
        "duration": 4.76,
        "text": "Ai and and and rag like you might find"
      },
      {
        "start": 3053.88,
        "duration": 4.04,
        "text": "this frustrating but the amount the"
      },
      {
        "start": 3055.68,
        "duration": 3.6,
        "text": "amount of time you spend writing code is"
      },
      {
        "start": 3057.92,
        "duration": 3.439,
        "text": "going to be a lot less than the amount"
      },
      {
        "start": 3059.28,
        "duration": 4.0,
        "text": "of time you spend like experimenting"
      },
      {
        "start": 3061.359,
        "duration": 3.641,
        "text": "with these different things right David"
      },
      {
        "start": 3063.28,
        "duration": 4.36,
        "text": "talked about David talked about swap"
      },
      {
        "start": 3065.0,
        "duration": 4.799,
        "text": "swapping in and out llms we just talked"
      },
      {
        "start": 3067.64,
        "duration": 4.84,
        "text": "about like different chunking strategies"
      },
      {
        "start": 3069.799,
        "duration": 4.0,
        "text": "and try this and like I I think it's FR"
      },
      {
        "start": 3072.48,
        "duration": 3.52,
        "text": "I think it will be it's frustrating for"
      },
      {
        "start": 3073.799,
        "duration": 4.401,
        "text": "some developers who are accustomed to"
      },
      {
        "start": 3076.0,
        "duration": 3.76,
        "text": "thinking of their productivity based on"
      },
      {
        "start": 3078.2,
        "duration": 3.639,
        "text": "the number of lines of code that they're"
      },
      {
        "start": 3079.76,
        "duration": 5.599,
        "text": "kind of writing per day but AI"
      },
      {
        "start": 3081.839,
        "duration": 5.361,
        "text": "engineering is um often times uh more"
      },
      {
        "start": 3085.359,
        "duration": 3.96,
        "text": "about like iterating right it's more"
      },
      {
        "start": 3087.2,
        "duration": 4.32,
        "text": "about trying different things looking"
      },
      {
        "start": 3089.319,
        "duration": 4.24,
        "text": "look looking at the results tweaking"
      },
      {
        "start": 3091.52,
        "duration": 3.44,
        "text": "those tweaking some of those parameters"
      },
      {
        "start": 3093.559,
        "duration": 3.76,
        "text": "and then trying it again this is true"
      },
      {
        "start": 3094.96,
        "duration": 5.119,
        "text": "for prompt engineering true for chunking"
      },
      {
        "start": 3097.319,
        "duration": 4.201,
        "text": "true true for llm choices um and frankly"
      },
      {
        "start": 3100.079,
        "duration": 3.24,
        "text": "I think it's kind of I think it's it's"
      },
      {
        "start": 3101.52,
        "duration": 3.52,
        "text": "overall a good thing right I mean like"
      },
      {
        "start": 3103.319,
        "duration": 3.52,
        "text": "you know it's a it's definitely less"
      },
      {
        "start": 3105.04,
        "duration": 3.519,
        "text": "about like writing code and more about"
      },
      {
        "start": 3106.839,
        "duration": 3.601,
        "text": "like understanding how to like integrate"
      },
      {
        "start": 3108.559,
        "duration": 3.8,
        "text": "these different tools and optimize the"
      },
      {
        "start": 3110.44,
        "duration": 3.96,
        "text": "results for developers um someone asked"
      },
      {
        "start": 3112.359,
        "duration": 4.48,
        "text": "a really great question about the the"
      },
      {
        "start": 3114.4,
        "duration": 3.64,
        "text": "embedding part right um and there's a"
      },
      {
        "start": 3116.839,
        "duration": 3.681,
        "text": "bunch of really cool stuff that we're"
      },
      {
        "start": 3118.04,
        "duration": 4.799,
        "text": "doing to like make this part easier I"
      },
      {
        "start": 3120.52,
        "duration": 4.52,
        "text": "thought Alex um could maybe uh dive in a"
      },
      {
        "start": 3122.839,
        "duration": 2.201,
        "text": "little"
      },
      {
        "start": 3125.52,
        "duration": 5.92,
        "text": "bit Yeah so um can you explain so the"
      },
      {
        "start": 3130.16,
        "duration": 3.8,
        "text": "question is can you please explain the"
      },
      {
        "start": 3131.44,
        "duration": 5.24,
        "text": "embedding part in more detail um so"
      },
      {
        "start": 3133.96,
        "duration": 4.96,
        "text": "basically in order to perform a vector"
      },
      {
        "start": 3136.68,
        "duration": 5.36,
        "text": "search you first need to take kind of"
      },
      {
        "start": 3138.92,
        "duration": 5.36,
        "text": "your document Corpus and convert it into"
      },
      {
        "start": 3142.04,
        "duration": 5.039,
        "text": "Vector embeddings um which are basically"
      },
      {
        "start": 3144.28,
        "duration": 5.12,
        "text": "just arrays of numbers"
      },
      {
        "start": 3147.079,
        "duration": 4.561,
        "text": "um so basically how you do that is you"
      },
      {
        "start": 3149.4,
        "duration": 4.919,
        "text": "call an external API in my example I"
      },
      {
        "start": 3151.64,
        "duration": 5.679,
        "text": "used open AI open AI will take that raw"
      },
      {
        "start": 3154.319,
        "duration": 4.48,
        "text": "text convert it into this array of"
      },
      {
        "start": 3157.319,
        "duration": 4.161,
        "text": "numbers and then you sort end of"
      },
      {
        "start": 3158.799,
        "duration": 4.121,
        "text": "actually datab base like asra um so we"
      },
      {
        "start": 3161.48,
        "duration": 3.8,
        "text": "recently introduced this feature called"
      },
      {
        "start": 3162.92,
        "duration": 4.399,
        "text": "vectorize to make this entire process"
      },
      {
        "start": 3165.28,
        "duration": 3.72,
        "text": "easier so rather than kind of playing"
      },
      {
        "start": 3167.319,
        "duration": 5.201,
        "text": "around with a bunch of external apis you"
      },
      {
        "start": 3169.0,
        "duration": 5.559,
        "text": "can now use the ACT be vectorized API"
      },
      {
        "start": 3172.52,
        "duration": 4.4,
        "text": "with a single API call embed your data"
      },
      {
        "start": 3174.559,
        "duration": 5.201,
        "text": "and also write to the DV so we can share"
      },
      {
        "start": 3176.92,
        "duration": 4.96,
        "text": "more information on that um it's also"
      },
      {
        "start": 3179.76,
        "duration": 3.319,
        "text": "super easy to embed your your your"
      },
      {
        "start": 3181.88,
        "duration": 3.28,
        "text": "content with the link below that David"
      },
      {
        "start": 3183.079,
        "duration": 5.321,
        "text": "showed a bit as"
      },
      {
        "start": 3185.16,
        "duration": 4.6,
        "text": "well um is there a way to and this is a"
      },
      {
        "start": 3188.4,
        "duration": 2.76,
        "text": "question just came in that's relevant is"
      },
      {
        "start": 3189.76,
        "duration": 3.48,
        "text": "there a way to find out the quality of"
      },
      {
        "start": 3191.16,
        "duration": 3.8,
        "text": "embeddings like how do we know embedding"
      },
      {
        "start": 3193.24,
        "duration": 3.359,
        "text": "is good or not um there's a bunch of"
      },
      {
        "start": 3194.96,
        "duration": 3.24,
        "text": "rankings online on like the best"
      },
      {
        "start": 3196.599,
        "duration": 3.361,
        "text": "embedding models that you can take a"
      },
      {
        "start": 3198.2,
        "duration": 3.96,
        "text": "look at um if you Google just like"
      },
      {
        "start": 3199.96,
        "duration": 4.04,
        "text": "embedding model ranking hog and face is"
      },
      {
        "start": 3202.16,
        "duration": 4.56,
        "text": "really good"
      },
      {
        "start": 3204.0,
        "duration": 4.52,
        "text": "list yeah and I think um another thing"
      },
      {
        "start": 3206.72,
        "duration": 3.359,
        "text": "another recommendation that i' I've seen"
      },
      {
        "start": 3208.52,
        "duration": 4.12,
        "text": "people Implement and I I think yield"
      },
      {
        "start": 3210.079,
        "duration": 4.121,
        "text": "good results like you like as developers"
      },
      {
        "start": 3212.64,
        "duration": 3.679,
        "text": "like we're totally accustomed to"
      },
      {
        "start": 3214.2,
        "duration": 5.04,
        "text": "building writing unit tests and like"
      },
      {
        "start": 3216.319,
        "duration": 4.28,
        "text": "writing integration tests like there's"
      },
      {
        "start": 3219.24,
        "duration": 2.92,
        "text": "you're basically going to do the same"
      },
      {
        "start": 3220.599,
        "duration": 3.561,
        "text": "thing for these applications right like"
      },
      {
        "start": 3222.16,
        "duration": 3.56,
        "text": "you're gonna you're gonna have you you"
      },
      {
        "start": 3224.16,
        "duration": 4.199,
        "text": "should you can build a test harness and"
      },
      {
        "start": 3225.72,
        "duration": 5.76,
        "text": "a test Suite that has a bunch of"
      },
      {
        "start": 3228.359,
        "duration": 4.641,
        "text": "expected questions or expected prompts"
      },
      {
        "start": 3231.48,
        "duration": 3.119,
        "text": "uh and then you can run those prompts"
      },
      {
        "start": 3233.0,
        "duration": 3.64,
        "text": "through your application and you can"
      },
      {
        "start": 3234.599,
        "duration": 3.96,
        "text": "actually use an lln and you can have"
      },
      {
        "start": 3236.64,
        "duration": 5.28,
        "text": "like an expected output and you can"
      },
      {
        "start": 3238.559,
        "duration": 6.04,
        "text": "actually use llms to compare the actual"
      },
      {
        "start": 3241.92,
        "duration": 4.879,
        "text": "output to the expected output so even if"
      },
      {
        "start": 3244.599,
        "duration": 3.0,
        "text": "it isn't character that's cool even if"
      },
      {
        "start": 3246.799,
        "duration": 3.201,
        "text": "it"
      },
      {
        "start": 3247.599,
        "duration": 4.561,
        "text": "isn't even if it isn't character for"
      },
      {
        "start": 3250.0,
        "duration": 4.359,
        "text": "character identical like you can ask the"
      },
      {
        "start": 3252.16,
        "duration": 5.08,
        "text": "LM like hey like is this is this like is"
      },
      {
        "start": 3254.359,
        "duration": 4.641,
        "text": "this like 90% similar right um and I've"
      },
      {
        "start": 3257.24,
        "duration": 4.0,
        "text": "seen people people do that um and you're"
      },
      {
        "start": 3259.0,
        "duration": 4.599,
        "text": "gonna want to do that because once again"
      },
      {
        "start": 3261.24,
        "duration": 3.92,
        "text": "like you know think why do we have unit"
      },
      {
        "start": 3263.599,
        "duration": 3.401,
        "text": "tests like right we have unit tests"
      },
      {
        "start": 3265.16,
        "duration": 3.159,
        "text": "because like you're constantly iterating"
      },
      {
        "start": 3267.0,
        "duration": 3.079,
        "text": "iterating on your application making"
      },
      {
        "start": 3268.319,
        "duration": 3.441,
        "text": "changes and you have to have confidence"
      },
      {
        "start": 3270.079,
        "duration": 3.161,
        "text": "that when you make changes before you"
      },
      {
        "start": 3271.76,
        "duration": 3.28,
        "text": "ship the changes to production you"
      },
      {
        "start": 3273.24,
        "duration": 4.52,
        "text": "haven't created a regression or broken"
      },
      {
        "start": 3275.04,
        "duration": 4.48,
        "text": "everything so this is AI engineering is"
      },
      {
        "start": 3277.76,
        "duration": 3.599,
        "text": "just introducing it's taking a lot of"
      },
      {
        "start": 3279.52,
        "duration": 4.76,
        "text": "things that we're used to but changing"
      },
      {
        "start": 3281.359,
        "duration": 5.48,
        "text": "them into into sort of a new form of"
      },
      {
        "start": 3284.28,
        "duration": 5.0,
        "text": "those things like for for these for this"
      },
      {
        "start": 3286.839,
        "duration": 3.801,
        "text": "generative AI age that we're in um I"
      },
      {
        "start": 3289.28,
        "duration": 3.64,
        "text": "wanted to get to this question because"
      },
      {
        "start": 3290.64,
        "duration": 4.36,
        "text": "it it's um sorry we're because we're"
      },
      {
        "start": 3292.92,
        "duration": 3.84,
        "text": "running low on time um because I think"
      },
      {
        "start": 3295.0,
        "duration": 3.52,
        "text": "this is important right like someone"
      },
      {
        "start": 3296.76,
        "duration": 4.599,
        "text": "this person's asking like hey like how"
      },
      {
        "start": 3298.52,
        "duration": 4.599,
        "text": "do we how do we think about you know the"
      },
      {
        "start": 3301.359,
        "duration": 4.321,
        "text": "r part of things like you know what how"
      },
      {
        "start": 3303.119,
        "duration": 5.2,
        "text": "do we think about you know um leaking"
      },
      {
        "start": 3305.68,
        "duration": 5.919,
        "text": "confidential information um to"
      },
      {
        "start": 3308.319,
        "duration": 5.161,
        "text": "llms uh very quick comment for me um"
      },
      {
        "start": 3311.599,
        "duration": 4.561,
        "text": "there are two kinds of llms that you can"
      },
      {
        "start": 3313.48,
        "duration": 4.56,
        "text": "use uh there are open source llms and"
      },
      {
        "start": 3316.16,
        "duration": 4.08,
        "text": "there are sort of close Source like you"
      },
      {
        "start": 3318.04,
        "duration": 4.799,
        "text": "know uh service llms you know think of"
      },
      {
        "start": 3320.24,
        "duration": 4.559,
        "text": "open AI is like an example of that right"
      },
      {
        "start": 3322.839,
        "duration": 4.2,
        "text": "um if you're using an open source llm"
      },
      {
        "start": 3324.799,
        "duration": 3.601,
        "text": "you don't need to worry about your data"
      },
      {
        "start": 3327.039,
        "duration": 3.0,
        "text": "or your you know your your company's"
      },
      {
        "start": 3328.4,
        "duration": 3.959,
        "text": "data or your customers data being leaked"
      },
      {
        "start": 3330.039,
        "duration": 4.481,
        "text": "to anywhere right and that might be a"
      },
      {
        "start": 3332.359,
        "duration": 4.0,
        "text": "consideration that you that you make"
      },
      {
        "start": 3334.52,
        "duration": 4.279,
        "text": "when you're trying to decide what llm to"
      },
      {
        "start": 3336.359,
        "duration": 4.2,
        "text": "use but conversely like if you want to"
      },
      {
        "start": 3338.799,
        "duration": 5.721,
        "text": "use a service-based"
      },
      {
        "start": 3340.559,
        "duration": 5.8,
        "text": "llm uh you simply like every other API"
      },
      {
        "start": 3344.52,
        "duration": 3.599,
        "text": "or every other service or every other"
      },
      {
        "start": 3346.359,
        "duration": 3.72,
        "text": "database that you might think of using"
      },
      {
        "start": 3348.119,
        "duration": 3.361,
        "text": "for sensitive customer information"
      },
      {
        "start": 3350.079,
        "duration": 3.201,
        "text": "you're going to have to pay attention to"
      },
      {
        "start": 3351.48,
        "duration": 3.599,
        "text": "the you know to the to the sort of the"
      },
      {
        "start": 3353.28,
        "duration": 4.279,
        "text": "terms of use and the terms of service"
      },
      {
        "start": 3355.079,
        "duration": 4.841,
        "text": "right um uh so in the same way that you"
      },
      {
        "start": 3357.559,
        "duration": 5.24,
        "text": "might ask the question like where can I"
      },
      {
        "start": 3359.92,
        "duration": 5.199,
        "text": "store sensitive and customer data like"
      },
      {
        "start": 3362.799,
        "duration": 5.04,
        "text": "ask those exact same questions in terms"
      },
      {
        "start": 3365.119,
        "duration": 6.561,
        "text": "of the llm services that you might use"
      },
      {
        "start": 3367.839,
        "duration": 6.161,
        "text": "so for instance um Astra Alex did you"
      },
      {
        "start": 3371.68,
        "duration": 6.359,
        "text": "talk about uh vectorized as as part of"
      },
      {
        "start": 3374.0,
        "duration": 7.039,
        "text": "asra yet yeah yeah yeah awesome so so as"
      },
      {
        "start": 3378.039,
        "duration": 6.481,
        "text": "Alex mentioned like you know we natively"
      },
      {
        "start": 3381.039,
        "duration": 7.401,
        "text": "support a bunch of uh uh providers uh"
      },
      {
        "start": 3384.52,
        "duration": 7.279,
        "text": "and embedding models in as DB um and we"
      },
      {
        "start": 3388.44,
        "duration": 6.24,
        "text": "support both open AI um and Azure open"
      },
      {
        "start": 3391.799,
        "duration": 5.921,
        "text": "AI uh so for you know for developers"
      },
      {
        "start": 3394.68,
        "duration": 6.56,
        "text": "that build as part of um Microsoft and"
      },
      {
        "start": 3397.72,
        "duration": 7.28,
        "text": "azure's ecosystem and uh and sort of"
      },
      {
        "start": 3401.24,
        "duration": 5.599,
        "text": "have uh a preference uh for storing data"
      },
      {
        "start": 3405.0,
        "duration": 4.48,
        "text": "and using apis that are part of that"
      },
      {
        "start": 3406.839,
        "duration": 3.641,
        "text": "ecosystem like we support Azure open AI"
      },
      {
        "start": 3409.48,
        "duration": 1.96,
        "text": "um but that's just that's that's"
      },
      {
        "start": 3410.48,
        "duration": 2.599,
        "text": "something that you would just sort of"
      },
      {
        "start": 3411.44,
        "duration": 3.0,
        "text": "need to pay attention to um as you're"
      },
      {
        "start": 3413.079,
        "duration": 4.48,
        "text": "building these"
      },
      {
        "start": 3414.44,
        "duration": 6.08,
        "text": "applications um cool uh so we're running"
      },
      {
        "start": 3417.559,
        "duration": 5.28,
        "text": "low on time um I wanted I wanted I"
      },
      {
        "start": 3420.52,
        "duration": 4.64,
        "text": "wanted to I want to kind of maybe close"
      },
      {
        "start": 3422.839,
        "duration": 3.921,
        "text": "to this right um and I'll just I'll pop"
      },
      {
        "start": 3425.16,
        "duration": 3.12,
        "text": "this up right because I'm sorry we can't"
      },
      {
        "start": 3426.76,
        "duration": 3.359,
        "text": "we can't get to everything but these"
      },
      {
        "start": 3428.28,
        "duration": 3.4,
        "text": "questions have been awesome right and I"
      },
      {
        "start": 3430.119,
        "duration": 4.361,
        "text": "think this is a good one to close with"
      },
      {
        "start": 3431.68,
        "duration": 5.56,
        "text": "right like and I'll pose it to both"
      },
      {
        "start": 3434.48,
        "duration": 4.16,
        "text": "David and Alex right like what is how"
      },
      {
        "start": 3437.24,
        "duration": 4.0,
        "text": "would what's like the one or two"
      },
      {
        "start": 3438.64,
        "duration": 5.32,
        "text": "sentence like explanation or just"
      },
      {
        "start": 3441.24,
        "duration": 5.24,
        "text": "analogy that like you could use to"
      },
      {
        "start": 3443.96,
        "duration": 4.0,
        "text": "explain rag to I don't know I people"
      },
      {
        "start": 3446.48,
        "duration": 3.359,
        "text": "always use the stereotype of like your"
      },
      {
        "start": 3447.96,
        "duration": 3.839,
        "text": "mom but I think that's kind of like you"
      },
      {
        "start": 3449.839,
        "duration": 3.801,
        "text": "know let's not let's not be mean to moms"
      },
      {
        "start": 3451.799,
        "duration": 3.52,
        "text": "in the world right maybe your kid right"
      },
      {
        "start": 3453.64,
        "duration": 3.56,
        "text": "like you know like what is like how"
      },
      {
        "start": 3455.319,
        "duration": 3.8,
        "text": "would you sort of describe it like I"
      },
      {
        "start": 3457.2,
        "duration": 5.72,
        "text": "I'll go first right um I don't know if"
      },
      {
        "start": 3459.119,
        "duration": 7.161,
        "text": "this is the best analogy right um but uh"
      },
      {
        "start": 3462.92,
        "duration": 6.28,
        "text": "some there's a our chief product officer"
      },
      {
        "start": 3466.28,
        "duration": 6.24,
        "text": "uh here at data Stacks um he has to do"
      },
      {
        "start": 3469.2,
        "duration": 5.28,
        "text": "uh a lot of uh sort of um like U he has"
      },
      {
        "start": 3472.52,
        "duration": 4.76,
        "text": "to have a lot of meetings and do a lot"
      },
      {
        "start": 3474.48,
        "duration": 5.359,
        "text": "of interviews with like analysts uh in"
      },
      {
        "start": 3477.28,
        "duration": 4.2,
        "text": "journalists um and there's there's"
      },
      {
        "start": 3479.839,
        "duration": 5.121,
        "text": "there's sort of a a game that gets"
      },
      {
        "start": 3481.48,
        "duration": 5.359,
        "text": "played where um you know because people"
      },
      {
        "start": 3484.96,
        "duration": 3.76,
        "text": "can ask like any kind of question and"
      },
      {
        "start": 3486.839,
        "duration": 4.2,
        "text": "you have to have like information like"
      },
      {
        "start": 3488.72,
        "duration": 4.04,
        "text": "available like on hand to be able to"
      },
      {
        "start": 3491.039,
        "duration": 3.0,
        "text": "intelligently answer answer those"
      },
      {
        "start": 3492.76,
        "duration": 2.72,
        "text": "questions because you just never know"
      },
      {
        "start": 3494.039,
        "duration": 4.361,
        "text": "what an analyst or a journalist is going"
      },
      {
        "start": 3495.48,
        "duration": 4.72,
        "text": "to throw at you um and and and there are"
      },
      {
        "start": 3498.4,
        "duration": 4.0,
        "text": "assistants like there are there people"
      },
      {
        "start": 3500.2,
        "duration": 4.32,
        "text": "that work with Ed our chief product"
      },
      {
        "start": 3502.4,
        "duration": 3.399,
        "text": "officer that like have that data like at"
      },
      {
        "start": 3504.52,
        "duration": 3.2,
        "text": "their fingertips and they can sort of"
      },
      {
        "start": 3505.799,
        "duration": 4.24,
        "text": "provide to Ed so that he can sort of"
      },
      {
        "start": 3507.72,
        "duration": 4.44,
        "text": "answer the question um you know with"
      },
      {
        "start": 3510.039,
        "duration": 3.601,
        "text": "with like with enough context to like"
      },
      {
        "start": 3512.16,
        "duration": 3.0,
        "text": "help help the analyst or help the"
      },
      {
        "start": 3513.64,
        "duration": 2.679,
        "text": "journalist sort of understand what the"
      },
      {
        "start": 3515.16,
        "duration": 3.72,
        "text": "answer is and I think that's kind of"
      },
      {
        "start": 3516.319,
        "duration": 4.841,
        "text": "like a a decent sort of metaphor for how"
      },
      {
        "start": 3518.88,
        "duration": 5.199,
        "text": "rag works right where like the question"
      },
      {
        "start": 3521.16,
        "duration": 4.8,
        "text": "or the prompt is just unknown in advance"
      },
      {
        "start": 3524.079,
        "duration": 4.0,
        "text": "um but like you can use that question or"
      },
      {
        "start": 3525.96,
        "duration": 4.48,
        "text": "that prompt to sort of like very quickly"
      },
      {
        "start": 3528.079,
        "duration": 3.841,
        "text": "and efficiently like get some context"
      },
      {
        "start": 3530.44,
        "duration": 3.679,
        "text": "and some information and then you"
      },
      {
        "start": 3531.92,
        "duration": 4.399,
        "text": "provide it to you know someone like Ed"
      },
      {
        "start": 3534.119,
        "duration": 4.401,
        "text": "um or someone else that like can sort"
      },
      {
        "start": 3536.319,
        "duration": 5.0,
        "text": "take that context alongside the original"
      },
      {
        "start": 3538.52,
        "duration": 5.039,
        "text": "question and provide like a really great"
      },
      {
        "start": 3541.319,
        "duration": 3.8,
        "text": "like easy to understand answer you know"
      },
      {
        "start": 3543.559,
        "duration": 3.201,
        "text": "for the person who asked the question in"
      },
      {
        "start": 3545.119,
        "duration": 2.92,
        "text": "the first place so that's like I don't"
      },
      {
        "start": 3546.76,
        "duration": 2.72,
        "text": "know that's like that's one thing that"
      },
      {
        "start": 3548.039,
        "duration": 2.921,
        "text": "kind of came to mind for me but David"
      },
      {
        "start": 3549.48,
        "duration": 3.72,
        "text": "I'm curious if you if you've got"
      },
      {
        "start": 3550.96,
        "duration": 3.48,
        "text": "something better oh I don't know I'm I'm"
      },
      {
        "start": 3553.2,
        "duration": 3.32,
        "text": "actually laughing at Hugh Brown's"
      },
      {
        "start": 3554.44,
        "duration": 3.8,
        "text": "comment there um it's you know as you"
      },
      {
        "start": 3556.52,
        "duration": 4.279,
        "text": "can tell it's actually really hard this"
      },
      {
        "start": 3558.24,
        "duration": 4.48,
        "text": "is hard one put a short explanation but"
      },
      {
        "start": 3560.799,
        "duration": 4.24,
        "text": "yeah I would say I would say it's almost"
      },
      {
        "start": 3562.72,
        "duration": 5.079,
        "text": "like um"
      },
      {
        "start": 3565.039,
        "duration": 5.401,
        "text": "having you know uh a your business"
      },
      {
        "start": 3567.799,
        "duration": 4.04,
        "text": "domain expert following you around right"
      },
      {
        "start": 3570.44,
        "duration": 2.76,
        "text": "um because the way I usually explain it"
      },
      {
        "start": 3571.839,
        "duration": 3.081,
        "text": "in terms of domains whether it's my"
      },
      {
        "start": 3573.2,
        "duration": 4.119,
        "text": "personal domain or my business domain"
      },
      {
        "start": 3574.92,
        "duration": 3.72,
        "text": "the llms just aren't trained on that"
      },
      {
        "start": 3577.319,
        "duration": 2.841,
        "text": "right so it's like you've got you've got"
      },
      {
        "start": 3578.64,
        "duration": 2.719,
        "text": "your little business domain expert who's"
      },
      {
        "start": 3580.16,
        "duration": 2.84,
        "text": "following you around and so when"
      },
      {
        "start": 3581.359,
        "duration": 3.561,
        "text": "somebody asks a question they can"
      },
      {
        "start": 3583.0,
        "duration": 3.119,
        "text": "immediately inject that context very"
      },
      {
        "start": 3584.92,
        "duration": 5.36,
        "text": "similar to what carer was saying"
      },
      {
        "start": 3586.119,
        "duration": 6.161,
        "text": "honestly um but uh that's that's my my"
      },
      {
        "start": 3590.28,
        "duration": 4.4,
        "text": "shot at it I don't"
      },
      {
        "start": 3592.28,
        "duration": 4.48,
        "text": "know Alex I'm not gonna put Alex on Alex"
      },
      {
        "start": 3594.68,
        "duration": 3.04,
        "text": "do you have like a piffy sort of like"
      },
      {
        "start": 3596.76,
        "duration": 4.64,
        "text": "fun"
      },
      {
        "start": 3597.72,
        "duration": 7.56,
        "text": "analogy I can't come up with anything"
      },
      {
        "start": 3601.4,
        "duration": 6.8,
        "text": "better don't want to disappoint"
      },
      {
        "start": 3605.28,
        "duration": 4.64,
        "text": "you no worries but but look look I guess"
      },
      {
        "start": 3608.2,
        "duration": 3.8,
        "text": "the other thing that I'll say um as and"
      },
      {
        "start": 3609.92,
        "duration": 3.159,
        "text": "as we kind of close this out like"
      },
      {
        "start": 3612.0,
        "duration": 3.2,
        "text": "actually it's not it's not really an"
      },
      {
        "start": 3613.079,
        "duration": 4.921,
        "text": "analogy I think it's like a fact like if"
      },
      {
        "start": 3615.2,
        "duration": 5.08,
        "text": "you are a full stack developer right and"
      },
      {
        "start": 3618.0,
        "duration": 5.64,
        "text": "you have been writing you know sequel"
      },
      {
        "start": 3620.28,
        "duration": 5.039,
        "text": "queries or like no SQL queries for the"
      },
      {
        "start": 3623.64,
        "duration": 3.919,
        "text": "better part of a several years or"
      },
      {
        "start": 3625.319,
        "duration": 4.48,
        "text": "several decades build full stack"
      },
      {
        "start": 3627.559,
        "duration": 4.681,
        "text": "applications like honestly that's all"
      },
      {
        "start": 3629.799,
        "duration": 5.121,
        "text": "this is right if you know how to build a"
      },
      {
        "start": 3632.24,
        "duration": 5.28,
        "text": "crud app where like you know the user"
      },
      {
        "start": 3634.92,
        "duration": 4.919,
        "text": "shows up to your app and it wants to you"
      },
      {
        "start": 3637.52,
        "duration": 4.44,
        "text": "know it wants to view the the the the"
      },
      {
        "start": 3639.839,
        "duration": 3.72,
        "text": "detailed description for some book"
      },
      {
        "start": 3641.96,
        "duration": 3.24,
        "text": "that's in like your book database and"
      },
      {
        "start": 3643.559,
        "duration": 3.321,
        "text": "like you know how to do the select query"
      },
      {
        "start": 3645.2,
        "duration": 3.359,
        "text": "or you know how to do the the nosql"
      },
      {
        "start": 3646.88,
        "duration": 3.6,
        "text": "query like if you know how to build crud"
      },
      {
        "start": 3648.559,
        "duration": 3.881,
        "text": "applications I just think that you'll"
      },
      {
        "start": 3650.48,
        "duration": 3.359,
        "text": "you'll be super comfortable with rag"
      },
      {
        "start": 3652.44,
        "duration": 3.679,
        "text": "right because that's what it is right"
      },
      {
        "start": 3653.839,
        "duration": 3.881,
        "text": "like rag is just sort of like the only"
      },
      {
        "start": 3656.119,
        "duration": 3.361,
        "text": "the nuanced difference is that like when"
      },
      {
        "start": 3657.72,
        "duration": 3.079,
        "text": "you build these cred applications"
      },
      {
        "start": 3659.48,
        "duration": 2.96,
        "text": "usually you have these like fixed"
      },
      {
        "start": 3660.799,
        "duration": 4.0,
        "text": "Properties or fixed columns and you're"
      },
      {
        "start": 3662.44,
        "duration": 4.32,
        "text": "kind of composing a SQL query with a"
      },
      {
        "start": 3664.799,
        "duration": 4.921,
        "text": "with a wear Clause right you know select"
      },
      {
        "start": 3666.76,
        "duration": 5.12,
        "text": "from books where ID equals x right so"
      },
      {
        "start": 3669.72,
        "duration": 4.119,
        "text": "that's that's what crud applications are"
      },
      {
        "start": 3671.88,
        "duration": 3.719,
        "text": "and really just rag applications are"
      },
      {
        "start": 3673.839,
        "duration": 3.881,
        "text": "like this really slight Nuance where"
      },
      {
        "start": 3675.599,
        "duration": 4.121,
        "text": "it's like you know hey like you know"
      },
      {
        "start": 3677.72,
        "duration": 4.68,
        "text": "like get all the documents like where"
      },
      {
        "start": 3679.72,
        "duration": 4.68,
        "text": "the question matches you know matches"
      },
      {
        "start": 3682.4,
        "duration": 3.6,
        "text": "the vector right but like conceptually"
      },
      {
        "start": 3684.4,
        "duration": 2.88,
        "text": "like that's really what you're doing um"
      },
      {
        "start": 3686.0,
        "duration": 3.319,
        "text": "um and then there's a little bit of"
      },
      {
        "start": 3687.28,
        "duration": 3.88,
        "text": "detail on the other end but I think if"
      },
      {
        "start": 3689.319,
        "duration": 3.48,
        "text": "you're a full stack application and"
      },
      {
        "start": 3691.16,
        "duration": 3.52,
        "text": "application developer and you're"
      },
      {
        "start": 3692.799,
        "duration": 3.8,
        "text": "comfortable with crud um I think you'll"
      },
      {
        "start": 3694.68,
        "duration": 3.32,
        "text": "be really comfortable with rag you'll"
      },
      {
        "start": 3696.599,
        "duration": 3.081,
        "text": "certainly be more comfortable with rag"
      },
      {
        "start": 3698.0,
        "duration": 2.92,
        "text": "than you would be with fine tuning or"
      },
      {
        "start": 3699.68,
        "duration": 3.24,
        "text": "some of the other techniques that"
      },
      {
        "start": 3700.92,
        "duration": 5.32,
        "text": "require like radically different like"
      },
      {
        "start": 3702.92,
        "duration": 5.679,
        "text": "domain expertise and knowledge okay well"
      },
      {
        "start": 3706.24,
        "duration": 4.039,
        "text": "think I have I have a concise one it's"
      },
      {
        "start": 3708.599,
        "duration": 4.321,
        "text": "having a natural conversation with your"
      },
      {
        "start": 3710.279,
        "duration": 4.401,
        "text": "data right like because everything you"
      },
      {
        "start": 3712.92,
        "duration": 4.439,
        "text": "were just talking about like for decades"
      },
      {
        "start": 3714.68,
        "duration": 5.08,
        "text": "we've had to you know learn how to write"
      },
      {
        "start": 3717.359,
        "duration": 3.48,
        "text": "SQL or do keywords or find all these"
      },
      {
        "start": 3719.76,
        "duration": 2.44,
        "text": "different ways we can get at the data"
      },
      {
        "start": 3720.839,
        "duration": 3.44,
        "text": "but now you can literally just have a"
      },
      {
        "start": 3722.2,
        "duration": 4.839,
        "text": "natural conversation with your data"
      },
      {
        "start": 3724.279,
        "duration": 4.441,
        "text": "that's my that's that's my take now"
      },
      {
        "start": 3727.039,
        "duration": 3.52,
        "text": "aesome and that's and that's a perfect"
      },
      {
        "start": 3728.72,
        "duration": 3.399,
        "text": "way to end it um so we're a couple"
      },
      {
        "start": 3730.559,
        "duration": 3.321,
        "text": "minutes over but thanks for sticking"
      },
      {
        "start": 3732.119,
        "duration": 2.92,
        "text": "around everybody this is super fun um"
      },
      {
        "start": 3733.88,
        "duration": 3.919,
        "text": "we're gonna do a lot more of these"
      },
      {
        "start": 3735.039,
        "duration": 4.361,
        "text": "things um it's a thanks for all the"
      },
      {
        "start": 3737.799,
        "duration": 3.161,
        "text": "awesome questions thank you so much to"
      },
      {
        "start": 3739.4,
        "duration": 3.919,
        "text": "David and thank you so much to Alex for"
      },
      {
        "start": 3740.96,
        "duration": 4.04,
        "text": "joining us once again this is all being"
      },
      {
        "start": 3743.319,
        "duration": 4.0,
        "text": "recorded uh you can we're going to post"
      },
      {
        "start": 3745.0,
        "duration": 3.88,
        "text": "it it'll be online available immediately"
      },
      {
        "start": 3747.319,
        "duration": 4.321,
        "text": "after this is over you can share it with"
      },
      {
        "start": 3748.88,
        "duration": 4.479,
        "text": "your friends and colleagues uh and uh"
      },
      {
        "start": 3751.64,
        "duration": 3.439,
        "text": "yeah and we'll uh we'll hopefully we'll"
      },
      {
        "start": 3753.359,
        "duration": 4.401,
        "text": "we'll see you all soon for uh for our"
      },
      {
        "start": 3755.079,
        "duration": 4.76,
        "text": "next stream uh so until then H take care"
      },
      {
        "start": 3757.76,
        "duration": 4.24,
        "text": "everybody see you later thank youall see"
      },
      {
        "start": 3759.839,
        "duration": 2.161,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-11T21:41:18.514203+00:00"
}