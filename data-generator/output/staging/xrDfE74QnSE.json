{
  "video_id": "xrDfE74QnSE",
  "title": "2/3 Apache Cassandra‚Ñ¢ Data Modeling workshop",
  "description": "Please find below links that could be useful to you during the session (expand)üëá\n\nüí¨ DISCORD - chat, questions\nhttps://discord.gg/UEBDeBq\n\n‚ùìMentimeter  - quiz, games\nGo to menti.com and enter code: [coming soon]\n\nüìö GITHUB  - materials\n[coming soon]\n\nüõ¢Ô∏è ASTRA  - database\nhttps://astra.dev/yt-7-27\n\nüéì HOMEWORKS - badges\n[coming soon]\n\nüë®‚ÄçüöÄ GET IN TOUCH WITH THE SPEAKERS\nCedrick =  http://dtsx.io/cedrick\n\nüìÖ UPCOMING EVENTS\nhttps://www.datastax.com/workshops\n\nüöÄ üöÄ ENJOY !! üöÄ üöÄ",
  "published_at": "2022-07-27T17:25:41Z",
  "thumbnail": "https://i.ytimg.com/vi/xrDfE74QnSE/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "workshop",
    "data_modeling",
    "cassandra",
    "database",
    "apache_cassandra",
    "astra",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=xrDfE74QnSE",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "foreign [Music] foreign [Music] [Music] foreign [Music] foreign can you hear us yeah aha I see people joining that is amazing so uh that's uh Alex voluschniff and artemis.com developer Advocates at data stacks and sound is good amazing yeah Katie I made some homework as you see I hope you did it too so let's move on um so I'm Alex with data Stacks my job here is not let developers make mistakes and fail with Apache Cassandra and distributed systems in general and that's uh arctometer could you introduce yourself yes so I'm developer Advocate my interest is main interest in data modeling data quality but I also love data warehousing work with SQL databases as well but over my career I've been working with pretty much every major a type of database relational XML rdf graph no SQL different type of types of nosql and so on and I'm happy to join this Workshop to talk about data modeling for Apache Cassandra there will be very cool demo later hope you will like it yep uh you know uh we data Stacks developers will know whom to invite for each workshop and artem is the person who developed a data modeling methodology for Apache Cassandra so here on all of the world he is exactly the right guy to talk about that um good today we will use GitHub repository as well last time you've seen that we will do some practice scenarios with Astra and for data modeling we will use a special tool developer to make your life easier before we proceed and to let everyone jump in please jump in on mint here and answer our questions first question will be to understand your experience how much SQL experience do you have with relational databases if you attended our last Workshop you already know what to do just go to mentee.com and use the code 14095206 and oh it's not mind but momentum link is on the screen menchie.com and code is on the screen too I see we have some experts which is good okay more people joining let's jump to the next question how much no SQL experience do you have okay a little bit that's a good place for you to be no SQL a lot good no private experience also nice so don't forget nosql is very different so your knowledge of will not help you with Cassandra and your knowledge of Cassandra will not help you with neo4j those are different tools for different uh use cases and today you are going to improve your knowledge of one of the most powerful and most scalable of the nosql databases good then let me check are you into the topic already no SQL databases are schema-less correct I love asking this question no okay will anyone answer yes yes okay someone okay looks like someone missed our first Workshop not all nosql databases are schema less there are plenty of schema full nosql databases so the correct answer is no and I see most of you know that already isn't that amazing we have some people of experience here today what about normalization and denormalization do you know what is that do you know when to use it do you use it all the time okay some people understanding that or at least basic understanding very well if you don't have don't worry we will briefly explain it to you today because normalization and denormalization are very important techniques to um learn to master if you want to be good engineer if you want your applications to be quick and efficient and your customers to be happy you totally need to know and understand both techniques we will taught what denormalization is bad and that's why I have to ask you what about uh generalization is it an absolute evil or there are scenarios where it can be good skip question is totally fine because we will explain uh the normalization foundations today so take a look at Tom we work with pretty experienced audience today because on most of our workshops then I ask this question what people answer no denormalization is an evil the normalization is bad there denormalization can be good absolutely as long as you control it don't let the normalization control you you know that's so you are the engineer you have to stay in control there are certain things we will talk about the normalization that's certainly useful but you need to be aware of of the drawbacks as well good data duplication yes so all the latecomers have joined judging by the uh stream viewers so we can proceed but again thank you everyone for joining that mattress a tone to us today we will speak about uh data storage organization and distribution in Cassandra because that's what something makes Cassandra so special very performant but also with some sharp edges you need to know not to hurt yourself then we will speak about keys and how keys are so important how Keys defined so much we will speak about SQL data types not on big details but we want this Workshop to be two hours not two days okay then there is a lot of attention to data modeling process because it's the most important part of the day optimization techniques and basically what's next homework and so on and so forth and we will start with a data storage overview so data distribution we discussed it briefly last week but I see some people still not completely getting into that and how important it is and may also maybe there are some newcomers today Cassandra keeps data distributed it means what the same pieces of the same table will be spread to over multiple servers servers keeping your information are organized into so-called Rings or you can also call it just a data center and those data centers combine it together will build a cluster and this cluster can be geographically distributed with all nodes active there are no idea like a slave node or a secondary node for Royal node each node can process each request globally there is no single point of failure it scale it scales perfectly for right applications and for read applications and your app can contact any node switch to next node work with next next again switch to next data center if required it's totally possible and that what makes Cassandra globally available and highly available data and Cassandra is organized as stables and those tables have strict schema there's still no SQL but those Stables are distributed tables so data of these tables are spread across the cluster across your data centers and there is no single node what which called all of your data Cassandra is ready to work with data of any size and that means petabytes literally petabytes and petabytes ladies and gentlemen that's a lot so how it works quick reminder then you arrange a partition key we will discuss it in details today then data arrives on a node or basically even earlier actually when your driver starts vibration Cassandra driver in your application starts some operation to write or to read it will get a partition key and hash it to a token from string or from whatever value into an integer value using some special hashing algorithm and get a token per table each node owns a range of tokens numbers you see on the screen 0 to 16 17 to 32 and so on you actually uh yes those tokens are like those numbers but much much longer of course because like it could be billions of partitions and then deity is not only partitioned but also replicated as my as many times as you define in replication Factor so you see this data on the left left bottom bottom part are exactly the same rows exactly the same partitions but they are stored on the multiple servers because you want your customers want your application to be always available and that's what Cassandra does data organization we briefly discussed already so data organization organized a cell included in the row in the partition in the table in the key space key space is a logical group of tables and some other settings user definer types grouping at all logically tables organized into rows and columns and groups of related rows call it partitions what are store it together and that is a very important feature for both good and bad for restrictions and for power each row contains a partition key you cannot store data without petrifying a partition key it's technically not possible cluster will just not know where to put your data starting working with Cassandra first thing you have to do is to create a key space how do you create a key space very easy there here you see SQL statement Cassandra query language statement what creates key space and a Cassandra query language is designed specifically to be as close to SQL as possible to be just more familiar to every developer in the world when you create a key space you have to specify its name quite obvious but uh that's typical for any database but also you have to explain replication you have to tell cluster how do you want it to handle this data you have to define a replication strategy class and you have to Define replication Factor so replication strategy class is a very basically you have two options networked apology strategy and simple strategy so not a lot of shirts simple strategy is good for your laptop and bad for anything else you use Simple topology strategy simple strategy for your laptop for development environment maybe for test uh scenarios maybe some for develop yeah for development environment maybe is for some kind of development servers but you definitely don't go to production with simple strategy with simple strategy Network topology strategy is a vice versa for production placements and for uh your staging maybe environment because it's a very cool Advanced strategy it does really a lot of work for you take a look on the lines uh for the data centers here you see your United States West one Europe Central One those are data centers names of your data centers for different companies you will have different data centers names right and you say what for United States West one I want to have replication Factor free for the Europe Central one I want to have replication Factor 5 for whatever reason and he comes Network topology strategy what it does it takes your um replication Factor Define it and puts the data in the way what it will be located within single data center but on the multiple different server racks or if you use clouds so it will be the same region for example United States West one but different availability zones you understand why it's happening again your customers want your application to be available always when we use networked apology strategym it's a very Advanced thing what key what takes care of keeping your replicas not together but as far from which hour as possible within one data center or region why it matters the story is availability zone of a cloudflower provider can get down if all of your replicas were Within These um availability Zone what will happen your data will be unavailable same happens with your data center on the in the data center you have multiple server racks but servers within single server Rec are also vulnerable to the same issues for example if power outage for a single server Rack or network outage the wall server rack will become unavailable so you need to have your replicas on the different server racks or on the different availability zones of the cloud and that is a very important and network topology does it for you absolutely transparently so you don't have to take care of that isn't that amazing uh then very uh common misconception what I see very often is what people start to do weird things with Fair replication they try to Define all the data centers they have uh in the list of these replication story but that's not exactly right take a look I can have a dozen of data centers all across the world Europe Central One Europe Central to Europe East three uh whatever I don't know Asia and so on you don't have to specify all of them here here you specify only data centers what you want to take care of this data for this case space it will be United States and Europe for another key space for example I don't want to keep data anywhere I need it only on your in a Europa Central one so I don't specify Us West and I have only data replicated to a single Data Center well it decreases availability of the data because availability will be then available to only one single Data Center so you may have to consider different scenarios for different kinds of data you are working with that must be quite obvious when we create a table we have to specify key space we are going to use a table name also quite of this um columns with pair types and we have to Define primary gamer or key which consists of a network of partition key and clustering columns those are extremely important so we will speak a lot about it today that's a much more advanced thing and very much more important thing than you use it to think in relational databases and here we go atom let's create as a let's create database we will work with maybe you have it done already yes so we will create a new database in the srdb if you already have created the database previously then you may need to create a new key space or maybe you already have it from the are you sharing your screen sorry are you sharing your screen uh yes um yeah because I see the slides but we will need your screen I guess okay so yeah to start yes to start you will have to um uh go to the link that is on GitHub you can see it in the chat so it's uh a link that will bring you to this web page readme file and here we will be creating new asterdb instance or using the previous one so this is uh sorry it didn't work as expected okay so we're going to create a new assadb instance what is srdb it's it's a cloud service Cloud database service that is built based on Apache Cassandra um you can click the create s3dp and you will have a screen where you will be able to either sign up or sign in I'm already signed in into mine account and I have uh some other hibernated database here but I will create a new one following the instructions so I will click create serverless database and we'll create database called workshops and the keyspace name that we want to use and you already know what key space is Alex talked about it just recently so it's going to be sensor underscore data okay we also need to select the provider and region we are going to use Google cloud and in my case it's going to be North America and I need to select one of the regions that is not logged I'm also using free account just like you so in this case this is South Carolina and I can click create database and it will take a couple of minutes to get created so we will be able to use it later for the next Lab but at this point it's finishing up okay well it says it's uh the the status is still pending so we will wait and while we wait in uh we can continue with the next topic okay so the next topic I will talk about uh key definitions and and and you've already seen some of those things but we will still repeat what is primary key what is partition key what is clustering key because this is essentially very very important and essential for for schema design right and schema design is part of the data modeling process so this table in this example um that you that you may seen already in in the last Workshop we have uh primary key definition here that consists of partition key and clustering key so the the role of the partition key is to uniquely identify a partition within a table but also as you know already that partition key is responsible for it for for data distribution strategy so it defines which nodes and replicas will get that particular partition we'll store it and we'll serve it we'll retrieve it send it back to the application okay so how you Define partition key will be will Define not only uniqueness of the partition but also how the data will be distributed and that's that's very important so in this example uh where we have sensor as a partition key and timestamp as a clustering column okay in in in this case uh the the sensor ID itself will Define the the partition and um in other words all data that generated by that sensor will be stored in that one partition but we if you look at the last example where we have sensor and timestamp together this is composite partition key then in this case science sensor and timestamp will always be unique each sensor generates only one Baler for a given timestamp then each partition will essentially contain just one single row okay while in the in the first example we have a multi-row partitions here we have a single row partition for the example where I have we have both sensor and timestamp as a partition key now besides the partition key primary key consists of optional clustering key or sometimes we just say clustering columns and the purpose of clustering columns so if you have clustering columns a clustering key then your partition can have multiple rows so it's a multi row partition and clustering key uniquely identifies a row within a partition so that's one purpose to ensure uniqueness within of that row within the partition but the second purpose is also sort in order so as you know tables are stored as as as a stables internally so they assorted strings how they assorted they assorted based on on clustering columns so it's clustering columns will Define uh the physical ordering on disk and when you retrieve the data when you retrieve that partition you will be able to get that order that you specified or you can reverse it so if you need your data sorted you need to use you need to think about classing columns how you use them and whether they will be what kind of cluster in order you will use whether it's descending or ascending I I want to step sorry I want to step in here for a moment regarding sorting um sure yep uh so the story is when coming from relational databases you use it to be able to sort data by any field you use it to be able to filter data by any field and you take it as given which is not always correct so we work with the data of a very different sizes usually we work with a data distributed over hundreds of servers over multiple continents and the long story short sorting in sorting data of this size over multiple servers over multiple continents is totally not easy but still Cassandra can return your data sorted extremely quickly how it happens that is a part of our course at the academy.datastags.com it's a free course so it's not really an advertising for it but yes it is despite its free it's also very important for you to get this one to get real understanding and get ready for the certification for Apache Cassandra which data Stacks sponsors so Vivas you can get certified in Apache Cassandra totally for free now getting to the Sorting part clustering columns are very important because they Define this sorting and on the way how data will be stored on right time so when you are going to retrieve this data on read time it will be sorted already and there will be no need for Cassandra to change anything as it sorted already just return this data back and we are done so good thing it's even for sorting extremely quickly bad thing you can sort data as you will see soon only based on the clustering columns you cannot sort in this case in this example you cannot sort data by value without using some nasty hacks we recommend you not to use right and it's important to remember that sorting is defined within a partition not within the whole table so if you're going to retrieve more than one partition then the Sorting order is going to break so but if you return one partition and you have clustering key there and clustering order Define then you will get the the rows in that partition within that partition sorted so in this example of course every time we design primary key we're thinking about how we going to access data are we going to create it and design our table and primary key base on uh based on that query so in this example if we say that sensor is the partition key there is no question key and we try to store temperature Baler some kind of Valor that that sensor gen generates then each time we will add that we will write into that table for that sensor we will basically absurd the previous failure because uh the the there is no class and key nothing to distinguish the rows are not unique so each each time so it's basically a table with singular operations for each sensor there is only one partition with one row there so this is not going to be a good design if you try to store values if we try to store if you also uh um for example our query would be store all the values generated by um or retrieve all the Bell is generated by a sensor and filter the based on dates for example specify the date range how you want to retrieve that data so in this case if we add timestamp to this primary key as a clustering column then we kind of solving the problem of uniqueness because now each time each sensor can only generate better with with a unique timestamp and then the next failure will have a different time stamp so in this case we guarantee that we will not have absurds but we it's it's a little bit harder to retrieve that data based on date it's still possible but you can replace date with timestamps but it may not be the the 100 easiest solution now the third example here is not good because we also add in value into this clustering column so you can think so the failure so all the data are generated by this by each by by a sensor will be sorted based on failure first and only then based on time steps so we will not be able to uh uniqueness is there but we will not be able to filter based on dates correctly and then the last one is probably the best example for uh the uh this particular query uh we are going to retrieve data for a particular sensor do the range search on dates and and timestamp is there to guarantee uniqueness okay so uh together the primary key consists of of mandatory partition key and optional clustering key but together primary key gives you uniqueness overall within a table right remember partition Keys is the unique identifies partition within a table a clustering key uniquely advice row visit table and a row within a partition a primary key you need a device row within a table okay so partition Keys like we already talked about they they Define uh data distribution of a cluster that's important to remember uh so it's it's you need so you will need when you design primary key you need to design it for specific uh query so to for example support retrieving data based on sensor ID and date but they also need to think about the how that data will be partitioned based on that specific partition key and clusting columns like we said they Define sorted how the data is sorted on disk literally physically so you can retrieve in that order or you can reserve uh you can reverse that order so um for this example where we have primary key that consists of partition kit sensor and date and clustering key timestamp what kind what types of fees we can we can do over this table we can we cannot for example retrieve data for one particular sensor because we cannot query based on partial partition key so we will have to specify both sensor and date we cannot same we cannot do the sensor greater than something we cannot use partial partition key subset of partition key we cannot ever use inequality like greater than on a partition key column so that's not going to work either even here we're using sensor and data together inequality is not going to work so types of periods of predicated we can Define here for this specific primary key we can we will have to specify sensor and date and we we can also specify time State timestamp using either equality or inequality search okay so the the one of the consequences of defining your primary key the way you define it besides the distribution data distribution and sorting will be cql queries what types of queries you can deal okay another consequence is schema immutability once you define your primary key you cannot change it you cannot just alter that key you can add some other columns that will not be part of the primary key but the primary key is something that you do not want you you cannot change and there is a again a good reason for that we're dealing with with large data set um that is spread over multiple nodes uh across many nodes in in your cluster and and possibly multiple data centers that communicate uh over Network and they may be in different parts of the world so in that case if you if if you change the the primary key then you will basically have to redistribute your data right basically changing redistribute and and sort it differently possibly so that's not a good uh thing to do when you're dealing with large data sets so if if you do find yourself needing to change something in primary key you will have to drop the table or you will have to create a new table first with new primary key transfer the data and then drop the all table but usually you want to design your table right correctly right away now a question that we frequently get is why don't we use sequential IDs in Cassandra something like Auto increment and again this is this is actually not a Cassandra thing this is a any distributed system saying that it's not easy to maintain that sequence to because you have multiple nodes in your cluster each one can generate a new ID and and if if you want the sequence then all of those nodes have to communicate to agree on um on the next available ID to use for when I when you insert in the row so in MySQL for example you can use Auto increment which is sometimes convenient it's it's artificial surrogate ID which just generates a sequence of numbers but in case of Cassandra and and most distributed systems we're using uuids and time viewing these so those are two different types of uids and essentially each any node can generate that uid or your application can generate that uad very quickly efficiently and and guaranteed that there will be no uh conflict between uh those different ideas generated by different nodes Okay so and the next topic the the rules for good partitioning I don't know if Alex wants to yep I would love to it's one of my favorite topics you know so give me a moment to switch back to myself boom [Music] yes we are good uh so uh first of all I had to ask are you guys listening as well because I see in the YouTube chat some people are mentioning mentioning buffering I don't know on which side it is because YouTube shows me a excellent stream status excellent all green all positive streaming software shows me some minor issues so if you can hear us oh yeah it's bearable thank you Sumit uh so let's proceed then good so um three uh very important rules of a good partition just free so it's easy to learn them all but very important to follow um we will work on this example which is familiar to you already we will work with a table of a data temperatures by sensor table definition is quite simple we store sensor day timestamp value that's it so text date timestamp flawed solve it but working with Cassandra you should not forget what author were wide part of the table amount of columns may be low amount of data in this parallelists in this table can be extremely big like very very long so let's take a look at few things uh store together what you retrieve together avoid big partitions avoid Port partitions only three things you have to remember but you have to remember it very very well Let's Take on the example when their do not store together what you retrieve together for example we make a partition key you see in this case both sensor and timestamp will be parts of a partition key for this table what will happen then we will have as much partitions as much records we will have because sensor ID which is always the same per sensor and timestamp which is always new per record uh timestamp will be changing all the time they will be hashed together and as a result you will have cash always new and you will have as much partitions as much records you have is that bad by itself it's not bad in Cassandra you can have as much partitions as you would like to not a problem what is the real problem then real problem is on the retrieval time to get all of the data for last week for example you want to see a temperature of a sensor X for the last week sounds like a reasonable query right but what will happen on the execution time then you execute this query don't forget querying data we have to give all the parts of the partition key that means what to retrieve data we have to specify sensor ID which we know mostly probably and timestamps of all the records first of all we don't know them but even if we know them somehow magically then as there's a different partitions they can be stored on different servers and therefore we will have to reach as much servers as much server stores your data and that is as stupid as it sounds exactly but there is a second example which is much better still have some problems to be discussed on the next slides but already much better sensor as a partition key and timestamp as a clustering column what it gives to us first of all data is grouped by sensor that is good because if I want to see data for sensor X on July 6th I have to specify uh sensor ID which I know and then as timestamp as a clustering column I can use inequality predicates I can say like before 6th of June like after 5th of July uh before 7th month of July which will be my perfect single July for example on the partition keys on the previous example I cannot use inequalities so I cannot make a range bigger than lesser than if we go with a primary key like this so this one simply will not work in this case we have data grouped by sensor and order it by timestamp so boom it's now solved and that helps me to keep my data together and retrieve that together because it's always stored on the same server we discussed that we rush thank you for a good question we discussed it soon then second question avoid big partitions first of all uh don't forget what why do we do partition after all why partition data we partition date because sharding is very painful and hard and we don't we want to avoid sharding so we work with the data of a big size and we split this data into chunks partitions so they always will be handleable but then you do two big partition partition grow grow grow what happens next boom you have the same problem like you are tried to dodge just before it's your partition to Big not too wall table but the consequences are exactly the same your database will be slow it will be hard to impossible to maintain it and so on and so forth so we really have to think of how much data you will have per partition there are only one hard limit you cannot have more than 2 billion cells per partition so intersection intersections of columns to rows but this is the only hard partition our hard limit our recommendation soft limit is not to have more than 100 000 rows in a partition or a partition to be a size of more than 100 megabytes ah now how do we control it with our partition Keys partition key can be composite or compound and that means what we can include multiple different columns in the partition key you need to keep it under control because don't forget on the verra2 kinds of two ways we access data when we write and when we read when we write data we can put two partition key basically whatever we prefer whatever we know about this piece of data will it work it will work we will have small partitions but then on the read time what will happen we will again have to give all of everything what we put into a partition key and there's no going to be a lot of fun so we need to keep our partition small but not too small otherwise we will have problems reading it um let's take a look at the first example sensor as a partition key timestamp as a clustering column and you may be now like what why wait Alex you just told us previous slide what that is a solution that is the right approach like you remember previous slide store together what you retrieve together you group data by sensor sort by timestamp and you are good is that right approach uh there is a checkbox but it's gray not green because it is the right approach but you can have different scenarios and that's not always the right answer take a look if you have your data written once in a day once in a week once in a month then this approach can perfectly work grouping by sensor partitioning by sensor because you have your data once in a week then therefore in a couple of years you will have like 100 and something records in six years you will have 600 records per partition it's totally fine but imagine you have your record storing every 10 seconds 5 Seconds every second that's also happening in iot World totally what will you do then your partitions will grow over time so then you store all the data for a sensor uh restoring it every second and your sensor runs for years what will happen with this partition over time nothing good will happen with this partition Cassandra has some tools to discard old data so-called TTL time to leave so creating a record you can specify I want this record to be automatically deleted after one month but what if you want your data to be available after years for example you have strict audit audit requirements from government or whatever so you have to store data for a long period you cannot delete it with time to leave uh property but uh we still have to handle it somehow very easy we make these compound partition key which stores sensor and also some value depending on the period you want to store data in a group it can be our if you have really a lot of Rights per sensor per second it can be they it can be weak it can be month it can be here it depends on the amount of writings per this period of time in this case for example I want to group them by month remember bigger the partition easier to read but it will cost you a lot of partition becomes too big so don't make partitions too small it will strike back on the read time keep them reasonably small and we recommend to stick to 100 000 values in Partition up to 100 megabytes in Partition in this particular case I don't care about the size because the data we are working with is text date timestamp float so each row will have really small footprint but in general the amount of rows can definitely become problem um yeah so bucketing is usually it's called when you use a totally artificial key for grouping in this case month like for example that is a July of year 2022 this month value can be strict string can be integer doesn't matter will be uh two zero two two zero seven year 2022 a seven month a month uh seventh month um and that's not totally artificial Bitcoin because it comes from timestamp uh but it's also not like we usually speak about bucketing okay and finally avoid what part partitions that I have to give credits uh a totally great example introduced by uh Cedric lunvin and Cedric thank you it much better when it was before really uh primary key date sensor timestamp in this case as you see we use as a partition key word date and that brings to interesting consequence it's very easy to get information for each sensor for this particular date today is 27th of July so I want to see data of all the sensors for 27th on July with a table partition it like that I can do it with a single query reaching single server so read time can be extremely efficient right but take a look what's going to happen you know what Cassandra scales very well I told you and there was a little Mark like it depends on your data model last week maybe you remember that now take a look you have 100 servers you store a lot of data and you have a table like that over time if this model doesn't work very well your servers are overloaded there are too much of Rights and you think hey Cassandra scale so good for rights I will simply go and add more servers I have money I can afford it I will make this 200 servers I will go and buy 100 more servers what's happening then now you have 200 servers did it help nope nope nope it didn't help you can buy 1000 it will not help why because data is written to servers responsible for this partition with replication Factor free you will have free servers responsible for this partition in this database we have a huge amount of rights that will be basically one single partition active all the time there will be no partition the partitions will be more or less even so partition for today partition for yesterday we will be overall of more or less the same size but workload will be different servers responsible for yesterday partition will be idling and servers responsible for today partition will burn in hell uh just because your data model was not good enough so think about it don't be rude to your servers take care or take care of them like they are good they deserve some good attention I tell you as an operations guide now uh take a look for the second example which is significantly better if for you it's important to group data by date to be able to see all of the data with one single first query then these design totally makes sense you group data by date and sensor so therefore partition you will have different partitions per date per sensor and it will be never too hot because at a big amount of partitions will be distributed over your all of your servers and in this case if your cluster is overloaded you can buy in your servers bring them to the cluster what will happen token ranges will change each server will be responsible for less amount of partitions and you have a smaller workload per each of them so here scaling of Cassandra comes but scaling of Cassandra is a shared responsibility it's not only Cassandra does it but you have to think about it in advance designing your data model and our Tom we are done with this uh page if you want to add something that's fine there are a couple of good questions uh okay one question and both of them I think from viraj and the first question uh for the use case for the example when we use um sensor and mons as a partition key um he asked so for the current months that partition will be hot versus for the previous months those parties nobody is gonna use those partitions yeah I believe I answered it in the end uh the story is not yeah our story is not to have our Lord partitions uh as long as your partitions are small you can scale you have high Lord you add more servers your data being shuffled to them and yes workload on the server everything is good the big problem for uh the big problem much bigger problem is then you have an even size or uneven workload on the partitions when all other partitions are idling in one partition is too hot for a single server uh to handle don't forget partition is a base unit of access it's something what you can pick up and put to a different place as long as your server can pick up single partition and put it to a different place you are good then it's uh when it has multiple heavy partitions you can put it to different servers but when you have one huge or one which is being overwritten all the time with like billions of requests per second then obviously there is no server to handle that you want to add something yeah I think the the there could be I don't know if it's uh maybe something that that is not obvious so yes for the current months there will be more access to those partitions but um months is not the only column in the partition key the sensor ID is is also there so it's not like uh okay for January all the partitions will be on this node uh because the sensor will also change the partition key so for the the the partitions for January will be distributed across all the nodes in the cluster because the sensor IDs will be random and things like that so so there should be no problem with uh having uh loads uh very high on one specific note or a few of the nodes if of course you you um using uh the the sensor IDs are more or less randomized and and there is no subset of sensors that are getting generating more data than others and things like that and there was another question uh about the case when we have something like users who are uh following other users or they they social media other users social media yeah so and in that case if you have a celebrity there are so many people following so you will have millions of people millions of roles for that person uh for their celebrity and and followers of That Celebrity and uh this question is actually um so great because it gives us uh the next Lab that we are going to do right now lab two uh is going to talk about Dynamic marketing specifically for this for this use case um and we're gonna talk about uh sensors but you can imagine and send instead of sensors by Network it's the same thing would be followers by user something like that so um let me so we are switching to oops wait a second yes so it's a second lab on GitHub let me switch it on your screen wait a moment yes please yep okay on GitHub we have number eight here in the our readme file is dynamic bucket then so what is dynamic marketing so let's look based on the this example we have a table that supports uh query find all sensors in a specified Network so given the network so we are going to group all the sensors over over a given Network so we will have to use network ID or network name as as a partition key and sensor ID will be clustering column so this table only has two columns both of them part part of the primary key for Simplicity but what it means for the network partition we will store all that sensors and it's like we'll saw all the all the followers of of a user right in this case some networks may have just a few sensors or dozens of sensors so the the partition for that for those networks will have dozens of rows uh which is not a big deal but maybe some sensors maybe within a city region or something they may have uh thousands or even Millions and tens of millions of Those sensors so we do not want the partition to have millions of of the sensor stored uh so and so the the key attributes of the problem that we are trying to solve is that the number of rows in the partition can can be dramatically different so in one case we can we can store everything in one partition in enough for another Network we'll have to create 10 partitions but for the third network we may have to create 100 partitions so it's going to happen dynamically and maybe we keep adding more sensors to the network or maybe our sensors are actually mobile and my cell phone is a sensor so once I move to a different location I'm joining different network so the the there is Dynamics there so we will store so that we will use Dynamic bucketing and we'll store our sensors inside of buckets and buckets it's essentially artificial surrogate partition and we will assign those buckets to each Network so one some Network may have only one bucket another Network may have two buckets 10 buckets another one may have hundred buckets so we will need two tables for that and I'm gonna explain you how it works first and then you can go to astrodb and work and basically try this example there the first table is going to manage Pockets so for each Network we will have a list of buckets and so network will be partition key bucket will be clustering column what's important to notice here is that bucket is time uad that this is important because so you you already gives us easy way to assign unique IDs but time ID also allows us to sort those Pockets based on time component of the uuid so why is it useful is because when you when you want to add new sensor into a bucket you want to retrieve the latest packet the packet with the the highest timestamp and and that will that sorting order will allow you just to retrieve one bucket for that Network just the latest bucket so limit one we will see how it's done and it's very convenient so time uad is better than uad in this case and then the other table is going to store sensors in those buckets and you can see network is not even mentioned so there is a networked Network set buckets buckets have sensors right very simple design pocket is prediction key sensor is um clustering key okay and at this point let me actually go to Astrid B and new and stay logged in I'm on time so uh we created here the our database which is Workshop database it has key space sensor data so I will use cql console and we'll say use sensor data so I will select my key space that I want to use for this lab and I will copy the this definition of two tables and we insert in some sample data we insert in a forest network has two buckets one starts with four another with with seven and for each of the bucket we will insert some sensors so there are two sensors in the first bucket and One sensor in the second bucket so they the IDS here are just regular strings um easier to read okay so let's create these tables insert some data so now what we want to know how to use these two tables now and specifically we want to be able to add a new sensor to a network what happens in that case to add a new sensor we need to First decide which packet to use okay which bucket to add maybe there is only one bucket but maybe there are multiple so we will first select the latest bucket the bucket which was created the most most recently how do we do that we simply select the bucket from buckets by Network where networks equals firstnet limit one remember our a bucket ID is Tiny UAV and it's clustering key and it's clustering order bucket descendant so it's ordered based on the uh time component of the time uad so we will get the latest one by just retrieving one row from that table okay let me do that okay so this is our latest bucket and we can actually verify that that it has its time component is um higher timestamp is higher than the previous one we don't need to do that however so then what's the next thing we want to find out whether this bucket is full or not so we will count how many rows how many sensors we already have in that bucket which is very simple create it again so we only have one sensor that's a second bucket the first one we have two sensors the second one we have one sensor so at this point your application logic will decide whether this bucket is full and we need to create a new bucket with new to generate new time uad and and insert into new bucket or if it still can hold additional sensors in this case it can be simply insert into that bucket the sorry this this one we simply insert into that uh bucket the new sensor with IDs 1004. okay so quite straightforward now we added new sensor how about we retrieve remember the the query that we needed to support is to get all the sensors for a given Network but we again need to First retrieve all the buckets for the given Network and then retrieve the sensors so this is we retrieving all the buckets get all the um bucket IDs from bucket by Network for specific Network okay and we have only two buckets you can notice the ID 7449 and this is done in within your application so the next step we will trip sensors from both of those buckets so where bucket in 7449 and we will be able to get all four sensors in our result so to finish this lab what I want to say the the dynamic back bucketing is extremely powerful mechanism that you can solve all kinds of uh problems with big partitions and and thought partitions dynamically but of course if you introduce new buckets they correspond to partitions and your access pattern changes you have to create multiple buckets or multiple partitions like in this example where we use in bucket in we basically accessing two partitions we in two partitions is slower than creating one partition right unless we are split in very large partition in into two partitions right in that case it's it's better to create two partitions because you basically your workload distributes better right you using more nodes to access that large partition okay do you have any questions um uh looks like I don't um no I don't nope we are good we are good okay so in this case we can continue and Alex the next part is still your part right yes uh as far as I remember so uh the only thing I wanted to add is I see in them and the slides uh oh sorry in the slides I see on YouTube the question about like if we have really a lot of access to a single piece of data I would cache something maybe with a caching layer um radius or something on top of Cassandra um so I'm not saying you not to use uh a cache HTTP cache or whatever cash I remind you what cash also introduces complexity so you have to be careful with cash how you are going to invalidate that if you have a distributed application then how exactly your cache do you go for distributed cash invalidated cash and validation becomes much harder so uh with cash cash is a powerful technique but it also comes with some costs now regarding a lot of reads as long as it's not billions of free to a single partition uh it should be totally fine so Cassandra that is not afraid of a lot of reads as long as you can evenly distribute workload over multiple servers if you have a lot of these celebrities therefore you have them spread it over multiple servers and you are good so let's move on uh data types so first of all Cassandra features all the kind of the types you use it to have in different uh databases whatever integer whatever Boolean whatever string small int text and so on and so forth blob so very typical set of different data types you use it to have there are some unusual like time uuid but archon I believe you discussed the time you already right yes indeed we talked about time UD and uid yes yeah good uh so uh Varin varchar so all the types like that that shouldn't be a big surprise to you so I don't want to spend too much time on it uh there are some more types what uh totally what can be interesting for some of the data if you uh you may if you store some complex data types you may be interested in collections so set list map uh Aviv map you can Define uh internal Types on your own it can be text text in text text int and so on so collection types must be pretty self-explanatory you have this kind of data in any kind of a programming language shouldn't be new to um you user defined types of course a user defined type is an interesting thing for a key space you can create type of your own type it's like a class in object oriented programming for example address or bank account or whatever type is interesting to you and Define types there and it will be your user definer type so you could use you could work with that in the way you need and for example you can even Store Plain Json uh as a UDT and it will be uh it will be stored as a user-defined type as long as it exists also you could have some custom types but that's in general uh pretty Advanced strategy and very often not recommended it was maybe a thing for Cassandra of older versions but now all kind of required types um exist already so there is no need to make some more advanced things and like words are cheap practices golden uh you will proceed with working with data types step right atom so the the data types will be more homework this is part okay if you might It's homework get a badge yes foreign you've seen the explanations already uh please do it don't ignore do it and uh then next one is going to be data modeling practice process and I uh hereby give me microphone to the deer archon okay let me switch my screen yes it's your screen gnome okay Okay so data modeling process and here we started our main TVs normalization versus denormalization and we said the immunization is not always good also in relational world people think about it as Evil saying because it brings anomalies right you you create multiple you duplicate your data in multiple places in multiple tables and then you have to remember to update those multiple places to keep those duplicates consistency consistent between each other so more headache kind of seeing but um and that's true that's true the uh everything comes at a price database Innovation is is a great thing it's based on normalization CA it's it's not it's quite complex Mass there if you if you try to actually look at the algories that decompose your tables to achieve higher normal forms and all of that but why was it designed like that why why is it important because at that time it was designed disk space was expensive this was expensive and and you didn't want to duplicate your data you wanted to store it more efficiently and you would use joins and and other operators like intersect and Union to combine your data from different tables to compute the result but now uh so for example in this in this example we have employees and departments two separate tables and we have a foreign key Department ID is a foreign key which is key reference to a different table to departments table so we can find out that Edgar Court department based on this one we go to a different table or join with with these table departments and find the department name is actually engineering so this is how relational databases work but in case of distributed databases it's it joins away can be very expensive um because uh the data that we said yes what happened in a no SQL database distributed database is that the the the the record from oral from employees table is on one note and roll from departments table is on different nodes so to join them to join them based on the foreign key like relational databases do you have to move data into some other nodes you need to move it together on one node and then compute it is out that's expensive moving the data is expensive so what nosql databases do not only Cassandra but others and what for example data warehouses do they use the normalization so instead of storing the foreign key for the Department ID they will actually store the Baler that you may need in your query if you need the department name they will store it here the problem is that is okay engineering is repeated here twice if we decide that we change engineering from the the name of the department from engineering to the world-class engineering then we will have to change it here in the Departments table but we'll also have it have to change it in the employees table multiple times so that's why the normalization is can be considered bad so you have to remember do these kind of things and if you have time we will talk about how to use batches to actually do these kind of things efficiently okay so sorry sorry sorry sorry I want to step in a little bit it's one of very important topics could you please switch to previous slides here this one good so uh regarding uh uh that's in general balance between uh multiple of Rights or more complex reads with normalization you go for more complex reads with joints with denormalization you go with more uh the bigger rights multiple rights for one single update instead of one single update um there are some database developers in the world who are trying to claim like yeah we solve a bit of a problem there is new SQL which is great so you can have your data distributed but with joints sounds good and even works on a very small data sets so to build a join you have to get all the data on the single node will it work yes it will when it will work when you when your data fits into a single server and then it's all great but when you don't have to distribute it at all so that is the biggest problem of new SQL distributed SQL it works but only on a small uh data sets but uh that is a different story what I wanted to say like what's most important for me in this story of a battle between normalization and denormalization well there is no real battle it's like a battle of a hammer and range they don't battle they have nothing against each other you know their friends maybe even but it's uh some people go for their normalization some people go to normalization you need to understand both you need to understand then to normalize then to their normalize only then you can be a senior developer software engineer and so on now story most important part of it what is very different between write and read with join right in Cassandra is a single Atomic operation and Cassandra is very capable for rights so you can execute multiple rights in parallel even addressing different notes because well as different tables different partitions it totally can be different notes so you can execute 10 right in a moment of a time and it will be totally fine for your database as long as it's right capable database like Cassandra uh and you run them all at once I think asynchron knows them what's happening with uh joins it's a little bit different story there are very many cases then you cannot run all the joints at one mostly probably your joints will what depend one on each other if you have multiple joints in a select query it will have to first make first join intersect and select some data on it then get the second join third join fourth join step by step by step synchronously all this time you will be waiting so you cannot in most of the cases execute those joints simultaneously and that makes a big problem so although right is considered to be more expensive operation if Cassandra of right is cheap and you can run them in parallel but joins has to have to be executed consecutively and also select is in theory cheap operation is getting much more expensive with joints then you have to wait for every next join to be completed before you can proceed and that is a very important limitation and that is a very important thing to understand yes but um to add there are actually distributed SQL engines and and just if you think about spark SQL that you can run on top of Cassandra and there will be some optimizations where joins will be computed in parallel based on subset of partitions on each node and and engines like Trina um that we'll be able to do things in parallel as well but uh another thing I wanted to mention denominization is used with relational databases as well for performance optimization and but here we with Cassandra this is what we do all the time and going next to the approach so frequently relational modeling starts with you completely focus on data and you model entities relationships and you normalize them and only then you think about okay I need to execute this query and currently I need to do 50 joints to do that that's that's that's possibility no that's possibility I wrote queries with 50 joints before I reached once I reached once a maximum amount of joints allow it in my sequel I got once exception uh by the way it's an interesting to ask on YouTube I see some people watching also quite extensive experience I just want them to guess make a guess once in my life I've seen an exception like you cannot use more than x joins in a statement it was my sequel it was around 12 years ago maybe 10 years ago I don't remember exactly would you guess how many was this number it will be different for different databases for postgres it maybe mostly probably will be different maybe it's changed to newer versions of MySQL I don't work with it for many years already what would be your guess atom and what do you think what would you ask for uh I think it was something like 64 or something like that uh 128 I don't remember okay so our Tom says 64. what would our visitors try Okay the last thing 64. okay uh six wow I mean you Googled it or you knew it 61. 61 right answer is 61. can you imagine maintaining this query that was such a damn nightmare maybe it was different database or different um uh here different version I did yeah yeah for me it was 61 that's for sure I remember this number I would make a tattoo with this number it was so much pain maintaining it but the thing is with if you the relational database is one thing right but if you look at the data warehouses people write those queries like every day with 60 joints because yeah they they it happens especially uh it happened to me not so far ago but anyway data focus on data for relational data modeling and then once you create the the data models then you will think about application how your application is used those tables join them and all of that and then you will think okay maybe I need to create an index maybe I need to generalize here and what's extremely important here also to understand is that it's not just one application new design database once it's relational databases are good and known as integration database you design your database once and you can have multiple applications working with the same tables they can join they can do whatever they need to extract specific data on the other hand no SQL databases they are different usually designed database specific to each application so for each application you will start with with uh thinking about what your application will need what type of data will it retrieve what kind of workload loads you you will of course get some idea of data there as well because you cannot Define queries without data right you will think about okay I need an iterative sensor location sensor failure the the temperature failure and and region as it's things like that the the characteristics of a sensor so you will when you think about application you're also thinking about the data but the data layout the model of the data will be based on those queries primarily so you will use the memorization there you will use indexes as well in some cases but yeah but you the main point is you will Design the the design the the data modeling is driven by your application by queries and with that um we will uh talk about this even in in more damn depths we kind of formalize it into a methodology and I will show you a tool that implements part of this methodology and and we will be able to quiz to design our table the tool design tables for us we will just specify what kind of queries we want to use so data modeling is actually could be quite complex process because it oops yeah I can leave could be quite complex process if you start from scratch you need you need to you start from you you don't have uh data yet you you didn't think about applications so you will have to collect data requirements you will have to understand entities relationship cardinalities keys right so what what's going to be unique for that entity or for that relationship queries how you're gonna create how you access your data in Access patterns involve queries involve inserts involved transactions updates deletes and all of that and only then you will be able to organize a structure and after you organize the strategy you still so you you will produce some kind of database schema you will optimize it with indexes with the normalization we're spocketing like a dynamic packeting like we discussed and so on but usually people think about data model and they think of it about designing schema okay this can be more complacent chance okay well let's let's start with with these five tables no you need to do other things but most of the time maybe for when you join an existing project you will look at the schema somebody designed it already and that's that schema and data modeling data model is extremely important especially uh for Cassandra because you may have things like absurds you may have uh all kind of you may not be able to create it because your primary key does not support that PD uh efficiency scalability right we need to distribute data correctly we need to be able to sort the data in some cases so we need to keep data consistent if we duplicate data in multiple places and all of that so I Define these four data modeling very general high-level data modeling principles you need to know your data and and some of the most important things it would be Keys you need to understand a keys and cardinalities like Network may contain many sensors but sensor must belong to exactly one network or not it depends on your requirements maybe this the sensor like a cell phone may be reached by Two Towers at the same time and belong to two networks okay so this is all something that you need to understand before you do data modeling know your quiz you need to know how you create it and access data Nest data Nest data it's essentially that the normalization that we talked about right so we're going to Nest multiple rows in the same partition or we will create a collection a set or list or map to Nest that data so that's kind of the normalization if you think about it it breaks the rules of normalization cereals right so that's nascular data and and some nosql databases actually like like document databases Json they I think they use the term as data uh before they use the randomization and duplicate data is over the same subset of data you will have to organize that subset of data differently in different tables and and by doing that you will duplicate your data so do you make it a little bit more formal and repeatable as as you will see it's it's possible to even automate this process this is the the methodology in a nutshell we need to understand the data identify access patterns apply apply the query first approach optimize and Implement okay so by understanding the data we are going to do the conceptual data modeling one way to represent it graphically is using anti-relationship diagram uh four to identify access patterns we will do the application workflow model and we'll use application workflow diagram so why it's just so the application workflow you will see an example it involves queries because it involves tasks that are supported by queries because we design application uh data driven application um at some so we have the workflow that creates our database and and at each step in that workflow we know which data which queries we already executed and which type of data we already have and then these two will map into logical data model and one way to represent it would be using Chipotle diagram I will show you an example and logical data models still can be analyzed and optimized and implemented as as a physical data model and we will see the physical levels of a code diagram and cqo implementation as well so four objectives understand data identify access pattern and so on four models conceptual data model application workflow model and two transitions map and optimize what is more most difficult here is I would say the most difficult here is if you're doing it by hand then map and optimize and conceptual data model properly with the map and optimize will be the most difficult if you're using a tool then you you're literally the mapping will be done for you and and maybe even optimization in in some cases so the this is the first step we need to design conceptual data mode on application workflow diagram concurrently or one after another which one is first probably it's hard to decide because um do you need to some understanding of data before you can design queries but in any case this example of the conceptual data model that we already used in the previous Workshop we have a network that networks can have many sensors sensors record temperature so each sensor can record many has many uh temperature valers each one will have a timestamp um and the sensors have ID location latitude longitude they have some characteristics net perhaps name description region number of sensors network has name as the ID sensor has ID as its identifier and the temperature doesn't have enough attributes it's a weak entity type it doesn't have enough edit business to define a key the key is there is a partial key timestamp but also has to borrow the ID from the strong edit type from sensor so they they you need to uniquely identify the value of the temperature you have to have both ID and timestamp so this is how to read it and we I will not spend too much time on this right now so this is a example of application workflow diagram there are four tasks here um they and there are they are annotated with uh specific data access patterns like uh finding information about all Networks and ordering by name finding hourly average temperatures for every sensor and so on and so on and then you can see because each task query is database we need to support this query and how will we support this query we will Design table for each task to support this video usually one table supports one Tweety but not always there may be multiple queries that that are useful that are supported by the same table so sorry uh may I would like to step in here for a moment um there is a very important Point uh could you please switch to a previous slide yeah right like that is an application workflow diagram it describes how customer access your application uses it wants to see in which order what and so on how do you build this well it all comes with the experience of course but for me easiest way to step in and start designing application worklight diagram was my previous experience with user stories maybe you have heard something about user stories before remember like designing application or designing test cases I am starting to think like as a customer for what four maybe buy something later I uh push the button to include some particular pink into my uh watch later or by later reminder list like imagine we are speaking about e-commerce up like in Amazon and this approach uh user stories as customer to do as user role to do something I do following steps a very simple approach and with this approach you can easily analyze your application your um some uh some scientists working with this data of a sensors doesn't think this way but we have to structure um steps he or she will have to do in order to reach the data what I need to uh what as a as a customer as a scientist working with scientifical data temperature data I want to do something I want to see history of the temperatures on a particular location or from a particular sensor that is going to be my primary query and then I start to think so that is a goal of my customer at this moment and this particular case but how do I show temperature values for a sensor in order to show temperature values for a sensor I need to know which sensor we are going to work with do you think your users remember IDs of your goods or whatever videos on Netflix of course not you can just go and show a video on Netflix you need to know its ID okay then in order to give some choice to our customer to our scientists we have to do what display all sensors in the network when we show list a sensor when we show list of sensors he or she can click on the particular one and get a result and here you find very interesting thing we use it to think what software has dependencies like your python application depends on some library or your JavaScript application depends on half of the world at least according to the size of node modulus folder but my story is a workflows also have dependencies you cannot show temperatures as long as you don't show something what will allow us to get a ID of a sensor and then to show uh sensor Networks uh you use sensors in the network you need to show sensors and heavy identified workflows and dependencies between them and finally in order to see it all I have to log in so here is a going to be a q0 actually on this workflow hidden for clarity what we will need to compare email and password and make customer login yes absolutely thank you for the explanation here Alex so the next step would be designing logical data model and uh how you design the data model logical data model based on the queries you already Define in application workflow and based on the data and keys and cardinalities that that you defined in the conceptual data model so there are some basic rules you can follow when you're designing those tables I call them mapping rules and and there are five of them so the first one uh is based on conceptual data model so the the the query that you're going to support will involve some entities and relationship from that model so you will the The Entity relationship types will become tables and the attributes uh type attribute types will become respect respectively columns in those tables so this is the first rule the second one is based on the next three are based on the query so the second one equality search attributes in your query predicate will become the beginning counts of primary key they will form form partition key and possibly subset of clustering key all maybe just partition key but they will be in the beginning of your primary key inequality search attributes will have to be clustering columns but because that's the only way we can do inequality greater than less than and ordering attributes will map the cluster income because that's the only way we will be able to sort data in Cassandra and the final one the final one is usually where most people uh stumble with they have difficulty with uh and and design incorrect primary Keys is this key attributes key attributes from conceptual data model they will have to be part of the primary key in your table to maintain uniqueness okay and those keys are of course when you so for entity types usually easy to define the key but you need to also Define for relationship types and they usually not even shown on the diagrams because they can be derived so let's see an example how we can apply this rule this is a query five that was not I specifically made a more complexity so you can you can demonstrate all five rules that's the same subset of our conceptual data model sensory courts temperature and the nuclear fine draw measurements for a given location and a daytime range order by timestamp descending so obviously here we creating all of this subsets so we basically creating this relationship that involves sensor and temperature and we call this stable temperatures by sensor and we are going to need Valor we're going to need latitude longitude and time step so that's the mapping rule number one maybe rule number two equality search attributes from our query will become the beginning the prefix of our primary key they will form partition key completely also or part of it so in this case what what do we see given location okay given location daytime range doesn't count it's not equality it's inequality so given location is slightly longitude so latitude longitude become the partition key columns and see there is a network problem in the chat um yeah looks like some network is lagging somewhere today um we cannot change it anyhow right now so I hope it's just not too bad yeah I can hear Alex uh in real time no issues at all yeah so mostly probably is between me and restream or between restream and YouTube or maybe restream server yes yes sorry for that so continue with this example let it longitude will be either both of them will be partition key or one of them will be partition key the other one cluster income but they will be in the beginning of the primary key in this case both of them I decided let both of them location will be partition key the next rule is going to class the inequality search will become clustering columns so date time range is our timestamp so we add in timestamp here as a clustering column it's ascending order because we don't care about order yet and the next rule rule number four says that the if you need to order right the ordering attributes will have to become clustering columns and you need to switch you need to use correct order sorry correct order so in this case when we apply Maple rule four we get the cluster in column descending order in this case and then the final rule the final rule says that we need to make sure that the key in this case key of this relationship is preserved in our primary key so we still need to add sensor to uniquely identify our failure right it's location is how we want to retrieve the data but the daily uniquely identified by sensor and timestamp right so we still need to add the sensor and this is this is the last rule that that most of the time people make error here for getting this sensor but this is how to how to apply that we can actually do this example in in our data modeling tool later and see how it constructs this type of uh primary key for us so following these rules we can support our keys by by designing this logical data model with with Stables we have the sensor byte Network table that we used already and and we applied as an example Dynamic bike bucketing on this on this table but this is how it looks looks like and for the sake of time I will skip description of each table but I will show you later then in in the data modeling tool so and the final step is to optimize and implement the result in Cassandra using Cassandra queer language so in this case the what kind of optimization so probably the the five most common ones are here the partition size is split in large partitions when we kind of already discuss it in with Dynamic bucketing and and this large partitions hot partitions spend a lot of time on that and data duplications and and maybe you can use batches sometimes to solve the problem uh indexing and materialized views will we use them will we not use them what are the pros and cons concurrent data access if you have multiple uh multiple user multiple applications changing the same Valor is is the change either important if uh will it will there be any conflict right so we can we if we have time we can discuss that or maybe discussed in in a separate Workshop but lightweight transactions is one way to solve that and dealing with with storm Stones is also an interesting topic that will probably not have time to talk about today so that actually three optimizations that were applied here on physical data model first of all what's the difference that you have data types specified but also in green here we have um we have the highlighted the the optimization that we applied since we want to retrieve all the networks we put all of them into one bucket so we can only access one bucket on one partition this is the optimization set of storing each Network in a separate partition we store in all of them in one partition so we can retrieve them as one partition very two optimizations here eight hours into one column season dates separately in our separately we're just using timestamp and storing them together and also week was added as part of the partition key and you probably know why to split the large partition because the um if we don't add any time component into partition key then our partition grows over time and and it will become a large partition and finally implementing these tables in cql should be quite straightforward the um either the same tables and with data types with Partition classroom key primary key design so one one of the things I wanted to mention here to wrap it up with this approach or methodology is that uh what's the difference actually between relational data modeling and Cassandra data modeling okay and you can see these two methodologies they have some things in common like you you can use conceptual data model design in both of them but the big difference is that you do not use normalization CE and the queries in relational approach so you you do conceptual map it to relational logical then map normalize it get normalized and then you do physical optimizations that's when your physical optimization that's when your quiz I use that when you decide okay I need to create an index here uh or to support specific join or or select and I also need to um maybe denormalize because this join is not performing as fast as I wanted to uh and and things like that in case of Cassandra there are fewer steps uh and actually I would say it's a simpler methodology even so um it's not the easiest one right but uh you you can you can see there's the queries will be used right away to design your tables and there will be no normalization right so that's a difference and with that said I will show you KDM data modeling tool which one is great and it's part of the hour a game GitHub Workshop uh the readme file so you can the the tool itself itself you can just open it online and you can download the XML file which is a project file and you can follow me follow what I'm doing but I will show you first this is just an empty empty project um for the for the KDM tool there is nothing defined here but I will show you how to do it so um it's it's not that difficult so we will try to do our uh just one relationship just just to see see the process so we had the network and we have uh sensor okay and we have relationship networks let's say has sensor we will connect them okay we will say the network can have many sensors so I will annotate with many and each sensor belongs to One Network I will annotate now I need to add some attributes let's not get too crazy just add couple of them for each one so there will be name of the network and description and the ID of the sensor and say description okay let's connect them to you did I connect it right did I not let me check yes okay and then I will we need to design this designate a key attributes so right click this is gonna be our key for the network this is gonna be uh ID is going to be key okay so this let's go to the next step access patterns we will only use one just one want to show you how to do it the um so as I said just just a simple tutorial so let's retrieve all sensors in a network we had a query like that so what we want to find is the sensor ID so find sensor ID and find description and what is given is the name of the network okay given name uh and at this point we can click logical and this is a table that is generated for us given the name of the sensors as a banana the name of the set the network will get we can find ID and sensor description okay um and the we can continue and generate physical besides okay ID will be maybe this time it will be uuid and then cqo and finally we have the table that we can use yay yes uh what happens if we change the cardinality why cardinality is important let me say the different cardinality I will regenerate the well you know in this the not for this query I will also need to change the query anyway let me show more complex feeling for you with with the actual example that we have in the slides okay so this is this should be familiar Network sensors um uh these are the four queries that we defined in this tool and also in our model that we already discussed right the finding information about all Networks finding hourly average temperature finding information about all sensors um finding raw measurements and all of that so all four are defined we can generate logical and sometimes we'll have a choice right we can choose one of these tables for example so um and and usually the choice is because of the ordering like ID and date change the order or maybe date can be just clustering column ID can be classed in column you can you can choose which one you like similarly as before and generate physical generate SQL but let me show you some more complexity um the for example for example what about we want to what if we want to retrieve this so let's create new query five and let's say we want to retrieve all the raw measurements from possibly multiple sensors from multiple networks based on the region okay so we're gonna want to find this value and we will retrieve based on the region information that's given okay so what type of table do we need for that let's see okay so this is P5 given the region we will uh retrieve the Valor but we will also add timestamp and sensor ID as the clustering key and the order is not really important unless we want to sort we probably want to sort based on timestamp so this is how easy you can design a table using using a tool um basically automates this design and if you notice not even network name is used as part of the partition key and the reason is because this the key of this relationship is sensor ID sensor can belong only to One Network if we change that we probably will have the we should have I would say uh name becomes part of the clustering key so this is the end of this demo and we are actually very close to the end of our two hours so at this point I would say we will skip all the optimization techniques and we'll wrap it up Alex yes uh we anyway have it in the primary course so that is an introductional level series and you get deeper in the academy data stack scores uh data modeling DS 220 at the Academy and it's the only right way to get ready for the certification uh so let me switch to my screen back in a moment and the tool is free and as you may guess it's designed by um uh doctor Cash live who is a professor in Eastern Michigan University um that is pretty cool so um switching to my screen yep good okay uh so yeah I love this tool I'm with you Cedric it's uh totally a great thing absolutely great thing it helped so many people oops it helped so many people uh that is absolutely amazing good so what's next we will have a quiz so if you didn't win prizes last week now you have chances to do it but before that places for you to know um datastacks.com learn data modeling by example that is a very important thing and that I think what like a very well explain it many cases explanations done by archon Cassandra data modeling exercises are available at killer kodam by the link above we are at your disposal at the Discord server so we can answer questions sir uh some more cases and interesting readings uh we also could I don't know if I can copy link address and send it to the Chart it may be a very interesting reading yes I can which is great uh don't forget to do the homework submit the homework form and submit my homework with screenshots and get your data Stacks modeling Workshop page but what is better when beige is a real globally recognized certification so don't forget data Stacks offer more than than just this Workshop you can get your education training and certification totally for free if data Stacks developers Discord Community I already mentioned uh this part I will not be there next weeks but our data Stacks developers will be so we could help you your instructors PhD data modeling methodology outer and meme developer Advocate leader data Stacks alexnev links on the screen are for you to add us on LinkedIn so it's very easy uh type jump at us and we will be happy to have more friends sir and finally you cannot wait for the quiz I guess so let's go if you are not on Main tier then jump on jump in right now because we are short on time so quiz starts in some seconds to join the quiz you can enter the code 14095206 on mentee.com or you can scan the QR code on the screen and oh I see artium hides the code a bit sorry uh it's on my side but again code is 1409 uh or I can just call for mentee on the YouTube chat good so I hope you are in already one hint I want to give you as you are so great people visiting our Workshop already not the first time most of you I want to give you a little hint YouTube has a little discrepancy a little luck a little DeLay So answering questions you better watch uh not a YouTube stream but many screen because it will be a little bit ahead so you have more chances to get more points and get closer to your victory uh from this point I see people joining I hope you all are good very last moment to join very last moments to get chances to win price and let's start it will be eight questions answer fast to get more points a key space a key space is organized into rows and columns key space contains tables and sets replication keyspace is the base unit of access key space is a place to store extra house keys so you are answering quickly I see most of the attendees already voted with the last few seconds will we have any late camera and time is over so most of you made it right key space contains tables and sets replication partition is the base unit of access and organize it into rows and columns as a table not key space who was the fastest this time brand the broken made it with 982 points which is incredibly fast fastest hand on the west question number two so answer fast to get more points what's the partition key you were paying killed is it an optional optional column to allow Group by it's maybe a column to Define partitions required it's maybe a required column to set sorting order or is that the key to all the doors yes partition key is a column to Define partitions it is required it's not to set sorting order but to set partitions well who was the fastest FaceTime Praveen was the fastest keeping the first place nitation II and Sumit on the third with Mr Wonka and Rita a couple of points difference of places number four and five it's not over yet we are just starting so let's go to question number three and answer fast to get more points table can have many rows per partition true false it requires special Cassandra yaml configuration it's illegal what do you think is it correct wrong or maybe special it's totally legal and that's perfectly true and everything is fine it does not require any special configuration ah okay so was anyone faster Miss Praveen this time Sumit was faster keeping the third place but Praveen still on the first one uh by the way I know there are people there is a conference in New York right now API days New York and I know they are watching us I'm very curious if anyone is joining our quiz from API days to New York that would be very interesting question four so let's see what will happen answer fast to get more points in Cassandra tables which are required data columns clustering columns partition Keys user defined types what is required in Cassandra tables I should have added the question if nosql is schema-less uh that's pretty said I didn't do it that would be a good filter to those who paid attention partition keys right partition keys are required you can safely emit clustering columns if they are not required by your data model but technically only partition keys are required okay so there are no mistakes between leaders but looks like amid was a little bit slower this time and Praveen was fastest again so no changes in top three and that is going to be question number five so answer fast to get more points inequality predicates a allowed on all table columns partition key columns clustering key columns no inequality predicates are allow it okay people giving their answers but time is up right answer inequality predicates are allow it on clustering key columns on partition Keys you cannot have any inequalities only equalities make a mistake that means what top three will change right now we've need as fast as jumping on the first place moving Praveen down to a second and Mr Wonka makes it to the third place with tiger baby very very very close you uh Mr Wonka you can hear his breathing like somewhere from behind a competition is not done yet okay let's go question number six Summit uh keep fighting answer fast to get more points in the data modeling methodology we start modeling Thief physical data model logical data model conceptual data model and application workflow copy paste from stack overflow time is up and most of you made it right conceptual data model and application workflow to map them into logical data model which is a wrong answer and physical data module is one of the latest Steps From the data modeling methodology like we have a guest here like uh you have and Mr Wonka makes a mistake just right after getting in the top three oh my God Praveen returned to first place with nitesh on the second and now tiger baby on the third place with Amit on Fifth and Kevin and fourth it's almost done question number seven answer first to get more points primary key defines row uniqueness pulse correct primary key is deprecated see I meet says what question 6 appeared in the first Workshop as well yes and that is an intention I want you to remember the steps correct primary key defines raw uniqueness and that is a totally correct statement so who was fastest this time there are no mistakes but who was fastest looks like nitesh was fastest very well done a Praveen nitesh made no mistake so far and tiger baby is one of the third place with one mistake and Kevin p is now 50 points behind tiger baby which is nearly nothing uh that is the last question so you want me to push this button right okay let's go answer fast to get more points how does Cassandra perform joints Cassandra joins require a joint table just like sequel joins Cassandra does not support joints or Cassandra only joins good clubs time is ticking most of you made their step already and correct answer is Cassandra does not support joints Cassandra joins don't require joint table it's not a thing it doesn't exist it exists only in my imagination it's not like just equal joints SQL joints are totally great but they don't work on Big Data okay okay they work on Big Data but very very slowly I better say it this way if you have a customer facing database you cannot afford joins on Cassandra Cassandra simply does not support joints and Kevin makes mistake but that doesn't matter because Praveen nitesh and tiger baby made no mistake nitesh gets overtaking Praveen again gets to a first place very well so we congratulate nitesh Praveen and tiger baby please make a screenshot of your winning screen with your position number one number two number three and send it to me on LinkedIn using https Alex Alex I need to ask congrats and I will take care of you getting the prizes uh now uh verus who are on the leaderboard congrats you made it very well even though you didn't made it in the top three but remember we will have a next Workshop soon third Workshop of this series so me don't be disappointed we will have one more chance at our next Workshop by the way I think next Workshop will be not next week please notice that but Uber next next week I believe it's going on to be next next week you have to check the schedule and finally if you are not even on a leaderboard most important thing we are giving today not the prices also their fun but actually knowledge because yeah it's in two weeks uh so next on 10th of August thank you Cedric and knowledge is much more valuable than our swag and then finally make a screenshot and changing the page if you didn't still contact me two questions how do you like this Workshop series would you recommend it to your friends it's a quick choice okay looks like first answer was very quick and very positive thank you so much I see like uh a very good score after all I'm sorry if you rate it not so high I hope you will improve for the next series but I know you know what you stayed with us till the very end of a second Workshop you spend with us almost five hours overall that means you like it admit it like I Know It And by the way don't forget to like And subscribe on us on YouTube and then finally what would you suggest any feedback regarding this Workshop or this series in general just specify please what exactly you mean because it's a second Workshop in this series I will keep this window open so you can write your feedback after the workshop it will be open for half an hour more and let us switch to the last slides uh don't forget to complete the homework and it's expected we explain how to do it in our GitHub repository which you have seen already join Discord if you will have any questions or catch us on LinkedIn links are on the screen and homework right yeah homework actually instructions are configured by Cedric thank you uh with that said that was Alex Anderson thank you so much for joining it was a real pleasure to work with you and many good questions today and I think we are done after do you like to add anything no it was great thanks for coming and hope to see you during the next Workshop yes I will be in the chat great uh so uh soon then in two weeks thank you Katie thank you everyone uh thank you for joining nitesh and our winners send me a message on LinkedIn and then meet you soon thank you Rita thank you for coming foreign [Music] foreign [Music]",
    "segments": [
      {
        "start": 0.359,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 5.12,
        "duration": 29.999,
        "text": "[Music]"
      },
      {
        "start": 36.6,
        "duration": 17.799,
        "text": "foreign"
      },
      {
        "start": 38.57,
        "duration": 15.829,
        "text": "[Music]"
      },
      {
        "start": 56.52,
        "duration": 14.59,
        "text": "[Music]"
      },
      {
        "start": 69.24,
        "duration": 38.079,
        "text": "foreign"
      },
      {
        "start": 71.11,
        "duration": 36.209,
        "text": "[Music]"
      },
      {
        "start": 111.119,
        "duration": 2.241,
        "text": "foreign"
      },
      {
        "start": 126.259,
        "duration": 7.321,
        "text": "can you hear us"
      },
      {
        "start": 129.319,
        "duration": 7.601,
        "text": "yeah aha I see people joining"
      },
      {
        "start": 133.58,
        "duration": 7.0,
        "text": "that is amazing"
      },
      {
        "start": 136.92,
        "duration": 6.24,
        "text": "so uh that's uh Alex voluschniff and"
      },
      {
        "start": 140.58,
        "duration": 3.54,
        "text": "artemis.com developer Advocates at data"
      },
      {
        "start": 143.16,
        "duration": 4.92,
        "text": "stacks"
      },
      {
        "start": 144.12,
        "duration": 6.18,
        "text": "and sound is good amazing yeah Katie I"
      },
      {
        "start": 148.08,
        "duration": 4.08,
        "text": "made some homework as you see I hope you"
      },
      {
        "start": 150.3,
        "duration": 4.939,
        "text": "did it too"
      },
      {
        "start": 152.16,
        "duration": 3.079,
        "text": "so let's move on"
      },
      {
        "start": 155.4,
        "duration": 6.18,
        "text": "um so I'm Alex with data Stacks my job"
      },
      {
        "start": 158.16,
        "duration": 6.18,
        "text": "here is not let developers make mistakes"
      },
      {
        "start": 161.58,
        "duration": 5.7,
        "text": "and fail with Apache Cassandra and"
      },
      {
        "start": 164.34,
        "duration": 5.399,
        "text": "distributed systems in general"
      },
      {
        "start": 167.28,
        "duration": 5.12,
        "text": "and that's uh arctometer could you"
      },
      {
        "start": 169.739,
        "duration": 2.661,
        "text": "introduce yourself"
      },
      {
        "start": 172.62,
        "duration": 6.539,
        "text": "yes so I'm developer Advocate my"
      },
      {
        "start": 176.64,
        "duration": 4.56,
        "text": "interest is main interest in data"
      },
      {
        "start": 179.159,
        "duration": 6.061,
        "text": "modeling data quality but I also love"
      },
      {
        "start": 181.2,
        "duration": 8.459,
        "text": "data warehousing work with SQL databases"
      },
      {
        "start": 185.22,
        "duration": 8.28,
        "text": "as well but over my career I've been"
      },
      {
        "start": 189.659,
        "duration": 6.901,
        "text": "working with pretty much every major"
      },
      {
        "start": 193.5,
        "duration": 5.879,
        "text": "a type of database relational XML rdf"
      },
      {
        "start": 196.56,
        "duration": 6.0,
        "text": "graph no SQL different type of types of"
      },
      {
        "start": 199.379,
        "duration": 5.161,
        "text": "nosql and so on and I'm happy to join"
      },
      {
        "start": 202.56,
        "duration": 4.259,
        "text": "this Workshop to talk about data"
      },
      {
        "start": 204.54,
        "duration": 5.339,
        "text": "modeling for Apache Cassandra there will"
      },
      {
        "start": 206.819,
        "duration": 7.321,
        "text": "be very cool demo later hope you will"
      },
      {
        "start": 209.879,
        "duration": 5.881,
        "text": "like it yep uh you know uh we data"
      },
      {
        "start": 214.14,
        "duration": 5.94,
        "text": "Stacks developers will know whom to"
      },
      {
        "start": 215.76,
        "duration": 6.6,
        "text": "invite for each workshop and artem is"
      },
      {
        "start": 220.08,
        "duration": 5.04,
        "text": "the person who developed a data modeling"
      },
      {
        "start": 222.36,
        "duration": 5.04,
        "text": "methodology for Apache Cassandra so here"
      },
      {
        "start": 225.12,
        "duration": 5.64,
        "text": "on all of the world he is exactly the"
      },
      {
        "start": 227.4,
        "duration": 7.5,
        "text": "right guy to talk about that"
      },
      {
        "start": 230.76,
        "duration": 6.72,
        "text": "um good today we will use GitHub"
      },
      {
        "start": 234.9,
        "duration": 5.88,
        "text": "repository as well last time you've seen"
      },
      {
        "start": 237.48,
        "duration": 4.8,
        "text": "that we will do some practice scenarios"
      },
      {
        "start": 240.78,
        "duration": 4.5,
        "text": "with Astra"
      },
      {
        "start": 242.28,
        "duration": 6.06,
        "text": "and for data modeling we will use a"
      },
      {
        "start": 245.28,
        "duration": 6.9,
        "text": "special tool developer to make your life"
      },
      {
        "start": 248.34,
        "duration": 6.08,
        "text": "easier before we proceed and to let"
      },
      {
        "start": 252.18,
        "duration": 4.76,
        "text": "everyone jump in"
      },
      {
        "start": 254.42,
        "duration": 6.18,
        "text": "please"
      },
      {
        "start": 256.94,
        "duration": 5.64,
        "text": "jump in on"
      },
      {
        "start": 260.6,
        "duration": 5.08,
        "text": "mint here"
      },
      {
        "start": 262.58,
        "duration": 5.8,
        "text": "and answer our questions"
      },
      {
        "start": 265.68,
        "duration": 5.64,
        "text": "first question will be to understand"
      },
      {
        "start": 268.38,
        "duration": 6.06,
        "text": "your experience how much SQL experience"
      },
      {
        "start": 271.32,
        "duration": 5.7,
        "text": "do you have with relational databases"
      },
      {
        "start": 274.44,
        "duration": 5.039,
        "text": "if you attended our last Workshop you"
      },
      {
        "start": 277.02,
        "duration": 7.739,
        "text": "already know what to do just go to"
      },
      {
        "start": 279.479,
        "duration": 5.28,
        "text": "mentee.com and use the code 14095206"
      },
      {
        "start": 285.72,
        "duration": 4.88,
        "text": "and oh it's not mind but momentum"
      },
      {
        "start": 292.04,
        "duration": 7.12,
        "text": "link is on the screen menchie.com and"
      },
      {
        "start": 295.5,
        "duration": 8.58,
        "text": "code is on the screen too"
      },
      {
        "start": 299.16,
        "duration": 8.099,
        "text": "I see we have some experts which is good"
      },
      {
        "start": 304.08,
        "duration": 4.619,
        "text": "okay more people joining let's jump to"
      },
      {
        "start": 307.259,
        "duration": 5.901,
        "text": "the next question"
      },
      {
        "start": 308.699,
        "duration": 4.461,
        "text": "how much no SQL experience do you have"
      },
      {
        "start": 314.16,
        "duration": 4.92,
        "text": "okay"
      },
      {
        "start": 316.5,
        "duration": 6.9,
        "text": "a little bit that's a good place for you"
      },
      {
        "start": 319.08,
        "duration": 6.72,
        "text": "to be no SQL a lot good no private"
      },
      {
        "start": 323.4,
        "duration": 5.54,
        "text": "experience also nice"
      },
      {
        "start": 325.8,
        "duration": 6.3,
        "text": "so don't forget nosql is very different"
      },
      {
        "start": 328.94,
        "duration": 5.199,
        "text": "so your knowledge of will not help"
      },
      {
        "start": 332.1,
        "duration": 5.039,
        "text": "you with Cassandra and your knowledge of"
      },
      {
        "start": 334.139,
        "duration": 5.12,
        "text": "Cassandra will not help you with neo4j"
      },
      {
        "start": 337.139,
        "duration": 4.56,
        "text": "those are different tools for different"
      },
      {
        "start": 339.259,
        "duration": 5.141,
        "text": "uh use cases"
      },
      {
        "start": 341.699,
        "duration": 4.621,
        "text": "and today you are going to improve your"
      },
      {
        "start": 344.4,
        "duration": 5.12,
        "text": "knowledge of one of the most powerful"
      },
      {
        "start": 346.32,
        "duration": 6.78,
        "text": "and most scalable of the nosql databases"
      },
      {
        "start": 349.52,
        "duration": 6.04,
        "text": "good then let me check are you into the"
      },
      {
        "start": 353.1,
        "duration": 5.539,
        "text": "topic already no SQL databases are"
      },
      {
        "start": 355.56,
        "duration": 3.079,
        "text": "schema-less correct"
      },
      {
        "start": 359.34,
        "duration": 7.62,
        "text": "I love asking this question no okay will"
      },
      {
        "start": 364.259,
        "duration": 5.401,
        "text": "anyone answer yes"
      },
      {
        "start": 366.96,
        "duration": 5.16,
        "text": "yes okay someone okay looks like someone"
      },
      {
        "start": 369.66,
        "duration": 5.46,
        "text": "missed our first Workshop"
      },
      {
        "start": 372.12,
        "duration": 5.46,
        "text": "not all nosql databases are schema less"
      },
      {
        "start": 375.12,
        "duration": 5.28,
        "text": "there are plenty of schema full nosql"
      },
      {
        "start": 377.58,
        "duration": 5.399,
        "text": "databases so the correct answer is no"
      },
      {
        "start": 380.4,
        "duration": 5.76,
        "text": "and I see most of you know that already"
      },
      {
        "start": 382.979,
        "duration": 5.461,
        "text": "isn't that amazing we have some people"
      },
      {
        "start": 386.16,
        "duration": 4.5,
        "text": "of experience here today"
      },
      {
        "start": 388.44,
        "duration": 3.84,
        "text": "what about normalization and"
      },
      {
        "start": 390.66,
        "duration": 3.78,
        "text": "denormalization"
      },
      {
        "start": 392.28,
        "duration": 4.199,
        "text": "do you know what is that do you know"
      },
      {
        "start": 394.44,
        "duration": 3.56,
        "text": "when to use it do you use it all the"
      },
      {
        "start": 396.479,
        "duration": 5.701,
        "text": "time"
      },
      {
        "start": 398.0,
        "duration": 6.1,
        "text": "okay some people understanding that or"
      },
      {
        "start": 402.18,
        "duration": 5.16,
        "text": "at least basic understanding very well"
      },
      {
        "start": 404.1,
        "duration": 5.46,
        "text": "if you don't have don't worry we will"
      },
      {
        "start": 407.34,
        "duration": 5.1,
        "text": "briefly explain it to you today because"
      },
      {
        "start": 409.56,
        "duration": 6.6,
        "text": "normalization and denormalization are"
      },
      {
        "start": 412.44,
        "duration": 6.78,
        "text": "very important techniques to um learn to"
      },
      {
        "start": 416.16,
        "duration": 4.92,
        "text": "master if you want to be good engineer"
      },
      {
        "start": 419.22,
        "duration": 3.9,
        "text": "if you want your applications to be"
      },
      {
        "start": 421.08,
        "duration": 4.559,
        "text": "quick and efficient and your customers"
      },
      {
        "start": 423.12,
        "duration": 4.44,
        "text": "to be happy you totally need to know and"
      },
      {
        "start": 425.639,
        "duration": 5.4,
        "text": "understand both techniques"
      },
      {
        "start": 427.56,
        "duration": 4.74,
        "text": "we will taught what denormalization is"
      },
      {
        "start": 431.039,
        "duration": 4.861,
        "text": "bad"
      },
      {
        "start": 432.3,
        "duration": 5.94,
        "text": "and that's why I have to ask you what"
      },
      {
        "start": 435.9,
        "duration": 5.28,
        "text": "about uh generalization is it an"
      },
      {
        "start": 438.24,
        "duration": 6.5,
        "text": "absolute evil or there are scenarios"
      },
      {
        "start": 441.18,
        "duration": 3.56,
        "text": "where it can be good"
      },
      {
        "start": 444.9,
        "duration": 4.44,
        "text": "skip question is totally fine because we"
      },
      {
        "start": 447.24,
        "duration": 5.12,
        "text": "will explain uh the normalization"
      },
      {
        "start": 449.34,
        "duration": 3.02,
        "text": "foundations today"
      },
      {
        "start": 452.759,
        "duration": 4.081,
        "text": "so take a look at Tom we work with"
      },
      {
        "start": 455.16,
        "duration": 4.56,
        "text": "pretty experienced audience today"
      },
      {
        "start": 456.84,
        "duration": 5.579,
        "text": "because on most of our workshops then I"
      },
      {
        "start": 459.72,
        "duration": 5.039,
        "text": "ask this question what people answer no"
      },
      {
        "start": 462.419,
        "duration": 4.56,
        "text": "denormalization is an evil the"
      },
      {
        "start": 464.759,
        "duration": 4.321,
        "text": "normalization is bad"
      },
      {
        "start": 466.979,
        "duration": 4.741,
        "text": "there denormalization can be good"
      },
      {
        "start": 469.08,
        "duration": 4.92,
        "text": "absolutely as long as you control it"
      },
      {
        "start": 471.72,
        "duration": 4.14,
        "text": "don't let the normalization control you"
      },
      {
        "start": 474.0,
        "duration": 4.74,
        "text": "you know"
      },
      {
        "start": 475.86,
        "duration": 5.16,
        "text": "that's so you are the engineer you have"
      },
      {
        "start": 478.74,
        "duration": 3.899,
        "text": "to stay in control"
      },
      {
        "start": 481.02,
        "duration": 3.42,
        "text": "there are certain things we will talk"
      },
      {
        "start": 482.639,
        "duration": 4.5,
        "text": "about the normalization that's certainly"
      },
      {
        "start": 484.44,
        "duration": 5.46,
        "text": "useful but you need to be aware of of"
      },
      {
        "start": 487.139,
        "duration": 3.96,
        "text": "the drawbacks as well"
      },
      {
        "start": 489.9,
        "duration": 3.54,
        "text": "good"
      },
      {
        "start": 491.099,
        "duration": 5.04,
        "text": "data duplication yes"
      },
      {
        "start": 493.44,
        "duration": 6.479,
        "text": "so all the latecomers have joined"
      },
      {
        "start": 496.139,
        "duration": 6.84,
        "text": "judging by the uh stream viewers so we"
      },
      {
        "start": 499.919,
        "duration": 5.641,
        "text": "can proceed but again thank you everyone"
      },
      {
        "start": 502.979,
        "duration": 5.881,
        "text": "for joining that mattress a tone to us"
      },
      {
        "start": 505.56,
        "duration": 5.52,
        "text": "today we will speak about uh data"
      },
      {
        "start": 508.86,
        "duration": 4.619,
        "text": "storage organization and distribution in"
      },
      {
        "start": 511.08,
        "duration": 5.22,
        "text": "Cassandra because that's what something"
      },
      {
        "start": 513.479,
        "duration": 6.54,
        "text": "makes Cassandra so special very"
      },
      {
        "start": 516.3,
        "duration": 6.0,
        "text": "performant but also with some sharp"
      },
      {
        "start": 520.019,
        "duration": 3.361,
        "text": "edges you need to know not to hurt"
      },
      {
        "start": 522.3,
        "duration": 4.74,
        "text": "yourself"
      },
      {
        "start": 523.38,
        "duration": 6.36,
        "text": "then we will speak about keys and how"
      },
      {
        "start": 527.04,
        "duration": 5.52,
        "text": "keys are so important how Keys defined"
      },
      {
        "start": 529.74,
        "duration": 5.4,
        "text": "so much we will speak about SQL data"
      },
      {
        "start": 532.56,
        "duration": 5.219,
        "text": "types not on big details but we want"
      },
      {
        "start": 535.14,
        "duration": 5.52,
        "text": "this Workshop to be two hours not two"
      },
      {
        "start": 537.779,
        "duration": 4.801,
        "text": "days okay then there is a lot of"
      },
      {
        "start": 540.66,
        "duration": 3.84,
        "text": "attention to data modeling process"
      },
      {
        "start": 542.58,
        "duration": 4.56,
        "text": "because it's the most important part of"
      },
      {
        "start": 544.5,
        "duration": 5.519,
        "text": "the day optimization techniques and"
      },
      {
        "start": 547.14,
        "duration": 4.199,
        "text": "basically what's next homework and so on"
      },
      {
        "start": 550.019,
        "duration": 4.44,
        "text": "and so forth"
      },
      {
        "start": 551.339,
        "duration": 5.581,
        "text": "and we will start with a data storage"
      },
      {
        "start": 554.459,
        "duration": 5.581,
        "text": "overview"
      },
      {
        "start": 556.92,
        "duration": 5.46,
        "text": "so data distribution we discussed it"
      },
      {
        "start": 560.04,
        "duration": 3.6,
        "text": "briefly last week but I see some people"
      },
      {
        "start": 562.38,
        "duration": 3.6,
        "text": "still"
      },
      {
        "start": 563.64,
        "duration": 4.8,
        "text": "not completely getting into that and how"
      },
      {
        "start": 565.98,
        "duration": 4.44,
        "text": "important it is and may also maybe there"
      },
      {
        "start": 568.44,
        "duration": 5.94,
        "text": "are some newcomers today"
      },
      {
        "start": 570.42,
        "duration": 6.18,
        "text": "Cassandra keeps data distributed it"
      },
      {
        "start": 574.38,
        "duration": 4.5,
        "text": "means what the same pieces of the same"
      },
      {
        "start": 576.6,
        "duration": 3.359,
        "text": "table will be spread to over multiple"
      },
      {
        "start": 578.88,
        "duration": 3.959,
        "text": "servers"
      },
      {
        "start": 579.959,
        "duration": 6.121,
        "text": "servers keeping your information"
      },
      {
        "start": 582.839,
        "duration": 6.541,
        "text": "are organized into so-called Rings or"
      },
      {
        "start": 586.08,
        "duration": 6.72,
        "text": "you can also call it just a data center"
      },
      {
        "start": 589.38,
        "duration": 5.76,
        "text": "and those data centers combine it"
      },
      {
        "start": 592.8,
        "duration": 3.719,
        "text": "together will build a cluster and this"
      },
      {
        "start": 595.14,
        "duration": 4.5,
        "text": "cluster can be geographically"
      },
      {
        "start": 596.519,
        "duration": 5.76,
        "text": "distributed with all nodes active there"
      },
      {
        "start": 599.64,
        "duration": 5.16,
        "text": "are no idea like a slave node or a"
      },
      {
        "start": 602.279,
        "duration": 5.761,
        "text": "secondary node for Royal node each node"
      },
      {
        "start": 604.8,
        "duration": 5.7,
        "text": "can process each request globally"
      },
      {
        "start": 608.04,
        "duration": 4.5,
        "text": "there is no single point of failure it"
      },
      {
        "start": 610.5,
        "duration": 4.339,
        "text": "scale it scales perfectly for right"
      },
      {
        "start": 612.54,
        "duration": 6.18,
        "text": "applications and for read applications"
      },
      {
        "start": 614.839,
        "duration": 6.581,
        "text": "and your app can contact any node switch"
      },
      {
        "start": 618.72,
        "duration": 4.98,
        "text": "to next node work with next next again"
      },
      {
        "start": 621.42,
        "duration": 4.56,
        "text": "switch to next data center if required"
      },
      {
        "start": 623.7,
        "duration": 4.379,
        "text": "it's totally possible and that what"
      },
      {
        "start": 625.98,
        "duration": 4.5,
        "text": "makes Cassandra globally available and"
      },
      {
        "start": 628.079,
        "duration": 4.921,
        "text": "highly available"
      },
      {
        "start": 630.48,
        "duration": 5.58,
        "text": "data and Cassandra is organized as"
      },
      {
        "start": 633.0,
        "duration": 4.22,
        "text": "stables and those tables have strict"
      },
      {
        "start": 636.06,
        "duration": 4.38,
        "text": "schema"
      },
      {
        "start": 637.22,
        "duration": 6.94,
        "text": "there's still no SQL"
      },
      {
        "start": 640.44,
        "duration": 6.0,
        "text": "but those Stables are distributed tables"
      },
      {
        "start": 644.16,
        "duration": 4.56,
        "text": "so data of these tables are spread"
      },
      {
        "start": 646.44,
        "duration": 3.839,
        "text": "across the cluster across your data"
      },
      {
        "start": 648.72,
        "duration": 3.96,
        "text": "centers"
      },
      {
        "start": 650.279,
        "duration": 5.101,
        "text": "and there is no single node what which"
      },
      {
        "start": 652.68,
        "duration": 5.76,
        "text": "called all of your data Cassandra is"
      },
      {
        "start": 655.38,
        "duration": 5.639,
        "text": "ready to work with data of any size and"
      },
      {
        "start": 658.44,
        "duration": 4.38,
        "text": "that means petabytes literally petabytes"
      },
      {
        "start": 661.019,
        "duration": 3.301,
        "text": "and petabytes ladies and gentlemen"
      },
      {
        "start": 662.82,
        "duration": 3.54,
        "text": "that's a lot"
      },
      {
        "start": 664.32,
        "duration": 5.28,
        "text": "so"
      },
      {
        "start": 666.36,
        "duration": 5.58,
        "text": "how it works quick reminder then you"
      },
      {
        "start": 669.6,
        "duration": 3.859,
        "text": "arrange a partition key we will discuss"
      },
      {
        "start": 671.94,
        "duration": 5.04,
        "text": "it in details today"
      },
      {
        "start": 673.459,
        "duration": 6.641,
        "text": "then data arrives on a node or basically"
      },
      {
        "start": 676.98,
        "duration": 5.76,
        "text": "even earlier actually when your driver"
      },
      {
        "start": 680.1,
        "duration": 4.56,
        "text": "starts vibration Cassandra driver in"
      },
      {
        "start": 682.74,
        "duration": 4.32,
        "text": "your application starts some operation"
      },
      {
        "start": 684.66,
        "duration": 5.1,
        "text": "to write or to read it will get a"
      },
      {
        "start": 687.06,
        "duration": 5.519,
        "text": "partition key and hash it to a token"
      },
      {
        "start": 689.76,
        "duration": 5.639,
        "text": "from string or from whatever value into"
      },
      {
        "start": 692.579,
        "duration": 5.94,
        "text": "an integer value using some special"
      },
      {
        "start": 695.399,
        "duration": 6.801,
        "text": "hashing algorithm and get a token per"
      },
      {
        "start": 698.519,
        "duration": 7.32,
        "text": "table each node owns a range of tokens"
      },
      {
        "start": 702.2,
        "duration": 6.819,
        "text": "numbers you see on the screen 0 to 16 17"
      },
      {
        "start": 705.839,
        "duration": 5.881,
        "text": "to 32 and so on you actually uh yes"
      },
      {
        "start": 709.019,
        "duration": 5.401,
        "text": "those tokens are like those numbers but"
      },
      {
        "start": 711.72,
        "duration": 6.419,
        "text": "much much longer of course because like"
      },
      {
        "start": 714.42,
        "duration": 6.719,
        "text": "it could be billions of partitions"
      },
      {
        "start": 718.139,
        "duration": 6.421,
        "text": "and then deity is not only partitioned"
      },
      {
        "start": 721.139,
        "duration": 6.361,
        "text": "but also replicated as my as many times"
      },
      {
        "start": 724.56,
        "duration": 5.339,
        "text": "as you define in replication Factor so"
      },
      {
        "start": 727.5,
        "duration": 5.7,
        "text": "you see this data on the left left"
      },
      {
        "start": 729.899,
        "duration": 6.06,
        "text": "bottom bottom part are exactly the same"
      },
      {
        "start": 733.2,
        "duration": 4.62,
        "text": "rows exactly the same partitions but"
      },
      {
        "start": 735.959,
        "duration": 4.021,
        "text": "they are stored on the multiple servers"
      },
      {
        "start": 737.82,
        "duration": 4.56,
        "text": "because you want your customers want"
      },
      {
        "start": 739.98,
        "duration": 6.32,
        "text": "your application to be always available"
      },
      {
        "start": 742.38,
        "duration": 3.92,
        "text": "and that's what Cassandra does"
      },
      {
        "start": 746.459,
        "duration": 5.401,
        "text": "data organization"
      },
      {
        "start": 748.68,
        "duration": 6.06,
        "text": "we briefly discussed already so data"
      },
      {
        "start": 751.86,
        "duration": 4.86,
        "text": "organization organized a cell included"
      },
      {
        "start": 754.74,
        "duration": 4.8,
        "text": "in the row in the partition in the table"
      },
      {
        "start": 756.72,
        "duration": 5.52,
        "text": "in the key space key space is a logical"
      },
      {
        "start": 759.54,
        "duration": 6.0,
        "text": "group of tables and some other settings"
      },
      {
        "start": 762.24,
        "duration": 5.12,
        "text": "user definer types grouping at all"
      },
      {
        "start": 765.54,
        "duration": 5.039,
        "text": "logically"
      },
      {
        "start": 767.36,
        "duration": 6.219,
        "text": "tables organized into rows and columns"
      },
      {
        "start": 770.579,
        "duration": 4.921,
        "text": "and groups of related rows call it"
      },
      {
        "start": 773.579,
        "duration": 5.341,
        "text": "partitions what are store it together"
      },
      {
        "start": 775.5,
        "duration": 5.82,
        "text": "and that is a very important feature for"
      },
      {
        "start": 778.92,
        "duration": 3.78,
        "text": "both good and bad for restrictions and"
      },
      {
        "start": 781.32,
        "duration": 3.959,
        "text": "for power"
      },
      {
        "start": 782.7,
        "duration": 4.68,
        "text": "each row contains a partition key you"
      },
      {
        "start": 785.279,
        "duration": 3.781,
        "text": "cannot store data without petrifying a"
      },
      {
        "start": 787.38,
        "duration": 3.72,
        "text": "partition key it's technically not"
      },
      {
        "start": 789.06,
        "duration": 4.7,
        "text": "possible cluster will just not know"
      },
      {
        "start": 791.1,
        "duration": 5.88,
        "text": "where to put your data"
      },
      {
        "start": 793.76,
        "duration": 5.62,
        "text": "starting working with Cassandra first"
      },
      {
        "start": 796.98,
        "duration": 5.7,
        "text": "thing you have to do is to create a key"
      },
      {
        "start": 799.38,
        "duration": 5.94,
        "text": "space how do you create a key space very"
      },
      {
        "start": 802.68,
        "duration": 5.7,
        "text": "easy there here you see SQL statement"
      },
      {
        "start": 805.32,
        "duration": 5.639,
        "text": "Cassandra query language statement what"
      },
      {
        "start": 808.38,
        "duration": 5.34,
        "text": "creates key space and a Cassandra query"
      },
      {
        "start": 810.959,
        "duration": 6.241,
        "text": "language is designed specifically to be"
      },
      {
        "start": 813.72,
        "duration": 6.359,
        "text": "as close to SQL as possible to be just"
      },
      {
        "start": 817.2,
        "duration": 5.579,
        "text": "more familiar to every developer in the"
      },
      {
        "start": 820.079,
        "duration": 5.521,
        "text": "world when you create a key space"
      },
      {
        "start": 822.779,
        "duration": 6.0,
        "text": "you have to specify its name"
      },
      {
        "start": 825.6,
        "duration": 5.88,
        "text": "quite obvious but uh that's typical for"
      },
      {
        "start": 828.779,
        "duration": 4.68,
        "text": "any database but also you have to"
      },
      {
        "start": 831.48,
        "duration": 5.219,
        "text": "explain replication you have to tell"
      },
      {
        "start": 833.459,
        "duration": 4.56,
        "text": "cluster how do you want it to handle"
      },
      {
        "start": 836.699,
        "duration": 4.101,
        "text": "this data"
      },
      {
        "start": 838.019,
        "duration": 5.221,
        "text": "you have to define a replication"
      },
      {
        "start": 840.8,
        "duration": 5.62,
        "text": "strategy class and you have to Define"
      },
      {
        "start": 843.24,
        "duration": 6.42,
        "text": "replication Factor so replication"
      },
      {
        "start": 846.42,
        "duration": 5.4,
        "text": "strategy class is a very basically you"
      },
      {
        "start": 849.66,
        "duration": 5.34,
        "text": "have two options networked apology"
      },
      {
        "start": 851.82,
        "duration": 5.879,
        "text": "strategy and simple strategy"
      },
      {
        "start": 855.0,
        "duration": 5.88,
        "text": "so not a lot of shirts simple strategy"
      },
      {
        "start": 857.699,
        "duration": 5.961,
        "text": "is good for your laptop and bad for"
      },
      {
        "start": 860.88,
        "duration": 5.399,
        "text": "anything else you use Simple topology"
      },
      {
        "start": 863.66,
        "duration": 5.38,
        "text": "strategy simple strategy for your laptop"
      },
      {
        "start": 866.279,
        "duration": 5.821,
        "text": "for development environment maybe for"
      },
      {
        "start": 869.04,
        "duration": 5.039,
        "text": "test uh scenarios maybe some for develop"
      },
      {
        "start": 872.1,
        "duration": 4.919,
        "text": "yeah for development environment maybe"
      },
      {
        "start": 874.079,
        "duration": 4.741,
        "text": "is for some kind of development servers"
      },
      {
        "start": 877.019,
        "duration": 3.661,
        "text": "but you definitely don't go to"
      },
      {
        "start": 878.82,
        "duration": 3.48,
        "text": "production with simple strategy with"
      },
      {
        "start": 880.68,
        "duration": 5.04,
        "text": "simple strategy"
      },
      {
        "start": 882.3,
        "duration": 7.08,
        "text": "Network topology strategy is a vice"
      },
      {
        "start": 885.72,
        "duration": 6.6,
        "text": "versa for production placements and for"
      },
      {
        "start": 889.38,
        "duration": 5.34,
        "text": "uh your staging maybe environment"
      },
      {
        "start": 892.32,
        "duration": 5.16,
        "text": "because it's a very cool Advanced"
      },
      {
        "start": 894.72,
        "duration": 3.84,
        "text": "strategy it does really a lot of work"
      },
      {
        "start": 897.48,
        "duration": 4.919,
        "text": "for you"
      },
      {
        "start": 898.56,
        "duration": 6.18,
        "text": "take a look on the lines uh for the data"
      },
      {
        "start": 902.399,
        "duration": 5.581,
        "text": "centers here you see your United States"
      },
      {
        "start": 904.74,
        "duration": 5.52,
        "text": "West one Europe Central One those are"
      },
      {
        "start": 907.98,
        "duration": 4.26,
        "text": "data centers names of your data centers"
      },
      {
        "start": 910.26,
        "duration": 4.259,
        "text": "for different companies you will have"
      },
      {
        "start": 912.24,
        "duration": 4.38,
        "text": "different data centers names right and"
      },
      {
        "start": 914.519,
        "duration": 4.26,
        "text": "you say what for United States West one"
      },
      {
        "start": 916.62,
        "duration": 4.8,
        "text": "I want to have replication Factor free"
      },
      {
        "start": 918.779,
        "duration": 5.161,
        "text": "for the Europe Central one I want to"
      },
      {
        "start": 921.42,
        "duration": 3.779,
        "text": "have replication Factor 5 for whatever"
      },
      {
        "start": 923.94,
        "duration": 4.019,
        "text": "reason"
      },
      {
        "start": 925.199,
        "duration": 6.621,
        "text": "and he comes Network topology strategy"
      },
      {
        "start": 927.959,
        "duration": 6.661,
        "text": "what it does it takes your um"
      },
      {
        "start": 931.82,
        "duration": 5.5,
        "text": "replication Factor Define it and puts"
      },
      {
        "start": 934.62,
        "duration": 6.54,
        "text": "the data in the way what it will be"
      },
      {
        "start": 937.32,
        "duration": 6.54,
        "text": "located within single data center but on"
      },
      {
        "start": 941.16,
        "duration": 6.0,
        "text": "the multiple different server racks or"
      },
      {
        "start": 943.86,
        "duration": 5.76,
        "text": "if you use clouds so it will be the same"
      },
      {
        "start": 947.16,
        "duration": 6.239,
        "text": "region for example United States West"
      },
      {
        "start": 949.62,
        "duration": 6.6,
        "text": "one but different availability zones you"
      },
      {
        "start": 953.399,
        "duration": 4.74,
        "text": "understand why it's happening again your"
      },
      {
        "start": 956.22,
        "duration": 4.679,
        "text": "customers want your application to be"
      },
      {
        "start": 958.139,
        "duration": 5.581,
        "text": "available always when we use networked"
      },
      {
        "start": 960.899,
        "duration": 5.221,
        "text": "apology strategym it's a very Advanced"
      },
      {
        "start": 963.72,
        "duration": 5.34,
        "text": "thing what key what takes care of"
      },
      {
        "start": 966.12,
        "duration": 5.279,
        "text": "keeping your replicas not together but"
      },
      {
        "start": 969.06,
        "duration": 5.579,
        "text": "as far from which hour as possible"
      },
      {
        "start": 971.399,
        "duration": 6.0,
        "text": "within one data center or region why it"
      },
      {
        "start": 974.639,
        "duration": 5.301,
        "text": "matters the story is availability zone"
      },
      {
        "start": 977.399,
        "duration": 5.341,
        "text": "of a cloudflower provider can get down"
      },
      {
        "start": 979.94,
        "duration": 5.62,
        "text": "if all of your replicas were Within"
      },
      {
        "start": 982.74,
        "duration": 5.58,
        "text": "These um availability Zone what will"
      },
      {
        "start": 985.56,
        "duration": 5.82,
        "text": "happen your data will be unavailable"
      },
      {
        "start": 988.32,
        "duration": 4.98,
        "text": "same happens with your data center on"
      },
      {
        "start": 991.38,
        "duration": 4.92,
        "text": "the in the data center you have multiple"
      },
      {
        "start": 993.3,
        "duration": 5.88,
        "text": "server racks but servers within single"
      },
      {
        "start": 996.3,
        "duration": 5.279,
        "text": "server Rec are also"
      },
      {
        "start": 999.18,
        "duration": 5.04,
        "text": "vulnerable to the same issues for"
      },
      {
        "start": 1001.579,
        "duration": 5.281,
        "text": "example if power outage for a single"
      },
      {
        "start": 1004.22,
        "duration": 5.16,
        "text": "server Rack or network outage the wall"
      },
      {
        "start": 1006.86,
        "duration": 4.979,
        "text": "server rack will become unavailable so"
      },
      {
        "start": 1009.38,
        "duration": 4.56,
        "text": "you need to have your replicas on the"
      },
      {
        "start": 1011.839,
        "duration": 3.781,
        "text": "different server racks or on the"
      },
      {
        "start": 1013.94,
        "duration": 3.54,
        "text": "different availability zones of the"
      },
      {
        "start": 1015.62,
        "duration": 3.959,
        "text": "cloud and that is a very important and"
      },
      {
        "start": 1017.48,
        "duration": 4.38,
        "text": "network topology does it for you"
      },
      {
        "start": 1019.579,
        "duration": 3.961,
        "text": "absolutely transparently so you don't"
      },
      {
        "start": 1021.86,
        "duration": 3.599,
        "text": "have to take care of that isn't that"
      },
      {
        "start": 1023.54,
        "duration": 5.279,
        "text": "amazing"
      },
      {
        "start": 1025.459,
        "duration": 5.821,
        "text": "uh then very uh common misconception"
      },
      {
        "start": 1028.819,
        "duration": 4.441,
        "text": "what I see very often is what people"
      },
      {
        "start": 1031.28,
        "duration": 5.519,
        "text": "start to do weird things with Fair"
      },
      {
        "start": 1033.26,
        "duration": 6.419,
        "text": "replication they try to Define all the"
      },
      {
        "start": 1036.799,
        "duration": 5.52,
        "text": "data centers they have uh in the list of"
      },
      {
        "start": 1039.679,
        "duration": 5.701,
        "text": "these replication story but that's not"
      },
      {
        "start": 1042.319,
        "duration": 5.701,
        "text": "exactly right take a look I can have a"
      },
      {
        "start": 1045.38,
        "duration": 5.039,
        "text": "dozen of data centers all across the"
      },
      {
        "start": 1048.02,
        "duration": 6.3,
        "text": "world Europe Central One Europe Central"
      },
      {
        "start": 1050.419,
        "duration": 5.941,
        "text": "to Europe East three uh whatever I don't"
      },
      {
        "start": 1054.32,
        "duration": 4.26,
        "text": "know Asia and so on you don't have to"
      },
      {
        "start": 1056.36,
        "duration": 4.8,
        "text": "specify all of them here here you"
      },
      {
        "start": 1058.58,
        "duration": 5.82,
        "text": "specify only data centers what you want"
      },
      {
        "start": 1061.16,
        "duration": 5.28,
        "text": "to take care of this data for this case"
      },
      {
        "start": 1064.4,
        "duration": 4.5,
        "text": "space it will be United States and"
      },
      {
        "start": 1066.44,
        "duration": 6.0,
        "text": "Europe for another key space for example"
      },
      {
        "start": 1068.9,
        "duration": 6.54,
        "text": "I don't want to keep data anywhere I"
      },
      {
        "start": 1072.44,
        "duration": 6.0,
        "text": "need it only on your in a Europa Central"
      },
      {
        "start": 1075.44,
        "duration": 5.34,
        "text": "one so I don't specify Us West and I"
      },
      {
        "start": 1078.44,
        "duration": 3.599,
        "text": "have only data replicated to a single"
      },
      {
        "start": 1080.78,
        "duration": 4.74,
        "text": "Data Center"
      },
      {
        "start": 1082.039,
        "duration": 5.341,
        "text": "well it decreases availability of the"
      },
      {
        "start": 1085.52,
        "duration": 4.82,
        "text": "data because availability will be then"
      },
      {
        "start": 1087.38,
        "duration": 5.7,
        "text": "available to only one single Data Center"
      },
      {
        "start": 1090.34,
        "duration": 5.199,
        "text": "so you may have to consider different"
      },
      {
        "start": 1093.08,
        "duration": 4.979,
        "text": "scenarios for different kinds of data"
      },
      {
        "start": 1095.539,
        "duration": 5.281,
        "text": "you are working with"
      },
      {
        "start": 1098.059,
        "duration": 6.541,
        "text": "that must be quite obvious when we"
      },
      {
        "start": 1100.82,
        "duration": 6.479,
        "text": "create a table we have to specify key"
      },
      {
        "start": 1104.6,
        "duration": 5.04,
        "text": "space we are going to use a table name"
      },
      {
        "start": 1107.299,
        "duration": 5.401,
        "text": "also quite of this"
      },
      {
        "start": 1109.64,
        "duration": 5.76,
        "text": "um columns with pair types and we have"
      },
      {
        "start": 1112.7,
        "duration": 5.04,
        "text": "to Define primary gamer or key which"
      },
      {
        "start": 1115.4,
        "duration": 4.8,
        "text": "consists of a network of partition key"
      },
      {
        "start": 1117.74,
        "duration": 4.319,
        "text": "and clustering columns those are"
      },
      {
        "start": 1120.2,
        "duration": 4.92,
        "text": "extremely important so we will speak a"
      },
      {
        "start": 1122.059,
        "duration": 5.281,
        "text": "lot about it today that's a much more"
      },
      {
        "start": 1125.12,
        "duration": 4.26,
        "text": "advanced thing and very much more"
      },
      {
        "start": 1127.34,
        "duration": 5.48,
        "text": "important thing than you use it to think"
      },
      {
        "start": 1129.38,
        "duration": 3.44,
        "text": "in relational databases"
      },
      {
        "start": 1133.36,
        "duration": 7.3,
        "text": "and here we go atom"
      },
      {
        "start": 1138.08,
        "duration": 4.92,
        "text": "let's create as a let's create database"
      },
      {
        "start": 1140.66,
        "duration": 6.08,
        "text": "we will work with"
      },
      {
        "start": 1143.0,
        "duration": 7.5,
        "text": "maybe you have it done already"
      },
      {
        "start": 1146.74,
        "duration": 7.48,
        "text": "yes so we will create a new database in"
      },
      {
        "start": 1150.5,
        "duration": 6.6,
        "text": "the srdb if you already have created the"
      },
      {
        "start": 1154.22,
        "duration": 5.339,
        "text": "database previously then you may need to"
      },
      {
        "start": 1157.1,
        "duration": 4.92,
        "text": "create a new key space or maybe you"
      },
      {
        "start": 1159.559,
        "duration": 4.261,
        "text": "already have it from the are you sharing"
      },
      {
        "start": 1162.02,
        "duration": 4.1,
        "text": "your screen sorry are you sharing your"
      },
      {
        "start": 1163.82,
        "duration": 2.3,
        "text": "screen"
      },
      {
        "start": 1166.539,
        "duration": 4.721,
        "text": "uh yes"
      },
      {
        "start": 1169.52,
        "duration": 3.899,
        "text": "um"
      },
      {
        "start": 1171.26,
        "duration": 5.48,
        "text": "yeah because I see the slides but we"
      },
      {
        "start": 1173.419,
        "duration": 3.321,
        "text": "will need your screen I guess"
      },
      {
        "start": 1177.559,
        "duration": 2.541,
        "text": "okay"
      },
      {
        "start": 1181.64,
        "duration": 6.36,
        "text": "so yeah to start yes to start you will"
      },
      {
        "start": 1185.48,
        "duration": 6.6,
        "text": "have to um"
      },
      {
        "start": 1188.0,
        "duration": 6.179,
        "text": "uh go to the link that is on GitHub you"
      },
      {
        "start": 1192.08,
        "duration": 4.14,
        "text": "can see it in the chat"
      },
      {
        "start": 1194.179,
        "duration": 5.581,
        "text": "so it's uh"
      },
      {
        "start": 1196.22,
        "duration": 5.459,
        "text": "a link that will bring you to this web"
      },
      {
        "start": 1199.76,
        "duration": 3.539,
        "text": "page readme file"
      },
      {
        "start": 1201.679,
        "duration": 4.88,
        "text": "and here"
      },
      {
        "start": 1203.299,
        "duration": 5.941,
        "text": "we will be creating new"
      },
      {
        "start": 1206.559,
        "duration": 5.041,
        "text": "asterdb instance or using the previous"
      },
      {
        "start": 1209.24,
        "duration": 2.36,
        "text": "one"
      },
      {
        "start": 1216.82,
        "duration": 4.979,
        "text": "so this is uh"
      },
      {
        "start": 1223.52,
        "duration": 5.82,
        "text": "sorry it didn't work as expected okay so"
      },
      {
        "start": 1226.76,
        "duration": 3.659,
        "text": "we're going to create a new assadb"
      },
      {
        "start": 1229.34,
        "duration": 5.459,
        "text": "instance"
      },
      {
        "start": 1230.419,
        "duration": 7.021,
        "text": "what is srdb it's it's a cloud service"
      },
      {
        "start": 1234.799,
        "duration": 5.581,
        "text": "Cloud database service that is built"
      },
      {
        "start": 1237.44,
        "duration": 6.479,
        "text": "based on Apache Cassandra"
      },
      {
        "start": 1240.38,
        "duration": 5.94,
        "text": "um you can click the create s3dp and you"
      },
      {
        "start": 1243.919,
        "duration": 5.581,
        "text": "will have a screen where you will be"
      },
      {
        "start": 1246.32,
        "duration": 7.68,
        "text": "able to either sign up or sign in I'm"
      },
      {
        "start": 1249.5,
        "duration": 7.919,
        "text": "already signed in into mine account and"
      },
      {
        "start": 1254.0,
        "duration": 6.44,
        "text": "I have uh some other hibernated database"
      },
      {
        "start": 1257.419,
        "duration": 6.0,
        "text": "here but I will create a new one"
      },
      {
        "start": 1260.44,
        "duration": 6.58,
        "text": "following the instructions so I will"
      },
      {
        "start": 1263.419,
        "duration": 5.941,
        "text": "click create serverless database"
      },
      {
        "start": 1267.02,
        "duration": 5.159,
        "text": "and we'll create"
      },
      {
        "start": 1269.36,
        "duration": 5.76,
        "text": "database called workshops"
      },
      {
        "start": 1272.179,
        "duration": 4.681,
        "text": "and the keyspace name that we want to"
      },
      {
        "start": 1275.12,
        "duration": 5.46,
        "text": "use and you already know what key space"
      },
      {
        "start": 1276.86,
        "duration": 5.699,
        "text": "is Alex talked about it just recently so"
      },
      {
        "start": 1280.58,
        "duration": 6.12,
        "text": "it's going to be"
      },
      {
        "start": 1282.559,
        "duration": 7.681,
        "text": "sensor underscore data"
      },
      {
        "start": 1286.7,
        "duration": 6.0,
        "text": "okay we also need to select the provider"
      },
      {
        "start": 1290.24,
        "duration": 4.34,
        "text": "and region we are going to use Google"
      },
      {
        "start": 1292.7,
        "duration": 4.92,
        "text": "cloud and"
      },
      {
        "start": 1294.58,
        "duration": 7.479,
        "text": "in my case it's going to be North"
      },
      {
        "start": 1297.62,
        "duration": 7.26,
        "text": "America and I need to select one of the"
      },
      {
        "start": 1302.059,
        "duration": 5.041,
        "text": "regions that is not logged I'm also"
      },
      {
        "start": 1304.88,
        "duration": 6.179,
        "text": "using free account just like you"
      },
      {
        "start": 1307.1,
        "duration": 8.819,
        "text": "so in this case this is South Carolina"
      },
      {
        "start": 1311.059,
        "duration": 8.341,
        "text": "and I can click create database and it"
      },
      {
        "start": 1315.919,
        "duration": 8.541,
        "text": "will take a couple of minutes"
      },
      {
        "start": 1319.4,
        "duration": 5.06,
        "text": "to get created so we will be able to"
      },
      {
        "start": 1324.94,
        "duration": 6.66,
        "text": "use it later for the next Lab but at"
      },
      {
        "start": 1329.24,
        "duration": 2.36,
        "text": "this point"
      },
      {
        "start": 1331.64,
        "duration": 3.62,
        "text": "it's finishing up"
      },
      {
        "start": 1337.94,
        "duration": 5.119,
        "text": "okay"
      },
      {
        "start": 1339.44,
        "duration": 3.619,
        "text": "well it says it's uh"
      },
      {
        "start": 1346.94,
        "duration": 6.54,
        "text": "the the status is still pending so we"
      },
      {
        "start": 1349.82,
        "duration": 6.02,
        "text": "will wait and while we wait in uh we can"
      },
      {
        "start": 1353.48,
        "duration": 2.36,
        "text": "continue"
      },
      {
        "start": 1356.179,
        "duration": 4.161,
        "text": "with the next topic"
      },
      {
        "start": 1363.02,
        "duration": 5.639,
        "text": "okay so the next topic I will talk about"
      },
      {
        "start": 1365.0,
        "duration": 6.12,
        "text": "uh key definitions and and and you've"
      },
      {
        "start": 1368.659,
        "duration": 4.561,
        "text": "already seen some of those things but we"
      },
      {
        "start": 1371.12,
        "duration": 4.32,
        "text": "will still repeat what is primary key"
      },
      {
        "start": 1373.22,
        "duration": 5.819,
        "text": "what is partition key what is clustering"
      },
      {
        "start": 1375.44,
        "duration": 6.18,
        "text": "key because this is essentially very"
      },
      {
        "start": 1379.039,
        "duration": 5.76,
        "text": "very important and essential for for"
      },
      {
        "start": 1381.62,
        "duration": 5.82,
        "text": "schema design right and schema design is"
      },
      {
        "start": 1384.799,
        "duration": 5.301,
        "text": "part of the data modeling process"
      },
      {
        "start": 1387.44,
        "duration": 2.66,
        "text": "so"
      },
      {
        "start": 1390.559,
        "duration": 5.941,
        "text": "this table in this example"
      },
      {
        "start": 1393.799,
        "duration": 6.12,
        "text": "um that you that you may seen already in"
      },
      {
        "start": 1396.5,
        "duration": 5.58,
        "text": "in the last Workshop we have uh primary"
      },
      {
        "start": 1399.919,
        "duration": 5.041,
        "text": "key definition here that consists of"
      },
      {
        "start": 1402.08,
        "duration": 5.76,
        "text": "partition key and clustering key so the"
      },
      {
        "start": 1404.96,
        "duration": 5.4,
        "text": "the role of the partition key is to"
      },
      {
        "start": 1407.84,
        "duration": 5.64,
        "text": "uniquely identify a partition within a"
      },
      {
        "start": 1410.36,
        "duration": 6.66,
        "text": "table but also as you know already that"
      },
      {
        "start": 1413.48,
        "duration": 6.179,
        "text": "partition key is responsible for it for"
      },
      {
        "start": 1417.02,
        "duration": 6.96,
        "text": "for data distribution strategy so it"
      },
      {
        "start": 1419.659,
        "duration": 7.26,
        "text": "defines which nodes and replicas will"
      },
      {
        "start": 1423.98,
        "duration": 4.679,
        "text": "get that particular partition we'll"
      },
      {
        "start": 1426.919,
        "duration": 3.481,
        "text": "store it and we'll serve it we'll"
      },
      {
        "start": 1428.659,
        "duration": 2.941,
        "text": "retrieve it send it back to the"
      },
      {
        "start": 1430.4,
        "duration": 3.96,
        "text": "application"
      },
      {
        "start": 1431.6,
        "duration": 6.78,
        "text": "okay so how you Define partition key"
      },
      {
        "start": 1434.36,
        "duration": 6.179,
        "text": "will be will Define not only uniqueness"
      },
      {
        "start": 1438.38,
        "duration": 4.26,
        "text": "of the partition but also how the data"
      },
      {
        "start": 1440.539,
        "duration": 3.781,
        "text": "will be distributed and that's that's"
      },
      {
        "start": 1442.64,
        "duration": 5.7,
        "text": "very important so"
      },
      {
        "start": 1444.32,
        "duration": 5.7,
        "text": "in this example uh where we have sensor"
      },
      {
        "start": 1448.34,
        "duration": 6.26,
        "text": "as a partition key"
      },
      {
        "start": 1450.02,
        "duration": 4.58,
        "text": "and timestamp as a clustering column"
      },
      {
        "start": 1457.46,
        "duration": 8.28,
        "text": "okay in in in this case"
      },
      {
        "start": 1461.799,
        "duration": 7.961,
        "text": "uh the the sensor ID itself will Define"
      },
      {
        "start": 1465.74,
        "duration": 6.419,
        "text": "the the partition and"
      },
      {
        "start": 1469.76,
        "duration": 6.18,
        "text": "um in other words"
      },
      {
        "start": 1472.159,
        "duration": 6.601,
        "text": "all data that generated by that sensor"
      },
      {
        "start": 1475.94,
        "duration": 4.92,
        "text": "will be stored in that one partition but"
      },
      {
        "start": 1478.76,
        "duration": 4.82,
        "text": "we if you look at the last example where"
      },
      {
        "start": 1480.86,
        "duration": 6.059,
        "text": "we have sensor and timestamp together"
      },
      {
        "start": 1483.58,
        "duration": 4.479,
        "text": "this is composite partition key then in"
      },
      {
        "start": 1486.919,
        "duration": 3.781,
        "text": "this case"
      },
      {
        "start": 1488.059,
        "duration": 6.061,
        "text": "science sensor and timestamp will always"
      },
      {
        "start": 1490.7,
        "duration": 7.68,
        "text": "be unique each sensor generates only one"
      },
      {
        "start": 1494.12,
        "duration": 6.72,
        "text": "Baler for a given timestamp then"
      },
      {
        "start": 1498.38,
        "duration": 6.84,
        "text": "each partition will essentially contain"
      },
      {
        "start": 1500.84,
        "duration": 6.42,
        "text": "just one single row okay while in the in"
      },
      {
        "start": 1505.22,
        "duration": 5.4,
        "text": "the first example we have a multi-row"
      },
      {
        "start": 1507.26,
        "duration": 5.34,
        "text": "partitions here we have a single row"
      },
      {
        "start": 1510.62,
        "duration": 4.74,
        "text": "partition for the example where I have"
      },
      {
        "start": 1512.6,
        "duration": 3.959,
        "text": "we have both sensor and timestamp as a"
      },
      {
        "start": 1515.36,
        "duration": 3.48,
        "text": "partition key"
      },
      {
        "start": 1516.559,
        "duration": 6.36,
        "text": "now besides the partition key primary"
      },
      {
        "start": 1518.84,
        "duration": 4.079,
        "text": "key consists of optional"
      },
      {
        "start": 1523.48,
        "duration": 4.12,
        "text": "clustering key or sometimes we just say"
      },
      {
        "start": 1525.98,
        "duration": 5.22,
        "text": "clustering columns"
      },
      {
        "start": 1527.6,
        "duration": 5.22,
        "text": "and the purpose of clustering columns so"
      },
      {
        "start": 1531.2,
        "duration": 4.38,
        "text": "if you have clustering columns a"
      },
      {
        "start": 1532.82,
        "duration": 5.16,
        "text": "clustering key then your partition can"
      },
      {
        "start": 1535.58,
        "duration": 6.5,
        "text": "have multiple rows so it's a multi row"
      },
      {
        "start": 1537.98,
        "duration": 7.799,
        "text": "partition and clustering key uniquely"
      },
      {
        "start": 1542.08,
        "duration": 6.04,
        "text": "identifies a row within a partition so"
      },
      {
        "start": 1545.779,
        "duration": 4.861,
        "text": "that's one purpose to ensure uniqueness"
      },
      {
        "start": 1548.12,
        "duration": 6.059,
        "text": "within of that row within the partition"
      },
      {
        "start": 1550.64,
        "duration": 7.08,
        "text": "but the second purpose is also sort in"
      },
      {
        "start": 1554.179,
        "duration": 6.961,
        "text": "order so as you know tables are stored"
      },
      {
        "start": 1557.72,
        "duration": 5.459,
        "text": "as as as a stables internally so they"
      },
      {
        "start": 1561.14,
        "duration": 5.1,
        "text": "assorted strings how they assorted they"
      },
      {
        "start": 1563.179,
        "duration": 6.5,
        "text": "assorted based on on clustering columns"
      },
      {
        "start": 1566.24,
        "duration": 7.38,
        "text": "so it's clustering columns will Define"
      },
      {
        "start": 1569.679,
        "duration": 6.521,
        "text": "uh the physical ordering on disk and"
      },
      {
        "start": 1573.62,
        "duration": 4.86,
        "text": "when you retrieve the data when you"
      },
      {
        "start": 1576.2,
        "duration": 5.339,
        "text": "retrieve that partition you will be able"
      },
      {
        "start": 1578.48,
        "duration": 5.819,
        "text": "to get that order that you specified or"
      },
      {
        "start": 1581.539,
        "duration": 4.62,
        "text": "you can reverse it so if you need your"
      },
      {
        "start": 1584.299,
        "duration": 3.661,
        "text": "data sorted you need to use you need to"
      },
      {
        "start": 1586.159,
        "duration": 3.721,
        "text": "think about classing columns how you use"
      },
      {
        "start": 1587.96,
        "duration": 4.5,
        "text": "them and whether they will be what kind"
      },
      {
        "start": 1589.88,
        "duration": 5.64,
        "text": "of cluster in order you will use whether"
      },
      {
        "start": 1592.46,
        "duration": 5.339,
        "text": "it's descending or ascending I I want to"
      },
      {
        "start": 1595.52,
        "duration": 5.1,
        "text": "step sorry I want to step in here for a"
      },
      {
        "start": 1597.799,
        "duration": 6.061,
        "text": "moment regarding sorting"
      },
      {
        "start": 1600.62,
        "duration": 6.9,
        "text": "um sure yep uh so the story is when"
      },
      {
        "start": 1603.86,
        "duration": 6.24,
        "text": "coming from relational databases you use"
      },
      {
        "start": 1607.52,
        "duration": 5.46,
        "text": "it to be able to sort data by any field"
      },
      {
        "start": 1610.1,
        "duration": 7.38,
        "text": "you use it to be able to filter data by"
      },
      {
        "start": 1612.98,
        "duration": 8.28,
        "text": "any field and you take it as given"
      },
      {
        "start": 1617.48,
        "duration": 7.38,
        "text": "which is not always correct so we work"
      },
      {
        "start": 1621.26,
        "duration": 6.72,
        "text": "with the data of a very different sizes"
      },
      {
        "start": 1624.86,
        "duration": 6.36,
        "text": "usually we work with a data distributed"
      },
      {
        "start": 1627.98,
        "duration": 5.88,
        "text": "over hundreds of servers over multiple"
      },
      {
        "start": 1631.22,
        "duration": 5.939,
        "text": "continents and the long story short"
      },
      {
        "start": 1633.86,
        "duration": 6.059,
        "text": "sorting in sorting data of this size"
      },
      {
        "start": 1637.159,
        "duration": 6.181,
        "text": "over multiple servers over multiple"
      },
      {
        "start": 1639.919,
        "duration": 6.12,
        "text": "continents is totally not easy but still"
      },
      {
        "start": 1643.34,
        "duration": 4.74,
        "text": "Cassandra can return your data sorted"
      },
      {
        "start": 1646.039,
        "duration": 3.961,
        "text": "extremely quickly"
      },
      {
        "start": 1648.08,
        "duration": 4.94,
        "text": "how it happens"
      },
      {
        "start": 1650.0,
        "duration": 5.46,
        "text": "that is a part of our course at the"
      },
      {
        "start": 1653.02,
        "duration": 4.659,
        "text": "academy.datastags.com it's a free course"
      },
      {
        "start": 1655.46,
        "duration": 5.699,
        "text": "so it's not really an advertising for it"
      },
      {
        "start": 1657.679,
        "duration": 5.641,
        "text": "but yes it is despite its free it's also"
      },
      {
        "start": 1661.159,
        "duration": 4.321,
        "text": "very important for you to get this one"
      },
      {
        "start": 1663.32,
        "duration": 3.9,
        "text": "to get real understanding and get ready"
      },
      {
        "start": 1665.48,
        "duration": 4.679,
        "text": "for the certification for Apache"
      },
      {
        "start": 1667.22,
        "duration": 5.339,
        "text": "Cassandra which data Stacks sponsors so"
      },
      {
        "start": 1670.159,
        "duration": 4.981,
        "text": "Vivas you can get certified in Apache"
      },
      {
        "start": 1672.559,
        "duration": 5.34,
        "text": "Cassandra totally for free now getting"
      },
      {
        "start": 1675.14,
        "duration": 4.86,
        "text": "to the Sorting part clustering columns"
      },
      {
        "start": 1677.899,
        "duration": 4.801,
        "text": "are very important because they Define"
      },
      {
        "start": 1680.0,
        "duration": 6.0,
        "text": "this sorting and on the way how data"
      },
      {
        "start": 1682.7,
        "duration": 5.459,
        "text": "will be stored on right time so when you"
      },
      {
        "start": 1686.0,
        "duration": 4.86,
        "text": "are going to retrieve this data on read"
      },
      {
        "start": 1688.159,
        "duration": 5.221,
        "text": "time it will be sorted already and there"
      },
      {
        "start": 1690.86,
        "duration": 4.86,
        "text": "will be no need for Cassandra to change"
      },
      {
        "start": 1693.38,
        "duration": 5.039,
        "text": "anything as it sorted already just"
      },
      {
        "start": 1695.72,
        "duration": 5.819,
        "text": "return this data back and we are done"
      },
      {
        "start": 1698.419,
        "duration": 6.421,
        "text": "so good thing it's even for sorting"
      },
      {
        "start": 1701.539,
        "duration": 6.601,
        "text": "extremely quickly bad thing you can sort"
      },
      {
        "start": 1704.84,
        "duration": 6.6,
        "text": "data as you will see soon only based on"
      },
      {
        "start": 1708.14,
        "duration": 6.0,
        "text": "the clustering columns you cannot sort"
      },
      {
        "start": 1711.44,
        "duration": 6.3,
        "text": "in this case in this example you cannot"
      },
      {
        "start": 1714.14,
        "duration": 8.06,
        "text": "sort data by value without using some"
      },
      {
        "start": 1717.74,
        "duration": 4.46,
        "text": "nasty hacks we recommend you not to use"
      },
      {
        "start": 1722.299,
        "duration": 5.341,
        "text": "right and it's important to remember"
      },
      {
        "start": 1725.059,
        "duration": 5.041,
        "text": "that sorting is defined within a"
      },
      {
        "start": 1727.64,
        "duration": 3.779,
        "text": "partition not within the whole table so"
      },
      {
        "start": 1730.1,
        "duration": 3.6,
        "text": "if you're going to retrieve more than"
      },
      {
        "start": 1731.419,
        "duration": 4.62,
        "text": "one partition then the Sorting order is"
      },
      {
        "start": 1733.7,
        "duration": 3.359,
        "text": "going to break so but if you return one"
      },
      {
        "start": 1736.039,
        "duration": 3.601,
        "text": "partition"
      },
      {
        "start": 1737.059,
        "duration": 4.74,
        "text": "and you have clustering key there and"
      },
      {
        "start": 1739.64,
        "duration": 4.919,
        "text": "clustering order Define then you will"
      },
      {
        "start": 1741.799,
        "duration": 5.401,
        "text": "get the the rows in that partition"
      },
      {
        "start": 1744.559,
        "duration": 5.1,
        "text": "within that partition sorted so in this"
      },
      {
        "start": 1747.2,
        "duration": 4.979,
        "text": "example of course every time we design"
      },
      {
        "start": 1749.659,
        "duration": 4.5,
        "text": "primary key we're thinking about how we"
      },
      {
        "start": 1752.179,
        "duration": 4.38,
        "text": "going to access data are we going to"
      },
      {
        "start": 1754.159,
        "duration": 5.941,
        "text": "create it and design our table and"
      },
      {
        "start": 1756.559,
        "duration": 7.1,
        "text": "primary key base on uh based on that"
      },
      {
        "start": 1760.1,
        "duration": 6.12,
        "text": "query so in this example if we say that"
      },
      {
        "start": 1763.659,
        "duration": 5.681,
        "text": "sensor is the partition key there is no"
      },
      {
        "start": 1766.22,
        "duration": 4.5,
        "text": "question key and we try to store"
      },
      {
        "start": 1769.34,
        "duration": 3.78,
        "text": "temperature"
      },
      {
        "start": 1770.72,
        "duration": 6.54,
        "text": "Baler some kind of Valor that that"
      },
      {
        "start": 1773.12,
        "duration": 7.02,
        "text": "sensor gen generates then each time we"
      },
      {
        "start": 1777.26,
        "duration": 5.58,
        "text": "will add that we will write into that"
      },
      {
        "start": 1780.14,
        "duration": 6.06,
        "text": "table for that sensor we will basically"
      },
      {
        "start": 1782.84,
        "duration": 5.78,
        "text": "absurd the previous failure because uh"
      },
      {
        "start": 1786.2,
        "duration": 6.959,
        "text": "the the there is no class and key"
      },
      {
        "start": 1788.62,
        "duration": 6.46,
        "text": "nothing to distinguish the rows are not"
      },
      {
        "start": 1793.159,
        "duration": 3.841,
        "text": "unique so each each time so it's"
      },
      {
        "start": 1795.08,
        "duration": 4.26,
        "text": "basically a table with singular"
      },
      {
        "start": 1797.0,
        "duration": 7.32,
        "text": "operations for each sensor there is only"
      },
      {
        "start": 1799.34,
        "duration": 6.48,
        "text": "one partition with one row there so this"
      },
      {
        "start": 1804.32,
        "duration": 4.5,
        "text": "is not going to be a good design if you"
      },
      {
        "start": 1805.82,
        "duration": 5.579,
        "text": "try to store values if we try to store"
      },
      {
        "start": 1808.82,
        "duration": 5.88,
        "text": "if you also uh"
      },
      {
        "start": 1811.399,
        "duration": 6.361,
        "text": "um for example our query would be store"
      },
      {
        "start": 1814.7,
        "duration": 5.099,
        "text": "all the values generated by"
      },
      {
        "start": 1817.76,
        "duration": 5.46,
        "text": "um or retrieve all the Bell is generated"
      },
      {
        "start": 1819.799,
        "duration": 6.961,
        "text": "by a sensor and"
      },
      {
        "start": 1823.22,
        "duration": 6.66,
        "text": "filter the based on dates for example"
      },
      {
        "start": 1826.76,
        "duration": 6.72,
        "text": "specify the date range how you want to"
      },
      {
        "start": 1829.88,
        "duration": 7.38,
        "text": "retrieve that data so in this case if we"
      },
      {
        "start": 1833.48,
        "duration": 7.28,
        "text": "add timestamp to this primary key as a"
      },
      {
        "start": 1837.26,
        "duration": 5.94,
        "text": "clustering column then we kind of"
      },
      {
        "start": 1840.76,
        "duration": 5.74,
        "text": "solving the problem of uniqueness"
      },
      {
        "start": 1843.2,
        "duration": 6.12,
        "text": "because now each time each sensor can"
      },
      {
        "start": 1846.5,
        "duration": 5.34,
        "text": "only generate better with with a unique"
      },
      {
        "start": 1849.32,
        "duration": 4.44,
        "text": "timestamp and then the next failure will"
      },
      {
        "start": 1851.84,
        "duration": 4.92,
        "text": "have a different time stamp"
      },
      {
        "start": 1853.76,
        "duration": 6.539,
        "text": "so in this case we guarantee that we"
      },
      {
        "start": 1856.76,
        "duration": 6.32,
        "text": "will not have absurds but we it's it's a"
      },
      {
        "start": 1860.299,
        "duration": 2.781,
        "text": "little bit harder to"
      },
      {
        "start": 1863.38,
        "duration": 5.919,
        "text": "retrieve that data based on date it's"
      },
      {
        "start": 1866.659,
        "duration": 6.36,
        "text": "still possible but you can replace date"
      },
      {
        "start": 1869.299,
        "duration": 7.561,
        "text": "with timestamps but it may not be the"
      },
      {
        "start": 1873.019,
        "duration": 7.621,
        "text": "the 100 easiest solution now the third"
      },
      {
        "start": 1876.86,
        "duration": 7.02,
        "text": "example here is not good because we also"
      },
      {
        "start": 1880.64,
        "duration": 7.08,
        "text": "add in value into this clustering column"
      },
      {
        "start": 1883.88,
        "duration": 6.779,
        "text": "so you can think so the failure so all"
      },
      {
        "start": 1887.72,
        "duration": 5.64,
        "text": "the data are generated by this by each"
      },
      {
        "start": 1890.659,
        "duration": 5.4,
        "text": "by by a sensor will be sorted based on"
      },
      {
        "start": 1893.36,
        "duration": 5.96,
        "text": "failure first and only then based on"
      },
      {
        "start": 1896.059,
        "duration": 5.46,
        "text": "time steps so we will not be able to uh"
      },
      {
        "start": 1899.32,
        "duration": 4.56,
        "text": "uniqueness is there but we will not be"
      },
      {
        "start": 1901.519,
        "duration": 5.101,
        "text": "able to filter based on dates correctly"
      },
      {
        "start": 1903.88,
        "duration": 7.24,
        "text": "and then the last one"
      },
      {
        "start": 1906.62,
        "duration": 7.62,
        "text": "is probably the best example for uh the"
      },
      {
        "start": 1911.12,
        "duration": 7.74,
        "text": "uh this particular query uh we are going"
      },
      {
        "start": 1914.24,
        "duration": 7.319,
        "text": "to retrieve data for a particular sensor"
      },
      {
        "start": 1918.86,
        "duration": 5.039,
        "text": "do the range search on dates and and"
      },
      {
        "start": 1921.559,
        "duration": 4.86,
        "text": "timestamp is there to guarantee"
      },
      {
        "start": 1923.899,
        "duration": 4.321,
        "text": "uniqueness"
      },
      {
        "start": 1926.419,
        "duration": 3.961,
        "text": "okay"
      },
      {
        "start": 1928.22,
        "duration": 4.14,
        "text": "so uh"
      },
      {
        "start": 1930.38,
        "duration": 6.72,
        "text": "together"
      },
      {
        "start": 1932.36,
        "duration": 6.78,
        "text": "the primary key consists of of mandatory"
      },
      {
        "start": 1937.1,
        "duration": 4.799,
        "text": "partition key and optional clustering"
      },
      {
        "start": 1939.14,
        "duration": 6.659,
        "text": "key but together primary key gives you"
      },
      {
        "start": 1941.899,
        "duration": 7.561,
        "text": "uniqueness overall within a table right"
      },
      {
        "start": 1945.799,
        "duration": 6.841,
        "text": "remember partition Keys is the unique"
      },
      {
        "start": 1949.46,
        "duration": 5.339,
        "text": "identifies partition within a table a"
      },
      {
        "start": 1952.64,
        "duration": 5.58,
        "text": "clustering key uniquely advice row visit"
      },
      {
        "start": 1954.799,
        "duration": 5.581,
        "text": "table and a row within a partition a"
      },
      {
        "start": 1958.22,
        "duration": 4.98,
        "text": "primary key you need a device row within"
      },
      {
        "start": 1960.38,
        "duration": 7.38,
        "text": "a table"
      },
      {
        "start": 1963.2,
        "duration": 8.579,
        "text": "okay so partition Keys like we already"
      },
      {
        "start": 1967.76,
        "duration": 5.7,
        "text": "talked about they they Define uh data"
      },
      {
        "start": 1971.779,
        "duration": 5.581,
        "text": "distribution of a cluster that's"
      },
      {
        "start": 1973.46,
        "duration": 6.66,
        "text": "important to remember uh so it's it's"
      },
      {
        "start": 1977.36,
        "duration": 5.22,
        "text": "you need so you will need when you"
      },
      {
        "start": 1980.12,
        "duration": 7.26,
        "text": "design primary key you need to design it"
      },
      {
        "start": 1982.58,
        "duration": 7.74,
        "text": "for specific uh query so to for example"
      },
      {
        "start": 1987.38,
        "duration": 6.24,
        "text": "support retrieving data based on sensor"
      },
      {
        "start": 1990.32,
        "duration": 6.42,
        "text": "ID and date but they also need to think"
      },
      {
        "start": 1993.62,
        "duration": 4.98,
        "text": "about the how that data will be"
      },
      {
        "start": 1996.74,
        "duration": 4.679,
        "text": "partitioned based on that specific"
      },
      {
        "start": 1998.6,
        "duration": 5.76,
        "text": "partition key and clusting columns like"
      },
      {
        "start": 2001.419,
        "duration": 5.36,
        "text": "we said they Define sorted how the data"
      },
      {
        "start": 2004.36,
        "duration": 5.039,
        "text": "is sorted on disk"
      },
      {
        "start": 2006.779,
        "duration": 5.561,
        "text": "literally physically so you can retrieve"
      },
      {
        "start": 2009.399,
        "duration": 6.78,
        "text": "in that order or you can reserve uh you"
      },
      {
        "start": 2012.34,
        "duration": 6.6,
        "text": "can reverse that order so"
      },
      {
        "start": 2016.179,
        "duration": 4.681,
        "text": "um for this example where we have"
      },
      {
        "start": 2018.94,
        "duration": 4.739,
        "text": "primary key that consists of partition"
      },
      {
        "start": 2020.86,
        "duration": 5.819,
        "text": "kit sensor and date and clustering key"
      },
      {
        "start": 2023.679,
        "duration": 6.061,
        "text": "timestamp what kind what types of fees"
      },
      {
        "start": 2026.679,
        "duration": 5.701,
        "text": "we can we can do over this table we can"
      },
      {
        "start": 2029.74,
        "duration": 4.319,
        "text": "we cannot for example retrieve data for"
      },
      {
        "start": 2032.38,
        "duration": 4.26,
        "text": "one particular sensor"
      },
      {
        "start": 2034.059,
        "duration": 5.1,
        "text": "because we cannot query based on partial"
      },
      {
        "start": 2036.64,
        "duration": 6.84,
        "text": "partition key so we will have to specify"
      },
      {
        "start": 2039.159,
        "duration": 6.0,
        "text": "both sensor and date we cannot same we"
      },
      {
        "start": 2043.48,
        "duration": 4.079,
        "text": "cannot do the sensor greater than"
      },
      {
        "start": 2045.159,
        "duration": 4.401,
        "text": "something we cannot use partial"
      },
      {
        "start": 2047.559,
        "duration": 5.52,
        "text": "partition key"
      },
      {
        "start": 2049.56,
        "duration": 7.059,
        "text": "subset of partition key we cannot ever"
      },
      {
        "start": 2053.079,
        "duration": 6.6,
        "text": "use inequality like greater than on a"
      },
      {
        "start": 2056.619,
        "duration": 4.74,
        "text": "partition key column so that's not going"
      },
      {
        "start": 2059.679,
        "duration": 3.72,
        "text": "to work either even here we're using"
      },
      {
        "start": 2061.359,
        "duration": 5.181,
        "text": "sensor and data together inequality is"
      },
      {
        "start": 2063.399,
        "duration": 7.26,
        "text": "not going to work so types of"
      },
      {
        "start": 2066.54,
        "duration": 6.76,
        "text": "periods of predicated we can Define"
      },
      {
        "start": 2070.659,
        "duration": 4.801,
        "text": "here for this specific"
      },
      {
        "start": 2073.3,
        "duration": 4.92,
        "text": "primary key we can we will have to"
      },
      {
        "start": 2075.46,
        "duration": 6.02,
        "text": "specify sensor and date"
      },
      {
        "start": 2078.22,
        "duration": 6.179,
        "text": "and we we can also specify time State"
      },
      {
        "start": 2081.48,
        "duration": 4.48,
        "text": "timestamp using either equality or"
      },
      {
        "start": 2084.399,
        "duration": 4.321,
        "text": "inequality search"
      },
      {
        "start": 2085.96,
        "duration": 5.639,
        "text": "okay so the the one of the consequences"
      },
      {
        "start": 2088.72,
        "duration": 7.08,
        "text": "of defining your primary key the way you"
      },
      {
        "start": 2091.599,
        "duration": 7.321,
        "text": "define it besides the distribution data"
      },
      {
        "start": 2095.8,
        "duration": 5.76,
        "text": "distribution and sorting will be cql"
      },
      {
        "start": 2098.92,
        "duration": 4.32,
        "text": "queries what types of queries you can"
      },
      {
        "start": 2101.56,
        "duration": 5.16,
        "text": "deal"
      },
      {
        "start": 2103.24,
        "duration": 5.339,
        "text": "okay another consequence is schema"
      },
      {
        "start": 2106.72,
        "duration": 4.2,
        "text": "immutability once you define your"
      },
      {
        "start": 2108.579,
        "duration": 5.52,
        "text": "primary key you cannot change it you"
      },
      {
        "start": 2110.92,
        "duration": 6.54,
        "text": "cannot just alter that key you can add"
      },
      {
        "start": 2114.099,
        "duration": 5.461,
        "text": "some other columns that will not be part"
      },
      {
        "start": 2117.46,
        "duration": 4.619,
        "text": "of the primary key but the primary key"
      },
      {
        "start": 2119.56,
        "duration": 5.1,
        "text": "is something that you do not want you"
      },
      {
        "start": 2122.079,
        "duration": 3.961,
        "text": "you cannot change and there is a again a"
      },
      {
        "start": 2124.66,
        "duration": 4.08,
        "text": "good reason for that we're dealing with"
      },
      {
        "start": 2126.04,
        "duration": 6.42,
        "text": "with large data set"
      },
      {
        "start": 2128.74,
        "duration": 6.42,
        "text": "um that is spread over multiple nodes uh"
      },
      {
        "start": 2132.46,
        "duration": 6.18,
        "text": "across many nodes in in your cluster and"
      },
      {
        "start": 2135.16,
        "duration": 6.72,
        "text": "and possibly multiple data centers that"
      },
      {
        "start": 2138.64,
        "duration": 6.12,
        "text": "communicate uh over Network and they may"
      },
      {
        "start": 2141.88,
        "duration": 4.739,
        "text": "be in different parts of the world so in"
      },
      {
        "start": 2144.76,
        "duration": 5.28,
        "text": "that case if you"
      },
      {
        "start": 2146.619,
        "duration": 5.701,
        "text": "if if you change the the primary key"
      },
      {
        "start": 2150.04,
        "duration": 4.5,
        "text": "then you will basically have to"
      },
      {
        "start": 2152.32,
        "duration": 5.22,
        "text": "redistribute your data right basically"
      },
      {
        "start": 2154.54,
        "duration": 6.42,
        "text": "changing redistribute and and sort it"
      },
      {
        "start": 2157.54,
        "duration": 6.24,
        "text": "differently possibly so that's not a"
      },
      {
        "start": 2160.96,
        "duration": 4.8,
        "text": "good uh thing to do when you're dealing"
      },
      {
        "start": 2163.78,
        "duration": 3.72,
        "text": "with large data sets so if if you do"
      },
      {
        "start": 2165.76,
        "duration": 4.319,
        "text": "find yourself needing to change"
      },
      {
        "start": 2167.5,
        "duration": 5.7,
        "text": "something in primary key you will have"
      },
      {
        "start": 2170.079,
        "duration": 5.04,
        "text": "to drop the table or you will have to"
      },
      {
        "start": 2173.2,
        "duration": 4.379,
        "text": "create a new table first with new"
      },
      {
        "start": 2175.119,
        "duration": 4.74,
        "text": "primary key transfer the data and then"
      },
      {
        "start": 2177.579,
        "duration": 4.801,
        "text": "drop the all table but usually you want"
      },
      {
        "start": 2179.859,
        "duration": 5.701,
        "text": "to design your table right"
      },
      {
        "start": 2182.38,
        "duration": 5.16,
        "text": "correctly right away now a question that"
      },
      {
        "start": 2185.56,
        "duration": 4.5,
        "text": "we frequently get is why don't we use"
      },
      {
        "start": 2187.54,
        "duration": 5.28,
        "text": "sequential IDs in Cassandra something"
      },
      {
        "start": 2190.06,
        "duration": 5.039,
        "text": "like Auto increment"
      },
      {
        "start": 2192.82,
        "duration": 4.56,
        "text": "and again this is this is actually not a"
      },
      {
        "start": 2195.099,
        "duration": 6.24,
        "text": "Cassandra thing this is a any"
      },
      {
        "start": 2197.38,
        "duration": 7.92,
        "text": "distributed system saying that it's not"
      },
      {
        "start": 2201.339,
        "duration": 6.301,
        "text": "easy to maintain that sequence to"
      },
      {
        "start": 2205.3,
        "duration": 6.539,
        "text": "because you have multiple nodes in your"
      },
      {
        "start": 2207.64,
        "duration": 5.959,
        "text": "cluster each one can generate a new ID"
      },
      {
        "start": 2211.839,
        "duration": 5.161,
        "text": "and and"
      },
      {
        "start": 2213.599,
        "duration": 5.74,
        "text": "if if you want the sequence then all of"
      },
      {
        "start": 2217.0,
        "duration": 3.66,
        "text": "those nodes have to communicate to agree"
      },
      {
        "start": 2219.339,
        "duration": 5.28,
        "text": "on"
      },
      {
        "start": 2220.66,
        "duration": 6.419,
        "text": "um on the next available ID to use for"
      },
      {
        "start": 2224.619,
        "duration": 4.381,
        "text": "when I when you insert in the row so in"
      },
      {
        "start": 2227.079,
        "duration": 4.801,
        "text": "MySQL for example you can use Auto"
      },
      {
        "start": 2229.0,
        "duration": 6.72,
        "text": "increment which is sometimes convenient"
      },
      {
        "start": 2231.88,
        "duration": 7.56,
        "text": "it's it's artificial surrogate ID which"
      },
      {
        "start": 2235.72,
        "duration": 5.7,
        "text": "just generates a sequence of numbers but"
      },
      {
        "start": 2239.44,
        "duration": 5.28,
        "text": "in case of Cassandra and and most"
      },
      {
        "start": 2241.42,
        "duration": 6.179,
        "text": "distributed systems we're using uuids"
      },
      {
        "start": 2244.72,
        "duration": 6.119,
        "text": "and time viewing these so those are two"
      },
      {
        "start": 2247.599,
        "duration": 6.361,
        "text": "different types of uids and essentially"
      },
      {
        "start": 2250.839,
        "duration": 5.041,
        "text": "each any node can generate that uid or"
      },
      {
        "start": 2253.96,
        "duration": 4.8,
        "text": "your application can generate that uad"
      },
      {
        "start": 2255.88,
        "duration": 5.76,
        "text": "very quickly efficiently and and"
      },
      {
        "start": 2258.76,
        "duration": 4.68,
        "text": "guaranteed that there will be no uh"
      },
      {
        "start": 2261.64,
        "duration": 5.34,
        "text": "conflict between"
      },
      {
        "start": 2263.44,
        "duration": 7.679,
        "text": "uh those different ideas generated by"
      },
      {
        "start": 2266.98,
        "duration": 7.619,
        "text": "different nodes Okay so"
      },
      {
        "start": 2271.119,
        "duration": 5.161,
        "text": "and the next topic the the rules for"
      },
      {
        "start": 2274.599,
        "duration": 5.821,
        "text": "good partitioning I don't know if Alex"
      },
      {
        "start": 2276.28,
        "duration": 6.78,
        "text": "wants to yep I would love to it's one of"
      },
      {
        "start": 2280.42,
        "duration": 7.5,
        "text": "my favorite topics you know so give me a"
      },
      {
        "start": 2283.06,
        "duration": 6.68,
        "text": "moment to switch back to myself"
      },
      {
        "start": 2287.92,
        "duration": 5.12,
        "text": "boom"
      },
      {
        "start": 2289.74,
        "duration": 3.3,
        "text": "[Music]"
      },
      {
        "start": 2293.74,
        "duration": 7.74,
        "text": "yes we are good uh so uh first of all I"
      },
      {
        "start": 2298.66,
        "duration": 5.52,
        "text": "had to ask are you guys listening as"
      },
      {
        "start": 2301.48,
        "duration": 4.92,
        "text": "well because I see in the YouTube chat"
      },
      {
        "start": 2304.18,
        "duration": 3.54,
        "text": "some people are mentioning mentioning"
      },
      {
        "start": 2306.4,
        "duration": 3.84,
        "text": "buffering"
      },
      {
        "start": 2307.72,
        "duration": 5.94,
        "text": "I don't know on which side it is because"
      },
      {
        "start": 2310.24,
        "duration": 6.42,
        "text": "YouTube shows me a excellent stream"
      },
      {
        "start": 2313.66,
        "duration": 6.06,
        "text": "status excellent all green all positive"
      },
      {
        "start": 2316.66,
        "duration": 5.939,
        "text": "streaming software shows me some minor"
      },
      {
        "start": 2319.72,
        "duration": 5.22,
        "text": "issues so if you can hear us oh yeah"
      },
      {
        "start": 2322.599,
        "duration": 4.921,
        "text": "it's bearable thank you Sumit"
      },
      {
        "start": 2324.94,
        "duration": 5.22,
        "text": "uh so let's proceed then"
      },
      {
        "start": 2327.52,
        "duration": 3.44,
        "text": "good so"
      },
      {
        "start": 2330.16,
        "duration": 4.439,
        "text": "um"
      },
      {
        "start": 2330.96,
        "duration": 6.399,
        "text": "three uh very important rules of a good"
      },
      {
        "start": 2334.599,
        "duration": 4.801,
        "text": "partition just free so it's easy to"
      },
      {
        "start": 2337.359,
        "duration": 3.72,
        "text": "learn them all but very important to"
      },
      {
        "start": 2339.4,
        "duration": 5.34,
        "text": "follow"
      },
      {
        "start": 2341.079,
        "duration": 6.241,
        "text": "um we will work on this example which is"
      },
      {
        "start": 2344.74,
        "duration": 5.22,
        "text": "familiar to you already we will work"
      },
      {
        "start": 2347.32,
        "duration": 3.9,
        "text": "with a table of a data temperatures by"
      },
      {
        "start": 2349.96,
        "duration": 4.139,
        "text": "sensor"
      },
      {
        "start": 2351.22,
        "duration": 6.78,
        "text": "table definition is quite simple we"
      },
      {
        "start": 2354.099,
        "duration": 8.161,
        "text": "store sensor day timestamp value that's"
      },
      {
        "start": 2358.0,
        "duration": 5.0,
        "text": "it so text date timestamp flawed solve"
      },
      {
        "start": 2362.26,
        "duration": 3.72,
        "text": "it"
      },
      {
        "start": 2363.0,
        "duration": 6.22,
        "text": "but working with Cassandra you should"
      },
      {
        "start": 2365.98,
        "duration": 5.94,
        "text": "not forget what author were wide part of"
      },
      {
        "start": 2369.22,
        "duration": 5.52,
        "text": "the table amount of columns may be low"
      },
      {
        "start": 2371.92,
        "duration": 5.22,
        "text": "amount of data in this parallelists in"
      },
      {
        "start": 2374.74,
        "duration": 4.2,
        "text": "this table can be extremely big like"
      },
      {
        "start": 2377.14,
        "duration": 2.88,
        "text": "very very long"
      },
      {
        "start": 2378.94,
        "duration": 4.82,
        "text": "so"
      },
      {
        "start": 2380.02,
        "duration": 3.74,
        "text": "let's take a look at few things"
      },
      {
        "start": 2386.56,
        "duration": 3.42,
        "text": "uh store together what you retrieve"
      },
      {
        "start": 2388.78,
        "duration": 3.36,
        "text": "together"
      },
      {
        "start": 2389.98,
        "duration": 4.8,
        "text": "avoid big partitions"
      },
      {
        "start": 2392.14,
        "duration": 5.16,
        "text": "avoid Port partitions only three things"
      },
      {
        "start": 2394.78,
        "duration": 4.799,
        "text": "you have to remember but you have to"
      },
      {
        "start": 2397.3,
        "duration": 5.46,
        "text": "remember it very very well"
      },
      {
        "start": 2399.579,
        "duration": 7.321,
        "text": "Let's Take on the example"
      },
      {
        "start": 2402.76,
        "duration": 6.42,
        "text": "when their do not store together what"
      },
      {
        "start": 2406.9,
        "duration": 6.06,
        "text": "you retrieve together"
      },
      {
        "start": 2409.18,
        "duration": 5.88,
        "text": "for example we make a partition key you"
      },
      {
        "start": 2412.96,
        "duration": 4.92,
        "text": "see in this case both sensor and"
      },
      {
        "start": 2415.06,
        "duration": 6.0,
        "text": "timestamp will be parts of a partition"
      },
      {
        "start": 2417.88,
        "duration": 6.54,
        "text": "key for this table"
      },
      {
        "start": 2421.06,
        "duration": 6.779,
        "text": "what will happen then we will have as"
      },
      {
        "start": 2424.42,
        "duration": 7.439,
        "text": "much partitions as much records we will"
      },
      {
        "start": 2427.839,
        "duration": 7.321,
        "text": "have because sensor ID which is always"
      },
      {
        "start": 2431.859,
        "duration": 6.96,
        "text": "the same per sensor and timestamp which"
      },
      {
        "start": 2435.16,
        "duration": 6.06,
        "text": "is always new per record"
      },
      {
        "start": 2438.819,
        "duration": 4.921,
        "text": "uh timestamp will be changing all the"
      },
      {
        "start": 2441.22,
        "duration": 8.58,
        "text": "time they will be hashed together and as"
      },
      {
        "start": 2443.74,
        "duration": 8.339,
        "text": "a result you will have cash always new"
      },
      {
        "start": 2449.8,
        "duration": 5.64,
        "text": "and you will have as much partitions as"
      },
      {
        "start": 2452.079,
        "duration": 4.321,
        "text": "much records you have is that bad by"
      },
      {
        "start": 2455.44,
        "duration": 3.659,
        "text": "itself"
      },
      {
        "start": 2456.4,
        "duration": 5.16,
        "text": "it's not bad in Cassandra you can have"
      },
      {
        "start": 2459.099,
        "duration": 5.52,
        "text": "as much partitions as you would like to"
      },
      {
        "start": 2461.56,
        "duration": 6.96,
        "text": "not a problem what is the real problem"
      },
      {
        "start": 2464.619,
        "duration": 5.161,
        "text": "then real problem is on the retrieval"
      },
      {
        "start": 2468.52,
        "duration": 3.86,
        "text": "time"
      },
      {
        "start": 2469.78,
        "duration": 5.46,
        "text": "to get all of the data"
      },
      {
        "start": 2472.38,
        "duration": 5.8,
        "text": "for last week for example you want to"
      },
      {
        "start": 2475.24,
        "duration": 3.96,
        "text": "see a temperature of a sensor X for the"
      },
      {
        "start": 2478.18,
        "duration": 4.38,
        "text": "last week"
      },
      {
        "start": 2479.2,
        "duration": 5.58,
        "text": "sounds like a reasonable query right but"
      },
      {
        "start": 2482.56,
        "duration": 5.1,
        "text": "what will happen on the execution time"
      },
      {
        "start": 2484.78,
        "duration": 6.18,
        "text": "then you execute this query"
      },
      {
        "start": 2487.66,
        "duration": 6.6,
        "text": "don't forget querying data we have to"
      },
      {
        "start": 2490.96,
        "duration": 6.0,
        "text": "give all the parts of the"
      },
      {
        "start": 2494.26,
        "duration": 4.92,
        "text": "partition key that means what to"
      },
      {
        "start": 2496.96,
        "duration": 4.92,
        "text": "retrieve data we have to specify sensor"
      },
      {
        "start": 2499.18,
        "duration": 5.52,
        "text": "ID which we know mostly probably and"
      },
      {
        "start": 2501.88,
        "duration": 5.64,
        "text": "timestamps of all the records"
      },
      {
        "start": 2504.7,
        "duration": 5.159,
        "text": "first of all we don't know them"
      },
      {
        "start": 2507.52,
        "duration": 5.22,
        "text": "but even if we know them somehow"
      },
      {
        "start": 2509.859,
        "duration": 5.341,
        "text": "magically then as there's a different"
      },
      {
        "start": 2512.74,
        "duration": 4.8,
        "text": "partitions they can be stored on"
      },
      {
        "start": 2515.2,
        "duration": 4.8,
        "text": "different servers and therefore we will"
      },
      {
        "start": 2517.54,
        "duration": 5.52,
        "text": "have to reach as much servers as much"
      },
      {
        "start": 2520.0,
        "duration": 6.119,
        "text": "server stores your data and that is as"
      },
      {
        "start": 2523.06,
        "duration": 4.5,
        "text": "stupid as it sounds exactly"
      },
      {
        "start": 2526.119,
        "duration": 3.921,
        "text": "but"
      },
      {
        "start": 2527.56,
        "duration": 5.34,
        "text": "there is a second example"
      },
      {
        "start": 2530.04,
        "duration": 4.84,
        "text": "which is much better still have some"
      },
      {
        "start": 2532.9,
        "duration": 5.219,
        "text": "problems to be discussed on the next"
      },
      {
        "start": 2534.88,
        "duration": 6.0,
        "text": "slides but already much better sensor as"
      },
      {
        "start": 2538.119,
        "duration": 4.441,
        "text": "a partition key and timestamp as a"
      },
      {
        "start": 2540.88,
        "duration": 3.54,
        "text": "clustering column"
      },
      {
        "start": 2542.56,
        "duration": 5.64,
        "text": "what it gives to us"
      },
      {
        "start": 2544.42,
        "duration": 6.54,
        "text": "first of all data is grouped by sensor"
      },
      {
        "start": 2548.2,
        "duration": 6.72,
        "text": "that is good because if I want to see"
      },
      {
        "start": 2550.96,
        "duration": 8.82,
        "text": "data for sensor X on July 6th I have to"
      },
      {
        "start": 2554.92,
        "duration": 7.26,
        "text": "specify uh sensor ID which I know and"
      },
      {
        "start": 2559.78,
        "duration": 6.12,
        "text": "then as timestamp as a clustering column"
      },
      {
        "start": 2562.18,
        "duration": 7.74,
        "text": "I can use inequality predicates I can"
      },
      {
        "start": 2565.9,
        "duration": 7.5,
        "text": "say like before 6th of June like after"
      },
      {
        "start": 2569.92,
        "duration": 6.06,
        "text": "5th of July uh before 7th month of July"
      },
      {
        "start": 2573.4,
        "duration": 4.8,
        "text": "which will be my perfect single July for"
      },
      {
        "start": 2575.98,
        "duration": 4.32,
        "text": "example on the partition keys on the"
      },
      {
        "start": 2578.2,
        "duration": 4.919,
        "text": "previous example I cannot use"
      },
      {
        "start": 2580.3,
        "duration": 6.48,
        "text": "inequalities so I cannot make a range"
      },
      {
        "start": 2583.119,
        "duration": 6.181,
        "text": "bigger than lesser than if we go with a"
      },
      {
        "start": 2586.78,
        "duration": 6.12,
        "text": "primary key like this"
      },
      {
        "start": 2589.3,
        "duration": 6.779,
        "text": "so this one simply will not work"
      },
      {
        "start": 2592.9,
        "duration": 6.959,
        "text": "in this case we have data grouped by"
      },
      {
        "start": 2596.079,
        "duration": 7.981,
        "text": "sensor and order it by timestamp so boom"
      },
      {
        "start": 2599.859,
        "duration": 7.021,
        "text": "it's now solved and that helps me to"
      },
      {
        "start": 2604.06,
        "duration": 4.86,
        "text": "keep my data together and retrieve that"
      },
      {
        "start": 2606.88,
        "duration": 4.76,
        "text": "together because it's always stored on"
      },
      {
        "start": 2608.92,
        "duration": 5.88,
        "text": "the same server"
      },
      {
        "start": 2611.64,
        "duration": 6.06,
        "text": "we discussed that we rush thank you for"
      },
      {
        "start": 2614.8,
        "duration": 5.519,
        "text": "a good question we discussed it soon"
      },
      {
        "start": 2617.7,
        "duration": 5.2,
        "text": "then second question"
      },
      {
        "start": 2620.319,
        "duration": 6.481,
        "text": "avoid big partitions"
      },
      {
        "start": 2622.9,
        "duration": 6.66,
        "text": "first of all uh don't forget"
      },
      {
        "start": 2626.8,
        "duration": 5.519,
        "text": "what why do we do partition after all"
      },
      {
        "start": 2629.56,
        "duration": 5.34,
        "text": "why partition data we partition date"
      },
      {
        "start": 2632.319,
        "duration": 4.5,
        "text": "because sharding is very painful and"
      },
      {
        "start": 2634.9,
        "duration": 3.0,
        "text": "hard and we don't we want to avoid"
      },
      {
        "start": 2636.819,
        "duration": 2.161,
        "text": "sharding"
      },
      {
        "start": 2637.9,
        "duration": 4.199,
        "text": "so"
      },
      {
        "start": 2638.98,
        "duration": 4.98,
        "text": "we work with the data of a big size and"
      },
      {
        "start": 2642.099,
        "duration": 4.561,
        "text": "we split this data into chunks"
      },
      {
        "start": 2643.96,
        "duration": 5.22,
        "text": "partitions so they always will be"
      },
      {
        "start": 2646.66,
        "duration": 5.28,
        "text": "handleable but then you do two big"
      },
      {
        "start": 2649.18,
        "duration": 5.22,
        "text": "partition partition grow grow grow what"
      },
      {
        "start": 2651.94,
        "duration": 5.28,
        "text": "happens next boom you have the same"
      },
      {
        "start": 2654.4,
        "duration": 5.28,
        "text": "problem like you are tried to dodge just"
      },
      {
        "start": 2657.22,
        "duration": 4.92,
        "text": "before it's your partition to Big not"
      },
      {
        "start": 2659.68,
        "duration": 4.62,
        "text": "too wall table but the consequences are"
      },
      {
        "start": 2662.14,
        "duration": 4.74,
        "text": "exactly the same your database will be"
      },
      {
        "start": 2664.3,
        "duration": 6.059,
        "text": "slow it will be hard to impossible to"
      },
      {
        "start": 2666.88,
        "duration": 6.18,
        "text": "maintain it and so on and so forth so we"
      },
      {
        "start": 2670.359,
        "duration": 5.161,
        "text": "really have to think of how much data"
      },
      {
        "start": 2673.06,
        "duration": 5.759,
        "text": "you will have per partition"
      },
      {
        "start": 2675.52,
        "duration": 5.28,
        "text": "there are only one hard limit you cannot"
      },
      {
        "start": 2678.819,
        "duration": 4.621,
        "text": "have more than 2 billion cells per"
      },
      {
        "start": 2680.8,
        "duration": 6.9,
        "text": "partition so intersection intersections"
      },
      {
        "start": 2683.44,
        "duration": 7.02,
        "text": "of columns to rows but this is the only"
      },
      {
        "start": 2687.7,
        "duration": 5.94,
        "text": "hard partition our hard limit our"
      },
      {
        "start": 2690.46,
        "duration": 5.34,
        "text": "recommendation soft limit is not to have"
      },
      {
        "start": 2693.64,
        "duration": 5.28,
        "text": "more than 100"
      },
      {
        "start": 2695.8,
        "duration": 7.7,
        "text": "000 rows in a partition or a partition"
      },
      {
        "start": 2698.92,
        "duration": 8.399,
        "text": "to be a size of more than 100 megabytes"
      },
      {
        "start": 2703.5,
        "duration": 6.46,
        "text": "ah now how do we control it with our"
      },
      {
        "start": 2707.319,
        "duration": 5.581,
        "text": "partition Keys partition key can be"
      },
      {
        "start": 2709.96,
        "duration": 4.74,
        "text": "composite or compound and that means"
      },
      {
        "start": 2712.9,
        "duration": 4.439,
        "text": "what we can include multiple different"
      },
      {
        "start": 2714.7,
        "duration": 4.379,
        "text": "columns in the partition key you need to"
      },
      {
        "start": 2717.339,
        "duration": 6.301,
        "text": "keep it under control because don't"
      },
      {
        "start": 2719.079,
        "duration": 7.861,
        "text": "forget on the verra2 kinds of two ways"
      },
      {
        "start": 2723.64,
        "duration": 6.78,
        "text": "we access data when we write and when we"
      },
      {
        "start": 2726.94,
        "duration": 5.46,
        "text": "read when we write data we can put two"
      },
      {
        "start": 2730.42,
        "duration": 4.08,
        "text": "partition key basically whatever we"
      },
      {
        "start": 2732.4,
        "duration": 4.98,
        "text": "prefer whatever we know about this piece"
      },
      {
        "start": 2734.5,
        "duration": 5.7,
        "text": "of data will it work it will work we"
      },
      {
        "start": 2737.38,
        "duration": 5.16,
        "text": "will have small partitions but then on"
      },
      {
        "start": 2740.2,
        "duration": 4.379,
        "text": "the read time what will happen we will"
      },
      {
        "start": 2742.54,
        "duration": 5.1,
        "text": "again have to give all of everything"
      },
      {
        "start": 2744.579,
        "duration": 5.881,
        "text": "what we put into a partition key and"
      },
      {
        "start": 2747.64,
        "duration": 6.06,
        "text": "there's no going to be a lot of fun so"
      },
      {
        "start": 2750.46,
        "duration": 5.52,
        "text": "we need to keep our partition small but"
      },
      {
        "start": 2753.7,
        "duration": 4.8,
        "text": "not too small otherwise we will have"
      },
      {
        "start": 2755.98,
        "duration": 3.9,
        "text": "problems reading it"
      },
      {
        "start": 2758.5,
        "duration": 3.66,
        "text": "um let's take a look at the first"
      },
      {
        "start": 2759.88,
        "duration": 6.06,
        "text": "example sensor as a partition key"
      },
      {
        "start": 2762.16,
        "duration": 6.9,
        "text": "timestamp as a clustering column and you"
      },
      {
        "start": 2765.94,
        "duration": 5.52,
        "text": "may be now like what why wait Alex you"
      },
      {
        "start": 2769.06,
        "duration": 4.799,
        "text": "just told us previous slide what that is"
      },
      {
        "start": 2771.46,
        "duration": 4.619,
        "text": "a solution that is the right approach"
      },
      {
        "start": 2773.859,
        "duration": 4.5,
        "text": "like you remember previous slide store"
      },
      {
        "start": 2776.079,
        "duration": 5.04,
        "text": "together what you retrieve together you"
      },
      {
        "start": 2778.359,
        "duration": 6.061,
        "text": "group data by sensor sort by timestamp"
      },
      {
        "start": 2781.119,
        "duration": 6.181,
        "text": "and you are good is that right approach"
      },
      {
        "start": 2784.42,
        "duration": 5.22,
        "text": "uh there is a checkbox but it's gray not"
      },
      {
        "start": 2787.3,
        "duration": 5.34,
        "text": "green because it is the right approach"
      },
      {
        "start": 2789.64,
        "duration": 5.34,
        "text": "but you can have different scenarios and"
      },
      {
        "start": 2792.64,
        "duration": 3.84,
        "text": "that's not always the right answer"
      },
      {
        "start": 2794.98,
        "duration": 5.7,
        "text": "take a look"
      },
      {
        "start": 2796.48,
        "duration": 5.099,
        "text": "if you have your data written once in a"
      },
      {
        "start": 2800.68,
        "duration": 4.679,
        "text": "day"
      },
      {
        "start": 2801.579,
        "duration": 7.081,
        "text": "once in a week once in a month then this"
      },
      {
        "start": 2805.359,
        "duration": 5.581,
        "text": "approach can perfectly work grouping by"
      },
      {
        "start": 2808.66,
        "duration": 5.34,
        "text": "sensor partitioning by sensor because"
      },
      {
        "start": 2810.94,
        "duration": 5.46,
        "text": "you have your data once in a week then"
      },
      {
        "start": 2814.0,
        "duration": 6.96,
        "text": "therefore in a couple of years you will"
      },
      {
        "start": 2816.4,
        "duration": 7.02,
        "text": "have like 100 and something records in"
      },
      {
        "start": 2820.96,
        "duration": 5.399,
        "text": "six years you will have 600 records per"
      },
      {
        "start": 2823.42,
        "duration": 6.3,
        "text": "partition it's totally fine but imagine"
      },
      {
        "start": 2826.359,
        "duration": 6.781,
        "text": "you have your record storing every 10"
      },
      {
        "start": 2829.72,
        "duration": 6.48,
        "text": "seconds 5 Seconds every second that's"
      },
      {
        "start": 2833.14,
        "duration": 5.64,
        "text": "also happening in iot World totally"
      },
      {
        "start": 2836.2,
        "duration": 4.26,
        "text": "what will you do then your partitions"
      },
      {
        "start": 2838.78,
        "duration": 4.079,
        "text": "will grow over time"
      },
      {
        "start": 2840.46,
        "duration": 6.24,
        "text": "so then you store all the data for a"
      },
      {
        "start": 2842.859,
        "duration": 6.541,
        "text": "sensor uh restoring it every second and"
      },
      {
        "start": 2846.7,
        "duration": 4.32,
        "text": "your sensor runs for years what will"
      },
      {
        "start": 2849.4,
        "duration": 4.14,
        "text": "happen with this partition over time"
      },
      {
        "start": 2851.02,
        "duration": 5.88,
        "text": "nothing good will happen with this"
      },
      {
        "start": 2853.54,
        "duration": 6.48,
        "text": "partition Cassandra has some tools to"
      },
      {
        "start": 2856.9,
        "duration": 5.4,
        "text": "discard old data so-called TTL time to"
      },
      {
        "start": 2860.02,
        "duration": 4.38,
        "text": "leave so creating a record you can"
      },
      {
        "start": 2862.3,
        "duration": 5.34,
        "text": "specify I want this record to be"
      },
      {
        "start": 2864.4,
        "duration": 5.699,
        "text": "automatically deleted after one month"
      },
      {
        "start": 2867.64,
        "duration": 5.04,
        "text": "but what if you want your data to be"
      },
      {
        "start": 2870.099,
        "duration": 5.701,
        "text": "available after years for example you"
      },
      {
        "start": 2872.68,
        "duration": 5.52,
        "text": "have strict audit audit requirements"
      },
      {
        "start": 2875.8,
        "duration": 4.319,
        "text": "from government or whatever"
      },
      {
        "start": 2878.2,
        "duration": 4.56,
        "text": "so you have to store data for a long"
      },
      {
        "start": 2880.119,
        "duration": 6.781,
        "text": "period you cannot delete it with time to"
      },
      {
        "start": 2882.76,
        "duration": 6.839,
        "text": "leave uh property but uh we still have"
      },
      {
        "start": 2886.9,
        "duration": 4.919,
        "text": "to handle it somehow very easy we make"
      },
      {
        "start": 2889.599,
        "duration": 7.041,
        "text": "these compound partition key which"
      },
      {
        "start": 2891.819,
        "duration": 7.74,
        "text": "stores sensor and also some value"
      },
      {
        "start": 2896.64,
        "duration": 5.86,
        "text": "depending on the period you want to"
      },
      {
        "start": 2899.559,
        "duration": 5.28,
        "text": "store data in a group it can be our if"
      },
      {
        "start": 2902.5,
        "duration": 5.819,
        "text": "you have really a lot of Rights per"
      },
      {
        "start": 2904.839,
        "duration": 5.52,
        "text": "sensor per second it can be they it can"
      },
      {
        "start": 2908.319,
        "duration": 6.0,
        "text": "be weak it can be month it can be here"
      },
      {
        "start": 2910.359,
        "duration": 6.061,
        "text": "it depends on the amount of writings per"
      },
      {
        "start": 2914.319,
        "duration": 4.921,
        "text": "this period of time"
      },
      {
        "start": 2916.42,
        "duration": 5.76,
        "text": "in this case for example I want to group"
      },
      {
        "start": 2919.24,
        "duration": 6.119,
        "text": "them by month remember bigger the"
      },
      {
        "start": 2922.18,
        "duration": 5.22,
        "text": "partition easier to read but it will"
      },
      {
        "start": 2925.359,
        "duration": 4.74,
        "text": "cost you a lot of partition becomes too"
      },
      {
        "start": 2927.4,
        "duration": 5.219,
        "text": "big so don't make partitions too small"
      },
      {
        "start": 2930.099,
        "duration": 4.98,
        "text": "it will strike back on the read time"
      },
      {
        "start": 2932.619,
        "duration": 5.22,
        "text": "keep them reasonably small and we"
      },
      {
        "start": 2935.079,
        "duration": 5.04,
        "text": "recommend to stick to 100 000 values in"
      },
      {
        "start": 2937.839,
        "duration": 4.861,
        "text": "Partition up to 100 megabytes in"
      },
      {
        "start": 2940.119,
        "duration": 5.101,
        "text": "Partition in this particular case I"
      },
      {
        "start": 2942.7,
        "duration": 5.04,
        "text": "don't care about the size because the"
      },
      {
        "start": 2945.22,
        "duration": 5.879,
        "text": "data we are working with is text date"
      },
      {
        "start": 2947.74,
        "duration": 6.24,
        "text": "timestamp float so each row will have"
      },
      {
        "start": 2951.099,
        "duration": 6.421,
        "text": "really small footprint"
      },
      {
        "start": 2953.98,
        "duration": 6.56,
        "text": "but in general the amount of rows can"
      },
      {
        "start": 2957.52,
        "duration": 3.02,
        "text": "definitely become problem"
      },
      {
        "start": 2960.819,
        "duration": 6.661,
        "text": "um yeah so bucketing is usually it's"
      },
      {
        "start": 2964.18,
        "duration": 7.379,
        "text": "called when you use a totally artificial"
      },
      {
        "start": 2967.48,
        "duration": 7.94,
        "text": "key for grouping in this case month like"
      },
      {
        "start": 2971.559,
        "duration": 7.26,
        "text": "for example that is a July of year 2022"
      },
      {
        "start": 2975.42,
        "duration": 7.48,
        "text": "this month value can be strict string"
      },
      {
        "start": 2978.819,
        "duration": 9.0,
        "text": "can be integer doesn't matter will be uh"
      },
      {
        "start": 2982.9,
        "duration": 9.12,
        "text": "two zero two two zero seven year 2022 a"
      },
      {
        "start": 2987.819,
        "duration": 5.161,
        "text": "seven month a month uh seventh month"
      },
      {
        "start": 2992.02,
        "duration": 3.059,
        "text": "um"
      },
      {
        "start": 2992.98,
        "duration": 4.98,
        "text": "and that's not totally artificial"
      },
      {
        "start": 2995.079,
        "duration": 6.78,
        "text": "Bitcoin because it comes from timestamp"
      },
      {
        "start": 2997.96,
        "duration": 5.82,
        "text": "uh but it's also not like we usually"
      },
      {
        "start": 3001.859,
        "duration": 4.381,
        "text": "speak about bucketing"
      },
      {
        "start": 3003.78,
        "duration": 5.18,
        "text": "okay"
      },
      {
        "start": 3006.24,
        "duration": 7.8,
        "text": "and finally avoid what part partitions"
      },
      {
        "start": 3008.96,
        "duration": 8.56,
        "text": "that I have to give credits uh a totally"
      },
      {
        "start": 3014.04,
        "duration": 5.94,
        "text": "great example introduced by uh Cedric"
      },
      {
        "start": 3017.52,
        "duration": 4.86,
        "text": "lunvin and Cedric thank you it much"
      },
      {
        "start": 3019.98,
        "duration": 7.44,
        "text": "better when it was before really"
      },
      {
        "start": 3022.38,
        "duration": 7.92,
        "text": "uh primary key date sensor timestamp in"
      },
      {
        "start": 3027.42,
        "duration": 6.74,
        "text": "this case as you see we use as a"
      },
      {
        "start": 3030.3,
        "duration": 3.86,
        "text": "partition key word date"
      },
      {
        "start": 3035.28,
        "duration": 3.66,
        "text": "and that brings to interesting"
      },
      {
        "start": 3037.319,
        "duration": 4.921,
        "text": "consequence"
      },
      {
        "start": 3038.94,
        "duration": 6.6,
        "text": "it's very easy to get information for"
      },
      {
        "start": 3042.24,
        "duration": 5.3,
        "text": "each sensor for this particular date"
      },
      {
        "start": 3045.54,
        "duration": 5.7,
        "text": "today is"
      },
      {
        "start": 3047.54,
        "duration": 7.6,
        "text": "27th of July so I want to see data of"
      },
      {
        "start": 3051.24,
        "duration": 5.879,
        "text": "all the sensors for 27th on July with a"
      },
      {
        "start": 3055.14,
        "duration": 4.14,
        "text": "table partition it like that I can do it"
      },
      {
        "start": 3057.119,
        "duration": 5.521,
        "text": "with a single query reaching single"
      },
      {
        "start": 3059.28,
        "duration": 4.68,
        "text": "server so read time can be extremely"
      },
      {
        "start": 3062.64,
        "duration": 5.219,
        "text": "efficient right"
      },
      {
        "start": 3063.96,
        "duration": 6.3,
        "text": "but take a look what's going to happen"
      },
      {
        "start": 3067.859,
        "duration": 5.46,
        "text": "you know what Cassandra scales very well"
      },
      {
        "start": 3070.26,
        "duration": 6.0,
        "text": "I told you and there was a little Mark"
      },
      {
        "start": 3073.319,
        "duration": 5.28,
        "text": "like it depends on your data model last"
      },
      {
        "start": 3076.26,
        "duration": 5.7,
        "text": "week maybe you remember that"
      },
      {
        "start": 3078.599,
        "duration": 5.76,
        "text": "now take a look you have 100 servers you"
      },
      {
        "start": 3081.96,
        "duration": 4.619,
        "text": "store a lot of data"
      },
      {
        "start": 3084.359,
        "duration": 3.661,
        "text": "and you have a table like that"
      },
      {
        "start": 3086.579,
        "duration": 3.901,
        "text": "over time"
      },
      {
        "start": 3088.02,
        "duration": 4.92,
        "text": "if this model doesn't work very well"
      },
      {
        "start": 3090.48,
        "duration": 5.22,
        "text": "your servers are overloaded there are"
      },
      {
        "start": 3092.94,
        "duration": 5.58,
        "text": "too much of Rights and you think hey"
      },
      {
        "start": 3095.7,
        "duration": 5.399,
        "text": "Cassandra scale so good for rights I"
      },
      {
        "start": 3098.52,
        "duration": 6.44,
        "text": "will simply go and add more servers I"
      },
      {
        "start": 3101.099,
        "duration": 7.701,
        "text": "have money I can afford it I will"
      },
      {
        "start": 3104.96,
        "duration": 3.84,
        "text": "make this"
      },
      {
        "start": 3108.839,
        "duration": 5.76,
        "text": "200 servers I will go and buy 100 more"
      },
      {
        "start": 3112.5,
        "duration": 5.22,
        "text": "servers"
      },
      {
        "start": 3114.599,
        "duration": 6.0,
        "text": "what's happening then"
      },
      {
        "start": 3117.72,
        "duration": 5.099,
        "text": "now you have 200 servers did it help"
      },
      {
        "start": 3120.599,
        "duration": 4.381,
        "text": "nope"
      },
      {
        "start": 3122.819,
        "duration": 5.881,
        "text": "nope nope it didn't help you can buy"
      },
      {
        "start": 3124.98,
        "duration": 6.839,
        "text": "1000 it will not help why because data"
      },
      {
        "start": 3128.7,
        "duration": 5.46,
        "text": "is written to servers responsible for"
      },
      {
        "start": 3131.819,
        "duration": 3.421,
        "text": "this partition with replication Factor"
      },
      {
        "start": 3134.16,
        "duration": 3.659,
        "text": "free"
      },
      {
        "start": 3135.24,
        "duration": 5.339,
        "text": "you will have free servers responsible"
      },
      {
        "start": 3137.819,
        "duration": 5.641,
        "text": "for this partition in this database we"
      },
      {
        "start": 3140.579,
        "duration": 5.581,
        "text": "have a huge amount of rights that will"
      },
      {
        "start": 3143.46,
        "duration": 6.899,
        "text": "be basically one single partition active"
      },
      {
        "start": 3146.16,
        "duration": 6.84,
        "text": "all the time there will be no partition"
      },
      {
        "start": 3150.359,
        "duration": 5.641,
        "text": "the partitions will be more or less even"
      },
      {
        "start": 3153.0,
        "duration": 5.579,
        "text": "so partition for today partition for"
      },
      {
        "start": 3156.0,
        "duration": 6.0,
        "text": "yesterday we will be overall of more or"
      },
      {
        "start": 3158.579,
        "duration": 5.52,
        "text": "less the same size but workload will be"
      },
      {
        "start": 3162.0,
        "duration": 5.52,
        "text": "different servers responsible for"
      },
      {
        "start": 3164.099,
        "duration": 5.52,
        "text": "yesterday partition will be idling"
      },
      {
        "start": 3167.52,
        "duration": 5.52,
        "text": "and servers responsible for today"
      },
      {
        "start": 3169.619,
        "duration": 6.181,
        "text": "partition will burn in hell uh just"
      },
      {
        "start": 3173.04,
        "duration": 5.88,
        "text": "because your data model was not good"
      },
      {
        "start": 3175.8,
        "duration": 5.22,
        "text": "enough so think about it don't be rude"
      },
      {
        "start": 3178.92,
        "duration": 5.699,
        "text": "to your servers take care or take care"
      },
      {
        "start": 3181.02,
        "duration": 5.339,
        "text": "of them like they are good they deserve"
      },
      {
        "start": 3184.619,
        "duration": 4.861,
        "text": "some good attention I tell you as an"
      },
      {
        "start": 3186.359,
        "duration": 6.781,
        "text": "operations guide now"
      },
      {
        "start": 3189.48,
        "duration": 7.74,
        "text": "uh take a look for the second example"
      },
      {
        "start": 3193.14,
        "duration": 7.439,
        "text": "which is significantly better if for you"
      },
      {
        "start": 3197.22,
        "duration": 6.599,
        "text": "it's important to group data by date to"
      },
      {
        "start": 3200.579,
        "duration": 4.98,
        "text": "be able to see all of the data with one"
      },
      {
        "start": 3203.819,
        "duration": 4.681,
        "text": "single first query"
      },
      {
        "start": 3205.559,
        "duration": 5.04,
        "text": "then these design totally makes sense"
      },
      {
        "start": 3208.5,
        "duration": 3.96,
        "text": "you group data by date"
      },
      {
        "start": 3210.599,
        "duration": 5.52,
        "text": "and sensor"
      },
      {
        "start": 3212.46,
        "duration": 6.599,
        "text": "so therefore partition you will have"
      },
      {
        "start": 3216.119,
        "duration": 6.541,
        "text": "different partitions per date per sensor"
      },
      {
        "start": 3219.059,
        "duration": 5.461,
        "text": "and it will be never too hot because at"
      },
      {
        "start": 3222.66,
        "duration": 4.08,
        "text": "a big amount of partitions will be"
      },
      {
        "start": 3224.52,
        "duration": 5.18,
        "text": "distributed over your all of your"
      },
      {
        "start": 3226.74,
        "duration": 6.24,
        "text": "servers and in this case if your cluster"
      },
      {
        "start": 3229.7,
        "duration": 5.919,
        "text": "is overloaded you can buy in your"
      },
      {
        "start": 3232.98,
        "duration": 5.099,
        "text": "servers bring them to the cluster what"
      },
      {
        "start": 3235.619,
        "duration": 5.581,
        "text": "will happen token ranges will change"
      },
      {
        "start": 3238.079,
        "duration": 7.141,
        "text": "each server will be responsible for less"
      },
      {
        "start": 3241.2,
        "duration": 6.72,
        "text": "amount of partitions and you have a"
      },
      {
        "start": 3245.22,
        "duration": 5.28,
        "text": "smaller workload per each of them so"
      },
      {
        "start": 3247.92,
        "duration": 4.919,
        "text": "here scaling of Cassandra comes but"
      },
      {
        "start": 3250.5,
        "duration": 4.5,
        "text": "scaling of Cassandra is a shared"
      },
      {
        "start": 3252.839,
        "duration": 4.081,
        "text": "responsibility it's not only Cassandra"
      },
      {
        "start": 3255.0,
        "duration": 6.079,
        "text": "does it but you have to think about it"
      },
      {
        "start": 3256.92,
        "duration": 9.36,
        "text": "in advance designing your data model"
      },
      {
        "start": 3261.079,
        "duration": 9.341,
        "text": "and our Tom we are done with this uh"
      },
      {
        "start": 3266.28,
        "duration": 5.64,
        "text": "page if you want to add something that's"
      },
      {
        "start": 3270.42,
        "duration": 4.56,
        "text": "fine"
      },
      {
        "start": 3271.92,
        "duration": 5.76,
        "text": "there are a couple of good questions uh"
      },
      {
        "start": 3274.98,
        "duration": 5.839,
        "text": "okay one question and both of them I"
      },
      {
        "start": 3277.68,
        "duration": 6.54,
        "text": "think from viraj and the first question"
      },
      {
        "start": 3280.819,
        "duration": 4.48,
        "text": "uh for the use case for the example when"
      },
      {
        "start": 3284.22,
        "duration": 5.7,
        "text": "we use"
      },
      {
        "start": 3285.299,
        "duration": 7.441,
        "text": "um sensor and mons as a partition key"
      },
      {
        "start": 3289.92,
        "duration": 6.899,
        "text": "um he asked so for the current months"
      },
      {
        "start": 3292.74,
        "duration": 6.3,
        "text": "that partition will be hot versus for"
      },
      {
        "start": 3296.819,
        "duration": 6.141,
        "text": "the previous months those parties nobody"
      },
      {
        "start": 3299.04,
        "duration": 3.92,
        "text": "is gonna use those partitions"
      },
      {
        "start": 3304.04,
        "duration": 7.18,
        "text": "yeah I believe I answered it in the end"
      },
      {
        "start": 3307.2,
        "duration": 7.44,
        "text": "uh the story is not yeah our story is"
      },
      {
        "start": 3311.22,
        "duration": 5.639,
        "text": "not to have our Lord partitions uh as"
      },
      {
        "start": 3314.64,
        "duration": 4.979,
        "text": "long as your partitions are small you"
      },
      {
        "start": 3316.859,
        "duration": 5.281,
        "text": "can scale you have high Lord you add"
      },
      {
        "start": 3319.619,
        "duration": 5.101,
        "text": "more servers your data being shuffled to"
      },
      {
        "start": 3322.14,
        "duration": 6.3,
        "text": "them and yes workload on the server"
      },
      {
        "start": 3324.72,
        "duration": 5.66,
        "text": "everything is good the big problem for"
      },
      {
        "start": 3328.44,
        "duration": 6.359,
        "text": "uh the big problem much bigger problem"
      },
      {
        "start": 3330.38,
        "duration": 7.0,
        "text": "is then you have an even size or uneven"
      },
      {
        "start": 3334.799,
        "duration": 4.8,
        "text": "workload on the partitions when all"
      },
      {
        "start": 3337.38,
        "duration": 4.739,
        "text": "other partitions are idling in one"
      },
      {
        "start": 3339.599,
        "duration": 5.22,
        "text": "partition is too hot for a single server"
      },
      {
        "start": 3342.119,
        "duration": 5.041,
        "text": "uh to handle don't forget partition is a"
      },
      {
        "start": 3344.819,
        "duration": 3.861,
        "text": "base unit of access it's something what"
      },
      {
        "start": 3347.16,
        "duration": 4.98,
        "text": "you can pick"
      },
      {
        "start": 3348.68,
        "duration": 5.619,
        "text": "up and put to a different place as long"
      },
      {
        "start": 3352.14,
        "duration": 3.659,
        "text": "as your server can pick up single"
      },
      {
        "start": 3354.299,
        "duration": 5.161,
        "text": "partition and put it to a different"
      },
      {
        "start": 3355.799,
        "duration": 5.941,
        "text": "place you are good then it's uh when it"
      },
      {
        "start": 3359.46,
        "duration": 4.619,
        "text": "has multiple heavy partitions you can"
      },
      {
        "start": 3361.74,
        "duration": 5.28,
        "text": "put it to different servers but when you"
      },
      {
        "start": 3364.079,
        "duration": 5.881,
        "text": "have one huge or one which is being"
      },
      {
        "start": 3367.02,
        "duration": 5.7,
        "text": "overwritten all the time with like"
      },
      {
        "start": 3369.96,
        "duration": 4.8,
        "text": "billions of requests per second then"
      },
      {
        "start": 3372.72,
        "duration": 6.24,
        "text": "obviously there is no server to handle"
      },
      {
        "start": 3374.76,
        "duration": 6.96,
        "text": "that you want to add something"
      },
      {
        "start": 3378.96,
        "duration": 4.5,
        "text": "yeah I think the the there could be I"
      },
      {
        "start": 3381.72,
        "duration": 3.0,
        "text": "don't know if it's"
      },
      {
        "start": 3383.46,
        "duration": 4.7,
        "text": "uh"
      },
      {
        "start": 3384.72,
        "duration": 6.54,
        "text": "maybe something that that is not obvious"
      },
      {
        "start": 3388.16,
        "duration": 6.58,
        "text": "so yes for the current months there will"
      },
      {
        "start": 3391.26,
        "duration": 6.539,
        "text": "be more access to those partitions but"
      },
      {
        "start": 3394.74,
        "duration": 6.0,
        "text": "um months is not the only column in the"
      },
      {
        "start": 3397.799,
        "duration": 6.78,
        "text": "partition key the sensor ID is is also"
      },
      {
        "start": 3400.74,
        "duration": 6.24,
        "text": "there so it's not like uh okay for"
      },
      {
        "start": 3404.579,
        "duration": 5.401,
        "text": "January all the partitions will be on"
      },
      {
        "start": 3406.98,
        "duration": 7.139,
        "text": "this node uh because the sensor will"
      },
      {
        "start": 3409.98,
        "duration": 6.54,
        "text": "also change the partition key so for the"
      },
      {
        "start": 3414.119,
        "duration": 5.041,
        "text": "the the partitions for January will be"
      },
      {
        "start": 3416.52,
        "duration": 4.92,
        "text": "distributed across all the nodes in the"
      },
      {
        "start": 3419.16,
        "duration": 5.52,
        "text": "cluster because the sensor IDs will be"
      },
      {
        "start": 3421.44,
        "duration": 6.98,
        "text": "random and things like that so"
      },
      {
        "start": 3424.68,
        "duration": 6.139,
        "text": "so there should be no problem with uh"
      },
      {
        "start": 3428.42,
        "duration": 6.76,
        "text": "having uh"
      },
      {
        "start": 3430.819,
        "duration": 7.3,
        "text": "loads uh very high on one specific note"
      },
      {
        "start": 3435.18,
        "duration": 4.379,
        "text": "or a few of the nodes if of course you"
      },
      {
        "start": 3438.119,
        "duration": 3.5,
        "text": "you"
      },
      {
        "start": 3439.559,
        "duration": 7.221,
        "text": "um using"
      },
      {
        "start": 3441.619,
        "duration": 8.141,
        "text": "uh the the sensor IDs"
      },
      {
        "start": 3446.78,
        "duration": 5.88,
        "text": "are more or less randomized"
      },
      {
        "start": 3449.76,
        "duration": 5.24,
        "text": "and and there is no"
      },
      {
        "start": 3452.66,
        "duration": 4.54,
        "text": "subset of sensors that are getting"
      },
      {
        "start": 3455.0,
        "duration": 3.76,
        "text": "generating more data than others and"
      },
      {
        "start": 3457.2,
        "duration": 4.08,
        "text": "things like that"
      },
      {
        "start": 3458.76,
        "duration": 6.98,
        "text": "and there was another question uh about"
      },
      {
        "start": 3461.28,
        "duration": 7.76,
        "text": "the case when we have something like"
      },
      {
        "start": 3465.74,
        "duration": 6.7,
        "text": "users who are"
      },
      {
        "start": 3469.04,
        "duration": 6.46,
        "text": "uh following other users or they they"
      },
      {
        "start": 3472.44,
        "duration": 4.619,
        "text": "social media other users social media"
      },
      {
        "start": 3475.5,
        "duration": 3.96,
        "text": "yeah so"
      },
      {
        "start": 3477.059,
        "duration": 4.201,
        "text": "and in that case if you have a celebrity"
      },
      {
        "start": 3479.46,
        "duration": 3.379,
        "text": "there are so many people following so"
      },
      {
        "start": 3481.26,
        "duration": 5.4,
        "text": "you will have millions of people"
      },
      {
        "start": 3482.839,
        "duration": 5.921,
        "text": "millions of roles for that person uh for"
      },
      {
        "start": 3486.66,
        "duration": 5.22,
        "text": "their celebrity and and followers of"
      },
      {
        "start": 3488.76,
        "duration": 4.26,
        "text": "That Celebrity and uh this question is"
      },
      {
        "start": 3491.88,
        "duration": 3.959,
        "text": "actually"
      },
      {
        "start": 3493.02,
        "duration": 4.559,
        "text": "um so great because it gives us uh the"
      },
      {
        "start": 3495.839,
        "duration": 4.381,
        "text": "next Lab that we are going to do right"
      },
      {
        "start": 3497.579,
        "duration": 5.101,
        "text": "now lab two uh is going to talk about"
      },
      {
        "start": 3500.22,
        "duration": 4.32,
        "text": "Dynamic marketing specifically for this"
      },
      {
        "start": 3502.68,
        "duration": 4.8,
        "text": "for this use case"
      },
      {
        "start": 3504.54,
        "duration": 6.66,
        "text": "um and we're gonna talk about uh sensors"
      },
      {
        "start": 3507.48,
        "duration": 6.48,
        "text": "but you can imagine and send instead of"
      },
      {
        "start": 3511.2,
        "duration": 5.34,
        "text": "sensors by Network it's the same thing"
      },
      {
        "start": 3513.96,
        "duration": 4.379,
        "text": "would be followers by user something"
      },
      {
        "start": 3516.54,
        "duration": 4.259,
        "text": "like that"
      },
      {
        "start": 3518.339,
        "duration": 5.541,
        "text": "so um"
      },
      {
        "start": 3520.799,
        "duration": 3.081,
        "text": "let me"
      },
      {
        "start": 3524.88,
        "duration": 3.479,
        "text": "so we are switching to oops wait a"
      },
      {
        "start": 3527.52,
        "duration": 4.5,
        "text": "second"
      },
      {
        "start": 3528.359,
        "duration": 5.401,
        "text": "yes so it's a second lab on GitHub let"
      },
      {
        "start": 3532.02,
        "duration": 3.839,
        "text": "me switch it on your screen wait a"
      },
      {
        "start": 3533.76,
        "duration": 4.819,
        "text": "moment yes please"
      },
      {
        "start": 3535.859,
        "duration": 2.72,
        "text": "yep"
      },
      {
        "start": 3539.16,
        "duration": 6.659,
        "text": "okay on GitHub we have number eight here"
      },
      {
        "start": 3542.4,
        "duration": 4.08,
        "text": "in the our readme file is dynamic bucket"
      },
      {
        "start": 3545.819,
        "duration": 3.3,
        "text": "then"
      },
      {
        "start": 3546.48,
        "duration": 5.639,
        "text": "so what is dynamic marketing so"
      },
      {
        "start": 3549.119,
        "duration": 6.72,
        "text": "let's look based on the this example we"
      },
      {
        "start": 3552.119,
        "duration": 7.44,
        "text": "have a table that supports uh query find"
      },
      {
        "start": 3555.839,
        "duration": 6.061,
        "text": "all sensors in a specified Network so"
      },
      {
        "start": 3559.559,
        "duration": 4.381,
        "text": "given the network so we are going to"
      },
      {
        "start": 3561.9,
        "duration": 4.56,
        "text": "group all the sensors over over a given"
      },
      {
        "start": 3563.94,
        "duration": 6.0,
        "text": "Network so we will have to use network"
      },
      {
        "start": 3566.46,
        "duration": 6.24,
        "text": "ID or network name as as a partition key"
      },
      {
        "start": 3569.94,
        "duration": 4.8,
        "text": "and sensor ID will be clustering column"
      },
      {
        "start": 3572.7,
        "duration": 4.379,
        "text": "so this table only has two columns both"
      },
      {
        "start": 3574.74,
        "duration": 3.72,
        "text": "of them part part of the primary key for"
      },
      {
        "start": 3577.079,
        "duration": 4.201,
        "text": "Simplicity"
      },
      {
        "start": 3578.46,
        "duration": 5.339,
        "text": "but what it means for the network"
      },
      {
        "start": 3581.28,
        "duration": 5.579,
        "text": "partition we will store all that sensors"
      },
      {
        "start": 3583.799,
        "duration": 5.401,
        "text": "and it's like we'll saw all the all the"
      },
      {
        "start": 3586.859,
        "duration": 4.921,
        "text": "followers of of a user"
      },
      {
        "start": 3589.2,
        "duration": 4.74,
        "text": "right in this case some networks may"
      },
      {
        "start": 3591.78,
        "duration": 4.26,
        "text": "have just a few sensors or dozens of"
      },
      {
        "start": 3593.94,
        "duration": 4.44,
        "text": "sensors so the the partition for that"
      },
      {
        "start": 3596.04,
        "duration": 5.7,
        "text": "for those networks will have dozens of"
      },
      {
        "start": 3598.38,
        "duration": 5.78,
        "text": "rows uh which is not a big deal but"
      },
      {
        "start": 3601.74,
        "duration": 5.52,
        "text": "maybe some sensors maybe within a city"
      },
      {
        "start": 3604.16,
        "duration": 5.32,
        "text": "region or something they may have uh"
      },
      {
        "start": 3607.26,
        "duration": 5.22,
        "text": "thousands or even Millions"
      },
      {
        "start": 3609.48,
        "duration": 5.22,
        "text": "and tens of millions of Those sensors so"
      },
      {
        "start": 3612.48,
        "duration": 5.639,
        "text": "we do not want the partition to have"
      },
      {
        "start": 3614.7,
        "duration": 6.44,
        "text": "millions of of the sensor stored uh so"
      },
      {
        "start": 3618.119,
        "duration": 5.281,
        "text": "and so the the key"
      },
      {
        "start": 3621.14,
        "duration": 4.479,
        "text": "attributes of the problem that we are"
      },
      {
        "start": 3623.4,
        "duration": 5.58,
        "text": "trying to solve is that the number of"
      },
      {
        "start": 3625.619,
        "duration": 6.061,
        "text": "rows in the partition can can be"
      },
      {
        "start": 3628.98,
        "duration": 4.139,
        "text": "dramatically different so in one case we"
      },
      {
        "start": 3631.68,
        "duration": 3.36,
        "text": "can we can store everything in one"
      },
      {
        "start": 3633.119,
        "duration": 4.141,
        "text": "partition in enough for another Network"
      },
      {
        "start": 3635.04,
        "duration": 3.9,
        "text": "we'll have to create 10 partitions but"
      },
      {
        "start": 3637.26,
        "duration": 5.4,
        "text": "for the third network we may have to"
      },
      {
        "start": 3638.94,
        "duration": 6.06,
        "text": "create 100 partitions so it's"
      },
      {
        "start": 3642.66,
        "duration": 5.1,
        "text": "going to happen dynamically and maybe we"
      },
      {
        "start": 3645.0,
        "duration": 5.22,
        "text": "keep adding more sensors to the network"
      },
      {
        "start": 3647.76,
        "duration": 6.24,
        "text": "or maybe our sensors are actually mobile"
      },
      {
        "start": 3650.22,
        "duration": 6.54,
        "text": "and my cell phone is a sensor so once I"
      },
      {
        "start": 3654.0,
        "duration": 6.0,
        "text": "move to a different location I'm joining"
      },
      {
        "start": 3656.76,
        "duration": 6.9,
        "text": "different network so the the"
      },
      {
        "start": 3660.0,
        "duration": 6.48,
        "text": "there is Dynamics there so we will store"
      },
      {
        "start": 3663.66,
        "duration": 5.699,
        "text": "so that we will use Dynamic bucketing"
      },
      {
        "start": 3666.48,
        "duration": 6.0,
        "text": "and we'll store our"
      },
      {
        "start": 3669.359,
        "duration": 6.061,
        "text": "sensors inside of buckets and buckets"
      },
      {
        "start": 3672.48,
        "duration": 4.56,
        "text": "it's essentially artificial surrogate"
      },
      {
        "start": 3675.42,
        "duration": 5.34,
        "text": "partition"
      },
      {
        "start": 3677.04,
        "duration": 5.88,
        "text": "and we will assign those buckets to each"
      },
      {
        "start": 3680.76,
        "duration": 4.44,
        "text": "Network so one some Network may have"
      },
      {
        "start": 3682.92,
        "duration": 4.919,
        "text": "only one bucket another Network may have"
      },
      {
        "start": 3685.2,
        "duration": 4.859,
        "text": "two buckets 10 buckets another one may"
      },
      {
        "start": 3687.839,
        "duration": 5.821,
        "text": "have hundred buckets so we will need two"
      },
      {
        "start": 3690.059,
        "duration": 5.76,
        "text": "tables for that and I'm gonna explain"
      },
      {
        "start": 3693.66,
        "duration": 6.48,
        "text": "you how it works first and then you can"
      },
      {
        "start": 3695.819,
        "duration": 7.321,
        "text": "go to astrodb and work and basically try"
      },
      {
        "start": 3700.14,
        "duration": 6.6,
        "text": "this example there the first table is"
      },
      {
        "start": 3703.14,
        "duration": 7.14,
        "text": "going to manage Pockets so for each"
      },
      {
        "start": 3706.74,
        "duration": 4.92,
        "text": "Network we will have a list of buckets"
      },
      {
        "start": 3710.28,
        "duration": 4.68,
        "text": "and"
      },
      {
        "start": 3711.66,
        "duration": 5.34,
        "text": "so network will be partition key bucket"
      },
      {
        "start": 3714.96,
        "duration": 4.8,
        "text": "will be clustering column what's"
      },
      {
        "start": 3717.0,
        "duration": 5.039,
        "text": "important to notice here is that bucket"
      },
      {
        "start": 3719.76,
        "duration": 6.48,
        "text": "is time uad that this is important"
      },
      {
        "start": 3722.039,
        "duration": 7.02,
        "text": "because so you you already gives us easy"
      },
      {
        "start": 3726.24,
        "duration": 5.54,
        "text": "way to assign unique IDs but time ID"
      },
      {
        "start": 3729.059,
        "duration": 7.441,
        "text": "also allows us to sort those Pockets"
      },
      {
        "start": 3731.78,
        "duration": 7.92,
        "text": "based on time component of the uuid so"
      },
      {
        "start": 3736.5,
        "duration": 6.9,
        "text": "why is it useful is because when you"
      },
      {
        "start": 3739.7,
        "duration": 5.2,
        "text": "when you want to add new sensor into a"
      },
      {
        "start": 3743.4,
        "duration": 5.219,
        "text": "bucket you want to retrieve the latest"
      },
      {
        "start": 3744.9,
        "duration": 6.78,
        "text": "packet the packet with the the highest"
      },
      {
        "start": 3748.619,
        "duration": 4.68,
        "text": "timestamp and and that will that sorting"
      },
      {
        "start": 3751.68,
        "duration": 4.619,
        "text": "order will allow you just to retrieve"
      },
      {
        "start": 3753.299,
        "duration": 5.52,
        "text": "one bucket for that Network just the"
      },
      {
        "start": 3756.299,
        "duration": 5.82,
        "text": "latest bucket so limit one we will see"
      },
      {
        "start": 3758.819,
        "duration": 6.061,
        "text": "how it's done and it's very convenient"
      },
      {
        "start": 3762.119,
        "duration": 5.041,
        "text": "so time uad is better than uad in this"
      },
      {
        "start": 3764.88,
        "duration": 4.8,
        "text": "case and then"
      },
      {
        "start": 3767.16,
        "duration": 4.919,
        "text": "the other table is going to store"
      },
      {
        "start": 3769.68,
        "duration": 4.139,
        "text": "sensors in those buckets and you can see"
      },
      {
        "start": 3772.079,
        "duration": 4.561,
        "text": "network is not even mentioned so there"
      },
      {
        "start": 3773.819,
        "duration": 5.76,
        "text": "is a networked Network set buckets"
      },
      {
        "start": 3776.64,
        "duration": 5.459,
        "text": "buckets have sensors right very simple"
      },
      {
        "start": 3779.579,
        "duration": 4.02,
        "text": "design pocket is prediction key sensor"
      },
      {
        "start": 3782.099,
        "duration": 2.161,
        "text": "is"
      },
      {
        "start": 3783.599,
        "duration": 4.02,
        "text": "um"
      },
      {
        "start": 3784.26,
        "duration": 7.079,
        "text": "clustering key okay and"
      },
      {
        "start": 3787.619,
        "duration": 6.841,
        "text": "at this point let me actually"
      },
      {
        "start": 3791.339,
        "duration": 7.621,
        "text": "go to Astrid B and new"
      },
      {
        "start": 3794.46,
        "duration": 8.28,
        "text": "and stay logged in I'm on time so uh we"
      },
      {
        "start": 3798.96,
        "duration": 6.5,
        "text": "created here the our database which is"
      },
      {
        "start": 3802.74,
        "duration": 8.72,
        "text": "Workshop database it has key space"
      },
      {
        "start": 3805.46,
        "duration": 6.0,
        "text": "sensor data so I will use cql console"
      },
      {
        "start": 3813.839,
        "duration": 6.061,
        "text": "and we'll say use sensor data"
      },
      {
        "start": 3817.26,
        "duration": 3.96,
        "text": "so I will select my key space that I"
      },
      {
        "start": 3819.9,
        "duration": 4.459,
        "text": "want to"
      },
      {
        "start": 3821.22,
        "duration": 3.139,
        "text": "use for this"
      },
      {
        "start": 3824.4,
        "duration": 4.52,
        "text": "lab"
      },
      {
        "start": 3825.78,
        "duration": 3.14,
        "text": "and I will"
      },
      {
        "start": 3830.099,
        "duration": 5.101,
        "text": "copy the"
      },
      {
        "start": 3832.68,
        "duration": 4.5,
        "text": "this definition of two tables and we"
      },
      {
        "start": 3835.2,
        "duration": 6.0,
        "text": "insert in some sample data we insert in"
      },
      {
        "start": 3837.18,
        "duration": 6.0,
        "text": "a forest network has two buckets one"
      },
      {
        "start": 3841.2,
        "duration": 4.2,
        "text": "starts with four another with with seven"
      },
      {
        "start": 3843.18,
        "duration": 4.139,
        "text": "and for each of the bucket we will"
      },
      {
        "start": 3845.4,
        "duration": 4.32,
        "text": "insert some sensors so there are two"
      },
      {
        "start": 3847.319,
        "duration": 5.28,
        "text": "sensors in the first bucket and One"
      },
      {
        "start": 3849.72,
        "duration": 6.42,
        "text": "sensor in the second bucket so they the"
      },
      {
        "start": 3852.599,
        "duration": 8.0,
        "text": "IDS here are just regular strings"
      },
      {
        "start": 3856.14,
        "duration": 4.459,
        "text": "um easier to read okay so let's"
      },
      {
        "start": 3862.319,
        "duration": 7.381,
        "text": "create these tables insert some data so"
      },
      {
        "start": 3865.92,
        "duration": 6.54,
        "text": "now what we want to know how to use"
      },
      {
        "start": 3869.7,
        "duration": 4.58,
        "text": "these two tables now"
      },
      {
        "start": 3872.46,
        "duration": 4.56,
        "text": "and"
      },
      {
        "start": 3874.28,
        "duration": 5.559,
        "text": "specifically we want to be able to add a"
      },
      {
        "start": 3877.02,
        "duration": 4.86,
        "text": "new sensor to a network what happens in"
      },
      {
        "start": 3879.839,
        "duration": 4.921,
        "text": "that case to add a new sensor we need to"
      },
      {
        "start": 3881.88,
        "duration": 5.1,
        "text": "First decide which packet to use okay"
      },
      {
        "start": 3884.76,
        "duration": 3.96,
        "text": "which bucket to add maybe there is only"
      },
      {
        "start": 3886.98,
        "duration": 4.8,
        "text": "one bucket but maybe there are multiple"
      },
      {
        "start": 3888.72,
        "duration": 7.26,
        "text": "so we will first select the latest"
      },
      {
        "start": 3891.78,
        "duration": 6.6,
        "text": "bucket the bucket which was created the"
      },
      {
        "start": 3895.98,
        "duration": 4.559,
        "text": "most most recently how do we do that we"
      },
      {
        "start": 3898.38,
        "duration": 5.4,
        "text": "simply select the bucket from buckets by"
      },
      {
        "start": 3900.539,
        "duration": 6.06,
        "text": "Network where networks equals firstnet"
      },
      {
        "start": 3903.78,
        "duration": 6.66,
        "text": "limit one remember our"
      },
      {
        "start": 3906.599,
        "duration": 5.46,
        "text": "a bucket ID is Tiny UAV"
      },
      {
        "start": 3910.44,
        "duration": 5.099,
        "text": "and"
      },
      {
        "start": 3912.059,
        "duration": 5.821,
        "text": "it's clustering key and it's clustering"
      },
      {
        "start": 3915.539,
        "duration": 5.76,
        "text": "order bucket descendant so it's ordered"
      },
      {
        "start": 3917.88,
        "duration": 5.34,
        "text": "based on the uh time component of the"
      },
      {
        "start": 3921.299,
        "duration": 5.161,
        "text": "time uad so we will get the latest one"
      },
      {
        "start": 3923.22,
        "duration": 4.68,
        "text": "by just retrieving one row from that"
      },
      {
        "start": 3926.46,
        "duration": 4.52,
        "text": "table"
      },
      {
        "start": 3927.9,
        "duration": 3.08,
        "text": "okay let me do that"
      },
      {
        "start": 3931.38,
        "duration": 8.219,
        "text": "okay so this is our latest bucket and we"
      },
      {
        "start": 3934.74,
        "duration": 7.5,
        "text": "can actually verify that that it has its"
      },
      {
        "start": 3939.599,
        "duration": 5.46,
        "text": "time component is"
      },
      {
        "start": 3942.24,
        "duration": 4.5,
        "text": "um higher timestamp is higher than the"
      },
      {
        "start": 3945.059,
        "duration": 4.621,
        "text": "previous one we don't need to do that"
      },
      {
        "start": 3946.74,
        "duration": 6.599,
        "text": "however so then what's the next thing we"
      },
      {
        "start": 3949.68,
        "duration": 6.0,
        "text": "want to find out whether this bucket is"
      },
      {
        "start": 3953.339,
        "duration": 5.041,
        "text": "full or not so we will count how many"
      },
      {
        "start": 3955.68,
        "duration": 7.02,
        "text": "rows how many sensors we already have in"
      },
      {
        "start": 3958.38,
        "duration": 6.6,
        "text": "that bucket which is very simple"
      },
      {
        "start": 3962.7,
        "duration": 4.44,
        "text": "create it again"
      },
      {
        "start": 3964.98,
        "duration": 4.26,
        "text": "so we only have one sensor that's a"
      },
      {
        "start": 3967.14,
        "duration": 3.54,
        "text": "second bucket the first one we have two"
      },
      {
        "start": 3969.24,
        "duration": 4.859,
        "text": "sensors the second one we have one"
      },
      {
        "start": 3970.68,
        "duration": 6.359,
        "text": "sensor so at this point your application"
      },
      {
        "start": 3974.099,
        "duration": 6.301,
        "text": "logic will decide whether this bucket is"
      },
      {
        "start": 3977.039,
        "duration": 6.481,
        "text": "full and we need to create a new bucket"
      },
      {
        "start": 3980.4,
        "duration": 6.06,
        "text": "with new to generate new time uad and"
      },
      {
        "start": 3983.52,
        "duration": 6.0,
        "text": "and insert into new bucket or if it"
      },
      {
        "start": 3986.46,
        "duration": 6.599,
        "text": "still can hold additional sensors in"
      },
      {
        "start": 3989.52,
        "duration": 7.079,
        "text": "this case it can be simply insert into"
      },
      {
        "start": 3993.059,
        "duration": 5.461,
        "text": "that bucket the sorry this this one we"
      },
      {
        "start": 3996.599,
        "duration": 8.041,
        "text": "simply insert into that"
      },
      {
        "start": 3998.52,
        "duration": 6.12,
        "text": "uh bucket the new sensor with IDs 1004."
      },
      {
        "start": 4004.94,
        "duration": 5.28,
        "text": "okay so quite"
      },
      {
        "start": 4007.24,
        "duration": 5.5,
        "text": "straightforward now we added new sensor"
      },
      {
        "start": 4010.22,
        "duration": 4.8,
        "text": "how about we retrieve remember the the"
      },
      {
        "start": 4012.74,
        "duration": 5.819,
        "text": "query that we needed to support is to"
      },
      {
        "start": 4015.02,
        "duration": 7.26,
        "text": "get all the sensors for a given Network"
      },
      {
        "start": 4018.559,
        "duration": 5.52,
        "text": "but we again need to First retrieve all"
      },
      {
        "start": 4022.28,
        "duration": 3.839,
        "text": "the buckets for the given Network and"
      },
      {
        "start": 4024.079,
        "duration": 5.52,
        "text": "then retrieve the sensors so this is we"
      },
      {
        "start": 4026.119,
        "duration": 4.141,
        "text": "retrieving all the buckets get all the"
      },
      {
        "start": 4029.599,
        "duration": 3.301,
        "text": "um"
      },
      {
        "start": 4030.26,
        "duration": 5.42,
        "text": "bucket IDs from bucket by Network for"
      },
      {
        "start": 4032.9,
        "duration": 2.78,
        "text": "specific Network"
      },
      {
        "start": 4037.76,
        "duration": 5.24,
        "text": "okay and we have only two buckets you"
      },
      {
        "start": 4041.059,
        "duration": 5.101,
        "text": "can notice the ID"
      },
      {
        "start": 4043.0,
        "duration": 4.72,
        "text": "7449 and this is done in within your"
      },
      {
        "start": 4046.16,
        "duration": 3.959,
        "text": "application"
      },
      {
        "start": 4047.72,
        "duration": 4.859,
        "text": "so the next step we will trip sensors"
      },
      {
        "start": 4050.119,
        "duration": 6.48,
        "text": "from both of those buckets so where"
      },
      {
        "start": 4052.579,
        "duration": 4.02,
        "text": "bucket in 7449"
      },
      {
        "start": 4057.079,
        "duration": 5.161,
        "text": "and we will be able to get all four"
      },
      {
        "start": 4059.559,
        "duration": 6.161,
        "text": "sensors in our result"
      },
      {
        "start": 4062.24,
        "duration": 5.819,
        "text": "so to finish this lab what I want to say"
      },
      {
        "start": 4065.72,
        "duration": 5.339,
        "text": "the the dynamic back bucketing is"
      },
      {
        "start": 4068.059,
        "duration": 6.06,
        "text": "extremely powerful mechanism that you"
      },
      {
        "start": 4071.059,
        "duration": 4.861,
        "text": "can solve all kinds of uh problems with"
      },
      {
        "start": 4074.119,
        "duration": 6.061,
        "text": "big partitions and and thought"
      },
      {
        "start": 4075.92,
        "duration": 7.679,
        "text": "partitions dynamically but of course if"
      },
      {
        "start": 4080.18,
        "duration": 5.399,
        "text": "you introduce new buckets they"
      },
      {
        "start": 4083.599,
        "duration": 4.681,
        "text": "correspond to partitions and your access"
      },
      {
        "start": 4085.579,
        "duration": 5.121,
        "text": "pattern changes you have to create"
      },
      {
        "start": 4088.28,
        "duration": 5.94,
        "text": "multiple buckets or multiple"
      },
      {
        "start": 4090.7,
        "duration": 7.24,
        "text": "partitions like in this example where we"
      },
      {
        "start": 4094.22,
        "duration": 6.539,
        "text": "use in bucket in we basically accessing"
      },
      {
        "start": 4097.94,
        "duration": 5.279,
        "text": "two partitions we in two partitions is"
      },
      {
        "start": 4100.759,
        "duration": 5.4,
        "text": "slower than creating one partition right"
      },
      {
        "start": 4103.219,
        "duration": 5.221,
        "text": "unless we are split in very large"
      },
      {
        "start": 4106.159,
        "duration": 4.56,
        "text": "partition in into two partitions right"
      },
      {
        "start": 4108.44,
        "duration": 4.799,
        "text": "in that case it's it's better to create"
      },
      {
        "start": 4110.719,
        "duration": 5.761,
        "text": "two partitions because you basically"
      },
      {
        "start": 4113.239,
        "duration": 5.401,
        "text": "your workload distributes better right"
      },
      {
        "start": 4116.48,
        "duration": 4.879,
        "text": "you using more nodes to access that"
      },
      {
        "start": 4118.64,
        "duration": 2.719,
        "text": "large partition"
      },
      {
        "start": 4121.46,
        "duration": 7.5,
        "text": "okay do you have any questions"
      },
      {
        "start": 4124.279,
        "duration": 6.841,
        "text": "um uh looks like I don't"
      },
      {
        "start": 4128.96,
        "duration": 3.779,
        "text": "um no I don't nope we are good we are"
      },
      {
        "start": 4131.12,
        "duration": 4.86,
        "text": "good"
      },
      {
        "start": 4132.739,
        "duration": 6.42,
        "text": "okay so in this case we can"
      },
      {
        "start": 4135.98,
        "duration": 6.179,
        "text": "continue and Alex the next part is still"
      },
      {
        "start": 4139.159,
        "duration": 4.2,
        "text": "your part right yes uh as far as I"
      },
      {
        "start": 4142.159,
        "duration": 5.401,
        "text": "remember"
      },
      {
        "start": 4143.359,
        "duration": 6.36,
        "text": "so uh the only thing I wanted to add is"
      },
      {
        "start": 4147.56,
        "duration": 5.52,
        "text": "I see in them"
      },
      {
        "start": 4149.719,
        "duration": 6.361,
        "text": "and the slides uh oh sorry in the slides"
      },
      {
        "start": 4153.08,
        "duration": 5.88,
        "text": "I see on YouTube the question about like"
      },
      {
        "start": 4156.08,
        "duration": 6.0,
        "text": "if we have really a lot of access to a"
      },
      {
        "start": 4158.96,
        "duration": 5.879,
        "text": "single piece of data I would cache"
      },
      {
        "start": 4162.08,
        "duration": 4.5,
        "text": "something maybe with a caching layer"
      },
      {
        "start": 4164.839,
        "duration": 3.301,
        "text": "um radius or something on top of"
      },
      {
        "start": 4166.58,
        "duration": 5.82,
        "text": "Cassandra"
      },
      {
        "start": 4168.14,
        "duration": 7.199,
        "text": "um so I'm not saying you not to use uh a"
      },
      {
        "start": 4172.4,
        "duration": 6.299,
        "text": "cache HTTP cache or whatever cash"
      },
      {
        "start": 4175.339,
        "duration": 4.681,
        "text": "I remind you what cash also introduces"
      },
      {
        "start": 4178.699,
        "duration": 4.02,
        "text": "complexity"
      },
      {
        "start": 4180.02,
        "duration": 5.88,
        "text": "so you have to be careful with cash how"
      },
      {
        "start": 4182.719,
        "duration": 5.161,
        "text": "you are going to invalidate that if you"
      },
      {
        "start": 4185.9,
        "duration": 3.54,
        "text": "have a distributed application then how"
      },
      {
        "start": 4187.88,
        "duration": 3.959,
        "text": "exactly your cache do you go for"
      },
      {
        "start": 4189.44,
        "duration": 5.279,
        "text": "distributed cash invalidated cash and"
      },
      {
        "start": 4191.839,
        "duration": 5.4,
        "text": "validation becomes much harder so uh"
      },
      {
        "start": 4194.719,
        "duration": 5.101,
        "text": "with cash cash is a powerful technique"
      },
      {
        "start": 4197.239,
        "duration": 4.861,
        "text": "but it also comes with some costs now"
      },
      {
        "start": 4199.82,
        "duration": 6.899,
        "text": "regarding a lot of reads"
      },
      {
        "start": 4202.1,
        "duration": 6.68,
        "text": "as long as it's not billions of free to"
      },
      {
        "start": 4206.719,
        "duration": 4.861,
        "text": "a single partition"
      },
      {
        "start": 4208.78,
        "duration": 4.84,
        "text": "uh it should be totally fine so"
      },
      {
        "start": 4211.58,
        "duration": 3.42,
        "text": "Cassandra that is not afraid of a lot of"
      },
      {
        "start": 4213.62,
        "duration": 4.079,
        "text": "reads"
      },
      {
        "start": 4215.0,
        "duration": 5.64,
        "text": "as long as you can evenly distribute"
      },
      {
        "start": 4217.699,
        "duration": 5.661,
        "text": "workload over multiple servers if you"
      },
      {
        "start": 4220.64,
        "duration": 5.16,
        "text": "have a lot of these celebrities"
      },
      {
        "start": 4223.36,
        "duration": 5.44,
        "text": "therefore you have them spread it over"
      },
      {
        "start": 4225.8,
        "duration": 5.899,
        "text": "multiple servers and you are good"
      },
      {
        "start": 4228.8,
        "duration": 2.899,
        "text": "so let's move on"
      },
      {
        "start": 4232.58,
        "duration": 6.36,
        "text": "uh data types so first of all Cassandra"
      },
      {
        "start": 4235.88,
        "duration": 7.7,
        "text": "features all the kind of the types you"
      },
      {
        "start": 4238.94,
        "duration": 8.16,
        "text": "use it to have in different uh"
      },
      {
        "start": 4243.58,
        "duration": 7.26,
        "text": "databases whatever integer whatever"
      },
      {
        "start": 4247.1,
        "duration": 7.02,
        "text": "Boolean whatever string small int text"
      },
      {
        "start": 4250.84,
        "duration": 7.12,
        "text": "and so on and so forth blob so very"
      },
      {
        "start": 4254.12,
        "duration": 6.48,
        "text": "typical set of different data types you"
      },
      {
        "start": 4257.96,
        "duration": 6.18,
        "text": "use it to have there are some unusual"
      },
      {
        "start": 4260.6,
        "duration": 7.22,
        "text": "like time uuid but archon I believe you"
      },
      {
        "start": 4264.14,
        "duration": 3.68,
        "text": "discussed the time you already right"
      },
      {
        "start": 4268.159,
        "duration": 8.281,
        "text": "yes indeed we talked about time UD and"
      },
      {
        "start": 4271.159,
        "duration": 7.56,
        "text": "uid yes yeah good uh so uh Varin varchar"
      },
      {
        "start": 4276.44,
        "duration": 5.1,
        "text": "so all the types like that that"
      },
      {
        "start": 4278.719,
        "duration": 5.401,
        "text": "shouldn't be a big surprise to you so I"
      },
      {
        "start": 4281.54,
        "duration": 6.659,
        "text": "don't want to spend too much time on it"
      },
      {
        "start": 4284.12,
        "duration": 7.2,
        "text": "uh there are some more types what uh"
      },
      {
        "start": 4288.199,
        "duration": 4.861,
        "text": "totally what can be interesting for some"
      },
      {
        "start": 4291.32,
        "duration": 6.419,
        "text": "of the data"
      },
      {
        "start": 4293.06,
        "duration": 7.139,
        "text": "if you uh you may if you store some"
      },
      {
        "start": 4297.739,
        "duration": 6.541,
        "text": "complex data types you may be interested"
      },
      {
        "start": 4300.199,
        "duration": 7.381,
        "text": "in collections so set list map"
      },
      {
        "start": 4304.28,
        "duration": 6.959,
        "text": "uh Aviv map you can Define uh internal"
      },
      {
        "start": 4307.58,
        "duration": 6.42,
        "text": "Types on your own it can be text text in"
      },
      {
        "start": 4311.239,
        "duration": 6.901,
        "text": "text text int and so on so collection"
      },
      {
        "start": 4314.0,
        "duration": 8.04,
        "text": "types must be pretty self-explanatory"
      },
      {
        "start": 4318.14,
        "duration": 5.76,
        "text": "you have this kind of data in any kind"
      },
      {
        "start": 4322.04,
        "duration": 3.48,
        "text": "of a programming language shouldn't be"
      },
      {
        "start": 4323.9,
        "duration": 5.4,
        "text": "new to"
      },
      {
        "start": 4325.52,
        "duration": 5.52,
        "text": "um you user defined types of course a"
      },
      {
        "start": 4329.3,
        "duration": 2.6,
        "text": "user defined type is an interesting"
      },
      {
        "start": 4331.04,
        "duration": 4.26,
        "text": "thing"
      },
      {
        "start": 4331.9,
        "duration": 6.64,
        "text": "for a key space you can create type of"
      },
      {
        "start": 4335.3,
        "duration": 5.879,
        "text": "your own type it's like a class in"
      },
      {
        "start": 4338.54,
        "duration": 6.72,
        "text": "object oriented programming for example"
      },
      {
        "start": 4341.179,
        "duration": 8.52,
        "text": "address or bank account or whatever type"
      },
      {
        "start": 4345.26,
        "duration": 5.22,
        "text": "is interesting to you and Define types"
      },
      {
        "start": 4349.699,
        "duration": 4.561,
        "text": "there"
      },
      {
        "start": 4350.48,
        "duration": 7.199,
        "text": "and it will be your user definer type so"
      },
      {
        "start": 4354.26,
        "duration": 7.439,
        "text": "you could use you could work with that"
      },
      {
        "start": 4357.679,
        "duration": 7.801,
        "text": "in the way you need and for example you"
      },
      {
        "start": 4361.699,
        "duration": 6.261,
        "text": "can even Store Plain Json uh as a UDT"
      },
      {
        "start": 4365.48,
        "duration": 5.4,
        "text": "and it will be uh"
      },
      {
        "start": 4367.96,
        "duration": 5.62,
        "text": "it will be stored as a user-defined type"
      },
      {
        "start": 4370.88,
        "duration": 6.26,
        "text": "as long as it exists also you could have"
      },
      {
        "start": 4373.58,
        "duration": 6.599,
        "text": "some custom types but that's in general"
      },
      {
        "start": 4377.14,
        "duration": 5.74,
        "text": "uh pretty Advanced strategy and very"
      },
      {
        "start": 4380.179,
        "duration": 5.701,
        "text": "often not recommended it was maybe a"
      },
      {
        "start": 4382.88,
        "duration": 6.66,
        "text": "thing for Cassandra of older versions"
      },
      {
        "start": 4385.88,
        "duration": 4.64,
        "text": "but now all kind of required types"
      },
      {
        "start": 4389.54,
        "duration": 4.38,
        "text": "um"
      },
      {
        "start": 4390.52,
        "duration": 6.3,
        "text": "exist already so there is no need to"
      },
      {
        "start": 4393.92,
        "duration": 7.259,
        "text": "make some more advanced things"
      },
      {
        "start": 4396.82,
        "duration": 5.339,
        "text": "and like words are cheap practices"
      },
      {
        "start": 4401.179,
        "duration": 4.081,
        "text": "golden"
      },
      {
        "start": 4402.159,
        "duration": 6.721,
        "text": "uh you will proceed with working with"
      },
      {
        "start": 4405.26,
        "duration": 3.62,
        "text": "data types step right"
      },
      {
        "start": 4410.3,
        "duration": 7.8,
        "text": "atom so the the data types will be more"
      },
      {
        "start": 4415.159,
        "duration": 5.881,
        "text": "homework this is part okay if you might"
      },
      {
        "start": 4418.1,
        "duration": 5.66,
        "text": "It's homework get a badge yes"
      },
      {
        "start": 4421.04,
        "duration": 2.72,
        "text": "foreign"
      },
      {
        "start": 4427.6,
        "duration": 4.9,
        "text": "you've seen the explanations already uh"
      },
      {
        "start": 4430.94,
        "duration": 3.84,
        "text": "please do it"
      },
      {
        "start": 4432.5,
        "duration": 5.76,
        "text": "don't ignore do it"
      },
      {
        "start": 4434.78,
        "duration": 6.6,
        "text": "and uh then next one is going to be data"
      },
      {
        "start": 4438.26,
        "duration": 6.62,
        "text": "modeling practice process and I uh"
      },
      {
        "start": 4441.38,
        "duration": 6.839,
        "text": "hereby give me microphone to the"
      },
      {
        "start": 4444.88,
        "duration": 4.799,
        "text": "deer archon"
      },
      {
        "start": 4448.219,
        "duration": 5.281,
        "text": "okay"
      },
      {
        "start": 4449.679,
        "duration": 7.56,
        "text": "let me switch my screen"
      },
      {
        "start": 4453.5,
        "duration": 3.739,
        "text": "yes it's your screen gnome"
      },
      {
        "start": 4460.58,
        "duration": 2.48,
        "text": "okay"
      },
      {
        "start": 4464.6,
        "duration": 5.78,
        "text": "Okay so"
      },
      {
        "start": 4466.1,
        "duration": 4.28,
        "text": "data modeling process and"
      },
      {
        "start": 4470.54,
        "duration": 4.92,
        "text": "here we started our main TVs"
      },
      {
        "start": 4472.94,
        "duration": 4.08,
        "text": "normalization versus denormalization and"
      },
      {
        "start": 4475.46,
        "duration": 4.259,
        "text": "we said the immunization is not always"
      },
      {
        "start": 4477.02,
        "duration": 5.52,
        "text": "good also in relational world people"
      },
      {
        "start": 4479.719,
        "duration": 5.161,
        "text": "think about it as Evil saying because it"
      },
      {
        "start": 4482.54,
        "duration": 5.4,
        "text": "brings anomalies right you you create"
      },
      {
        "start": 4484.88,
        "duration": 6.359,
        "text": "multiple you duplicate your data in"
      },
      {
        "start": 4487.94,
        "duration": 6.42,
        "text": "multiple places in multiple tables and"
      },
      {
        "start": 4491.239,
        "duration": 5.181,
        "text": "then you have to remember to update"
      },
      {
        "start": 4494.36,
        "duration": 5.18,
        "text": "those multiple places"
      },
      {
        "start": 4496.42,
        "duration": 5.98,
        "text": "to keep those duplicates consistency"
      },
      {
        "start": 4499.54,
        "duration": 4.48,
        "text": "consistent between each other so more"
      },
      {
        "start": 4502.4,
        "duration": 3.48,
        "text": "headache kind of"
      },
      {
        "start": 4504.02,
        "duration": 4.5,
        "text": "seeing but um"
      },
      {
        "start": 4505.88,
        "duration": 5.04,
        "text": "and that's true that's true the uh"
      },
      {
        "start": 4508.52,
        "duration": 4.679,
        "text": "everything comes at a price database"
      },
      {
        "start": 4510.92,
        "duration": 5.16,
        "text": "Innovation is is a great thing it's"
      },
      {
        "start": 4513.199,
        "duration": 6.181,
        "text": "based on normalization CA it's it's not"
      },
      {
        "start": 4516.08,
        "duration": 6.24,
        "text": "it's quite complex Mass there if you if"
      },
      {
        "start": 4519.38,
        "duration": 6.2,
        "text": "you try to actually look at the algories"
      },
      {
        "start": 4522.32,
        "duration": 6.419,
        "text": "that decompose"
      },
      {
        "start": 4525.58,
        "duration": 6.4,
        "text": "your tables to achieve higher normal"
      },
      {
        "start": 4528.739,
        "duration": 5.041,
        "text": "forms and all of that but why was it"
      },
      {
        "start": 4531.98,
        "duration": 4.02,
        "text": "designed like that why why is it"
      },
      {
        "start": 4533.78,
        "duration": 4.8,
        "text": "important because at that time it was"
      },
      {
        "start": 4536.0,
        "duration": 4.739,
        "text": "designed disk space was expensive this"
      },
      {
        "start": 4538.58,
        "duration": 3.96,
        "text": "was expensive and and you didn't want to"
      },
      {
        "start": 4540.739,
        "duration": 3.92,
        "text": "duplicate your data you wanted to store"
      },
      {
        "start": 4542.54,
        "duration": 6.48,
        "text": "it more efficiently and you would use"
      },
      {
        "start": 4544.659,
        "duration": 8.04,
        "text": "joins and and other operators like"
      },
      {
        "start": 4549.02,
        "duration": 6.84,
        "text": "intersect and Union to combine your data"
      },
      {
        "start": 4552.699,
        "duration": 5.561,
        "text": "from different tables to compute the"
      },
      {
        "start": 4555.86,
        "duration": 4.68,
        "text": "result but now"
      },
      {
        "start": 4558.26,
        "duration": 4.08,
        "text": "uh so for example in this in this"
      },
      {
        "start": 4560.54,
        "duration": 4.08,
        "text": "example we have employees and"
      },
      {
        "start": 4562.34,
        "duration": 4.8,
        "text": "departments two separate tables and we"
      },
      {
        "start": 4564.62,
        "duration": 4.74,
        "text": "have a foreign key Department ID is a"
      },
      {
        "start": 4567.14,
        "duration": 4.559,
        "text": "foreign key which is key reference to a"
      },
      {
        "start": 4569.36,
        "duration": 3.9,
        "text": "different table to departments table so"
      },
      {
        "start": 4571.699,
        "duration": 5.161,
        "text": "we can find out that Edgar Court"
      },
      {
        "start": 4573.26,
        "duration": 6.0,
        "text": "department based on this one we go to a"
      },
      {
        "start": 4576.86,
        "duration": 3.839,
        "text": "different table or join with with these"
      },
      {
        "start": 4579.26,
        "duration": 4.02,
        "text": "table departments and find the"
      },
      {
        "start": 4580.699,
        "duration": 5.46,
        "text": "department name is actually engineering"
      },
      {
        "start": 4583.28,
        "duration": 5.18,
        "text": "so this is how relational databases work"
      },
      {
        "start": 4586.159,
        "duration": 6.421,
        "text": "but"
      },
      {
        "start": 4588.46,
        "duration": 7.6,
        "text": "in case of distributed databases it's it"
      },
      {
        "start": 4592.58,
        "duration": 4.639,
        "text": "joins away can be very expensive"
      },
      {
        "start": 4596.06,
        "duration": 5.52,
        "text": "um because"
      },
      {
        "start": 4597.219,
        "duration": 5.881,
        "text": "uh the data that we said"
      },
      {
        "start": 4601.58,
        "duration": 4.159,
        "text": "yes"
      },
      {
        "start": 4603.1,
        "duration": 5.92,
        "text": "what happened"
      },
      {
        "start": 4605.739,
        "duration": 7.901,
        "text": "in a no SQL database distributed"
      },
      {
        "start": 4609.02,
        "duration": 7.98,
        "text": "database is that the the the the record"
      },
      {
        "start": 4613.64,
        "duration": 5.88,
        "text": "from oral from employees table is on one"
      },
      {
        "start": 4617.0,
        "duration": 6.84,
        "text": "note and roll from departments table is"
      },
      {
        "start": 4619.52,
        "duration": 6.719,
        "text": "on different nodes so to join them"
      },
      {
        "start": 4623.84,
        "duration": 5.64,
        "text": "to join them based on the foreign key"
      },
      {
        "start": 4626.239,
        "duration": 6.661,
        "text": "like relational databases do you have to"
      },
      {
        "start": 4629.48,
        "duration": 5.4,
        "text": "move data into some other nodes you need"
      },
      {
        "start": 4632.9,
        "duration": 3.42,
        "text": "to move it together on one node and then"
      },
      {
        "start": 4634.88,
        "duration": 4.04,
        "text": "compute it is out that's expensive"
      },
      {
        "start": 4636.32,
        "duration": 5.339,
        "text": "moving the data is expensive so what"
      },
      {
        "start": 4638.92,
        "duration": 5.14,
        "text": "nosql databases do not only Cassandra"
      },
      {
        "start": 4641.659,
        "duration": 5.761,
        "text": "but others and what for example data"
      },
      {
        "start": 4644.06,
        "duration": 6.3,
        "text": "warehouses do they use the normalization"
      },
      {
        "start": 4647.42,
        "duration": 4.88,
        "text": "so instead of storing the foreign key"
      },
      {
        "start": 4650.36,
        "duration": 4.98,
        "text": "for the Department ID they will actually"
      },
      {
        "start": 4652.3,
        "duration": 4.359,
        "text": "store the Baler that you may need in"
      },
      {
        "start": 4655.34,
        "duration": 4.14,
        "text": "your query if you need the department"
      },
      {
        "start": 4656.659,
        "duration": 6.301,
        "text": "name they will store it here the problem"
      },
      {
        "start": 4659.48,
        "duration": 6.719,
        "text": "is that is okay engineering is repeated"
      },
      {
        "start": 4662.96,
        "duration": 4.86,
        "text": "here twice if we decide that we change"
      },
      {
        "start": 4666.199,
        "duration": 3.96,
        "text": "engineering"
      },
      {
        "start": 4667.82,
        "duration": 5.28,
        "text": "from the the name of the department from"
      },
      {
        "start": 4670.159,
        "duration": 5.101,
        "text": "engineering to the world-class"
      },
      {
        "start": 4673.1,
        "duration": 5.099,
        "text": "engineering then we will have to change"
      },
      {
        "start": 4675.26,
        "duration": 5.58,
        "text": "it here in the Departments table but"
      },
      {
        "start": 4678.199,
        "duration": 6.0,
        "text": "we'll also have it have to change it in"
      },
      {
        "start": 4680.84,
        "duration": 5.879,
        "text": "the employees table multiple times so"
      },
      {
        "start": 4684.199,
        "duration": 4.441,
        "text": "that's why the normalization is can be"
      },
      {
        "start": 4686.719,
        "duration": 4.261,
        "text": "considered bad so you have to remember"
      },
      {
        "start": 4688.64,
        "duration": 4.26,
        "text": "do these kind of things and if you have"
      },
      {
        "start": 4690.98,
        "duration": 5.1,
        "text": "time we will talk about how to use"
      },
      {
        "start": 4692.9,
        "duration": 5.16,
        "text": "batches to actually do these kind of"
      },
      {
        "start": 4696.08,
        "duration": 5.88,
        "text": "things efficiently"
      },
      {
        "start": 4698.06,
        "duration": 6.42,
        "text": "okay so sorry sorry sorry sorry I want"
      },
      {
        "start": 4701.96,
        "duration": 4.259,
        "text": "to step in a little bit it's one of very"
      },
      {
        "start": 4704.48,
        "duration": 5.4,
        "text": "important topics could you please switch"
      },
      {
        "start": 4706.219,
        "duration": 6.061,
        "text": "to previous slides here this one good so"
      },
      {
        "start": 4709.88,
        "duration": 6.0,
        "text": "uh regarding uh"
      },
      {
        "start": 4712.28,
        "duration": 6.54,
        "text": "uh that's in general balance between uh"
      },
      {
        "start": 4715.88,
        "duration": 5.52,
        "text": "multiple of Rights or more complex reads"
      },
      {
        "start": 4718.82,
        "duration": 4.74,
        "text": "with normalization you go for more"
      },
      {
        "start": 4721.4,
        "duration": 5.16,
        "text": "complex reads with joints with"
      },
      {
        "start": 4723.56,
        "duration": 6.179,
        "text": "denormalization you go with more uh"
      },
      {
        "start": 4726.56,
        "duration": 5.4,
        "text": "the bigger rights multiple rights for"
      },
      {
        "start": 4729.739,
        "duration": 3.661,
        "text": "one single update instead of one single"
      },
      {
        "start": 4731.96,
        "duration": 2.4,
        "text": "update"
      },
      {
        "start": 4733.4,
        "duration": 3.72,
        "text": "um"
      },
      {
        "start": 4734.36,
        "duration": 5.04,
        "text": "there are some database developers in"
      },
      {
        "start": 4737.12,
        "duration": 4.079,
        "text": "the world who are trying to claim like"
      },
      {
        "start": 4739.4,
        "duration": 5.16,
        "text": "yeah we solve a bit of a problem there"
      },
      {
        "start": 4741.199,
        "duration": 5.701,
        "text": "is new SQL which is great so you can"
      },
      {
        "start": 4744.56,
        "duration": 6.36,
        "text": "have your data distributed but with"
      },
      {
        "start": 4746.9,
        "duration": 6.0,
        "text": "joints sounds good and even works on a"
      },
      {
        "start": 4750.92,
        "duration": 4.5,
        "text": "very small data sets"
      },
      {
        "start": 4752.9,
        "duration": 4.86,
        "text": "so to build a join you have to get all"
      },
      {
        "start": 4755.42,
        "duration": 5.22,
        "text": "the data on the single node"
      },
      {
        "start": 4757.76,
        "duration": 5.1,
        "text": "will it work yes it will when it will"
      },
      {
        "start": 4760.64,
        "duration": 4.38,
        "text": "work when you when your data fits into a"
      },
      {
        "start": 4762.86,
        "duration": 3.96,
        "text": "single server and then it's all great"
      },
      {
        "start": 4765.02,
        "duration": 2.94,
        "text": "but when you don't have to distribute it"
      },
      {
        "start": 4766.82,
        "duration": 3.24,
        "text": "at all"
      },
      {
        "start": 4767.96,
        "duration": 6.719,
        "text": "so that is the biggest problem of new"
      },
      {
        "start": 4770.06,
        "duration": 7.26,
        "text": "SQL distributed SQL it works but only on"
      },
      {
        "start": 4774.679,
        "duration": 4.56,
        "text": "a small uh data sets"
      },
      {
        "start": 4777.32,
        "duration": 5.22,
        "text": "but uh"
      },
      {
        "start": 4779.239,
        "duration": 5.821,
        "text": "that is a different story"
      },
      {
        "start": 4782.54,
        "duration": 5.04,
        "text": "what I wanted to say like what's most"
      },
      {
        "start": 4785.06,
        "duration": 4.139,
        "text": "important for me in this story of a"
      },
      {
        "start": 4787.58,
        "duration": 3.9,
        "text": "battle between normalization and"
      },
      {
        "start": 4789.199,
        "duration": 5.161,
        "text": "denormalization well there is no real"
      },
      {
        "start": 4791.48,
        "duration": 5.759,
        "text": "battle it's like a battle of a hammer"
      },
      {
        "start": 4794.36,
        "duration": 4.799,
        "text": "and range they don't battle they have"
      },
      {
        "start": 4797.239,
        "duration": 5.281,
        "text": "nothing against each other you know"
      },
      {
        "start": 4799.159,
        "duration": 5.341,
        "text": "their friends maybe even but it's uh"
      },
      {
        "start": 4802.52,
        "duration": 4.5,
        "text": "some people go for their normalization"
      },
      {
        "start": 4804.5,
        "duration": 4.139,
        "text": "some people go to normalization you need"
      },
      {
        "start": 4807.02,
        "duration": 3.6,
        "text": "to understand both you need to"
      },
      {
        "start": 4808.639,
        "duration": 4.741,
        "text": "understand then to normalize then to"
      },
      {
        "start": 4810.62,
        "duration": 5.16,
        "text": "their normalize only then you can be a"
      },
      {
        "start": 4813.38,
        "duration": 4.319,
        "text": "senior developer software engineer and"
      },
      {
        "start": 4815.78,
        "duration": 6.68,
        "text": "so on now"
      },
      {
        "start": 4817.699,
        "duration": 4.761,
        "text": "story most important part of it"
      },
      {
        "start": 4822.52,
        "duration": 6.58,
        "text": "what is very different between write and"
      },
      {
        "start": 4826.639,
        "duration": 5.281,
        "text": "read with join"
      },
      {
        "start": 4829.1,
        "duration": 5.28,
        "text": "right in Cassandra is a single Atomic"
      },
      {
        "start": 4831.92,
        "duration": 5.46,
        "text": "operation and Cassandra is very capable"
      },
      {
        "start": 4834.38,
        "duration": 5.52,
        "text": "for rights so you can execute multiple"
      },
      {
        "start": 4837.38,
        "duration": 4.38,
        "text": "rights in parallel even addressing"
      },
      {
        "start": 4839.9,
        "duration": 4.14,
        "text": "different notes because well as"
      },
      {
        "start": 4841.76,
        "duration": 4.439,
        "text": "different tables different partitions it"
      },
      {
        "start": 4844.04,
        "duration": 4.86,
        "text": "totally can be different notes so you"
      },
      {
        "start": 4846.199,
        "duration": 4.741,
        "text": "can execute 10 right in a moment of a"
      },
      {
        "start": 4848.9,
        "duration": 5.22,
        "text": "time and it will be totally fine for"
      },
      {
        "start": 4850.94,
        "duration": 5.88,
        "text": "your database as long as it's right"
      },
      {
        "start": 4854.12,
        "duration": 5.94,
        "text": "capable database like Cassandra"
      },
      {
        "start": 4856.82,
        "duration": 5.1,
        "text": "uh and you run them all at once I think"
      },
      {
        "start": 4860.06,
        "duration": 6.72,
        "text": "asynchron knows them"
      },
      {
        "start": 4861.92,
        "duration": 7.62,
        "text": "what's happening with uh joins"
      },
      {
        "start": 4866.78,
        "duration": 5.82,
        "text": "it's a little bit different story there"
      },
      {
        "start": 4869.54,
        "duration": 5.699,
        "text": "are very many cases then you cannot run"
      },
      {
        "start": 4872.6,
        "duration": 5.94,
        "text": "all the joints at one mostly probably"
      },
      {
        "start": 4875.239,
        "duration": 5.821,
        "text": "your joints will what depend one on each"
      },
      {
        "start": 4878.54,
        "duration": 5.28,
        "text": "other if you have multiple joints in a"
      },
      {
        "start": 4881.06,
        "duration": 5.639,
        "text": "select query it will have to first make"
      },
      {
        "start": 4883.82,
        "duration": 5.46,
        "text": "first join intersect and select some"
      },
      {
        "start": 4886.699,
        "duration": 6.241,
        "text": "data on it then get the second join"
      },
      {
        "start": 4889.28,
        "duration": 6.359,
        "text": "third join fourth join step by step by"
      },
      {
        "start": 4892.94,
        "duration": 4.02,
        "text": "step synchronously all this time you"
      },
      {
        "start": 4895.639,
        "duration": 3.661,
        "text": "will be waiting"
      },
      {
        "start": 4896.96,
        "duration": 5.1,
        "text": "so you cannot in most of the cases"
      },
      {
        "start": 4899.3,
        "duration": 5.339,
        "text": "execute those joints simultaneously and"
      },
      {
        "start": 4902.06,
        "duration": 4.8,
        "text": "that makes a big problem so although"
      },
      {
        "start": 4904.639,
        "duration": 4.741,
        "text": "right is considered to be more expensive"
      },
      {
        "start": 4906.86,
        "duration": 4.68,
        "text": "operation if Cassandra of right is cheap"
      },
      {
        "start": 4909.38,
        "duration": 4.4,
        "text": "and you can run them in parallel but"
      },
      {
        "start": 4911.54,
        "duration": 5.82,
        "text": "joins has to have to be executed"
      },
      {
        "start": 4913.78,
        "duration": 6.7,
        "text": "consecutively and also select is in"
      },
      {
        "start": 4917.36,
        "duration": 5.7,
        "text": "theory cheap operation is getting much"
      },
      {
        "start": 4920.48,
        "duration": 4.98,
        "text": "more expensive with joints then you have"
      },
      {
        "start": 4923.06,
        "duration": 4.5,
        "text": "to wait for every next join to be"
      },
      {
        "start": 4925.46,
        "duration": 4.32,
        "text": "completed before you can proceed"
      },
      {
        "start": 4927.56,
        "duration": 4.02,
        "text": "and that is a very important limitation"
      },
      {
        "start": 4929.78,
        "duration": 3.919,
        "text": "and that is a very important thing to"
      },
      {
        "start": 4931.58,
        "duration": 2.119,
        "text": "understand"
      },
      {
        "start": 4934.76,
        "duration": 3.24,
        "text": "yes but"
      },
      {
        "start": 4937.46,
        "duration": 4.08,
        "text": "um"
      },
      {
        "start": 4938.0,
        "duration": 7.56,
        "text": "to add there are actually distributed"
      },
      {
        "start": 4941.54,
        "duration": 7.199,
        "text": "SQL engines and and just"
      },
      {
        "start": 4945.56,
        "duration": 5.24,
        "text": "if you think about spark SQL that you"
      },
      {
        "start": 4948.739,
        "duration": 4.561,
        "text": "can run on top of Cassandra"
      },
      {
        "start": 4950.8,
        "duration": 5.859,
        "text": "and there will be some optimizations"
      },
      {
        "start": 4953.3,
        "duration": 6.24,
        "text": "where joins will be computed in parallel"
      },
      {
        "start": 4956.659,
        "duration": 4.08,
        "text": "based on subset of partitions on each"
      },
      {
        "start": 4959.54,
        "duration": 5.58,
        "text": "node"
      },
      {
        "start": 4960.739,
        "duration": 6.48,
        "text": "and and engines like Trina"
      },
      {
        "start": 4965.12,
        "duration": 4.8,
        "text": "um that we'll be able to do things in"
      },
      {
        "start": 4967.219,
        "duration": 4.801,
        "text": "parallel as well but uh another thing I"
      },
      {
        "start": 4969.92,
        "duration": 4.259,
        "text": "wanted to mention denominization"
      },
      {
        "start": 4972.02,
        "duration": 2.88,
        "text": "is used with relational databases as"
      },
      {
        "start": 4974.179,
        "duration": 3.0,
        "text": "well"
      },
      {
        "start": 4974.9,
        "duration": 4.68,
        "text": "for performance optimization and but"
      },
      {
        "start": 4977.179,
        "duration": 6.361,
        "text": "here we with Cassandra this is what we"
      },
      {
        "start": 4979.58,
        "duration": 7.28,
        "text": "do all the time and"
      },
      {
        "start": 4983.54,
        "duration": 6.84,
        "text": "going next to the approach so frequently"
      },
      {
        "start": 4986.86,
        "duration": 6.879,
        "text": "relational modeling starts with you"
      },
      {
        "start": 4990.38,
        "duration": 7.68,
        "text": "completely focus on data and you model"
      },
      {
        "start": 4993.739,
        "duration": 6.681,
        "text": "entities relationships and you normalize"
      },
      {
        "start": 4998.06,
        "duration": 4.92,
        "text": "them and only then you think about okay"
      },
      {
        "start": 5000.42,
        "duration": 5.2,
        "text": "I need to execute this query and"
      },
      {
        "start": 5002.98,
        "duration": 5.06,
        "text": "currently I need to do 50 joints to do"
      },
      {
        "start": 5005.62,
        "duration": 5.4,
        "text": "that that's that's that's"
      },
      {
        "start": 5008.04,
        "duration": 6.159,
        "text": "possibility no that's possibility I"
      },
      {
        "start": 5011.02,
        "duration": 5.76,
        "text": "wrote queries with 50 joints before I"
      },
      {
        "start": 5014.199,
        "duration": 6.781,
        "text": "reached once I reached once a maximum"
      },
      {
        "start": 5016.78,
        "duration": 7.439,
        "text": "amount of joints allow it in my sequel I"
      },
      {
        "start": 5020.98,
        "duration": 5.699,
        "text": "got once exception uh by the way it's an"
      },
      {
        "start": 5024.219,
        "duration": 5.341,
        "text": "interesting to ask on YouTube I see some"
      },
      {
        "start": 5026.679,
        "duration": 5.881,
        "text": "people watching also quite extensive"
      },
      {
        "start": 5029.56,
        "duration": 6.54,
        "text": "experience I just want them to guess"
      },
      {
        "start": 5032.56,
        "duration": 6.9,
        "text": "make a guess once in my life I've seen"
      },
      {
        "start": 5036.1,
        "duration": 7.38,
        "text": "an exception like you cannot use more"
      },
      {
        "start": 5039.46,
        "duration": 7.8,
        "text": "than x joins in a statement it was my"
      },
      {
        "start": 5043.48,
        "duration": 6.48,
        "text": "sequel it was around"
      },
      {
        "start": 5047.26,
        "duration": 5.22,
        "text": "12 years ago maybe 10 years ago I don't"
      },
      {
        "start": 5049.96,
        "duration": 6.08,
        "text": "remember exactly would you guess how"
      },
      {
        "start": 5052.48,
        "duration": 3.56,
        "text": "many was this number"
      },
      {
        "start": 5056.32,
        "duration": 4.62,
        "text": "it will be different for different"
      },
      {
        "start": 5058.0,
        "duration": 4.92,
        "text": "databases for postgres it maybe mostly"
      },
      {
        "start": 5060.94,
        "duration": 4.68,
        "text": "probably will be different maybe it's"
      },
      {
        "start": 5062.92,
        "duration": 4.08,
        "text": "changed to newer versions of MySQL I"
      },
      {
        "start": 5065.62,
        "duration": 5.18,
        "text": "don't work with it for many years"
      },
      {
        "start": 5067.0,
        "duration": 3.8,
        "text": "already what would be your guess"
      },
      {
        "start": 5075.46,
        "duration": 3.5,
        "text": "atom and what do you think what would"
      },
      {
        "start": 5077.56,
        "duration": 4.619,
        "text": "you ask for"
      },
      {
        "start": 5078.96,
        "duration": 5.98,
        "text": "uh I think it was something like 64 or"
      },
      {
        "start": 5082.179,
        "duration": 5.941,
        "text": "something like that uh 128 I don't"
      },
      {
        "start": 5084.94,
        "duration": 6.239,
        "text": "remember okay so our Tom says 64. what"
      },
      {
        "start": 5088.12,
        "duration": 5.099,
        "text": "would our visitors try Okay the last"
      },
      {
        "start": 5091.179,
        "duration": 4.761,
        "text": "thing 64."
      },
      {
        "start": 5093.219,
        "duration": 2.721,
        "text": "okay"
      },
      {
        "start": 5096.04,
        "duration": 10.56,
        "text": "uh six wow I mean you Googled it or you"
      },
      {
        "start": 5101.5,
        "duration": 6.199,
        "text": "knew it 61. 61 right answer is 61. can"
      },
      {
        "start": 5106.6,
        "duration": 4.8,
        "text": "you imagine"
      },
      {
        "start": 5107.699,
        "duration": 6.701,
        "text": "maintaining this query that was such a"
      },
      {
        "start": 5111.4,
        "duration": 5.16,
        "text": "damn nightmare maybe it was different"
      },
      {
        "start": 5114.4,
        "duration": 5.759,
        "text": "database or different"
      },
      {
        "start": 5116.56,
        "duration": 6.54,
        "text": "um uh here different version I did yeah"
      },
      {
        "start": 5120.159,
        "duration": 5.281,
        "text": "yeah for me it was 61 that's for sure I"
      },
      {
        "start": 5123.1,
        "duration": 4.5,
        "text": "remember this number I would make a"
      },
      {
        "start": 5125.44,
        "duration": 3.92,
        "text": "tattoo with this number it was so much"
      },
      {
        "start": 5127.6,
        "duration": 5.039,
        "text": "pain maintaining it"
      },
      {
        "start": 5129.36,
        "duration": 5.02,
        "text": "but the thing is with if you the"
      },
      {
        "start": 5132.639,
        "duration": 4.461,
        "text": "relational database is one thing right"
      },
      {
        "start": 5134.38,
        "duration": 6.48,
        "text": "but if you look at the data warehouses"
      },
      {
        "start": 5137.1,
        "duration": 6.78,
        "text": "people write those queries like every"
      },
      {
        "start": 5140.86,
        "duration": 6.42,
        "text": "day with 60 joints"
      },
      {
        "start": 5143.88,
        "duration": 6.88,
        "text": "because yeah they they it happens"
      },
      {
        "start": 5147.28,
        "duration": 6.68,
        "text": "especially uh it happened to me"
      },
      {
        "start": 5150.76,
        "duration": 5.879,
        "text": "not so far ago but anyway"
      },
      {
        "start": 5153.96,
        "duration": 5.14,
        "text": "data focus on data for relational data"
      },
      {
        "start": 5156.639,
        "duration": 6.301,
        "text": "modeling and then once you create the"
      },
      {
        "start": 5159.1,
        "duration": 5.52,
        "text": "the data models then you will think"
      },
      {
        "start": 5162.94,
        "duration": 4.199,
        "text": "about application how your application"
      },
      {
        "start": 5164.62,
        "duration": 3.599,
        "text": "is used those tables join them and all"
      },
      {
        "start": 5167.139,
        "duration": 3.241,
        "text": "of that and then you will think okay"
      },
      {
        "start": 5168.219,
        "duration": 4.741,
        "text": "maybe I need to create an index maybe I"
      },
      {
        "start": 5170.38,
        "duration": 4.14,
        "text": "need to generalize here and what's"
      },
      {
        "start": 5172.96,
        "duration": 3.36,
        "text": "extremely important here also to"
      },
      {
        "start": 5174.52,
        "duration": 4.139,
        "text": "understand is that it's not just one"
      },
      {
        "start": 5176.32,
        "duration": 5.339,
        "text": "application new design database once"
      },
      {
        "start": 5178.659,
        "duration": 5.281,
        "text": "it's relational databases are good and"
      },
      {
        "start": 5181.659,
        "duration": 3.961,
        "text": "known as integration database you design"
      },
      {
        "start": 5183.94,
        "duration": 4.259,
        "text": "your database once and you can have"
      },
      {
        "start": 5185.62,
        "duration": 4.68,
        "text": "multiple applications working with the"
      },
      {
        "start": 5188.199,
        "duration": 4.081,
        "text": "same tables they can join they can do"
      },
      {
        "start": 5190.3,
        "duration": 3.18,
        "text": "whatever they need to extract specific"
      },
      {
        "start": 5192.28,
        "duration": 5.399,
        "text": "data"
      },
      {
        "start": 5193.48,
        "duration": 6.14,
        "text": "on the other hand no SQL databases they"
      },
      {
        "start": 5197.679,
        "duration": 5.341,
        "text": "are different usually designed database"
      },
      {
        "start": 5199.62,
        "duration": 6.059,
        "text": "specific to each application so for each"
      },
      {
        "start": 5203.02,
        "duration": 5.639,
        "text": "application you will start with with"
      },
      {
        "start": 5205.679,
        "duration": 5.321,
        "text": "uh thinking about what your application"
      },
      {
        "start": 5208.659,
        "duration": 5.401,
        "text": "will need what type of data will it"
      },
      {
        "start": 5211.0,
        "duration": 5.52,
        "text": "retrieve what kind of workload loads you"
      },
      {
        "start": 5214.06,
        "duration": 4.92,
        "text": "you will of course get some idea of data"
      },
      {
        "start": 5216.52,
        "duration": 4.74,
        "text": "there as well because"
      },
      {
        "start": 5218.98,
        "duration": 3.9,
        "text": "you cannot Define queries without data"
      },
      {
        "start": 5221.26,
        "duration": 3.2,
        "text": "right you will think about okay I need"
      },
      {
        "start": 5222.88,
        "duration": 5.16,
        "text": "an iterative"
      },
      {
        "start": 5224.46,
        "duration": 6.759,
        "text": "sensor location sensor failure the the"
      },
      {
        "start": 5228.04,
        "duration": 4.679,
        "text": "temperature failure and and region as"
      },
      {
        "start": 5231.219,
        "duration": 3.181,
        "text": "it's things like that the the"
      },
      {
        "start": 5232.719,
        "duration": 3.781,
        "text": "characteristics of a sensor so you will"
      },
      {
        "start": 5234.4,
        "duration": 4.319,
        "text": "when you think about application you're"
      },
      {
        "start": 5236.5,
        "duration": 6.179,
        "text": "also thinking about the data but the"
      },
      {
        "start": 5238.719,
        "duration": 6.92,
        "text": "data layout the model of the data will"
      },
      {
        "start": 5242.679,
        "duration": 5.04,
        "text": "be based on those queries"
      },
      {
        "start": 5245.639,
        "duration": 4.5,
        "text": "primarily so you will use the"
      },
      {
        "start": 5247.719,
        "duration": 5.581,
        "text": "memorization there you will use"
      },
      {
        "start": 5250.139,
        "duration": 5.56,
        "text": "indexes as well in some cases"
      },
      {
        "start": 5253.3,
        "duration": 6.12,
        "text": "but yeah but you the main point is you"
      },
      {
        "start": 5255.699,
        "duration": 6.121,
        "text": "will Design the the design the the data"
      },
      {
        "start": 5259.42,
        "duration": 6.239,
        "text": "modeling is driven by your application"
      },
      {
        "start": 5261.82,
        "duration": 5.339,
        "text": "by queries and with that"
      },
      {
        "start": 5265.659,
        "duration": 5.161,
        "text": "um we will"
      },
      {
        "start": 5267.159,
        "duration": 6.901,
        "text": "uh talk about this even in in more damn"
      },
      {
        "start": 5270.82,
        "duration": 6.66,
        "text": "depths we kind of formalize it into a"
      },
      {
        "start": 5274.06,
        "duration": 5.4,
        "text": "methodology and I will show you a tool"
      },
      {
        "start": 5277.48,
        "duration": 6.42,
        "text": "that implements part of this methodology"
      },
      {
        "start": 5279.46,
        "duration": 6.96,
        "text": "and and we will be able to quiz to"
      },
      {
        "start": 5283.9,
        "duration": 4.56,
        "text": "design our table the tool design tables"
      },
      {
        "start": 5286.42,
        "duration": 5.819,
        "text": "for us we will just specify what kind of"
      },
      {
        "start": 5288.46,
        "duration": 6.5,
        "text": "queries we want to use so data modeling"
      },
      {
        "start": 5292.239,
        "duration": 6.841,
        "text": "is actually could be quite complex"
      },
      {
        "start": 5294.96,
        "duration": 7.62,
        "text": "process because it oops"
      },
      {
        "start": 5299.08,
        "duration": 3.5,
        "text": "yeah I can leave"
      },
      {
        "start": 5303.699,
        "duration": 5.701,
        "text": "could be quite complex process"
      },
      {
        "start": 5306.6,
        "duration": 4.78,
        "text": "if you start from scratch you need you"
      },
      {
        "start": 5309.4,
        "duration": 5.279,
        "text": "need to you start from you you don't"
      },
      {
        "start": 5311.38,
        "duration": 4.92,
        "text": "have uh data yet you you didn't think"
      },
      {
        "start": 5314.679,
        "duration": 3.54,
        "text": "about applications so you will have to"
      },
      {
        "start": 5316.3,
        "duration": 4.82,
        "text": "collect data requirements you will have"
      },
      {
        "start": 5318.219,
        "duration": 4.52,
        "text": "to understand entities relationship"
      },
      {
        "start": 5321.12,
        "duration": 4.84,
        "text": "cardinalities"
      },
      {
        "start": 5322.739,
        "duration": 5.321,
        "text": "keys right so what what's going to be"
      },
      {
        "start": 5325.96,
        "duration": 4.14,
        "text": "unique for that entity or for that"
      },
      {
        "start": 5328.06,
        "duration": 4.74,
        "text": "relationship queries how you're gonna"
      },
      {
        "start": 5330.1,
        "duration": 5.039,
        "text": "create how you access your data in"
      },
      {
        "start": 5332.8,
        "duration": 4.68,
        "text": "Access patterns involve queries involve"
      },
      {
        "start": 5335.139,
        "duration": 4.861,
        "text": "inserts involved transactions updates"
      },
      {
        "start": 5337.48,
        "duration": 5.4,
        "text": "deletes and all of that and only then"
      },
      {
        "start": 5340.0,
        "duration": 6.06,
        "text": "you will be able to organize a structure"
      },
      {
        "start": 5342.88,
        "duration": 5.16,
        "text": "and after you organize the strategy you"
      },
      {
        "start": 5346.06,
        "duration": 4.5,
        "text": "still so you you will produce some kind"
      },
      {
        "start": 5348.04,
        "duration": 4.5,
        "text": "of database schema you will optimize it"
      },
      {
        "start": 5350.56,
        "duration": 4.2,
        "text": "with indexes with the normalization"
      },
      {
        "start": 5352.54,
        "duration": 4.86,
        "text": "we're spocketing like a dynamic"
      },
      {
        "start": 5354.76,
        "duration": 5.1,
        "text": "packeting like we discussed and so on"
      },
      {
        "start": 5357.4,
        "duration": 3.92,
        "text": "but usually people think about data"
      },
      {
        "start": 5359.86,
        "duration": 4.74,
        "text": "model and they think of it about"
      },
      {
        "start": 5361.32,
        "duration": 5.26,
        "text": "designing schema okay this can be more"
      },
      {
        "start": 5364.6,
        "duration": 5.099,
        "text": "complacent chance okay well let's let's"
      },
      {
        "start": 5366.58,
        "duration": 6.18,
        "text": "start with with these five tables no you"
      },
      {
        "start": 5369.699,
        "duration": 5.761,
        "text": "need to do other things but most of the"
      },
      {
        "start": 5372.76,
        "duration": 4.68,
        "text": "time maybe for when you join an existing"
      },
      {
        "start": 5375.46,
        "duration": 4.8,
        "text": "project you will look at the schema"
      },
      {
        "start": 5377.44,
        "duration": 6.18,
        "text": "somebody designed it already and that's"
      },
      {
        "start": 5380.26,
        "duration": 6.36,
        "text": "that schema and data modeling data model"
      },
      {
        "start": 5383.62,
        "duration": 6.42,
        "text": "is extremely important especially"
      },
      {
        "start": 5386.62,
        "duration": 6.18,
        "text": "uh for Cassandra because you may have"
      },
      {
        "start": 5390.04,
        "duration": 5.28,
        "text": "things like absurds you may have uh all"
      },
      {
        "start": 5392.8,
        "duration": 5.16,
        "text": "kind of you may not be able to create it"
      },
      {
        "start": 5395.32,
        "duration": 5.16,
        "text": "because your primary key does not"
      },
      {
        "start": 5397.96,
        "duration": 5.34,
        "text": "support that PD uh efficiency"
      },
      {
        "start": 5400.48,
        "duration": 6.32,
        "text": "scalability right we need to distribute"
      },
      {
        "start": 5403.3,
        "duration": 7.8,
        "text": "data correctly we need to be able to"
      },
      {
        "start": 5406.8,
        "duration": 6.64,
        "text": "sort the data in some cases so we need"
      },
      {
        "start": 5411.1,
        "duration": 4.98,
        "text": "to keep data consistent if we duplicate"
      },
      {
        "start": 5413.44,
        "duration": 6.12,
        "text": "data in multiple places and all of that"
      },
      {
        "start": 5416.08,
        "duration": 5.7,
        "text": "so I Define these four data modeling"
      },
      {
        "start": 5419.56,
        "duration": 4.079,
        "text": "very general high-level data modeling"
      },
      {
        "start": 5421.78,
        "duration": 3.899,
        "text": "principles you need to know your data"
      },
      {
        "start": 5423.639,
        "duration": 4.02,
        "text": "and and some of the most important"
      },
      {
        "start": 5425.679,
        "duration": 4.02,
        "text": "things it would be Keys you need to"
      },
      {
        "start": 5427.659,
        "duration": 4.861,
        "text": "understand a keys and cardinalities like"
      },
      {
        "start": 5429.699,
        "duration": 4.52,
        "text": "Network may contain many sensors but"
      },
      {
        "start": 5432.52,
        "duration": 5.46,
        "text": "sensor"
      },
      {
        "start": 5434.219,
        "duration": 6.401,
        "text": "must belong to exactly one network or"
      },
      {
        "start": 5437.98,
        "duration": 5.28,
        "text": "not it depends on your requirements"
      },
      {
        "start": 5440.62,
        "duration": 5.88,
        "text": "maybe this the sensor like a cell phone"
      },
      {
        "start": 5443.26,
        "duration": 5.58,
        "text": "may be reached by Two Towers at the same"
      },
      {
        "start": 5446.5,
        "duration": 4.5,
        "text": "time and belong to two networks okay so"
      },
      {
        "start": 5448.84,
        "duration": 4.56,
        "text": "this is all something that you need to"
      },
      {
        "start": 5451.0,
        "duration": 4.92,
        "text": "understand before you do data modeling"
      },
      {
        "start": 5453.4,
        "duration": 5.819,
        "text": "know your quiz you need to know how you"
      },
      {
        "start": 5455.92,
        "duration": 5.88,
        "text": "create it and access data Nest data Nest"
      },
      {
        "start": 5459.219,
        "duration": 4.92,
        "text": "data it's essentially that the"
      },
      {
        "start": 5461.8,
        "duration": 4.859,
        "text": "normalization that we talked about right"
      },
      {
        "start": 5464.139,
        "duration": 4.801,
        "text": "so we're going to Nest multiple rows in"
      },
      {
        "start": 5466.659,
        "duration": 3.48,
        "text": "the same partition or we will create a"
      },
      {
        "start": 5468.94,
        "duration": 5.4,
        "text": "collection"
      },
      {
        "start": 5470.139,
        "duration": 6.0,
        "text": "a set or list or map to Nest that data"
      },
      {
        "start": 5474.34,
        "duration": 4.04,
        "text": "so that's kind of the normalization if"
      },
      {
        "start": 5476.139,
        "duration": 4.621,
        "text": "you think about it it"
      },
      {
        "start": 5478.38,
        "duration": 4.96,
        "text": "breaks the rules of normalization"
      },
      {
        "start": 5480.76,
        "duration": 5.22,
        "text": "cereals right so that's nascular data"
      },
      {
        "start": 5483.34,
        "duration": 5.879,
        "text": "and and some nosql databases actually"
      },
      {
        "start": 5485.98,
        "duration": 5.88,
        "text": "like like document databases Json they I"
      },
      {
        "start": 5489.219,
        "duration": 5.161,
        "text": "think they use the term as data uh"
      },
      {
        "start": 5491.86,
        "duration": 5.48,
        "text": "before they use the randomization and"
      },
      {
        "start": 5494.38,
        "duration": 2.96,
        "text": "duplicate data"
      },
      {
        "start": 5499.92,
        "duration": 6.759,
        "text": "is over the same subset of data you will"
      },
      {
        "start": 5504.639,
        "duration": 4.741,
        "text": "have to organize that subset of data"
      },
      {
        "start": 5506.679,
        "duration": 5.04,
        "text": "differently in different tables and and"
      },
      {
        "start": 5509.38,
        "duration": 7.14,
        "text": "by doing that you will duplicate your"
      },
      {
        "start": 5511.719,
        "duration": 7.44,
        "text": "data so do you make it a little bit more"
      },
      {
        "start": 5516.52,
        "duration": 5.52,
        "text": "formal and repeatable as as you will see"
      },
      {
        "start": 5519.159,
        "duration": 4.221,
        "text": "it's it's possible to even automate this"
      },
      {
        "start": 5522.04,
        "duration": 4.199,
        "text": "process"
      },
      {
        "start": 5523.38,
        "duration": 5.44,
        "text": "this is the the methodology in a"
      },
      {
        "start": 5526.239,
        "duration": 5.781,
        "text": "nutshell we need to understand the data"
      },
      {
        "start": 5528.82,
        "duration": 6.3,
        "text": "identify access patterns apply"
      },
      {
        "start": 5532.02,
        "duration": 6.4,
        "text": "apply the query first approach optimize"
      },
      {
        "start": 5535.12,
        "duration": 5.7,
        "text": "and Implement okay so by understanding"
      },
      {
        "start": 5538.42,
        "duration": 6.42,
        "text": "the data we are going to do the"
      },
      {
        "start": 5540.82,
        "duration": 5.819,
        "text": "conceptual data modeling one way to"
      },
      {
        "start": 5544.84,
        "duration": 3.54,
        "text": "represent it graphically is using"
      },
      {
        "start": 5546.639,
        "duration": 4.921,
        "text": "anti-relationship diagram"
      },
      {
        "start": 5548.38,
        "duration": 5.16,
        "text": "uh four to identify access patterns we"
      },
      {
        "start": 5551.56,
        "duration": 3.84,
        "text": "will do the application workflow model"
      },
      {
        "start": 5553.54,
        "duration": 3.54,
        "text": "and we'll use application workflow"
      },
      {
        "start": 5555.4,
        "duration": 4.739,
        "text": "diagram"
      },
      {
        "start": 5557.08,
        "duration": 5.159,
        "text": "so why it's just so"
      },
      {
        "start": 5560.139,
        "duration": 4.861,
        "text": "the application workflow you will see an"
      },
      {
        "start": 5562.239,
        "duration": 5.221,
        "text": "example it involves queries because it"
      },
      {
        "start": 5565.0,
        "duration": 5.34,
        "text": "involves tasks that are supported by"
      },
      {
        "start": 5567.46,
        "duration": 5.1,
        "text": "queries because we design application uh"
      },
      {
        "start": 5570.34,
        "duration": 5.1,
        "text": "data driven application"
      },
      {
        "start": 5572.56,
        "duration": 5.46,
        "text": "um at some so we have the workflow that"
      },
      {
        "start": 5575.44,
        "duration": 4.86,
        "text": "creates our database and and at each"
      },
      {
        "start": 5578.02,
        "duration": 4.44,
        "text": "step in that workflow we know which data"
      },
      {
        "start": 5580.3,
        "duration": 4.62,
        "text": "which queries we already executed and"
      },
      {
        "start": 5582.46,
        "duration": 5.66,
        "text": "which type of data we already have"
      },
      {
        "start": 5584.92,
        "duration": 5.12,
        "text": "and then these two will map into logical"
      },
      {
        "start": 5588.12,
        "duration": 3.64,
        "text": "data model"
      },
      {
        "start": 5590.04,
        "duration": 3.82,
        "text": "and"
      },
      {
        "start": 5591.76,
        "duration": 3.959,
        "text": "one way to represent it would be using"
      },
      {
        "start": 5593.86,
        "duration": 4.92,
        "text": "Chipotle diagram I will show you an"
      },
      {
        "start": 5595.719,
        "duration": 6.061,
        "text": "example and logical data models still"
      },
      {
        "start": 5598.78,
        "duration": 6.72,
        "text": "can be analyzed and optimized and"
      },
      {
        "start": 5601.78,
        "duration": 6.84,
        "text": "implemented as as a physical data model"
      },
      {
        "start": 5605.5,
        "duration": 6.48,
        "text": "and we will see the physical levels of a"
      },
      {
        "start": 5608.62,
        "duration": 7.26,
        "text": "code diagram and cqo implementation as"
      },
      {
        "start": 5611.98,
        "duration": 6.179,
        "text": "well so four objectives understand data"
      },
      {
        "start": 5615.88,
        "duration": 4.62,
        "text": "identify access pattern and so on four"
      },
      {
        "start": 5618.159,
        "duration": 4.681,
        "text": "models conceptual data model application"
      },
      {
        "start": 5620.5,
        "duration": 5.4,
        "text": "workflow model and two transitions map"
      },
      {
        "start": 5622.84,
        "duration": 5.64,
        "text": "and optimize what is more most difficult"
      },
      {
        "start": 5625.9,
        "duration": 5.759,
        "text": "here is I would say the most difficult"
      },
      {
        "start": 5628.48,
        "duration": 6.06,
        "text": "here is if you're doing it by hand then"
      },
      {
        "start": 5631.659,
        "duration": 4.741,
        "text": "map and optimize and conceptual data"
      },
      {
        "start": 5634.54,
        "duration": 3.599,
        "text": "model properly with the map and optimize"
      },
      {
        "start": 5636.4,
        "duration": 4.2,
        "text": "will be the most difficult if you're"
      },
      {
        "start": 5638.139,
        "duration": 6.06,
        "text": "using a tool then you you're literally"
      },
      {
        "start": 5640.6,
        "duration": 7.559,
        "text": "the mapping will be done for you and and"
      },
      {
        "start": 5644.199,
        "duration": 7.201,
        "text": "maybe even optimization in in some cases"
      },
      {
        "start": 5648.159,
        "duration": 4.621,
        "text": "so the this is the first step we need to"
      },
      {
        "start": 5651.4,
        "duration": 3.02,
        "text": "design conceptual data mode on"
      },
      {
        "start": 5652.78,
        "duration": 5.04,
        "text": "application workflow diagram"
      },
      {
        "start": 5654.42,
        "duration": 5.92,
        "text": "concurrently or one after another which"
      },
      {
        "start": 5657.82,
        "duration": 3.66,
        "text": "one is first probably it's hard to"
      },
      {
        "start": 5660.34,
        "duration": 1.819,
        "text": "decide because"
      },
      {
        "start": 5661.48,
        "duration": 4.02,
        "text": "um"
      },
      {
        "start": 5662.159,
        "duration": 6.641,
        "text": "do you need to some understanding of"
      },
      {
        "start": 5665.5,
        "duration": 5.04,
        "text": "data before you can design queries but"
      },
      {
        "start": 5668.8,
        "duration": 4.08,
        "text": "in any case"
      },
      {
        "start": 5670.54,
        "duration": 4.679,
        "text": "this example of the conceptual data"
      },
      {
        "start": 5672.88,
        "duration": 3.799,
        "text": "model that we already used in the"
      },
      {
        "start": 5675.219,
        "duration": 6.601,
        "text": "previous"
      },
      {
        "start": 5676.679,
        "duration": 7.801,
        "text": "Workshop we have a network that networks"
      },
      {
        "start": 5681.82,
        "duration": 5.64,
        "text": "can have many sensors sensors record"
      },
      {
        "start": 5684.48,
        "duration": 7.0,
        "text": "temperature so each sensor can record"
      },
      {
        "start": 5687.46,
        "duration": 7.259,
        "text": "many has many uh temperature valers each"
      },
      {
        "start": 5691.48,
        "duration": 5.699,
        "text": "one will have a timestamp"
      },
      {
        "start": 5694.719,
        "duration": 4.681,
        "text": "um and the sensors have ID location"
      },
      {
        "start": 5697.179,
        "duration": 4.081,
        "text": "latitude longitude they have some"
      },
      {
        "start": 5699.4,
        "duration": 4.259,
        "text": "characteristics net perhaps name"
      },
      {
        "start": 5701.26,
        "duration": 6.54,
        "text": "description region number of sensors"
      },
      {
        "start": 5703.659,
        "duration": 6.721,
        "text": "network has name as the ID sensor has ID"
      },
      {
        "start": 5707.8,
        "duration": 4.98,
        "text": "as its identifier"
      },
      {
        "start": 5710.38,
        "duration": 5.7,
        "text": "and the temperature"
      },
      {
        "start": 5712.78,
        "duration": 4.68,
        "text": "doesn't have enough attributes it's a"
      },
      {
        "start": 5716.08,
        "duration": 4.139,
        "text": "weak entity type it doesn't have enough"
      },
      {
        "start": 5717.46,
        "duration": 5.12,
        "text": "edit business to define a key the key is"
      },
      {
        "start": 5720.219,
        "duration": 5.821,
        "text": "there is a partial key"
      },
      {
        "start": 5722.58,
        "duration": 8.32,
        "text": "timestamp but also has to borrow the ID"
      },
      {
        "start": 5726.04,
        "duration": 7.38,
        "text": "from the strong edit type from sensor so"
      },
      {
        "start": 5730.9,
        "duration": 5.16,
        "text": "they they you need to uniquely identify"
      },
      {
        "start": 5733.42,
        "duration": 5.699,
        "text": "the value of the temperature you have to"
      },
      {
        "start": 5736.06,
        "duration": 5.099,
        "text": "have both ID and timestamp so this is"
      },
      {
        "start": 5739.119,
        "duration": 4.62,
        "text": "how to read it and we"
      },
      {
        "start": 5741.159,
        "duration": 6.361,
        "text": "I will not spend too much time"
      },
      {
        "start": 5743.739,
        "duration": 5.88,
        "text": "on this right now so this is a example"
      },
      {
        "start": 5747.52,
        "duration": 4.44,
        "text": "of application workflow diagram there"
      },
      {
        "start": 5749.619,
        "duration": 4.141,
        "text": "are four tasks here"
      },
      {
        "start": 5751.96,
        "duration": 4.64,
        "text": "um they and there are they are annotated"
      },
      {
        "start": 5753.76,
        "duration": 6.06,
        "text": "with uh specific data access patterns"
      },
      {
        "start": 5756.6,
        "duration": 4.42,
        "text": "like uh finding information about all"
      },
      {
        "start": 5759.82,
        "duration": 3.66,
        "text": "Networks"
      },
      {
        "start": 5761.02,
        "duration": 5.099,
        "text": "and ordering by name finding hourly"
      },
      {
        "start": 5763.48,
        "duration": 7.44,
        "text": "average temperatures for every sensor"
      },
      {
        "start": 5766.119,
        "duration": 7.741,
        "text": "and so on and so on and then you can see"
      },
      {
        "start": 5770.92,
        "duration": 5.04,
        "text": "because each task query is database we"
      },
      {
        "start": 5773.86,
        "duration": 4.68,
        "text": "need to support this query and how will"
      },
      {
        "start": 5775.96,
        "duration": 5.88,
        "text": "we support this query we will Design"
      },
      {
        "start": 5778.54,
        "duration": 5.94,
        "text": "table for each task to support this"
      },
      {
        "start": 5781.84,
        "duration": 5.58,
        "text": "video usually one table supports one"
      },
      {
        "start": 5784.48,
        "duration": 4.739,
        "text": "Tweety but not always there may be"
      },
      {
        "start": 5787.42,
        "duration": 4.38,
        "text": "multiple queries that that are useful"
      },
      {
        "start": 5789.219,
        "duration": 5.101,
        "text": "that are supported by the same table so"
      },
      {
        "start": 5791.8,
        "duration": 4.319,
        "text": "sorry uh may I would like to step in"
      },
      {
        "start": 5794.32,
        "duration": 4.56,
        "text": "here for a moment"
      },
      {
        "start": 5796.119,
        "duration": 4.381,
        "text": "um there is a very important Point uh"
      },
      {
        "start": 5798.88,
        "duration": 4.14,
        "text": "could you please switch to a previous"
      },
      {
        "start": 5800.5,
        "duration": 4.619,
        "text": "slide yeah right like that is an"
      },
      {
        "start": 5803.02,
        "duration": 4.199,
        "text": "application workflow diagram it"
      },
      {
        "start": 5805.119,
        "duration": 4.341,
        "text": "describes how customer access your"
      },
      {
        "start": 5807.219,
        "duration": 5.101,
        "text": "application uses it"
      },
      {
        "start": 5809.46,
        "duration": 6.219,
        "text": "wants to see in which order what and so"
      },
      {
        "start": 5812.32,
        "duration": 6.12,
        "text": "on how do you build this well it all"
      },
      {
        "start": 5815.679,
        "duration": 5.701,
        "text": "comes with the experience of course but"
      },
      {
        "start": 5818.44,
        "duration": 5.279,
        "text": "for me easiest way to step in and start"
      },
      {
        "start": 5821.38,
        "duration": 5.04,
        "text": "designing application worklight diagram"
      },
      {
        "start": 5823.719,
        "duration": 4.98,
        "text": "was my previous experience with user"
      },
      {
        "start": 5826.42,
        "duration": 5.04,
        "text": "stories maybe you have heard something"
      },
      {
        "start": 5828.699,
        "duration": 5.101,
        "text": "about user stories before remember like"
      },
      {
        "start": 5831.46,
        "duration": 6.719,
        "text": "designing application or designing test"
      },
      {
        "start": 5833.8,
        "duration": 5.18,
        "text": "cases I am starting to think like as a"
      },
      {
        "start": 5838.179,
        "duration": 5.821,
        "text": "customer"
      },
      {
        "start": 5838.98,
        "duration": 9.759,
        "text": "for what four maybe buy something later"
      },
      {
        "start": 5844.0,
        "duration": 8.52,
        "text": "I uh push the button to include some"
      },
      {
        "start": 5848.739,
        "duration": 7.741,
        "text": "particular pink into my uh watch later"
      },
      {
        "start": 5852.52,
        "duration": 6.719,
        "text": "or by later reminder list like imagine"
      },
      {
        "start": 5856.48,
        "duration": 4.139,
        "text": "we are speaking about e-commerce up like"
      },
      {
        "start": 5859.239,
        "duration": 4.801,
        "text": "in Amazon"
      },
      {
        "start": 5860.619,
        "duration": 7.62,
        "text": "and this approach uh user stories as"
      },
      {
        "start": 5864.04,
        "duration": 8.159,
        "text": "customer to do as user role to do"
      },
      {
        "start": 5868.239,
        "duration": 6.301,
        "text": "something I do following steps a very"
      },
      {
        "start": 5872.199,
        "duration": 4.261,
        "text": "simple approach and with this approach"
      },
      {
        "start": 5874.54,
        "duration": 3.78,
        "text": "you can easily analyze your application"
      },
      {
        "start": 5876.46,
        "duration": 2.6,
        "text": "your"
      },
      {
        "start": 5878.32,
        "duration": 5.1,
        "text": "um"
      },
      {
        "start": 5879.06,
        "duration": 7.9,
        "text": "some uh some scientists working with"
      },
      {
        "start": 5883.42,
        "duration": 6.36,
        "text": "this data of a sensors doesn't think"
      },
      {
        "start": 5886.96,
        "duration": 6.36,
        "text": "this way but we have to structure"
      },
      {
        "start": 5889.78,
        "duration": 6.899,
        "text": "um steps he or she will have to do in"
      },
      {
        "start": 5893.32,
        "duration": 6.0,
        "text": "order to reach the data what I need to"
      },
      {
        "start": 5896.679,
        "duration": 4.681,
        "text": "uh what as a as a customer as a"
      },
      {
        "start": 5899.32,
        "duration": 4.56,
        "text": "scientist working with scientifical data"
      },
      {
        "start": 5901.36,
        "duration": 4.74,
        "text": "temperature data I want to do something"
      },
      {
        "start": 5903.88,
        "duration": 4.859,
        "text": "I want to see history of the"
      },
      {
        "start": 5906.1,
        "duration": 5.16,
        "text": "temperatures on a particular location or"
      },
      {
        "start": 5908.739,
        "duration": 5.281,
        "text": "from a particular sensor that is going"
      },
      {
        "start": 5911.26,
        "duration": 5.04,
        "text": "to be my primary query"
      },
      {
        "start": 5914.02,
        "duration": 5.099,
        "text": "and then I start to think"
      },
      {
        "start": 5916.3,
        "duration": 6.48,
        "text": "so that is a goal of my customer at this"
      },
      {
        "start": 5919.119,
        "duration": 6.721,
        "text": "moment and this particular case but"
      },
      {
        "start": 5922.78,
        "duration": 4.98,
        "text": "how do I show temperature values for a"
      },
      {
        "start": 5925.84,
        "duration": 5.64,
        "text": "sensor in order to show temperature"
      },
      {
        "start": 5927.76,
        "duration": 6.359,
        "text": "values for a sensor I need to know which"
      },
      {
        "start": 5931.48,
        "duration": 5.46,
        "text": "sensor we are going to work with do you"
      },
      {
        "start": 5934.119,
        "duration": 6.0,
        "text": "think your users remember IDs of your"
      },
      {
        "start": 5936.94,
        "duration": 6.239,
        "text": "goods or whatever videos on Netflix of"
      },
      {
        "start": 5940.119,
        "duration": 5.881,
        "text": "course not you can just go and show a"
      },
      {
        "start": 5943.179,
        "duration": 4.201,
        "text": "video on Netflix you need to know its ID"
      },
      {
        "start": 5946.0,
        "duration": 5.1,
        "text": "okay"
      },
      {
        "start": 5947.38,
        "duration": 6.42,
        "text": "then in order to give some choice to our"
      },
      {
        "start": 5951.1,
        "duration": 5.22,
        "text": "customer to our scientists we have to do"
      },
      {
        "start": 5953.8,
        "duration": 5.28,
        "text": "what display all sensors in the network"
      },
      {
        "start": 5956.32,
        "duration": 5.52,
        "text": "when we show list a sensor when we show"
      },
      {
        "start": 5959.08,
        "duration": 5.7,
        "text": "list of sensors he or she can click on"
      },
      {
        "start": 5961.84,
        "duration": 5.879,
        "text": "the particular one and get a result"
      },
      {
        "start": 5964.78,
        "duration": 5.879,
        "text": "and here you find very interesting thing"
      },
      {
        "start": 5967.719,
        "duration": 5.701,
        "text": "we use it to think what software has"
      },
      {
        "start": 5970.659,
        "duration": 6.48,
        "text": "dependencies like your python"
      },
      {
        "start": 5973.42,
        "duration": 6.18,
        "text": "application depends on some library or"
      },
      {
        "start": 5977.139,
        "duration": 6.48,
        "text": "your JavaScript application depends on"
      },
      {
        "start": 5979.6,
        "duration": 8.7,
        "text": "half of the world at least according to"
      },
      {
        "start": 5983.619,
        "duration": 7.741,
        "text": "the size of node modulus folder"
      },
      {
        "start": 5988.3,
        "duration": 4.62,
        "text": "but my story is a workflows also have"
      },
      {
        "start": 5991.36,
        "duration": 3.839,
        "text": "dependencies you cannot show"
      },
      {
        "start": 5992.92,
        "duration": 5.64,
        "text": "temperatures as long as you don't show"
      },
      {
        "start": 5995.199,
        "duration": 6.721,
        "text": "something what will allow us to get a ID"
      },
      {
        "start": 5998.56,
        "duration": 4.5,
        "text": "of a sensor and then to show uh sensor"
      },
      {
        "start": 6001.92,
        "duration": 4.38,
        "text": "Networks"
      },
      {
        "start": 6003.06,
        "duration": 5.34,
        "text": "uh you use sensors in the network you"
      },
      {
        "start": 6006.3,
        "duration": 4.8,
        "text": "need to show sensors and heavy"
      },
      {
        "start": 6008.4,
        "duration": 5.52,
        "text": "identified workflows and dependencies"
      },
      {
        "start": 6011.1,
        "duration": 5.7,
        "text": "between them and finally in order to see"
      },
      {
        "start": 6013.92,
        "duration": 5.64,
        "text": "it all I have to log in so here is a"
      },
      {
        "start": 6016.8,
        "duration": 5.7,
        "text": "going to be a q0 actually on this"
      },
      {
        "start": 6019.56,
        "duration": 7.2,
        "text": "workflow hidden for clarity what we will"
      },
      {
        "start": 6022.5,
        "duration": 7.219,
        "text": "need to compare email and password and"
      },
      {
        "start": 6026.76,
        "duration": 2.959,
        "text": "make customer login"
      },
      {
        "start": 6030.8,
        "duration": 5.08,
        "text": "yes absolutely thank you for the"
      },
      {
        "start": 6034.139,
        "duration": 4.261,
        "text": "explanation here Alex"
      },
      {
        "start": 6035.88,
        "duration": 4.259,
        "text": "so the next step"
      },
      {
        "start": 6038.4,
        "duration": 4.44,
        "text": "would be"
      },
      {
        "start": 6040.139,
        "duration": 5.06,
        "text": "designing logical data model"
      },
      {
        "start": 6042.84,
        "duration": 6.0,
        "text": "and uh"
      },
      {
        "start": 6045.199,
        "duration": 5.381,
        "text": "how you design the data model logical"
      },
      {
        "start": 6048.84,
        "duration": 4.799,
        "text": "data model based on the queries you"
      },
      {
        "start": 6050.58,
        "duration": 6.059,
        "text": "already Define in application workflow"
      },
      {
        "start": 6053.639,
        "duration": 6.121,
        "text": "and based on the data and keys and"
      },
      {
        "start": 6056.639,
        "duration": 6.241,
        "text": "cardinalities that that you defined in"
      },
      {
        "start": 6059.76,
        "duration": 5.64,
        "text": "the conceptual data model so there are"
      },
      {
        "start": 6062.88,
        "duration": 4.92,
        "text": "some basic rules you can follow when"
      },
      {
        "start": 6065.4,
        "duration": 4.08,
        "text": "you're designing those tables I call"
      },
      {
        "start": 6067.8,
        "duration": 2.76,
        "text": "them mapping rules and and there are"
      },
      {
        "start": 6069.48,
        "duration": 3.84,
        "text": "five of them"
      },
      {
        "start": 6070.56,
        "duration": 6.0,
        "text": "so the first one uh"
      },
      {
        "start": 6073.32,
        "duration": 6.62,
        "text": "is based on conceptual data model so the"
      },
      {
        "start": 6076.56,
        "duration": 6.84,
        "text": "the the query that you're going to"
      },
      {
        "start": 6079.94,
        "duration": 5.679,
        "text": "support will involve some entities and"
      },
      {
        "start": 6083.4,
        "duration": 4.38,
        "text": "relationship from that model so you will"
      },
      {
        "start": 6085.619,
        "duration": 6.361,
        "text": "the The Entity relationship types will"
      },
      {
        "start": 6087.78,
        "duration": 6.3,
        "text": "become tables and the attributes uh type"
      },
      {
        "start": 6091.98,
        "duration": 5.52,
        "text": "attribute types will become respect"
      },
      {
        "start": 6094.08,
        "duration": 6.84,
        "text": "respectively columns in those tables so"
      },
      {
        "start": 6097.5,
        "duration": 6.48,
        "text": "this is the first rule the second one is"
      },
      {
        "start": 6100.92,
        "duration": 5.46,
        "text": "based on the next three are based on the"
      },
      {
        "start": 6103.98,
        "duration": 5.699,
        "text": "query so the second one equality search"
      },
      {
        "start": 6106.38,
        "duration": 6.06,
        "text": "attributes in your query predicate will"
      },
      {
        "start": 6109.679,
        "duration": 5.161,
        "text": "become the beginning counts of primary"
      },
      {
        "start": 6112.44,
        "duration": 5.82,
        "text": "key they will form form partition key"
      },
      {
        "start": 6114.84,
        "duration": 5.7,
        "text": "and possibly subset of clustering key"
      },
      {
        "start": 6118.26,
        "duration": 3.78,
        "text": "all maybe just partition key but they"
      },
      {
        "start": 6120.54,
        "duration": 3.84,
        "text": "will be in the beginning of your primary"
      },
      {
        "start": 6122.04,
        "duration": 4.079,
        "text": "key inequality search attributes will"
      },
      {
        "start": 6124.38,
        "duration": 4.38,
        "text": "have to be clustering columns but"
      },
      {
        "start": 6126.119,
        "duration": 5.401,
        "text": "because that's the only way we can do"
      },
      {
        "start": 6128.76,
        "duration": 5.34,
        "text": "inequality greater than less than"
      },
      {
        "start": 6131.52,
        "duration": 4.74,
        "text": "and ordering attributes"
      },
      {
        "start": 6134.1,
        "duration": 4.92,
        "text": "will map the cluster income because"
      },
      {
        "start": 6136.26,
        "duration": 5.399,
        "text": "that's the only way we will be able to"
      },
      {
        "start": 6139.02,
        "duration": 4.92,
        "text": "sort data in Cassandra"
      },
      {
        "start": 6141.659,
        "duration": 5.881,
        "text": "and the final one the final one is"
      },
      {
        "start": 6143.94,
        "duration": 7.08,
        "text": "usually where most people uh stumble"
      },
      {
        "start": 6147.54,
        "duration": 5.82,
        "text": "with they have difficulty with uh and"
      },
      {
        "start": 6151.02,
        "duration": 4.74,
        "text": "and design incorrect primary Keys is"
      },
      {
        "start": 6153.36,
        "duration": 4.759,
        "text": "this key attributes key attributes from"
      },
      {
        "start": 6155.76,
        "duration": 5.879,
        "text": "conceptual data model"
      },
      {
        "start": 6158.119,
        "duration": 4.381,
        "text": "they will have to be part of the primary"
      },
      {
        "start": 6161.639,
        "duration": 4.141,
        "text": "key"
      },
      {
        "start": 6162.5,
        "duration": 7.119,
        "text": "in your table to maintain uniqueness"
      },
      {
        "start": 6165.78,
        "duration": 6.3,
        "text": "okay and those keys are of course when"
      },
      {
        "start": 6169.619,
        "duration": 4.62,
        "text": "you so for entity types usually easy to"
      },
      {
        "start": 6172.08,
        "duration": 3.96,
        "text": "define the key but you need to also"
      },
      {
        "start": 6174.239,
        "duration": 3.661,
        "text": "Define for relationship types and they"
      },
      {
        "start": 6176.04,
        "duration": 4.02,
        "text": "usually not even shown on the diagrams"
      },
      {
        "start": 6177.9,
        "duration": 4.08,
        "text": "because they can be derived so let's see"
      },
      {
        "start": 6180.06,
        "duration": 5.28,
        "text": "an example how we can apply this rule"
      },
      {
        "start": 6181.98,
        "duration": 5.88,
        "text": "this is a query five that was not I"
      },
      {
        "start": 6185.34,
        "duration": 4.92,
        "text": "specifically made a more complexity so"
      },
      {
        "start": 6187.86,
        "duration": 6.66,
        "text": "you can you can demonstrate all five"
      },
      {
        "start": 6190.26,
        "duration": 6.32,
        "text": "rules that's the same subset of our"
      },
      {
        "start": 6194.52,
        "duration": 5.28,
        "text": "conceptual data model sensory courts"
      },
      {
        "start": 6196.58,
        "duration": 6.28,
        "text": "temperature and the nuclear fine draw"
      },
      {
        "start": 6199.8,
        "duration": 6.48,
        "text": "measurements for a given location and a"
      },
      {
        "start": 6202.86,
        "duration": 4.74,
        "text": "daytime range order by timestamp"
      },
      {
        "start": 6206.28,
        "duration": 2.399,
        "text": "descending"
      },
      {
        "start": 6207.6,
        "duration": 4.579,
        "text": "so"
      },
      {
        "start": 6208.679,
        "duration": 6.601,
        "text": "obviously here we creating"
      },
      {
        "start": 6212.179,
        "duration": 5.381,
        "text": "all of this subsets so we basically"
      },
      {
        "start": 6215.28,
        "duration": 5.58,
        "text": "creating this relationship that involves"
      },
      {
        "start": 6217.56,
        "duration": 5.88,
        "text": "sensor and temperature and we call this"
      },
      {
        "start": 6220.86,
        "duration": 5.12,
        "text": "stable temperatures by sensor and we are"
      },
      {
        "start": 6223.44,
        "duration": 5.88,
        "text": "going to need Valor we're going to need"
      },
      {
        "start": 6225.98,
        "duration": 5.739,
        "text": "latitude longitude and time step"
      },
      {
        "start": 6229.32,
        "duration": 4.7,
        "text": "so that's the mapping rule number one"
      },
      {
        "start": 6231.719,
        "duration": 5.281,
        "text": "maybe rule number two"
      },
      {
        "start": 6234.02,
        "duration": 5.74,
        "text": "equality search attributes from our"
      },
      {
        "start": 6237.0,
        "duration": 5.34,
        "text": "query will become the beginning the"
      },
      {
        "start": 6239.76,
        "duration": 5.64,
        "text": "prefix of our primary key they will form"
      },
      {
        "start": 6242.34,
        "duration": 5.48,
        "text": "partition key completely also or part of"
      },
      {
        "start": 6245.4,
        "duration": 5.04,
        "text": "it so in this case what what do we see"
      },
      {
        "start": 6247.82,
        "duration": 4.96,
        "text": "given location"
      },
      {
        "start": 6250.44,
        "duration": 4.62,
        "text": "okay given location"
      },
      {
        "start": 6252.78,
        "duration": 3.959,
        "text": "daytime range doesn't count it's not"
      },
      {
        "start": 6255.06,
        "duration": 4.38,
        "text": "equality it's inequality so given"
      },
      {
        "start": 6256.739,
        "duration": 6.781,
        "text": "location is slightly longitude so"
      },
      {
        "start": 6259.44,
        "duration": 4.08,
        "text": "latitude longitude become"
      },
      {
        "start": 6264.06,
        "duration": 7.98,
        "text": "the partition key columns"
      },
      {
        "start": 6269.159,
        "duration": 5.701,
        "text": "and see there is a network problem"
      },
      {
        "start": 6272.04,
        "duration": 4.86,
        "text": "in the chat"
      },
      {
        "start": 6274.86,
        "duration": 4.44,
        "text": "um yeah looks like some network is"
      },
      {
        "start": 6276.9,
        "duration": 3.06,
        "text": "lagging somewhere today"
      },
      {
        "start": 6279.3,
        "duration": 3.18,
        "text": "um"
      },
      {
        "start": 6279.96,
        "duration": 6.14,
        "text": "we cannot change it anyhow right now so"
      },
      {
        "start": 6282.48,
        "duration": 3.62,
        "text": "I hope it's just not too bad"
      },
      {
        "start": 6287.1,
        "duration": 5.82,
        "text": "yeah I can hear Alex"
      },
      {
        "start": 6289.32,
        "duration": 5.52,
        "text": "uh in real time no issues at all yeah so"
      },
      {
        "start": 6292.92,
        "duration": 4.92,
        "text": "mostly probably is between me and"
      },
      {
        "start": 6294.84,
        "duration": 6.18,
        "text": "restream or between restream and YouTube"
      },
      {
        "start": 6297.84,
        "duration": 5.76,
        "text": "or maybe restream server"
      },
      {
        "start": 6301.02,
        "duration": 5.88,
        "text": "yes yes sorry for that"
      },
      {
        "start": 6303.6,
        "duration": 5.94,
        "text": "so continue with this example"
      },
      {
        "start": 6306.9,
        "duration": 4.38,
        "text": "let it longitude will be"
      },
      {
        "start": 6309.54,
        "duration": 3.72,
        "text": "either both of them will be partition"
      },
      {
        "start": 6311.28,
        "duration": 3.66,
        "text": "key or one of them will be partition key"
      },
      {
        "start": 6313.26,
        "duration": 3.06,
        "text": "the other one cluster income but they"
      },
      {
        "start": 6314.94,
        "duration": 3.719,
        "text": "will be in the beginning of the primary"
      },
      {
        "start": 6316.32,
        "duration": 4.319,
        "text": "key in this case both of them I decided"
      },
      {
        "start": 6318.659,
        "duration": 5.52,
        "text": "let both of them location will be"
      },
      {
        "start": 6320.639,
        "duration": 5.881,
        "text": "partition key the next rule is going to"
      },
      {
        "start": 6324.179,
        "duration": 5.341,
        "text": "class the inequality search will become"
      },
      {
        "start": 6326.52,
        "duration": 5.4,
        "text": "clustering columns so date time range is"
      },
      {
        "start": 6329.52,
        "duration": 4.56,
        "text": "our timestamp so we add in timestamp"
      },
      {
        "start": 6331.92,
        "duration": 4.199,
        "text": "here as a clustering column it's"
      },
      {
        "start": 6334.08,
        "duration": 5.639,
        "text": "ascending order because we don't care"
      },
      {
        "start": 6336.119,
        "duration": 7.02,
        "text": "about order yet and the next rule rule"
      },
      {
        "start": 6339.719,
        "duration": 6.121,
        "text": "number four says that the if you need to"
      },
      {
        "start": 6343.139,
        "duration": 5.221,
        "text": "order right the ordering attributes will"
      },
      {
        "start": 6345.84,
        "duration": 4.98,
        "text": "have to become clustering columns and"
      },
      {
        "start": 6348.36,
        "duration": 4.68,
        "text": "you need to switch you need to use"
      },
      {
        "start": 6350.82,
        "duration": 6.18,
        "text": "correct order"
      },
      {
        "start": 6353.04,
        "duration": 6.42,
        "text": "sorry correct order so in this case when"
      },
      {
        "start": 6357.0,
        "duration": 6.06,
        "text": "we apply Maple rule four we get the"
      },
      {
        "start": 6359.46,
        "duration": 4.62,
        "text": "cluster in column descending order in"
      },
      {
        "start": 6363.06,
        "duration": 3.84,
        "text": "this case"
      },
      {
        "start": 6364.08,
        "duration": 6.119,
        "text": "and then the final rule the final rule"
      },
      {
        "start": 6366.9,
        "duration": 5.819,
        "text": "says that we need to make sure that the"
      },
      {
        "start": 6370.199,
        "duration": 6.721,
        "text": "key in this case key of this"
      },
      {
        "start": 6372.719,
        "duration": 8.46,
        "text": "relationship is preserved in our primary"
      },
      {
        "start": 6376.92,
        "duration": 7.319,
        "text": "key so we still need to add sensor"
      },
      {
        "start": 6381.179,
        "duration": 5.221,
        "text": "to uniquely identify our failure right"
      },
      {
        "start": 6384.239,
        "duration": 5.281,
        "text": "it's location"
      },
      {
        "start": 6386.4,
        "duration": 5.88,
        "text": "is how we want to retrieve the data but"
      },
      {
        "start": 6389.52,
        "duration": 5.28,
        "text": "the daily uniquely identified by sensor"
      },
      {
        "start": 6392.28,
        "duration": 4.74,
        "text": "and timestamp right so we still need to"
      },
      {
        "start": 6394.8,
        "duration": 4.02,
        "text": "add the sensor and this is this is the"
      },
      {
        "start": 6397.02,
        "duration": 4.02,
        "text": "last rule that that most of the time"
      },
      {
        "start": 6398.82,
        "duration": 4.379,
        "text": "people make error here for getting this"
      },
      {
        "start": 6401.04,
        "duration": 4.56,
        "text": "sensor but this is how to how to apply"
      },
      {
        "start": 6403.199,
        "duration": 4.98,
        "text": "that we can actually do this example in"
      },
      {
        "start": 6405.6,
        "duration": 6.019,
        "text": "in our data modeling tool later and see"
      },
      {
        "start": 6408.179,
        "duration": 6.0,
        "text": "how it constructs this type of uh"
      },
      {
        "start": 6411.619,
        "duration": 3.761,
        "text": "primary key for us"
      },
      {
        "start": 6414.179,
        "duration": 4.881,
        "text": "so"
      },
      {
        "start": 6415.38,
        "duration": 7.319,
        "text": "following these rules we can support our"
      },
      {
        "start": 6419.06,
        "duration": 6.88,
        "text": "keys by by designing this logical data"
      },
      {
        "start": 6422.699,
        "duration": 6.061,
        "text": "model with with Stables we have the"
      },
      {
        "start": 6425.94,
        "duration": 5.699,
        "text": "sensor byte Network table that we used"
      },
      {
        "start": 6428.76,
        "duration": 5.76,
        "text": "already and and we applied"
      },
      {
        "start": 6431.639,
        "duration": 4.98,
        "text": "as an example Dynamic bike bucketing on"
      },
      {
        "start": 6434.52,
        "duration": 4.86,
        "text": "this on this table but this is how it"
      },
      {
        "start": 6436.619,
        "duration": 6.901,
        "text": "looks looks like and"
      },
      {
        "start": 6439.38,
        "duration": 7.319,
        "text": "for the sake of time I will skip"
      },
      {
        "start": 6443.52,
        "duration": 5.639,
        "text": "description of each table but I will"
      },
      {
        "start": 6446.699,
        "duration": 4.92,
        "text": "show you later then in in the data"
      },
      {
        "start": 6449.159,
        "duration": 5.761,
        "text": "modeling tool so"
      },
      {
        "start": 6451.619,
        "duration": 5.781,
        "text": "and the final step is to optimize and"
      },
      {
        "start": 6454.92,
        "duration": 5.52,
        "text": "implement the result"
      },
      {
        "start": 6457.4,
        "duration": 4.779,
        "text": "in Cassandra using Cassandra queer"
      },
      {
        "start": 6460.44,
        "duration": 4.679,
        "text": "language so"
      },
      {
        "start": 6462.179,
        "duration": 5.52,
        "text": "in this case the what kind of"
      },
      {
        "start": 6465.119,
        "duration": 5.341,
        "text": "optimization so probably the the five"
      },
      {
        "start": 6467.699,
        "duration": 4.741,
        "text": "most common ones are here the partition"
      },
      {
        "start": 6470.46,
        "duration": 4.02,
        "text": "size is split in large partitions when"
      },
      {
        "start": 6472.44,
        "duration": 4.08,
        "text": "we kind of already discuss it in with"
      },
      {
        "start": 6474.48,
        "duration": 4.56,
        "text": "Dynamic bucketing and and this large"
      },
      {
        "start": 6476.52,
        "duration": 5.58,
        "text": "partitions hot partitions spend a lot of"
      },
      {
        "start": 6479.04,
        "duration": 5.699,
        "text": "time on that and data duplications and"
      },
      {
        "start": 6482.1,
        "duration": 6.119,
        "text": "and maybe you can use batches sometimes"
      },
      {
        "start": 6484.739,
        "duration": 5.4,
        "text": "to solve the problem uh indexing and"
      },
      {
        "start": 6488.219,
        "duration": 4.681,
        "text": "materialized views will we use them will"
      },
      {
        "start": 6490.139,
        "duration": 4.281,
        "text": "we not use them what are the pros and"
      },
      {
        "start": 6492.9,
        "duration": 3.96,
        "text": "cons"
      },
      {
        "start": 6494.42,
        "duration": 6.34,
        "text": "concurrent data access if you have"
      },
      {
        "start": 6496.86,
        "duration": 7.859,
        "text": "multiple uh multiple user multiple"
      },
      {
        "start": 6500.76,
        "duration": 7.22,
        "text": "applications changing the same Valor is"
      },
      {
        "start": 6504.719,
        "duration": 7.381,
        "text": "is the change either important if uh"
      },
      {
        "start": 6507.98,
        "duration": 6.46,
        "text": "will it will there be any conflict right"
      },
      {
        "start": 6512.1,
        "duration": 3.599,
        "text": "so we can we if we have time we can"
      },
      {
        "start": 6514.44,
        "duration": 4.199,
        "text": "discuss"
      },
      {
        "start": 6515.699,
        "duration": 5.04,
        "text": "that or maybe discussed in in a separate"
      },
      {
        "start": 6518.639,
        "duration": 4.381,
        "text": "Workshop but lightweight transactions is"
      },
      {
        "start": 6520.739,
        "duration": 5.341,
        "text": "one way to solve that and dealing with"
      },
      {
        "start": 6523.02,
        "duration": 6.3,
        "text": "with storm Stones is also an interesting"
      },
      {
        "start": 6526.08,
        "duration": 6.24,
        "text": "topic that will probably not have time"
      },
      {
        "start": 6529.32,
        "duration": 5.46,
        "text": "to talk about today so that actually"
      },
      {
        "start": 6532.32,
        "duration": 5.04,
        "text": "three optimizations that were applied"
      },
      {
        "start": 6534.78,
        "duration": 5.16,
        "text": "here on physical data model first of all"
      },
      {
        "start": 6537.36,
        "duration": 5.46,
        "text": "what's the difference that you have data"
      },
      {
        "start": 6539.94,
        "duration": 4.98,
        "text": "types specified but also in green here"
      },
      {
        "start": 6542.82,
        "duration": 5.58,
        "text": "we have"
      },
      {
        "start": 6544.92,
        "duration": 5.64,
        "text": "um we have the highlighted the the"
      },
      {
        "start": 6548.4,
        "duration": 5.1,
        "text": "optimization that we applied since we"
      },
      {
        "start": 6550.56,
        "duration": 5.579,
        "text": "want to retrieve all the networks we put"
      },
      {
        "start": 6553.5,
        "duration": 5.46,
        "text": "all of them into one bucket so we can"
      },
      {
        "start": 6556.139,
        "duration": 5.58,
        "text": "only access one bucket on one partition"
      },
      {
        "start": 6558.96,
        "duration": 5.4,
        "text": "this is the optimization set of storing"
      },
      {
        "start": 6561.719,
        "duration": 4.44,
        "text": "each Network in a separate partition we"
      },
      {
        "start": 6564.36,
        "duration": 4.5,
        "text": "store in all of them in one partition so"
      },
      {
        "start": 6566.159,
        "duration": 4.881,
        "text": "we can retrieve them as one partition"
      },
      {
        "start": 6568.86,
        "duration": 6.06,
        "text": "very"
      },
      {
        "start": 6571.04,
        "duration": 5.199,
        "text": "two optimizations here eight hours into"
      },
      {
        "start": 6574.92,
        "duration": 3.48,
        "text": "one column"
      },
      {
        "start": 6576.239,
        "duration": 3.9,
        "text": "season dates separately in our"
      },
      {
        "start": 6578.4,
        "duration": 5.58,
        "text": "separately we're just using timestamp"
      },
      {
        "start": 6580.139,
        "duration": 7.621,
        "text": "and storing them together and also week"
      },
      {
        "start": 6583.98,
        "duration": 7.8,
        "text": "was added as part of the partition key"
      },
      {
        "start": 6587.76,
        "duration": 7.68,
        "text": "and you probably know why to split the"
      },
      {
        "start": 6591.78,
        "duration": 5.879,
        "text": "large partition because the um if we"
      },
      {
        "start": 6595.44,
        "duration": 4.739,
        "text": "don't add any time component into"
      },
      {
        "start": 6597.659,
        "duration": 5.46,
        "text": "partition key then our partition grows"
      },
      {
        "start": 6600.179,
        "duration": 5.101,
        "text": "over time and and it will become a large"
      },
      {
        "start": 6603.119,
        "duration": 4.921,
        "text": "partition"
      },
      {
        "start": 6605.28,
        "duration": 5.399,
        "text": "and finally implementing these tables in"
      },
      {
        "start": 6608.04,
        "duration": 4.199,
        "text": "cql should be quite straightforward"
      },
      {
        "start": 6610.679,
        "duration": 5.641,
        "text": "the um"
      },
      {
        "start": 6612.239,
        "duration": 5.301,
        "text": "either the same tables and with data"
      },
      {
        "start": 6616.32,
        "duration": 4.62,
        "text": "types with"
      },
      {
        "start": 6617.54,
        "duration": 6.4,
        "text": "Partition classroom key primary key"
      },
      {
        "start": 6620.94,
        "duration": 6.06,
        "text": "design so one one of the things I wanted"
      },
      {
        "start": 6623.94,
        "duration": 5.759,
        "text": "to mention here to wrap it up with this"
      },
      {
        "start": 6627.0,
        "duration": 4.38,
        "text": "approach or methodology"
      },
      {
        "start": 6629.699,
        "duration": 3.0,
        "text": "is that"
      },
      {
        "start": 6631.38,
        "duration": 3.299,
        "text": "uh"
      },
      {
        "start": 6632.699,
        "duration": 3.9,
        "text": "what's the difference actually between"
      },
      {
        "start": 6634.679,
        "duration": 6.301,
        "text": "relational data modeling and Cassandra"
      },
      {
        "start": 6636.599,
        "duration": 6.481,
        "text": "data modeling okay and you can see these"
      },
      {
        "start": 6640.98,
        "duration": 3.78,
        "text": "two methodologies they have some things"
      },
      {
        "start": 6643.08,
        "duration": 4.139,
        "text": "in common like you you can use"
      },
      {
        "start": 6644.76,
        "duration": 3.359,
        "text": "conceptual data model design in both of"
      },
      {
        "start": 6647.219,
        "duration": 4.281,
        "text": "them"
      },
      {
        "start": 6648.119,
        "duration": 5.461,
        "text": "but the big difference is that"
      },
      {
        "start": 6651.5,
        "duration": 6.52,
        "text": "you do not"
      },
      {
        "start": 6653.58,
        "duration": 6.539,
        "text": "use normalization CE and the queries in"
      },
      {
        "start": 6658.02,
        "duration": 4.44,
        "text": "relational approach"
      },
      {
        "start": 6660.119,
        "duration": 5.58,
        "text": "so you you do conceptual map it to"
      },
      {
        "start": 6662.46,
        "duration": 6.779,
        "text": "relational logical then map normalize it"
      },
      {
        "start": 6665.699,
        "duration": 5.221,
        "text": "get normalized and then you do physical"
      },
      {
        "start": 6669.239,
        "duration": 4.261,
        "text": "optimizations that's when your physical"
      },
      {
        "start": 6670.92,
        "duration": 4.199,
        "text": "optimization that's when your quiz I use"
      },
      {
        "start": 6673.5,
        "duration": 4.44,
        "text": "that when you decide okay I need to"
      },
      {
        "start": 6675.119,
        "duration": 6.6,
        "text": "create an index here uh or to support"
      },
      {
        "start": 6677.94,
        "duration": 4.86,
        "text": "specific join or or select and I also"
      },
      {
        "start": 6681.719,
        "duration": 1.98,
        "text": "need to"
      },
      {
        "start": 6682.8,
        "duration": 4.56,
        "text": "um"
      },
      {
        "start": 6683.699,
        "duration": 7.261,
        "text": "maybe denormalize because this join is"
      },
      {
        "start": 6687.36,
        "duration": 6.48,
        "text": "not performing as fast as I wanted to uh"
      },
      {
        "start": 6690.96,
        "duration": 5.52,
        "text": "and and things like that in case of"
      },
      {
        "start": 6693.84,
        "duration": 4.74,
        "text": "Cassandra there are fewer steps uh and"
      },
      {
        "start": 6696.48,
        "duration": 5.54,
        "text": "actually I would say it's a simpler"
      },
      {
        "start": 6698.58,
        "duration": 7.139,
        "text": "methodology even so um"
      },
      {
        "start": 6702.02,
        "duration": 6.04,
        "text": "it's not the easiest one right but uh"
      },
      {
        "start": 6705.719,
        "duration": 4.5,
        "text": "you you can you can see there's the"
      },
      {
        "start": 6708.06,
        "duration": 4.26,
        "text": "queries will be used right away to"
      },
      {
        "start": 6710.219,
        "duration": 4.801,
        "text": "design your tables and there will be no"
      },
      {
        "start": 6712.32,
        "duration": 4.399,
        "text": "normalization right so"
      },
      {
        "start": 6715.02,
        "duration": 6.619,
        "text": "that's a difference"
      },
      {
        "start": 6716.719,
        "duration": 8.38,
        "text": "and with that said I will show you"
      },
      {
        "start": 6721.639,
        "duration": 5.381,
        "text": "KDM data modeling tool which one is"
      },
      {
        "start": 6725.099,
        "duration": 6.901,
        "text": "great"
      },
      {
        "start": 6727.02,
        "duration": 6.719,
        "text": "and it's part of the hour a game GitHub"
      },
      {
        "start": 6732.0,
        "duration": 3.239,
        "text": "Workshop"
      },
      {
        "start": 6733.739,
        "duration": 4.621,
        "text": "uh"
      },
      {
        "start": 6735.239,
        "duration": 5.761,
        "text": "the readme file so you can"
      },
      {
        "start": 6738.36,
        "duration": 4.799,
        "text": "the the tool itself itself you can just"
      },
      {
        "start": 6741.0,
        "duration": 5.52,
        "text": "open it online and you can download the"
      },
      {
        "start": 6743.159,
        "duration": 6.02,
        "text": "XML file which is a project file and you"
      },
      {
        "start": 6746.52,
        "duration": 4.98,
        "text": "can follow me"
      },
      {
        "start": 6749.179,
        "duration": 6.04,
        "text": "follow what I'm doing but I will show"
      },
      {
        "start": 6751.5,
        "duration": 5.04,
        "text": "you first this is just an empty empty"
      },
      {
        "start": 6755.219,
        "duration": 4.98,
        "text": "project"
      },
      {
        "start": 6756.54,
        "duration": 5.94,
        "text": "um for the for the KDM tool"
      },
      {
        "start": 6760.199,
        "duration": 4.5,
        "text": "there is nothing defined here but I will"
      },
      {
        "start": 6762.48,
        "duration": 4.86,
        "text": "show you how to do it so"
      },
      {
        "start": 6764.699,
        "duration": 6.121,
        "text": "um it's it's not that difficult so we"
      },
      {
        "start": 6767.34,
        "duration": 7.68,
        "text": "will try to do our uh just one"
      },
      {
        "start": 6770.82,
        "duration": 8.48,
        "text": "relationship just just to see see the"
      },
      {
        "start": 6775.02,
        "duration": 4.28,
        "text": "process so we had the network"
      },
      {
        "start": 6779.82,
        "duration": 4.52,
        "text": "and we have uh sensor"
      },
      {
        "start": 6785.34,
        "duration": 7.259,
        "text": "okay and we have relationship"
      },
      {
        "start": 6788.48,
        "duration": 6.84,
        "text": "networks let's say has sensor we will"
      },
      {
        "start": 6792.599,
        "duration": 2.721,
        "text": "connect them"
      },
      {
        "start": 6796.139,
        "duration": 7.02,
        "text": "okay we will say the network can have"
      },
      {
        "start": 6799.02,
        "duration": 7.02,
        "text": "many sensors so I will annotate with"
      },
      {
        "start": 6803.159,
        "duration": 4.621,
        "text": "many and each sensor belongs to One"
      },
      {
        "start": 6806.04,
        "duration": 3.599,
        "text": "Network"
      },
      {
        "start": 6807.78,
        "duration": 4.64,
        "text": "I will annotate"
      },
      {
        "start": 6809.639,
        "duration": 6.301,
        "text": "now I need to add some attributes let's"
      },
      {
        "start": 6812.42,
        "duration": 5.819,
        "text": "not get too crazy just add couple of"
      },
      {
        "start": 6815.94,
        "duration": 6.48,
        "text": "them for"
      },
      {
        "start": 6818.239,
        "duration": 8.44,
        "text": "each one so there will be name of the"
      },
      {
        "start": 6822.42,
        "duration": 4.259,
        "text": "network and description"
      },
      {
        "start": 6826.699,
        "duration": 6.46,
        "text": "and the ID of the sensor"
      },
      {
        "start": 6830.28,
        "duration": 8.06,
        "text": "and say description"
      },
      {
        "start": 6833.159,
        "duration": 5.181,
        "text": "okay let's connect them to you"
      },
      {
        "start": 6840.9,
        "duration": 5.66,
        "text": "did I connect it right did I not let me"
      },
      {
        "start": 6843.96,
        "duration": 2.6,
        "text": "check yes"
      },
      {
        "start": 6847.139,
        "duration": 6.361,
        "text": "okay and then I will we need to design"
      },
      {
        "start": 6850.44,
        "duration": 5.46,
        "text": "this designate a key attributes so right"
      },
      {
        "start": 6853.5,
        "duration": 4.199,
        "text": "click this is gonna be our key for the"
      },
      {
        "start": 6855.9,
        "duration": 7.52,
        "text": "network this is gonna be"
      },
      {
        "start": 6857.699,
        "duration": 8.581,
        "text": "uh ID is going to be key okay so this"
      },
      {
        "start": 6863.42,
        "duration": 5.739,
        "text": "let's go to the next step access"
      },
      {
        "start": 6866.28,
        "duration": 5.76,
        "text": "patterns we will only use one just one"
      },
      {
        "start": 6869.159,
        "duration": 3.96,
        "text": "want to show you how to do it the"
      },
      {
        "start": 6872.04,
        "duration": 5.699,
        "text": "um so"
      },
      {
        "start": 6873.119,
        "duration": 7.741,
        "text": "as I said just just a simple tutorial so"
      },
      {
        "start": 6877.739,
        "duration": 5.46,
        "text": "let's retrieve all sensors in a network"
      },
      {
        "start": 6880.86,
        "duration": 5.46,
        "text": "we had a query like that so what we want"
      },
      {
        "start": 6883.199,
        "duration": 9.061,
        "text": "to find is the sensor ID"
      },
      {
        "start": 6886.32,
        "duration": 8.7,
        "text": "so find sensor ID and find description"
      },
      {
        "start": 6892.26,
        "duration": 4.02,
        "text": "and what is given is the name of the"
      },
      {
        "start": 6895.02,
        "duration": 3.84,
        "text": "network"
      },
      {
        "start": 6896.28,
        "duration": 5.819,
        "text": "okay given name"
      },
      {
        "start": 6898.86,
        "duration": 5.879,
        "text": "uh and at this point we can click"
      },
      {
        "start": 6902.099,
        "duration": 4.981,
        "text": "logical and this is a table that is"
      },
      {
        "start": 6904.739,
        "duration": 4.38,
        "text": "generated for us given the name of the"
      },
      {
        "start": 6907.08,
        "duration": 5.22,
        "text": "sensors as a banana the name of the set"
      },
      {
        "start": 6909.119,
        "duration": 6.54,
        "text": "the network will get we can find ID and"
      },
      {
        "start": 6912.3,
        "duration": 5.819,
        "text": "sensor description okay"
      },
      {
        "start": 6915.659,
        "duration": 6.0,
        "text": "um and the we can continue and generate"
      },
      {
        "start": 6918.119,
        "duration": 6.241,
        "text": "physical besides okay ID will be maybe"
      },
      {
        "start": 6921.659,
        "duration": 6.96,
        "text": "this time it will be uuid"
      },
      {
        "start": 6924.36,
        "duration": 7.62,
        "text": "and then cqo and finally we have the"
      },
      {
        "start": 6928.619,
        "duration": 7.02,
        "text": "table that we can use yay"
      },
      {
        "start": 6931.98,
        "duration": 6.179,
        "text": "yes uh what happens if we change the"
      },
      {
        "start": 6935.639,
        "duration": 6.0,
        "text": "cardinality why cardinality is important"
      },
      {
        "start": 6938.159,
        "duration": 5.281,
        "text": "let me say the different cardinality I"
      },
      {
        "start": 6941.639,
        "duration": 3.181,
        "text": "will regenerate"
      },
      {
        "start": 6943.44,
        "duration": 4.02,
        "text": "the"
      },
      {
        "start": 6944.82,
        "duration": 4.14,
        "text": "well you know in this the not for this"
      },
      {
        "start": 6947.46,
        "duration": 3.42,
        "text": "query I will also need to change the"
      },
      {
        "start": 6948.96,
        "duration": 4.88,
        "text": "query anyway"
      },
      {
        "start": 6950.88,
        "duration": 4.68,
        "text": "let me show more complex feeling"
      },
      {
        "start": 6953.84,
        "duration": 4.5,
        "text": "for you"
      },
      {
        "start": 6955.56,
        "duration": 2.78,
        "text": "with"
      },
      {
        "start": 6958.679,
        "duration": 6.361,
        "text": "with the actual example that we have in"
      },
      {
        "start": 6962.28,
        "duration": 6.0,
        "text": "the slides okay so this is this should"
      },
      {
        "start": 6965.04,
        "duration": 6.119,
        "text": "be familiar Network sensors"
      },
      {
        "start": 6968.28,
        "duration": 4.14,
        "text": "um uh these are the four queries that we"
      },
      {
        "start": 6971.159,
        "duration": 3.301,
        "text": "defined"
      },
      {
        "start": 6972.42,
        "duration": 5.1,
        "text": "in"
      },
      {
        "start": 6974.46,
        "duration": 5.159,
        "text": "this tool and also in our model that we"
      },
      {
        "start": 6977.52,
        "duration": 3.9,
        "text": "already discussed right the finding"
      },
      {
        "start": 6979.619,
        "duration": 4.261,
        "text": "information"
      },
      {
        "start": 6981.42,
        "duration": 4.679,
        "text": "about all Networks"
      },
      {
        "start": 6983.88,
        "duration": 6.96,
        "text": "finding hourly average temperature"
      },
      {
        "start": 6986.099,
        "duration": 7.56,
        "text": "finding information about all sensors"
      },
      {
        "start": 6990.84,
        "duration": 3.6,
        "text": "um finding raw measurements and all of"
      },
      {
        "start": 6993.659,
        "duration": 4.621,
        "text": "that"
      },
      {
        "start": 6994.44,
        "duration": 5.04,
        "text": "so all four are defined we can generate"
      },
      {
        "start": 6998.28,
        "duration": 3.959,
        "text": "logical"
      },
      {
        "start": 6999.48,
        "duration": 4.92,
        "text": "and sometimes we'll have a choice right"
      },
      {
        "start": 7002.239,
        "duration": 4.081,
        "text": "we can choose one of these tables for"
      },
      {
        "start": 7004.4,
        "duration": 4.14,
        "text": "example so"
      },
      {
        "start": 7006.32,
        "duration": 5.22,
        "text": "um and and usually the choice is because"
      },
      {
        "start": 7008.54,
        "duration": 5.94,
        "text": "of the ordering like ID and date change"
      },
      {
        "start": 7011.54,
        "duration": 5.099,
        "text": "the order or maybe date can be just"
      },
      {
        "start": 7014.48,
        "duration": 4.619,
        "text": "clustering column ID can be classed in"
      },
      {
        "start": 7016.639,
        "duration": 6.181,
        "text": "column you can you can choose which one"
      },
      {
        "start": 7019.099,
        "duration": 6.841,
        "text": "you like similarly as before and"
      },
      {
        "start": 7022.82,
        "duration": 6.6,
        "text": "generate physical generate SQL"
      },
      {
        "start": 7025.94,
        "duration": 4.32,
        "text": "but let me show you some more complexity"
      },
      {
        "start": 7029.42,
        "duration": 3.48,
        "text": "um"
      },
      {
        "start": 7030.26,
        "duration": 4.82,
        "text": "the"
      },
      {
        "start": 7032.9,
        "duration": 5.1,
        "text": "for example for example"
      },
      {
        "start": 7035.08,
        "duration": 5.86,
        "text": "what about we want to what if we want to"
      },
      {
        "start": 7038.0,
        "duration": 4.8,
        "text": "retrieve this so let's create new query"
      },
      {
        "start": 7040.94,
        "duration": 5.46,
        "text": "five"
      },
      {
        "start": 7042.8,
        "duration": 6.14,
        "text": "and let's say we want to retrieve all"
      },
      {
        "start": 7046.4,
        "duration": 5.299,
        "text": "the raw measurements"
      },
      {
        "start": 7048.94,
        "duration": 5.98,
        "text": "from possibly multiple"
      },
      {
        "start": 7051.699,
        "duration": 6.52,
        "text": "sensors from multiple networks based on"
      },
      {
        "start": 7054.92,
        "duration": 6.08,
        "text": "the region okay so we're gonna want to"
      },
      {
        "start": 7058.219,
        "duration": 2.781,
        "text": "find this value"
      },
      {
        "start": 7061.52,
        "duration": 5.579,
        "text": "and we will retrieve based on the region"
      },
      {
        "start": 7064.46,
        "duration": 4.04,
        "text": "information that's given"
      },
      {
        "start": 7067.099,
        "duration": 4.56,
        "text": "okay"
      },
      {
        "start": 7068.5,
        "duration": 5.139,
        "text": "so what type of table do we need for"
      },
      {
        "start": 7071.659,
        "duration": 4.821,
        "text": "that"
      },
      {
        "start": 7073.639,
        "duration": 2.841,
        "text": "let's see"
      },
      {
        "start": 7077.3,
        "duration": 4.56,
        "text": "okay so this is P5"
      },
      {
        "start": 7079.76,
        "duration": 4.919,
        "text": "given the region"
      },
      {
        "start": 7081.86,
        "duration": 6.299,
        "text": "we will uh retrieve the Valor but we"
      },
      {
        "start": 7084.679,
        "duration": 6.381,
        "text": "will also add timestamp and sensor ID"
      },
      {
        "start": 7088.159,
        "duration": 5.881,
        "text": "as the"
      },
      {
        "start": 7091.06,
        "duration": 5.559,
        "text": "clustering key and the order is not"
      },
      {
        "start": 7094.04,
        "duration": 4.139,
        "text": "really important unless we want to sort"
      },
      {
        "start": 7096.619,
        "duration": 3.901,
        "text": "we probably want to sort based on"
      },
      {
        "start": 7098.179,
        "duration": 6.54,
        "text": "timestamp so this is how easy you can"
      },
      {
        "start": 7100.52,
        "duration": 4.92,
        "text": "design a table using using a tool"
      },
      {
        "start": 7104.719,
        "duration": 5.181,
        "text": "um"
      },
      {
        "start": 7105.44,
        "duration": 4.46,
        "text": "basically automates this design"
      },
      {
        "start": 7110.119,
        "duration": 6.901,
        "text": "and"
      },
      {
        "start": 7112.88,
        "duration": 7.319,
        "text": "if you notice not even network name is"
      },
      {
        "start": 7117.02,
        "duration": 5.579,
        "text": "used as part of the partition key and"
      },
      {
        "start": 7120.199,
        "duration": 4.101,
        "text": "the reason is"
      },
      {
        "start": 7122.599,
        "duration": 4.441,
        "text": "because this"
      },
      {
        "start": 7124.3,
        "duration": 4.66,
        "text": "the key of this relationship is sensor"
      },
      {
        "start": 7127.04,
        "duration": 4.38,
        "text": "ID sensor can belong only to One Network"
      },
      {
        "start": 7128.96,
        "duration": 3.42,
        "text": "if we change that we probably will have"
      },
      {
        "start": 7131.42,
        "duration": 4.86,
        "text": "the"
      },
      {
        "start": 7132.38,
        "duration": 6.739,
        "text": "we should have I would say"
      },
      {
        "start": 7136.28,
        "duration": 2.839,
        "text": "uh"
      },
      {
        "start": 7140.179,
        "duration": 6.361,
        "text": "name"
      },
      {
        "start": 7142.06,
        "duration": 9.159,
        "text": "becomes part of the clustering key so"
      },
      {
        "start": 7146.54,
        "duration": 4.679,
        "text": "this is the end of this demo and"
      },
      {
        "start": 7152.179,
        "duration": 7.621,
        "text": "we are actually very close to the end"
      },
      {
        "start": 7156.32,
        "duration": 5.1,
        "text": "of our two hours so at this point I"
      },
      {
        "start": 7159.8,
        "duration": 4.56,
        "text": "would say we will skip all the"
      },
      {
        "start": 7161.42,
        "duration": 7.319,
        "text": "optimization techniques and we'll wrap"
      },
      {
        "start": 7164.36,
        "duration": 7.319,
        "text": "it up Alex yes uh we anyway have it in"
      },
      {
        "start": 7168.739,
        "duration": 5.641,
        "text": "the primary course so that is an"
      },
      {
        "start": 7171.679,
        "duration": 5.901,
        "text": "introductional level series and you get"
      },
      {
        "start": 7174.38,
        "duration": 8.339,
        "text": "deeper in the academy data stack scores"
      },
      {
        "start": 7177.58,
        "duration": 8.139,
        "text": "uh data modeling DS 220 at the Academy"
      },
      {
        "start": 7182.719,
        "duration": 5.101,
        "text": "and it's the only right way to get ready"
      },
      {
        "start": 7185.719,
        "duration": 3.621,
        "text": "for the certification"
      },
      {
        "start": 7187.82,
        "duration": 5.22,
        "text": "uh"
      },
      {
        "start": 7189.34,
        "duration": 5.379,
        "text": "so let me switch to my screen back in a"
      },
      {
        "start": 7193.04,
        "duration": 4.079,
        "text": "moment"
      },
      {
        "start": 7194.719,
        "duration": 4.261,
        "text": "and the tool is free and as you may"
      },
      {
        "start": 7197.119,
        "duration": 3.56,
        "text": "guess it's designed by"
      },
      {
        "start": 7198.98,
        "duration": 4.86,
        "text": "um uh"
      },
      {
        "start": 7200.679,
        "duration": 5.56,
        "text": "doctor Cash live who is a professor in"
      },
      {
        "start": 7203.84,
        "duration": 4.259,
        "text": "Eastern Michigan University"
      },
      {
        "start": 7206.239,
        "duration": 5.821,
        "text": "um"
      },
      {
        "start": 7208.099,
        "duration": 4.56,
        "text": "that is pretty cool so"
      },
      {
        "start": 7212.06,
        "duration": 3.92,
        "text": "um"
      },
      {
        "start": 7212.659,
        "duration": 3.321,
        "text": "switching to my screen"
      },
      {
        "start": 7219.92,
        "duration": 3.86,
        "text": "yep good"
      },
      {
        "start": 7221.719,
        "duration": 5.221,
        "text": "okay"
      },
      {
        "start": 7223.78,
        "duration": 7.0,
        "text": "uh so yeah I love this tool I'm with you"
      },
      {
        "start": 7226.94,
        "duration": 6.9,
        "text": "Cedric it's uh totally a great thing"
      },
      {
        "start": 7230.78,
        "duration": 7.58,
        "text": "absolutely great thing it helped so many"
      },
      {
        "start": 7233.84,
        "duration": 4.52,
        "text": "people oops it helped so many people"
      },
      {
        "start": 7238.699,
        "duration": 7.381,
        "text": "uh that is absolutely amazing good so"
      },
      {
        "start": 7243.619,
        "duration": 4.861,
        "text": "what's next we will have a quiz"
      },
      {
        "start": 7246.08,
        "duration": 4.8,
        "text": "so if you didn't win prizes last week"
      },
      {
        "start": 7248.48,
        "duration": 6.78,
        "text": "now you have chances to do it"
      },
      {
        "start": 7250.88,
        "duration": 5.48,
        "text": "but before that places for you to know"
      },
      {
        "start": 7255.26,
        "duration": 4.8,
        "text": "um"
      },
      {
        "start": 7256.36,
        "duration": 6.66,
        "text": "datastacks.com learn data modeling by"
      },
      {
        "start": 7260.06,
        "duration": 6.3,
        "text": "example that is a very important thing"
      },
      {
        "start": 7263.02,
        "duration": 6.9,
        "text": "and that I think what like a very well"
      },
      {
        "start": 7266.36,
        "duration": 6.2,
        "text": "explain it many cases explanations done"
      },
      {
        "start": 7269.92,
        "duration": 5.56,
        "text": "by archon"
      },
      {
        "start": 7272.56,
        "duration": 5.98,
        "text": "Cassandra data modeling exercises are"
      },
      {
        "start": 7275.48,
        "duration": 6.96,
        "text": "available at killer kodam by the link"
      },
      {
        "start": 7278.54,
        "duration": 6.599,
        "text": "above we are at your disposal at the"
      },
      {
        "start": 7282.44,
        "duration": 4.199,
        "text": "Discord server so we can answer"
      },
      {
        "start": 7285.139,
        "duration": 4.08,
        "text": "questions sir"
      },
      {
        "start": 7286.639,
        "duration": 7.04,
        "text": "uh some more cases and interesting"
      },
      {
        "start": 7289.219,
        "duration": 4.46,
        "text": "readings uh we also could"
      },
      {
        "start": 7293.9,
        "duration": 6.96,
        "text": "I don't know if I can copy link address"
      },
      {
        "start": 7296.54,
        "duration": 7.5,
        "text": "and send it to the Chart it may be a"
      },
      {
        "start": 7300.86,
        "duration": 5.879,
        "text": "very interesting reading yes I can"
      },
      {
        "start": 7304.04,
        "duration": 5.04,
        "text": "which is great"
      },
      {
        "start": 7306.739,
        "duration": 6.181,
        "text": "uh don't forget to do the homework"
      },
      {
        "start": 7309.08,
        "duration": 7.079,
        "text": "submit the homework form and submit my"
      },
      {
        "start": 7312.92,
        "duration": 6.42,
        "text": "homework with screenshots and get your"
      },
      {
        "start": 7316.159,
        "duration": 5.641,
        "text": "data Stacks modeling Workshop page"
      },
      {
        "start": 7319.34,
        "duration": 4.74,
        "text": "but what is better when beige is a real"
      },
      {
        "start": 7321.8,
        "duration": 5.04,
        "text": "globally recognized certification so"
      },
      {
        "start": 7324.08,
        "duration": 6.24,
        "text": "don't forget data Stacks offer more than"
      },
      {
        "start": 7326.84,
        "duration": 5.819,
        "text": "than just this Workshop you can get your"
      },
      {
        "start": 7330.32,
        "duration": 4.62,
        "text": "education training and certification"
      },
      {
        "start": 7332.659,
        "duration": 5.46,
        "text": "totally for free if data Stacks"
      },
      {
        "start": 7334.94,
        "duration": 5.239,
        "text": "developers Discord Community I already"
      },
      {
        "start": 7338.119,
        "duration": 3.661,
        "text": "mentioned"
      },
      {
        "start": 7340.179,
        "duration": 4.54,
        "text": "uh"
      },
      {
        "start": 7341.78,
        "duration": 6.78,
        "text": "this part I will not be there next weeks"
      },
      {
        "start": 7344.719,
        "duration": 6.561,
        "text": "but our data Stacks developers will be"
      },
      {
        "start": 7348.56,
        "duration": 5.72,
        "text": "so we could help you"
      },
      {
        "start": 7351.28,
        "duration": 6.939,
        "text": "your instructors"
      },
      {
        "start": 7354.28,
        "duration": 6.28,
        "text": "PhD data modeling methodology outer and"
      },
      {
        "start": 7358.219,
        "duration": 5.4,
        "text": "meme developer Advocate leader data"
      },
      {
        "start": 7360.56,
        "duration": 5.76,
        "text": "Stacks alexnev links on the screen are"
      },
      {
        "start": 7363.619,
        "duration": 6.781,
        "text": "for you to add us on LinkedIn"
      },
      {
        "start": 7366.32,
        "duration": 7.08,
        "text": "so it's very easy uh"
      },
      {
        "start": 7370.4,
        "duration": 4.86,
        "text": "type jump at us and we will be happy to"
      },
      {
        "start": 7373.4,
        "duration": 6.6,
        "text": "have more friends sir"
      },
      {
        "start": 7375.26,
        "duration": 6.06,
        "text": "and finally you cannot wait for the quiz"
      },
      {
        "start": 7380.0,
        "duration": 3.179,
        "text": "I guess"
      },
      {
        "start": 7381.32,
        "duration": 4.799,
        "text": "so let's go"
      },
      {
        "start": 7383.179,
        "duration": 5.581,
        "text": "if you are not on Main tier then jump on"
      },
      {
        "start": 7386.119,
        "duration": 5.841,
        "text": "jump in right now because we are short"
      },
      {
        "start": 7388.76,
        "duration": 9.02,
        "text": "on time so quiz starts in some seconds"
      },
      {
        "start": 7391.96,
        "duration": 5.82,
        "text": "to join the quiz you can enter the code"
      },
      {
        "start": 7398.199,
        "duration": 8.621,
        "text": "14095206 on mentee.com or you can scan"
      },
      {
        "start": 7402.8,
        "duration": 7.14,
        "text": "the QR code on the screen and oh I see"
      },
      {
        "start": 7406.82,
        "duration": 8.06,
        "text": "artium hides the code a bit sorry uh"
      },
      {
        "start": 7409.94,
        "duration": 9.54,
        "text": "it's on my side but again code is 1409"
      },
      {
        "start": 7414.88,
        "duration": 7.96,
        "text": "uh or I can just call for mentee"
      },
      {
        "start": 7419.48,
        "duration": 6.96,
        "text": "on the YouTube chat good"
      },
      {
        "start": 7422.84,
        "duration": 5.58,
        "text": "so I hope you are in already one hint I"
      },
      {
        "start": 7426.44,
        "duration": 5.04,
        "text": "want to give you as you are so great"
      },
      {
        "start": 7428.42,
        "duration": 5.58,
        "text": "people visiting our Workshop already not"
      },
      {
        "start": 7431.48,
        "duration": 6.0,
        "text": "the first time most of you I want to"
      },
      {
        "start": 7434.0,
        "duration": 5.52,
        "text": "give you a little hint YouTube has a"
      },
      {
        "start": 7437.48,
        "duration": 4.98,
        "text": "little discrepancy a little luck a"
      },
      {
        "start": 7439.52,
        "duration": 6.36,
        "text": "little DeLay So answering questions you"
      },
      {
        "start": 7442.46,
        "duration": 5.58,
        "text": "better watch uh not a YouTube stream but"
      },
      {
        "start": 7445.88,
        "duration": 4.799,
        "text": "many screen because it will be a little"
      },
      {
        "start": 7448.04,
        "duration": 4.92,
        "text": "bit ahead so you have more chances to"
      },
      {
        "start": 7450.679,
        "duration": 4.081,
        "text": "get more points and get closer to your"
      },
      {
        "start": 7452.96,
        "duration": 4.46,
        "text": "victory"
      },
      {
        "start": 7454.76,
        "duration": 5.76,
        "text": "uh from this point"
      },
      {
        "start": 7457.42,
        "duration": 5.799,
        "text": "I see people joining"
      },
      {
        "start": 7460.52,
        "duration": 5.88,
        "text": "I hope you all are good very last moment"
      },
      {
        "start": 7463.219,
        "duration": 5.341,
        "text": "to join very last moments to get chances"
      },
      {
        "start": 7466.4,
        "duration": 5.12,
        "text": "to win price"
      },
      {
        "start": 7468.56,
        "duration": 2.96,
        "text": "and let's start"
      },
      {
        "start": 7474.38,
        "duration": 3.92,
        "text": "it will be eight questions"
      },
      {
        "start": 7478.76,
        "duration": 6.06,
        "text": "answer fast"
      },
      {
        "start": 7480.44,
        "duration": 8.279,
        "text": "to get more points a key space"
      },
      {
        "start": 7484.82,
        "duration": 6.899,
        "text": "a key space is organized into rows and"
      },
      {
        "start": 7488.719,
        "duration": 5.88,
        "text": "columns key space contains tables and"
      },
      {
        "start": 7491.719,
        "duration": 5.88,
        "text": "sets replication keyspace is the base"
      },
      {
        "start": 7494.599,
        "duration": 6.56,
        "text": "unit of access key space is a place to"
      },
      {
        "start": 7497.599,
        "duration": 3.56,
        "text": "store extra house keys"
      },
      {
        "start": 7503.179,
        "duration": 6.42,
        "text": "so you are answering quickly I see most"
      },
      {
        "start": 7506.42,
        "duration": 6.179,
        "text": "of the attendees already voted"
      },
      {
        "start": 7509.599,
        "duration": 5.221,
        "text": "with the last few seconds will we have"
      },
      {
        "start": 7512.599,
        "duration": 6.241,
        "text": "any late camera"
      },
      {
        "start": 7514.82,
        "duration": 6.54,
        "text": "and time is over so most of you made it"
      },
      {
        "start": 7518.84,
        "duration": 4.98,
        "text": "right key space contains tables and sets"
      },
      {
        "start": 7521.36,
        "duration": 5.879,
        "text": "replication partition is the base unit"
      },
      {
        "start": 7523.82,
        "duration": 7.14,
        "text": "of access and organize it into rows and"
      },
      {
        "start": 7527.239,
        "duration": 6.42,
        "text": "columns as a table not key space"
      },
      {
        "start": 7530.96,
        "duration": 7.259,
        "text": "who was the fastest this time"
      },
      {
        "start": 7533.659,
        "duration": 6.741,
        "text": "brand the broken made it with 982 points"
      },
      {
        "start": 7538.219,
        "duration": 5.601,
        "text": "which is incredibly fast"
      },
      {
        "start": 7540.4,
        "duration": 5.799,
        "text": "fastest hand on the west"
      },
      {
        "start": 7543.82,
        "duration": 5.98,
        "text": "question number two"
      },
      {
        "start": 7546.199,
        "duration": 6.42,
        "text": "so answer fast to get more points what's"
      },
      {
        "start": 7549.8,
        "duration": 5.46,
        "text": "the partition key you were paying killed"
      },
      {
        "start": 7552.619,
        "duration": 5.46,
        "text": "is it an optional optional column to"
      },
      {
        "start": 7555.26,
        "duration": 6.359,
        "text": "allow Group by it's maybe a column to"
      },
      {
        "start": 7558.079,
        "duration": 6.901,
        "text": "Define partitions required it's maybe a"
      },
      {
        "start": 7561.619,
        "duration": 6.241,
        "text": "required column to set sorting order or"
      },
      {
        "start": 7564.98,
        "duration": 5.88,
        "text": "is that the key to all the doors"
      },
      {
        "start": 7567.86,
        "duration": 6.12,
        "text": "yes partition key is a column to Define"
      },
      {
        "start": 7570.86,
        "duration": 7.2,
        "text": "partitions it is required it's not to"
      },
      {
        "start": 7573.98,
        "duration": 6.54,
        "text": "set sorting order but to set partitions"
      },
      {
        "start": 7578.06,
        "duration": 6.5,
        "text": "well"
      },
      {
        "start": 7580.52,
        "duration": 4.04,
        "text": "who was the fastest FaceTime"
      },
      {
        "start": 7585.94,
        "duration": 7.299,
        "text": "Praveen was the fastest keeping the"
      },
      {
        "start": 7589.28,
        "duration": 7.26,
        "text": "first place nitation II and Sumit on the"
      },
      {
        "start": 7593.239,
        "duration": 6.301,
        "text": "third with Mr Wonka and Rita a couple of"
      },
      {
        "start": 7596.54,
        "duration": 4.44,
        "text": "points difference of places number four"
      },
      {
        "start": 7599.54,
        "duration": 4.26,
        "text": "and five"
      },
      {
        "start": 7600.98,
        "duration": 5.639,
        "text": "it's not over yet we are just starting"
      },
      {
        "start": 7603.8,
        "duration": 6.6,
        "text": "so let's go to question number three"
      },
      {
        "start": 7606.619,
        "duration": 8.821,
        "text": "and answer fast to get more points"
      },
      {
        "start": 7610.4,
        "duration": 9.239,
        "text": "table can have many rows per partition"
      },
      {
        "start": 7615.44,
        "duration": 9.32,
        "text": "true false it requires special Cassandra"
      },
      {
        "start": 7619.639,
        "duration": 5.121,
        "text": "yaml configuration it's illegal"
      },
      {
        "start": 7626.78,
        "duration": 4.319,
        "text": "what do you think is it correct wrong or"
      },
      {
        "start": 7629.599,
        "duration": 4.261,
        "text": "maybe"
      },
      {
        "start": 7631.099,
        "duration": 6.181,
        "text": "special it's totally legal and that's"
      },
      {
        "start": 7633.86,
        "duration": 4.859,
        "text": "perfectly true and everything is fine it"
      },
      {
        "start": 7637.28,
        "duration": 3.98,
        "text": "does not require any special"
      },
      {
        "start": 7638.719,
        "duration": 5.281,
        "text": "configuration"
      },
      {
        "start": 7641.26,
        "duration": 6.24,
        "text": "ah okay so"
      },
      {
        "start": 7644.0,
        "duration": 7.639,
        "text": "was anyone faster Miss Praveen this time"
      },
      {
        "start": 7647.5,
        "duration": 8.86,
        "text": "Sumit was faster keeping the third place"
      },
      {
        "start": 7651.639,
        "duration": 7.241,
        "text": "but Praveen still on the first one uh by"
      },
      {
        "start": 7656.36,
        "duration": 5.279,
        "text": "the way I know there are people there is"
      },
      {
        "start": 7658.88,
        "duration": 5.04,
        "text": "a conference in New York right now API"
      },
      {
        "start": 7661.639,
        "duration": 4.861,
        "text": "days New York and I know they are"
      },
      {
        "start": 7663.92,
        "duration": 5.94,
        "text": "watching us I'm very curious if anyone"
      },
      {
        "start": 7666.5,
        "duration": 7.079,
        "text": "is joining our quiz from API days to New"
      },
      {
        "start": 7669.86,
        "duration": 5.64,
        "text": "York that would be very interesting"
      },
      {
        "start": 7673.579,
        "duration": 4.201,
        "text": "question four"
      },
      {
        "start": 7675.5,
        "duration": 5.159,
        "text": "so let's see"
      },
      {
        "start": 7677.78,
        "duration": 6.24,
        "text": "what will happen answer fast to get more"
      },
      {
        "start": 7680.659,
        "duration": 7.02,
        "text": "points in Cassandra tables which are"
      },
      {
        "start": 7684.02,
        "duration": 8.719,
        "text": "required data columns clustering columns"
      },
      {
        "start": 7687.679,
        "duration": 5.06,
        "text": "partition Keys user defined types"
      },
      {
        "start": 7696.38,
        "duration": 5.239,
        "text": "what is required in Cassandra tables"
      },
      {
        "start": 7702.56,
        "duration": 4.44,
        "text": "I should have added the question if"
      },
      {
        "start": 7704.599,
        "duration": 6.921,
        "text": "nosql is schema-less"
      },
      {
        "start": 7707.0,
        "duration": 4.52,
        "text": "uh that's pretty said I didn't do it"
      },
      {
        "start": 7711.56,
        "duration": 4.32,
        "text": "that would be a good filter to those who"
      },
      {
        "start": 7713.84,
        "duration": 4.44,
        "text": "paid attention"
      },
      {
        "start": 7715.88,
        "duration": 5.04,
        "text": "partition keys right partition keys are"
      },
      {
        "start": 7718.28,
        "duration": 4.56,
        "text": "required you can safely emit clustering"
      },
      {
        "start": 7720.92,
        "duration": 3.659,
        "text": "columns if they are not required by your"
      },
      {
        "start": 7722.84,
        "duration": 5.279,
        "text": "data model but technically only"
      },
      {
        "start": 7724.579,
        "duration": 5.64,
        "text": "partition keys are required"
      },
      {
        "start": 7728.119,
        "duration": 4.62,
        "text": "okay"
      },
      {
        "start": 7730.219,
        "duration": 5.281,
        "text": "so there are no mistakes between leaders"
      },
      {
        "start": 7732.739,
        "duration": 6.061,
        "text": "but looks like amid was a little bit"
      },
      {
        "start": 7735.5,
        "duration": 7.92,
        "text": "slower this time and Praveen was fastest"
      },
      {
        "start": 7738.8,
        "duration": 6.779,
        "text": "again so no changes in top three"
      },
      {
        "start": 7743.42,
        "duration": 3.0,
        "text": "and that is going to be question number"
      },
      {
        "start": 7745.579,
        "duration": 4.16,
        "text": "five"
      },
      {
        "start": 7746.42,
        "duration": 8.1,
        "text": "so answer fast to get more points"
      },
      {
        "start": 7749.739,
        "duration": 8.161,
        "text": "inequality predicates a allowed on"
      },
      {
        "start": 7754.52,
        "duration": 5.699,
        "text": "all table columns partition key columns"
      },
      {
        "start": 7757.9,
        "duration": 6.94,
        "text": "clustering key columns"
      },
      {
        "start": 7760.219,
        "duration": 8.4,
        "text": "no inequality predicates are allow it"
      },
      {
        "start": 7764.84,
        "duration": 7.44,
        "text": "okay people giving their answers"
      },
      {
        "start": 7768.619,
        "duration": 6.181,
        "text": "but time is up right answer inequality"
      },
      {
        "start": 7772.28,
        "duration": 5.52,
        "text": "predicates are allow it on clustering"
      },
      {
        "start": 7774.8,
        "duration": 8.1,
        "text": "key columns on partition Keys you cannot"
      },
      {
        "start": 7777.8,
        "duration": 5.1,
        "text": "have any inequalities only equalities"
      },
      {
        "start": 7785.32,
        "duration": 6.759,
        "text": "make a mistake that means what top three"
      },
      {
        "start": 7788.719,
        "duration": 6.0,
        "text": "will change right now we've need as fast"
      },
      {
        "start": 7792.079,
        "duration": 6.181,
        "text": "as jumping on the first place moving"
      },
      {
        "start": 7794.719,
        "duration": 6.301,
        "text": "Praveen down to a second and Mr Wonka"
      },
      {
        "start": 7798.26,
        "duration": 7.8,
        "text": "makes it to the third place with tiger"
      },
      {
        "start": 7801.02,
        "duration": 7.679,
        "text": "baby very very very close you uh Mr"
      },
      {
        "start": 7806.06,
        "duration": 5.94,
        "text": "Wonka you can hear his breathing like"
      },
      {
        "start": 7808.699,
        "duration": 5.121,
        "text": "somewhere from behind a competition is"
      },
      {
        "start": 7812.0,
        "duration": 3.619,
        "text": "not done yet"
      },
      {
        "start": 7813.82,
        "duration": 4.72,
        "text": "okay"
      },
      {
        "start": 7815.619,
        "duration": 6.821,
        "text": "let's go"
      },
      {
        "start": 7818.54,
        "duration": 5.039,
        "text": "question number six Summit uh keep"
      },
      {
        "start": 7822.44,
        "duration": 4.56,
        "text": "fighting"
      },
      {
        "start": 7823.579,
        "duration": 5.881,
        "text": "answer fast to get more points in the"
      },
      {
        "start": 7827.0,
        "duration": 4.5,
        "text": "data modeling methodology we start"
      },
      {
        "start": 7829.46,
        "duration": 4.94,
        "text": "modeling Thief"
      },
      {
        "start": 7831.5,
        "duration": 5.4,
        "text": "physical data model logical data model"
      },
      {
        "start": 7834.4,
        "duration": 8.04,
        "text": "conceptual data model and application"
      },
      {
        "start": 7836.9,
        "duration": 5.54,
        "text": "workflow copy paste from stack overflow"
      },
      {
        "start": 7845.0,
        "duration": 4.199,
        "text": "time is up"
      },
      {
        "start": 7846.739,
        "duration": 4.92,
        "text": "and most of you made it right conceptual"
      },
      {
        "start": 7849.199,
        "duration": 5.161,
        "text": "data model and application workflow to"
      },
      {
        "start": 7851.659,
        "duration": 5.221,
        "text": "map them into logical data model which"
      },
      {
        "start": 7854.36,
        "duration": 5.879,
        "text": "is a wrong answer and physical data"
      },
      {
        "start": 7856.88,
        "duration": 5.94,
        "text": "module is one of the latest Steps From"
      },
      {
        "start": 7860.239,
        "duration": 6.061,
        "text": "the data modeling methodology"
      },
      {
        "start": 7862.82,
        "duration": 6.54,
        "text": "like we have a guest here like uh you"
      },
      {
        "start": 7866.3,
        "duration": 7.02,
        "text": "have and Mr Wonka makes a mistake just"
      },
      {
        "start": 7869.36,
        "duration": 5.9,
        "text": "right after getting in the top three"
      },
      {
        "start": 7873.32,
        "duration": 5.339,
        "text": "oh my God"
      },
      {
        "start": 7875.26,
        "duration": 5.62,
        "text": "Praveen returned to first place with"
      },
      {
        "start": 7878.659,
        "duration": 5.761,
        "text": "nitesh on the second and now tiger baby"
      },
      {
        "start": 7880.88,
        "duration": 7.819,
        "text": "on the third place with Amit on Fifth"
      },
      {
        "start": 7884.42,
        "duration": 4.279,
        "text": "and Kevin and fourth it's almost done"
      },
      {
        "start": 7890.36,
        "duration": 6.06,
        "text": "question number seven"
      },
      {
        "start": 7893.06,
        "duration": 7.7,
        "text": "answer first to get more points"
      },
      {
        "start": 7896.42,
        "duration": 9.659,
        "text": "primary key defines row uniqueness"
      },
      {
        "start": 7900.76,
        "duration": 9.1,
        "text": "pulse correct primary key is deprecated"
      },
      {
        "start": 7906.079,
        "duration": 6.06,
        "text": "see I meet says what question 6 appeared"
      },
      {
        "start": 7909.86,
        "duration": 4.14,
        "text": "in the first Workshop as well yes and"
      },
      {
        "start": 7912.139,
        "duration": 4.921,
        "text": "that is an intention"
      },
      {
        "start": 7914.0,
        "duration": 5.34,
        "text": "I want you to remember the steps"
      },
      {
        "start": 7917.06,
        "duration": 4.32,
        "text": "correct primary key defines raw"
      },
      {
        "start": 7919.34,
        "duration": 3.56,
        "text": "uniqueness and that is a totally correct"
      },
      {
        "start": 7921.38,
        "duration": 5.04,
        "text": "statement"
      },
      {
        "start": 7922.9,
        "duration": 6.52,
        "text": "so who was fastest this time there are"
      },
      {
        "start": 7926.42,
        "duration": 6.06,
        "text": "no mistakes but who was fastest"
      },
      {
        "start": 7929.42,
        "duration": 7.259,
        "text": "looks like nitesh was fastest very well"
      },
      {
        "start": 7932.48,
        "duration": 7.259,
        "text": "done a Praveen nitesh made no mistake so"
      },
      {
        "start": 7936.679,
        "duration": 5.221,
        "text": "far and tiger baby is one of the third"
      },
      {
        "start": 7939.739,
        "duration": 6.061,
        "text": "place with one mistake"
      },
      {
        "start": 7941.9,
        "duration": 7.38,
        "text": "and Kevin p is now 50 points behind"
      },
      {
        "start": 7945.8,
        "duration": 7.319,
        "text": "tiger baby which is nearly nothing"
      },
      {
        "start": 7949.28,
        "duration": 5.459,
        "text": "uh that is the last question"
      },
      {
        "start": 7953.119,
        "duration": 3.661,
        "text": "so"
      },
      {
        "start": 7954.739,
        "duration": 6.0,
        "text": "you want me to push this button right"
      },
      {
        "start": 7956.78,
        "duration": 5.339,
        "text": "okay let's go answer fast to get more"
      },
      {
        "start": 7960.739,
        "duration": 5.821,
        "text": "points"
      },
      {
        "start": 7962.119,
        "duration": 8.04,
        "text": "how does Cassandra perform joints"
      },
      {
        "start": 7966.56,
        "duration": 6.0,
        "text": "Cassandra joins require a joint table"
      },
      {
        "start": 7970.159,
        "duration": 5.401,
        "text": "just like sequel joins"
      },
      {
        "start": 7972.56,
        "duration": 6.92,
        "text": "Cassandra does not support joints or"
      },
      {
        "start": 7975.56,
        "duration": 3.92,
        "text": "Cassandra only joins good clubs"
      },
      {
        "start": 7992.78,
        "duration": 6.18,
        "text": "time is ticking most of you made their"
      },
      {
        "start": 7996.5,
        "duration": 5.219,
        "text": "step already and correct answer is"
      },
      {
        "start": 7998.96,
        "duration": 5.46,
        "text": "Cassandra does not support joints"
      },
      {
        "start": 8001.719,
        "duration": 4.801,
        "text": "Cassandra joins don't require joint"
      },
      {
        "start": 8004.42,
        "duration": 5.04,
        "text": "table it's not a thing it doesn't exist"
      },
      {
        "start": 8006.52,
        "duration": 5.88,
        "text": "it exists only in my imagination"
      },
      {
        "start": 8009.46,
        "duration": 4.679,
        "text": "it's not like just equal joints SQL"
      },
      {
        "start": 8012.4,
        "duration": 3.779,
        "text": "joints are totally great but they don't"
      },
      {
        "start": 8014.139,
        "duration": 4.741,
        "text": "work on Big Data"
      },
      {
        "start": 8016.179,
        "duration": 4.081,
        "text": "okay okay they work on Big Data but very"
      },
      {
        "start": 8018.88,
        "duration": 4.799,
        "text": "very slowly"
      },
      {
        "start": 8020.26,
        "duration": 5.819,
        "text": "I better say it this way if you have a"
      },
      {
        "start": 8023.679,
        "duration": 5.04,
        "text": "customer facing database"
      },
      {
        "start": 8026.079,
        "duration": 5.58,
        "text": "you cannot afford joins on Cassandra"
      },
      {
        "start": 8028.719,
        "duration": 4.561,
        "text": "Cassandra simply does not support joints"
      },
      {
        "start": 8031.659,
        "duration": 3.901,
        "text": "and"
      },
      {
        "start": 8033.28,
        "duration": 4.68,
        "text": "Kevin makes mistake but that doesn't"
      },
      {
        "start": 8035.56,
        "duration": 5.42,
        "text": "matter because Praveen nitesh and tiger"
      },
      {
        "start": 8037.96,
        "duration": 6.779,
        "text": "baby made no mistake"
      },
      {
        "start": 8040.98,
        "duration": 7.96,
        "text": "nitesh gets overtaking Praveen again"
      },
      {
        "start": 8044.739,
        "duration": 7.681,
        "text": "gets to a first place very well"
      },
      {
        "start": 8048.94,
        "duration": 6.0,
        "text": "so we congratulate nitesh Praveen and"
      },
      {
        "start": 8052.42,
        "duration": 5.1,
        "text": "tiger baby please make a screenshot of"
      },
      {
        "start": 8054.94,
        "duration": 5.52,
        "text": "your winning screen with your position"
      },
      {
        "start": 8057.52,
        "duration": 9.0,
        "text": "number one number two number three and"
      },
      {
        "start": 8060.46,
        "duration": 6.06,
        "text": "send it to me on LinkedIn using https"
      },
      {
        "start": 8067.38,
        "duration": 5.44,
        "text": "Alex Alex"
      },
      {
        "start": 8069.46,
        "duration": 5.58,
        "text": "I need to ask congrats and I will take"
      },
      {
        "start": 8072.82,
        "duration": 3.899,
        "text": "care of you getting the prizes"
      },
      {
        "start": 8075.04,
        "duration": 4.559,
        "text": "uh now"
      },
      {
        "start": 8076.719,
        "duration": 4.38,
        "text": "uh verus who are on the leaderboard"
      },
      {
        "start": 8079.599,
        "duration": 4.261,
        "text": "congrats"
      },
      {
        "start": 8081.099,
        "duration": 4.441,
        "text": "you made it very well even though you"
      },
      {
        "start": 8083.86,
        "duration": 4.319,
        "text": "didn't made it in the top three but"
      },
      {
        "start": 8085.54,
        "duration": 6.059,
        "text": "remember we will have a next Workshop"
      },
      {
        "start": 8088.179,
        "duration": 6.42,
        "text": "soon third Workshop of this series so me"
      },
      {
        "start": 8091.599,
        "duration": 5.461,
        "text": "don't be disappointed we will have one"
      },
      {
        "start": 8094.599,
        "duration": 5.341,
        "text": "more chance at our next Workshop by the"
      },
      {
        "start": 8097.06,
        "duration": 6.539,
        "text": "way I think next Workshop will be not"
      },
      {
        "start": 8099.94,
        "duration": 8.219,
        "text": "next week please notice that but Uber"
      },
      {
        "start": 8103.599,
        "duration": 6.54,
        "text": "next next week I believe it's going on"
      },
      {
        "start": 8108.159,
        "duration": 4.681,
        "text": "to be next next week you have to check"
      },
      {
        "start": 8110.139,
        "duration": 4.741,
        "text": "the schedule and finally"
      },
      {
        "start": 8112.84,
        "duration": 4.44,
        "text": "if you are not even on a leaderboard"
      },
      {
        "start": 8114.88,
        "duration": 6.06,
        "text": "most important thing we are giving today"
      },
      {
        "start": 8117.28,
        "duration": 7.14,
        "text": "not the prices also their fun but"
      },
      {
        "start": 8120.94,
        "duration": 5.279,
        "text": "actually knowledge because yeah it's in"
      },
      {
        "start": 8124.42,
        "duration": 6.54,
        "text": "two weeks"
      },
      {
        "start": 8126.219,
        "duration": 6.301,
        "text": "uh so next on 10th of August thank you"
      },
      {
        "start": 8130.96,
        "duration": 4.32,
        "text": "Cedric"
      },
      {
        "start": 8132.52,
        "duration": 4.5,
        "text": "and knowledge is much more valuable than"
      },
      {
        "start": 8135.28,
        "duration": 4.74,
        "text": "our swag"
      },
      {
        "start": 8137.02,
        "duration": 6.26,
        "text": "and then finally make a screenshot and"
      },
      {
        "start": 8140.02,
        "duration": 3.26,
        "text": "changing the page"
      },
      {
        "start": 8143.56,
        "duration": 4.32,
        "text": "if you didn't still contact me two"
      },
      {
        "start": 8146.32,
        "duration": 5.22,
        "text": "questions"
      },
      {
        "start": 8147.88,
        "duration": 6.38,
        "text": "how do you like this Workshop series"
      },
      {
        "start": 8151.54,
        "duration": 5.4,
        "text": "would you recommend it to your friends"
      },
      {
        "start": 8154.26,
        "duration": 4.479,
        "text": "it's a quick choice"
      },
      {
        "start": 8156.94,
        "duration": 4.08,
        "text": "okay"
      },
      {
        "start": 8158.739,
        "duration": 5.161,
        "text": "looks like first answer was very quick"
      },
      {
        "start": 8161.02,
        "duration": 5.82,
        "text": "and very positive"
      },
      {
        "start": 8163.9,
        "duration": 6.06,
        "text": "thank you so much"
      },
      {
        "start": 8166.84,
        "duration": 6.42,
        "text": "I see like uh"
      },
      {
        "start": 8169.96,
        "duration": 5.759,
        "text": "a very good score after all I'm sorry if"
      },
      {
        "start": 8173.26,
        "duration": 4.52,
        "text": "you rate it not so high I hope you will"
      },
      {
        "start": 8175.719,
        "duration": 4.681,
        "text": "improve for the next series"
      },
      {
        "start": 8177.78,
        "duration": 4.839,
        "text": "but I know you know what you stayed with"
      },
      {
        "start": 8180.4,
        "duration": 5.4,
        "text": "us till the very end of a second"
      },
      {
        "start": 8182.619,
        "duration": 5.46,
        "text": "Workshop you spend with us almost five"
      },
      {
        "start": 8185.8,
        "duration": 4.56,
        "text": "hours overall that means you like it"
      },
      {
        "start": 8188.079,
        "duration": 4.381,
        "text": "admit it like I Know It And by the way"
      },
      {
        "start": 8190.36,
        "duration": 5.34,
        "text": "don't forget to like And subscribe on us"
      },
      {
        "start": 8192.46,
        "duration": 6.479,
        "text": "on YouTube and then finally what would"
      },
      {
        "start": 8195.7,
        "duration": 6.119,
        "text": "you suggest any feedback regarding this"
      },
      {
        "start": 8198.939,
        "duration": 4.801,
        "text": "Workshop or this series in general just"
      },
      {
        "start": 8201.819,
        "duration": 4.261,
        "text": "specify please what exactly you mean"
      },
      {
        "start": 8203.74,
        "duration": 5.399,
        "text": "because it's a second Workshop in this"
      },
      {
        "start": 8206.08,
        "duration": 5.099,
        "text": "series I will keep this window open so"
      },
      {
        "start": 8209.139,
        "duration": 4.561,
        "text": "you can write your feedback after the"
      },
      {
        "start": 8211.179,
        "duration": 5.04,
        "text": "workshop it will be open for half an"
      },
      {
        "start": 8213.7,
        "duration": 4.5,
        "text": "hour more and let us switch to the last"
      },
      {
        "start": 8216.219,
        "duration": 6.8,
        "text": "slides"
      },
      {
        "start": 8218.2,
        "duration": 4.819,
        "text": "uh don't forget to complete the homework"
      },
      {
        "start": 8223.2,
        "duration": 7.18,
        "text": "and it's expected we explain how to do"
      },
      {
        "start": 8227.5,
        "duration": 5.599,
        "text": "it in our GitHub repository which you"
      },
      {
        "start": 8230.38,
        "duration": 2.719,
        "text": "have seen already"
      },
      {
        "start": 8233.979,
        "duration": 6.0,
        "text": "join Discord if you will have any"
      },
      {
        "start": 8235.96,
        "duration": 6.32,
        "text": "questions or catch us on LinkedIn links"
      },
      {
        "start": 8239.979,
        "duration": 5.641,
        "text": "are on the screen"
      },
      {
        "start": 8242.28,
        "duration": 5.439,
        "text": "and homework right yeah homework"
      },
      {
        "start": 8245.62,
        "duration": 5.519,
        "text": "actually instructions are configured by"
      },
      {
        "start": 8247.719,
        "duration": 6.061,
        "text": "Cedric thank you uh with that said that"
      },
      {
        "start": 8251.139,
        "duration": 4.741,
        "text": "was Alex Anderson thank you so much for"
      },
      {
        "start": 8253.78,
        "duration": 5.22,
        "text": "joining it was a real pleasure to work"
      },
      {
        "start": 8255.88,
        "duration": 5.639,
        "text": "with you and many good questions today"
      },
      {
        "start": 8259.0,
        "duration": 5.28,
        "text": "and I think we are done after do you"
      },
      {
        "start": 8261.519,
        "duration": 5.941,
        "text": "like to add anything"
      },
      {
        "start": 8264.28,
        "duration": 5.159,
        "text": "no it was great thanks for coming and"
      },
      {
        "start": 8267.46,
        "duration": 3.899,
        "text": "hope to see you during the next Workshop"
      },
      {
        "start": 8269.439,
        "duration": 6.96,
        "text": "yes I will be in the chat"
      },
      {
        "start": 8271.359,
        "duration": 8.16,
        "text": "great uh so uh soon then in two weeks"
      },
      {
        "start": 8276.399,
        "duration": 6.181,
        "text": "thank you Katie thank you everyone uh"
      },
      {
        "start": 8279.519,
        "duration": 5.34,
        "text": "thank you for joining nitesh and our"
      },
      {
        "start": 8282.58,
        "duration": 4.139,
        "text": "winners send me a message on LinkedIn"
      },
      {
        "start": 8284.859,
        "duration": 4.561,
        "text": "and then"
      },
      {
        "start": 8286.719,
        "duration": 5.061,
        "text": "meet you soon thank you Rita thank you"
      },
      {
        "start": 8289.42,
        "duration": 2.36,
        "text": "for coming"
      },
      {
        "start": 8295.479,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 8317.77,
        "duration": 7.839,
        "text": "[Music]"
      },
      {
        "start": 8327.04,
        "duration": 3.0,
        "text": "foreign"
      },
      {
        "start": 8331.24,
        "duration": 9.159,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T18:48:13.758090+00:00"
}