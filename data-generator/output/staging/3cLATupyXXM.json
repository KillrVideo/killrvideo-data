{
  "video_id": "3cLATupyXXM",
  "title": "Distributed Data Show 64: Future Enterprise Data Architecture with Josh Perryman",
  "description": "We talk with Josh Perryman of Expero about the current state of the art in enterprise data architectures, how he sees that changing in the future to include a broader set of database and streaming technologies, and how to deal with the resulting complexity.\n\n0:15 - Welcoming Josh back to the show to talk about enterprise data architecture \n1:39 - The state of the art in enterprise data architectures - relational databases. Problems come when you have relational databases in 3rd normal form that can’t support the required joins on the read path at scale\n3:20 - The toolset for solving these problems - it starts with understanding your entire stack and creating your data model appropriately\n5:05 - You can’t just create any data model and expect it to scale. You need to think about data locality - getting your data on the same node, the same partition, or even the same location on disk.\n7:40 - The emerging state of the art - a deconstruction of the traditional database architecture consisting of storage, transaction logs, indexes, etc. Now we can mix and match different technologies according to our application needs, for example Cassandra for persistence and Kafka for streaming\n10:24 - On the similarity of Kafka to the traditional transaction log from the relational database world\n12:02 - Managing the complexity of the polyglot persistence approach. We need better tools for managing interfaces and schema across technologies and service boundaries\n15:15 - The role of analytics, machine learning and distributed tracing in complex enterprise data architectures \n16:45 - Wrapping up and teasing some potential topics for future episodes with Josh\n\n\nABOUT DATASTAX ENTERPRISE 6\nDataStax  powers  the  Right-Now  Enterprise  with  the  always-on,  distributed  cloud  database  built  on  Apache  Cassandra™  and designed for hybrid cloud. DataStax Enterprise 6 (DSE 6) includes industry-leading performance, self-driving operational simplicity, and robust analytics.\n\nLearn more at ",
  "published_at": "2018-09-11T15:00:01Z",
  "thumbnail": "https://i.ytimg.com/vi/3cLATupyXXM/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "performance",
    "talk",
    "architecture",
    "dse",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=3cLATupyXXM",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems hey it's Jeff carpenter here again with Josh Pearman from expiry so long since we last spoke I've got a laundry cycle myself it looks like you've done the same yeah yeah you know brush my teeth a couple times but today is a new day so to speak last time when we talked we got a bit of your history on how you got into graph databases in particular like kind of how that voyage of discovery that you were on and some of the discoveries that you had around when to use a graph database what it really excels at how you mix graph databases into your solution and what parts of the problem you choose to apply your graph database on spoiler alert if you haven't watched that or listened to that episode yet it's more on the read path in Josh's experience so what I want to talk about with you today is basically like where are we at now in the world of enterprise data architecture when we're kind of building large-scale systems and thinking in particular at the data tier like what's the state of the art right now that you see in industry and then where should we be going where are we going where we headed in the future so what do you think so state of the art I know where a lot of enterprises want to be but I know where most of them are is they're still working with their relational databases and I think that's a really good thing in large cases because that's a known and well established technology area where we see them running into problems is when they start scaling or running into places where they're Reed intensive environments and the relational databases are third normal form and every single query is going to be multiple joints it's too much to do at runtime yeah and so that's when you get the phone call is when they're pushing up against the it's of what their current database or data layer can handle is that right when I look at the last particularly of my last four years or so of working with different development groups because I don't I don't work with product owners I usually work with development teams it's going in and helping them with to expand their existing toolset they know the relation database as well but when they get to a point and we do this all over the place where we have our our tools for solving problems and we have our common patterns for addressing those but when our problems get too big or they change dramatically or our business requirements may change dramatically we may have huge amounts more data than we were expecting or some other major shift that's when we need to expand our tool set and that's usually when I get to come in because I've been working with a variety of different tools and working in those problem areas and so I get to kind of come alongside those other developers and say hey here's a really amazing technology and the data stacks is build let me show you the right way to use it so you don't get hurt in the process and we actually solve the problems and you don't get frustrated so what's the toolset spill a lot of this okay so you know when I come back to this and I've got some great points along the way a lot of it is understanding what's happening at the persistence layer or understanding kind of this full stack I was in Denver a couple of years ago working with I can say was Comcast because they actually did a talk about the learnings that we went through there and and they were on their third graph database engine and they were looking at a scale out solution and and I talked with him what they had learned up to that point I'm like yeah okay you you learned a lot so let's see me show you how to use data stacks graph to solve this problem and I went toe-to-toe with our architect a really really sharp guy and he says no that's not the way graph works I'm like well we're not really modeling for graph we're modeling for Cassandra here and this is kind of the tool set and this is what I learned so much from going through the data stacks Academy courses really in data sex bootcamp and other things was we model for our access patterns and you can really optimize for that and when you do that you are now able to and with when you give up on joins as well you're able to do some amazing things in performant ways across multiple machines it was really neat about that experience in Denver was kind of talking with them and saying okay here's some of the trade-offs that we have to make from our graph design point of view but when we do that we're using Cassandra really well underneath and we're still able to reason over our data for in a graph way so it was a bit of a twofer we got the performance benefits from Cassandra and the scaling benefits but we were able to think about and reason in their domain in a graph way gotcha okay so it sounds like state of the art where we're at in industry is in a number of places maybe not every company not every company has massive data sets or massive scale out problems but we're seeing companies that are needed to scale beyond what they can get from the traditional relational database even with recent advances and and offerings from a variety of sources I'm still running into those and what what you're doing is not only applying graph databases to those problems but it sounds like a graph solution built on Cassandra to the extent that you actually need to think about what you're doing with your data model in order to get the scale it's not a just a pure abstraction that you could just drop in and say okay I can create whatever data model I want and expect it to scale well and perform well that's exactly the conversation I had in Denver you're staying like no we just need to use as a graph database and like no you're you can do that when you're dealing with toys and when you're dealing with small data sets but when you start dealing with interesting levels of data you have to start thinking about data locality where is my data located and if I'm gonna be querying two pieces of data regularly I want them to be on the same device or better yet in the same table or better yet like on the same partition of disk right oh so that's the secret sauce then a lot of it comes down to understanding what's happening at that low level at the disk layer where is my data what note is in the cluster is my data on within that node where is it on disk of data Calla t that's what often times when I'm trying to optimize for except when I can't in different cases where I can't of course yeah yeah but but when it comes down to ultimately is I need no second latency on on my query that I'm trying to serve have a massive data set it's spread across multiple nodes in a cluster and I wanted to do as few reads as possible across you know as off of literally off of disk or maybe I even have stuff cache but I want to be doing as as few data accesses possible to get back the data that I need so I can meet my SLA that's what it's come down to you yes that those are the environments that I get to work in I'd love to be in some week-long batch lob chuck batch processing position we're like the performance they just they want to submit on Monday morning and get results by Friday that would be that would be kind of fun maybe it's an interesting for a while I'm sure I don't know I'm not I'm not sure that you would find your fulfillment there but no I think there I say yeah so okay so let's let's turn our gaze to the horizon here and where are we going in this world of data architecture what's gonna be happening or what kind of problems are you gonna be solving down the road there's like kind of tickets there what does it look like well and this you know I'm standing on the backs of Giants with this because there's some incredibly talented people that are writing about this and are and I'm trying to follow on with them and then I'm interacting with some really top-notch architects at different client sites so this is I just have to preface by saying this is a really limited view of where things are going but one of the things that has struck me before I got into graph and the Kassandra world in this 8 sx world I was in to kind of performance for relational databases and when you start working there you start looking at how does a relational database is it constructed how do they achieve under the covers what's going on under the covers right so in typical relational database will have its its main data store and then it will also have a transaction log and then it keeps those things consistent and then it provides a really nice through SQL distraction over that and maybe it also includes a full-text indexing or some other things all of these parts are happening under the covers and what I see going on in the world now is that we realize that the relational database package is a beautiful thing for a certain set of problems but in some cases we only need parts of that and in fact we'd like to relax the acid constraints or maybe we don't really need joints because we're comfortable enough just having a different separate table for every single access pattern that we do so at a high level what I'm seeing is a deconstruction of the relational database and we're beginning to pick and choose technologies that will allow us to to build kind of boutique solutions for these big data areas okay so yeah what does that mean deconstructing the relational database so Cassandra is a great persistence layer and you can do all sorts of amazing things particularly like storing time series and other stuff in there but it's really awful for aq the anti pattern there we don't we don't want to do that and you can't do joints and there's there but there are times where I wanted I want to bring this stuff together so one of the kind of the simple steps if I'm wanting to join together or bring together data now is we've got a DAC graph and so we can throw a graph in there and and now we've got if I'm just reading a set of rows or a set of stuff I can do like I can do that if I'm wanting to join I now have this graph abstraction layer in there so I can do joins but what if I'm wanting to do something like a queue or a transaction log that that type of pattern and I perhaps I want to replay that multiple times well now we've got Kafka coming in and we now have these streaming solutions right and as I was reading into Kafka and understanding how Kafka was working at the very low level um I realized it was extremely similar to what the relational database people had been doing for years in terms of the management of the transaction logs Kafka works in a very similar fashion to how the relational database vendors I mean Kafka they recommend they optimize for the use of the the file system as a file system and then they kind of abstract away but under the covers that's what they're doing so under the covers Kafka is really operating a lot like eight or so relational databases are operating very close to the metal on the working with that file system very closely Kafka is doing the same thing and if you look at the design of how relational databases have optimized their transaction logging infrastructure and compare that to how Kafka has built its infrastructure they're very similar and so I'm seeing now is any type of use case where I would want to optimize my use of a relational database transaction log I can almost yank out that code and replace it with Kafka and get a lot for free all of the Kafka benefits in there so I think we're dealing like one of the next things is we're now dealing with relational databases or we're now dealing with our data set not just as a store of state that is a stream of events okay I gotcha so yeah what I'm hearing from you is I think that we we have a number of new options that are available to us and it's not only the relational databases those are still around but we also have some of these no SQL or not only sequel tools like Cassandra that it came into the mix but then also we have streaming technologies we have Kafka so now we have all of these things and I'm contrasting with maybe architectures of the early 2000s where maybe we had a relational database and then we had like a message broker like a job a message service or a message queue kind of thing and then those were kind of our data at rest and moving data around asynchronously let's say a synchronous message passing and then those were kind of like our two main choices and we take the database and we pick a message broker and we were done now you're telling me I might have a relational database I might have a couple of other databases a graph database a message I have a message queue or a streaming or multiple streaming sources coming in this sounds like a lot of complexity coming in so how do we manage all of this and this in this sort of I guess maybe what we're calling the polyglot persistence world that is a great question we should have a part three and I can research it I just build these things I don't run them no there there is a lot of there is a lot of complexity with this and and what one of the interesting areas that I'm I'm beginning to cut my teeth on is how do you manage that complexity because now you've got multiple solutions multiple schemas multiple versions of things in a big dependency problem that's coming along with this and so that's where you know I start talking with developers that are wanting to go down that path I'm like okay well you you need to understand your your trading you may be robbing Peter to pay Paul with this because you may solve your monolithic problems and now have decoupled all parts of your infrastructure but at the same time now you're loosely coupled or coupled in strange and unusual ways and it becomes really difficult to reason over that kind of that dispersed of an environment you've got too many moving parts to keep track of and so I think we're gonna be developing some tools for managing schema versions better and syncing those up between different things we're gonna we're gonna have to be very firm in terms of how we build our interfaces and we establish our contracts between things we have to be really clear in terms of where where we establish those contracts we need to be really clever in terms of and maybe this is also luck in terms of defining those boundaries the service boundaries or other boundaries between these things because if we're not careful about those things we're gonna we're gonna shoot ourselves in the foot and we're gonna run back to the mana left right maybe we'll go back to writing big XML schemas for no no we're not gonna do that no but yeah I guess to throw some other ideas in the mix there you know because I can and because I'm asking the questions no I think that there may be some someplace for some analytical solutions to this kind of thing to to be able to go in and use analytic tools spark what have you other platforms that allow us to kind of aggregate data across multiple sources maybe sometimes in real time maybe sometimes in not quite real time to really got to be able to go in and look and see what's happening across multiple data sources or maybe we're going to end up doing more distributed tracing and kind of as we trace the the path of a particular piece of information through the system and all the different databases and queues and streams that it ends up in to just kind of watch what happened with a particular business transaction I think there's a number of different creative solutions that are gonna start coming into play there yeah I agree with you with that at the distributed tracing is going to be a that's gonna become essential as we'd a couple things and I'm curious you I haven't thought about this yet and I've got some guys that I that look they know this technology area better than I do and I'm wondering if with that analytics we could marry that with some machine learning or something else to better and perhaps as a way to understand and optimize our environments or complex environments that we're managing oh absolutely watch this space I think is the word on that one so okay as we often tend to do on the distributed data show we have an ongoing conversation with with many voices in it and I think we'll stop ourselves for today and and leave that topic on the table as a tease for a future episode because it Amit Lee is an ongoing conversation that we have here in a rapidly changing industry in a place that is fun to be honestly from a technology perspective so Josh we've really had enjoyed having you on the show and we're definitely leaving some teasers out there so we can have you on in the future to talk more I want to hear once you've learned the secret to managing the complexity of all these different tools I want to hear some of those secrets so yeah well I've got to thank you very much Jeff this has been a lot of fun I'm I mean that really is the frontier I see as next as we're as we've deconstructed this database and we've blown everything apart now we've got state multiple places and projections of our data and lots of different processes interacting in strange and unexpected ways this is it is the Wild West out there and that's of course is where I'd like to play and I'm I'm thank you for this opportunity to talk about that excellence well at this point we will ride off into the sunset of our wild wild west here and thanks for watching this episode of the distributed data show see you next time thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data stacks Academy and tell us what you think you can also find us on the data stacks Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.31,
        "duration": 4.29,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.6,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.28,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 8.52,
        "text": "large-scale distributed systems hey it's"
      },
      {
        "start": 16.74,
        "duration": 4.459,
        "text": "Jeff carpenter here again with Josh"
      },
      {
        "start": 19.17,
        "duration": 7.32,
        "text": "Pearman from expiry"
      },
      {
        "start": 21.199,
        "duration": 7.361,
        "text": "so long since we last spoke I've got a"
      },
      {
        "start": 26.49,
        "duration": 4.859,
        "text": "laundry cycle myself it looks like"
      },
      {
        "start": 28.56,
        "duration": 4.8,
        "text": "you've done the same yeah yeah you know"
      },
      {
        "start": 31.349,
        "duration": 5.101,
        "text": "brush my teeth a couple times but today"
      },
      {
        "start": 33.36,
        "duration": 5.519,
        "text": "is a new day so to speak last time when"
      },
      {
        "start": 36.45,
        "duration": 5.879,
        "text": "we talked we got a bit of your history"
      },
      {
        "start": 38.879,
        "duration": 5.43,
        "text": "on how you got into graph databases in"
      },
      {
        "start": 42.329,
        "duration": 4.651,
        "text": "particular like kind of how that voyage"
      },
      {
        "start": 44.309,
        "duration": 4.491,
        "text": "of discovery that you were on and some"
      },
      {
        "start": 46.98,
        "duration": 4.349,
        "text": "of the discoveries that you had around"
      },
      {
        "start": 48.8,
        "duration": 5.2,
        "text": "when to use a graph database what it"
      },
      {
        "start": 51.329,
        "duration": 6.061,
        "text": "really excels at how you mix graph"
      },
      {
        "start": 54.0,
        "duration": 5.25,
        "text": "databases into your solution and what"
      },
      {
        "start": 57.39,
        "duration": 6.18,
        "text": "parts of the problem you choose to apply"
      },
      {
        "start": 59.25,
        "duration": 6.059,
        "text": "your graph database on spoiler alert if"
      },
      {
        "start": 63.57,
        "duration": 3.96,
        "text": "you haven't watched that or listened to"
      },
      {
        "start": 65.309,
        "duration": 5.161,
        "text": "that episode yet it's more on the read"
      },
      {
        "start": 67.53,
        "duration": 6.56,
        "text": "path in Josh's experience so what I want"
      },
      {
        "start": 70.47,
        "duration": 7.32,
        "text": "to talk about with you today is"
      },
      {
        "start": 74.09,
        "duration": 5.529,
        "text": "basically like where are we at now in"
      },
      {
        "start": 77.79,
        "duration": 3.42,
        "text": "the world of enterprise data"
      },
      {
        "start": 79.619,
        "duration": 4.591,
        "text": "architecture when we're kind of building"
      },
      {
        "start": 81.21,
        "duration": 4.949,
        "text": "large-scale systems and thinking in"
      },
      {
        "start": 84.21,
        "duration": 4.049,
        "text": "particular at the data tier like what's"
      },
      {
        "start": 86.159,
        "duration": 4.861,
        "text": "the state of the art right now that you"
      },
      {
        "start": 88.259,
        "duration": 4.29,
        "text": "see in industry and then where should we"
      },
      {
        "start": 91.02,
        "duration": 3.959,
        "text": "be going where are we going where we"
      },
      {
        "start": 92.549,
        "duration": 6.541,
        "text": "headed in the future so what do you"
      },
      {
        "start": 94.979,
        "duration": 5.881,
        "text": "think so state of the art I know where a"
      },
      {
        "start": 99.09,
        "duration": 3.3,
        "text": "lot of enterprises want to be but I know"
      },
      {
        "start": 100.86,
        "duration": 2.969,
        "text": "where most of them are is they're still"
      },
      {
        "start": 102.39,
        "duration": 3.63,
        "text": "working with their relational databases"
      },
      {
        "start": 103.829,
        "duration": 4.261,
        "text": "and I think that's a really good thing"
      },
      {
        "start": 106.02,
        "duration": 4.65,
        "text": "in large cases because that's a known"
      },
      {
        "start": 108.09,
        "duration": 4.77,
        "text": "and well established technology area"
      },
      {
        "start": 110.67,
        "duration": 4.83,
        "text": "where we see them running into problems"
      },
      {
        "start": 112.86,
        "duration": 5.45,
        "text": "is when they start scaling or running"
      },
      {
        "start": 115.5,
        "duration": 4.469,
        "text": "into places where they're Reed intensive"
      },
      {
        "start": 118.31,
        "duration": 4.08,
        "text": "environments and the relational"
      },
      {
        "start": 119.969,
        "duration": 4.621,
        "text": "databases are third normal form and"
      },
      {
        "start": 122.39,
        "duration": 4.119,
        "text": "every single query is going to be"
      },
      {
        "start": 124.59,
        "duration": 4.919,
        "text": "multiple joints it's too much to do at"
      },
      {
        "start": 126.509,
        "duration": 4.891,
        "text": "runtime yeah and so that's when you get"
      },
      {
        "start": 129.509,
        "duration": 2.641,
        "text": "the phone call is when they're pushing"
      },
      {
        "start": 131.4,
        "duration": 2.699,
        "text": "up against the"
      },
      {
        "start": 132.15,
        "duration": 5.759,
        "text": "it's of what their current database or"
      },
      {
        "start": 134.099,
        "duration": 5.31,
        "text": "data layer can handle is that right when"
      },
      {
        "start": 137.909,
        "duration": 4.53,
        "text": "I look at the last particularly of my"
      },
      {
        "start": 139.409,
        "duration": 4.83,
        "text": "last four years or so of working with"
      },
      {
        "start": 142.439,
        "duration": 4.11,
        "text": "different development groups because I"
      },
      {
        "start": 144.239,
        "duration": 5.041,
        "text": "don't I don't work with product owners I"
      },
      {
        "start": 146.549,
        "duration": 6.181,
        "text": "usually work with development teams it's"
      },
      {
        "start": 149.28,
        "duration": 5.28,
        "text": "going in and helping them with to expand"
      },
      {
        "start": 152.73,
        "duration": 3.959,
        "text": "their existing toolset they know the"
      },
      {
        "start": 154.56,
        "duration": 3.75,
        "text": "relation database as well but when they"
      },
      {
        "start": 156.689,
        "duration": 4.231,
        "text": "get to a point and we do this all over"
      },
      {
        "start": 158.31,
        "duration": 5.789,
        "text": "the place where we have our our tools"
      },
      {
        "start": 160.92,
        "duration": 4.92,
        "text": "for solving problems and we have our"
      },
      {
        "start": 164.099,
        "duration": 3.54,
        "text": "common patterns for addressing those but"
      },
      {
        "start": 165.84,
        "duration": 3.36,
        "text": "when our problems get too big or they"
      },
      {
        "start": 167.639,
        "duration": 3.93,
        "text": "change dramatically or our business"
      },
      {
        "start": 169.2,
        "duration": 5.22,
        "text": "requirements may change dramatically"
      },
      {
        "start": 171.569,
        "duration": 4.471,
        "text": "we may have huge amounts more data than"
      },
      {
        "start": 174.42,
        "duration": 4.439,
        "text": "we were expecting or some other major"
      },
      {
        "start": 176.04,
        "duration": 5.25,
        "text": "shift that's when we need to expand our"
      },
      {
        "start": 178.859,
        "duration": 4.44,
        "text": "tool set and that's usually when I get"
      },
      {
        "start": 181.29,
        "duration": 4.38,
        "text": "to come in because I've been working"
      },
      {
        "start": 183.299,
        "duration": 4.08,
        "text": "with a variety of different tools and"
      },
      {
        "start": 185.67,
        "duration": 3.42,
        "text": "working in those problem areas and so I"
      },
      {
        "start": 187.379,
        "duration": 3.75,
        "text": "get to kind of come alongside those"
      },
      {
        "start": 189.09,
        "duration": 4.11,
        "text": "other developers and say hey here's a"
      },
      {
        "start": 191.129,
        "duration": 3.51,
        "text": "really amazing technology and the data"
      },
      {
        "start": 193.2,
        "duration": 3.96,
        "text": "stacks is build let me show you the"
      },
      {
        "start": 194.639,
        "duration": 4.081,
        "text": "right way to use it so you don't get"
      },
      {
        "start": 197.16,
        "duration": 2.639,
        "text": "hurt in the process and we actually"
      },
      {
        "start": 198.72,
        "duration": 7.049,
        "text": "solve the problems and you don't get"
      },
      {
        "start": 199.799,
        "duration": 9.241,
        "text": "frustrated so what's the toolset spill a"
      },
      {
        "start": 205.769,
        "duration": 5.19,
        "text": "lot of this okay so you know when I come"
      },
      {
        "start": 209.04,
        "duration": 4.349,
        "text": "back to this and I've got some great"
      },
      {
        "start": 210.959,
        "duration": 3.75,
        "text": "points along the way a lot of it is"
      },
      {
        "start": 213.389,
        "duration": 5.49,
        "text": "understanding what's happening at the"
      },
      {
        "start": 214.709,
        "duration": 6.301,
        "text": "persistence layer or understanding kind"
      },
      {
        "start": 218.879,
        "duration": 4.621,
        "text": "of this full stack I was in Denver a"
      },
      {
        "start": 221.01,
        "duration": 3.809,
        "text": "couple of years ago working with I can"
      },
      {
        "start": 223.5,
        "duration": 4.29,
        "text": "say was Comcast because they actually"
      },
      {
        "start": 224.819,
        "duration": 5.491,
        "text": "did a talk about the learnings that we"
      },
      {
        "start": 227.79,
        "duration": 4.619,
        "text": "went through there and and they were on"
      },
      {
        "start": 230.31,
        "duration": 4.109,
        "text": "their third graph database engine and"
      },
      {
        "start": 232.409,
        "duration": 3.961,
        "text": "they were looking at a scale out"
      },
      {
        "start": 234.419,
        "duration": 3.06,
        "text": "solution and and I talked with him what"
      },
      {
        "start": 236.37,
        "duration": 4.14,
        "text": "they had learned up to that point I'm"
      },
      {
        "start": 237.479,
        "duration": 5.01,
        "text": "like yeah okay you you learned a lot so"
      },
      {
        "start": 240.51,
        "duration": 3.42,
        "text": "let's see me show you how to use data"
      },
      {
        "start": 242.489,
        "duration": 3.15,
        "text": "stacks graph to solve this problem and I"
      },
      {
        "start": 243.93,
        "duration": 4.199,
        "text": "went toe-to-toe with our architect a"
      },
      {
        "start": 245.639,
        "duration": 3.78,
        "text": "really really sharp guy and he says no"
      },
      {
        "start": 248.129,
        "duration": 3.42,
        "text": "that's not the way graph works I'm like"
      },
      {
        "start": 249.419,
        "duration": 4.771,
        "text": "well we're not really modeling for graph"
      },
      {
        "start": 251.549,
        "duration": 5.131,
        "text": "we're modeling for Cassandra here and"
      },
      {
        "start": 254.19,
        "duration": 4.919,
        "text": "this is kind of the tool set and this is"
      },
      {
        "start": 256.68,
        "duration": 3.959,
        "text": "what I learned so much from going"
      },
      {
        "start": 259.109,
        "duration": 3.93,
        "text": "through the data stacks Academy courses"
      },
      {
        "start": 260.639,
        "duration": 5.131,
        "text": "really in data sex bootcamp and other"
      },
      {
        "start": 263.039,
        "duration": 4.921,
        "text": "things was we model for our access"
      },
      {
        "start": 265.77,
        "duration": 4.47,
        "text": "patterns and you can really optimize for"
      },
      {
        "start": 267.96,
        "duration": 4.38,
        "text": "that and when you do that you are now"
      },
      {
        "start": 270.24,
        "duration": 5.19,
        "text": "able to and with when you give up on"
      },
      {
        "start": 272.34,
        "duration": 5.91,
        "text": "joins as well you're able to do some"
      },
      {
        "start": 275.43,
        "duration": 4.799,
        "text": "amazing things in performant ways across"
      },
      {
        "start": 278.25,
        "duration": 4.08,
        "text": "multiple machines it was really neat"
      },
      {
        "start": 280.229,
        "duration": 3.12,
        "text": "about that experience in Denver was kind"
      },
      {
        "start": 282.33,
        "duration": 2.01,
        "text": "of talking with them and saying okay"
      },
      {
        "start": 283.349,
        "duration": 3.391,
        "text": "here's some of the trade-offs that we"
      },
      {
        "start": 284.34,
        "duration": 4.77,
        "text": "have to make from our graph design point"
      },
      {
        "start": 286.74,
        "duration": 4.17,
        "text": "of view but when we do that we're using"
      },
      {
        "start": 289.11,
        "duration": 3.98,
        "text": "Cassandra really well underneath and"
      },
      {
        "start": 290.91,
        "duration": 5.789,
        "text": "we're still able to reason over our data"
      },
      {
        "start": 293.09,
        "duration": 4.15,
        "text": "for in a graph way so it was a bit of a"
      },
      {
        "start": 296.699,
        "duration": 2.22,
        "text": "twofer"
      },
      {
        "start": 297.24,
        "duration": 5.16,
        "text": "we got the performance benefits from"
      },
      {
        "start": 298.919,
        "duration": 5.191,
        "text": "Cassandra and the scaling benefits but"
      },
      {
        "start": 302.4,
        "duration": 4.32,
        "text": "we were able to think about and reason"
      },
      {
        "start": 304.11,
        "duration": 5.19,
        "text": "in their domain in a graph way gotcha"
      },
      {
        "start": 306.72,
        "duration": 5.28,
        "text": "okay so it sounds like state of the art"
      },
      {
        "start": 309.3,
        "duration": 4.29,
        "text": "where we're at in industry is in a"
      },
      {
        "start": 312.0,
        "duration": 4.11,
        "text": "number of places maybe not every company"
      },
      {
        "start": 313.59,
        "duration": 5.04,
        "text": "not every company has massive data sets"
      },
      {
        "start": 316.11,
        "duration": 4.529,
        "text": "or massive scale out problems but we're"
      },
      {
        "start": 318.63,
        "duration": 5.64,
        "text": "seeing companies that are needed to"
      },
      {
        "start": 320.639,
        "duration": 5.971,
        "text": "scale beyond what they can get from the"
      },
      {
        "start": 324.27,
        "duration": 4.59,
        "text": "traditional relational database even"
      },
      {
        "start": 326.61,
        "duration": 4.38,
        "text": "with recent advances and and offerings"
      },
      {
        "start": 328.86,
        "duration": 4.23,
        "text": "from a variety of sources I'm still"
      },
      {
        "start": 330.99,
        "duration": 4.919,
        "text": "running into those and what what you're"
      },
      {
        "start": 333.09,
        "duration": 4.319,
        "text": "doing is not only applying graph"
      },
      {
        "start": 335.909,
        "duration": 3.931,
        "text": "databases to those problems but it"
      },
      {
        "start": 337.409,
        "duration": 4.921,
        "text": "sounds like a graph solution built on"
      },
      {
        "start": 339.84,
        "duration": 4.829,
        "text": "Cassandra to the extent that you"
      },
      {
        "start": 342.33,
        "duration": 4.44,
        "text": "actually need to think about what you're"
      },
      {
        "start": 344.669,
        "duration": 4.891,
        "text": "doing with your data model in order to"
      },
      {
        "start": 346.77,
        "duration": 4.619,
        "text": "get the scale it's not a just a pure"
      },
      {
        "start": 349.56,
        "duration": 4.409,
        "text": "abstraction that you could just drop in"
      },
      {
        "start": 351.389,
        "duration": 4.5,
        "text": "and say okay I can create whatever data"
      },
      {
        "start": 353.969,
        "duration": 4.561,
        "text": "model I want and expect it to scale well"
      },
      {
        "start": 355.889,
        "duration": 5.041,
        "text": "and perform well that's exactly the"
      },
      {
        "start": 358.53,
        "duration": 3.75,
        "text": "conversation I had in Denver you're"
      },
      {
        "start": 360.93,
        "duration": 3.9,
        "text": "staying like no we just need to use as a"
      },
      {
        "start": 362.28,
        "duration": 3.81,
        "text": "graph database and like no you're you"
      },
      {
        "start": 364.83,
        "duration": 3.03,
        "text": "can do that when you're dealing with"
      },
      {
        "start": 366.09,
        "duration": 3.24,
        "text": "toys and when you're dealing with small"
      },
      {
        "start": 367.86,
        "duration": 4.26,
        "text": "data sets but when you start dealing"
      },
      {
        "start": 369.33,
        "duration": 4.17,
        "text": "with interesting levels of data you have"
      },
      {
        "start": 372.12,
        "duration": 3.87,
        "text": "to start thinking about data locality"
      },
      {
        "start": 373.5,
        "duration": 4.469,
        "text": "where is my data located and if I'm"
      },
      {
        "start": 375.99,
        "duration": 3.69,
        "text": "gonna be querying two pieces of data"
      },
      {
        "start": 377.969,
        "duration": 4.081,
        "text": "regularly I want them to be on the same"
      },
      {
        "start": 379.68,
        "duration": 4.35,
        "text": "device or better yet in the same table"
      },
      {
        "start": 382.05,
        "duration": 4.649,
        "text": "or better yet like on the same partition"
      },
      {
        "start": 384.03,
        "duration": 4.889,
        "text": "of disk right oh so that's the secret"
      },
      {
        "start": 386.699,
        "duration": 3.931,
        "text": "sauce then a lot of it comes down to"
      },
      {
        "start": 388.919,
        "duration": 4.441,
        "text": "understanding what's happening at that"
      },
      {
        "start": 390.63,
        "duration": 4.56,
        "text": "low level at the disk layer where is my"
      },
      {
        "start": 393.36,
        "duration": 4.619,
        "text": "data what note is in the cluster is my"
      },
      {
        "start": 395.19,
        "duration": 4.08,
        "text": "data on within that node where is it on"
      },
      {
        "start": 397.979,
        "duration": 3.631,
        "text": "disk of data"
      },
      {
        "start": 399.27,
        "duration": 3.99,
        "text": "Calla t that's what often times when I'm"
      },
      {
        "start": 401.61,
        "duration": 3.57,
        "text": "trying to optimize for except when I"
      },
      {
        "start": 403.26,
        "duration": 3.09,
        "text": "can't in different cases where I can't"
      },
      {
        "start": 405.18,
        "duration": 2.76,
        "text": "of course"
      },
      {
        "start": 406.35,
        "duration": 4.47,
        "text": "yeah yeah but but when it comes down to"
      },
      {
        "start": 407.94,
        "duration": 6.06,
        "text": "ultimately is I need no second latency"
      },
      {
        "start": 410.82,
        "duration": 5.07,
        "text": "on on my query that I'm trying to serve"
      },
      {
        "start": 414.0,
        "duration": 5.22,
        "text": "have a massive data set it's spread"
      },
      {
        "start": 415.89,
        "duration": 5.94,
        "text": "across multiple nodes in a cluster and I"
      },
      {
        "start": 419.22,
        "duration": 5.94,
        "text": "wanted to do as few reads as possible"
      },
      {
        "start": 421.83,
        "duration": 5.19,
        "text": "across you know as off of literally off"
      },
      {
        "start": 425.16,
        "duration": 4.17,
        "text": "of disk or maybe I even have stuff cache"
      },
      {
        "start": 427.02,
        "duration": 4.65,
        "text": "but I want to be doing as as few data"
      },
      {
        "start": 429.33,
        "duration": 4.5,
        "text": "accesses possible to get back the data"
      },
      {
        "start": 431.67,
        "duration": 3.9,
        "text": "that I need so I can meet my SLA that's"
      },
      {
        "start": 433.83,
        "duration": 3.3,
        "text": "what it's come down to you yes that"
      },
      {
        "start": 435.57,
        "duration": 4.71,
        "text": "those are the environments that I get to"
      },
      {
        "start": 437.13,
        "duration": 6.33,
        "text": "work in I'd love to be in some week-long"
      },
      {
        "start": 440.28,
        "duration": 5.79,
        "text": "batch lob chuck batch processing"
      },
      {
        "start": 443.46,
        "duration": 3.93,
        "text": "position we're like the performance they"
      },
      {
        "start": 446.07,
        "duration": 3.06,
        "text": "just they want to submit on Monday"
      },
      {
        "start": 447.39,
        "duration": 3.84,
        "text": "morning and get results by Friday that"
      },
      {
        "start": 449.13,
        "duration": 3.42,
        "text": "would be that would be kind of fun maybe"
      },
      {
        "start": 451.23,
        "duration": 4.2,
        "text": "it's an interesting for a while I'm sure"
      },
      {
        "start": 452.55,
        "duration": 4.71,
        "text": "I don't know I'm not I'm not sure that"
      },
      {
        "start": 455.43,
        "duration": 5.1,
        "text": "you would find your fulfillment there"
      },
      {
        "start": 457.26,
        "duration": 6.27,
        "text": "but no I think there I say yeah so okay"
      },
      {
        "start": 460.53,
        "duration": 7.71,
        "text": "so let's let's turn our gaze to the"
      },
      {
        "start": 463.53,
        "duration": 7.98,
        "text": "horizon here and where are we going in"
      },
      {
        "start": 468.24,
        "duration": 4.47,
        "text": "this world of data architecture what's"
      },
      {
        "start": 471.51,
        "duration": 3.03,
        "text": "gonna be happening or what kind of"
      },
      {
        "start": 472.71,
        "duration": 3.15,
        "text": "problems are you gonna be solving down"
      },
      {
        "start": 474.54,
        "duration": 3.24,
        "text": "the road there's like kind of tickets"
      },
      {
        "start": 475.86,
        "duration": 3.42,
        "text": "there what does it look like well and"
      },
      {
        "start": 477.78,
        "duration": 3.45,
        "text": "this you know I'm standing on the backs"
      },
      {
        "start": 479.28,
        "duration": 4.35,
        "text": "of Giants with this because there's some"
      },
      {
        "start": 481.23,
        "duration": 4.74,
        "text": "incredibly talented people that are"
      },
      {
        "start": 483.63,
        "duration": 3.96,
        "text": "writing about this and are and I'm"
      },
      {
        "start": 485.97,
        "duration": 3.36,
        "text": "trying to follow on with them and then"
      },
      {
        "start": 487.59,
        "duration": 5.13,
        "text": "I'm interacting with some really"
      },
      {
        "start": 489.33,
        "duration": 7.59,
        "text": "top-notch architects at different client"
      },
      {
        "start": 492.72,
        "duration": 5.7,
        "text": "sites so this is I just have to preface"
      },
      {
        "start": 496.92,
        "duration": 3.15,
        "text": "by saying this is a really limited view"
      },
      {
        "start": 498.42,
        "duration": 5.52,
        "text": "of where things are going but one of the"
      },
      {
        "start": 500.07,
        "duration": 6.51,
        "text": "things that has struck me before I got"
      },
      {
        "start": 503.94,
        "duration": 5.31,
        "text": "into graph and the Kassandra world in"
      },
      {
        "start": 506.58,
        "duration": 5.07,
        "text": "this 8 sx world I was in to kind of"
      },
      {
        "start": 509.25,
        "duration": 4.86,
        "text": "performance for relational databases and"
      },
      {
        "start": 511.65,
        "duration": 4.02,
        "text": "when you start working there you start"
      },
      {
        "start": 514.11,
        "duration": 4.17,
        "text": "looking at how does a relational"
      },
      {
        "start": 515.67,
        "duration": 4.95,
        "text": "database is it constructed how do they"
      },
      {
        "start": 518.28,
        "duration": 4.28,
        "text": "achieve under the covers what's going on"
      },
      {
        "start": 520.62,
        "duration": 4.17,
        "text": "under the covers right so in typical"
      },
      {
        "start": 522.56,
        "duration": 4.3,
        "text": "relational database will have its its"
      },
      {
        "start": 524.79,
        "duration": 3.96,
        "text": "main data store and then it will also"
      },
      {
        "start": 526.86,
        "duration": 3.39,
        "text": "have a transaction log and then it keeps"
      },
      {
        "start": 528.75,
        "duration": 4.44,
        "text": "those things consistent and then it"
      },
      {
        "start": 530.25,
        "duration": 4.35,
        "text": "provides a really nice through SQL"
      },
      {
        "start": 533.19,
        "duration": 3.12,
        "text": "distraction over that and maybe it also"
      },
      {
        "start": 534.6,
        "duration": 3.45,
        "text": "includes a full-text indexing or some"
      },
      {
        "start": 536.31,
        "duration": 3.75,
        "text": "other things all of these parts are"
      },
      {
        "start": 538.05,
        "duration": 4.77,
        "text": "happening under the covers and what I"
      },
      {
        "start": 540.06,
        "duration": 5.73,
        "text": "see going on in the world now is that we"
      },
      {
        "start": 542.82,
        "duration": 4.92,
        "text": "realize that the relational database"
      },
      {
        "start": 545.79,
        "duration": 4.29,
        "text": "package is a beautiful thing for a"
      },
      {
        "start": 547.74,
        "duration": 4.77,
        "text": "certain set of problems but in some"
      },
      {
        "start": 550.08,
        "duration": 4.77,
        "text": "cases we only need parts of that and in"
      },
      {
        "start": 552.51,
        "duration": 3.63,
        "text": "fact we'd like to relax the acid"
      },
      {
        "start": 554.85,
        "duration": 3.0,
        "text": "constraints or maybe we don't really"
      },
      {
        "start": 556.14,
        "duration": 5.04,
        "text": "need joints because we're comfortable"
      },
      {
        "start": 557.85,
        "duration": 5.19,
        "text": "enough just having a different separate"
      },
      {
        "start": 561.18,
        "duration": 4.68,
        "text": "table for every single access pattern"
      },
      {
        "start": 563.04,
        "duration": 4.38,
        "text": "that we do so at a high level what I'm"
      },
      {
        "start": 565.86,
        "duration": 3.42,
        "text": "seeing is a deconstruction of the"
      },
      {
        "start": 567.42,
        "duration": 4.47,
        "text": "relational database and we're beginning"
      },
      {
        "start": 569.28,
        "duration": 6.24,
        "text": "to pick and choose technologies that"
      },
      {
        "start": 571.89,
        "duration": 6.42,
        "text": "will allow us to to build kind of"
      },
      {
        "start": 575.52,
        "duration": 6.41,
        "text": "boutique solutions for these big data"
      },
      {
        "start": 578.31,
        "duration": 6.06,
        "text": "areas okay so yeah what does that mean"
      },
      {
        "start": 581.93,
        "duration": 6.37,
        "text": "deconstructing the relational database"
      },
      {
        "start": 584.37,
        "duration": 5.61,
        "text": "so Cassandra is a great persistence"
      },
      {
        "start": 588.3,
        "duration": 4.02,
        "text": "layer and you can do all sorts of"
      },
      {
        "start": 589.98,
        "duration": 4.41,
        "text": "amazing things particularly like storing"
      },
      {
        "start": 592.32,
        "duration": 4.08,
        "text": "time series and other stuff in there but"
      },
      {
        "start": 594.39,
        "duration": 3.24,
        "text": "it's really awful for aq the anti"
      },
      {
        "start": 596.4,
        "duration": 3.27,
        "text": "pattern there we don't we don't want to"
      },
      {
        "start": 597.63,
        "duration": 4.35,
        "text": "do that and you can't do joints and"
      },
      {
        "start": 599.67,
        "duration": 4.05,
        "text": "there's there but there are times where"
      },
      {
        "start": 601.98,
        "duration": 2.91,
        "text": "I wanted I want to bring this stuff"
      },
      {
        "start": 603.72,
        "duration": 3.18,
        "text": "together so one of the kind of the"
      },
      {
        "start": 604.89,
        "duration": 3.96,
        "text": "simple steps if I'm wanting to join"
      },
      {
        "start": 606.9,
        "duration": 4.53,
        "text": "together or bring together data now is"
      },
      {
        "start": 608.85,
        "duration": 4.2,
        "text": "we've got a DAC graph and so we can"
      },
      {
        "start": 611.43,
        "duration": 4.5,
        "text": "throw a graph in there and and now we've"
      },
      {
        "start": 613.05,
        "duration": 5.19,
        "text": "got if I'm just reading a set of rows or"
      },
      {
        "start": 615.93,
        "duration": 4.74,
        "text": "a set of stuff I can do like I can do"
      },
      {
        "start": 618.24,
        "duration": 4.41,
        "text": "that if I'm wanting to join I now have"
      },
      {
        "start": 620.67,
        "duration": 4.59,
        "text": "this graph abstraction layer in there so"
      },
      {
        "start": 622.65,
        "duration": 4.44,
        "text": "I can do joins but what if I'm wanting"
      },
      {
        "start": 625.26,
        "duration": 5.22,
        "text": "to do something like a queue or a"
      },
      {
        "start": 627.09,
        "duration": 5.4,
        "text": "transaction log that that type of"
      },
      {
        "start": 630.48,
        "duration": 5.16,
        "text": "pattern and I perhaps I want to replay"
      },
      {
        "start": 632.49,
        "duration": 4.92,
        "text": "that multiple times well now we've got"
      },
      {
        "start": 635.64,
        "duration": 4.08,
        "text": "Kafka coming in and we now have these"
      },
      {
        "start": 637.41,
        "duration": 5.1,
        "text": "streaming solutions right and as I was"
      },
      {
        "start": 639.72,
        "duration": 5.07,
        "text": "reading into Kafka and understanding how"
      },
      {
        "start": 642.51,
        "duration": 5.55,
        "text": "Kafka was working at the very low level"
      },
      {
        "start": 644.79,
        "duration": 4.65,
        "text": "um I realized it was extremely similar"
      },
      {
        "start": 648.06,
        "duration": 3.66,
        "text": "to what the relational database people"
      },
      {
        "start": 649.44,
        "duration": 5.04,
        "text": "had been doing for years in terms of the"
      },
      {
        "start": 651.72,
        "duration": 5.52,
        "text": "management of the transaction logs Kafka"
      },
      {
        "start": 654.48,
        "duration": 4.47,
        "text": "works in a very similar fashion to how"
      },
      {
        "start": 657.24,
        "duration": 4.5,
        "text": "the relational database vendors I mean"
      },
      {
        "start": 658.95,
        "duration": 5.73,
        "text": "Kafka they recommend they optimize for"
      },
      {
        "start": 661.74,
        "duration": 4.83,
        "text": "the use of the the file system as a file"
      },
      {
        "start": 664.68,
        "duration": 2.34,
        "text": "system and then they kind of abstract"
      },
      {
        "start": 666.57,
        "duration": 1.92,
        "text": "away"
      },
      {
        "start": 667.02,
        "duration": 4.79,
        "text": "but under the covers that's what they're"
      },
      {
        "start": 668.49,
        "duration": 6.51,
        "text": "doing so under the covers Kafka is"
      },
      {
        "start": 671.81,
        "duration": 5.89,
        "text": "really operating a lot like eight or so"
      },
      {
        "start": 675.0,
        "duration": 4.23,
        "text": "relational databases are operating very"
      },
      {
        "start": 677.7,
        "duration": 4.11,
        "text": "close to the metal on the working with"
      },
      {
        "start": 679.23,
        "duration": 4.68,
        "text": "that file system very closely Kafka is"
      },
      {
        "start": 681.81,
        "duration": 4.44,
        "text": "doing the same thing and if you look at"
      },
      {
        "start": 683.91,
        "duration": 4.65,
        "text": "the design of how relational databases"
      },
      {
        "start": 686.25,
        "duration": 4.44,
        "text": "have optimized their transaction logging"
      },
      {
        "start": 688.56,
        "duration": 4.32,
        "text": "infrastructure and compare that to how"
      },
      {
        "start": 690.69,
        "duration": 5.13,
        "text": "Kafka has built its infrastructure"
      },
      {
        "start": 692.88,
        "duration": 5.04,
        "text": "they're very similar and so I'm seeing"
      },
      {
        "start": 695.82,
        "duration": 4.83,
        "text": "now is any type of use case where I"
      },
      {
        "start": 697.92,
        "duration": 4.47,
        "text": "would want to optimize my use of a"
      },
      {
        "start": 700.65,
        "duration": 5.19,
        "text": "relational database transaction log I"
      },
      {
        "start": 702.39,
        "duration": 5.73,
        "text": "can almost yank out that code and"
      },
      {
        "start": 705.84,
        "duration": 5.01,
        "text": "replace it with Kafka and get a lot for"
      },
      {
        "start": 708.12,
        "duration": 4.86,
        "text": "free all of the Kafka benefits in there"
      },
      {
        "start": 710.85,
        "duration": 4.89,
        "text": "so I think we're dealing like one of the"
      },
      {
        "start": 712.98,
        "duration": 4.92,
        "text": "next things is we're now dealing with"
      },
      {
        "start": 715.74,
        "duration": 3.9,
        "text": "relational databases or we're now"
      },
      {
        "start": 717.9,
        "duration": 3.42,
        "text": "dealing with our data set not just as a"
      },
      {
        "start": 719.64,
        "duration": 5.31,
        "text": "store of state that is a stream of"
      },
      {
        "start": 721.32,
        "duration": 5.97,
        "text": "events okay I gotcha so yeah what I'm"
      },
      {
        "start": 724.95,
        "duration": 5.76,
        "text": "hearing from you is I think that we we"
      },
      {
        "start": 727.29,
        "duration": 5.94,
        "text": "have a number of new options that are"
      },
      {
        "start": 730.71,
        "duration": 4.02,
        "text": "available to us and it's not only the"
      },
      {
        "start": 733.23,
        "duration": 4.56,
        "text": "relational databases those are still"
      },
      {
        "start": 734.73,
        "duration": 6.33,
        "text": "around but we also have some of these no"
      },
      {
        "start": 737.79,
        "duration": 4.86,
        "text": "SQL or not only sequel tools like"
      },
      {
        "start": 741.06,
        "duration": 3.24,
        "text": "Cassandra that it came into the mix but"
      },
      {
        "start": 742.65,
        "duration": 3.81,
        "text": "then also we have streaming technologies"
      },
      {
        "start": 744.3,
        "duration": 4.68,
        "text": "we have Kafka so now we have all of"
      },
      {
        "start": 746.46,
        "duration": 6.93,
        "text": "these things and I'm contrasting with"
      },
      {
        "start": 748.98,
        "duration": 7.29,
        "text": "maybe architectures of the early 2000s"
      },
      {
        "start": 753.39,
        "duration": 5.22,
        "text": "where maybe we had a relational database"
      },
      {
        "start": 756.27,
        "duration": 4.67,
        "text": "and then we had like a message broker"
      },
      {
        "start": 758.61,
        "duration": 4.59,
        "text": "like a job a message service or a"
      },
      {
        "start": 760.94,
        "duration": 5.07,
        "text": "message queue kind of thing and then"
      },
      {
        "start": 763.2,
        "duration": 6.57,
        "text": "those were kind of our data at rest and"
      },
      {
        "start": 766.01,
        "duration": 5.41,
        "text": "moving data around asynchronously let's"
      },
      {
        "start": 769.77,
        "duration": 3.0,
        "text": "say a synchronous message passing and"
      },
      {
        "start": 771.42,
        "duration": 2.76,
        "text": "then those were kind of like our two"
      },
      {
        "start": 772.77,
        "duration": 3.6,
        "text": "main choices and we take the database"
      },
      {
        "start": 774.18,
        "duration": 4.83,
        "text": "and we pick a message broker and we were"
      },
      {
        "start": 776.37,
        "duration": 4.11,
        "text": "done now you're telling me I might have"
      },
      {
        "start": 779.01,
        "duration": 2.88,
        "text": "a relational database I might have a"
      },
      {
        "start": 780.48,
        "duration": 5.1,
        "text": "couple of other databases a graph"
      },
      {
        "start": 781.89,
        "duration": 5.61,
        "text": "database a message I have a message"
      },
      {
        "start": 785.58,
        "duration": 3.84,
        "text": "queue or a streaming or multiple"
      },
      {
        "start": 787.5,
        "duration": 4.71,
        "text": "streaming sources coming in this sounds"
      },
      {
        "start": 789.42,
        "duration": 6.0,
        "text": "like a lot of complexity coming in so"
      },
      {
        "start": 792.21,
        "duration": 4.8,
        "text": "how do we manage all of this and this in"
      },
      {
        "start": 795.42,
        "duration": 4.149,
        "text": "this sort of I guess maybe what we're"
      },
      {
        "start": 797.01,
        "duration": 5.36,
        "text": "calling the polyglot persistence world"
      },
      {
        "start": 799.569,
        "duration": 7.171,
        "text": "that is a great question we should have"
      },
      {
        "start": 802.37,
        "duration": 4.37,
        "text": "a part three and I can research it I"
      },
      {
        "start": 806.949,
        "duration": 6.43,
        "text": "just build these things I don't run them"
      },
      {
        "start": 809.24,
        "duration": 6.589,
        "text": "no there there is a lot of there is a"
      },
      {
        "start": 813.379,
        "duration": 5.671,
        "text": "lot of complexity with this and and what"
      },
      {
        "start": 815.829,
        "duration": 6.55,
        "text": "one of the interesting areas that I'm"
      },
      {
        "start": 819.05,
        "duration": 5.579,
        "text": "I'm beginning to cut my teeth on is how"
      },
      {
        "start": 822.379,
        "duration": 4.531,
        "text": "do you manage that complexity because"
      },
      {
        "start": 824.629,
        "duration": 4.531,
        "text": "now you've got multiple solutions"
      },
      {
        "start": 826.91,
        "duration": 5.27,
        "text": "multiple schemas multiple versions of"
      },
      {
        "start": 829.16,
        "duration": 5.609,
        "text": "things in a big dependency problem"
      },
      {
        "start": 832.18,
        "duration": 4.449,
        "text": "that's coming along with this and so"
      },
      {
        "start": 834.769,
        "duration": 3.601,
        "text": "that's where you know I start talking"
      },
      {
        "start": 836.629,
        "duration": 3.12,
        "text": "with developers that are wanting to go"
      },
      {
        "start": 838.37,
        "duration": 3.8,
        "text": "down that path I'm like okay well you"
      },
      {
        "start": 839.749,
        "duration": 4.95,
        "text": "you need to understand your your trading"
      },
      {
        "start": 842.17,
        "duration": 4.899,
        "text": "you may be robbing Peter to pay Paul"
      },
      {
        "start": 844.699,
        "duration": 4.62,
        "text": "with this because you may solve your"
      },
      {
        "start": 847.069,
        "duration": 3.421,
        "text": "monolithic problems and now have"
      },
      {
        "start": 849.319,
        "duration": 2.971,
        "text": "decoupled all parts of your"
      },
      {
        "start": 850.49,
        "duration": 4.829,
        "text": "infrastructure but at the same time now"
      },
      {
        "start": 852.29,
        "duration": 5.219,
        "text": "you're loosely coupled or coupled in"
      },
      {
        "start": 855.319,
        "duration": 4.56,
        "text": "strange and unusual ways and it becomes"
      },
      {
        "start": 857.509,
        "duration": 7.231,
        "text": "really difficult to reason over that"
      },
      {
        "start": 859.879,
        "duration": 7.111,
        "text": "kind of that dispersed of an environment"
      },
      {
        "start": 864.74,
        "duration": 4.019,
        "text": "you've got too many moving parts to keep"
      },
      {
        "start": 866.99,
        "duration": 4.399,
        "text": "track of and so I think we're gonna be"
      },
      {
        "start": 868.759,
        "duration": 5.461,
        "text": "developing some tools for managing"
      },
      {
        "start": 871.389,
        "duration": 4.51,
        "text": "schema versions better and syncing those"
      },
      {
        "start": 874.22,
        "duration": 4.169,
        "text": "up between different things we're gonna"
      },
      {
        "start": 875.899,
        "duration": 5.55,
        "text": "we're gonna have to be very firm in"
      },
      {
        "start": 878.389,
        "duration": 4.88,
        "text": "terms of how we build our interfaces and"
      },
      {
        "start": 881.449,
        "duration": 4.08,
        "text": "we establish our contracts between"
      },
      {
        "start": 883.269,
        "duration": 5.26,
        "text": "things we have to be really clear in"
      },
      {
        "start": 885.529,
        "duration": 5.55,
        "text": "terms of where where we establish those"
      },
      {
        "start": 888.529,
        "duration": 5.91,
        "text": "contracts we need to be really clever in"
      },
      {
        "start": 891.079,
        "duration": 5.281,
        "text": "terms of and maybe this is also luck in"
      },
      {
        "start": 894.439,
        "duration": 3.45,
        "text": "terms of defining those boundaries the"
      },
      {
        "start": 896.36,
        "duration": 4.74,
        "text": "service boundaries or other boundaries"
      },
      {
        "start": 897.889,
        "duration": 4.591,
        "text": "between these things because if we're"
      },
      {
        "start": 901.1,
        "duration": 3.12,
        "text": "not careful about those things we're"
      },
      {
        "start": 902.48,
        "duration": 3.089,
        "text": "gonna we're gonna shoot ourselves in the"
      },
      {
        "start": 904.22,
        "duration": 4.83,
        "text": "foot and we're gonna run back to the"
      },
      {
        "start": 905.569,
        "duration": 8.911,
        "text": "mana left right maybe we'll go back to"
      },
      {
        "start": 909.05,
        "duration": 9.029,
        "text": "writing big XML schemas for no no we're"
      },
      {
        "start": 914.48,
        "duration": 5.519,
        "text": "not gonna do that no but yeah I guess to"
      },
      {
        "start": 918.079,
        "duration": 4.38,
        "text": "throw some other ideas in the mix there"
      },
      {
        "start": 919.999,
        "duration": 5.911,
        "text": "you know because I can and because I'm"
      },
      {
        "start": 922.459,
        "duration": 5.22,
        "text": "asking the questions no I think that"
      },
      {
        "start": 925.91,
        "duration": 3.779,
        "text": "there may be some someplace for some"
      },
      {
        "start": 927.679,
        "duration": 4.811,
        "text": "analytical solutions to this kind of"
      },
      {
        "start": 929.689,
        "duration": 5.591,
        "text": "thing to to be able to go in"
      },
      {
        "start": 932.49,
        "duration": 4.5,
        "text": "and use analytic tools spark what have"
      },
      {
        "start": 935.28,
        "duration": 3.45,
        "text": "you other platforms that allow us to"
      },
      {
        "start": 936.99,
        "duration": 4.2,
        "text": "kind of aggregate data across multiple"
      },
      {
        "start": 938.73,
        "duration": 4.98,
        "text": "sources maybe sometimes in real time"
      },
      {
        "start": 941.19,
        "duration": 4.05,
        "text": "maybe sometimes in not quite real time"
      },
      {
        "start": 943.71,
        "duration": 3.27,
        "text": "to really got to be able to go in and"
      },
      {
        "start": 945.24,
        "duration": 4.77,
        "text": "look and see what's happening across"
      },
      {
        "start": 946.98,
        "duration": 4.86,
        "text": "multiple data sources or maybe we're"
      },
      {
        "start": 950.01,
        "duration": 5.7,
        "text": "going to end up doing more distributed"
      },
      {
        "start": 951.84,
        "duration": 5.4,
        "text": "tracing and kind of as we trace the the"
      },
      {
        "start": 955.71,
        "duration": 3.03,
        "text": "path of a particular piece of"
      },
      {
        "start": 957.24,
        "duration": 3.57,
        "text": "information through the system and all"
      },
      {
        "start": 958.74,
        "duration": 3.93,
        "text": "the different databases and queues and"
      },
      {
        "start": 960.81,
        "duration": 4.37,
        "text": "streams that it ends up in to just kind"
      },
      {
        "start": 962.67,
        "duration": 5.61,
        "text": "of watch what happened with a particular"
      },
      {
        "start": 965.18,
        "duration": 4.78,
        "text": "business transaction I think there's a"
      },
      {
        "start": 968.28,
        "duration": 2.94,
        "text": "number of different creative solutions"
      },
      {
        "start": 969.96,
        "duration": 3.39,
        "text": "that are gonna start coming into play"
      },
      {
        "start": 971.22,
        "duration": 3.93,
        "text": "there yeah I agree with you with that at"
      },
      {
        "start": 973.35,
        "duration": 4.11,
        "text": "the distributed tracing is going to be a"
      },
      {
        "start": 975.15,
        "duration": 6.18,
        "text": "that's gonna become essential as we'd a"
      },
      {
        "start": 977.46,
        "duration": 6.06,
        "text": "couple things and I'm curious you I"
      },
      {
        "start": 981.33,
        "duration": 4.74,
        "text": "haven't thought about this yet and I've"
      },
      {
        "start": 983.52,
        "duration": 3.84,
        "text": "got some guys that I that look they know"
      },
      {
        "start": 986.07,
        "duration": 3.39,
        "text": "this technology area better than I do"
      },
      {
        "start": 987.36,
        "duration": 4.92,
        "text": "and I'm wondering if with that analytics"
      },
      {
        "start": 989.46,
        "duration": 4.65,
        "text": "we could marry that with some machine"
      },
      {
        "start": 992.28,
        "duration": 3.9,
        "text": "learning or something else to better and"
      },
      {
        "start": 994.11,
        "duration": 4.5,
        "text": "perhaps as a way to understand and"
      },
      {
        "start": 996.18,
        "duration": 3.57,
        "text": "optimize our environments or complex"
      },
      {
        "start": 998.61,
        "duration": 4.59,
        "text": "environments that we're managing"
      },
      {
        "start": 999.75,
        "duration": 4.92,
        "text": "oh absolutely watch this space I think"
      },
      {
        "start": 1003.2,
        "duration": 6.51,
        "text": "is the word on that one"
      },
      {
        "start": 1004.67,
        "duration": 7.31,
        "text": "so okay as we often tend to do on the"
      },
      {
        "start": 1009.71,
        "duration": 5.34,
        "text": "distributed data show we have an ongoing"
      },
      {
        "start": 1011.98,
        "duration": 6.4,
        "text": "conversation with with many voices in it"
      },
      {
        "start": 1015.05,
        "duration": 6.12,
        "text": "and I think we'll stop ourselves for"
      },
      {
        "start": 1018.38,
        "duration": 5.45,
        "text": "today and and leave that topic on the"
      },
      {
        "start": 1021.17,
        "duration": 5.64,
        "text": "table as a tease for a future episode"
      },
      {
        "start": 1023.83,
        "duration": 6.28,
        "text": "because it Amit Lee is an ongoing"
      },
      {
        "start": 1026.81,
        "duration": 6.48,
        "text": "conversation that we have here in a"
      },
      {
        "start": 1030.11,
        "duration": 5.55,
        "text": "rapidly changing industry in a place"
      },
      {
        "start": 1033.29,
        "duration": 5.73,
        "text": "that is fun to be honestly from a"
      },
      {
        "start": 1035.66,
        "duration": 5.73,
        "text": "technology perspective so Josh we've"
      },
      {
        "start": 1039.02,
        "duration": 5.46,
        "text": "really had enjoyed having you on the"
      },
      {
        "start": 1041.39,
        "duration": 4.56,
        "text": "show and we're definitely leaving some"
      },
      {
        "start": 1044.48,
        "duration": 3.18,
        "text": "teasers out there so we can have you on"
      },
      {
        "start": 1045.95,
        "duration": 3.72,
        "text": "in the future to talk more I want to"
      },
      {
        "start": 1047.66,
        "duration": 4.77,
        "text": "hear once you've learned the secret to"
      },
      {
        "start": 1049.67,
        "duration": 4.2,
        "text": "managing the complexity of all these"
      },
      {
        "start": 1052.43,
        "duration": 4.41,
        "text": "different tools I want to hear some of"
      },
      {
        "start": 1053.87,
        "duration": 4.47,
        "text": "those secrets so yeah well I've got to"
      },
      {
        "start": 1056.84,
        "duration": 4.05,
        "text": "thank you very much Jeff this has been a"
      },
      {
        "start": 1058.34,
        "duration": 4.98,
        "text": "lot of fun I'm I mean that really is the"
      },
      {
        "start": 1060.89,
        "duration": 4.02,
        "text": "frontier I see as next as we're as we've"
      },
      {
        "start": 1063.32,
        "duration": 2.74,
        "text": "deconstructed this database and we've"
      },
      {
        "start": 1064.91,
        "duration": 3.04,
        "text": "blown everything apart"
      },
      {
        "start": 1066.06,
        "duration": 3.9,
        "text": "now we've got state multiple places and"
      },
      {
        "start": 1067.95,
        "duration": 3.48,
        "text": "projections of our data and lots of"
      },
      {
        "start": 1069.96,
        "duration": 4.71,
        "text": "different processes interacting in"
      },
      {
        "start": 1071.43,
        "duration": 5.85,
        "text": "strange and unexpected ways this is it"
      },
      {
        "start": 1074.67,
        "duration": 3.9,
        "text": "is the Wild West out there and that's of"
      },
      {
        "start": 1077.28,
        "duration": 2.97,
        "text": "course is where I'd like to play and I'm"
      },
      {
        "start": 1078.57,
        "duration": 4.11,
        "text": "I'm thank you for this opportunity to"
      },
      {
        "start": 1080.25,
        "duration": 4.53,
        "text": "talk about that excellence well at this"
      },
      {
        "start": 1082.68,
        "duration": 5.43,
        "text": "point we will ride off into the sunset"
      },
      {
        "start": 1084.78,
        "duration": 4.89,
        "text": "of our wild wild west here and thanks"
      },
      {
        "start": 1088.11,
        "duration": 4.16,
        "text": "for watching this episode of the"
      },
      {
        "start": 1089.67,
        "duration": 4.89,
        "text": "distributed data show see you next time"
      },
      {
        "start": 1092.27,
        "duration": 4.27,
        "text": "thank you for joining us again for the"
      },
      {
        "start": 1094.56,
        "duration": 3.69,
        "text": "distributed data show we love your"
      },
      {
        "start": 1096.54,
        "duration": 3.54,
        "text": "feedback so go to the distributed data"
      },
      {
        "start": 1098.25,
        "duration": 3.66,
        "text": "show page on data stacks Academy and"
      },
      {
        "start": 1100.08,
        "duration": 3.48,
        "text": "tell us what you think you can also find"
      },
      {
        "start": 1101.91,
        "duration": 4.35,
        "text": "us on the data stacks Academy YouTube"
      },
      {
        "start": 1103.56,
        "duration": 4.74,
        "text": "channel or find our podcast on itunes"
      },
      {
        "start": 1106.26,
        "duration": 4.5,
        "text": "google play or wherever you get great"
      },
      {
        "start": 1108.3,
        "duration": 4.17,
        "text": "podcast while you're there make sure and"
      },
      {
        "start": 1110.76,
        "duration": 2.51,
        "text": "subscribe so you don't miss a single"
      },
      {
        "start": 1112.47,
        "duration": 5.74,
        "text": "episode"
      },
      {
        "start": 1113.27,
        "duration": 4.94,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T05:58:22.703188+00:00"
}