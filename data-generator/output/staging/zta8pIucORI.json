{
  "video_id": "zta8pIucORI",
  "title": "DataStax Presents: When Rotten Tomatoes Isn't Enough with Amanda Moran",
  "description": "Getting real-time insights is essential in this fast-paced world - like finding a good movie to catch this weekend. In this talk, we'll use sentiment analysis on Twitter data about the latest movie titles to answer that age old question: \"Is that movie any good?\" We'll show how we built the solution using Apache Cassandra, Apache Spark and DataStax Enterprise Analytics. This is a great talk to attend if you are new to the big data space, want to learn more about Cassandra and Spark, or just want to see a demo of DataStax latest product.\n\nABOUT DATASTAX ENTERPRISE 6\nDataStax  powers  the  Right-Now  Enterprise  with  the  always-on,  distributed  cloud  database  built  on  Apache  Cassandra™  and designed for hybrid cloud. DataStax Enterprise 6 (DSE 6) includes industry-leading performance, self-driving operational simplicity, and robust analytics.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://www.datastax.com/products/datastax-enterprise-6\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax | https://twitter.com/datastax-academy\nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax Enterprise©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2018-10-31T13:00:30Z",
  "thumbnail": "https://i.ytimg.com/vi/zta8pIucORI/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "performance",
    "talk",
    "demo",
    "dse",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=zta8pIucORI",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "thank you very much so yeah so this is my talk when Rotten Tomatoes isn't enough so we're gonna be analyzing Twitter movie reviews with data stacks enterprise so let's talk about what we're actually going to talk about what problem are we really trying to solve here so what we're gonna do is an enterprise introduction to Apache Cassandra what it is why do I need it a very quick introduction to Apache spark what it is why do I need it I have a strong feeling that this group is very familiar with these things but we're just gonna do a really light touch on both of these items and then we're gonna go into a live demo so and then we're gonna talk about what is cinnamon analysis because we're gonna do a little bit of data science here we're gonna do an overview of the demo I'm gonna do and then we're gonna do an actual live demo all right so you already heard enough about me but this is a little bit about me it's pretty much the same thing okay so what problem are we really trying to solve here we're trying to solve what movie should I see so wouldn't it be great if I could ask a million people this question wouldn't it be even greater if I could automate this process so basically data analytics and data science doesn't have to be complicated so we're gonna utilize the power of Big Data using Apache Cassandra Apache spark the spark machine learning libraries Jupiter notebooks Python PI spark which I didn't mention here Twitter tweets in the Twitter dev API and we're gonna use pattern which is actually a Python package for sentiment analysis okay so we're gonna do the world's briefest introduction to Apache Cassandra alright what is actually is it and this group again Apache Cassandra has been around for 10 years so this group is probably pretty familiar with what it actually is but let's just do a high-level for people who aren't familiar with it it was developed by Facebook again about 10 years ago it became a top-level Apache project in 2010 so here's the key it is a distributed decentralized database these are the keywords that you need to keep remembering it's a lab simply scaleable you can add and remove nodes with no downtime it has very high performance it's very fast it has high availability and fault tolerance there is no single point of failure we're gonna talk a little bit about that here in the next couple of slides it solves many of the problems that you might face with a traditional database for certain workloads all right so I work for data data stacks so I just want to do a quick just a little plug for Deus Ex Enterprise basically they have a lot of the key contributors to the Apache Cassandra project and it's the commercial product around a Apache Cassandra has a lot of cool features more QA and more support and actually the demo that I'm going to do for you is actually just a one node data sex Enterprise analytics node just here on my laptop alright so what does this all mean so let's talk about four big topics we're gonna talk about distributed replication elastically scalable and high availability now like I said before this is a super brief intro so for more information we actually have it's called theta sex Academy it's actually totally free courses on all these things I'm going to talk about and way more so if you're interested in any of things I'm talking about check this out it's totally free alright so distributed every node in the cluster has exactly the same role and I put here really because sometimes you kind of hear about these things and you're not sure if they're actually true but this is actually true Cassandra does not have a master worker architecture so every client can connect to any node because every node is exactly the same all nodes are available for reads and writes and they're all ready but this is not to say that all nodes have all of the same data that's not very scalable alright so replication here we are we're talking about the data and where it resides so to be able to survive a node going down data must be copied to other nodes so if any of you I mean we're all big data people you're all familiar with HDFS you're all familiar with these types of things so replications back are something you're very used to but this is something that's set by the user so Cassandra you can set this anywhere from just one I just have one replica of my data up to the number of nodes that you have in your cluster which is not actually recommended but you could do it if you want to normally the recommendation around replication is 3 so the data is asynchronously replicated automatically so there's peer-to-peer communication alright so elastically scalable so the more nodes that are added the performance actually increases linearly which is important because not only can you add the notes but you're getting you're getting that increased performance so you can scale up and scale down with no time downtime you don't even need a restart to add notes and the reason writes both scale alright so high availability this is kind of one of the key points besides the distributed decentralized database but the lack of the master node allows for high availability because there is no single point of failure so replication allows the nodes to fail and data to still be available so cassandra expects nodes to fail that's what it was built for it has this already built in it knows what's gonna happen and it doesn't panic when it does happen so and also has multiple data center support right out of the box you can just have a US data center and a Europe data center very easily it just has to be configured in a gamma file alright so one small trade-off because I've been talking about all the amazing things of Cassandra and I know sometimes people get up here and they want to talk about their product and how amazing it is and how magical but we do have one small trade off and it is very small but I want to bring it up especially for a tech crowd and this is all revolved around the cap theorem which is if you don't know about it you should google it it's actually very interesting but it's about availability consistency and partition tolerance and a network so basically a database cannot have all of these it's impossible you can't have all three and you can see in this chart here so what Cassandra decides to do is it wants to be highly available and so because of that it chooses that it's going to have eventual consistency so that's the default but you can prioritize your consistency of your data over availability so these are all configurable things it's just really about what's important to you think about whether you have data that's important to you or data that maybe is not as important like likes on a Twitter tweet so the guy said the consistency levels are configurable so you can have and here's another easy equation is that the right consistency plus abrecan Sisseton see as long as it's greater than your replication factor you have you have strong consistency okay so why would I need Apache Cassandra so basically in this group I think you pretty much have really good understanding of this but if you have a big data do you need to be able to read and write fast do you need to be able to scale up and scale down easily do you have do you need high availability which you probably do do you need multiple data center support for your application do you have you need multi cloud or hybrid cloud support if you need any things you probably need Cassandra alright now this is the world's quickest introduction to Apache spark okay so what is Apache spark Apache spark is a unified analytics engine for large-scale data processing so I'm just gonna highlight this term right here analytics engine it's gonna help us do our analytics especially here in this demo so it's a hundred times faster than Hadoop and it utilizes in-memory processing and amazing parallelism to actually get that and so we're gonna be talking about it had quite a few things that spark heads but we're gonna be talking about the machine learning libraries okay so why would you need spark again this is a super quick light intro to spark if you have big data do you need high availability do you need analytics at lightning speed and if you need insights into your data you might want to consider using spark okay so now we're gonna start talking about kind of the overarching thing of this talk which is the Twitter movie reviews so what is sentiment analysis what are we in trying to do here with data science okay so at a very high level now you could talk about sentiment analysis probably could have whole courses on it but for this case we're just gonna talk at a very high level and it's very simple it's basically natural language processing and text analytics determine if a word in a sent or sentence is positive negative or neutral so this is very easy for us to understand at a high level but it's very difficult for machines to learn how to do but also think about us in this day and age with text messages think how difficult it is even when like somebody sends you like a text message and they say hi and they put a period right you have to figure out what that person means are they happy or they neutral are they sad so even for us it's getting more difficult to understand what people actually mean with what they type so imagine for a machine to try to figure that out okay so let's do an overview of the demo alrighty so what we're going to do is I have a local data Stax enterprise and it's set up here on my laptop it's just a one node cluster cluster I have a local Jupiter notebook set up here on my laptop so we're gonna pull Twitter data on a movie title so in this particular instance we're gonna use Mission Impossible we're gonna clean up the tweets we're gonna insert that data into Cassandra and we're gonna create a spark data frame from that because DSC analytics which I didn't really talk about here but it has that all integrated right in the box and you'll see how easy it is for us to move from Cassandra to spark we're gonna use spark machine learning libraries we're gonna do cinnamon analysis with pattern which is a Python package and it's gonna give us the positive or negative we're gonna take an average of all the scores and then we're gonna decide should I actually see this movie or not okay so let's get to the demo all right so it's a jupiter notebook so make it a little bit difficult to see in the back but i do have this on my github and anybody's read downloaded so let's just start walking through this jupiter notebook so i have again if you wanted to download this from my github i have all the steps on what you would need to do to actually get it set up and just running on your laptop so we won't walk over the through those it's not that interesting but it looks like it's a lot of steps but it's actually the complete amount of steps it probably would only take you 20 minutes to get this all set up and running these are just some environment variables that you need you import some packages in python this is just a helper nice function to do some like nice formatting pretty printing per spark data frames alright so now let's get to data stack enterprise analytics so we're gonna create the table we're gonna pull the tweets and we're gonna load the table so we're using the Python data sacks Python cassandra driver and so here this is all we need to do to actually connect to our cluster and like I said it's a one-note cluster just running here in my laptop so I'm just connecting to localhost here I get my cluster object and I'm able to create a session just that easily from there we're actually gonna create a key space now a key space and Cassandra is similar to if you're familiar with Oracle it's like a bit of a schema or if your terror data is like a database and so we're going set that up we're gonna use a simple strategy and we're gonna use our replication factor which I talked about before we're just gonna set that to one because there's no point in replicating my data because I only have one note and next we're gonna actually just set our key space and now we're gonna set up our movie title so in this case we're gonna search on Mission Impossible and we're gonna search we're gonna search for positive tweets and negative tweets so we're gonna create two tables and Cassandra for this movie title one for the path ative and one for the negative so Twitter actually the Twitter dev API if any familiar with it it's actually really awesome you can get a ton of real time information about basically anything you want to search for see it actually gives you a ton of information way more than we need for just the sake of this demo so we're just gonna utilize the Twitter ID as our primary key to what actually we want to partition our data by because it's unique and then we're gonna get the actual tweet so just a little note here you may want to think about when you're actually distributing your data at scale with Cassandra if that primary key of your Twitter ID is really the right thing to partition by in this case because I just have one note it doesn't really matter but it is something to consider like for your data model when you're choosing your primary key so we're gonna create both of those tables so from there we're gonna actually set up our search terms for gathering tweets from the Twitter API so what's really cool about Twitter and their API is what I noticed when I was working on this demo is they actually do a first pass of cinnamon analysis on the Twitter tweets and you can actually search that literally by a happy face or a sad face and they look it's actually true and they will give you back either positive tweets or negative tweets um and we'll see as we go through this actually their their first pass at it with the positive tweets is it's spot on you almost always get positive tweets for some reason whatever algorithm that they're using for the negative tweets you don't always get negative us I'm not quite sure why I've been playing with it now for a couple weeks it doesn't really seem to work but the positive seems to be spot-on but we'll see more about that as we walk through this alright so now I'm gonna have another function here that's actually gonna clean up the tweets we're gonna remove the oh geez flags special characters URLs and we're gonna move our tea because when you pull in the Twitter data and actually for retweets it just puts its RT in there I just removed it just to make it a little easier for the sentiment analysis functions just in case so wouldn't get confused and actually would be pretty great if we can do sentiment analysis around emojis because a lot of emotion comes through with those emojis but in this case we just we just removed them already so then to be able to use Twitter and their API you have to set up some keys and things like that and they walk you through it all in their their URLs and their links so I got that all set up here alright so this so we're actually gonna pull the tweets from Twitter so the maximum number of tweets you can pull it any one time for free is only 100 so you can actually run this code a couple times to pull more and more so once the tweets are collected let's loop over the list clean up the tweets and then insert them into the table so we have a large for loop around here that surrounds this to make one call for the positive and one for the negative and then we also have two URL encode our happy base in our side base so that's what this is doing here and because this is a very techy crowd you'll notice I have a comment here I actually have a comment on the actual insert we're not actually not gonna insert this because I already found some really great data that I want to show you so even though if we could we could pull it live we're not inserting it into the table so let's so we're seeing actually some of the tweets that got pulled live just when I ran this just a little bit ago and these are all about mission impossible so then we can do a select star on the table and verified that the tweets were actually inserted into our Cassandra table and so we can see here that they were alright so now we're starting to get to some analytics with Apache spark so now it's actually time for that so let's so what we're gonna do in this one line of code here is we're able to take our Apache Cassandra table and load it into a spark data frame and so we're gonna create two spark data frames one for positive tweets and one for negative tweets and just this one line of code right here will move all the data from Cassandra into spark no really I think again this is all just around one node but imagine this head scale right and how easy that was to do and then we're just gonna take a count of how many rows I got for each so it looks like I had 50 tweets for the positive and 75 for the negative so now we're gonna actually use those machine learning libraries to break up the sentences into actual words so we're gonna use the spark tokenizer and it's gonna cut up these sentence into individual words and we're gonna do that for the positive and for the negative and you can see we just print out the data frame here it shows the tweet when it's cut up into words and then how many words were in each tweet all right so then the next thing that we're gonna do so we're actually gonna remove all the stop words anything that has like if you're familiar with of a the none of that's actually important to the sentiment so we're actually gonna strip those out and so we're using again the spark machine learning library stop words remover and we're gonna do that again for the positive and for the negative and so we can already start seeing some interesting things here we see the number of tokens that are originally so number of words in each sentence and then once we remove the stop words how many words we have left alright so now let's actually get to our sentiment analysis so we're gonna convert each spark data frame to a panda's data frame now I just want to let everyone know that this works as is because I'm working on my laptop anyone who's familiar with spark and data science and Big Data knows that pandas just runs locally wherever you're running it from be it your laptop or a server so to just move from one to the other you have to make sure that when you're moving from one to the other that you have the memory to actually do that so again it just works because it's here my laptop but it's something to consider so then we're gonna loop throat each of the rows and we're actually gonna give a sentiment score and we're gonna get on each tweet we're gonna get whether it's positive so it's like a positive number or it's negative which means it's a negative sentiment or we'll get a zero zero can mean neutral or zero can mean I don't have enough information to score this I really don't know what it means so then we're actually gonna have the assessment function which is part of the pattern package and it's gonna show whether the word that what words that we use to judge whether this was positive or negative so this here's the Python code here for this so okay so these are some of the tweets that we've gotten so here's an example I want to watch Mission Impossible has anyone watched it yet and then a sad safe so it's not really a movie review but it is a real-time tweet that I just pulled not too long ago and so this I in this case it got scored to the zero point three so kind of a negative sentiment alright so we have our here's our nice data frame here print it out we have our original tweet the score whether it's positive or negative and why we decided that score that we did so the assessment so straight away we're seeing something interesting here on our assessment we're seeing the word impossible so we'll come back to that here in a bit so let's do the same thing with our positive tweets and actually and another thing I forgot to mention is as we go through we're actually taking an average of the scores so that we can kind of make a rough estimate of whether we should see this movie or not so here's like Mission Impossible fall is great so we got a 0.8 so that's a very positive feeling about that and we can see straight away in our assessment that it gave the word great and it said okay that's why I'm gonna weigh it so highly on the positive because great is such a positive word alrighty so we're finally to the end here should I see this movie so basically how I'm saying in just my demo here is if the average of all the positive scores is greater than the average of the negative scores I'm saying hey go out there go see this movie people like it worth they're equal I'm saying hey go take a chance people are split and if the positive rating is actually less than a negative rating I'm saying people don't like this movie alrighty so our final positive rating score is 0.2 not that positive our negative score is actually negative 0.4 so we're saying people don't like this movie so is this the answer that you were expecting so when we look at Rotten Tomatoes for our mission impossible' has a super high score so maybe we need to either way we really need to go back and take a look at our data we need it data science is an iterative process so let's kind of scroll back up here to those negative reviews that we saw what do we keep seeing over and over again in our assessments the word impossible now because mission impossible is in the movie title maybe I should have removed that when I was removing my stop words right because the movie title doesn't have any weight on the actual assessment it's just it's just there it's the movie title so because we had that word impossible it feels like it's really negative so if I had removed that then we could probably get something much higher for the positive and the negative because it wouldn't have those negative words so here's just some important links so that you could learn more about Cassandra and spark and data stacks you can also follow me on Twitter and our team is just recently we're getting involved with live demos on Twitch so feel free to check that out like I said this is on github and definitely check out the data stacks Academy because all this information is totally free [Applause]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.95,
        "text": "thank you very much so yeah so this is"
      },
      {
        "start": 2.25,
        "duration": 4.379,
        "text": "my talk when Rotten Tomatoes isn't"
      },
      {
        "start": 4.98,
        "duration": 3.63,
        "text": "enough so we're gonna be analyzing"
      },
      {
        "start": 6.629,
        "duration": 4.081,
        "text": "Twitter movie reviews with data stacks"
      },
      {
        "start": 8.61,
        "duration": 3.149,
        "text": "enterprise so let's talk about what"
      },
      {
        "start": 10.71,
        "duration": 2.61,
        "text": "we're actually going to talk about what"
      },
      {
        "start": 11.759,
        "duration": 3.391,
        "text": "problem are we really trying to solve"
      },
      {
        "start": 13.32,
        "duration": 3.33,
        "text": "here so what we're gonna do is an"
      },
      {
        "start": 15.15,
        "duration": 4.56,
        "text": "enterprise introduction to Apache"
      },
      {
        "start": 16.65,
        "duration": 5.52,
        "text": "Cassandra what it is why do I need it a"
      },
      {
        "start": 19.71,
        "duration": 5.37,
        "text": "very quick introduction to Apache spark"
      },
      {
        "start": 22.17,
        "duration": 4.83,
        "text": "what it is why do I need it I have a"
      },
      {
        "start": 25.08,
        "duration": 3.33,
        "text": "strong feeling that this group is very"
      },
      {
        "start": 27.0,
        "duration": 2.91,
        "text": "familiar with these things but we're"
      },
      {
        "start": 28.41,
        "duration": 3.06,
        "text": "just gonna do a really light touch on"
      },
      {
        "start": 29.91,
        "duration": 5.19,
        "text": "both of these items and then we're gonna"
      },
      {
        "start": 31.47,
        "duration": 4.769,
        "text": "go into a live demo so and then we're"
      },
      {
        "start": 35.1,
        "duration": 2.43,
        "text": "gonna talk about what is cinnamon"
      },
      {
        "start": 36.239,
        "duration": 3.421,
        "text": "analysis because we're gonna do a little"
      },
      {
        "start": 37.53,
        "duration": 3.779,
        "text": "bit of data science here we're gonna do"
      },
      {
        "start": 39.66,
        "duration": 3.149,
        "text": "an overview of the demo I'm gonna do and"
      },
      {
        "start": 41.309,
        "duration": 3.511,
        "text": "then we're gonna do an actual live demo"
      },
      {
        "start": 42.809,
        "duration": 3.871,
        "text": "all right so you already heard enough"
      },
      {
        "start": 44.82,
        "duration": 4.2,
        "text": "about me but this is a little bit about"
      },
      {
        "start": 46.68,
        "duration": 4.5,
        "text": "me it's pretty much the same thing okay"
      },
      {
        "start": 49.02,
        "duration": 4.74,
        "text": "so what problem are we really trying to"
      },
      {
        "start": 51.18,
        "duration": 4.74,
        "text": "solve here we're trying to solve what"
      },
      {
        "start": 53.76,
        "duration": 4.319,
        "text": "movie should I see so wouldn't it be"
      },
      {
        "start": 55.92,
        "duration": 4.17,
        "text": "great if I could ask a million people"
      },
      {
        "start": 58.079,
        "duration": 4.341,
        "text": "this question wouldn't it be even"
      },
      {
        "start": 60.09,
        "duration": 4.889,
        "text": "greater if I could automate this process"
      },
      {
        "start": 62.42,
        "duration": 4.12,
        "text": "so basically data analytics and data"
      },
      {
        "start": 64.979,
        "duration": 3.991,
        "text": "science doesn't have to be complicated"
      },
      {
        "start": 66.54,
        "duration": 5.759,
        "text": "so we're gonna utilize the power of Big"
      },
      {
        "start": 68.97,
        "duration": 5.79,
        "text": "Data using Apache Cassandra Apache spark"
      },
      {
        "start": 72.299,
        "duration": 5.491,
        "text": "the spark machine learning libraries"
      },
      {
        "start": 74.76,
        "duration": 4.859,
        "text": "Jupiter notebooks Python PI spark which"
      },
      {
        "start": 77.79,
        "duration": 3.99,
        "text": "I didn't mention here Twitter tweets in"
      },
      {
        "start": 79.619,
        "duration": 3.811,
        "text": "the Twitter dev API and we're gonna use"
      },
      {
        "start": 81.78,
        "duration": 4.47,
        "text": "pattern which is actually a Python"
      },
      {
        "start": 83.43,
        "duration": 4.35,
        "text": "package for sentiment analysis okay so"
      },
      {
        "start": 86.25,
        "duration": 3.75,
        "text": "we're gonna do the world's briefest"
      },
      {
        "start": 87.78,
        "duration": 4.35,
        "text": "introduction to Apache Cassandra alright"
      },
      {
        "start": 90.0,
        "duration": 3.96,
        "text": "what is actually is it and this group"
      },
      {
        "start": 92.13,
        "duration": 3.54,
        "text": "again Apache Cassandra has been around"
      },
      {
        "start": 93.96,
        "duration": 3.69,
        "text": "for 10 years so this group is probably"
      },
      {
        "start": 95.67,
        "duration": 3.33,
        "text": "pretty familiar with what it actually is"
      },
      {
        "start": 97.65,
        "duration": 3.329,
        "text": "but let's just do a high-level for"
      },
      {
        "start": 99.0,
        "duration": 4.02,
        "text": "people who aren't familiar with it it"
      },
      {
        "start": 100.979,
        "duration": 4.411,
        "text": "was developed by Facebook again about 10"
      },
      {
        "start": 103.02,
        "duration": 6.779,
        "text": "years ago it became a top-level Apache"
      },
      {
        "start": 105.39,
        "duration": 7.229,
        "text": "project in 2010 so here's the key it is"
      },
      {
        "start": 109.799,
        "duration": 4.441,
        "text": "a distributed decentralized database"
      },
      {
        "start": 112.619,
        "duration": 4.021,
        "text": "these are the keywords that you need to"
      },
      {
        "start": 114.24,
        "duration": 4.35,
        "text": "keep remembering it's a lab simply"
      },
      {
        "start": 116.64,
        "duration": 4.979,
        "text": "scaleable you can add and remove nodes"
      },
      {
        "start": 118.59,
        "duration": 5.819,
        "text": "with no downtime it has very high"
      },
      {
        "start": 121.619,
        "duration": 5.1,
        "text": "performance it's very fast it has high"
      },
      {
        "start": 124.409,
        "duration": 3.6,
        "text": "availability and fault tolerance there"
      },
      {
        "start": 126.719,
        "duration": 2.52,
        "text": "is no single point of failure we're"
      },
      {
        "start": 128.009,
        "duration": 3.56,
        "text": "gonna talk a little bit about that here"
      },
      {
        "start": 129.239,
        "duration": 3.741,
        "text": "in the next couple of slides"
      },
      {
        "start": 131.569,
        "duration": 2.73,
        "text": "it solves many of the problems that you"
      },
      {
        "start": 132.98,
        "duration": 4.14,
        "text": "might face with a traditional database"
      },
      {
        "start": 134.299,
        "duration": 5.64,
        "text": "for certain workloads all right so I"
      },
      {
        "start": 137.12,
        "duration": 4.41,
        "text": "work for data data stacks so I just want"
      },
      {
        "start": 139.939,
        "duration": 3.69,
        "text": "to do a quick just a little plug for"
      },
      {
        "start": 141.53,
        "duration": 3.929,
        "text": "Deus Ex Enterprise basically they have a"
      },
      {
        "start": 143.629,
        "duration": 4.23,
        "text": "lot of the key contributors to the"
      },
      {
        "start": 145.459,
        "duration": 5.071,
        "text": "Apache Cassandra project and it's the"
      },
      {
        "start": 147.859,
        "duration": 5.041,
        "text": "commercial product around a Apache"
      },
      {
        "start": 150.53,
        "duration": 4.65,
        "text": "Cassandra has a lot of cool features"
      },
      {
        "start": 152.9,
        "duration": 3.869,
        "text": "more QA and more support and actually"
      },
      {
        "start": 155.18,
        "duration": 4.11,
        "text": "the demo that I'm going to do for you is"
      },
      {
        "start": 156.769,
        "duration": 4.62,
        "text": "actually just a one node data sex"
      },
      {
        "start": 159.29,
        "duration": 4.71,
        "text": "Enterprise analytics node just here on"
      },
      {
        "start": 161.389,
        "duration": 5.311,
        "text": "my laptop alright so what does this all"
      },
      {
        "start": 164.0,
        "duration": 4.459,
        "text": "mean so let's talk about four big topics"
      },
      {
        "start": 166.7,
        "duration": 4.319,
        "text": "we're gonna talk about distributed"
      },
      {
        "start": 168.459,
        "duration": 5.081,
        "text": "replication elastically scalable and"
      },
      {
        "start": 171.019,
        "duration": 6.0,
        "text": "high availability now like I said before"
      },
      {
        "start": 173.54,
        "duration": 5.25,
        "text": "this is a super brief intro so for more"
      },
      {
        "start": 177.019,
        "duration": 4.291,
        "text": "information we actually have it's called"
      },
      {
        "start": 178.79,
        "duration": 4.44,
        "text": "theta sex Academy it's actually totally"
      },
      {
        "start": 181.31,
        "duration": 4.139,
        "text": "free courses on all these things I'm"
      },
      {
        "start": 183.23,
        "duration": 3.479,
        "text": "going to talk about and way more so if"
      },
      {
        "start": 185.449,
        "duration": 2.46,
        "text": "you're interested in any of things I'm"
      },
      {
        "start": 186.709,
        "duration": 1.95,
        "text": "talking about check this out it's"
      },
      {
        "start": 187.909,
        "duration": 3.901,
        "text": "totally free"
      },
      {
        "start": 188.659,
        "duration": 6.54,
        "text": "alright so distributed every node in the"
      },
      {
        "start": 191.81,
        "duration": 5.97,
        "text": "cluster has exactly the same role and I"
      },
      {
        "start": 195.199,
        "duration": 4.081,
        "text": "put here really because sometimes you"
      },
      {
        "start": 197.78,
        "duration": 2.76,
        "text": "kind of hear about these things and"
      },
      {
        "start": 199.28,
        "duration": 2.28,
        "text": "you're not sure if they're actually true"
      },
      {
        "start": 200.54,
        "duration": 3.449,
        "text": "but this is actually true"
      },
      {
        "start": 201.56,
        "duration": 5.91,
        "text": "Cassandra does not have a master worker"
      },
      {
        "start": 203.989,
        "duration": 5.25,
        "text": "architecture so every client can connect"
      },
      {
        "start": 207.47,
        "duration": 4.53,
        "text": "to any node because every node is"
      },
      {
        "start": 209.239,
        "duration": 3.9,
        "text": "exactly the same all nodes are available"
      },
      {
        "start": 212.0,
        "duration": 3.9,
        "text": "for reads and writes and they're all"
      },
      {
        "start": 213.139,
        "duration": 5.09,
        "text": "ready but this is not to say that all"
      },
      {
        "start": 215.9,
        "duration": 5.25,
        "text": "nodes have all of the same data"
      },
      {
        "start": 218.229,
        "duration": 4.301,
        "text": "that's not very scalable alright so"
      },
      {
        "start": 221.15,
        "duration": 3.209,
        "text": "replication here we are we're talking"
      },
      {
        "start": 222.53,
        "duration": 3.78,
        "text": "about the data and where it resides so"
      },
      {
        "start": 224.359,
        "duration": 5.701,
        "text": "to be able to survive a node going down"
      },
      {
        "start": 226.31,
        "duration": 5.039,
        "text": "data must be copied to other nodes so if"
      },
      {
        "start": 230.06,
        "duration": 2.879,
        "text": "any of you I mean we're all big data"
      },
      {
        "start": 231.349,
        "duration": 2.85,
        "text": "people you're all familiar with HDFS"
      },
      {
        "start": 232.939,
        "duration": 2.88,
        "text": "you're all familiar with these types of"
      },
      {
        "start": 234.199,
        "duration": 4.02,
        "text": "things so replications back are"
      },
      {
        "start": 235.819,
        "duration": 4.32,
        "text": "something you're very used to but this"
      },
      {
        "start": 238.219,
        "duration": 3.45,
        "text": "is something that's set by the user so"
      },
      {
        "start": 240.139,
        "duration": 3.33,
        "text": "Cassandra you can set this anywhere from"
      },
      {
        "start": 241.669,
        "duration": 4.32,
        "text": "just one I just have one replica of my"
      },
      {
        "start": 243.469,
        "duration": 4.35,
        "text": "data up to the number of nodes that you"
      },
      {
        "start": 245.989,
        "duration": 3.18,
        "text": "have in your cluster which is not"
      },
      {
        "start": 247.819,
        "duration": 3.181,
        "text": "actually recommended but you could do it"
      },
      {
        "start": 249.169,
        "duration": 4.47,
        "text": "if you want to normally the"
      },
      {
        "start": 251.0,
        "duration": 6.079,
        "text": "recommendation around replication is 3"
      },
      {
        "start": 253.639,
        "duration": 5.13,
        "text": "so the data is asynchronously replicated"
      },
      {
        "start": 257.079,
        "duration": 4.301,
        "text": "automatically so there's peer-to-peer"
      },
      {
        "start": 258.769,
        "duration": 4.501,
        "text": "communication alright so elastically"
      },
      {
        "start": 261.38,
        "duration": 3.63,
        "text": "scalable so the more nodes that are"
      },
      {
        "start": 263.27,
        "duration": 3.78,
        "text": "added the performance actually"
      },
      {
        "start": 265.01,
        "duration": 3.45,
        "text": "increases linearly which is important"
      },
      {
        "start": 267.05,
        "duration": 3.54,
        "text": "because not only can you add the notes"
      },
      {
        "start": 268.46,
        "duration": 4.47,
        "text": "but you're getting you're getting that"
      },
      {
        "start": 270.59,
        "duration": 4.92,
        "text": "increased performance so you can scale"
      },
      {
        "start": 272.93,
        "duration": 4.41,
        "text": "up and scale down with no time downtime"
      },
      {
        "start": 275.51,
        "duration": 5.1,
        "text": "you don't even need a restart to add"
      },
      {
        "start": 277.34,
        "duration": 5.79,
        "text": "notes and the reason writes both scale"
      },
      {
        "start": 280.61,
        "duration": 3.93,
        "text": "alright so high availability this is"
      },
      {
        "start": 283.13,
        "duration": 3.24,
        "text": "kind of one of the key points besides"
      },
      {
        "start": 284.54,
        "duration": 4.77,
        "text": "the distributed decentralized database"
      },
      {
        "start": 286.37,
        "duration": 4.86,
        "text": "but the lack of the master node allows"
      },
      {
        "start": 289.31,
        "duration": 3.87,
        "text": "for high availability because there is"
      },
      {
        "start": 291.23,
        "duration": 4.44,
        "text": "no single point of failure so"
      },
      {
        "start": 293.18,
        "duration": 5.81,
        "text": "replication allows the nodes to fail and"
      },
      {
        "start": 295.67,
        "duration": 6.15,
        "text": "data to still be available so cassandra"
      },
      {
        "start": 298.99,
        "duration": 4.9,
        "text": "expects nodes to fail that's what it was"
      },
      {
        "start": 301.82,
        "duration": 3.51,
        "text": "built for it has this already built in"
      },
      {
        "start": 303.89,
        "duration": 4.68,
        "text": "it knows what's gonna happen and it"
      },
      {
        "start": 305.33,
        "duration": 5.04,
        "text": "doesn't panic when it does happen so and"
      },
      {
        "start": 308.57,
        "duration": 3.84,
        "text": "also has multiple data center support"
      },
      {
        "start": 310.37,
        "duration": 3.96,
        "text": "right out of the box you can just have a"
      },
      {
        "start": 312.41,
        "duration": 4.47,
        "text": "US data center and a Europe data center"
      },
      {
        "start": 314.33,
        "duration": 4.92,
        "text": "very easily it just has to be configured"
      },
      {
        "start": 316.88,
        "duration": 3.33,
        "text": "in a gamma file alright so one small"
      },
      {
        "start": 319.25,
        "duration": 2.52,
        "text": "trade-off because I've been talking"
      },
      {
        "start": 320.21,
        "duration": 3.87,
        "text": "about all the amazing things of"
      },
      {
        "start": 321.77,
        "duration": 3.36,
        "text": "Cassandra and I know sometimes people"
      },
      {
        "start": 324.08,
        "duration": 2.37,
        "text": "get up here and they want to talk about"
      },
      {
        "start": 325.13,
        "duration": 3.36,
        "text": "their product and how amazing it is and"
      },
      {
        "start": 326.45,
        "duration": 3.63,
        "text": "how magical but we do have one small"
      },
      {
        "start": 328.49,
        "duration": 2.79,
        "text": "trade off and it is very small but I"
      },
      {
        "start": 330.08,
        "duration": 4.14,
        "text": "want to bring it up especially for a"
      },
      {
        "start": 331.28,
        "duration": 5.52,
        "text": "tech crowd and this is all revolved"
      },
      {
        "start": 334.22,
        "duration": 4.5,
        "text": "around the cap theorem which is if you"
      },
      {
        "start": 336.8,
        "duration": 3.3,
        "text": "don't know about it you should google it"
      },
      {
        "start": 338.72,
        "duration": 3.57,
        "text": "it's actually very interesting but it's"
      },
      {
        "start": 340.1,
        "duration": 4.98,
        "text": "about availability consistency and"
      },
      {
        "start": 342.29,
        "duration": 4.86,
        "text": "partition tolerance and a network so"
      },
      {
        "start": 345.08,
        "duration": 3.63,
        "text": "basically a database cannot have all of"
      },
      {
        "start": 347.15,
        "duration": 3.06,
        "text": "these it's impossible you can't have all"
      },
      {
        "start": 348.71,
        "duration": 4.08,
        "text": "three and you can see in this chart here"
      },
      {
        "start": 350.21,
        "duration": 4.8,
        "text": "so what Cassandra decides to do is it"
      },
      {
        "start": 352.79,
        "duration": 4.23,
        "text": "wants to be highly available and so"
      },
      {
        "start": 355.01,
        "duration": 4.14,
        "text": "because of that it chooses that it's"
      },
      {
        "start": 357.02,
        "duration": 4.5,
        "text": "going to have eventual consistency so"
      },
      {
        "start": 359.15,
        "duration": 4.35,
        "text": "that's the default but you can"
      },
      {
        "start": 361.52,
        "duration": 4.89,
        "text": "prioritize your consistency of your data"
      },
      {
        "start": 363.5,
        "duration": 4.68,
        "text": "over availability so these are all"
      },
      {
        "start": 366.41,
        "duration": 3.87,
        "text": "configurable things it's just really"
      },
      {
        "start": 368.18,
        "duration": 4.95,
        "text": "about what's important to you think"
      },
      {
        "start": 370.28,
        "duration": 4.71,
        "text": "about whether you have data that's"
      },
      {
        "start": 373.13,
        "duration": 3.75,
        "text": "important to you or data that maybe is"
      },
      {
        "start": 374.99,
        "duration": 4.56,
        "text": "not as important like likes on a Twitter"
      },
      {
        "start": 376.88,
        "duration": 4.86,
        "text": "tweet so the guy said the consistency"
      },
      {
        "start": 379.55,
        "duration": 5.94,
        "text": "levels are configurable so you can have"
      },
      {
        "start": 381.74,
        "duration": 5.49,
        "text": "and here's another easy equation is that"
      },
      {
        "start": 385.49,
        "duration": 3.18,
        "text": "the right consistency plus abrecan"
      },
      {
        "start": 387.23,
        "duration": 3.63,
        "text": "Sisseton see as long as it's greater"
      },
      {
        "start": 388.67,
        "duration": 5.25,
        "text": "than your replication factor you have"
      },
      {
        "start": 390.86,
        "duration": 4.5,
        "text": "you have strong consistency okay so why"
      },
      {
        "start": 393.92,
        "duration": 3.9,
        "text": "would I need Apache Cassandra"
      },
      {
        "start": 395.36,
        "duration": 3.15,
        "text": "so basically in this group I think you"
      },
      {
        "start": 397.82,
        "duration": 2.31,
        "text": "pretty much have"
      },
      {
        "start": 398.51,
        "duration": 3.9,
        "text": "really good understanding of this but if"
      },
      {
        "start": 400.13,
        "duration": 4.26,
        "text": "you have a big data do you need to be"
      },
      {
        "start": 402.41,
        "duration": 3.66,
        "text": "able to read and write fast do you need"
      },
      {
        "start": 404.39,
        "duration": 4.59,
        "text": "to be able to scale up and scale down"
      },
      {
        "start": 406.07,
        "duration": 4.98,
        "text": "easily do you have do you need high"
      },
      {
        "start": 408.98,
        "duration": 3.81,
        "text": "availability which you probably do do"
      },
      {
        "start": 411.05,
        "duration": 4.29,
        "text": "you need multiple data center support"
      },
      {
        "start": 412.79,
        "duration": 4.38,
        "text": "for your application do you have you"
      },
      {
        "start": 415.34,
        "duration": 4.41,
        "text": "need multi cloud or hybrid cloud support"
      },
      {
        "start": 417.17,
        "duration": 4.59,
        "text": "if you need any things you probably need"
      },
      {
        "start": 419.75,
        "duration": 3.93,
        "text": "Cassandra alright now this is the"
      },
      {
        "start": 421.76,
        "duration": 4.17,
        "text": "world's quickest introduction to Apache"
      },
      {
        "start": 423.68,
        "duration": 4.26,
        "text": "spark okay so what is Apache spark"
      },
      {
        "start": 425.93,
        "duration": 3.93,
        "text": "Apache spark is a unified analytics"
      },
      {
        "start": 427.94,
        "duration": 3.45,
        "text": "engine for large-scale data processing"
      },
      {
        "start": 429.86,
        "duration": 3.42,
        "text": "so I'm just gonna highlight this term"
      },
      {
        "start": 431.39,
        "duration": 3.48,
        "text": "right here analytics engine it's gonna"
      },
      {
        "start": 433.28,
        "duration": 3.72,
        "text": "help us do our analytics especially here"
      },
      {
        "start": 434.87,
        "duration": 4.17,
        "text": "in this demo so it's a hundred times"
      },
      {
        "start": 437.0,
        "duration": 3.93,
        "text": "faster than Hadoop and it utilizes"
      },
      {
        "start": 439.04,
        "duration": 3.75,
        "text": "in-memory processing and amazing"
      },
      {
        "start": 440.93,
        "duration": 3.42,
        "text": "parallelism to actually get that and so"
      },
      {
        "start": 442.79,
        "duration": 4.05,
        "text": "we're gonna be talking about it had"
      },
      {
        "start": 444.35,
        "duration": 3.57,
        "text": "quite a few things that spark heads but"
      },
      {
        "start": 446.84,
        "duration": 2.7,
        "text": "we're gonna be talking about the machine"
      },
      {
        "start": 447.92,
        "duration": 3.78,
        "text": "learning libraries okay"
      },
      {
        "start": 449.54,
        "duration": 4.98,
        "text": "so why would you need spark again this"
      },
      {
        "start": 451.7,
        "duration": 4.47,
        "text": "is a super quick light intro to spark if"
      },
      {
        "start": 454.52,
        "duration": 4.08,
        "text": "you have big data do you need high"
      },
      {
        "start": 456.17,
        "duration": 4.74,
        "text": "availability do you need analytics at"
      },
      {
        "start": 458.6,
        "duration": 3.54,
        "text": "lightning speed and if you need insights"
      },
      {
        "start": 460.91,
        "duration": 3.78,
        "text": "into your data you might want to"
      },
      {
        "start": 462.14,
        "duration": 3.9,
        "text": "consider using spark okay"
      },
      {
        "start": 464.69,
        "duration": 2.88,
        "text": "so now we're gonna start talking about"
      },
      {
        "start": 466.04,
        "duration": 4.55,
        "text": "kind of the overarching thing of this"
      },
      {
        "start": 467.57,
        "duration": 5.43,
        "text": "talk which is the Twitter movie reviews"
      },
      {
        "start": 470.59,
        "duration": 3.4,
        "text": "so what is sentiment analysis what are"
      },
      {
        "start": 473.0,
        "duration": 3.99,
        "text": "we in trying to do here with data"
      },
      {
        "start": 473.99,
        "duration": 4.53,
        "text": "science okay so at a very high level now"
      },
      {
        "start": 476.99,
        "duration": 3.39,
        "text": "you could talk about sentiment analysis"
      },
      {
        "start": 478.52,
        "duration": 3.45,
        "text": "probably could have whole courses on it"
      },
      {
        "start": 480.38,
        "duration": 3.54,
        "text": "but for this case we're just gonna talk"
      },
      {
        "start": 481.97,
        "duration": 4.53,
        "text": "at a very high level and it's very"
      },
      {
        "start": 483.92,
        "duration": 5.04,
        "text": "simple it's basically natural language"
      },
      {
        "start": 486.5,
        "duration": 4.89,
        "text": "processing and text analytics determine"
      },
      {
        "start": 488.96,
        "duration": 6.51,
        "text": "if a word in a sent or sentence is"
      },
      {
        "start": 491.39,
        "duration": 7.38,
        "text": "positive negative or neutral so this is"
      },
      {
        "start": 495.47,
        "duration": 4.98,
        "text": "very easy for us to understand at a high"
      },
      {
        "start": 498.77,
        "duration": 4.02,
        "text": "level but it's very difficult for"
      },
      {
        "start": 500.45,
        "duration": 4.41,
        "text": "machines to learn how to do but also"
      },
      {
        "start": 502.79,
        "duration": 4.26,
        "text": "think about us in this day and age with"
      },
      {
        "start": 504.86,
        "duration": 4.08,
        "text": "text messages think how difficult it is"
      },
      {
        "start": 507.05,
        "duration": 3.45,
        "text": "even when like somebody sends you like a"
      },
      {
        "start": 508.94,
        "duration": 4.02,
        "text": "text message and they say hi and they"
      },
      {
        "start": 510.5,
        "duration": 3.69,
        "text": "put a period right you have to figure"
      },
      {
        "start": 512.96,
        "duration": 4.05,
        "text": "out what that person means are they"
      },
      {
        "start": 514.19,
        "duration": 4.71,
        "text": "happy or they neutral are they sad so"
      },
      {
        "start": 517.01,
        "duration": 3.719,
        "text": "even for us it's getting more difficult"
      },
      {
        "start": 518.9,
        "duration": 4.62,
        "text": "to understand what people actually mean"
      },
      {
        "start": 520.729,
        "duration": 4.291,
        "text": "with what they type so imagine for a"
      },
      {
        "start": 523.52,
        "duration": 4.04,
        "text": "machine to try to figure that out okay"
      },
      {
        "start": 525.02,
        "duration": 4.77,
        "text": "so let's do an overview of the demo"
      },
      {
        "start": 527.56,
        "duration": 4.12,
        "text": "alrighty so what we're going to do is I"
      },
      {
        "start": 529.79,
        "duration": 3.39,
        "text": "have a local data Stax enterprise and"
      },
      {
        "start": 531.68,
        "duration": 4.2,
        "text": "it's set up here on my laptop it's just"
      },
      {
        "start": 533.18,
        "duration": 4.56,
        "text": "a one node cluster cluster I have a"
      },
      {
        "start": 535.88,
        "duration": 4.26,
        "text": "local Jupiter notebook set up here on my"
      },
      {
        "start": 537.74,
        "duration": 4.65,
        "text": "laptop so we're gonna pull Twitter data"
      },
      {
        "start": 540.14,
        "duration": 3.99,
        "text": "on a movie title so in this particular"
      },
      {
        "start": 542.39,
        "duration": 4.35,
        "text": "instance we're gonna use Mission"
      },
      {
        "start": 544.13,
        "duration": 5.91,
        "text": "Impossible we're gonna clean up the"
      },
      {
        "start": 546.74,
        "duration": 5.82,
        "text": "tweets we're gonna insert that data into"
      },
      {
        "start": 550.04,
        "duration": 5.31,
        "text": "Cassandra and we're gonna create a spark"
      },
      {
        "start": 552.56,
        "duration": 4.23,
        "text": "data frame from that because DSC"
      },
      {
        "start": 555.35,
        "duration": 3.63,
        "text": "analytics which I didn't really talk"
      },
      {
        "start": 556.79,
        "duration": 3.66,
        "text": "about here but it has that all"
      },
      {
        "start": 558.98,
        "duration": 2.94,
        "text": "integrated right in the box and you'll"
      },
      {
        "start": 560.45,
        "duration": 3.99,
        "text": "see how easy it is for us to move from"
      },
      {
        "start": 561.92,
        "duration": 4.59,
        "text": "Cassandra to spark we're gonna use spark"
      },
      {
        "start": 564.44,
        "duration": 4.019,
        "text": "machine learning libraries we're gonna"
      },
      {
        "start": 566.51,
        "duration": 3.54,
        "text": "do cinnamon analysis with pattern which"
      },
      {
        "start": 568.459,
        "duration": 3.481,
        "text": "is a Python package and it's gonna give"
      },
      {
        "start": 570.05,
        "duration": 3.81,
        "text": "us the positive or negative we're gonna"
      },
      {
        "start": 571.94,
        "duration": 4.019,
        "text": "take an average of all the scores and"
      },
      {
        "start": 573.86,
        "duration": 4.5,
        "text": "then we're gonna decide should I"
      },
      {
        "start": 575.959,
        "duration": 8.311,
        "text": "actually see this movie or not okay so"
      },
      {
        "start": 578.36,
        "duration": 8.84,
        "text": "let's get to the demo all right so it's"
      },
      {
        "start": 584.27,
        "duration": 2.93,
        "text": "a jupiter notebook"
      },
      {
        "start": 587.5,
        "duration": 4.75,
        "text": "so make it a little bit difficult to see"
      },
      {
        "start": 589.85,
        "duration": 4.59,
        "text": "in the back but i do have this on my"
      },
      {
        "start": 592.25,
        "duration": 3.24,
        "text": "github and anybody's read downloaded so"
      },
      {
        "start": 594.44,
        "duration": 4.23,
        "text": "let's just start walking through this"
      },
      {
        "start": 595.49,
        "duration": 4.62,
        "text": "jupiter notebook so i have again if you"
      },
      {
        "start": 598.67,
        "duration": 2.609,
        "text": "wanted to download this from my github i"
      },
      {
        "start": 600.11,
        "duration": 2.52,
        "text": "have all the steps on what you would"
      },
      {
        "start": 601.279,
        "duration": 3.331,
        "text": "need to do to actually get it set up and"
      },
      {
        "start": 602.63,
        "duration": 3.75,
        "text": "just running on your laptop so we won't"
      },
      {
        "start": 604.61,
        "duration": 3.69,
        "text": "walk over the through those it's not"
      },
      {
        "start": 606.38,
        "duration": 3.06,
        "text": "that interesting but it looks like it's"
      },
      {
        "start": 608.3,
        "duration": 2.67,
        "text": "a lot of steps but it's actually the"
      },
      {
        "start": 609.44,
        "duration": 2.94,
        "text": "complete amount of steps it probably"
      },
      {
        "start": 610.97,
        "duration": 3.96,
        "text": "would only take you 20 minutes to get"
      },
      {
        "start": 612.38,
        "duration": 3.899,
        "text": "this all set up and running these are"
      },
      {
        "start": 614.93,
        "duration": 4.22,
        "text": "just some environment variables that you"
      },
      {
        "start": 616.279,
        "duration": 5.791,
        "text": "need you import some packages in python"
      },
      {
        "start": 619.15,
        "duration": 4.48,
        "text": "this is just a helper nice function to"
      },
      {
        "start": 622.07,
        "duration": 4.32,
        "text": "do some like nice formatting pretty"
      },
      {
        "start": 623.63,
        "duration": 4.1,
        "text": "printing per spark data frames alright"
      },
      {
        "start": 626.39,
        "duration": 3.72,
        "text": "so now let's get to data stack"
      },
      {
        "start": 627.73,
        "duration": 4.39,
        "text": "enterprise analytics so we're gonna"
      },
      {
        "start": 630.11,
        "duration": 4.83,
        "text": "create the table we're gonna pull the"
      },
      {
        "start": 632.12,
        "duration": 5.43,
        "text": "tweets and we're gonna load the table so"
      },
      {
        "start": 634.94,
        "duration": 5.46,
        "text": "we're using the Python data sacks Python"
      },
      {
        "start": 637.55,
        "duration": 4.26,
        "text": "cassandra driver and so here this is all"
      },
      {
        "start": 640.4,
        "duration": 2.76,
        "text": "we need to do to actually connect to our"
      },
      {
        "start": 641.81,
        "duration": 2.58,
        "text": "cluster and like I said it's a one-note"
      },
      {
        "start": 643.16,
        "duration": 3.51,
        "text": "cluster just running here in my laptop"
      },
      {
        "start": 644.39,
        "duration": 4.41,
        "text": "so I'm just connecting to localhost here"
      },
      {
        "start": 646.67,
        "duration": 5.159,
        "text": "I get my cluster object and I'm able to"
      },
      {
        "start": 648.8,
        "duration": 4.529,
        "text": "create a session just that easily from"
      },
      {
        "start": 651.829,
        "duration": 3.961,
        "text": "there we're actually gonna create a key"
      },
      {
        "start": 653.329,
        "duration": 3.831,
        "text": "space now a key space and Cassandra is"
      },
      {
        "start": 655.79,
        "duration": 5.549,
        "text": "similar to if you're familiar with"
      },
      {
        "start": 657.16,
        "duration": 6.88,
        "text": "Oracle it's like a bit of a schema or if"
      },
      {
        "start": 661.339,
        "duration": 3.991,
        "text": "your terror data is like a database and"
      },
      {
        "start": 664.04,
        "duration": 2.82,
        "text": "so we're going"
      },
      {
        "start": 665.33,
        "duration": 2.73,
        "text": "set that up we're gonna use a simple"
      },
      {
        "start": 666.86,
        "duration": 2.58,
        "text": "strategy and we're gonna use our"
      },
      {
        "start": 668.06,
        "duration": 3.469,
        "text": "replication factor which I talked about"
      },
      {
        "start": 669.44,
        "duration": 4.14,
        "text": "before we're just gonna set that to one"
      },
      {
        "start": 671.529,
        "duration": 4.471,
        "text": "because there's no point in replicating"
      },
      {
        "start": 673.58,
        "duration": 4.59,
        "text": "my data because I only have one note and"
      },
      {
        "start": 676.0,
        "duration": 4.0,
        "text": "next we're gonna actually just set our"
      },
      {
        "start": 678.17,
        "duration": 4.14,
        "text": "key space and now we're gonna set up our"
      },
      {
        "start": 680.0,
        "duration": 5.01,
        "text": "movie title so in this case we're gonna"
      },
      {
        "start": 682.31,
        "duration": 4.44,
        "text": "search on Mission Impossible and we're"
      },
      {
        "start": 685.01,
        "duration": 4.05,
        "text": "gonna search we're gonna search for"
      },
      {
        "start": 686.75,
        "duration": 3.779,
        "text": "positive tweets and negative tweets so"
      },
      {
        "start": 689.06,
        "duration": 4.23,
        "text": "we're gonna create two tables and"
      },
      {
        "start": 690.529,
        "duration": 4.231,
        "text": "Cassandra for this movie title one for"
      },
      {
        "start": 693.29,
        "duration": 4.02,
        "text": "the path ative and one for the negative"
      },
      {
        "start": 694.76,
        "duration": 4.56,
        "text": "so Twitter actually the Twitter dev API"
      },
      {
        "start": 697.31,
        "duration": 4.35,
        "text": "if any familiar with it it's actually"
      },
      {
        "start": 699.32,
        "duration": 4.829,
        "text": "really awesome you can get a ton of real"
      },
      {
        "start": 701.66,
        "duration": 4.859,
        "text": "time information about basically"
      },
      {
        "start": 704.149,
        "duration": 4.13,
        "text": "anything you want to search for see it"
      },
      {
        "start": 706.519,
        "duration": 4.081,
        "text": "actually gives you a ton of information"
      },
      {
        "start": 708.279,
        "duration": 4.511,
        "text": "way more than we need for just the sake"
      },
      {
        "start": 710.6,
        "duration": 4.56,
        "text": "of this demo so we're just gonna utilize"
      },
      {
        "start": 712.79,
        "duration": 3.72,
        "text": "the Twitter ID as our primary key to"
      },
      {
        "start": 715.16,
        "duration": 4.29,
        "text": "what actually we want to partition our"
      },
      {
        "start": 716.51,
        "duration": 5.73,
        "text": "data by because it's unique and then"
      },
      {
        "start": 719.45,
        "duration": 4.23,
        "text": "we're gonna get the actual tweet so just"
      },
      {
        "start": 722.24,
        "duration": 2.969,
        "text": "a little note here"
      },
      {
        "start": 723.68,
        "duration": 3.33,
        "text": "you may want to think about when you're"
      },
      {
        "start": 725.209,
        "duration": 4.411,
        "text": "actually distributing your data at scale"
      },
      {
        "start": 727.01,
        "duration": 3.99,
        "text": "with Cassandra if that primary key of"
      },
      {
        "start": 729.62,
        "duration": 3.57,
        "text": "your Twitter ID is really the right"
      },
      {
        "start": 731.0,
        "duration": 3.329,
        "text": "thing to partition by in this case"
      },
      {
        "start": 733.19,
        "duration": 2.43,
        "text": "because I just have one note it doesn't"
      },
      {
        "start": 734.329,
        "duration": 3.841,
        "text": "really matter but it is something to"
      },
      {
        "start": 735.62,
        "duration": 3.9,
        "text": "consider like for your data model when"
      },
      {
        "start": 738.17,
        "duration": 3.539,
        "text": "you're choosing your primary key so"
      },
      {
        "start": 739.52,
        "duration": 4.23,
        "text": "we're gonna create both of those tables"
      },
      {
        "start": 741.709,
        "duration": 4.201,
        "text": "so from there we're gonna actually set"
      },
      {
        "start": 743.75,
        "duration": 4.86,
        "text": "up our search terms for gathering tweets"
      },
      {
        "start": 745.91,
        "duration": 5.46,
        "text": "from the Twitter API so what's really"
      },
      {
        "start": 748.61,
        "duration": 3.99,
        "text": "cool about Twitter and their API is what"
      },
      {
        "start": 751.37,
        "duration": 3.6,
        "text": "I noticed when I was working on this"
      },
      {
        "start": 752.6,
        "duration": 4.77,
        "text": "demo is they actually do a first pass of"
      },
      {
        "start": 754.97,
        "duration": 3.929,
        "text": "cinnamon analysis on the Twitter tweets"
      },
      {
        "start": 757.37,
        "duration": 4.35,
        "text": "and you can actually search that"
      },
      {
        "start": 758.899,
        "duration": 5.401,
        "text": "literally by a happy face or a sad face"
      },
      {
        "start": 761.72,
        "duration": 4.65,
        "text": "and they look it's actually true and"
      },
      {
        "start": 764.3,
        "duration": 4.77,
        "text": "they will give you back either positive"
      },
      {
        "start": 766.37,
        "duration": 4.5,
        "text": "tweets or negative tweets um and we'll"
      },
      {
        "start": 769.07,
        "duration": 4.98,
        "text": "see as we go through this actually their"
      },
      {
        "start": 770.87,
        "duration": 5.55,
        "text": "their first pass at it with the positive"
      },
      {
        "start": 774.05,
        "duration": 4.47,
        "text": "tweets is it's spot on you almost always"
      },
      {
        "start": 776.42,
        "duration": 3.6,
        "text": "get positive tweets for some reason"
      },
      {
        "start": 778.52,
        "duration": 4.83,
        "text": "whatever algorithm that they're using"
      },
      {
        "start": 780.02,
        "duration": 4.95,
        "text": "for the negative tweets you don't always"
      },
      {
        "start": 783.35,
        "duration": 2.88,
        "text": "get negative us I'm not quite sure why"
      },
      {
        "start": 784.97,
        "duration": 3.239,
        "text": "I've been playing with it now for a"
      },
      {
        "start": 786.23,
        "duration": 3.299,
        "text": "couple weeks it doesn't really seem to"
      },
      {
        "start": 788.209,
        "duration": 1.771,
        "text": "work but the positive seems to be"
      },
      {
        "start": 789.529,
        "duration": 2.011,
        "text": "spot-on"
      },
      {
        "start": 789.98,
        "duration": 4.44,
        "text": "but we'll see more about that as we walk"
      },
      {
        "start": 791.54,
        "duration": 4.02,
        "text": "through this alright so now I'm gonna"
      },
      {
        "start": 794.42,
        "duration": 3.27,
        "text": "have another function here that's"
      },
      {
        "start": 795.56,
        "duration": 3.15,
        "text": "actually gonna clean up the tweets we're"
      },
      {
        "start": 797.69,
        "duration": 4.32,
        "text": "gonna remove the"
      },
      {
        "start": 798.71,
        "duration": 5.43,
        "text": "oh geez flags special characters URLs"
      },
      {
        "start": 802.01,
        "duration": 3.84,
        "text": "and we're gonna move our tea because"
      },
      {
        "start": 804.14,
        "duration": 3.48,
        "text": "when you pull in the Twitter data and"
      },
      {
        "start": 805.85,
        "duration": 4.2,
        "text": "actually for retweets it just puts its"
      },
      {
        "start": 807.62,
        "duration": 3.78,
        "text": "RT in there I just removed it just to"
      },
      {
        "start": 810.05,
        "duration": 3.78,
        "text": "make it a little easier for the"
      },
      {
        "start": 811.4,
        "duration": 4.77,
        "text": "sentiment analysis functions just in"
      },
      {
        "start": 813.83,
        "duration": 3.66,
        "text": "case so wouldn't get confused and"
      },
      {
        "start": 816.17,
        "duration": 3.75,
        "text": "actually would be pretty great if we can"
      },
      {
        "start": 817.49,
        "duration": 4.32,
        "text": "do sentiment analysis around emojis"
      },
      {
        "start": 819.92,
        "duration": 3.75,
        "text": "because a lot of emotion comes through"
      },
      {
        "start": 821.81,
        "duration": 5.52,
        "text": "with those emojis but in this case we"
      },
      {
        "start": 823.67,
        "duration": 5.4,
        "text": "just we just removed them already so"
      },
      {
        "start": 827.33,
        "duration": 3.51,
        "text": "then to be able to use Twitter and their"
      },
      {
        "start": 829.07,
        "duration": 3.18,
        "text": "API you have to set up some keys and"
      },
      {
        "start": 830.84,
        "duration": 4.2,
        "text": "things like that and they walk you"
      },
      {
        "start": 832.25,
        "duration": 4.77,
        "text": "through it all in their their URLs and"
      },
      {
        "start": 835.04,
        "duration": 5.43,
        "text": "their links so I got that all set up"
      },
      {
        "start": 837.02,
        "duration": 5.28,
        "text": "here alright so this so we're actually"
      },
      {
        "start": 840.47,
        "duration": 3.84,
        "text": "gonna pull the tweets from Twitter so"
      },
      {
        "start": 842.3,
        "duration": 4.23,
        "text": "the maximum number of tweets you can"
      },
      {
        "start": 844.31,
        "duration": 5.01,
        "text": "pull it any one time for free is only"
      },
      {
        "start": 846.53,
        "duration": 4.86,
        "text": "100 so you can actually run this code a"
      },
      {
        "start": 849.32,
        "duration": 3.93,
        "text": "couple times to pull more and more so"
      },
      {
        "start": 851.39,
        "duration": 3.96,
        "text": "once the tweets are collected let's loop"
      },
      {
        "start": 853.25,
        "duration": 4.17,
        "text": "over the list clean up the tweets and"
      },
      {
        "start": 855.35,
        "duration": 3.66,
        "text": "then insert them into the table so we"
      },
      {
        "start": 857.42,
        "duration": 3.93,
        "text": "have a large for loop around here that"
      },
      {
        "start": 859.01,
        "duration": 3.93,
        "text": "surrounds this to make one call for the"
      },
      {
        "start": 861.35,
        "duration": 3.81,
        "text": "positive and one for the negative and"
      },
      {
        "start": 862.94,
        "duration": 6.06,
        "text": "then we also have two URL encode our"
      },
      {
        "start": 865.16,
        "duration": 5.67,
        "text": "happy base in our side base so that's"
      },
      {
        "start": 869.0,
        "duration": 3.9,
        "text": "what this is doing here and because this"
      },
      {
        "start": 870.83,
        "duration": 3.81,
        "text": "is a very techy crowd you'll notice I"
      },
      {
        "start": 872.9,
        "duration": 4.74,
        "text": "have a comment here I actually have a"
      },
      {
        "start": 874.64,
        "duration": 4.32,
        "text": "comment on the actual insert we're not"
      },
      {
        "start": 877.64,
        "duration": 2.82,
        "text": "actually not gonna insert this because I"
      },
      {
        "start": 878.96,
        "duration": 3.45,
        "text": "already found some really great data"
      },
      {
        "start": 880.46,
        "duration": 3.45,
        "text": "that I want to show you so even though"
      },
      {
        "start": 882.41,
        "duration": 5.22,
        "text": "if we could we could pull it live"
      },
      {
        "start": 883.91,
        "duration": 5.73,
        "text": "we're not inserting it into the table so"
      },
      {
        "start": 887.63,
        "duration": 3.33,
        "text": "let's so we're seeing actually some of"
      },
      {
        "start": 889.64,
        "duration": 2.76,
        "text": "the tweets that got pulled live just"
      },
      {
        "start": 890.96,
        "duration": 4.23,
        "text": "when I ran this just a little bit ago"
      },
      {
        "start": 892.4,
        "duration": 5.55,
        "text": "and these are all about mission"
      },
      {
        "start": 895.19,
        "duration": 4.32,
        "text": "impossible so then we can do a select"
      },
      {
        "start": 897.95,
        "duration": 3.36,
        "text": "star on the table and verified that the"
      },
      {
        "start": 899.51,
        "duration": 3.84,
        "text": "tweets were actually inserted into our"
      },
      {
        "start": 901.31,
        "duration": 7.44,
        "text": "Cassandra table and so we can see here"
      },
      {
        "start": 903.35,
        "duration": 7.8,
        "text": "that they were alright so now we're"
      },
      {
        "start": 908.75,
        "duration": 4.5,
        "text": "starting to get to some analytics with"
      },
      {
        "start": 911.15,
        "duration": 2.64,
        "text": "Apache spark so now it's actually time"
      },
      {
        "start": 913.25,
        "duration": 2.04,
        "text": "for that"
      },
      {
        "start": 913.79,
        "duration": 4.71,
        "text": "so let's so what we're gonna do in this"
      },
      {
        "start": 915.29,
        "duration": 7.38,
        "text": "one line of code here is we're able to"
      },
      {
        "start": 918.5,
        "duration": 5.97,
        "text": "take our Apache Cassandra table and load"
      },
      {
        "start": 922.67,
        "duration": 3.72,
        "text": "it into a spark data frame and so we're"
      },
      {
        "start": 924.47,
        "duration": 3.69,
        "text": "gonna create two spark data frames one"
      },
      {
        "start": 926.39,
        "duration": 3.81,
        "text": "for positive tweets and one for negative"
      },
      {
        "start": 928.16,
        "duration": 4.17,
        "text": "tweets and just this one line of code"
      },
      {
        "start": 930.2,
        "duration": 5.91,
        "text": "right here will move all the data"
      },
      {
        "start": 932.33,
        "duration": 6.12,
        "text": "from Cassandra into spark no really I"
      },
      {
        "start": 936.11,
        "duration": 4.77,
        "text": "think again this is all just around one"
      },
      {
        "start": 938.45,
        "duration": 5.16,
        "text": "node but imagine this head scale right"
      },
      {
        "start": 940.88,
        "duration": 4.71,
        "text": "and how easy that was to do and then"
      },
      {
        "start": 943.61,
        "duration": 4.05,
        "text": "we're just gonna take a count of how"
      },
      {
        "start": 945.59,
        "duration": 4.29,
        "text": "many rows I got for each so it looks"
      },
      {
        "start": 947.66,
        "duration": 5.34,
        "text": "like I had 50 tweets for the positive"
      },
      {
        "start": 949.88,
        "duration": 4.2,
        "text": "and 75 for the negative so now we're"
      },
      {
        "start": 953.0,
        "duration": 3.84,
        "text": "gonna actually use those machine"
      },
      {
        "start": 954.08,
        "duration": 5.31,
        "text": "learning libraries to break up the"
      },
      {
        "start": 956.84,
        "duration": 5.1,
        "text": "sentences into actual words so we're"
      },
      {
        "start": 959.39,
        "duration": 4.47,
        "text": "gonna use the spark tokenizer and it's"
      },
      {
        "start": 961.94,
        "duration": 3.78,
        "text": "gonna cut up these sentence into"
      },
      {
        "start": 963.86,
        "duration": 3.47,
        "text": "individual words and we're gonna do that"
      },
      {
        "start": 965.72,
        "duration": 4.86,
        "text": "for the positive and for the negative"
      },
      {
        "start": 967.33,
        "duration": 5.65,
        "text": "and you can see we just print out the"
      },
      {
        "start": 970.58,
        "duration": 3.99,
        "text": "data frame here it shows the tweet when"
      },
      {
        "start": 972.98,
        "duration": 5.25,
        "text": "it's cut up into words and then how many"
      },
      {
        "start": 974.57,
        "duration": 4.77,
        "text": "words were in each tweet all right so"
      },
      {
        "start": 978.23,
        "duration": 2.64,
        "text": "then the next thing that we're gonna do"
      },
      {
        "start": 979.34,
        "duration": 4.32,
        "text": "so we're actually gonna remove all the"
      },
      {
        "start": 980.87,
        "duration": 5.28,
        "text": "stop words anything that has like if"
      },
      {
        "start": 983.66,
        "duration": 4.17,
        "text": "you're familiar with of a the none of"
      },
      {
        "start": 986.15,
        "duration": 3.33,
        "text": "that's actually important to the"
      },
      {
        "start": 987.83,
        "duration": 4.41,
        "text": "sentiment so we're actually gonna strip"
      },
      {
        "start": 989.48,
        "duration": 4.44,
        "text": "those out and so we're using again the"
      },
      {
        "start": 992.24,
        "duration": 3.09,
        "text": "spark machine learning library stop"
      },
      {
        "start": 993.92,
        "duration": 2.91,
        "text": "words remover and we're gonna do that"
      },
      {
        "start": 995.33,
        "duration": 3.87,
        "text": "again for the positive and for the"
      },
      {
        "start": 996.83,
        "duration": 4.89,
        "text": "negative and so we can already start"
      },
      {
        "start": 999.2,
        "duration": 3.6,
        "text": "seeing some interesting things here we"
      },
      {
        "start": 1001.72,
        "duration": 3.12,
        "text": "see the number of tokens that are"
      },
      {
        "start": 1002.8,
        "duration": 4.32,
        "text": "originally so number of words in each"
      },
      {
        "start": 1004.84,
        "duration": 4.32,
        "text": "sentence and then once we remove the"
      },
      {
        "start": 1007.12,
        "duration": 4.23,
        "text": "stop words how many words we have left"
      },
      {
        "start": 1009.16,
        "duration": 4.26,
        "text": "alright so now let's actually get to our"
      },
      {
        "start": 1011.35,
        "duration": 4.56,
        "text": "sentiment analysis so we're gonna"
      },
      {
        "start": 1013.42,
        "duration": 4.74,
        "text": "convert each spark data frame to a"
      },
      {
        "start": 1015.91,
        "duration": 4.32,
        "text": "panda's data frame now I just want to"
      },
      {
        "start": 1018.16,
        "duration": 4.08,
        "text": "let everyone know that this works as is"
      },
      {
        "start": 1020.23,
        "duration": 3.36,
        "text": "because I'm working on my laptop anyone"
      },
      {
        "start": 1022.24,
        "duration": 3.84,
        "text": "who's familiar with spark and data"
      },
      {
        "start": 1023.59,
        "duration": 4.14,
        "text": "science and Big Data knows that pandas"
      },
      {
        "start": 1026.08,
        "duration": 3.99,
        "text": "just runs locally wherever you're"
      },
      {
        "start": 1027.73,
        "duration": 5.13,
        "text": "running it from be it your laptop or a"
      },
      {
        "start": 1030.07,
        "duration": 4.65,
        "text": "server so to just move from one to the"
      },
      {
        "start": 1032.86,
        "duration": 3.15,
        "text": "other you have to make sure that when"
      },
      {
        "start": 1034.72,
        "duration": 2.85,
        "text": "you're moving from one to the other that"
      },
      {
        "start": 1036.01,
        "duration": 3.51,
        "text": "you have the memory to actually do that"
      },
      {
        "start": 1037.57,
        "duration": 3.45,
        "text": "so again it just works because it's here"
      },
      {
        "start": 1039.52,
        "duration": 3.84,
        "text": "my laptop but it's something to consider"
      },
      {
        "start": 1041.02,
        "duration": 3.96,
        "text": "so then we're gonna loop throat each of"
      },
      {
        "start": 1043.36,
        "duration": 3.78,
        "text": "the rows and we're actually gonna give a"
      },
      {
        "start": 1044.98,
        "duration": 4.26,
        "text": "sentiment score and we're gonna get on"
      },
      {
        "start": 1047.14,
        "duration": 3.84,
        "text": "each tweet we're gonna get whether it's"
      },
      {
        "start": 1049.24,
        "duration": 4.32,
        "text": "positive so it's like a positive number"
      },
      {
        "start": 1050.98,
        "duration": 4.98,
        "text": "or it's negative which means it's a"
      },
      {
        "start": 1053.56,
        "duration": 4.98,
        "text": "negative sentiment or we'll get a zero"
      },
      {
        "start": 1055.96,
        "duration": 4.56,
        "text": "zero can mean neutral or zero can mean I"
      },
      {
        "start": 1058.54,
        "duration": 3.36,
        "text": "don't have enough information to score"
      },
      {
        "start": 1060.52,
        "duration": 4.23,
        "text": "this I really don't know what it means"
      },
      {
        "start": 1061.9,
        "duration": 4.02,
        "text": "so then we're actually gonna have the"
      },
      {
        "start": 1064.75,
        "duration": 3.69,
        "text": "assessment function"
      },
      {
        "start": 1065.92,
        "duration": 4.86,
        "text": "which is part of the pattern package and"
      },
      {
        "start": 1068.44,
        "duration": 5.28,
        "text": "it's gonna show whether the word that"
      },
      {
        "start": 1070.78,
        "duration": 4.89,
        "text": "what words that we use to judge whether"
      },
      {
        "start": 1073.72,
        "duration": 5.37,
        "text": "this was positive or negative so this"
      },
      {
        "start": 1075.67,
        "duration": 4.65,
        "text": "here's the Python code here for this so"
      },
      {
        "start": 1079.09,
        "duration": 3.57,
        "text": "okay so these are some of the tweets"
      },
      {
        "start": 1080.32,
        "duration": 5.13,
        "text": "that we've gotten so here's an example I"
      },
      {
        "start": 1082.66,
        "duration": 4.71,
        "text": "want to watch Mission Impossible has"
      },
      {
        "start": 1085.45,
        "duration": 4.26,
        "text": "anyone watched it yet and then a sad"
      },
      {
        "start": 1087.37,
        "duration": 5.76,
        "text": "safe so it's not really a movie review"
      },
      {
        "start": 1089.71,
        "duration": 6.39,
        "text": "but it is a real-time tweet that I just"
      },
      {
        "start": 1093.13,
        "duration": 4.44,
        "text": "pulled not too long ago and so this I in"
      },
      {
        "start": 1096.1,
        "duration": 3.9,
        "text": "this case it got scored to the zero"
      },
      {
        "start": 1097.57,
        "duration": 5.61,
        "text": "point three so kind of a negative"
      },
      {
        "start": 1100.0,
        "duration": 5.34,
        "text": "sentiment alright so we have our here's"
      },
      {
        "start": 1103.18,
        "duration": 3.84,
        "text": "our nice data frame here print it out we"
      },
      {
        "start": 1105.34,
        "duration": 3.66,
        "text": "have our original tweet the score"
      },
      {
        "start": 1107.02,
        "duration": 5.91,
        "text": "whether it's positive or negative and"
      },
      {
        "start": 1109.0,
        "duration": 6.69,
        "text": "why we decided that score that we did so"
      },
      {
        "start": 1112.93,
        "duration": 4.29,
        "text": "the assessment so straight away we're"
      },
      {
        "start": 1115.69,
        "duration": 4.25,
        "text": "seeing something interesting here on our"
      },
      {
        "start": 1117.22,
        "duration": 6.06,
        "text": "assessment we're seeing the word"
      },
      {
        "start": 1119.94,
        "duration": 7.77,
        "text": "impossible so we'll come back to that"
      },
      {
        "start": 1123.28,
        "duration": 7.8,
        "text": "here in a bit so let's do the same thing"
      },
      {
        "start": 1127.71,
        "duration": 4.75,
        "text": "with our positive tweets and actually"
      },
      {
        "start": 1131.08,
        "duration": 3.69,
        "text": "and another thing I forgot to mention is"
      },
      {
        "start": 1132.46,
        "duration": 5.64,
        "text": "as we go through we're actually taking"
      },
      {
        "start": 1134.77,
        "duration": 5.01,
        "text": "an average of the scores so that we can"
      },
      {
        "start": 1138.1,
        "duration": 3.51,
        "text": "kind of make a rough estimate of whether"
      },
      {
        "start": 1139.78,
        "duration": 3.39,
        "text": "we should see this movie or not so"
      },
      {
        "start": 1141.61,
        "duration": 4.56,
        "text": "here's like Mission Impossible fall is"
      },
      {
        "start": 1143.17,
        "duration": 4.95,
        "text": "great so we got a 0.8 so that's a very"
      },
      {
        "start": 1146.17,
        "duration": 3.45,
        "text": "positive feeling about that and we can"
      },
      {
        "start": 1148.12,
        "duration": 3.9,
        "text": "see straight away in our assessment that"
      },
      {
        "start": 1149.62,
        "duration": 4.77,
        "text": "it gave the word great and it said okay"
      },
      {
        "start": 1152.02,
        "duration": 4.35,
        "text": "that's why I'm gonna weigh it so highly"
      },
      {
        "start": 1154.39,
        "duration": 5.37,
        "text": "on the positive because great is such a"
      },
      {
        "start": 1156.37,
        "duration": 6.09,
        "text": "positive word alrighty so we're finally"
      },
      {
        "start": 1159.76,
        "duration": 5.16,
        "text": "to the end here should I see this movie"
      },
      {
        "start": 1162.46,
        "duration": 4.68,
        "text": "so basically how I'm saying in just my"
      },
      {
        "start": 1164.92,
        "duration": 4.41,
        "text": "demo here is if the average of all the"
      },
      {
        "start": 1167.14,
        "duration": 3.9,
        "text": "positive scores is greater than the"
      },
      {
        "start": 1169.33,
        "duration": 3.24,
        "text": "average of the negative scores I'm"
      },
      {
        "start": 1171.04,
        "duration": 3.72,
        "text": "saying hey go out there go see this"
      },
      {
        "start": 1172.57,
        "duration": 3.81,
        "text": "movie people like it worth they're equal"
      },
      {
        "start": 1174.76,
        "duration": 4.47,
        "text": "I'm saying hey go take a chance people"
      },
      {
        "start": 1176.38,
        "duration": 4.74,
        "text": "are split and if the positive rating is"
      },
      {
        "start": 1179.23,
        "duration": 4.04,
        "text": "actually less than a negative rating I'm"
      },
      {
        "start": 1181.12,
        "duration": 3.36,
        "text": "saying people don't like this movie"
      },
      {
        "start": 1183.27,
        "duration": 3.45,
        "text": "alrighty"
      },
      {
        "start": 1184.48,
        "duration": 6.09,
        "text": "so our final positive rating score is"
      },
      {
        "start": 1186.72,
        "duration": 6.52,
        "text": "0.2 not that positive our negative score"
      },
      {
        "start": 1190.57,
        "duration": 6.6,
        "text": "is actually negative 0.4 so we're saying"
      },
      {
        "start": 1193.24,
        "duration": 6.299,
        "text": "people don't like this movie so is this"
      },
      {
        "start": 1197.17,
        "duration": 4.02,
        "text": "the answer that you were expecting so"
      },
      {
        "start": 1199.539,
        "duration": 3.09,
        "text": "when we look at Rotten Tomatoes for our"
      },
      {
        "start": 1201.19,
        "duration": 4.5,
        "text": "mission impossible' has a super high"
      },
      {
        "start": 1202.629,
        "duration": 4.5,
        "text": "score so maybe we need to either way we"
      },
      {
        "start": 1205.69,
        "duration": 3.66,
        "text": "really need to go back and take a look"
      },
      {
        "start": 1207.129,
        "duration": 4.8,
        "text": "at our data we need it data science is"
      },
      {
        "start": 1209.35,
        "duration": 5.459,
        "text": "an iterative process so let's kind of"
      },
      {
        "start": 1211.929,
        "duration": 6.511,
        "text": "scroll back up here to those negative"
      },
      {
        "start": 1214.809,
        "duration": 5.37,
        "text": "reviews that we saw what do we keep"
      },
      {
        "start": 1218.44,
        "duration": 6.179,
        "text": "seeing over and over again in our"
      },
      {
        "start": 1220.179,
        "duration": 7.08,
        "text": "assessments the word impossible now"
      },
      {
        "start": 1224.619,
        "duration": 4.74,
        "text": "because mission impossible is in the"
      },
      {
        "start": 1227.259,
        "duration": 4.11,
        "text": "movie title maybe I should have removed"
      },
      {
        "start": 1229.359,
        "duration": 3.721,
        "text": "that when I was removing my stop words"
      },
      {
        "start": 1231.369,
        "duration": 3.75,
        "text": "right because the movie title doesn't"
      },
      {
        "start": 1233.08,
        "duration": 4.319,
        "text": "have any weight on the actual assessment"
      },
      {
        "start": 1235.119,
        "duration": 4.38,
        "text": "it's just it's just there it's the movie"
      },
      {
        "start": 1237.399,
        "duration": 3.421,
        "text": "title so because we had that word"
      },
      {
        "start": 1239.499,
        "duration": 3.6,
        "text": "impossible it feels like it's really"
      },
      {
        "start": 1240.82,
        "duration": 4.199,
        "text": "negative so if I had removed that then"
      },
      {
        "start": 1243.099,
        "duration": 3.93,
        "text": "we could probably get something much"
      },
      {
        "start": 1245.019,
        "duration": 3.691,
        "text": "higher for the positive and the negative"
      },
      {
        "start": 1247.029,
        "duration": 4.89,
        "text": "because it wouldn't have those negative"
      },
      {
        "start": 1248.71,
        "duration": 5.37,
        "text": "words so here's just some important"
      },
      {
        "start": 1251.919,
        "duration": 4.89,
        "text": "links so that you could learn more about"
      },
      {
        "start": 1254.08,
        "duration": 5.13,
        "text": "Cassandra and spark and data stacks you"
      },
      {
        "start": 1256.809,
        "duration": 4.35,
        "text": "can also follow me on Twitter and our"
      },
      {
        "start": 1259.21,
        "duration": 4.769,
        "text": "team is just recently we're getting"
      },
      {
        "start": 1261.159,
        "duration": 4.89,
        "text": "involved with live demos on Twitch so"
      },
      {
        "start": 1263.979,
        "duration": 4.741,
        "text": "feel free to check that out like I said"
      },
      {
        "start": 1266.049,
        "duration": 4.74,
        "text": "this is on github and definitely check"
      },
      {
        "start": 1268.72,
        "duration": 5.48,
        "text": "out the data stacks Academy because all"
      },
      {
        "start": 1270.789,
        "duration": 3.411,
        "text": "this information is totally free"
      },
      {
        "start": 1276.55,
        "duration": 5.469,
        "text": "[Applause]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T05:47:16.680794+00:00"
}