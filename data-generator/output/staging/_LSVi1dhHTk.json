{
  "video_id": "_LSVi1dhHTk",
  "title": "Distributed Data Show Episode 16: Everything is Not a Graph Problem with Denise Gosnell",
  "description": "Denise Gosnell talks about working with Graph and why not every problem is a graph problem.\n\nABOUT DATASTAX ENTERPRISE 5\nDataStax Enterprise 5.0, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.0 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/datastax \nTwitter: https://twitter.com/datastax \nLinkedin: https://www.linkedin.com/company/datastax\nhttp://feeds.feedburner.com/datastax \nhttps://github.com/datastax \n\nABOUT DATASTAX ACADEMY\nOn the DataStax Academy YouTube channel, you can find tutorials, webinars and much more to help you learn and stay updated with the latest information on DataStax Enterprise©.  Create an account on https://academy.datastax.com to watch our free online courses, tutorials, and more.",
  "published_at": "2017-10-10T23:11:07Z",
  "thumbnail": "https://i.ytimg.com/vi/_LSVi1dhHTk/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "tutorial",
    "talk",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=_LSVi1dhHTk",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems welcome everyone to the distributed data show live in the studio in San Francisco today with me is do we hi Dom how are you today I'm fine so we have an exciting guest today boat joining us from lay waste wow that's a far away doctor Ganesa Denise Gosnell and I that's how I pronounced me was guys now I know there's multiple pronunciations but we're really excited to have you should just join data stacks recently super excited to get her on the show to talk about graph data and welcome to the show Denise yeah thank you I'm not really excited to be here looking forward to this discussion whatever ends up coming about it it will go in random directions I'm positive because I got you two on here that's just a preview if you're it will happen so Denise before we get too crazy why don't we level set who are you and why are you here tell us about yourself yeah so uh my my my first history started with a degree in mathematics and then after that I went in grad school and truth be told I was sitting there trying to register for classes after my master's in math my first semester and I got locked out of all the required classes and there's literally nothing left except for this one class called graph theory so I signed up is the only thing available plus some other kind of elective I go in there on the first day class expecting a whole semester of discussion about pie charts and like bar charts and the theory of maybe like data visualization or something like that and but lo and behold a graph theory has nothing to do with that and it has everything to do with modeling data with relationships and Persis and things like that so that's how I stumbled into this and it opened up my world to something I'm extremely passionate about and that I can talk about forever so after that I've continued on to get my PhD in computer science because at the University the graph theory was within that was within that department and afterwards I went to a start-up to build the health graph for the healthcare industry and that's kind of how I stumbled upon this group because I was using Titan at the time spent about a year and a half architecting and querying and really enjoying that project and afterwards I found that working here at theta stacks with natural fit to bring together my love for graphs and helping people be successful with building their own graph wow that's quite a story yeah it's funny cuz you mention that about graph if I wear a shirt with the word graph on it everybody thinks just that oh it's like pie charts and stuff no it's not and then yeah mom I don't want to explain it to you the the reality is is that we have a big education to do for the rest of the world but then again they don't know about relational databases either do they no and then that's even better when you're trying to describe the relationships of a graph versus a relational database and there's two words things getting mixed well we are really excited to have your data stacks because we like to think we collect all the smart people and here you are so you're you just up the IQ in the car so I you know you're gonna be doing this talk graph day and if anyone else it doesn't know that you should know this graph day in Seattle and you and I've talked about this quite a bit I think it's going to be a pretty dynamic talk for lack of a better word the thing that we we talked about which i think is so important and this is probably a bigger problem than the graph graph database world anyway you've seen this before everybody that comes that's new to graph comes and shows up gets super excited little over exuberant everything is a graph problem right oh so it's all graph right your rebuttal yeah so that's that's the theme of my talk I'm coming up here in a graph day Seattle I think October 20th 21st some time around then but essentially my my view of the space from a data science and a data modeler architect perspective is inherently not everything as a graph problem and as I see it and we'll kind of get into this but I see three buckets I see those problems that people are misclassifying as craft problems and they're really not graph problems and they're over here and then of the world of graph problem there's a lot of really interesting things to get in there but I I see that space kind of divided into two sections you've got you've got problems that are more like a graph database problem and then just a graph modelling a cool analytical approach to come up with a creative solution so those are the three buckets that's the way I see this world the things that are not and then within the things that are you have the database problems and then just to cool analytics problems and so I'll kind of be getting into that and talking about some of the issues that our eyes when you make assumptions with your architecture when you know you might not be going down the right path to begin with so then this tell us if you you choose the bad problem and you decide to apply the graph data model on a problem which is not a good fit what are the downsides yeah so the the immediate downsides you're gonna have or very similar to trying to fit a square peg in a round hole and what you're going to run into is a massive issue with expectations and performance there's going to be so many different ways you can attempt to model that graph problem there's going to exist a way to query it with Gremlin to get that answer mm-hmm at the end of the day the way that your performance is going to end up happening you're gonna have a bunch of under the hood OLAP entire global graph scans and you're really not gonna be able to get much out of answering that question because it's just not going to be performant or even return from an SLA perspective so for my from to really drill in and just say you know what's the downside it's it's going to be expectations on performance and you know really causing a massive problem with you know at the if the onset developer confusion around well how could you model this problem because there's going to be so much flexibility on how to squish it in telegraph yeah but when when you say that our performance expectation isn't it related to the implementation of the graph on the database suppose I will give you a counter example suppose your graph is so small right you have a graph okay but it's so small like 200 megabytes of data it can fit entirely in RAM in this case is performanced the real issue are even there another issues well so it also kind of depends with this problem so I kind of set this up by saying there's three buckets and this example you're bringing to me at this time I would kind of put that in the middle classification of sure it's a graph problem you've modeled it with the graph it's gonna fit in memory it's it's got some cool analytical application mm-hmm take a little bit for you to run your algorithm across the graph and for you to come up with a cool answer for whichever probably were solving hmm so there's gonna be gray area it's there's a little bit of a flow between one of these and the other and there's not some perfect answer but to me what you're describing is a cool graph allocation that you can fit in memory mm-hm it can fit on one machine there's no need to have a discussion for a globally distributed database that's completely separate problem okay and all of these these questions you can do in memory don't have it I mean have fun there's some really cool problems you can solve okay well how many times have we had this discussion with in any data problem where you have hey I'm gonna use spark and it's a single file are you just trying to show off that you can know you spark your because you know that that's not the problem anymore it's not you know if you if you have a petabyte of data to sort sparks great if you have a 200 mega file use grep yeah you know that's it's it's a different I think that's it is a problem that it's across every single field every single topic exuberant yeah we've all got multiple tools and our tools that we have can solve multiple problems and you can also just bring in the hammer and just slam it you can solve a bunch of stuff might not be necessary and and that's where you're gonna see a lot of cost these three buckets that I'm kind of having my theme with my theme there's gonna be some ebb and flow and you can make it work in one to the other but at the end of the day it really just depends on what you're trying to build mm-hmm what care about what questions you're really trying to answer and at the core of it what engineering problem you're really trying to solve so we talk about bad fits can you give us a typical example of good fit for graph database a very typical example so I don't know if you mean typical by I want you to tell me an exact problem but what I am gonna say is if your data and extracting useful information out of your data inherently relies on modeling relationships from one piece of your data to the other piece of data or some other data as soon as you see that as your fundamental engineering problem that is when you want to start stepping into the world of graphs if you are looking at your data and looking at your problem and you want to start to understand the distribution of say a few properties and maybe how a sliding scale on changing the value affects another distribution where we're starting to talk about global properties and how they're allocated across your data and that is not a graph problem that's trying to just understand fundamental properties about the data you have and how that may affect its its own distribution within that data set but that's but that's way different then if you have a user and that user has a relationship with something else in your data set another user or content or a product that relationship is what you want to model with about okay so I want to challenge you a little bit you said whenever the value of the data is in their relationship so it may be a good fit for graph data model but if I think back relational database we have the term relation right in the classical relational database we have by definition so even isn't it also a good fit for this kind of problem are you defining the good fit just by the use of the word relation yep so what I mean is what differs graph data modeling from relational database models because in relational database you can also model relationship basically yeah you can and the way the way I do see it again it depends on what you're trying to get back out of the data once you've put it into either of these models and when you want to get back out and understanding of that pie graph that kind of is from the beginning if you want a pie graph of the distributed key and its values throughout your set relational database model that's gonna be optimized for being able to grab and extract those insights on a little a little bit right there's a little hand weighting happening there but it's it's going to be able to be semi performed on answering those questions but that's but that's very different than if you want to be able to very granular ly describe just the relationships between one and another entertain your data that that has nothing to do with the values that that entity related relates or the values that that entity encompasses from you know different different types of keys and values within that entity it's all about taking that entity and looking at its edge to something else or its relationship to other items in your data in my hand that's completely separate and there really is a definitive line I don't know if I'm a particular you though it's particular for me so not tell us what are the fundamental biggest challenges in graph problems like the the issue that you face all the time on any data model so that I can do within two directions with that I I can go at it from a use case perspective on where people always start and the fundamental problems they have when they're starting yeah or I can kind of go with what are some of the really difficult engineering problems were having from the database perspective I'll give a high-level on both and just let me know and do we can again and then follow the rabbit to go with it so from from my experience like I mentioned previously I got started off into this specific graph database world wanting to look at the relationships across healthcare data and just like many people when they start they see the power of graphs they understand and they're hearing that the real value here is having an entity and getting it in that graph database or in that graph model and being out a model its relationship to another entity the inherent problem that they're forgetting and that you're not taking into account so that you can get there is being able to deduce or be able to resolve all of that oh the versions of that entity that you have across all of your data you could have a web app and you could have all these different instances of users that one individual user that you have and essentially every record of that user user is an immutable entity it's a thing this person existed and here's their data you can't wait the fact that that user was there but being able to look across all of your user data and resolve that oh these six instances of immutable data represent the same person these are over here they're the same person and this one guys all by himself that step of entity resolution needs to happen so you can get the power of modeling a single entity in its relationship to another single entity I think that's a problem that people skip over when they initially start looking at craft databases they'll slam some vertices and some image of edges in the graph and they start modeling they get it up and prod and they're inserting stuff and life is pg but then you might want to merge with another graph or you have another set of data that you need to get into this graph model and that's where things start getting really hairy being able to you know to do switch vertices are the same or which entities where wasn't the same thing that's difficult okay so basically yeah it's it's all about data cleaning and data classification before injecting them in a graph model right I don't want to make that strong an assertion because I also have found that there are some problems where graph models for doing identity D duping mm-hmm very successful application okay what I'm saying is that you need to consider the types of entity resolution you need to do upfront in order to understand this is my one person that I care about there are some graph models or there are some graphical approaches in which the relationships between MCS do kind of find that social fingerprint for you that that gets you that person you were looking for or there's a lot of more legacy systems around being curious about you know fat fingering last names into a database from 10 years ago and you just need to know how to close this name matches someone else's name so I'm not gonna go ahead and I'm not gonna say that yeah and see a resolution put it outside of a graph because eating within that space I see two different worlds of problems some are great for graphs some are not well there you have the old versus OLTP as well I mean that and I think that's the clear definition that we need to make is it OLTP workloads should be just that do not do not think you can get a faster OLAP to be OLTP exactly and that so when you first ask this question we kind of went down a hole on the on the problems I see that people have when they start setting up their use cases and I mentioned that there's two ways I can go and you've got the engineering problems and I think that kind of brings up what you're mentioning Patrick around olá P versus LTP there's a really interesting problem right now that has a lot of a lot of great minds thinking about it there's some research out there and and that problem is around when you're looking at the perspective of alright I've got a globally distributed graph by vertices and my edges are existing on servers all over the world in different partitions of Cassandra there's a very interesting graph problem that comes out of well how do you best partition your vertices so that when you're traversing your edges you're minimizing the number of servers that you're hopping to then give you a LTP performance because if you're traversing down a path of length 6 unless you have those vertices properly set up in a cassandra partition you could be hopping all over a bunch of different servers and then your SLA is our you know a little bit that problem of being able to cluster vertices inside certain groupings that are optimal to minimize that crossover between edges that current that graph partition partitioning problem from a theoretical perspective is an np-complete problem mm-hm we've got databases out there that need to know this today and so that's a very interesting thing I know that the engineers and all of the graph team here at data stacks is working on it's it's really great to get to be a part of that and we'll sue those conversations well I think dissolution as everything that is np-complete is quantum computing that'll that'll fix it right well if that happens then the entire internet is insecure so you've got other problems but I get an oil TB workload of my graph so I think I'm pretty happy with that meanwhile your financial data is everywhere yeah that's then my view the downside well I mean think you bring out a really good point though it is dara'a there is to quote no magic that is really about knowing your data you really there's still not a place where you just dump data in and hope for the best there's a there's a certain amount of knowledge you need to have about what you're doing nor is there one tool that if you put your data in that tool it's gonna solve all your problems right and that that does seem to be I see a lot of people looking for that lost city of gold that just doesn't exist you know their words Eldorado doesn't exist and hanging out here on the beach in Charleston well you guys all look for that you're gonna die in the jungle it's it is and I think it's a great you know it's a great Nirvana to think about maybe it exists but we we just need to be honest as computer scientists that this is not something that exists that weak we have a duty this is why we get paid to use intelligence when we pick data models and the data model is not optional and the tools that we use are not optional nor well are they forgiving there you're not going to give in to our will because we want that you know I'm not a three-year-old it's it will work the way it's supposed to work understand how it works understand how to data model with it your life will be a lot easier and you'll probably gainfully employed yeah I was thinking about one specific big challenge in a graph which is the the super node challenge right and because as a data modeler I'm helping customers every day and I can see this pattern come coming again and again not necessary only graph problem but also data modeling in customer problem let's say you have a general data set and 1% or less than 1% of your data we call this the earlier data mm-hmm they have huge cardinalities but only 1% right 99 order of your data is perfectly fine a small cardinality and the challenge for me as a data motor is okay should I accommodate all of my data model just to solve this one percent you know scenario of my data set because everything is trade-off so if I accommodate my data model to fit those just one percent of my data set it means that it had constrained extra constraint on my other 99 percent and so this is my my problem can I find a happy medium between okay solving this one percent and making the other 99 percent have you move let's talk about np-complete you can see we can see it from the theory perspective right oh you can see it from the engineering perspective yeah and I think this might be one of those topics that as I you know get my mind gate of stocks feet under me a little bit more it might be a good topic to kind of come back to because right now I kind of have this potentially too naive answer or look on that problem so who knows but the way I kind of see it at this stage is is that when you do have your super node problem it comes down to avoiding traversals or at least that's what I want to keep myself from doing traversing through that super node because that's when you get no matter talking about OLTP in a graph database or you just for solving fun problems mm-hmm when you traverse through it that's when it becomes a problem so from my naive perspective I would look at that and I would say all right well why why don't we make that a property that would give us the ability to lasso vertices with that property if we want mm-hmm but LTPS perspective we're obviously going to be starting with a very large number of vertices very large being pretty hand wavy but you're going to be starting a traversal from very large number of vertices and that's already gonna get you started on the wrong foot so I would look at while wanting to start from a different subset of properties maybe looking at how that property that has shared among those one percents in combination with another property starts to make it a little bit more granular so define I don't go so the baby yeah setting up an awesome cliffhanger mm-hmm and Denise this is great because I think this ends things really nicely is is the answer is I'm not really sure yet means that I would love to have you come back and tell us more well it is well our you know you said I am there are some things in my journey that I'm learning that would be helpful for others but you know currently underway and we would love for you to come back if you could come - I'm really looking forward to especially knowing if only I'm not even a full month in we're still looking at weeks and how long I've been here of the different types of knowledge buckets that I gained and other types of experience so yeah I'd love to you yeah that sounds great I mean because you you do we I really pointed out something is that there's there's some domain knowledge and things that are really interesting are they solving the problem or they not how do you solve it using data stacks products there's a lot to choose from I mean there's a lot of things you can do with it is it the right choice and I think that'd be really interesting yeah especially with good smart people talking about topics that are truthy we love the truthiness so I think the earthiness to the show so far and till somebody puts in the comments Denise is not truthy I'm sure we'll have that I really doubt but we do invite people to you know if you have a comment you bring it to the bring it to the YouTube channel or meet us on slack you're on you're on our Dave stacks Academy slack I'm sure if not we'll fix that there we have the DC graph slack Channel in in data stacks of Academy slack the data is a great place to interact with the people at data stacks doing graph all day eating it for breakfast it's on the spit roast for lunch it's all there I'm having it with a side of Cassandra and happens every day every day I like to throw a barbeque breakfast yeah all right well thank you very much for joining us today thank you and thank you everyone for joining us on the distributed data show and we will see you next time thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data stacks Academy and tell us what you think you can also find us on the data stacks Academy YouTube channel or find our podcast on iTunes Google Play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode you [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.37,
        "duration": 4.23,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.6,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 8.28,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 7.59,
        "text": "large-scale distributed systems welcome"
      },
      {
        "start": 16.74,
        "duration": 3.18,
        "text": "everyone to the distributed data show"
      },
      {
        "start": 18.24,
        "duration": 5.4,
        "text": "live in the studio in San Francisco"
      },
      {
        "start": 19.92,
        "duration": 6.48,
        "text": "today with me is do we hi Dom how are"
      },
      {
        "start": 23.64,
        "duration": 5.07,
        "text": "you today I'm fine so we have an"
      },
      {
        "start": 26.4,
        "duration": 6.6,
        "text": "exciting guest today boat joining us"
      },
      {
        "start": 28.71,
        "duration": 8.55,
        "text": "from lay waste wow that's a far away"
      },
      {
        "start": 33.0,
        "duration": 5.969,
        "text": "doctor Ganesa Denise Gosnell and I"
      },
      {
        "start": 37.26,
        "duration": 3.209,
        "text": "that's how I pronounced me was guys now"
      },
      {
        "start": 38.969,
        "duration": 3.481,
        "text": "I know there's multiple pronunciations"
      },
      {
        "start": 40.469,
        "duration": 4.641,
        "text": "but we're really excited to have you"
      },
      {
        "start": 42.45,
        "duration": 4.859,
        "text": "should just join data stacks recently"
      },
      {
        "start": 45.11,
        "duration": 5.949,
        "text": "super excited to get her on the show to"
      },
      {
        "start": 47.309,
        "duration": 5.761,
        "text": "talk about graph data and welcome to the"
      },
      {
        "start": 51.059,
        "duration": 3.451,
        "text": "show Denise yeah thank you I'm not"
      },
      {
        "start": 53.07,
        "duration": 3.03,
        "text": "really excited to be here looking"
      },
      {
        "start": 54.51,
        "duration": 3.869,
        "text": "forward to this discussion whatever ends"
      },
      {
        "start": 56.1,
        "duration": 4.38,
        "text": "up coming about it it will go in random"
      },
      {
        "start": 58.379,
        "duration": 5.131,
        "text": "directions I'm positive because I got"
      },
      {
        "start": 60.48,
        "duration": 6.66,
        "text": "you two on here that's just a preview if"
      },
      {
        "start": 63.51,
        "duration": 4.469,
        "text": "you're it will happen so Denise before"
      },
      {
        "start": 67.14,
        "duration": 3.12,
        "text": "we get too crazy"
      },
      {
        "start": 67.979,
        "duration": 3.271,
        "text": "why don't we level set who are you and"
      },
      {
        "start": 70.26,
        "duration": 5.219,
        "text": "why are you here"
      },
      {
        "start": 71.25,
        "duration": 6.93,
        "text": "tell us about yourself yeah so uh my my"
      },
      {
        "start": 75.479,
        "duration": 4.291,
        "text": "my first history started with a degree"
      },
      {
        "start": 78.18,
        "duration": 4.59,
        "text": "in mathematics and then after that I"
      },
      {
        "start": 79.77,
        "duration": 4.889,
        "text": "went in grad school and truth be told I"
      },
      {
        "start": 82.77,
        "duration": 4.68,
        "text": "was sitting there trying to register for"
      },
      {
        "start": 84.659,
        "duration": 4.381,
        "text": "classes after my master's in math my"
      },
      {
        "start": 87.45,
        "duration": 3.029,
        "text": "first semester and I got locked out of"
      },
      {
        "start": 89.04,
        "duration": 3.6,
        "text": "all the required classes and there's"
      },
      {
        "start": 90.479,
        "duration": 4.021,
        "text": "literally nothing left except for this"
      },
      {
        "start": 92.64,
        "duration": 3.72,
        "text": "one class called graph theory so I"
      },
      {
        "start": 94.5,
        "duration": 4.439,
        "text": "signed up is the only thing available"
      },
      {
        "start": 96.36,
        "duration": 4.35,
        "text": "plus some other kind of elective I go in"
      },
      {
        "start": 98.939,
        "duration": 4.5,
        "text": "there on the first day class expecting a"
      },
      {
        "start": 100.71,
        "duration": 5.28,
        "text": "whole semester of discussion about pie"
      },
      {
        "start": 103.439,
        "duration": 4.411,
        "text": "charts and like bar charts and the"
      },
      {
        "start": 105.99,
        "duration": 3.6,
        "text": "theory of maybe like data visualization"
      },
      {
        "start": 107.85,
        "duration": 4.229,
        "text": "or something like that and but lo and"
      },
      {
        "start": 109.59,
        "duration": 4.26,
        "text": "behold a graph theory has nothing to do"
      },
      {
        "start": 112.079,
        "duration": 3.601,
        "text": "with that and it has everything to do"
      },
      {
        "start": 113.85,
        "duration": 3.39,
        "text": "with modeling data with relationships"
      },
      {
        "start": 115.68,
        "duration": 4.2,
        "text": "and Persis and things like that so"
      },
      {
        "start": 117.24,
        "duration": 4.47,
        "text": "that's how I stumbled into this and it"
      },
      {
        "start": 119.88,
        "duration": 3.75,
        "text": "opened up my world to something I'm"
      },
      {
        "start": 121.71,
        "duration": 5.28,
        "text": "extremely passionate about and that I"
      },
      {
        "start": 123.63,
        "duration": 5.73,
        "text": "can talk about forever so after that"
      },
      {
        "start": 126.99,
        "duration": 3.84,
        "text": "I've continued on to get my PhD in"
      },
      {
        "start": 129.36,
        "duration": 2.34,
        "text": "computer science because at the"
      },
      {
        "start": 130.83,
        "duration": 3.57,
        "text": "University"
      },
      {
        "start": 131.7,
        "duration": 5.85,
        "text": "the graph theory was within that was"
      },
      {
        "start": 134.4,
        "duration": 5.55,
        "text": "within that department and afterwards I"
      },
      {
        "start": 137.55,
        "duration": 4.17,
        "text": "went to a start-up to build the health"
      },
      {
        "start": 139.95,
        "duration": 3.36,
        "text": "graph for the healthcare industry and"
      },
      {
        "start": 141.72,
        "duration": 3.36,
        "text": "that's kind of how I stumbled upon this"
      },
      {
        "start": 143.31,
        "duration": 3.69,
        "text": "group because I was using Titan at the"
      },
      {
        "start": 145.08,
        "duration": 4.14,
        "text": "time spent about a year and a half"
      },
      {
        "start": 147.0,
        "duration": 4.53,
        "text": "architecting and querying and really"
      },
      {
        "start": 149.22,
        "duration": 3.69,
        "text": "enjoying that project and afterwards I"
      },
      {
        "start": 151.53,
        "duration": 4.02,
        "text": "found that working here at theta stacks"
      },
      {
        "start": 152.91,
        "duration": 5.25,
        "text": "with natural fit to bring together my"
      },
      {
        "start": 155.55,
        "duration": 4.31,
        "text": "love for graphs and helping people be"
      },
      {
        "start": 158.16,
        "duration": 4.77,
        "text": "successful with building their own graph"
      },
      {
        "start": 159.86,
        "duration": 5.11,
        "text": "wow that's quite a story yeah it's funny"
      },
      {
        "start": 162.93,
        "duration": 3.889,
        "text": "cuz you mention that about graph if I"
      },
      {
        "start": 164.97,
        "duration": 4.53,
        "text": "wear a shirt with the word graph on it"
      },
      {
        "start": 166.819,
        "duration": 5.711,
        "text": "everybody thinks just that oh it's like"
      },
      {
        "start": 169.5,
        "duration": 4.92,
        "text": "pie charts and stuff no it's not"
      },
      {
        "start": 172.53,
        "duration": 5.25,
        "text": "and then yeah mom I don't want to"
      },
      {
        "start": 174.42,
        "duration": 5.52,
        "text": "explain it to you the the reality is is"
      },
      {
        "start": 177.78,
        "duration": 3.539,
        "text": "that we have a big education to do for"
      },
      {
        "start": 179.94,
        "duration": 2.519,
        "text": "the rest of the world but then again"
      },
      {
        "start": 181.319,
        "duration": 3.901,
        "text": "they don't know about relational"
      },
      {
        "start": 182.459,
        "duration": 4.11,
        "text": "databases either do they no and then"
      },
      {
        "start": 185.22,
        "duration": 3.15,
        "text": "that's even better when you're trying to"
      },
      {
        "start": 186.569,
        "duration": 3.841,
        "text": "describe the relationships of a graph"
      },
      {
        "start": 188.37,
        "duration": 5.67,
        "text": "versus a relational database and there's"
      },
      {
        "start": 190.41,
        "duration": 5.189,
        "text": "two words things getting mixed well we"
      },
      {
        "start": 194.04,
        "duration": 3.0,
        "text": "are really excited to have your data"
      },
      {
        "start": 195.599,
        "duration": 3.211,
        "text": "stacks because we like to think we"
      },
      {
        "start": 197.04,
        "duration": 4.319,
        "text": "collect all the smart people and here"
      },
      {
        "start": 198.81,
        "duration": 8.13,
        "text": "you are so you're you just up the IQ in"
      },
      {
        "start": 201.359,
        "duration": 9.241,
        "text": "the car so I you know you're gonna be"
      },
      {
        "start": 206.94,
        "duration": 5.16,
        "text": "doing this talk graph day and if anyone"
      },
      {
        "start": 210.6,
        "duration": 4.289,
        "text": "else it doesn't know that you should"
      },
      {
        "start": 212.1,
        "duration": 4.41,
        "text": "know this graph day in Seattle and you"
      },
      {
        "start": 214.889,
        "duration": 3.241,
        "text": "and I've talked about this quite a bit I"
      },
      {
        "start": 216.51,
        "duration": 3.979,
        "text": "think it's going to be a pretty dynamic"
      },
      {
        "start": 218.13,
        "duration": 5.97,
        "text": "talk for lack of a better word"
      },
      {
        "start": 220.489,
        "duration": 5.711,
        "text": "the thing that we we talked about which"
      },
      {
        "start": 224.1,
        "duration": 3.69,
        "text": "i think is so important and this is"
      },
      {
        "start": 226.2,
        "duration": 4.819,
        "text": "probably a bigger problem than the graph"
      },
      {
        "start": 227.79,
        "duration": 6.029,
        "text": "graph database world anyway"
      },
      {
        "start": 231.019,
        "duration": 5.171,
        "text": "you've seen this before everybody that"
      },
      {
        "start": 233.819,
        "duration": 5.76,
        "text": "comes that's new to graph comes and"
      },
      {
        "start": 236.19,
        "duration": 5.79,
        "text": "shows up gets super excited little over"
      },
      {
        "start": 239.579,
        "duration": 6.871,
        "text": "exuberant everything is a graph problem"
      },
      {
        "start": 241.98,
        "duration": 8.49,
        "text": "right oh so it's all graph right your"
      },
      {
        "start": 246.45,
        "duration": 6.48,
        "text": "rebuttal yeah so that's that's the theme"
      },
      {
        "start": 250.47,
        "duration": 5.73,
        "text": "of my talk I'm coming up here in a graph"
      },
      {
        "start": 252.93,
        "duration": 5.73,
        "text": "day Seattle I think October 20th 21st"
      },
      {
        "start": 256.2,
        "duration": 5.55,
        "text": "some time around then but essentially my"
      },
      {
        "start": 258.66,
        "duration": 4.98,
        "text": "my view of the space from a data science"
      },
      {
        "start": 261.75,
        "duration": 4.77,
        "text": "and a data modeler architect perspective"
      },
      {
        "start": 263.64,
        "duration": 6.39,
        "text": "is inherently not everything as a graph"
      },
      {
        "start": 266.52,
        "duration": 5.19,
        "text": "problem and as I see it and we'll kind"
      },
      {
        "start": 270.03,
        "duration": 4.74,
        "text": "of get into this but I see three buckets"
      },
      {
        "start": 271.71,
        "duration": 4.74,
        "text": "I see those problems that people are"
      },
      {
        "start": 274.77,
        "duration": 3.03,
        "text": "misclassifying as craft problems and"
      },
      {
        "start": 276.45,
        "duration": 3.72,
        "text": "they're really not graph problems and"
      },
      {
        "start": 277.8,
        "duration": 3.93,
        "text": "they're over here and then of the world"
      },
      {
        "start": 280.17,
        "duration": 3.36,
        "text": "of graph problem there's a lot of really"
      },
      {
        "start": 281.73,
        "duration": 4.14,
        "text": "interesting things to get in there but I"
      },
      {
        "start": 283.53,
        "duration": 4.98,
        "text": "I see that space kind of divided into"
      },
      {
        "start": 285.87,
        "duration": 3.96,
        "text": "two sections you've got you've got"
      },
      {
        "start": 288.51,
        "duration": 3.21,
        "text": "problems that are more like a graph"
      },
      {
        "start": 289.83,
        "duration": 5.01,
        "text": "database problem and then just a graph"
      },
      {
        "start": 291.72,
        "duration": 5.52,
        "text": "modelling a cool analytical approach to"
      },
      {
        "start": 294.84,
        "duration": 3.6,
        "text": "come up with a creative solution so"
      },
      {
        "start": 297.24,
        "duration": 2.64,
        "text": "those are the three buckets that's the"
      },
      {
        "start": 298.44,
        "duration": 3.75,
        "text": "way I see this world the things that are"
      },
      {
        "start": 299.88,
        "duration": 4.11,
        "text": "not and then within the things that are"
      },
      {
        "start": 302.19,
        "duration": 3.93,
        "text": "you have the database problems and then"
      },
      {
        "start": 303.99,
        "duration": 3.96,
        "text": "just to cool analytics problems and so"
      },
      {
        "start": 306.12,
        "duration": 4.23,
        "text": "I'll kind of be getting into that and"
      },
      {
        "start": 307.95,
        "duration": 4.02,
        "text": "talking about some of the issues that"
      },
      {
        "start": 310.35,
        "duration": 4.53,
        "text": "our eyes when you make assumptions with"
      },
      {
        "start": 311.97,
        "duration": 4.14,
        "text": "your architecture when you know you"
      },
      {
        "start": 314.88,
        "duration": 6.18,
        "text": "might not be going down the right path"
      },
      {
        "start": 316.11,
        "duration": 9.9,
        "text": "to begin with so then this tell us if"
      },
      {
        "start": 321.06,
        "duration": 7.98,
        "text": "you you choose the bad problem and you"
      },
      {
        "start": 326.01,
        "duration": 7.05,
        "text": "decide to apply the graph data model on"
      },
      {
        "start": 329.04,
        "duration": 7.71,
        "text": "a problem which is not a good fit what"
      },
      {
        "start": 333.06,
        "duration": 6.06,
        "text": "are the downsides yeah so the the"
      },
      {
        "start": 336.75,
        "duration": 3.96,
        "text": "immediate downsides you're gonna have or"
      },
      {
        "start": 339.12,
        "duration": 4.95,
        "text": "very similar to trying to fit a square"
      },
      {
        "start": 340.71,
        "duration": 4.8,
        "text": "peg in a round hole and what you're"
      },
      {
        "start": 344.07,
        "duration": 4.04,
        "text": "going to run into is a massive issue"
      },
      {
        "start": 345.51,
        "duration": 4.98,
        "text": "with expectations and performance"
      },
      {
        "start": 348.11,
        "duration": 4.15,
        "text": "there's going to be so many different"
      },
      {
        "start": 350.49,
        "duration": 4.8,
        "text": "ways you can attempt to model that graph"
      },
      {
        "start": 352.26,
        "duration": 5.25,
        "text": "problem there's going to exist a way to"
      },
      {
        "start": 355.29,
        "duration": 5.73,
        "text": "query it with Gremlin to get that answer"
      },
      {
        "start": 357.51,
        "duration": 5.43,
        "text": "mm-hmm at the end of the day the way"
      },
      {
        "start": 361.02,
        "duration": 3.39,
        "text": "that your performance is going to end up"
      },
      {
        "start": 362.94,
        "duration": 2.34,
        "text": "happening you're gonna have a bunch of"
      },
      {
        "start": 364.41,
        "duration": 4.49,
        "text": "under the hood"
      },
      {
        "start": 365.28,
        "duration": 5.639,
        "text": "OLAP entire global graph scans and"
      },
      {
        "start": 368.9,
        "duration": 3.43,
        "text": "you're really not gonna be able to get"
      },
      {
        "start": 370.919,
        "duration": 2.641,
        "text": "much out of answering that question"
      },
      {
        "start": 372.33,
        "duration": 4.08,
        "text": "because it's just not going to be"
      },
      {
        "start": 373.56,
        "duration": 6.12,
        "text": "performant or even return from an SLA"
      },
      {
        "start": 376.41,
        "duration": 4.65,
        "text": "perspective so for my from to really"
      },
      {
        "start": 379.68,
        "duration": 2.64,
        "text": "drill in and just say you know what's"
      },
      {
        "start": 381.06,
        "duration": 3.3,
        "text": "the downside it's it's going to be"
      },
      {
        "start": 382.32,
        "duration": 4.94,
        "text": "expectations on performance and you know"
      },
      {
        "start": 384.36,
        "duration": 6.57,
        "text": "really causing a massive problem with"
      },
      {
        "start": 387.26,
        "duration": 5.409,
        "text": "you know at the if the onset developer"
      },
      {
        "start": 390.93,
        "duration": 2.97,
        "text": "confusion around well how could you"
      },
      {
        "start": 392.669,
        "duration": 3.09,
        "text": "model this problem because there's going"
      },
      {
        "start": 393.9,
        "duration": 3.96,
        "text": "to be so much flexibility"
      },
      {
        "start": 395.759,
        "duration": 3.84,
        "text": "on how to squish it in telegraph yeah"
      },
      {
        "start": 397.86,
        "duration": 4.979,
        "text": "but when when you say that our"
      },
      {
        "start": 399.599,
        "duration": 5.97,
        "text": "performance expectation isn't it related"
      },
      {
        "start": 402.839,
        "duration": 4.86,
        "text": "to the implementation of the graph on"
      },
      {
        "start": 405.569,
        "duration": 5.07,
        "text": "the database suppose I will give you a"
      },
      {
        "start": 407.699,
        "duration": 5.701,
        "text": "counter example suppose your graph is so"
      },
      {
        "start": 410.639,
        "duration": 6.24,
        "text": "small right you have a graph okay but"
      },
      {
        "start": 413.4,
        "duration": 6.359,
        "text": "it's so small like 200 megabytes of data"
      },
      {
        "start": 416.879,
        "duration": 6.09,
        "text": "it can fit entirely in RAM in this case"
      },
      {
        "start": 419.759,
        "duration": 6.87,
        "text": "is performanced the real issue are even"
      },
      {
        "start": 422.969,
        "duration": 5.88,
        "text": "there another issues well so it also"
      },
      {
        "start": 426.629,
        "duration": 3.78,
        "text": "kind of depends with this problem so I"
      },
      {
        "start": 428.849,
        "duration": 3.63,
        "text": "kind of set this up by saying there's"
      },
      {
        "start": 430.409,
        "duration": 3.93,
        "text": "three buckets and this example you're"
      },
      {
        "start": 432.479,
        "duration": 4.5,
        "text": "bringing to me at this time I would kind"
      },
      {
        "start": 434.339,
        "duration": 4.651,
        "text": "of put that in the middle classification"
      },
      {
        "start": 436.979,
        "duration": 3.66,
        "text": "of sure it's a graph problem you've"
      },
      {
        "start": 438.99,
        "duration": 3.269,
        "text": "modeled it with the graph it's gonna fit"
      },
      {
        "start": 440.639,
        "duration": 3.93,
        "text": "in memory it's it's got some cool"
      },
      {
        "start": 442.259,
        "duration": 4.14,
        "text": "analytical application mm-hmm take a"
      },
      {
        "start": 444.569,
        "duration": 3.87,
        "text": "little bit for you to run your algorithm"
      },
      {
        "start": 446.399,
        "duration": 3.24,
        "text": "across the graph and for you to come up"
      },
      {
        "start": 448.439,
        "duration": 3.84,
        "text": "with a cool answer for whichever"
      },
      {
        "start": 449.639,
        "duration": 5.071,
        "text": "probably were solving hmm so there's"
      },
      {
        "start": 452.279,
        "duration": 5.22,
        "text": "gonna be gray area it's there's a little"
      },
      {
        "start": 454.71,
        "duration": 3.959,
        "text": "bit of a flow between one of these and"
      },
      {
        "start": 457.499,
        "duration": 3.061,
        "text": "the other and there's not some perfect"
      },
      {
        "start": 458.669,
        "duration": 4.65,
        "text": "answer but to me what you're describing"
      },
      {
        "start": 460.56,
        "duration": 3.509,
        "text": "is a cool graph allocation that you can"
      },
      {
        "start": 463.319,
        "duration": 3.541,
        "text": "fit in memory"
      },
      {
        "start": 464.069,
        "duration": 4.291,
        "text": "mm-hm it can fit on one machine there's"
      },
      {
        "start": 466.86,
        "duration": 3.299,
        "text": "no need to have a discussion for a"
      },
      {
        "start": 468.36,
        "duration": 5.16,
        "text": "globally distributed database that's"
      },
      {
        "start": 470.159,
        "duration": 5.31,
        "text": "completely separate problem okay and all"
      },
      {
        "start": 473.52,
        "duration": 4.29,
        "text": "of these these questions you can do in"
      },
      {
        "start": 475.469,
        "duration": 3.81,
        "text": "memory don't have it I mean have fun"
      },
      {
        "start": 477.81,
        "duration": 3.87,
        "text": "there's some really cool problems you"
      },
      {
        "start": 479.279,
        "duration": 5.7,
        "text": "can solve okay well how many times have"
      },
      {
        "start": 481.68,
        "duration": 6.299,
        "text": "we had this discussion with in any data"
      },
      {
        "start": 484.979,
        "duration": 8.31,
        "text": "problem where you have hey I'm gonna use"
      },
      {
        "start": 487.979,
        "duration": 6.99,
        "text": "spark and it's a single file are you"
      },
      {
        "start": 493.289,
        "duration": 4.68,
        "text": "just trying to show off that you can"
      },
      {
        "start": 494.969,
        "duration": 4.801,
        "text": "know you spark your because you know"
      },
      {
        "start": 497.969,
        "duration": 3.24,
        "text": "that that's not the problem anymore it's"
      },
      {
        "start": 499.77,
        "duration": 3.869,
        "text": "not you know if you if you have a"
      },
      {
        "start": 501.209,
        "duration": 6.21,
        "text": "petabyte of data to sort sparks great if"
      },
      {
        "start": 503.639,
        "duration": 6.03,
        "text": "you have a 200 mega file use grep yeah"
      },
      {
        "start": 507.419,
        "duration": 4.62,
        "text": "you know that's it's it's a different I"
      },
      {
        "start": 509.669,
        "duration": 5.67,
        "text": "think that's it is a problem that it's"
      },
      {
        "start": 512.039,
        "duration": 6.78,
        "text": "across every single field every single"
      },
      {
        "start": 515.339,
        "duration": 6.721,
        "text": "topic exuberant yeah we've all got"
      },
      {
        "start": 518.819,
        "duration": 4.83,
        "text": "multiple tools and our tools that we"
      },
      {
        "start": 522.06,
        "duration": 3.029,
        "text": "have can solve multiple problems and you"
      },
      {
        "start": 523.649,
        "duration": 3.87,
        "text": "can also just bring in the hammer and"
      },
      {
        "start": 525.089,
        "duration": 2.851,
        "text": "just slam it you can solve a bunch of"
      },
      {
        "start": 527.519,
        "duration": 3.391,
        "text": "stuff"
      },
      {
        "start": 527.94,
        "duration": 4.32,
        "text": "might not be necessary and and that's"
      },
      {
        "start": 530.91,
        "duration": 2.58,
        "text": "where you're gonna see a lot of cost"
      },
      {
        "start": 532.26,
        "duration": 3.6,
        "text": "these three buckets that I'm kind of"
      },
      {
        "start": 533.49,
        "duration": 3.81,
        "text": "having my theme with my theme there's"
      },
      {
        "start": 535.86,
        "duration": 3.81,
        "text": "gonna be some ebb and flow and you can"
      },
      {
        "start": 537.3,
        "duration": 3.48,
        "text": "make it work in one to the other but at"
      },
      {
        "start": 539.67,
        "duration": 2.07,
        "text": "the end of the day it really just"
      },
      {
        "start": 540.78,
        "duration": 3.45,
        "text": "depends on what you're trying to build"
      },
      {
        "start": 541.74,
        "duration": 4.98,
        "text": "mm-hmm what care about what questions"
      },
      {
        "start": 544.23,
        "duration": 4.05,
        "text": "you're really trying to answer and at"
      },
      {
        "start": 546.72,
        "duration": 4.05,
        "text": "the core of it what engineering problem"
      },
      {
        "start": 548.28,
        "duration": 6.45,
        "text": "you're really trying to solve so we talk"
      },
      {
        "start": 550.77,
        "duration": 8.22,
        "text": "about bad fits can you give us a typical"
      },
      {
        "start": 554.73,
        "duration": 8.31,
        "text": "example of good fit for graph database a"
      },
      {
        "start": 558.99,
        "duration": 5.49,
        "text": "very typical example so I don't know if"
      },
      {
        "start": 563.04,
        "duration": 3.87,
        "text": "you mean typical by I want you to tell"
      },
      {
        "start": 564.48,
        "duration": 7.08,
        "text": "me an exact problem but what I am gonna"
      },
      {
        "start": 566.91,
        "duration": 6.03,
        "text": "say is if your data and extracting"
      },
      {
        "start": 571.56,
        "duration": 4.37,
        "text": "useful information out of your data"
      },
      {
        "start": 572.94,
        "duration": 5.67,
        "text": "inherently relies on modeling"
      },
      {
        "start": 575.93,
        "duration": 4.54,
        "text": "relationships from one piece of your"
      },
      {
        "start": 578.61,
        "duration": 4.68,
        "text": "data to the other piece of data or some"
      },
      {
        "start": 580.47,
        "duration": 4.56,
        "text": "other data as soon as you see that as"
      },
      {
        "start": 583.29,
        "duration": 3.03,
        "text": "your fundamental engineering problem"
      },
      {
        "start": 585.03,
        "duration": 4.68,
        "text": "that is when you want to start stepping"
      },
      {
        "start": 586.32,
        "duration": 5.19,
        "text": "into the world of graphs if you are"
      },
      {
        "start": 589.71,
        "duration": 2.94,
        "text": "looking at your data and looking at your"
      },
      {
        "start": 591.51,
        "duration": 5.46,
        "text": "problem and you want to start to"
      },
      {
        "start": 592.65,
        "duration": 7.02,
        "text": "understand the distribution of say a few"
      },
      {
        "start": 596.97,
        "duration": 5.73,
        "text": "properties and maybe how a sliding scale"
      },
      {
        "start": 599.67,
        "duration": 5.31,
        "text": "on changing the value affects another"
      },
      {
        "start": 602.7,
        "duration": 4.05,
        "text": "distribution where we're starting to"
      },
      {
        "start": 604.98,
        "duration": 4.5,
        "text": "talk about global properties and how"
      },
      {
        "start": 606.75,
        "duration": 4.56,
        "text": "they're allocated across your data and"
      },
      {
        "start": 609.48,
        "duration": 3.57,
        "text": "that is not a graph problem that's"
      },
      {
        "start": 611.31,
        "duration": 3.51,
        "text": "trying to just understand fundamental"
      },
      {
        "start": 613.05,
        "duration": 5.49,
        "text": "properties about the data you have and"
      },
      {
        "start": 614.82,
        "duration": 6.18,
        "text": "how that may affect its its own"
      },
      {
        "start": 618.54,
        "duration": 4.47,
        "text": "distribution within that data set but"
      },
      {
        "start": 621.0,
        "duration": 4.77,
        "text": "that's but that's way different then if"
      },
      {
        "start": 623.01,
        "duration": 4.56,
        "text": "you have a user and that user has a"
      },
      {
        "start": 625.77,
        "duration": 4.77,
        "text": "relationship with something else in your"
      },
      {
        "start": 627.57,
        "duration": 5.82,
        "text": "data set another user or content or a"
      },
      {
        "start": 630.54,
        "duration": 5.31,
        "text": "product that relationship is what you"
      },
      {
        "start": 633.39,
        "duration": 4.19,
        "text": "want to model with about okay so I want"
      },
      {
        "start": 635.85,
        "duration": 4.92,
        "text": "to challenge you a little bit you said"
      },
      {
        "start": 637.58,
        "duration": 5.23,
        "text": "whenever the value of the data is in"
      },
      {
        "start": 640.77,
        "duration": 4.68,
        "text": "their relationship so it may be a good"
      },
      {
        "start": 642.81,
        "duration": 5.34,
        "text": "fit for graph data model but if I think"
      },
      {
        "start": 645.45,
        "duration": 6.3,
        "text": "back relational database we have the"
      },
      {
        "start": 648.15,
        "duration": 5.88,
        "text": "term relation right in the classical"
      },
      {
        "start": 651.75,
        "duration": 2.85,
        "text": "relational database we have by"
      },
      {
        "start": 654.03,
        "duration": 4.02,
        "text": "definition"
      },
      {
        "start": 654.6,
        "duration": 4.929,
        "text": "so even isn't it also a good fit for"
      },
      {
        "start": 658.05,
        "duration": 4.51,
        "text": "this kind of problem"
      },
      {
        "start": 659.529,
        "duration": 6.331,
        "text": "are you defining the good fit just by"
      },
      {
        "start": 662.56,
        "duration": 6.81,
        "text": "the use of the word relation yep so what"
      },
      {
        "start": 665.86,
        "duration": 6.36,
        "text": "I mean is what differs graph data"
      },
      {
        "start": 669.37,
        "duration": 5.129,
        "text": "modeling from relational database models"
      },
      {
        "start": 672.22,
        "duration": 5.52,
        "text": "because in relational database you can"
      },
      {
        "start": 674.499,
        "duration": 6.5,
        "text": "also model relationship basically yeah"
      },
      {
        "start": 677.74,
        "duration": 5.31,
        "text": "you can and the way the way I do see it"
      },
      {
        "start": 680.999,
        "duration": 3.611,
        "text": "again it depends on what you're trying"
      },
      {
        "start": 683.05,
        "duration": 3.139,
        "text": "to get back out of the data once you've"
      },
      {
        "start": 684.61,
        "duration": 3.719,
        "text": "put it into either of these models and"
      },
      {
        "start": 686.189,
        "duration": 4.031,
        "text": "when you want to get back out and"
      },
      {
        "start": 688.329,
        "duration": 4.141,
        "text": "understanding of that pie graph that"
      },
      {
        "start": 690.22,
        "duration": 4.08,
        "text": "kind of is from the beginning if you"
      },
      {
        "start": 692.47,
        "duration": 4.159,
        "text": "want a pie graph of the distributed key"
      },
      {
        "start": 694.3,
        "duration": 4.32,
        "text": "and its values throughout your set"
      },
      {
        "start": 696.629,
        "duration": 3.76,
        "text": "relational database model that's gonna"
      },
      {
        "start": 698.62,
        "duration": 4.889,
        "text": "be optimized for being able to grab and"
      },
      {
        "start": 700.389,
        "duration": 4.62,
        "text": "extract those insights on a little a"
      },
      {
        "start": 703.509,
        "duration": 3.75,
        "text": "little bit right there's a little hand"
      },
      {
        "start": 705.009,
        "duration": 3.93,
        "text": "weighting happening there but it's it's"
      },
      {
        "start": 707.259,
        "duration": 4.111,
        "text": "going to be able to be semi performed on"
      },
      {
        "start": 708.939,
        "duration": 5.37,
        "text": "answering those questions but that's but"
      },
      {
        "start": 711.37,
        "duration": 7.29,
        "text": "that's very different than if you want"
      },
      {
        "start": 714.309,
        "duration": 8.611,
        "text": "to be able to very granular ly describe"
      },
      {
        "start": 718.66,
        "duration": 6.869,
        "text": "just the relationships between one and"
      },
      {
        "start": 722.92,
        "duration": 5.159,
        "text": "another entertain your data that that"
      },
      {
        "start": 725.529,
        "duration": 4.441,
        "text": "has nothing to do with the values that"
      },
      {
        "start": 728.079,
        "duration": 5.07,
        "text": "that entity related relates or the"
      },
      {
        "start": 729.97,
        "duration": 4.89,
        "text": "values that that entity encompasses from"
      },
      {
        "start": 733.149,
        "duration": 3.601,
        "text": "you know different different types of"
      },
      {
        "start": 734.86,
        "duration": 4.26,
        "text": "keys and values within that entity it's"
      },
      {
        "start": 736.75,
        "duration": 5.279,
        "text": "all about taking that entity and looking"
      },
      {
        "start": 739.12,
        "duration": 5.24,
        "text": "at its edge to something else or its"
      },
      {
        "start": 742.029,
        "duration": 5.04,
        "text": "relationship to other items in your data"
      },
      {
        "start": 744.36,
        "duration": 4.269,
        "text": "in my hand that's completely separate"
      },
      {
        "start": 747.069,
        "duration": 3.931,
        "text": "and there really is a definitive line I"
      },
      {
        "start": 748.629,
        "duration": 4.56,
        "text": "don't know if I'm a particular you"
      },
      {
        "start": 751.0,
        "duration": 6.6,
        "text": "though it's particular for me"
      },
      {
        "start": 753.189,
        "duration": 8.94,
        "text": "so not tell us what are the fundamental"
      },
      {
        "start": 757.6,
        "duration": 8.099,
        "text": "biggest challenges in graph problems"
      },
      {
        "start": 762.129,
        "duration": 9.361,
        "text": "like the the issue that you face all the"
      },
      {
        "start": 765.699,
        "duration": 7.531,
        "text": "time on any data model so that I can do"
      },
      {
        "start": 771.49,
        "duration": 5.31,
        "text": "within two directions"
      },
      {
        "start": 773.23,
        "duration": 6.269,
        "text": "with that I I can go at it from a use"
      },
      {
        "start": 776.8,
        "duration": 4.259,
        "text": "case perspective on where people always"
      },
      {
        "start": 779.499,
        "duration": 3.421,
        "text": "start and the fundamental problems they"
      },
      {
        "start": 781.059,
        "duration": 3.0,
        "text": "have when they're starting yeah or I can"
      },
      {
        "start": 782.92,
        "duration": 2.399,
        "text": "kind of go with what are some of the"
      },
      {
        "start": 784.059,
        "duration": 2.25,
        "text": "really difficult engineering problems"
      },
      {
        "start": 785.319,
        "duration": 3.39,
        "text": "were having from the database"
      },
      {
        "start": 786.309,
        "duration": 4.291,
        "text": "perspective I'll give a high-level on"
      },
      {
        "start": 788.709,
        "duration": 2.631,
        "text": "both and just let me know and do we can"
      },
      {
        "start": 790.6,
        "duration": 5.3,
        "text": "again"
      },
      {
        "start": 791.34,
        "duration": 8.46,
        "text": "and then follow the rabbit to go with it"
      },
      {
        "start": 795.9,
        "duration": 6.18,
        "text": "so from from my experience like I"
      },
      {
        "start": 799.8,
        "duration": 3.96,
        "text": "mentioned previously I got started off"
      },
      {
        "start": 802.08,
        "duration": 4.56,
        "text": "into this specific graph database world"
      },
      {
        "start": 803.76,
        "duration": 5.82,
        "text": "wanting to look at the relationships"
      },
      {
        "start": 806.64,
        "duration": 5.22,
        "text": "across healthcare data and just like"
      },
      {
        "start": 809.58,
        "duration": 4.17,
        "text": "many people when they start they see the"
      },
      {
        "start": 811.86,
        "duration": 4.32,
        "text": "power of graphs they understand and"
      },
      {
        "start": 813.75,
        "duration": 4.44,
        "text": "they're hearing that the real value here"
      },
      {
        "start": 816.18,
        "duration": 3.39,
        "text": "is having an entity and getting it in"
      },
      {
        "start": 818.19,
        "duration": 2.52,
        "text": "that graph database or in that graph"
      },
      {
        "start": 819.57,
        "duration": 4.019,
        "text": "model and being out a model its"
      },
      {
        "start": 820.71,
        "duration": 4.2,
        "text": "relationship to another entity the"
      },
      {
        "start": 823.589,
        "duration": 3.661,
        "text": "inherent problem that they're forgetting"
      },
      {
        "start": 824.91,
        "duration": 5.28,
        "text": "and that you're not taking into account"
      },
      {
        "start": 827.25,
        "duration": 6.27,
        "text": "so that you can get there is being able"
      },
      {
        "start": 830.19,
        "duration": 5.61,
        "text": "to deduce or be able to resolve all of"
      },
      {
        "start": 833.52,
        "duration": 5.22,
        "text": "that oh the versions of that entity that"
      },
      {
        "start": 835.8,
        "duration": 5.19,
        "text": "you have across all of your data you"
      },
      {
        "start": 838.74,
        "duration": 3.9,
        "text": "could have a web app and you could have"
      },
      {
        "start": 840.99,
        "duration": 3.69,
        "text": "all these different instances of users"
      },
      {
        "start": 842.64,
        "duration": 4.199,
        "text": "that one individual user that you have"
      },
      {
        "start": 844.68,
        "duration": 4.71,
        "text": "and essentially every record of that"
      },
      {
        "start": 846.839,
        "duration": 4.921,
        "text": "user user is an immutable entity it's a"
      },
      {
        "start": 849.39,
        "duration": 4.59,
        "text": "thing this person existed and here's"
      },
      {
        "start": 851.76,
        "duration": 4.89,
        "text": "their data you can't wait the fact that"
      },
      {
        "start": 853.98,
        "duration": 4.7,
        "text": "that user was there but being able to"
      },
      {
        "start": 856.65,
        "duration": 5.189,
        "text": "look across all of your user data and"
      },
      {
        "start": 858.68,
        "duration": 5.409,
        "text": "resolve that oh these six instances of"
      },
      {
        "start": 861.839,
        "duration": 3.931,
        "text": "immutable data represent the same person"
      },
      {
        "start": 864.089,
        "duration": 3.261,
        "text": "these are over here they're the same"
      },
      {
        "start": 865.77,
        "duration": 5.16,
        "text": "person and this one guys all by himself"
      },
      {
        "start": 867.35,
        "duration": 6.37,
        "text": "that step of entity resolution needs to"
      },
      {
        "start": 870.93,
        "duration": 4.5,
        "text": "happen so you can get the power of"
      },
      {
        "start": 873.72,
        "duration": 3.83,
        "text": "modeling a single entity in its"
      },
      {
        "start": 875.43,
        "duration": 4.38,
        "text": "relationship to another single entity I"
      },
      {
        "start": 877.55,
        "duration": 4.0,
        "text": "think that's a problem that people skip"
      },
      {
        "start": 879.81,
        "duration": 3.36,
        "text": "over when they initially start looking"
      },
      {
        "start": 881.55,
        "duration": 2.91,
        "text": "at craft databases they'll slam some"
      },
      {
        "start": 883.17,
        "duration": 2.88,
        "text": "vertices and some image of edges in the"
      },
      {
        "start": 884.46,
        "duration": 3.0,
        "text": "graph and they start modeling they get"
      },
      {
        "start": 886.05,
        "duration": 3.539,
        "text": "it up and prod and they're inserting"
      },
      {
        "start": 887.46,
        "duration": 3.57,
        "text": "stuff and life is pg"
      },
      {
        "start": 889.589,
        "duration": 4.261,
        "text": "but then you might want to merge with"
      },
      {
        "start": 891.03,
        "duration": 5.91,
        "text": "another graph or you have another set of"
      },
      {
        "start": 893.85,
        "duration": 4.98,
        "text": "data that you need to get into this"
      },
      {
        "start": 896.94,
        "duration": 3.93,
        "text": "graph model and that's where things"
      },
      {
        "start": 898.83,
        "duration": 4.02,
        "text": "start getting really hairy being able to"
      },
      {
        "start": 900.87,
        "duration": 3.42,
        "text": "you know to do switch vertices are the"
      },
      {
        "start": 902.85,
        "duration": 4.05,
        "text": "same or which entities where wasn't the"
      },
      {
        "start": 904.29,
        "duration": 4.799,
        "text": "same thing that's difficult okay so"
      },
      {
        "start": 906.9,
        "duration": 5.91,
        "text": "basically yeah it's it's all about data"
      },
      {
        "start": 909.089,
        "duration": 6.711,
        "text": "cleaning and data classification before"
      },
      {
        "start": 912.81,
        "duration": 5.399,
        "text": "injecting them in a graph model right I"
      },
      {
        "start": 915.8,
        "duration": 5.92,
        "text": "don't want to make that strong an"
      },
      {
        "start": 918.209,
        "duration": 4.171,
        "text": "assertion because I also have found that"
      },
      {
        "start": 921.72,
        "duration": 3.0,
        "text": "there are"
      },
      {
        "start": 922.38,
        "duration": 7.61,
        "text": "some problems where graph models for"
      },
      {
        "start": 924.72,
        "duration": 8.37,
        "text": "doing identity D duping mm-hmm very"
      },
      {
        "start": 929.99,
        "duration": 5.8,
        "text": "successful application okay what I'm"
      },
      {
        "start": 933.09,
        "duration": 5.07,
        "text": "saying is that you need to consider the"
      },
      {
        "start": 935.79,
        "duration": 5.49,
        "text": "types of entity resolution you need to"
      },
      {
        "start": 938.16,
        "duration": 5.61,
        "text": "do upfront in order to understand this"
      },
      {
        "start": 941.28,
        "duration": 4.23,
        "text": "is my one person that I care about there"
      },
      {
        "start": 943.77,
        "duration": 3.24,
        "text": "are some graph models or there are some"
      },
      {
        "start": 945.51,
        "duration": 4.68,
        "text": "graphical approaches in which the"
      },
      {
        "start": 947.01,
        "duration": 4.86,
        "text": "relationships between MCS do kind of"
      },
      {
        "start": 950.19,
        "duration": 3.69,
        "text": "find that social fingerprint for you"
      },
      {
        "start": 951.87,
        "duration": 5.1,
        "text": "that that gets you that person you were"
      },
      {
        "start": 953.88,
        "duration": 5.58,
        "text": "looking for or there's a lot of more"
      },
      {
        "start": 956.97,
        "duration": 5.25,
        "text": "legacy systems around being curious"
      },
      {
        "start": 959.46,
        "duration": 5.04,
        "text": "about you know fat fingering last names"
      },
      {
        "start": 962.22,
        "duration": 4.05,
        "text": "into a database from 10 years ago and"
      },
      {
        "start": 964.5,
        "duration": 5.76,
        "text": "you just need to know how to close this"
      },
      {
        "start": 966.27,
        "duration": 5.34,
        "text": "name matches someone else's name so I'm"
      },
      {
        "start": 970.26,
        "duration": 2.91,
        "text": "not gonna go ahead and I'm not gonna say"
      },
      {
        "start": 971.61,
        "duration": 2.76,
        "text": "that yeah and see a resolution put it"
      },
      {
        "start": 973.17,
        "duration": 3.03,
        "text": "outside of a graph because eating within"
      },
      {
        "start": 974.37,
        "duration": 4.59,
        "text": "that space I see two different worlds of"
      },
      {
        "start": 976.2,
        "duration": 3.96,
        "text": "problems some are great for graphs some"
      },
      {
        "start": 978.96,
        "duration": 3.9,
        "text": "are not well there you have the old"
      },
      {
        "start": 980.16,
        "duration": 4.17,
        "text": "versus OLTP as well I mean that and I"
      },
      {
        "start": 982.86,
        "duration": 3.84,
        "text": "think that's the clear definition that"
      },
      {
        "start": 984.33,
        "duration": 6.12,
        "text": "we need to make is it OLTP workloads"
      },
      {
        "start": 986.7,
        "duration": 6.44,
        "text": "should be just that do not do not think"
      },
      {
        "start": 990.45,
        "duration": 5.37,
        "text": "you can get a faster OLAP to be OLTP"
      },
      {
        "start": 993.14,
        "duration": 5.44,
        "text": "exactly and that so when you first ask"
      },
      {
        "start": 995.82,
        "duration": 5.91,
        "text": "this question we kind of went down a"
      },
      {
        "start": 998.58,
        "duration": 4.29,
        "text": "hole on the on the problems I see that"
      },
      {
        "start": 1001.73,
        "duration": 2.4,
        "text": "people have when they start setting up"
      },
      {
        "start": 1002.87,
        "duration": 3.36,
        "text": "their use cases and I mentioned that"
      },
      {
        "start": 1004.13,
        "duration": 3.81,
        "text": "there's two ways I can go and you've got"
      },
      {
        "start": 1006.23,
        "duration": 2.67,
        "text": "the engineering problems and I think"
      },
      {
        "start": 1007.94,
        "duration": 1.92,
        "text": "that kind of brings up what you're"
      },
      {
        "start": 1008.9,
        "duration": 4.05,
        "text": "mentioning Patrick around"
      },
      {
        "start": 1009.86,
        "duration": 5.49,
        "text": "olá P versus LTP there's a really"
      },
      {
        "start": 1012.95,
        "duration": 4.71,
        "text": "interesting problem right now that has a"
      },
      {
        "start": 1015.35,
        "duration": 3.66,
        "text": "lot of a lot of great minds thinking"
      },
      {
        "start": 1017.66,
        "duration": 4.41,
        "text": "about it there's some research out there"
      },
      {
        "start": 1019.01,
        "duration": 5.069,
        "text": "and and that problem is around when"
      },
      {
        "start": 1022.07,
        "duration": 3.24,
        "text": "you're looking at the perspective of"
      },
      {
        "start": 1024.079,
        "duration": 4.11,
        "text": "alright I've got a globally distributed"
      },
      {
        "start": 1025.31,
        "duration": 4.889,
        "text": "graph by vertices and my edges are"
      },
      {
        "start": 1028.189,
        "duration": 4.281,
        "text": "existing on servers all over the world"
      },
      {
        "start": 1030.199,
        "duration": 5.551,
        "text": "in different partitions of Cassandra"
      },
      {
        "start": 1032.47,
        "duration": 5.17,
        "text": "there's a very interesting graph problem"
      },
      {
        "start": 1035.75,
        "duration": 4.829,
        "text": "that comes out of well how do you best"
      },
      {
        "start": 1037.64,
        "duration": 4.23,
        "text": "partition your vertices so that when"
      },
      {
        "start": 1040.579,
        "duration": 2.701,
        "text": "you're traversing your edges you're"
      },
      {
        "start": 1041.87,
        "duration": 4.23,
        "text": "minimizing the number of servers that"
      },
      {
        "start": 1043.28,
        "duration": 5.58,
        "text": "you're hopping to then give you a LTP"
      },
      {
        "start": 1046.1,
        "duration": 5.61,
        "text": "performance because if you're traversing"
      },
      {
        "start": 1048.86,
        "duration": 4.29,
        "text": "down a path of length 6 unless you have"
      },
      {
        "start": 1051.71,
        "duration": 3.75,
        "text": "those vertices properly set up in a"
      },
      {
        "start": 1053.15,
        "duration": 3.21,
        "text": "cassandra partition you could be hopping"
      },
      {
        "start": 1055.46,
        "duration": 3.39,
        "text": "all over a bunch of different"
      },
      {
        "start": 1056.36,
        "duration": 6.42,
        "text": "servers and then your SLA is our you"
      },
      {
        "start": 1058.85,
        "duration": 8.43,
        "text": "know a little bit that problem of being"
      },
      {
        "start": 1062.78,
        "duration": 6.18,
        "text": "able to cluster vertices inside certain"
      },
      {
        "start": 1067.28,
        "duration": 4.14,
        "text": "groupings that are optimal to minimize"
      },
      {
        "start": 1068.96,
        "duration": 3.75,
        "text": "that crossover between edges that"
      },
      {
        "start": 1071.42,
        "duration": 2.61,
        "text": "current that graph partition"
      },
      {
        "start": 1072.71,
        "duration": 3.51,
        "text": "partitioning problem from a theoretical"
      },
      {
        "start": 1074.03,
        "duration": 5.25,
        "text": "perspective is an np-complete problem"
      },
      {
        "start": 1076.22,
        "duration": 4.829,
        "text": "mm-hm we've got databases out there that"
      },
      {
        "start": 1079.28,
        "duration": 2.91,
        "text": "need to know this today and so that's a"
      },
      {
        "start": 1081.049,
        "duration": 3.901,
        "text": "very interesting thing I know that the"
      },
      {
        "start": 1082.19,
        "duration": 4.65,
        "text": "engineers and all of the graph team here"
      },
      {
        "start": 1084.95,
        "duration": 3.15,
        "text": "at data stacks is working on it's it's"
      },
      {
        "start": 1086.84,
        "duration": 3.51,
        "text": "really great to get to be a part of that"
      },
      {
        "start": 1088.1,
        "duration": 4.47,
        "text": "and we'll sue those conversations well I"
      },
      {
        "start": 1090.35,
        "duration": 5.61,
        "text": "think dissolution as everything that is"
      },
      {
        "start": 1092.57,
        "duration": 6.03,
        "text": "np-complete is quantum computing that'll"
      },
      {
        "start": 1095.96,
        "duration": 4.29,
        "text": "that'll fix it right well if that"
      },
      {
        "start": 1098.6,
        "duration": 3.41,
        "text": "happens then the entire internet is"
      },
      {
        "start": 1100.25,
        "duration": 4.74,
        "text": "insecure so you've got other problems"
      },
      {
        "start": 1102.01,
        "duration": 6.21,
        "text": "but I get an oil TB workload of my graph"
      },
      {
        "start": 1104.99,
        "duration": 3.23,
        "text": "so I think I'm pretty happy with that"
      },
      {
        "start": 1108.73,
        "duration": 2.59,
        "text": "meanwhile your financial data is"
      },
      {
        "start": 1110.66,
        "duration": 2.37,
        "text": "everywhere"
      },
      {
        "start": 1111.32,
        "duration": 2.849,
        "text": "yeah that's then my view the downside"
      },
      {
        "start": 1113.03,
        "duration": 4.26,
        "text": "well I mean think you bring out a really"
      },
      {
        "start": 1114.169,
        "duration": 7.021,
        "text": "good point though it is dara'a there is"
      },
      {
        "start": 1117.29,
        "duration": 5.7,
        "text": "to quote no magic that is really about"
      },
      {
        "start": 1121.19,
        "duration": 4.53,
        "text": "knowing your data you really there's"
      },
      {
        "start": 1122.99,
        "duration": 4.38,
        "text": "still not a place where you just dump"
      },
      {
        "start": 1125.72,
        "duration": 3.42,
        "text": "data in and hope for the best"
      },
      {
        "start": 1127.37,
        "duration": 3.03,
        "text": "there's a there's a certain amount of"
      },
      {
        "start": 1129.14,
        "duration": 4.26,
        "text": "knowledge you need to have about what"
      },
      {
        "start": 1130.4,
        "duration": 4.769,
        "text": "you're doing nor is there one tool that"
      },
      {
        "start": 1133.4,
        "duration": 3.75,
        "text": "if you put your data in that tool it's"
      },
      {
        "start": 1135.169,
        "duration": 5.701,
        "text": "gonna solve all your problems right and"
      },
      {
        "start": 1137.15,
        "duration": 5.159,
        "text": "that that does seem to be I see a lot of"
      },
      {
        "start": 1140.87,
        "duration": 4.11,
        "text": "people looking for that lost city of"
      },
      {
        "start": 1142.309,
        "duration": 6.021,
        "text": "gold that just doesn't exist you know"
      },
      {
        "start": 1144.98,
        "duration": 5.189,
        "text": "their words Eldorado doesn't exist and"
      },
      {
        "start": 1148.33,
        "duration": 3.16,
        "text": "hanging out here on the beach in"
      },
      {
        "start": 1150.169,
        "duration": 8.581,
        "text": "Charleston well you guys all look for"
      },
      {
        "start": 1151.49,
        "duration": 9.42,
        "text": "that you're gonna die in the jungle it's"
      },
      {
        "start": 1158.75,
        "duration": 3.9,
        "text": "it is and I think it's a great you know"
      },
      {
        "start": 1160.91,
        "duration": 5.04,
        "text": "it's a great Nirvana to think about"
      },
      {
        "start": 1162.65,
        "duration": 5.519,
        "text": "maybe it exists but we we just need to"
      },
      {
        "start": 1165.95,
        "duration": 4.29,
        "text": "be honest as computer scientists that"
      },
      {
        "start": 1168.169,
        "duration": 5.071,
        "text": "this is not something that exists that"
      },
      {
        "start": 1170.24,
        "duration": 5.88,
        "text": "weak we have a duty this is why we get"
      },
      {
        "start": 1173.24,
        "duration": 4.74,
        "text": "paid to use intelligence when we pick"
      },
      {
        "start": 1176.12,
        "duration": 4.02,
        "text": "data models and the data model is not"
      },
      {
        "start": 1177.98,
        "duration": 3.76,
        "text": "optional and the tools that we use are"
      },
      {
        "start": 1180.14,
        "duration": 4.33,
        "text": "not optional nor"
      },
      {
        "start": 1181.74,
        "duration": 5.61,
        "text": "well are they forgiving there you're not"
      },
      {
        "start": 1184.47,
        "duration": 3.959,
        "text": "going to give in to our will because we"
      },
      {
        "start": 1187.35,
        "duration": 4.41,
        "text": "want that you know I'm not a"
      },
      {
        "start": 1188.429,
        "duration": 5.22,
        "text": "three-year-old it's it will work the way"
      },
      {
        "start": 1191.76,
        "duration": 2.37,
        "text": "it's supposed to work understand how it"
      },
      {
        "start": 1193.649,
        "duration": 2.191,
        "text": "works"
      },
      {
        "start": 1194.13,
        "duration": 3.75,
        "text": "understand how to data model with it"
      },
      {
        "start": 1195.84,
        "duration": 5.839,
        "text": "your life will be a lot easier and"
      },
      {
        "start": 1197.88,
        "duration": 9.539,
        "text": "you'll probably gainfully employed yeah"
      },
      {
        "start": 1201.679,
        "duration": 8.081,
        "text": "I was thinking about one specific big"
      },
      {
        "start": 1207.419,
        "duration": 4.89,
        "text": "challenge in a graph which is the the"
      },
      {
        "start": 1209.76,
        "duration": 4.08,
        "text": "super node challenge right and because"
      },
      {
        "start": 1212.309,
        "duration": 3.84,
        "text": "as a data modeler"
      },
      {
        "start": 1213.84,
        "duration": 4.89,
        "text": "I'm helping customers every day and I"
      },
      {
        "start": 1216.149,
        "duration": 5.28,
        "text": "can see this pattern come coming again"
      },
      {
        "start": 1218.73,
        "duration": 4.439,
        "text": "and again not necessary only graph"
      },
      {
        "start": 1221.429,
        "duration": 3.961,
        "text": "problem but also data modeling in"
      },
      {
        "start": 1223.169,
        "duration": 7.201,
        "text": "customer problem let's say you have a"
      },
      {
        "start": 1225.39,
        "duration": 8.25,
        "text": "general data set and 1% or less than 1%"
      },
      {
        "start": 1230.37,
        "duration": 6.59,
        "text": "of your data we call this the earlier"
      },
      {
        "start": 1233.64,
        "duration": 7.649,
        "text": "data mm-hmm they have huge cardinalities"
      },
      {
        "start": 1236.96,
        "duration": 7.15,
        "text": "but only 1% right 99 order of your data"
      },
      {
        "start": 1241.289,
        "duration": 6.151,
        "text": "is perfectly fine a small cardinality"
      },
      {
        "start": 1244.11,
        "duration": 8.13,
        "text": "and the challenge for me as a data motor"
      },
      {
        "start": 1247.44,
        "duration": 7.38,
        "text": "is okay should I accommodate all of my"
      },
      {
        "start": 1252.24,
        "duration": 7.14,
        "text": "data model just to solve this one"
      },
      {
        "start": 1254.82,
        "duration": 7.62,
        "text": "percent you know scenario of my data set"
      },
      {
        "start": 1259.38,
        "duration": 6.0,
        "text": "because everything is trade-off so if I"
      },
      {
        "start": 1262.44,
        "duration": 5.91,
        "text": "accommodate my data model to fit those"
      },
      {
        "start": 1265.38,
        "duration": 5.909,
        "text": "just one percent of my data set it means"
      },
      {
        "start": 1268.35,
        "duration": 7.549,
        "text": "that it had constrained extra constraint"
      },
      {
        "start": 1271.289,
        "duration": 8.701,
        "text": "on my other 99 percent and so this is my"
      },
      {
        "start": 1275.899,
        "duration": 6.76,
        "text": "my problem can I find a happy medium"
      },
      {
        "start": 1279.99,
        "duration": 6.799,
        "text": "between okay solving this one percent"
      },
      {
        "start": 1282.659,
        "duration": 9.601,
        "text": "and making the other 99 percent have you"
      },
      {
        "start": 1286.789,
        "duration": 7.541,
        "text": "move let's talk about np-complete you"
      },
      {
        "start": 1292.26,
        "duration": 4.32,
        "text": "can see we can see it from the theory"
      },
      {
        "start": 1294.33,
        "duration": 4.02,
        "text": "perspective right oh you can see it from"
      },
      {
        "start": 1296.58,
        "duration": 4.53,
        "text": "the engineering perspective"
      },
      {
        "start": 1298.35,
        "duration": 5.49,
        "text": "yeah and I think this might be one of"
      },
      {
        "start": 1301.11,
        "duration": 4.23,
        "text": "those topics that as I you know get my"
      },
      {
        "start": 1303.84,
        "duration": 3.18,
        "text": "mind gate of stocks feet under me a"
      },
      {
        "start": 1305.34,
        "duration": 3.959,
        "text": "little bit more it might be a good topic"
      },
      {
        "start": 1307.02,
        "duration": 5.07,
        "text": "to kind of come back to because right"
      },
      {
        "start": 1309.299,
        "duration": 6.73,
        "text": "now I kind of have this potentially too"
      },
      {
        "start": 1312.09,
        "duration": 6.61,
        "text": "naive answer or look on that problem"
      },
      {
        "start": 1316.029,
        "duration": 7.53,
        "text": "so who knows but the way I kind of see"
      },
      {
        "start": 1318.7,
        "duration": 7.199,
        "text": "it at this stage is is that when you do"
      },
      {
        "start": 1323.559,
        "duration": 5.401,
        "text": "have your super node problem it comes"
      },
      {
        "start": 1325.899,
        "duration": 4.921,
        "text": "down to avoiding traversals or at least"
      },
      {
        "start": 1328.96,
        "duration": 3.629,
        "text": "that's what I want to keep myself from"
      },
      {
        "start": 1330.82,
        "duration": 3.719,
        "text": "doing traversing through that super node"
      },
      {
        "start": 1332.589,
        "duration": 4.351,
        "text": "because that's when you get no matter"
      },
      {
        "start": 1334.539,
        "duration": 4.89,
        "text": "talking about OLTP in a graph database"
      },
      {
        "start": 1336.94,
        "duration": 3.299,
        "text": "or you just for solving fun problems"
      },
      {
        "start": 1339.429,
        "duration": 2.61,
        "text": "mm-hmm"
      },
      {
        "start": 1340.239,
        "duration": 4.05,
        "text": "when you traverse through it that's when"
      },
      {
        "start": 1342.039,
        "duration": 3.87,
        "text": "it becomes a problem so from my naive"
      },
      {
        "start": 1344.289,
        "duration": 3.84,
        "text": "perspective I would look at that and I"
      },
      {
        "start": 1345.909,
        "duration": 5.13,
        "text": "would say all right well why why don't"
      },
      {
        "start": 1348.129,
        "duration": 4.98,
        "text": "we make that a property that would give"
      },
      {
        "start": 1351.039,
        "duration": 5.64,
        "text": "us the ability to lasso vertices with"
      },
      {
        "start": 1353.109,
        "duration": 5.82,
        "text": "that property if we want mm-hmm but LTPS"
      },
      {
        "start": 1356.679,
        "duration": 4.11,
        "text": "perspective we're obviously going to be"
      },
      {
        "start": 1358.929,
        "duration": 3.63,
        "text": "starting with a very large number of"
      },
      {
        "start": 1360.789,
        "duration": 3.81,
        "text": "vertices very large being pretty hand"
      },
      {
        "start": 1362.559,
        "duration": 5.04,
        "text": "wavy but you're going to be starting a"
      },
      {
        "start": 1364.599,
        "duration": 4.56,
        "text": "traversal from very large number of"
      },
      {
        "start": 1367.599,
        "duration": 5.01,
        "text": "vertices and that's already gonna get"
      },
      {
        "start": 1369.159,
        "duration": 5.13,
        "text": "you started on the wrong foot so I would"
      },
      {
        "start": 1372.609,
        "duration": 3.721,
        "text": "look at while wanting to start from a"
      },
      {
        "start": 1374.289,
        "duration": 4.98,
        "text": "different subset of properties maybe"
      },
      {
        "start": 1376.33,
        "duration": 4.579,
        "text": "looking at how that property that has"
      },
      {
        "start": 1379.269,
        "duration": 3.691,
        "text": "shared among those one percents in"
      },
      {
        "start": 1380.909,
        "duration": 5.47,
        "text": "combination with another property starts"
      },
      {
        "start": 1382.96,
        "duration": 6.389,
        "text": "to make it a little bit more granular so"
      },
      {
        "start": 1386.379,
        "duration": 6.03,
        "text": "define I don't go so the baby yeah"
      },
      {
        "start": 1389.349,
        "duration": 5.25,
        "text": "setting up an awesome cliffhanger mm-hmm"
      },
      {
        "start": 1392.409,
        "duration": 5.161,
        "text": "and Denise this is great because I think"
      },
      {
        "start": 1394.599,
        "duration": 5.101,
        "text": "this ends things really nicely is is the"
      },
      {
        "start": 1397.57,
        "duration": 3.989,
        "text": "answer is I'm not really sure yet means"
      },
      {
        "start": 1399.7,
        "duration": 9.329,
        "text": "that I would love to have you come back"
      },
      {
        "start": 1401.559,
        "duration": 9.57,
        "text": "and tell us more well it is well our you"
      },
      {
        "start": 1409.029,
        "duration": 3.81,
        "text": "know you said I am there are some things"
      },
      {
        "start": 1411.129,
        "duration": 4.11,
        "text": "in my journey that I'm learning that"
      },
      {
        "start": 1412.839,
        "duration": 6.54,
        "text": "would be helpful for others but you know"
      },
      {
        "start": 1415.239,
        "duration": 6.9,
        "text": "currently underway and we would love for"
      },
      {
        "start": 1419.379,
        "duration": 4.86,
        "text": "you to come back if you could come - I'm"
      },
      {
        "start": 1422.139,
        "duration": 3.6,
        "text": "really looking forward to especially"
      },
      {
        "start": 1424.239,
        "duration": 2.79,
        "text": "knowing if only I'm not even a full"
      },
      {
        "start": 1425.739,
        "duration": 8.07,
        "text": "month in we're still looking at weeks"
      },
      {
        "start": 1427.029,
        "duration": 9.27,
        "text": "and how long I've been here of the"
      },
      {
        "start": 1433.809,
        "duration": 3.72,
        "text": "different types of knowledge buckets"
      },
      {
        "start": 1436.299,
        "duration": 2.79,
        "text": "that I gained and other types of"
      },
      {
        "start": 1437.529,
        "duration": 4.53,
        "text": "experience so yeah I'd love to you yeah"
      },
      {
        "start": 1439.089,
        "duration": 5.52,
        "text": "that sounds great I mean because you you"
      },
      {
        "start": 1442.059,
        "duration": 4.56,
        "text": "do we I really pointed out something is"
      },
      {
        "start": 1444.609,
        "duration": 3.48,
        "text": "that there's there's some domain"
      },
      {
        "start": 1446.619,
        "duration": 2.511,
        "text": "knowledge and things that are really"
      },
      {
        "start": 1448.089,
        "duration": 2.661,
        "text": "interesting"
      },
      {
        "start": 1449.13,
        "duration": 4.38,
        "text": "are they solving the problem or they not"
      },
      {
        "start": 1450.75,
        "duration": 4.59,
        "text": "how do you solve it using data stacks"
      },
      {
        "start": 1453.51,
        "duration": 3.39,
        "text": "products there's a lot to choose from I"
      },
      {
        "start": 1455.34,
        "duration": 3.96,
        "text": "mean there's a lot of things you can do"
      },
      {
        "start": 1456.9,
        "duration": 4.29,
        "text": "with it is it the right choice and I"
      },
      {
        "start": 1459.3,
        "duration": 4.08,
        "text": "think that'd be really interesting yeah"
      },
      {
        "start": 1461.19,
        "duration": 4.8,
        "text": "especially with good smart people"
      },
      {
        "start": 1463.38,
        "duration": 3.47,
        "text": "talking about topics that are truthy we"
      },
      {
        "start": 1465.99,
        "duration": 7.62,
        "text": "love the truthiness"
      },
      {
        "start": 1466.85,
        "duration": 8.59,
        "text": "so I think the earthiness to the show so"
      },
      {
        "start": 1473.61,
        "duration": 5.43,
        "text": "far and till somebody puts in the"
      },
      {
        "start": 1475.44,
        "duration": 8.37,
        "text": "comments Denise is not truthy I'm sure"
      },
      {
        "start": 1479.04,
        "duration": 6.48,
        "text": "we'll have that I really doubt but we do"
      },
      {
        "start": 1483.81,
        "duration": 3.81,
        "text": "invite people to you know if you have a"
      },
      {
        "start": 1485.52,
        "duration": 4.74,
        "text": "comment you bring it to the bring it to"
      },
      {
        "start": 1487.62,
        "duration": 4.32,
        "text": "the YouTube channel or meet us on slack"
      },
      {
        "start": 1490.26,
        "duration": 3.75,
        "text": "you're on you're on our Dave stacks"
      },
      {
        "start": 1491.94,
        "duration": 5.64,
        "text": "Academy slack I'm sure if not we'll fix"
      },
      {
        "start": 1494.01,
        "duration": 7.2,
        "text": "that there we have the DC graph slack"
      },
      {
        "start": 1497.58,
        "duration": 5.85,
        "text": "Channel in in data stacks of Academy"
      },
      {
        "start": 1501.21,
        "duration": 4.98,
        "text": "slack the data is a great place to"
      },
      {
        "start": 1503.43,
        "duration": 5.01,
        "text": "interact with the people at data stacks"
      },
      {
        "start": 1506.19,
        "duration": 4.2,
        "text": "doing graph all day eating it for"
      },
      {
        "start": 1508.44,
        "duration": 3.3,
        "text": "breakfast it's on the spit roast for"
      },
      {
        "start": 1510.39,
        "duration": 4.41,
        "text": "lunch it's all there"
      },
      {
        "start": 1511.74,
        "duration": 8.49,
        "text": "I'm having it with a side of Cassandra"
      },
      {
        "start": 1514.8,
        "duration": 7.83,
        "text": "and happens every day every day I like"
      },
      {
        "start": 1520.23,
        "duration": 3.57,
        "text": "to throw a barbeque breakfast yeah all"
      },
      {
        "start": 1522.63,
        "duration": 5.82,
        "text": "right well thank you very much for"
      },
      {
        "start": 1523.8,
        "duration": 6.09,
        "text": "joining us today thank you and thank you"
      },
      {
        "start": 1528.45,
        "duration": 3.66,
        "text": "everyone for joining us on the"
      },
      {
        "start": 1529.89,
        "duration": 5.1,
        "text": "distributed data show and we will see"
      },
      {
        "start": 1532.11,
        "duration": 4.92,
        "text": "you next time thank you for joining us"
      },
      {
        "start": 1534.99,
        "duration": 3.57,
        "text": "again for the distributed data show we"
      },
      {
        "start": 1537.03,
        "duration": 3.21,
        "text": "love your feedback so go to the"
      },
      {
        "start": 1538.56,
        "duration": 3.09,
        "text": "distributed data show page on data"
      },
      {
        "start": 1540.24,
        "duration": 3.3,
        "text": "stacks Academy and tell us what you"
      },
      {
        "start": 1541.65,
        "duration": 4.29,
        "text": "think you can also find us on the data"
      },
      {
        "start": 1543.54,
        "duration": 4.53,
        "text": "stacks Academy YouTube channel or find"
      },
      {
        "start": 1545.94,
        "duration": 4.59,
        "text": "our podcast on iTunes Google Play or"
      },
      {
        "start": 1548.07,
        "duration": 4.41,
        "text": "wherever you get great podcast while"
      },
      {
        "start": 1550.53,
        "duration": 4.32,
        "text": "you're there make sure and subscribe so"
      },
      {
        "start": 1552.48,
        "duration": 2.89,
        "text": "you don't miss a single episode"
      },
      {
        "start": 1554.85,
        "duration": 3.63,
        "text": "you"
      },
      {
        "start": 1555.37,
        "duration": 3.11,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T07:12:38.468838+00:00"
}