{
  "video_id": "Soav9mgRv5Q",
  "title": "Running a Spark job on Apache Cassandra‚Ñ¢",
  "description": "üèÜüèÜüèÜ MENTIMETER:\ncode=28 46 40 9 , LINK=https://www.menti.com/tqkagnb1fj\n\nüìÑ SLIDES/MATERIALS: \nhttps://github.com/Anant/cassandra.realtime\n\nüîî Sign up to our event alert:\nhttps://bit.ly/subscribe-datastaxdevs\n\nüí¨ CHAT = DISCORD, ask questions live: \nhttps://bit.ly/cassandra-workshop\n\n‚ùìFORUM = QUESTIONS during the week community.datastax.com : \nhttps://community.datastax.com\n\nSPECIAL GUEST\n- Rahul Singh\nüßë‚Äçü§ù‚Äçüßë THE WORKSHOP TEAM\n- Cedrick LUNVEN (@clunven, https://www.linkedin.com/in/clunven/)\n- David GILARDI (@SonicDMG, https://www.linkedin.com/in/david-gilardi)\n- Aleksandr VOLOCHNEV (@HadesArchitect)\n- Eric ZIETLOW (@EricZietlow)\n- Erick RAMIREZ (@ErickRamirezAU)\n- Jack FRYER (https://www.linkedin.com/in/jack-fryer)\n\nüöÄ üöÄ ENJOY !! üöÄ üöÄ",
  "published_at": "2020-12-08T19:25:09Z",
  "thumbnail": "https://i.ytimg.com/vi/Soav9mgRv5Q/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "workshop",
    "cassandra",
    "datastax",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=Soav9mgRv5Q",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "good morning everybody good evening um can you hear us can you give us a thumb up if you hear us well please raul can you say something hey good afternoon good morning good evening wherever you're at so what about the sounds folks can we go on ah waiting for yes we all good okay so welcome welcome everybody for uh yet another workshop so this time this is the third of a series where we talk about event driven toolkit all prepared with loved by raul um i'm so happy to have you back with us today and we do have a lot to cover again today i guess right yes absolutely it's uh it's like we're trying to boil the ocean today well hopefully we won't [Laughter] of course not um so today we will discuss a lot about spark spike streaming kafka kasambha and astra so now raul you are sharing your screen and the presentation should be coming up in a second of course thank you google internet um there we go i can see it yes here we are right hey cedric thank you so much for having me again um to do the spark streaming um uh with kafka and we're actually gonna cover some spark batch as well i'm really excited um because you know spark is a well it's like a swiss army toolkit you can do everything with it um but when we combine it with spark sorry when we combine spark with cassandra and kafka we can do a little bit about myself i'm a ceo of a small consulting team um i've also helped create cassandra.link which is a knowledge base of all things cassandra and i maintain a um well it's a readme but basically the best resources that you should need to know about cassandra i curate and i have a couple other awesome ones as well um and these days uh since meetup groups are no longer in person that's cool like that to meet all experts this is the mentee code if you didn't know keep that yeah we we jump into mentee right away all good um so this is part of a series and you know the first couple of topics we covered um were basically you know what is what is rest how is that related to event driven uh systems uh we actually built an api on cassandra we'll quickly take a look at it and even though astro comes with its own rest api and graphql api uh you know a lot of times you want to do some processing before we save it into uh cassandra so that's why we have our own custom api in python and node then the next webinar we did was how to use kafka in different ways to event source the information for a particular event and then use a processor to process that event information using a consumer um we actually connected kafka to cassandra using kafka connect and in case streams and today we're going to connect kafka to cassandra with spark streaming once the data is in spark sorry in cassandra we'll do some special processing this setup of cassandra spark and kafka is a very very basic setup and our goal is to give you a toolkit um today we're gonna review basically you know the kafka setup uh the kazandra setup that we have in our git pod uh we'll make sure that those uh you know systems are up and running uh you know if you want to follow this uh we're assuming that you've done this uh you know the other two webinars with us before and you have the casino api and you can spend real time get pods up and running with an astra account if you don't that's okay just follow me just follow along just watch what i'm doing all of this stuff as you'll notice is on github and you can do this anytime um and uh if you haven't used github before you'll see that i'm doing everything in the browser you don't have to you don't have to download any code and run it on your computer it's going to select some information and it's going to materialize a a table in cassandra and once data is in that table and actually looking at another data set we're going to have a batch drop that takes all the data from cassandra crunches it and then saves it back into another table these are some basic patterns that we see in the kafka cassandra spark ecosystem generally that we end up using different ways to stream data into kafka we use different ways to stream data out from kafka into cassandra and when we need to do some really heavy crunching of information or analytics or machine learning we end up using spark hopefully at the end of today you're going to have a basic understanding of spark spark streaming in the context of cassandra and kafka and you'll know how to run you know streaming job and the spark gap checker i want to thank data sax for being a great sponsor and partner um and you know giving cassandra as a service for free so you don't have to set up your own uh cassandra for doing these events um and get pod uh thank you git pod uh i have my sticker that i got uh from you guys uh lucky you i need those stickers as well make this code they've given us free pro account so thank you for the sponsorship and then deloitte has also been helpful in beta testing this workshop in a couple of different times before we started doing it publicly uh what is an architect uh we had another architect platforms of cassandra and related technologies an architect is a chief builder in computing it's somebody who designs or makes things so we design and make stuff that basically runs on cassandra and spark and kafka which are related technologies um love scalable fast data like literally what we're talking about today cassandra's far kafka we love doing that that's what we love doing uh and we do things without data stacks with data stacks sometimes the technology is slightly different but ultimately spark cassandra and kafka can be done in open source or it can be done on cloud it can be done on premise uh with commercial support from companies like confluent and data stacks on different clouds but the common denominator is we love doing scalable fast data and that's what we're going to talk about today great go ahead cedric okay yeah so um as usual during this live workshop uh we are uh on youtube answering your question but and we try to answer your question on the spot but if you do have long form question troubleshooting you should be interested to use discord okay where we do also have expert analyzing what you are doing and you can go to breakout rooms and discuss if you are really stuck today we you know we used a mentee already so you know about that and so we will use cassandra kafka and spark so the data will be stored in astra i will explain you what it is and that's on the top you see the link to the runtime we will give you some times to register to abstract if you don't have any account yet it's a free tier you can go there is five gigabytes which is much much more than we need for today and we will use uh two github repo the link are also in the youtube descriptions but i probably will give you the link again on the youtube chat and we will use git pod against each repo because we need a lot of power you know kafka and spark is a lot of cpu and using git pod and the virtual id they provide us we do have one dedicated for the api and kafka and another one for for spark or one over the other i don't know how you split workloads in the two but we would need two rows so uh you know just so that the gift pot can get warmed up we're gonna go ahead and launch getpod and the way you launch it is you just go to um sorry go to the url so let me share the url with you all i copy the link in the chat right now boom and once you get um the cassandra real time up and running you'll notice two git pod buttons one is for cassandra.api which as i mentioned it's it's uh it's nice to have you don't necessarily need it for this but we're gonna verify that asteroids off using this api so you know control click this button to open the cassandra api and get pod and then what you're going to do is you're going to scroll down a little bit until you find the the second one to start this in real time i think that there we go where it says two yeah don't hesitate to make your screen you know the screen bigger on readme you know just increase the font size for everyone yeah let me do that right now yeah great looks like yeah it looks a little bit better um so when we bring up uh our github url in git pod all we're really doing is just saying hey open up um using this url it's going to first ask you to log in you can just use your github login um and what it'll do is it'll actually save that workspace it's building a container right now for us and pulling down our code and getting everything up and running um all on the web so we're gonna let this kind of bake in the background it takes a few minutes for it to start up and we're going to continue on with the rest of the presentation um the first section of the presentation we're going to talk about is you know why are we doing this this this code base that we're showing what is the purpose of this code base and i personally like to learn um you know programming or technology if i know where there's a reason behind it right um and wow google it's either my google or it's my internet um it's taking a second here i might just uh not do the full presentation though going forward yeah so you know when you open up git pod it's gonna look something like this it looks like basically uh visual studio it's not visual studio actually it's uh thea which is a open source clone of visual studio and um it's the it's the editor it's the server it's it's kind of everything uh all in one so why are we building this well right now we have a platform that helps us generate the cassandra link website and we have the ability to generate many many more websites because our knowledge base has probably 20 30 000 links in it the cassandra knowledge base has about 10 uh sorry i think it's about a thousand to 1500 links in it um but it's it's a platform where we curate knowledge and there's an admin screen there's a there's kind of like an advanced view to look at this on my and php and uh we have a mirror of that data in cassandra and we have a mirror of that data in solar and uh we wanted to make this scalable we wanted to to make this go bigger so what we decided was let's see if we can take this whole platform and make it serverless all right and so the front end of this application is using the jam stack and there's an amazing workshop happening tomorrow about react and the jam stack and the ceo of netflix will be there so we use netflify to host interfaces um both that talk to apis uh but also we generate using gatsby a full website so all of the 1500 pages plus they get generated out but it runs off of an api so we want to migrate that api this part of the system is already serverless because it's using burcell and netlify the search stacks is a hosted solar server list we don't really worry about it and right now we want to stop managing our own api we want to eventually go to astra because astro gives us basically an api in graphql it gives an api in rest it's going to have other cool stuff and if we have any particular special needs for an api we'll we'll probably host them on uh like a kubernetes managed kubernetes so that can be a serverless kubernetes we also want to make this event driven right now the system is not event driven the whole process of these these talks has been to show how do we build an event-driven system and then after data comes in event driven and it's updated event driven we also want to have some uh processing uh of the data itself and you'll you'll see what they what type of data it's websites right we want to do some special analysis of the website uh data uh and see if things are correlated using machine learning there are two git pods one which is a cassandra api and there's parity between leaves api python and leaves api node uh if you look at the code they're basically doing the same thing they're just slightly different um the uh the only reason we have an api separate from the astra api that already exists for you is that when we were first building this app that that rest api was not because we were one of the first users of astra um and then once it was out we realized that we still needed to do some custom scraping right so we still need to have our own api layer uh even if we use these even if we peggy back up with these we need to have our own the git pod we're looking at today uh in the last talk we covered the kafka aspects of it right so we run uh kafka broker we have a registry we have a rest proxy um we have uh you know kaka producers and consumers that can talk to this uh there's a kafka gui powered by akhq that'll show us the topics in there and today we're going to be looking at this right the stream process that takes data from kafka puts it into cassandra and a badge process that reads from cassandra processes it and puts it back into cassandra quick overview of rest versus microservices um if you haven't been here on this talk before this is either going to be too much information or it's going to be just right information i apologize we just want to give everybody a context microservices are you know loosely coupled they can be written in basically a variety of different ways people can coordinate them uh you know using asynchronous technologies like amqp protocol or kafka itself um or they can do everything synchronously using rest um and you know for us just looking back at this each of these things right here could be a microservice if we make it loosely coupled meaning this is not dependent on this and this is not dependent on this over here so what we have today at the end of today is you can consider this could be its own microservice this could be its own microservice as these apis and the stream process as well um the point being that we can do a combination of synchronous and asynchronous processing of events on the same platform the only thing that we generally don't follow from the conventional micro service thinking is that each service needs its own db and that's not true in the cassandra world the reason is that cassandra can scale to thousands and hundreds of thousands of servers and you can think about a key space or a table like its own kind of microservice that scales on its own so because we're on astra which can infinitely scale we don't have to worry about a different database or a different key space or table per microservice even though we're doing some of that here we're not going to make another aster database when we add new functionality we can just make another table so you know generally in in the cassandra world what you have is you can have one standard cluster and you can have several microservices being powered by different key spaces uh another cool thing about uh and this is more on the data stack side is that you can bring data into cassandra and retrieve it out as json and vice versa um in the later version of data stacks there's you know bsc graph 6.8 you can add data using graph queries and then retrieve data using cql yes so a word on the micro service maybe with cassandra you know you might have heard that uh in a micro service world there is one database per micro service to avoid any resource sharing and any coupling be in between the micro service and i would like to challenge a bit that so um first when you hear that um you cannot have the same database it's really not the same it doesn't mean it's should not be the same installation of the database okay as long as you can uh have a proper handling of your resource you know you're good to go and in cassandra in a cassandra cluster you can have first multiple data centers so depending on where you are where is your location you can have some nodes in azure some nodes in europe some nodes uh wherever you like to reduce the latencies so first you can split the workload in data centers that first fantastic then in casanova you have a key space which is like the schema for oracle and when it tends to do is one key space per micro service because at the key space level you will define where the key space live on which data centers how many times does the data is replicated stuff like that but not only that in case i can also split by tables okay in the tables there is no joy no integrity constraint and so what you do most of the time is have a dedicated table for your dedicated query that means a micro service in charge of a bounding business context would be in charge of a limited set of table and it's pretty clear to see what is the scope of this micro service because now you don't need to do joints or everything anything like that there is no joints in cassandra and so with the same cassandra cluster you can split by data center key space table query and then of course you still have airbag and when you execute when you fire a query against cassandra the load will be distributing among the nodes for you okay so the the coupling is minimal absolutely and uh i by the way what you just said you know cedric i have to explain the same thing every uh every time i've talked to somebody who's done microservices not on a scalable data store they've done you know with or mysql or postgres they always come back to well what about the devops aspect of this you know what about the the infrastructure i tell them look at cassandra as a infrastructure itself right and when you uh think about you know creating a new database on on database instance for my sql because it needs to be powered uh uh you know enough so it can scale and you can vertically scale that generally you're gonna have to start sharding that database on my sql if it starts to grow well with cassandra if you just think about that infinite data store at the key space level you can grow it as big as you want it doesn't really matter and from a devops perspective you can have key space blue key space green right if you wanted to do blue green or even at the table level you can have different schemas on the same table because you know uh cassandra it's it's a nosql uh columnar data store uh which means that you can have two schemas that don't overlap and that data is not replicated it's just whatever you're setting is going to get set on the content cluster we can go so much into that discussion but cassandra is awesome for uh for microservices jeff carpenter has an amazing article and a couple of videos about this as well i just google microservices on cassandra you'll find his article and even a book and if you saw the definitive guide of cassandra in the datastax.com website you would see a link to get a free copy of the book but you know for this one i won't give you the link go to the datasacks.com and look around look for a book and you will see a couple of books with freedom nick excellent so one of the patterns of software that people implement with microservices is event sourcing and cqrs um cqrs stands for command query uh request segregation uh also uh you know people say command query separation but basically it's a way to scale systems so when an update comes it's an event and a processor basically saves that data to um potentially different places one for the event itself uh one for where the data is going to be queried and for example if you were not using data stacks and you did not have a built-in search with dsc search and you needed to materialize that data in both you know cassandra and elasticsearch your event processor would take that event and it would save it in both places um and aster has a search index using the new advanced uh you know search sai but um it's it's not as powerful exact for example like elasticsearch leucine is a very very powerful search index so in that case you can still save to astro have some basic indices but then simultaneously save that into solar or elasticsearch or a third-party cloud provider like algolia or or swift type you name it there's so many different third-party cloud search providers now um the other is that when we uh update data and when we retrieve data those are seen as two different types of uh requests right when we retrieve data um we're getting a report we're getting a data set when we're updating data could be updating various different things um and especially in uh the nosql world um we often materialize different sets of data for fast fortune that's you know one of the data modeling uh trainings on data sex academy it talks about you know the ideal is to have one partition for query now that partition may have multiple rows but you may have multiple tables to represent different types of queries so using event sources thing we can send one event and then process it and save that data into several different places so let's talk a little bit about spark what is it uh you know how to use it why to use it when to use it um apache spark is uh probably the second or third generation at this point yeah it's a spark 3.0 now um and you know if you uh i'll show you at google trends uh you know apache spark is the de facto way to do big data now um you know pretty much you can do other types of uh technologies for fast data but spark is kind of the name there are a lot more people that still use sorry there's a lot of people that still use you know yarn and map reviews but you can use spark on top of hadoop so they're not mutually exclusive people use hadoop hdfs and then they use spark alongside it what is spark it's uh it's a collection of technologies just like kafka has a bunch of stuff that runs on top of it to make it kafka apache has essentially a core and on top of the core we have spark sql which is a hive compliant uh way to correct data in spark uh well how to get data in spark you bring it into a data frame or uh you can map a hive table or a spark sql table to like a cassandra data store and you can do queries on cassandra you can do joins on cassandra tables using spark spark streaming uh this has gone through a couple of different iterations it's a way to stream events off of various different types of queues uh you can also have structured streaming which means that when you get the event it looks like a table essentially and we're going to look at that code later we have machine learning built in and there are extensions to machine learning libraries that you can run on top of spark and then graph which now we have graph frames um basically to to do graph processing uh with uh like if you wanted to do the page rank algorithm you could do it in like five line in in graph uh on top of spark when we make a spark job what we're really doing is we're creating a directed acyclic graph a directed asymptotic graph you're going to find this term in several places things like airflow we'll talk about it but basically directed means it's one way right the graph is going one way there's no loops in the graph acyclic uh is uh sorry directed means that it has arrows there's there's not there's no two way but acyclic meaning that there's no loops in it and it's a graph it's it's nodes and edges so a we're creating a directed acyclic graph of the work that needs to be done and we do that by writing spark code spark actually does this work for us it makes this and what it does it figures out how much of this directed acyclic graph needs to be run on which computers so if we do it right we can have the same spark job running on one computer or we can have it running on 100 computers and that's the point at which spark becomes a you know cousin uh so to speak or or like a best friend of cassandra and kafka because kafka can scale to hundreds and thousands of servers cassandra can scale to thousands to hundreds of thousands of servers uh spark i think the biggest one i've seen is about a thousand node cluster of spark right and the other cool part about spark is that it can talk to a bunch of stuff we can talk to any data store that you're looking to connect to you can bring data in you can send it to these different systems um and you can represent this data on these different systems in a similar way in data frames or now data sets is a new term it's a unified analytics engine but i would say it's like a general purpose computing engine distributed computing engine where if you wanted to execute just tasks you could use spark but you may find something else is a little bit uh more lightweight spark has this heaviness to it which only makes sense if you're really going to do some big number crunching yes so um just just a word on the overlap architecture so uh we won't dig in too much today about data stacks enterprise the the enterprise product of the nsx but in the same node we do have cassandra and spark so that means if you need to scale so you can scale both at the same time and spark is what we call token aware so when spark need to distribute a computation around multiple nodes on cassandra because spark is aware of the token range it can start up the executor as you can see here in the slide exactly at the good place to get the computation local with the data and that's you know just the neat features of the saxon enterprise if you don't have that you can still do it but you do have a cluster for spark and a cluster of cassandra you can do that as an open source as well yeah datastax makes it too easy to do spark with cassandra like once you use it um but uh you know maybe we'll that's that's gonna be a follow-on you know how to use data stacks for all of this stuff but uh you know today yeah we're gonna talk about astro which is basically cassandra as a service and we're going to use spark uh but spark with cassandra on the same note is very very powerful um and you know before we we end i'll just show kind of a comparison between if you were to do this on your own how much work you'd have to do versus kind of using the data stacks ecosystem when we make a spark program generally we have a driver we have a cluster manager that allocates resources and then we have different workers so you'll see in when we bring up spark we're going to bring up the master and then we're going to that's going to be in standalone mode and we're going to bring up one worker right because we we have viet pod giving us roughly i think 16 gigs of ram which i'm impressed how much did we get and but if we wanted to we could have thousands of nodes running and as long as we connect the worker to that cluster manager that cluster manager will see that as a new worker um a couple of things so spark sql uh is a way to uh query data uh update and really join data from various different places it has a built-in optimizer that once you write spark sql it creates a spark job and it goes grabs the data and brings it back to you um you can think about a a data frame like if you've ever used um pant your pandas a data frame is like kind of like a database in memory uh and so spark when you deal with spark when you do operations on spark it doesn't do anything until you say like you know do this up basically there's transformations and there's actions um but ultimately it only does the work once you execute the you know group y or aggregate function or output function up until then it kind of keeps this you know dag but a data frame is a is a place where you can have multiple kind of tables uh in one object and you can do operations on the same thing um we're gonna look at data frames very briefly um but uh you know uh just remember that data frames are like the newer way of doing things rdds or resilient data sets are the older way of doing things and now there's something called data sets which is the newer or yet still way of doing things but all of these data frames rdds uh they're just representations of your data right when you connect to cassandra and you say i want to select from here what it does it it gets that data from cassandra and brings it into memory in spark that's the way spark does its work when you update that data frame and you say save it it first updates it in memory and then and it saves it back to xampp spark streaming is uh gone through as i mentioned earlier two different generations um spark streaming has two ways of doing things one is just basic spark streaming and another is structured streaming we're going to be doing structured streaming um the main thing about structured streaming is that it gives you a schema right when you're getting the event from your stream you're getting it as a row with columns with the named columns so you can do select from that stream and you can do spark sql transformations on that data before you send it through right um this is the type of stuff that's also available in kafka streams right with k tables um but when we're dealing with spark streamings and especially structure streaming you have the power of spark across hundreds of thousands of nodes where you can distribute the work if you need to a common use case for this would be you have a model like a machine learning model that you've made already and you ingest as a streamed event and you evaluate that data using your model in in spark and then you send it through and simultaneously what you can say is go ahead and update my model with my positive evaluation a couple of use cases uh you may have heard of these companies uh uber pinterest uh netflix ebay and viva um what you know what do people do with spark i mean everything tell me what they don't do with spark uh um know used to be that we would say you know etl is spark is not for etl and over time spark is used for etl all the time um so but people now do streaming etl they bring data in you know they'll do they'll do elt right extract it load it and then transform it which is kind of what we're gonna do today uh to enrich information after it sits somewhere um i mean it's it's got a lot of power um i can't do it justice in this workshop to tell you the power of spark um once you start using it you'll understand that it's it's not um you know it's not a kitty tool like it's not a toy it's got a lot of power just like cassandra in kafka you can use it but it's really powerful when you bring these things together uh and then finally you know the spark um ecosystem um is continues to grow there's a site called spark packages um you know where you can see just for the tags for data sources there's like 61 different data sources that you can connect to um you can also go to the site and use there's about 500 different packages just for spark right but if you are in the smart casing system without any of these packages if you're using scala any scholar libraries available for you any java library is available to you um there's also r if you're a statistician or a data scientist sometimes people use r versus where it says python same thing with python all the things that you can do in python you can do in spark you just have to think about the distributed computing nature uh meaning you don't want to have a long running process on every world i mean you think about it but you can do it and then recently uh c sharp and f sharp um which are basically.net languages uh they also have a binding for spark oh really i was not aware c sharp f shaft yeah uh it's been there for a while it used to be called mobius um and then now it's just called.net spark um and uh and then finally kotlin uh which is fairly new language compared to uh in the spark in south ascala um it's kind of new it's not it's kind of a release candidate right now but you know if you're into kotlin you can check it out um just remember that scala and python are the only supported languages to do uh read evaluate print loop meaning you can just start up a shell and start programming in spark and and see things happen um and then sql is available in a rupple as well uh in the spark sql shell as well as uh if you start the thrift server you can get data via jdbc so you can connect a business intelligence tool like tableau or click or power bi to a spark instance and imagine right you can bring all this data into spark and then it once it's in there you can look at it and you can do joins on it and view it via different tools spark also runs on basically anything so it runs on docker i mean we're going to be running it inside a git pod docker there's mesos kubernetes you know you can run it basically anywhere technology runs you can run spark because it's java it's a jvm system right and these are just different ways to organize the cluster uh just just if before switching if you go back uh so we told you that you can do gdbc over uh spark that's you know that's true sparks ql and gdbc drivers like simba for instance that's still a spark you know don't expect real time uh computation when you query a billion rows okay yes spark is mostly for you know in this use case mostly for olap queries and the response time is about in a few seconds even minute depending on the volume the computation is still distributed but there are still a lot of data to move over the wire here and there so it's cool for tableau but you know pre-computed dashboard you know yeah yeah and it depends on the bi tool that you use a lot of these tools will cache the results and they'll you know they'll pull the the spark sql to get this information um but uh you know if you have a lot of juice you have a lot of machinery a lot of memory you can get pretty fast results you just have to have like terabytes of memory in your cluster yeah yeah you need power you need power exactly um this i found interesting i just was curious uh to see you know spark versus uh big data versus you know machine learning you know how has it come in terms of how the world sees this stuff and you know notice that machine learning has always been around well not always it's been around and it was more popular than big data and spark right this only goes back to december 2008 but around i would say 2010 or 11 big data started to take off um way more was much more popular and then spark was like slow and steady and here it comes right here it comes and it's now more popular than big data and machine learning people can do with it without spark but i'm just just fascinated how spark as a term apache spark is a term is more popular than the term big data because we do big data with spark right uh really interesting which you can find on google trends no more pig or yeah no i've no no spark is everywhere yeah um so i said you're just going to talk a little bit about astra yeah so let's let's yeah yeah so can you move to the next slide yeah i think i would explain everything in a single slide so really astra in top your mind should be a data platform as a service available in the cloud with cassandra at the core and tons of tools to um you know to help you build up on top of customers so api monitoring you know web console i kind of ide to to to shape your queries stuff like that so it's eliminates all the operation because it's software as a service it's secure your data because now you access them through api and airbag and in simplify your development because you know with the api now you can use either a document api and use cassandra like or um you know don't do that in data modeling okay that's technically feasible or you know pretty easy to generate api on top of of tables and if you go to next slide now so yes so at the core yes you see um cassandra running multi-cloud okay when you will start your instance later uh on the free tier i think you are limited to google cloud but astra can run on any cloud okay and you can spawn some instance on the region you like and it's you know high availability of course that's the natures of cassandra and on top of the database there are some tools so astra is not only a database as a service it's really your platform so providing api rest graphql a console the studio data loader you know ds bulk and maybe and soon another tools coming and if you want to automate the you know provisioning of the database now you do have the devops api uh the database export the matrix and if you're really into kubernetes you may have heard that we push pretty hard the kate sandra initiative with cassandra running in kubernetes with the operator and all the tools i introduced in the beginning well now with the service broker you can tell kubernetes to spawn your cassandra instance directly into astra now that mean that was uh a service broker i mean exposing the resource needed for an external cube cluster to you know run the pod spawn the resource directly into astra that's amazing uh the whole service broker idea is cool yes having astra available in the in the cluster in the kubernetes cluster is really and you can create an instance for free five gigabyte free forever not limited in time and we will never ask you the credit card it's really free definitely definitely very cool stuff i think you went over this but um yeah very very quickly so you can yeah you can interact with with cassandra using the cassandra query language and this is what we did in the first session or using the api uh you do have the tools and look at all the drivers available so that's to communicate to you know native cql with cassandra in astra you now also have the api raised in graphql but hey drivers are still uh pretty efficient and you know most people still use the driver especially the java one definitely the the java one i think is probably the most widely used i mean cassandra spark connector uses you know it inside so definitely exactly it does also mean that you know the spark drivers works on astra you know everything's related because the spark drivers wrap the java drivers at this core and you know that explain what it works yep absolutely so let's go ahead and uh launch astra um so astra i have my own instance ready to go um and you know i'm just gonna bring up my my database manager um i can actually just log into a good way astro.dsx.com and yep yeah i wish you guys had that when i was testing it so i i i have a really old account i should probably connect my i like i like signing you with github i love science single sign-on you know i don't really want to remember another database um so when we bring when we bring up um the uh you know astra dashboard uh you'll notice you have the ability to have different databases you can have different organizations um i have a free tier um just remember that if you don't use it uh data stacks will automatically park the database parking means that it's just turned off um so you know whenever you come on if you haven't used the database you gotta unpark it so right now this the server is running um and once it's running um i can you know learn how to connect to it by clicking here it's gonna give me the endpoints it's gonna give me the environment variables i need to connect to it um the way we're connecting to uh astra for the work that we've been doing is via the drivers yep yep um and uh you know we have to download this secure certificate bundle yes and when we download it it's just a zip file um and um what we do is we upload that zip file into our git pod and it's really easy you just kind of drag it and drag and drop it in there and i've already done that i'll show it to you um but yeah that's a common yeah no no so so one might ask why do you need to download a zip file whereas when i log into cassandra i'm only providing ipport and user password well now you are using the cloud so we want to create a secure connection between you and i two were authenticated using strong authentication and certificates in the zip file you do have the certificate needed to open that two-way communication with astra and then we use some technical tips and tricks to do the same load balancing and distribution of the load you use with the java driver but in the cloud environment yeah and um you know there are probably every i mean any cassandra application that you use today uh you can port it to use astra as long as you make sure your connection is using this um you know zip file that's really what it comes down to um and you know we have code in node python and java in the in the code that i'm about to show you um and spark as well and the spark connectivity is basically the same way we connect to java right we have to give the same information um and um it actually is really easy um i initially it was like oh i thought the same thing said it goes like i have to download a zip file but it's really not that hard if you're doing any secure connectivity with cassandra you would need to have a search file anyways yes so this isn't really that different um so we have the astra up and running just to kind of revisit what we're trying to do before we go hands-on um so remember we're trying to take these apis and make them event driven we did it back in the last session what we're doing today is we're going to focus on uh this engine right here and we're going to do two things with this engine which is we're going to take a stream of um basically events meaning new uh resources coming in new url's being curated and we're going to save it to astra um well kafka connect and these other tools we've built before already save it to to astra what we're going to do is we're going to parse the same event and materialize a table called leaves by tag right so in cassandra if you do the data modeling course you'll note that depending on how you access data you can create a table so we have a query table called leaves by tag meaning give me all the urls buy a particular tag in native cassandra you know technically this particular type of query we could put a uh you know a secondary index or we could put an sai on it but normally um these things have their limits and i think the sai is much more performant but currently cassandra 3 cassandra 4 like you know they don't have the sai so assuming that we're going to be you know using the core cassandra technology here um more than likely we're going to go to production we would end up using this and we test the sai or we would materialize the information in solar to get these tag counts but we we have a table called leaves by tag that gets materialized in sync in real time and there's another table that we're going to create um which is called tags which is given the tag give me the tag count right so you can imagine one of those it's easy to say here's a new url it has tags already in there i need to just save and update this information in my leaves by tag that's one use case and that can happen on a real-time basis but if i need to update my tag count right and we have a bunch of different sources and a bunch of different streams coming in it probably makes sense to read all the data and understand what my true count is and then update my tags right and that's what we're going to do with the spark that job you saw this before this is the streaming process that's going to pick from the broker save to leafs by tag and then this is the process that's going to read from cassandra do some crunching and then save it back to cassandra uh i think we do have a question on the previous schema what what is the tag tail maybe that's the features on your schema right it is it is it's um you'll see it i'll show you the schema when we bring up um the data stack studio um yeah so there's basically only three tables we're dealing with three tables in this example one is called urls another one is called uh tags and uh one is called leaves by tag because internally we call all of the urls leaves um so you'll see it and i think you'll understand it's just like you know if you had a like a wordpress blog right you have tags and categories that's what it is it's just a tag to um organize the urls okay a business concept in your use case then yeah exactly um so anyways if you haven't signed up for astra you know the only things that you need after you create the astro database is really you know um your your database name your key space name your username and password remember because you have that certificate um even if i show you my password here you won't be able to get access to that database without my secure certificate bundle since i've already made the database in the previous workshop i'm not going to go through this exercise again but if you look at the nice work that my colleagues and cedric have done there is a really really amazing step-by-step uh you know screenshot by screenshot process on github on the center.api uh repo which shows you how to get started and actually i don't even think you need it like if you've used any cloud service uh it's pretty self-explanatory right create an account make a new database fill out some forms uh if you if you're starting off you're gonna get google cloud as cedric mentioned you know you make your database you give it some things um it's standard i don't think it's that complicated in fact the newer interface gets better and better and better every time i log into it yeah so we change the ui a little bit you should then be lost you know you should have to you should provide the database name the key space name user and password pretty easy and then you need to pick uh one tier pick the free tier and then pick a region and if you select the free tier you are limited to google i think google cloud so now you do have two region u.s wastes europe west or us east and you you can pick the one you like to reduce latency yep um and you know what uh other stuff do you get on astra it's not just the cassandra database we're going to be using datastack studio there's also a way to get access to cqlsh via the browser there's a grafana dashboard to see some basic metrics um so that's all built into the uh the astra interface so just like a quick view here right i can say launch studio and this is a kind of a um like a tightened version of dataset studio it just has you know marked down in cql um aspects that if you have datastax enterprise there are some other things you can do uh like gremlin and and spark sql uh but basically it's a way it's a notebook interface to set up tables like if you wanted to create a schema or to do queries and we're going to come back to this um the other really cool um interface here is your console which you can also connect you know if you wanted to from your own machine but if you're learning cassandra um and so at the same time we had a question from arjun likes you know we we keep saying astra is free and everything so you're asking okay about anything special about the paid and premier tea and then i like the question a lot so um with the free tier you are limited in capacity i mean you do have a couple of nodes and so you are limited in space and throughput you can achieve whereas if you jump to the to the premium mob now you do have the you know the capacity you will pay for capacity pay pay as you go and you can have you know as many node as you need and um you know even have advanced features like vpc peering if you already have nodes running somewhere you can pair those you know like vpc playing with the three the three cloud providers and you know much much more now free tier is really wide but not everything is open yeah and um you know like i look at astra and datastax is doing a tremendous job of basically open sourcing the different components that run astra like stargate you can get you can download stargate which is the rest in the graphql api you can download kate sandra because astra is basically cassandra on kubernetes being managed by data size so you know um you really have to do the cost benefit scenario right do i really want to set up a kubernetes cluster and kate sandra and i want to bring up stargate and i want to do like do i really want to do that i'm a cassandra expert all right i don't want to do that you know um i because right now for this project that we're showing it's a real project right like if you go to casino.link this is a real project that uh runs and it's the site is generated and it's got it gets a you know good amount of traffic we don't want to make right as experts we're just focusing on finding the best content so uh do i really want to be managing a database no does anybody want to be managing a database server no i mean no no so yeah it's worth it's worth looking into but the technologies that run astra you can approximate a lot more time and effort to do that um there's these resources by the way this deck and everything will be made possible i made made available on um the github repo we'll link it there as well as we'll have a blog post on the us but um you know there's tons and tons of resources um you know just a quick thing spark even though it's open source uh databricks does a hosted spark manage spark it's kind of like astra for spark right and it's got a nice little interface and everything it's really cool and there's a talk that one of my colleagues is doing um about how to use databricks community with data stacks astra so free and free right check it out and but there are other providers for spark as well amazon's aws elastic mapreduce basically is a hosted spark azure hd insight is a host that sparked by uh by microsoft and then google dataproc more recent is a host of spark slash hadoop in fact all of these are hadoop spark variants um and those are not the only ones right so you can use cloudera you can use i mean there's so many different ways to run spark way more than i think to run cassandra ibm has a lot of good material on spark as well they're a big supporter of the project um so check it out um check out the center.link we uh have as you can see uh the only thing next to cassandra in terms of the tag count is spark and kafka right so there's a lot of articles on consider that link on how to use spark with cassandra we're ready for the hands-on it's going to be fairly quick because a lot of the stuff we had done before um we're just gonna verify that our api uh is up and running to make sure that you know if we do a process it sends it to the cassandra api it's gonna work we're gonna verify very quickly uh cassandra you know does our cockpit connect work and the reason is that we we want to show when we create events that the spark will be able to pick it up right um we're not gonna do all of the kafka use cases today we're just gonna generate some content um and then you know if you've never set up a spark this is just a suggested way of doing it on one computer right now and the only reason we're doing it in svt server is because i want to be able to make some changes to the code and then compile really quickly you don't have to have an spt server you can just use svt command line to build packages we're going to see this in action right kafka to cassandra and spark streaming and then we're going to see this in action using spark to read and then materialize data back into cassandra um we're going to see this one picture um again um these things the registry the broker the rest proxy um kafka gui they're running a services kafka connect can also run as a service but we're not gonna do that we're gonna do a standalone kafka process anything with a dotted line is a it's a process that we can start and stop versus these are going to be running uh all the time on this uh and actually i should have put in here the spark master and the spark worker too but i'll update that later um the materialization uh this is what you're asking you know what is a tag so currently kafka connect can take data from kafka and save it to cassandra and it uses cql to update this uh other code in cassandra.api writes data to this table directly uh you can also use a producer to sorry to consume from kafka and send requests to a consent of api there's an example for this uh which then populates via rest and then that then uses cql and then calculus streams uh can read from the queue and then properly via cql as well so this table already exists in astra right now um so if i go to my data stack studio and there's probably like a couple of thousand in here but you know even this limit statement isn't really going to help me much it's gonna it's gonna get um it's gonna do a table scan normally you would never do this right because our primary key is is uh it's not included in this query but you know this data um is you can look at it in like json view or uh right so this is the data that is inside the table that i'm looking at earlier okay uh it already exists there are other table um that we will recreate uh because they already exist because i rate our streaming from kafka and while one process writes to this another spark streaming process can be continuously updating the leafs by tag table what does this table have it basically has given a tag show me um everything that i need to basically you know populate a web page for example right show me the listing of all the articles for this particular tag and if you look at the columns for this table right it actually has a couple more things it has a title has a url because for that view that's all we need right to show that particular item on a page this is all we need we don't need to re um you know we don't need to copy everything that's in this main table into the leaves by tag the cassandra uh so this is another table called tags this is the one that's going to read from cassandra it's going to crunch it and it's going to save it back all it's really saving is um given a tag it saves the count so we can do a very quick query you know how many like the query that you see on this web page right here um a great suspender has suspended my my page yeah probably anyway great uh great plugin makes chrome uh much more usable if you have a thousand windows uh but like right here this uh listing right is coming from uh a database in my sql database we're just doing a query right group by and count and all that but in cassandra we can't do a google fly we can't do account in a group by so we have to materialize this table as well so this is kind of what it's going to show whereas the leaves by tag could potentially power this interface right here so give it a tag right show me the title show me and give me the url and uh maybe we have to put a couple of other things in there but that's kind of what we're doing we're using a real use case to make these tables go ahead and start up my uh get pot um it's uh normally if i started it once it doesn't take that long um give it a second while it's happening um just to quickly review uh the gitpod ide um you have an editor it's connected to get to a git repo and if you pay for gitpod you can connect your private repositories so you can use this for your projects for work um again with github.com um any open source repository you can pull and use gitpod to test it out to play around with it um you also have the ability to start terminals bash terminals and run services it can then expose the urls um that are like port 8000 or 480 on a special url that you can test so anything that you can imagine you're doing in a local host you can basically do on github the only thing that we found that you can't do right now is you can't run docker inside this container because this is a docker container itself um there's theoretically a way to do this where we loaded with docker but you know if you find this person named free time i'm looking for them right yeah and also so not only you do have the full ide with all the the vs extensions available for you but you know java is pre-installed know this pre-installed python it's print style so that's pretty powerful to death yeah um the this particular real-time repo is little heavy because we've got kafka we've got spark on it just a little just a little bit um but you know it was kind of the only way to make it as simple as possible but not simple right otherwise we would have to have you uh start another git pod repo to run spark and so that would have been a charlie so what i'm doing right here right as this thing came up these services got started i'm making these ports public right these are the different ports that i can make public i don't have to make all of them public i'm just making them public because i want to you know show you what i'm doing here so um what happened when i started this repo this uh get pod container uh kafka started up that's really what happened that's why these ports are open um and i'm gonna start something called akhq basically to um show give me a gui for kafka so the person first and foremost what we're going to do is we've got this up and running um this thing can take time it doesn't have to be up and running immediately but we're going to go and start up akhq what uh i like about akhq is it's free um it can work with basically any kafka so you can you can use akhq to talk to managed kafka service by amazon you can use it to talk to confluent in this case uh our kafka instance is is kind of a confluent community edition and it's going to be used for um just looking at and seeing like what are the schemas in there you know what are the topics can i look at the message inside the topic itself so if you've done this before you can fast forward to um we've already gotten this running um i'm just gonna quickly check to see is this actually running uh so because it has been started at load i mean there is a gitpod.yaml and you simply said i want everything that's running when the the instance just started yeah and this is i believe right it's green yep right this is my gitpod.yaml it basically says you know uh you know go ahead and start confluent right um it also cleans my uh scala program so i can then recompile it i don't necessarily have like old packages in there right that's what i wanted to do um so we got kafka running right um if i wanted to force it i could start it but i think it's already working right now um let's see if my previous work shows up which is what i run ak hq so i'm going to open this up and it should come up pretty quickly it's a nice little interface yeah so it used to be called kafka hq but probably due to you know the apache community not fun is reusing the name it's just hq trademark yeah exactly um so at the very beginning when confluence starts up right it it has some topics built in to run kafka connect basically this is what it's for um but there's no actual topics in here so we really have to go and just quickly create our topics um we're going to be creating a topic using a schema using avro that's something we covered last time the reason we have a schema is that um without a schema we cannot do structured streaming uh and without a schema we cannot uh do um kafka connect we need to have that i mean without a schema we can't do this the rest proxy either it's kind of like a must-have um you can get into an argument about um you know whether or not we should have schemas in kafka with somebody else because i won't have it i'm just going to tell you you should have schemas um so what i'm doing is i'm just listing right the topics and i can see now that there is a new topic called you know record leaves avro this is what i've made uh and it works it looks like it's working fine right um then i want to do is i want to create a bunch of messages um the departments for this should already be there but i'm just going to make sure that you still do it anyways okay it's already done good and i have a simple python program oh i'm sorry i do need to create a schema i just created the message that i have not created a schema now we have a schema and if i see what i have i don't have to go to command line if i just refresh yeah so um could we drop the pdf of the slide after the workshop it's it's it's in in the repo it's not there yet so i could put the pdf somewhere but that would be probably better simply in the repo just get asked yeah yeah we can put in the repo or usually what we do is we'll put it up on slide slideshare uh and then just embed it sounds great um so we got us we've got a schema right everything we verified that it exists uh we checked via 8khq and uh you know um what we have basically is a way to see messages as they come in that's why i like hq i don't have to have like another consumer to look at it i can actually see a live feel of what's happening um and let's go ahead and run some import process here so let's go to i'm going to do a live tail and i'm going to check out this here like 50 messages at a time and if i run so what this is doing is it's reading from like a json file and it's making a bunch of uh sample um you know messages and it should be showing up here so that's simply a loader of your topic written yeah that's what we're doing just kind of loading data into the queue we can take a look at over here so notice that we have the data populated in two different topics this one is with the schema there's about a thousand in there right and if i wanted to go in here and dig deeper it takes a second times to load it but i can see my actual messages like what did i send here and that was done so there's a thousand topics in here and we know um that they're that they're in here because akh is telling us now what we need to do is to take this and send it over to cassandra so how are we going to do that we're actually actually going to use the kafka connect because it's the easiest one krafka connect setup is fairly simple you can you know read it from the last example but um what i like about connect is all we needed to do was make a schema and uh you know given the bundle the secure bundle uh and authentication um though all the work i had to do in topic connect to make this work was say here i'll find it i needed to say this thing is equal to this thing this thing is equal to this thing this is the mapping that i made in kafka connect for it to take the data from kafka and just save it to center um you'll notice when we do the spark aspect of it that this is the same topic we're going to read from to save the the leafs by tag and to start up connect we're going to bypass some of these other ways of doing it as i mentioned there's a lot of different ways to do this um and we've already done this work we've already done this work and go in here i wouldn't do that you just need to start calculating it so as you can all see this you simply copy paste commands so you you could do that take your time don't expect to follow with us live but you know the stream is recorded you can go at your pace but it's free go there copy paste try by yourself yeah we're going to stop the service can fluent connect uh coffee connect because we are going to do a stand-alone service um there is a way to have this process running all the time so as data comes in you can automatically always save it to cassandra using kafka connect but because i wanted to have some control over this and be able to shut it down i'm just running it stand alone so this is maven doing some basic compilations and there's going to be some errors don't worry about it all right so it's up and running and um it's committing a bunch of uh the because we didn't consume the previously you know inputted data it's basically running some processes uh if we were to go to astra we would see you know section i'm curious to see if i go here to help so was kafka connect started before or did you just start now kafka connect was started so as soon yeah okay as soon as you uh push stuff in the topic because cafe connect was there he was ready to push that data somewhere so you define what we called a sink which is here astra and boom now that's a nice tune [Laughter] and now kafka connect on his own is really pushing the data into astral there is no extra stuff yet no spark involved yet yeah we're just testing to make sure that kafka is able to do its job and you know basically we can send data to it and we can retrieve data to it um and you know right now um there's like 17 clients connected and that's because connect is using a bunch of different connections to save data it's going to it's going to do as much as it can so copycat connect is pretty powerful if you just want to land data right from into it's it's perfect for that you don't need spark for that um so let's give that a little bit more time uh it will um tell us in akhq oops wrong topic so uh oh actually another place we can take is the dataset studio um so what we're going to do is we're going to do a count [Music] i know right you spark to count yes true true true um so we had we had about you know a couple i think uh yeah so it's kind of too long right it's going to take too long to do it um i believe i don't really have a way to change the timeout here but that's okay um let me see and i and i don't want to try my luck into it on on the console um so just give it give it a second um once the data shows up in uh cassandra um because this data is in the um uh the kafka uh uh we we can potentially drop our data and then recreate okay so what i'm gonna actually do um is i'm gonna truncate table urls okay um oh we don't need the okay good um and then let's see what this counts as okay so there's zero data in there right um and i'm going to go back here and i'm going to produce some messages and i'm going to open a new terminal and this is the same way we're going to produce messages when we start up spark right um meaning we're just going to use a python program that we had earlier and just populate the heck out of it and this data importer is pretty uh simple um you can take a look at it on your time all right so we're going to create a bunch of messages um and you know we're kafka connect is running right now it's going to start taking some tasks and in the meantime let's see wow look at that thousand items in like 30 minutes boom right so that's how we're going to create messages um let's go back to our uh readme so we verified that cassandra is up and running we verified kafka is up and running we've verified cockpit connect is doing its job right now we're gonna start doing some spark um and you know and we just we just basically did this um we have already downloaded smart right like what we did was download um the latest version uh and untarded uh i'm not gonna do that again because i want to mess up the installation but what what we see here in the spark directory if you get the git pod you normally wouldn't have this folder first but it shows uh spark uh the spark bin hadoop you wouldn't see that so we did that already the next thing that we do is we download svt uh really sbts used to compile scala programs you don't have to use scala you can use java you can use maven to compile your spark jobs i'm using scala i'm using simple build tool we have already made these tables okay um but just so that you believe me that this is working code so add if not exist somewhere i don't know yeah right um oh be careful you might truncate again your url table i mean i don't know what's wrong with that okay good uh and then tags so here if i go and check out what's nope all right so i can just do this i need to say drop table tags yeah that's what i was missing i was missing the table and drop table leaves by tag and this will update look at that it's gone forever just kidding um so we're gonna make these two tables right where we're gonna materialize our information and and [Music] we're gonna start our spark master uh what is a spark master uh spark master is kind of like the the commander for spark you give it um basically um uh by the way we're we're stopping uh kafka connect because we don't need it anymore right we already have kafka data in there um but the the spark master is just like the commander and it takes requests and it plans out and then delegates the work to the workers um so when we start the spark master we actually get a port that we can view kind of what's happening so right now there's no workers right we don't have any live workers we don't have any cords available we have nothing available but the spark master is up saying i'm ready to accept new workers right um and so we got to add a worker to it and uh you know what we need to do is uh you know we have to go in here and get the url for the spark master and um you know basically start the slave and say start slate map and then give it the master url uh if you're using um you know other technologies to run sparky you don't have to do this because it's kind of part of that package right important note here is um there's a lot of um different tunings that you can do with spark in the code in the configuration um and in the configuration you can give it like how many executors to use how many how much memory per executor um but um i'm not gonna cover all that um that's as i said you can expend days on end talking about spark um but it's important that you know you cannot use more resources than you have right so in our case when we run the job it's going to use as much as possible but if we say hey this streaming job only started with three cores and um you know you use like you know 1gb each it's going to use up basically 3gb and 3 cores and then we can start another job so spark isn't just a single uh tasker it can run multiple processes you just have to have enough resources right and that's why it makes it powerful because you can have a very very big cluster right and with like thousands of cores and terabytes of memory and you can say run this spark job run that spark job and depending on how big the job is it'll get spread out and it'll get executed um if we go back to the worker sorry this to the master if i refresh you'll see that that worker is not registered with this much available resources right i don't have enough resources on this git pod to open up another worker so i won't that's still a lot remember kafka is running in background including connect so we're going to start the spark sorry the simple build tool um i like having this utility to quickly recompile uh you know as i make some changes you don't need to do this normally like you don't have to have a spark build server so this is our kafka connect i can go ahead and stop this all right we don't need this anymore and let's see there we go and all this svt server is doing for me is giving me the ability to say assemble avengers assemble right now it's compiling and the beauty of scala is that when you say svt assemble it only goes and checks the scala files that have been changed and it's a little bit more elegant i think than maven like it does uh much faster in fact i don't know how to explain it but i read about it before it uses scala streams internally to basically build its own software um so it's starting up for the first time it's getting the basic um you know repos from maven right so scala is a jvm system that means that anything that's on maven anything that you have access to on on maven um you can get um all right so we got it and [Music] there's a couple more things that we needed for spark so it's downloading that and i'm making a uh what's called a fat jar okay um you don't have to make a fat jar um the reason we're making a fat jar is this jar has everything it needs so i can send it to any spark server and it'll work if that spark server had all of these libraries then my my jar would not have to be that big because i don't have to package my own smart connector driver right so this is just a way to ensure that my libraries that i need are going to be in that jar that's going to get executed if you're not familiar with what a jar file is a jar file is a glorified zip file it just ends in dot jar it's a way to package everything that executes in code into one jar file we have a properties configuration file um which i edited earlier but it's really just a way to configure the spark job without doing it on the command line but everything that you see in this properties file you can send in the command line like you can say use this different file uh for the for my secure bundle uh use these different views are different user and password um and if you can imagine the same spark job could be run against different cassandra servers different cassandra key spaces so this spark master needs to be updated because we we potentially have a new spark master here it should be the same because i i mean uh i'll double check though yeah it's actually it's not the same because i've started a new uh new master um and now we're ready we're ready to run um code and i'm gonna actually all right i don't need an svt server anymore i already compiled what i needed um so i'm gonna run my first spark job which is leaves by tag and uh be careful when you copy and paste this you have to give it uh you don't have to give it um you know all of these parameters but um i wanted to show that you can always override the conf file uh with whatever is in the con file with with your own setting here um so copy paste i'm just going to quickly paste it here i'm not going to save my file and i'm going to change this to my name of my database right it's called platform and what is this doing spark submit is saying run this class we'll take a look at that code using this properties file and by the way take a look at the zip file because that's where my secure bundle is and my stuff my stuff is in here my stuff is in this jar that i created earlier um so got that ready to go let's take a look at the code so if you go to the spark cassandra directory um you'll see in the source directory uh scala main blah blah blah this is this is just funny business in spark and scala but um leaps by tag is a very simple program um yeah we need all this stuff to kind of connect to cassandra but what is it doing it's connecting to kafka and it's making a data frame remember when we talked about data frames it's like a database in memory and we're using structured streaming so what's really happening is we're populating this data frame with the data from the stream and then when it's in there we can then select data from that data frame so what this is doing is saying select data tags as tag data.title this is sql by the way right and um we want to explode this into kind of our own map and it gets this data and once we're ready this data frame which came from this one we can basically say write that data back to a table into this table into the cassandra format that's it we populated this we will populate this uh topic again this code is going to read it and transform it in flight into the structure that we want in our table in our cassandra table and this code will write it okay so copy and paste oh uh i need to be in a different directory because i'm running spark submit right so i need to make sure i'm in the spark folder so when a spark job works sorry when a spark job is running it will also have its own ui which kind of tells you what's happening right so this job basically is running it's a stream job okay and um basically like i go to the master i can then go to the worker but i have to use the worker url that uh that i have from a git pod because this is using kind of an internal reference and then on that worker i can see essentially what is happening right so up until now we haven't really created new messages so our job is running okay it's kind of doing its thing we need to give it some new messages and we can do that back to my handy git repo and send some more messages so my my handy-dandy python importer um is just populating the topic in the meantime my spark job picked up these messages right and it's transforming it and it's writing to that table and if i refresh my jobs here so you can see it did some stuff does it mean the same data is read twice one from the connect and one with spark and written in another table is it the same data that you process in both cases i'm using the same data and actually it's a good point uh cedric that if i wanted to i could have just set the offset and replay the same data yeah but it's right now it's effectively the same data right if we were have if we had the spark job running at the same time as the uh cockpit connect both tables would have been populated because kafka connect is populating one table and this spark job is populating another table off of the same topic essentially so we have the spark job it shows it's running let's take a look at our uh data stack studio and what i want to do is see if there's any data in here so um well you saw me delete the table so if i do a query yeah hey sure it found some data right there's something in there uh awesome um and if i want to see the actual data this is what it looks like right given this particular tag here are the 43 results okay now this is a much faster query than to say you know select star from the main table where tag is equal to whatever um would allow filtering like we should never do a lot of filtering right and our goal with this table was to have a fast tag article look up and then lastly as we come to a close uh we have another job that we want to run to populate the the tags table i'm going to go ahead and stop and my last job that i'm going to run is we just verified this right we've got the tags we're in the second spark job and so similarly with the second spark job i'm just going to quickly examine it make sure that i'm using the right zip file um this spark streaming job is being stubborn but i'll show you a way to kill the job um with the ui with the spark ui we didn't talk at length about the spark ui but the spark ui is an excellent place to start to see how your spark job is performing what parts of the spark job are taking too long um to basically better um break up the work right um so this is the let's go back to spark master i'm gonna actually go to eight sorry all right so this is my spark worker and i'm going to go back to my spark master and you know looks like this application finished right it did its job but still thinks that it's it's doing something um in kafka in i cannot say kafka hq but ak hq so you can brought the topic can you see uh the consumer and the topic the the offset where they are just to see if they may have consumed or not yeah actually it shows you the offset okay uh and shows you which consumer groups are attached to it because it registered that registers that so it's going to it's going to be a second but i'm going to run the second spark job [Music] going to populate the second table and i had it right here yep and if i go back to my sparkmaster um and i refresh you see that now there's a new job right and that's what i was showing like if an application isn't dying on you you can always kill it um i think i have a runaway process on the other one but that's okay because the mar the master is not kind of dealing with it right now um this job should finish pretty quickly what it's doing by the way is it's reading the data from cassandra and it's then rewriting the data okay there it goes so that's pretty good so here you do have two job two different job two first is was spark streaming reading from kafka and the second was standalone spark to read from read from cassandra and back to casanova which is too good sample code for you to you know to start building spar jobs absolutely and you can see that this one took 34 seconds um so what cedric was talking about right when you do spark sql you know just be ready that sometimes spark the spark sql is getting made into a smart job and that spark job is getting executed um depending on how much memory and resources you have it may take a while right it may take a minute but it'll come back it will finish the job um and it's a heck of a lot better than hadoop that's for damn sure that's for sure for sure there we go the smart streaming job also uh disconnected properly um the tags code which we just ran the badge code to show you um it's a lot simpler than the leaves by tag because it's actually reading from cassandra and saving back to cassandra so what we're doing is we're saying hey get all of these tags from my main table right that had a thousand urls and i want you to make a different data frame basically that uh gets the tag and then it gets the count and i want to save that data frame back to cassandra and so that table gets materialized in cassandra as this table here and so if we do a select star from tags where tag is equal to spark we'll get the same thing and because this is a small table um you can just do select start from tags so it went through a thousand items in cassandra it read all of that data right it counted them and it saved it back in 34 seconds pretty cool you know even with the free tier you do have some power you have a lot of power with this um but that's spark you know uh in a nutshell what you can do uh is talk to any system and obviously you want to talk to cassandra you can read from consent you can write from cassandra uh you can read from kafka you can write your cassandra like this uh this is the latest and greatest using structured streaming and data frames um older spark code is not this elegant it is not as cool this is as close as it gets to select star from this table insert into this other table okay yeah you can do in uh sql as it gets yeah so i think it's time for a question i got some hold from smita from a couple of minutes now even hours is so we pick spark streaming um why not kafka stream what is the difference and which one should you use when perfect that's a really really good question um so kafka streams by default gives you access to all of the topics and it can even show those you can kind of even do a little bit of joins in between tables right but your data has to be put into kafka first for you to be able to do stuff with that data right um kafka streams also assumes that you're operating off of a topic and you're going to do something with that data and yeah kafka streams you can write a kafka stream's job in java or scala or anything um and that's it right spark is a much bigger ecosystem so you're not just limited to the data coming from kafka you could have that data coming from kinesis as a structured stream you could have that data coming from sql server as a structured stream and then that data frame that represents the kafka topic and that represents the the sql server topic you can do joins on it you can do manipulations in those between those data frames uh if you wanted to and then you can save that to to cassandra so that's one thing that you can do with spark the other is by the way you can also kind of do that with copycat streams but you wouldn't get a data frame of the sql server table right right and um you wouldn't necessarily get a structured stream for other stuff um the other thing that spark has is compute it can do massive amounts of data crunching so if your data comes in in a topic you can then essentially parse that data you can transform it you can enhance it you can evaluate it for machine learning if that process is going to need more power than one computer then you can use spark if that process is going to take more than one computer in kafka streams probably not possible you have to kind of break apart the work differently and then finally um i would say like to differentiate the two if you know your whole workflow is in kafka like every single thing you can kind of do everything in kafka streams only when you have to do big like batch processing then you would use spark you wouldn't necessarily use spark streaming for that if you have kafka streams go to great credence world yeah um i mean i did a good job on swimming all the question i guess it was you know pretty deep dive and also step by step so people can follow along and so we will share with you all the resources and you can see that you can do it on your own and with gitpod and astral there is nothing for you to install or to pay or to provide any info just watching for question uh oh we had a question about um spark uh would you use uh scala or java you know i i used to be as well a java i i'm a java hardcore programmer and when it comes to to spark really i'm i'm stuck pretty fast with the data structures they manipulate you don't have the same flows i don't know what you think about long-age war sure yeah so in sparc i think the question is you know which language to use um yep so you know i had to have this up here on one of the uh slides all the different languages so let me just bring that up um so scala spark is written in scala right um and you know there were features in scala before there were features in java and they kind of eventually get parody um ultimately this is a company or team decision um because these are the two compiled languages well maybe i have not tested against c-sharp but these are two compilable smart languages that can run the fastest right the one edge that scala has is that you can do what's called a spark shell right um and i can kind of like start it um by kind of a different deep dive but basically you can start a shell and you can copy and paste this scala code and try it out without compiling it yeah cool oh yeah okay it's pretty neat right right so you can say do this do this do this right and run this and run this and then run this again and run this again and so you can try out a bunch of stuff in real time in in a re-evaluate print loop that you couldn't do with job and that ability only exists in scala and python to be able to do it interactively yes okay that's cool also you know we we delivered a fat jar which i find is a you know the the easiest way to deploy spark stuff uh in a dedicated infra because it's a fajr everything in the single place if you are using spark hard or spark python it's more difficult to to package and deploy you can do the same but when it comes to putting that in production i felt it's a bit more difficult the ci cd is not as mature as the one for the javascale part yeah um absolutely what i find is the main workflow is that folks will there's people from different backgrounds that generally will work on an analytics platform so the data scientists will have r or python on jupiter you know the jupiter hub the web-based notebook they'll try different things out then when they're happy with something they will try spark python and then when they're really happy with it it needs to be faster they'll tell the data engineers to then make it in scala in order to make it in java but the same platform can support all of this right the same data sets the same general apis um you just have to change the syntax every now thanks and as always don't forget to click that subscribe button and ring that bell to get notifications for all of our future upcoming workshops on the same page [Music] me [Music] you",
    "segments": [
      {
        "start": 1.439,
        "duration": 6.081,
        "text": "good morning everybody good evening"
      },
      {
        "start": 3.84,
        "duration": 5.759,
        "text": "um can you hear us can you"
      },
      {
        "start": 7.52,
        "duration": 3.84,
        "text": "give us a thumb up if you hear us well"
      },
      {
        "start": 9.599,
        "duration": 5.12,
        "text": "please raul"
      },
      {
        "start": 11.36,
        "duration": 4.479,
        "text": "can you say something hey good afternoon"
      },
      {
        "start": 14.719,
        "duration": 2.801,
        "text": "good morning good evening wherever"
      },
      {
        "start": 15.839,
        "duration": 4.641,
        "text": "you're at"
      },
      {
        "start": 17.52,
        "duration": 5.12,
        "text": "so what about the sounds folks can we go"
      },
      {
        "start": 20.48,
        "duration": 2.16,
        "text": "on"
      },
      {
        "start": 24.56,
        "duration": 7.119,
        "text": "ah waiting for yes we all good"
      },
      {
        "start": 28.48,
        "duration": 5.68,
        "text": "okay so welcome"
      },
      {
        "start": 31.679,
        "duration": 3.761,
        "text": "welcome everybody for uh yet another"
      },
      {
        "start": 34.16,
        "duration": 4.399,
        "text": "workshop"
      },
      {
        "start": 35.44,
        "duration": 4.88,
        "text": "so this time this is the third of a"
      },
      {
        "start": 38.559,
        "duration": 5.441,
        "text": "series where we talk about"
      },
      {
        "start": 40.32,
        "duration": 6.96,
        "text": "event driven toolkit all prepared"
      },
      {
        "start": 44.0,
        "duration": 4.48,
        "text": "with loved by raul um i'm so happy to"
      },
      {
        "start": 47.28,
        "duration": 4.64,
        "text": "have you back"
      },
      {
        "start": 48.48,
        "duration": 3.919,
        "text": "with us today and we do have a lot to"
      },
      {
        "start": 51.92,
        "duration": 3.52,
        "text": "cover"
      },
      {
        "start": 52.399,
        "duration": 5.201,
        "text": "again today i guess right"
      },
      {
        "start": 55.44,
        "duration": 3.919,
        "text": "yes absolutely it's uh it's like we're"
      },
      {
        "start": 57.6,
        "duration": 2.84,
        "text": "trying to boil the ocean today"
      },
      {
        "start": 59.359,
        "duration": 3.68,
        "text": "well hopefully we won't"
      },
      {
        "start": 60.44,
        "duration": 5.719,
        "text": "[Laughter]"
      },
      {
        "start": 63.039,
        "duration": 4.641,
        "text": "of course not um so today we will"
      },
      {
        "start": 66.159,
        "duration": 4.681,
        "text": "discuss a lot about"
      },
      {
        "start": 67.68,
        "duration": 4.64,
        "text": "spark spike streaming kafka kasambha and"
      },
      {
        "start": 70.84,
        "duration": 5.319,
        "text": "astra"
      },
      {
        "start": 72.32,
        "duration": 6.24,
        "text": "so now raul you are sharing your screen"
      },
      {
        "start": 76.159,
        "duration": 4.96,
        "text": "and the presentation should be coming up"
      },
      {
        "start": 78.56,
        "duration": 2.559,
        "text": "in a second"
      },
      {
        "start": 81.84,
        "duration": 2.56,
        "text": "of course"
      },
      {
        "start": 85.759,
        "duration": 7.761,
        "text": "thank you google internet"
      },
      {
        "start": 90.0,
        "duration": 3.52,
        "text": "um there we go"
      },
      {
        "start": 97.2,
        "duration": 7.44,
        "text": "i can see it yes here we are right"
      },
      {
        "start": 101.52,
        "duration": 3.44,
        "text": "hey cedric thank you so much for having"
      },
      {
        "start": 104.64,
        "duration": 3.92,
        "text": "me"
      },
      {
        "start": 104.96,
        "duration": 5.76,
        "text": "again um to do the spark streaming"
      },
      {
        "start": 108.56,
        "duration": 4.879,
        "text": "um uh with kafka and we're actually"
      },
      {
        "start": 110.72,
        "duration": 5.84,
        "text": "gonna cover some spark batch as well"
      },
      {
        "start": 113.439,
        "duration": 3.68,
        "text": "i'm really excited um because you know"
      },
      {
        "start": 116.56,
        "duration": 3.76,
        "text": "spark"
      },
      {
        "start": 117.119,
        "duration": 4.64,
        "text": "is a well it's like a swiss army toolkit"
      },
      {
        "start": 120.32,
        "duration": 5.04,
        "text": "you can do everything with it"
      },
      {
        "start": 121.759,
        "duration": 5.36,
        "text": "um but when we combine it with spark"
      },
      {
        "start": 125.36,
        "duration": 4.72,
        "text": "sorry when we combine spark with"
      },
      {
        "start": 127.119,
        "duration": 7.281,
        "text": "cassandra and kafka"
      },
      {
        "start": 130.08,
        "duration": 8.4,
        "text": "we can do a little bit about myself"
      },
      {
        "start": 134.4,
        "duration": 8.0,
        "text": "i'm a ceo of a small consulting team"
      },
      {
        "start": 138.48,
        "duration": 6.08,
        "text": "um i've also helped create"
      },
      {
        "start": 142.4,
        "duration": 3.76,
        "text": "cassandra.link which is a knowledge base"
      },
      {
        "start": 144.56,
        "duration": 4.96,
        "text": "of all things cassandra"
      },
      {
        "start": 146.16,
        "duration": 5.04,
        "text": "and i maintain a um"
      },
      {
        "start": 149.52,
        "duration": 3.84,
        "text": "well it's a readme but basically the"
      },
      {
        "start": 151.2,
        "duration": 5.039,
        "text": "best resources that you should need"
      },
      {
        "start": 153.36,
        "duration": 4.8,
        "text": "to know about cassandra i curate and i"
      },
      {
        "start": 156.239,
        "duration": 5.521,
        "text": "have a couple other awesome ones as well"
      },
      {
        "start": 158.16,
        "duration": 6.4,
        "text": "um and these days uh since meetup"
      },
      {
        "start": 161.76,
        "duration": 3.199,
        "text": "groups are no longer in person that's"
      },
      {
        "start": 164.56,
        "duration": 4.24,
        "text": "cool"
      },
      {
        "start": 164.959,
        "duration": 3.841,
        "text": "like that to meet all experts"
      },
      {
        "start": 169.12,
        "duration": 3.68,
        "text": "this is the mentee code if you didn't"
      },
      {
        "start": 170.879,
        "duration": 5.921,
        "text": "know"
      },
      {
        "start": 172.8,
        "duration": 7.28,
        "text": "keep that yeah we we jump into"
      },
      {
        "start": 176.8,
        "duration": 6.32,
        "text": "mentee right away all good"
      },
      {
        "start": 180.08,
        "duration": 5.36,
        "text": "um so this is part of a series"
      },
      {
        "start": 183.12,
        "duration": 3.52,
        "text": "and you know the first couple of topics"
      },
      {
        "start": 185.44,
        "duration": 3.519,
        "text": "we covered"
      },
      {
        "start": 186.64,
        "duration": 3.2,
        "text": "um were basically you know what is what"
      },
      {
        "start": 188.959,
        "duration": 3.681,
        "text": "is rest"
      },
      {
        "start": 189.84,
        "duration": 3.84,
        "text": "how is that related to event driven uh"
      },
      {
        "start": 192.64,
        "duration": 3.28,
        "text": "systems"
      },
      {
        "start": 193.68,
        "duration": 4.4,
        "text": "uh we actually built an api on cassandra"
      },
      {
        "start": 195.92,
        "duration": 5.039,
        "text": "we'll quickly take a look at it"
      },
      {
        "start": 198.08,
        "duration": 5.439,
        "text": "and even though astro comes with its own"
      },
      {
        "start": 200.959,
        "duration": 4.321,
        "text": "rest api and graphql api"
      },
      {
        "start": 203.519,
        "duration": 3.761,
        "text": "uh you know a lot of times you want to"
      },
      {
        "start": 205.28,
        "duration": 3.92,
        "text": "do some processing before we save it"
      },
      {
        "start": 207.28,
        "duration": 5.36,
        "text": "into uh cassandra so that's why we have"
      },
      {
        "start": 209.2,
        "duration": 7.2,
        "text": "our own custom api in python and node"
      },
      {
        "start": 212.64,
        "duration": 7.92,
        "text": "then the next webinar we did"
      },
      {
        "start": 216.4,
        "duration": 6.96,
        "text": "was how to use kafka in different ways"
      },
      {
        "start": 220.56,
        "duration": 4.56,
        "text": "to event source the information for a"
      },
      {
        "start": 223.36,
        "duration": 3.519,
        "text": "particular event"
      },
      {
        "start": 225.12,
        "duration": 3.679,
        "text": "and then use a processor to process that"
      },
      {
        "start": 226.879,
        "duration": 5.041,
        "text": "event information"
      },
      {
        "start": 228.799,
        "duration": 3.841,
        "text": "using a consumer um we actually"
      },
      {
        "start": 231.92,
        "duration": 4.16,
        "text": "connected"
      },
      {
        "start": 232.64,
        "duration": 6.959,
        "text": "kafka to cassandra using kafka connect"
      },
      {
        "start": 236.08,
        "duration": 6.159,
        "text": "and in case streams and"
      },
      {
        "start": 239.599,
        "duration": 3.681,
        "text": "today we're going to connect kafka to"
      },
      {
        "start": 242.239,
        "duration": 3.92,
        "text": "cassandra"
      },
      {
        "start": 243.28,
        "duration": 3.599,
        "text": "with spark streaming once the data is in"
      },
      {
        "start": 246.159,
        "duration": 3.521,
        "text": "spark"
      },
      {
        "start": 246.879,
        "duration": 4.241,
        "text": "sorry in cassandra we'll do some special"
      },
      {
        "start": 249.68,
        "duration": 4.8,
        "text": "processing"
      },
      {
        "start": 251.12,
        "duration": 6.0,
        "text": "this setup of cassandra spark and kafka"
      },
      {
        "start": 254.48,
        "duration": 2.96,
        "text": "is a very very basic setup and our goal"
      },
      {
        "start": 257.12,
        "duration": 4.32,
        "text": "is"
      },
      {
        "start": 257.44,
        "duration": 8.0,
        "text": "to give you a toolkit um"
      },
      {
        "start": 261.44,
        "duration": 6.319,
        "text": "today we're gonna review basically"
      },
      {
        "start": 265.44,
        "duration": 3.36,
        "text": "you know the kafka setup uh the kazandra"
      },
      {
        "start": 267.759,
        "duration": 3.921,
        "text": "setup that we have"
      },
      {
        "start": 268.8,
        "duration": 3.28,
        "text": "in our git pod uh we'll make sure that"
      },
      {
        "start": 271.68,
        "duration": 2.64,
        "text": "those"
      },
      {
        "start": 272.08,
        "duration": 3.2,
        "text": "uh you know systems are up and running"
      },
      {
        "start": 274.32,
        "duration": 3.92,
        "text": "uh you know"
      },
      {
        "start": 275.28,
        "duration": 4.479,
        "text": "if you want to follow this uh we're"
      },
      {
        "start": 278.24,
        "duration": 4.32,
        "text": "assuming that you've done this"
      },
      {
        "start": 279.759,
        "duration": 4.481,
        "text": "uh you know the other two webinars with"
      },
      {
        "start": 282.56,
        "duration": 4.24,
        "text": "us before and you have the casino"
      },
      {
        "start": 284.24,
        "duration": 3.84,
        "text": "api and you can spend real time get pods"
      },
      {
        "start": 286.8,
        "duration": 3.28,
        "text": "up and running"
      },
      {
        "start": 288.08,
        "duration": 3.28,
        "text": "with an astra account if you don't"
      },
      {
        "start": 290.08,
        "duration": 3.6,
        "text": "that's okay just"
      },
      {
        "start": 291.36,
        "duration": 3.44,
        "text": "follow me just follow along just watch"
      },
      {
        "start": 293.68,
        "duration": 3.68,
        "text": "what i'm doing"
      },
      {
        "start": 294.8,
        "duration": 3.52,
        "text": "all of this stuff as you'll notice is on"
      },
      {
        "start": 297.36,
        "duration": 4.48,
        "text": "github"
      },
      {
        "start": 298.32,
        "duration": 5.12,
        "text": "and you can do this anytime um and uh if"
      },
      {
        "start": 301.84,
        "duration": 2.16,
        "text": "you haven't used github before you'll"
      },
      {
        "start": 303.44,
        "duration": 2.08,
        "text": "see that"
      },
      {
        "start": 304.0,
        "duration": 3.039,
        "text": "i'm doing everything in the browser you"
      },
      {
        "start": 305.52,
        "duration": 3.119,
        "text": "don't have to you don't have to download"
      },
      {
        "start": 307.039,
        "duration": 4.801,
        "text": "any code and run it"
      },
      {
        "start": 308.639,
        "duration": 3.201,
        "text": "on your computer"
      },
      {
        "start": 321.919,
        "duration": 3.521,
        "text": "it's going to select some information"
      },
      {
        "start": 323.44,
        "duration": 5.12,
        "text": "and it's going to materialize"
      },
      {
        "start": 325.44,
        "duration": 6.0,
        "text": "a a table in cassandra"
      },
      {
        "start": 328.56,
        "duration": 3.76,
        "text": "and once data is in that table and"
      },
      {
        "start": 331.44,
        "duration": 2.4,
        "text": "actually"
      },
      {
        "start": 332.32,
        "duration": 3.68,
        "text": "looking at another data set we're going"
      },
      {
        "start": 333.84,
        "duration": 4.4,
        "text": "to have a batch drop that takes all the"
      },
      {
        "start": 336.0,
        "duration": 4.08,
        "text": "data from cassandra"
      },
      {
        "start": 338.24,
        "duration": 3.92,
        "text": "crunches it and then saves it back into"
      },
      {
        "start": 340.08,
        "duration": 4.72,
        "text": "another table"
      },
      {
        "start": 342.16,
        "duration": 3.039,
        "text": "these are some basic patterns that we"
      },
      {
        "start": 344.8,
        "duration": 3.839,
        "text": "see"
      },
      {
        "start": 345.199,
        "duration": 5.761,
        "text": "in the kafka cassandra spark ecosystem"
      },
      {
        "start": 348.639,
        "duration": 4.241,
        "text": "generally that we end up using different"
      },
      {
        "start": 350.96,
        "duration": 3.6,
        "text": "ways to stream data into kafka"
      },
      {
        "start": 352.88,
        "duration": 3.84,
        "text": "we use different ways to stream data out"
      },
      {
        "start": 354.56,
        "duration": 4.32,
        "text": "from kafka into cassandra"
      },
      {
        "start": 356.72,
        "duration": 4.4,
        "text": "and when we need to do some really heavy"
      },
      {
        "start": 358.88,
        "duration": 5.039,
        "text": "crunching of information"
      },
      {
        "start": 361.12,
        "duration": 6.32,
        "text": "or analytics or machine learning we end"
      },
      {
        "start": 363.919,
        "duration": 5.761,
        "text": "up using spark"
      },
      {
        "start": 367.44,
        "duration": 3.039,
        "text": "hopefully at the end of today you're"
      },
      {
        "start": 369.68,
        "duration": 2.72,
        "text": "going to"
      },
      {
        "start": 370.479,
        "duration": 3.201,
        "text": "have a basic understanding of spark"
      },
      {
        "start": 372.4,
        "duration": 4.239,
        "text": "spark streaming"
      },
      {
        "start": 373.68,
        "duration": 4.639,
        "text": "in the context of cassandra and kafka"
      },
      {
        "start": 376.639,
        "duration": 4.161,
        "text": "and you'll know how to run"
      },
      {
        "start": 378.319,
        "duration": 4.801,
        "text": "you know streaming job and the spark gap"
      },
      {
        "start": 380.8,
        "duration": 2.32,
        "text": "checker"
      },
      {
        "start": 384.16,
        "duration": 4.72,
        "text": "i want to thank data sax for being a"
      },
      {
        "start": 387.039,
        "duration": 4.561,
        "text": "great sponsor and partner"
      },
      {
        "start": 388.88,
        "duration": 4.159,
        "text": "um and you know giving cassandra as a"
      },
      {
        "start": 391.6,
        "duration": 3.28,
        "text": "service for free so you don't have to"
      },
      {
        "start": 393.039,
        "duration": 5.681,
        "text": "set up your own uh cassandra"
      },
      {
        "start": 394.88,
        "duration": 6.96,
        "text": "for doing these events um and get pod"
      },
      {
        "start": 398.72,
        "duration": 5.759,
        "text": "uh thank you git pod uh i have my"
      },
      {
        "start": 401.84,
        "duration": 3.359,
        "text": "sticker that i got uh from you guys uh"
      },
      {
        "start": 404.479,
        "duration": 3.84,
        "text": "lucky you"
      },
      {
        "start": 405.199,
        "duration": 4.881,
        "text": "i need those stickers as well"
      },
      {
        "start": 408.319,
        "duration": 4.16,
        "text": "make this code they've given us free pro"
      },
      {
        "start": 410.08,
        "duration": 4.559,
        "text": "account so thank you for the sponsorship"
      },
      {
        "start": 412.479,
        "duration": 4.321,
        "text": "and then deloitte has also been helpful"
      },
      {
        "start": 414.639,
        "duration": 4.0,
        "text": "in beta testing this workshop"
      },
      {
        "start": 416.8,
        "duration": 6.0,
        "text": "in a couple of different times before we"
      },
      {
        "start": 418.639,
        "duration": 6.241,
        "text": "started doing it publicly uh"
      },
      {
        "start": 422.8,
        "duration": 3.76,
        "text": "what is an architect uh we had another"
      },
      {
        "start": 424.88,
        "duration": 2.8,
        "text": "architect platforms of cassandra and"
      },
      {
        "start": 426.56,
        "duration": 3.12,
        "text": "related technologies"
      },
      {
        "start": 427.68,
        "duration": 3.84,
        "text": "an architect is a chief builder in"
      },
      {
        "start": 429.68,
        "duration": 3.76,
        "text": "computing it's somebody who designs or"
      },
      {
        "start": 431.52,
        "duration": 4.88,
        "text": "makes things so we design and make stuff"
      },
      {
        "start": 433.44,
        "duration": 4.319,
        "text": "that basically runs on cassandra and"
      },
      {
        "start": 436.4,
        "duration": 2.56,
        "text": "spark and kafka which are related"
      },
      {
        "start": 437.759,
        "duration": 4.72,
        "text": "technologies"
      },
      {
        "start": 438.96,
        "duration": 5.12,
        "text": "um love scalable fast data"
      },
      {
        "start": 442.479,
        "duration": 3.44,
        "text": "like literally what we're talking about"
      },
      {
        "start": 444.08,
        "duration": 4.0,
        "text": "today cassandra's far kafka we love"
      },
      {
        "start": 445.919,
        "duration": 4.4,
        "text": "doing that that's what we love doing"
      },
      {
        "start": 448.08,
        "duration": 3.36,
        "text": "uh and we do things without data stacks"
      },
      {
        "start": 450.319,
        "duration": 2.561,
        "text": "with data stacks"
      },
      {
        "start": 451.44,
        "duration": 3.52,
        "text": "sometimes the technology is slightly"
      },
      {
        "start": 452.88,
        "duration": 4.319,
        "text": "different but ultimately spark"
      },
      {
        "start": 454.96,
        "duration": 4.0,
        "text": "cassandra and kafka can be done in open"
      },
      {
        "start": 457.199,
        "duration": 3.12,
        "text": "source or it can be done on cloud it can"
      },
      {
        "start": 458.96,
        "duration": 3.44,
        "text": "be done on premise"
      },
      {
        "start": 460.319,
        "duration": 4.401,
        "text": "uh with commercial support from"
      },
      {
        "start": 462.4,
        "duration": 4.479,
        "text": "companies like confluent and data stacks"
      },
      {
        "start": 464.72,
        "duration": 4.72,
        "text": "on different clouds but the common"
      },
      {
        "start": 466.879,
        "duration": 3.76,
        "text": "denominator is we love doing scalable"
      },
      {
        "start": 469.44,
        "duration": 3.68,
        "text": "fast data and that's what we're going to"
      },
      {
        "start": 470.639,
        "duration": 8.481,
        "text": "talk about today"
      },
      {
        "start": 473.12,
        "duration": 9.04,
        "text": "great go ahead cedric"
      },
      {
        "start": 479.12,
        "duration": 6.16,
        "text": "okay yeah so um as usual during this"
      },
      {
        "start": 482.16,
        "duration": 5.92,
        "text": "live workshop uh we are uh on"
      },
      {
        "start": 485.28,
        "duration": 4.639,
        "text": "youtube answering your question but and"
      },
      {
        "start": 488.08,
        "duration": 4.72,
        "text": "we try to answer your question"
      },
      {
        "start": 489.919,
        "duration": 4.161,
        "text": "on the spot but if you do have long form"
      },
      {
        "start": 492.8,
        "duration": 3.679,
        "text": "question"
      },
      {
        "start": 494.08,
        "duration": 3.519,
        "text": "troubleshooting you should be interested"
      },
      {
        "start": 496.479,
        "duration": 4.081,
        "text": "to use discord"
      },
      {
        "start": 497.599,
        "duration": 3.921,
        "text": "okay where we do also have expert"
      },
      {
        "start": 500.56,
        "duration": 3.199,
        "text": "analyzing"
      },
      {
        "start": 501.52,
        "duration": 3.84,
        "text": "what you are doing and you can go to"
      },
      {
        "start": 503.759,
        "duration": 5.28,
        "text": "breakout rooms and discuss"
      },
      {
        "start": 505.36,
        "duration": 6.88,
        "text": "if you are really stuck today we"
      },
      {
        "start": 509.039,
        "duration": 5.201,
        "text": "you know we used a mentee already so you"
      },
      {
        "start": 512.24,
        "duration": 5.44,
        "text": "know about that"
      },
      {
        "start": 514.24,
        "duration": 7.2,
        "text": "and so we will use cassandra kafka"
      },
      {
        "start": 517.68,
        "duration": 6.479,
        "text": "and spark so the data will be"
      },
      {
        "start": 521.44,
        "duration": 3.36,
        "text": "stored in astra i will explain you what"
      },
      {
        "start": 524.159,
        "duration": 2.8,
        "text": "it is"
      },
      {
        "start": 524.8,
        "duration": 3.599,
        "text": "and that's on the top you see the link"
      },
      {
        "start": 526.959,
        "duration": 3.521,
        "text": "to the runtime"
      },
      {
        "start": 528.399,
        "duration": 3.681,
        "text": "we will give you some times to register"
      },
      {
        "start": 530.48,
        "duration": 4.4,
        "text": "to abstract if you"
      },
      {
        "start": 532.08,
        "duration": 4.08,
        "text": "don't have any account yet it's a free"
      },
      {
        "start": 534.88,
        "duration": 3.44,
        "text": "tier you can go"
      },
      {
        "start": 536.16,
        "duration": 4.4,
        "text": "there is five gigabytes which is much"
      },
      {
        "start": 538.32,
        "duration": 6.24,
        "text": "much more than we need for today"
      },
      {
        "start": 540.56,
        "duration": 6.08,
        "text": "and we will use uh two github repo"
      },
      {
        "start": 544.56,
        "duration": 4.24,
        "text": "the link are also in the youtube"
      },
      {
        "start": 546.64,
        "duration": 3.36,
        "text": "descriptions but i probably will give"
      },
      {
        "start": 548.8,
        "duration": 4.08,
        "text": "you the link again"
      },
      {
        "start": 550.0,
        "duration": 3.519,
        "text": "on the youtube chat and we will use git"
      },
      {
        "start": 552.88,
        "duration": 4.399,
        "text": "pod"
      },
      {
        "start": 553.519,
        "duration": 4.481,
        "text": "against each repo because we need a lot"
      },
      {
        "start": 557.279,
        "duration": 4.401,
        "text": "of power"
      },
      {
        "start": 558.0,
        "duration": 6.48,
        "text": "you know kafka and spark is a lot of cpu"
      },
      {
        "start": 561.68,
        "duration": 4.0,
        "text": "and using git pod and the virtual id"
      },
      {
        "start": 564.48,
        "duration": 4.24,
        "text": "they provide us"
      },
      {
        "start": 565.68,
        "duration": 5.44,
        "text": "we do have one dedicated for the api and"
      },
      {
        "start": 568.72,
        "duration": 4.08,
        "text": "kafka and another one for for spark"
      },
      {
        "start": 571.12,
        "duration": 4.24,
        "text": "or one over the other i don't know how"
      },
      {
        "start": 572.8,
        "duration": 6.24,
        "text": "you split workloads in the two"
      },
      {
        "start": 575.36,
        "duration": 3.68,
        "text": "but we would need two rows"
      },
      {
        "start": 582.24,
        "duration": 6.08,
        "text": "so uh you know just so that the gift pot"
      },
      {
        "start": 585.44,
        "duration": 2.88,
        "text": "can get warmed up"
      },
      {
        "start": 588.48,
        "duration": 3.919,
        "text": "we're gonna go ahead and launch getpod"
      },
      {
        "start": 591.279,
        "duration": 4.481,
        "text": "and the way you launch it"
      },
      {
        "start": 592.399,
        "duration": 6.241,
        "text": "is you just go to um sorry"
      },
      {
        "start": 595.76,
        "duration": 2.88,
        "text": "go to the url"
      },
      {
        "start": 600.24,
        "duration": 7.599,
        "text": "so let me share the url with you all i"
      },
      {
        "start": 603.279,
        "duration": 4.56,
        "text": "copy the link in the chat right now boom"
      },
      {
        "start": 609.2,
        "duration": 6.96,
        "text": "and once you get um"
      },
      {
        "start": 612.48,
        "duration": 6.0,
        "text": "the cassandra real time up and running"
      },
      {
        "start": 616.16,
        "duration": 3.64,
        "text": "you'll notice two git pod buttons one is"
      },
      {
        "start": 618.48,
        "duration": 4.4,
        "text": "for"
      },
      {
        "start": 619.8,
        "duration": 3.479,
        "text": "cassandra.api which as i mentioned it's"
      },
      {
        "start": 622.88,
        "duration": 1.6,
        "text": "it's"
      },
      {
        "start": 623.279,
        "duration": 3.521,
        "text": "uh it's nice to have you don't"
      },
      {
        "start": 624.48,
        "duration": 5.039,
        "text": "necessarily need it for this"
      },
      {
        "start": 626.8,
        "duration": 4.4,
        "text": "but we're gonna verify that asteroids"
      },
      {
        "start": 629.519,
        "duration": 4.961,
        "text": "off using this api"
      },
      {
        "start": 631.2,
        "duration": 5.759,
        "text": "so you know control click this button to"
      },
      {
        "start": 634.48,
        "duration": 4.32,
        "text": "open the cassandra api and get pod"
      },
      {
        "start": 636.959,
        "duration": 4.401,
        "text": "and then what you're going to do is"
      },
      {
        "start": 638.8,
        "duration": 6.88,
        "text": "you're going to scroll down a little bit"
      },
      {
        "start": 641.36,
        "duration": 7.599,
        "text": "until you find the the second one"
      },
      {
        "start": 645.68,
        "duration": 4.159,
        "text": "to start this in real time i think that"
      },
      {
        "start": 648.959,
        "duration": 3.681,
        "text": "there we go"
      },
      {
        "start": 649.839,
        "duration": 2.801,
        "text": "where it says two"
      },
      {
        "start": 653.04,
        "duration": 3.12,
        "text": "yeah don't hesitate to make your screen"
      },
      {
        "start": 655.6,
        "duration": 2.88,
        "text": "you know"
      },
      {
        "start": 656.16,
        "duration": 5.76,
        "text": "the screen bigger on readme you know"
      },
      {
        "start": 658.48,
        "duration": 6.64,
        "text": "just increase the font size for everyone"
      },
      {
        "start": 661.92,
        "duration": 6.56,
        "text": "yeah let me do that right now yeah"
      },
      {
        "start": 665.12,
        "duration": 4.24,
        "text": "great looks like yeah it looks a little"
      },
      {
        "start": 668.48,
        "duration": 5.28,
        "text": "bit better"
      },
      {
        "start": 669.36,
        "duration": 7.28,
        "text": "um so when we bring up uh"
      },
      {
        "start": 673.76,
        "duration": 4.88,
        "text": "our github url in git pod all we're"
      },
      {
        "start": 676.64,
        "duration": 5.439,
        "text": "really doing is just saying hey open up"
      },
      {
        "start": 678.64,
        "duration": 4.8,
        "text": "um using this url it's going to first"
      },
      {
        "start": 682.079,
        "duration": 4.0,
        "text": "ask you to log in"
      },
      {
        "start": 683.44,
        "duration": 4.639,
        "text": "you can just use your github login um"
      },
      {
        "start": 686.079,
        "duration": 3.041,
        "text": "and what it'll do is it'll actually save"
      },
      {
        "start": 688.079,
        "duration": 3.281,
        "text": "that workspace"
      },
      {
        "start": 689.12,
        "duration": 4.32,
        "text": "it's building a container right now for"
      },
      {
        "start": 691.36,
        "duration": 5.039,
        "text": "us and pulling down our code"
      },
      {
        "start": 693.44,
        "duration": 4.639,
        "text": "and getting everything up and running um"
      },
      {
        "start": 696.399,
        "duration": 3.361,
        "text": "all on the web so we're gonna let this"
      },
      {
        "start": 698.079,
        "duration": 3.44,
        "text": "kind of bake in the background it takes"
      },
      {
        "start": 699.76,
        "duration": 4.8,
        "text": "a few minutes for it to start up"
      },
      {
        "start": 701.519,
        "duration": 5.601,
        "text": "and we're going to continue"
      },
      {
        "start": 704.56,
        "duration": 3.92,
        "text": "on with the rest of the presentation um"
      },
      {
        "start": 707.12,
        "duration": 2.32,
        "text": "the first section of the presentation"
      },
      {
        "start": 708.48,
        "duration": 3.84,
        "text": "we're going to talk about"
      },
      {
        "start": 709.44,
        "duration": 3.36,
        "text": "is you know why are we doing this this"
      },
      {
        "start": 712.32,
        "duration": 2.8,
        "text": "this"
      },
      {
        "start": 712.8,
        "duration": 3.839,
        "text": "code base that we're showing what is the"
      },
      {
        "start": 715.12,
        "duration": 5.279,
        "text": "purpose of this code base"
      },
      {
        "start": 716.639,
        "duration": 6.161,
        "text": "and i personally like to learn um"
      },
      {
        "start": 720.399,
        "duration": 4.081,
        "text": "you know programming or technology if i"
      },
      {
        "start": 722.8,
        "duration": 2.32,
        "text": "know where there's a reason behind it"
      },
      {
        "start": 724.48,
        "duration": 4.479,
        "text": "right"
      },
      {
        "start": 725.12,
        "duration": 6.48,
        "text": "um and"
      },
      {
        "start": 728.959,
        "duration": 3.44,
        "text": "wow google it's either my google or it's"
      },
      {
        "start": 731.6,
        "duration": 4.96,
        "text": "my internet"
      },
      {
        "start": 732.399,
        "duration": 6.24,
        "text": "um it's taking a second here"
      },
      {
        "start": 736.56,
        "duration": 4.959,
        "text": "i might just uh not do the full"
      },
      {
        "start": 738.639,
        "duration": 6.64,
        "text": "presentation though going forward"
      },
      {
        "start": 741.519,
        "duration": 4.721,
        "text": "yeah so you know when you open up git"
      },
      {
        "start": 745.279,
        "duration": 2.56,
        "text": "pod it's gonna look"
      },
      {
        "start": 746.24,
        "duration": 3.68,
        "text": "something like this it looks like"
      },
      {
        "start": 747.839,
        "duration": 5.041,
        "text": "basically uh visual studio"
      },
      {
        "start": 749.92,
        "duration": 3.76,
        "text": "it's not visual studio actually it's uh"
      },
      {
        "start": 752.88,
        "duration": 3.6,
        "text": "thea"
      },
      {
        "start": 753.68,
        "duration": 3.76,
        "text": "which is a open source clone of visual"
      },
      {
        "start": 756.48,
        "duration": 4.56,
        "text": "studio"
      },
      {
        "start": 757.44,
        "duration": 5.68,
        "text": "and um it's the it's the editor it's the"
      },
      {
        "start": 761.04,
        "duration": 5.359,
        "text": "server it's it's kind of everything"
      },
      {
        "start": 763.12,
        "duration": 4.8,
        "text": "uh all in one so"
      },
      {
        "start": 766.399,
        "duration": 3.44,
        "text": "why are we building this well right now"
      },
      {
        "start": 767.92,
        "duration": 4.24,
        "text": "we have a platform that"
      },
      {
        "start": 769.839,
        "duration": 3.44,
        "text": "helps us generate the cassandra link"
      },
      {
        "start": 772.16,
        "duration": 4.239,
        "text": "website"
      },
      {
        "start": 773.279,
        "duration": 4.721,
        "text": "and we have the ability to generate"
      },
      {
        "start": 776.399,
        "duration": 3.12,
        "text": "many many more websites because our"
      },
      {
        "start": 778.0,
        "duration": 3.839,
        "text": "knowledge base has"
      },
      {
        "start": 779.519,
        "duration": 4.721,
        "text": "probably 20 30 000 links in it the"
      },
      {
        "start": 781.839,
        "duration": 5.201,
        "text": "cassandra knowledge base has about"
      },
      {
        "start": 784.24,
        "duration": 4.719,
        "text": "10 uh sorry i think it's about a"
      },
      {
        "start": 787.04,
        "duration": 4.64,
        "text": "thousand to 1500 links in it"
      },
      {
        "start": 788.959,
        "duration": 3.201,
        "text": "um but it's it's a platform where we"
      },
      {
        "start": 791.68,
        "duration": 2.88,
        "text": "curate"
      },
      {
        "start": 792.16,
        "duration": 3.04,
        "text": "knowledge and there's an admin screen"
      },
      {
        "start": 794.56,
        "duration": 2.8,
        "text": "there's a"
      },
      {
        "start": 795.2,
        "duration": 3.199,
        "text": "there's kind of like an advanced view to"
      },
      {
        "start": 797.36,
        "duration": 4.24,
        "text": "look at this on"
      },
      {
        "start": 798.399,
        "duration": 4.88,
        "text": "my and php and"
      },
      {
        "start": 801.6,
        "duration": 3.44,
        "text": "uh we have a mirror of that data in"
      },
      {
        "start": 803.279,
        "duration": 3.12,
        "text": "cassandra and we have a mirror of that"
      },
      {
        "start": 805.04,
        "duration": 4.08,
        "text": "data in solar"
      },
      {
        "start": 806.399,
        "duration": 3.521,
        "text": "and uh we wanted to make this scalable"
      },
      {
        "start": 809.12,
        "duration": 4.24,
        "text": "we wanted to"
      },
      {
        "start": 809.92,
        "duration": 5.68,
        "text": "to make this go bigger so what we"
      },
      {
        "start": 813.36,
        "duration": 3.68,
        "text": "decided was let's see if we can take"
      },
      {
        "start": 815.6,
        "duration": 2.96,
        "text": "this whole platform and make it"
      },
      {
        "start": 817.04,
        "duration": 3.68,
        "text": "serverless"
      },
      {
        "start": 818.56,
        "duration": 3.279,
        "text": "all right and so the front end of this"
      },
      {
        "start": 820.72,
        "duration": 4.479,
        "text": "application"
      },
      {
        "start": 821.839,
        "duration": 5.601,
        "text": "is using the jam stack and"
      },
      {
        "start": 825.199,
        "duration": 3.041,
        "text": "there's an amazing workshop happening"
      },
      {
        "start": 827.44,
        "duration": 2.72,
        "text": "tomorrow"
      },
      {
        "start": 828.24,
        "duration": 3.76,
        "text": "about react and the jam stack and the"
      },
      {
        "start": 830.16,
        "duration": 3.359,
        "text": "ceo of netflix will be there so we use"
      },
      {
        "start": 832.0,
        "duration": 5.68,
        "text": "netflify to host"
      },
      {
        "start": 833.519,
        "duration": 7.12,
        "text": "interfaces um both that talk to apis"
      },
      {
        "start": 837.68,
        "duration": 3.839,
        "text": "uh but also we generate using gatsby a"
      },
      {
        "start": 840.639,
        "duration": 3.601,
        "text": "full website"
      },
      {
        "start": 841.519,
        "duration": 3.68,
        "text": "so all of the 1500 pages plus they get"
      },
      {
        "start": 844.24,
        "duration": 4.08,
        "text": "generated out"
      },
      {
        "start": 845.199,
        "duration": 4.481,
        "text": "but it runs off of an api so we want to"
      },
      {
        "start": 848.32,
        "duration": 2.959,
        "text": "migrate that api"
      },
      {
        "start": 849.68,
        "duration": 3.519,
        "text": "this part of the system is already"
      },
      {
        "start": 851.279,
        "duration": 4.081,
        "text": "serverless because it's using burcell"
      },
      {
        "start": 853.199,
        "duration": 4.08,
        "text": "and netlify"
      },
      {
        "start": 855.36,
        "duration": 3.36,
        "text": "the search stacks is a hosted solar"
      },
      {
        "start": 857.279,
        "duration": 1.92,
        "text": "server list we don't really worry about"
      },
      {
        "start": 858.72,
        "duration": 2.72,
        "text": "it"
      },
      {
        "start": 859.199,
        "duration": 4.721,
        "text": "and right now we want to stop managing"
      },
      {
        "start": 861.44,
        "duration": 5.68,
        "text": "our own api we want to eventually go to"
      },
      {
        "start": 863.92,
        "duration": 3.84,
        "text": "astra because astro gives us basically"
      },
      {
        "start": 867.12,
        "duration": 2.88,
        "text": "an api"
      },
      {
        "start": 867.76,
        "duration": 4.56,
        "text": "in graphql it gives an api in rest it's"
      },
      {
        "start": 870.0,
        "duration": 5.04,
        "text": "going to have other cool stuff"
      },
      {
        "start": 872.32,
        "duration": 4.079,
        "text": "and if we have any particular special"
      },
      {
        "start": 875.04,
        "duration": 4.4,
        "text": "needs for an api"
      },
      {
        "start": 876.399,
        "duration": 5.12,
        "text": "we'll we'll probably host them on uh"
      },
      {
        "start": 879.44,
        "duration": 5.04,
        "text": "like a kubernetes managed kubernetes so"
      },
      {
        "start": 881.519,
        "duration": 6.401,
        "text": "that can be a serverless kubernetes"
      },
      {
        "start": 884.48,
        "duration": 5.44,
        "text": "we also want to make this event driven"
      },
      {
        "start": 887.92,
        "duration": 4.24,
        "text": "right now the system is not event driven"
      },
      {
        "start": 889.92,
        "duration": 3.68,
        "text": "the whole process of these these talks"
      },
      {
        "start": 892.16,
        "duration": 3.119,
        "text": "has been to show how do we build an"
      },
      {
        "start": 893.6,
        "duration": 3.84,
        "text": "event-driven system"
      },
      {
        "start": 895.279,
        "duration": 4.081,
        "text": "and then after data comes in event"
      },
      {
        "start": 897.44,
        "duration": 4.88,
        "text": "driven and it's updated event driven"
      },
      {
        "start": 899.36,
        "duration": 3.44,
        "text": "we also want to have some uh processing"
      },
      {
        "start": 902.32,
        "duration": 2.319,
        "text": "uh"
      },
      {
        "start": 902.8,
        "duration": 3.039,
        "text": "of the data itself and you'll you'll see"
      },
      {
        "start": 904.639,
        "duration": 1.921,
        "text": "what they what type of data it's"
      },
      {
        "start": 905.839,
        "duration": 1.841,
        "text": "websites"
      },
      {
        "start": 906.56,
        "duration": 3.2,
        "text": "right we want to do some special"
      },
      {
        "start": 907.68,
        "duration": 5.36,
        "text": "analysis of the website uh"
      },
      {
        "start": 909.76,
        "duration": 6.8,
        "text": "data uh and see if things are correlated"
      },
      {
        "start": 913.04,
        "duration": 8.08,
        "text": "using machine learning there are two"
      },
      {
        "start": 916.56,
        "duration": 7.92,
        "text": "git pods one which is a cassandra api"
      },
      {
        "start": 921.12,
        "duration": 6.079,
        "text": "and there's parity between leaves"
      },
      {
        "start": 924.48,
        "duration": 3.919,
        "text": "api python and leaves api node uh if you"
      },
      {
        "start": 927.199,
        "duration": 2.401,
        "text": "look at the code they're basically doing"
      },
      {
        "start": 928.399,
        "duration": 1.921,
        "text": "the same thing they're just slightly"
      },
      {
        "start": 929.6,
        "duration": 5.28,
        "text": "different"
      },
      {
        "start": 930.32,
        "duration": 7.199,
        "text": "um the uh the only reason we have an api"
      },
      {
        "start": 934.88,
        "duration": 3.92,
        "text": "separate from the astra api that already"
      },
      {
        "start": 937.519,
        "duration": 3.041,
        "text": "exists for you"
      },
      {
        "start": 938.8,
        "duration": 4.0,
        "text": "is that when we were first building this"
      },
      {
        "start": 940.56,
        "duration": 2.719,
        "text": "app that that rest api was not because"
      },
      {
        "start": 942.8,
        "duration": 3.039,
        "text": "we were"
      },
      {
        "start": 943.279,
        "duration": 3.201,
        "text": "one of the first users of astra um and"
      },
      {
        "start": 945.839,
        "duration": 2.161,
        "text": "then"
      },
      {
        "start": 946.48,
        "duration": 3.599,
        "text": "once it was out we realized that we"
      },
      {
        "start": 948.0,
        "duration": 4.079,
        "text": "still needed to do some custom scraping"
      },
      {
        "start": 950.079,
        "duration": 5.521,
        "text": "right so we still need to have our own"
      },
      {
        "start": 952.079,
        "duration": 5.2,
        "text": "api layer uh even if we use these"
      },
      {
        "start": 955.6,
        "duration": 3.52,
        "text": "even if we peggy back up with these we"
      },
      {
        "start": 957.279,
        "duration": 4.881,
        "text": "need to have our own"
      },
      {
        "start": 959.12,
        "duration": 3.92,
        "text": "the git pod we're looking at today uh in"
      },
      {
        "start": 962.16,
        "duration": 4.0,
        "text": "the last talk"
      },
      {
        "start": 963.04,
        "duration": 6.0,
        "text": "we covered the kafka aspects of it"
      },
      {
        "start": 966.16,
        "duration": 5.28,
        "text": "right so we run uh kafka broker we have"
      },
      {
        "start": 969.04,
        "duration": 5.28,
        "text": "a registry we have a rest proxy"
      },
      {
        "start": 971.44,
        "duration": 4.72,
        "text": "um we have uh you know kaka producers"
      },
      {
        "start": 974.32,
        "duration": 4.639,
        "text": "and consumers that can talk to this"
      },
      {
        "start": 976.16,
        "duration": 4.799,
        "text": "uh there's a kafka gui powered by akhq"
      },
      {
        "start": 978.959,
        "duration": 3.361,
        "text": "that'll show us the topics in there"
      },
      {
        "start": 980.959,
        "duration": 4.0,
        "text": "and today we're going to be looking at"
      },
      {
        "start": 982.32,
        "duration": 4.879,
        "text": "this right the stream process"
      },
      {
        "start": 984.959,
        "duration": 4.081,
        "text": "that takes data from kafka puts it into"
      },
      {
        "start": 987.199,
        "duration": 3.281,
        "text": "cassandra and a badge process that reads"
      },
      {
        "start": 989.04,
        "duration": 8.32,
        "text": "from cassandra processes"
      },
      {
        "start": 990.48,
        "duration": 8.479,
        "text": "it and puts it back into cassandra"
      },
      {
        "start": 997.36,
        "duration": 3.839,
        "text": "quick overview of rest versus"
      },
      {
        "start": 998.959,
        "duration": 4.401,
        "text": "microservices um"
      },
      {
        "start": 1001.199,
        "duration": 3.521,
        "text": "if you haven't been here on this talk"
      },
      {
        "start": 1003.36,
        "duration": 3.12,
        "text": "before"
      },
      {
        "start": 1004.72,
        "duration": 3.2,
        "text": "this is either going to be too much"
      },
      {
        "start": 1006.48,
        "duration": 3.279,
        "text": "information or it's going to be just"
      },
      {
        "start": 1007.92,
        "duration": 4.64,
        "text": "right information i apologize"
      },
      {
        "start": 1009.759,
        "duration": 4.161,
        "text": "we just want to give everybody a context"
      },
      {
        "start": 1012.56,
        "duration": 4.48,
        "text": "microservices"
      },
      {
        "start": 1013.92,
        "duration": 4.4,
        "text": "are you know loosely coupled they can be"
      },
      {
        "start": 1017.04,
        "duration": 4.08,
        "text": "written in basically"
      },
      {
        "start": 1018.32,
        "duration": 3.84,
        "text": "a variety of different ways people can"
      },
      {
        "start": 1021.12,
        "duration": 3.6,
        "text": "coordinate them"
      },
      {
        "start": 1022.16,
        "duration": 4.48,
        "text": "uh you know using asynchronous"
      },
      {
        "start": 1024.72,
        "duration": 5.199,
        "text": "technologies like amqp"
      },
      {
        "start": 1026.64,
        "duration": 4.08,
        "text": "protocol or kafka itself um or they can"
      },
      {
        "start": 1029.919,
        "duration": 4.0,
        "text": "do everything"
      },
      {
        "start": 1030.72,
        "duration": 5.839,
        "text": "synchronously using rest um and"
      },
      {
        "start": 1033.919,
        "duration": 3.681,
        "text": "you know for us just looking back at"
      },
      {
        "start": 1036.559,
        "duration": 4.24,
        "text": "this"
      },
      {
        "start": 1037.6,
        "duration": 4.319,
        "text": "each of these things right here could be"
      },
      {
        "start": 1040.799,
        "duration": 3.601,
        "text": "a microservice"
      },
      {
        "start": 1041.919,
        "duration": 4.16,
        "text": "if we make it loosely coupled meaning"
      },
      {
        "start": 1044.4,
        "duration": 4.32,
        "text": "this is not dependent on this and this"
      },
      {
        "start": 1046.079,
        "duration": 4.561,
        "text": "is not dependent on this over here"
      },
      {
        "start": 1048.72,
        "duration": 3.04,
        "text": "so what we have today at the end of"
      },
      {
        "start": 1050.64,
        "duration": 3.6,
        "text": "today is"
      },
      {
        "start": 1051.76,
        "duration": 3.36,
        "text": "you can consider this could be its own"
      },
      {
        "start": 1054.24,
        "duration": 3.679,
        "text": "microservice"
      },
      {
        "start": 1055.12,
        "duration": 4.16,
        "text": "this could be its own microservice as"
      },
      {
        "start": 1057.919,
        "duration": 4.481,
        "text": "these apis"
      },
      {
        "start": 1059.28,
        "duration": 4.72,
        "text": "and the stream process as well um the"
      },
      {
        "start": 1062.4,
        "duration": 3.6,
        "text": "point being that we can do a combination"
      },
      {
        "start": 1064.0,
        "duration": 3.919,
        "text": "of synchronous and asynchronous"
      },
      {
        "start": 1066.0,
        "duration": 4.4,
        "text": "processing of events on the same"
      },
      {
        "start": 1067.919,
        "duration": 2.481,
        "text": "platform"
      },
      {
        "start": 1071.52,
        "duration": 4.08,
        "text": "the only thing that we generally don't"
      },
      {
        "start": 1073.679,
        "duration": 3.041,
        "text": "follow from the conventional micro"
      },
      {
        "start": 1075.6,
        "duration": 3.92,
        "text": "service thinking"
      },
      {
        "start": 1076.72,
        "duration": 4.4,
        "text": "is that each service needs its own db"
      },
      {
        "start": 1079.52,
        "duration": 2.48,
        "text": "and that's not true in the cassandra"
      },
      {
        "start": 1081.12,
        "duration": 2.799,
        "text": "world"
      },
      {
        "start": 1082.0,
        "duration": 3.28,
        "text": "the reason is that cassandra can scale"
      },
      {
        "start": 1083.919,
        "duration": 3.601,
        "text": "to thousands"
      },
      {
        "start": 1085.28,
        "duration": 4.0,
        "text": "and hundreds of thousands of servers and"
      },
      {
        "start": 1087.52,
        "duration": 2.72,
        "text": "you can think about a key space or a"
      },
      {
        "start": 1089.28,
        "duration": 3.68,
        "text": "table"
      },
      {
        "start": 1090.24,
        "duration": 4.16,
        "text": "like its own kind of microservice that"
      },
      {
        "start": 1092.96,
        "duration": 4.88,
        "text": "scales on its own"
      },
      {
        "start": 1094.4,
        "duration": 5.36,
        "text": "so because we're on astra which can"
      },
      {
        "start": 1097.84,
        "duration": 3.6,
        "text": "infinitely scale"
      },
      {
        "start": 1099.76,
        "duration": 3.36,
        "text": "we don't have to worry about a different"
      },
      {
        "start": 1101.44,
        "duration": 3.359,
        "text": "database or a different key space or"
      },
      {
        "start": 1103.12,
        "duration": 3.04,
        "text": "table per microservice"
      },
      {
        "start": 1104.799,
        "duration": 3.281,
        "text": "even though we're doing some of that"
      },
      {
        "start": 1106.16,
        "duration": 4.399,
        "text": "here we're not going to make another"
      },
      {
        "start": 1108.08,
        "duration": 3.839,
        "text": "aster database when we add new"
      },
      {
        "start": 1110.559,
        "duration": 3.681,
        "text": "functionality we can just make another"
      },
      {
        "start": 1111.919,
        "duration": 2.321,
        "text": "table"
      },
      {
        "start": 1116.72,
        "duration": 3.68,
        "text": "so you know generally in in the"
      },
      {
        "start": 1118.64,
        "duration": 3.12,
        "text": "cassandra world what you have is"
      },
      {
        "start": 1120.4,
        "duration": 3.2,
        "text": "you can have one standard cluster and"
      },
      {
        "start": 1121.76,
        "duration": 4.799,
        "text": "you can have several microservices"
      },
      {
        "start": 1123.6,
        "duration": 4.24,
        "text": "being powered by different key spaces uh"
      },
      {
        "start": 1126.559,
        "duration": 3.281,
        "text": "another cool thing about"
      },
      {
        "start": 1127.84,
        "duration": 4.24,
        "text": "uh and this is more on the data stack"
      },
      {
        "start": 1129.84,
        "duration": 3.36,
        "text": "side is that you can bring data into"
      },
      {
        "start": 1132.08,
        "duration": 4.16,
        "text": "cassandra"
      },
      {
        "start": 1133.2,
        "duration": 3.839,
        "text": "and retrieve it out as json and vice"
      },
      {
        "start": 1136.24,
        "duration": 2.799,
        "text": "versa"
      },
      {
        "start": 1137.039,
        "duration": 3.441,
        "text": "um in the later version of data stacks"
      },
      {
        "start": 1139.039,
        "duration": 4.481,
        "text": "there's you know bsc graph"
      },
      {
        "start": 1140.48,
        "duration": 7.04,
        "text": "6.8 you can add data using graph"
      },
      {
        "start": 1143.52,
        "duration": 4.0,
        "text": "queries and then retrieve data using cql"
      },
      {
        "start": 1148.559,
        "duration": 4.48,
        "text": "yes so a word on the micro service maybe"
      },
      {
        "start": 1151.28,
        "duration": 2.8,
        "text": "with cassandra you know you might have"
      },
      {
        "start": 1153.039,
        "duration": 4.64,
        "text": "heard that"
      },
      {
        "start": 1154.08,
        "duration": 4.56,
        "text": "uh in a micro service world there is one"
      },
      {
        "start": 1157.679,
        "duration": 4.0,
        "text": "database"
      },
      {
        "start": 1158.64,
        "duration": 3.84,
        "text": "per micro service to avoid any resource"
      },
      {
        "start": 1161.679,
        "duration": 4.0,
        "text": "sharing"
      },
      {
        "start": 1162.48,
        "duration": 4.319,
        "text": "and any coupling be in between the micro"
      },
      {
        "start": 1165.679,
        "duration": 2.961,
        "text": "service"
      },
      {
        "start": 1166.799,
        "duration": 3.361,
        "text": "and i would like to challenge a bit that"
      },
      {
        "start": 1168.64,
        "duration": 4.399,
        "text": "so um"
      },
      {
        "start": 1170.16,
        "duration": 4.72,
        "text": "first when you hear that um you cannot"
      },
      {
        "start": 1173.039,
        "duration": 5.201,
        "text": "have the same database"
      },
      {
        "start": 1174.88,
        "duration": 5.679,
        "text": "it's really not the same it doesn't mean"
      },
      {
        "start": 1178.24,
        "duration": 5.12,
        "text": "it's should not be the same installation"
      },
      {
        "start": 1180.559,
        "duration": 5.681,
        "text": "of the database okay as long as you can"
      },
      {
        "start": 1183.36,
        "duration": 3.52,
        "text": "uh have a proper handling of your"
      },
      {
        "start": 1186.24,
        "duration": 2.559,
        "text": "resource"
      },
      {
        "start": 1186.88,
        "duration": 4.4,
        "text": "you know you're good to go and in"
      },
      {
        "start": 1188.799,
        "duration": 5.521,
        "text": "cassandra in a cassandra cluster"
      },
      {
        "start": 1191.28,
        "duration": 5.68,
        "text": "you can have first multiple data centers"
      },
      {
        "start": 1194.32,
        "duration": 4.32,
        "text": "so depending on where you are where is"
      },
      {
        "start": 1196.96,
        "duration": 4.4,
        "text": "your location you can have"
      },
      {
        "start": 1198.64,
        "duration": 3.68,
        "text": "some nodes in azure some nodes in europe"
      },
      {
        "start": 1201.36,
        "duration": 2.64,
        "text": "some nodes"
      },
      {
        "start": 1202.32,
        "duration": 5.52,
        "text": "uh wherever you like to reduce the"
      },
      {
        "start": 1204.0,
        "duration": 3.84,
        "text": "latencies so first you can"
      },
      {
        "start": 1208.08,
        "duration": 6.64,
        "text": "split the workload in data centers"
      },
      {
        "start": 1211.44,
        "duration": 5.28,
        "text": "that first fantastic then in casanova"
      },
      {
        "start": 1214.72,
        "duration": 2.88,
        "text": "you have a key space which is like the"
      },
      {
        "start": 1216.72,
        "duration": 3.76,
        "text": "schema for"
      },
      {
        "start": 1217.6,
        "duration": 5.28,
        "text": "oracle and when it tends to do is one"
      },
      {
        "start": 1220.48,
        "duration": 4.96,
        "text": "key space per micro service because"
      },
      {
        "start": 1222.88,
        "duration": 4.32,
        "text": "at the key space level you will define"
      },
      {
        "start": 1225.44,
        "duration": 4.96,
        "text": "where the key space live"
      },
      {
        "start": 1227.2,
        "duration": 5.28,
        "text": "on which data centers how many times"
      },
      {
        "start": 1230.4,
        "duration": 5.519,
        "text": "does the data is replicated"
      },
      {
        "start": 1232.48,
        "duration": 6.72,
        "text": "stuff like that but not only that"
      },
      {
        "start": 1235.919,
        "duration": 6.24,
        "text": "in case i can also split by tables"
      },
      {
        "start": 1239.2,
        "duration": 4.8,
        "text": "okay in the tables there is no joy no"
      },
      {
        "start": 1242.159,
        "duration": 3.841,
        "text": "integrity constraint"
      },
      {
        "start": 1244.0,
        "duration": 3.36,
        "text": "and so what you do most of the time is"
      },
      {
        "start": 1246.0,
        "duration": 4.48,
        "text": "have a dedicated table"
      },
      {
        "start": 1247.36,
        "duration": 5.52,
        "text": "for your dedicated query that means"
      },
      {
        "start": 1250.48,
        "duration": 3.84,
        "text": "a micro service in charge of a bounding"
      },
      {
        "start": 1252.88,
        "duration": 4.32,
        "text": "business context"
      },
      {
        "start": 1254.32,
        "duration": 3.44,
        "text": "would be in charge of a limited set of"
      },
      {
        "start": 1257.2,
        "duration": 3.2,
        "text": "table"
      },
      {
        "start": 1257.76,
        "duration": 3.279,
        "text": "and it's pretty clear to see what is the"
      },
      {
        "start": 1260.4,
        "duration": 2.96,
        "text": "scope"
      },
      {
        "start": 1261.039,
        "duration": 4.321,
        "text": "of this micro service because now you"
      },
      {
        "start": 1263.36,
        "duration": 3.679,
        "text": "don't need to do joints or everything"
      },
      {
        "start": 1265.36,
        "duration": 2.799,
        "text": "anything like that there is no joints in"
      },
      {
        "start": 1267.039,
        "duration": 3.441,
        "text": "cassandra"
      },
      {
        "start": 1268.159,
        "duration": 3.361,
        "text": "and so with the same cassandra cluster"
      },
      {
        "start": 1270.48,
        "duration": 4.079,
        "text": "you can split"
      },
      {
        "start": 1271.52,
        "duration": 6.32,
        "text": "by data center key space table query"
      },
      {
        "start": 1274.559,
        "duration": 5.441,
        "text": "and then of course you still have airbag"
      },
      {
        "start": 1277.84,
        "duration": 4.319,
        "text": "and when you execute when you fire a"
      },
      {
        "start": 1280.0,
        "duration": 4.72,
        "text": "query against cassandra the load will be"
      },
      {
        "start": 1282.159,
        "duration": 4.64,
        "text": "distributing among the nodes for you"
      },
      {
        "start": 1284.72,
        "duration": 6.16,
        "text": "okay so the the coupling"
      },
      {
        "start": 1286.799,
        "duration": 6.88,
        "text": "is minimal"
      },
      {
        "start": 1290.88,
        "duration": 4.08,
        "text": "absolutely and uh i by the way what you"
      },
      {
        "start": 1293.679,
        "duration": 4.961,
        "text": "just said you know cedric i"
      },
      {
        "start": 1294.96,
        "duration": 5.199,
        "text": "have to explain the same thing every"
      },
      {
        "start": 1298.64,
        "duration": 3.039,
        "text": "uh every time i've talked to somebody"
      },
      {
        "start": 1300.159,
        "duration": 2.721,
        "text": "who's done microservices not on a"
      },
      {
        "start": 1301.679,
        "duration": 2.561,
        "text": "scalable data store"
      },
      {
        "start": 1302.88,
        "duration": 3.679,
        "text": "they've done you know with or"
      },
      {
        "start": 1304.24,
        "duration": 4.0,
        "text": "mysql or postgres they always come back"
      },
      {
        "start": 1306.559,
        "duration": 2.721,
        "text": "to well what about the devops aspect of"
      },
      {
        "start": 1308.24,
        "duration": 3.52,
        "text": "this you know what about"
      },
      {
        "start": 1309.28,
        "duration": 3.92,
        "text": "the the infrastructure i tell them look"
      },
      {
        "start": 1311.76,
        "duration": 4.399,
        "text": "at cassandra as a"
      },
      {
        "start": 1313.2,
        "duration": 3.44,
        "text": "infrastructure itself right and when you"
      },
      {
        "start": 1316.159,
        "duration": 2.721,
        "text": "uh"
      },
      {
        "start": 1316.64,
        "duration": 3.68,
        "text": "think about you know creating a new"
      },
      {
        "start": 1318.88,
        "duration": 4.0,
        "text": "database on"
      },
      {
        "start": 1320.32,
        "duration": 4.08,
        "text": "on database instance for my sql because"
      },
      {
        "start": 1322.88,
        "duration": 3.84,
        "text": "it needs to be powered"
      },
      {
        "start": 1324.4,
        "duration": 4.08,
        "text": "uh uh you know enough so it can scale"
      },
      {
        "start": 1326.72,
        "duration": 2.959,
        "text": "and you can vertically scale that"
      },
      {
        "start": 1328.48,
        "duration": 3.36,
        "text": "generally you're gonna have to start"
      },
      {
        "start": 1329.679,
        "duration": 3.281,
        "text": "sharding that database on my sql if it"
      },
      {
        "start": 1331.84,
        "duration": 3.199,
        "text": "starts to grow"
      },
      {
        "start": 1332.96,
        "duration": 4.24,
        "text": "well with cassandra if you just think"
      },
      {
        "start": 1335.039,
        "duration": 4.321,
        "text": "about that infinite data store"
      },
      {
        "start": 1337.2,
        "duration": 3.599,
        "text": "at the key space level you can grow it"
      },
      {
        "start": 1339.36,
        "duration": 2.16,
        "text": "as big as you want it doesn't really"
      },
      {
        "start": 1340.799,
        "duration": 2.721,
        "text": "matter and"
      },
      {
        "start": 1341.52,
        "duration": 3.68,
        "text": "from a devops perspective you can have"
      },
      {
        "start": 1343.52,
        "duration": 4.159,
        "text": "key space blue"
      },
      {
        "start": 1345.2,
        "duration": 3.599,
        "text": "key space green right if you wanted to"
      },
      {
        "start": 1347.679,
        "duration": 3.521,
        "text": "do blue green"
      },
      {
        "start": 1348.799,
        "duration": 4.401,
        "text": "or even at the table level you can have"
      },
      {
        "start": 1351.2,
        "duration": 4.479,
        "text": "different schemas on the same table"
      },
      {
        "start": 1353.2,
        "duration": 3.2,
        "text": "because you know uh cassandra it's it's"
      },
      {
        "start": 1355.679,
        "duration": 2.961,
        "text": "a nosql"
      },
      {
        "start": 1356.4,
        "duration": 4.24,
        "text": "uh columnar data store uh which means"
      },
      {
        "start": 1358.64,
        "duration": 4.8,
        "text": "that you can have"
      },
      {
        "start": 1360.64,
        "duration": 3.68,
        "text": "two schemas that don't overlap and that"
      },
      {
        "start": 1363.44,
        "duration": 2.479,
        "text": "data is not"
      },
      {
        "start": 1364.32,
        "duration": 2.719,
        "text": "replicated it's just whatever you're"
      },
      {
        "start": 1365.919,
        "duration": 2.561,
        "text": "setting is going to get set on the"
      },
      {
        "start": 1367.039,
        "duration": 2.961,
        "text": "content cluster"
      },
      {
        "start": 1368.48,
        "duration": 3.679,
        "text": "we can go so much into that discussion"
      },
      {
        "start": 1370.0,
        "duration": 4.72,
        "text": "but cassandra is"
      },
      {
        "start": 1372.159,
        "duration": 4.321,
        "text": "awesome for uh for microservices jeff"
      },
      {
        "start": 1374.72,
        "duration": 3.439,
        "text": "carpenter has an amazing"
      },
      {
        "start": 1376.48,
        "duration": 3.04,
        "text": "article and a couple of videos about"
      },
      {
        "start": 1378.159,
        "duration": 3.441,
        "text": "this as well"
      },
      {
        "start": 1379.52,
        "duration": 3.039,
        "text": "i just google microservices on cassandra"
      },
      {
        "start": 1381.6,
        "duration": 3.04,
        "text": "you'll find his article"
      },
      {
        "start": 1382.559,
        "duration": 4.401,
        "text": "and even a book and if you saw the"
      },
      {
        "start": 1384.64,
        "duration": 4.96,
        "text": "definitive guide of cassandra in the"
      },
      {
        "start": 1386.96,
        "duration": 5.92,
        "text": "datastax.com website you would see"
      },
      {
        "start": 1389.6,
        "duration": 5.04,
        "text": "a link to get a free copy of the book"
      },
      {
        "start": 1392.88,
        "duration": 3.919,
        "text": "but you know for this one i won't give"
      },
      {
        "start": 1394.64,
        "duration": 3.279,
        "text": "you the link go to the datasacks.com and"
      },
      {
        "start": 1396.799,
        "duration": 2.721,
        "text": "look around"
      },
      {
        "start": 1397.919,
        "duration": 3.361,
        "text": "look for a book and you will see a"
      },
      {
        "start": 1399.52,
        "duration": 4.56,
        "text": "couple of books with"
      },
      {
        "start": 1401.28,
        "duration": 2.8,
        "text": "freedom nick"
      },
      {
        "start": 1404.32,
        "duration": 5.12,
        "text": "excellent so one of the patterns of"
      },
      {
        "start": 1408.559,
        "duration": 4.801,
        "text": "software"
      },
      {
        "start": 1409.44,
        "duration": 7.52,
        "text": "that people implement with microservices"
      },
      {
        "start": 1413.36,
        "duration": 7.04,
        "text": "is event sourcing and cqrs"
      },
      {
        "start": 1416.96,
        "duration": 6.48,
        "text": "um cqrs stands for command query"
      },
      {
        "start": 1420.4,
        "duration": 4.72,
        "text": "uh request segregation uh also uh you"
      },
      {
        "start": 1423.44,
        "duration": 4.16,
        "text": "know people say command query separation"
      },
      {
        "start": 1425.12,
        "duration": 3.36,
        "text": "but basically it's a way to scale"
      },
      {
        "start": 1427.6,
        "duration": 4.48,
        "text": "systems"
      },
      {
        "start": 1428.48,
        "duration": 6.0,
        "text": "so when an update comes it's an event"
      },
      {
        "start": 1432.08,
        "duration": 3.28,
        "text": "and a processor basically saves that"
      },
      {
        "start": 1434.48,
        "duration": 5.12,
        "text": "data"
      },
      {
        "start": 1435.36,
        "duration": 6.96,
        "text": "to um potentially different places one"
      },
      {
        "start": 1439.6,
        "duration": 4.8,
        "text": "for the event itself uh one for where"
      },
      {
        "start": 1442.32,
        "duration": 5.2,
        "text": "the data is going to be queried and"
      },
      {
        "start": 1444.4,
        "duration": 5.519,
        "text": "for example if you were not"
      },
      {
        "start": 1447.52,
        "duration": 2.399,
        "text": "using"
      },
      {
        "start": 1450.559,
        "duration": 3.041,
        "text": "data stacks and you did not have a"
      },
      {
        "start": 1452.159,
        "duration": 4.0,
        "text": "built-in search"
      },
      {
        "start": 1453.6,
        "duration": 4.72,
        "text": "with dsc search and you needed to"
      },
      {
        "start": 1456.159,
        "duration": 4.961,
        "text": "materialize that data in both"
      },
      {
        "start": 1458.32,
        "duration": 4.32,
        "text": "you know cassandra and elasticsearch"
      },
      {
        "start": 1461.12,
        "duration": 2.799,
        "text": "your event processor would take that"
      },
      {
        "start": 1462.64,
        "duration": 2.08,
        "text": "event and it would save it in both"
      },
      {
        "start": 1463.919,
        "duration": 3.841,
        "text": "places"
      },
      {
        "start": 1464.72,
        "duration": 4.64,
        "text": "um and aster has a search index using"
      },
      {
        "start": 1467.76,
        "duration": 5.12,
        "text": "the new advanced"
      },
      {
        "start": 1469.36,
        "duration": 5.919,
        "text": "uh you know search sai but um"
      },
      {
        "start": 1472.88,
        "duration": 4.32,
        "text": "it's it's not as powerful exact for"
      },
      {
        "start": 1475.279,
        "duration": 3.841,
        "text": "example like elasticsearch leucine is a"
      },
      {
        "start": 1477.2,
        "duration": 5.2,
        "text": "very very powerful search index"
      },
      {
        "start": 1479.12,
        "duration": 5.039,
        "text": "so in that case you can still save to"
      },
      {
        "start": 1482.4,
        "duration": 5.04,
        "text": "astro have some basic indices"
      },
      {
        "start": 1484.159,
        "duration": 4.961,
        "text": "but then simultaneously save that into"
      },
      {
        "start": 1487.44,
        "duration": 4.239,
        "text": "solar or elasticsearch"
      },
      {
        "start": 1489.12,
        "duration": 3.84,
        "text": "or a third-party cloud provider like"
      },
      {
        "start": 1491.679,
        "duration": 3.041,
        "text": "algolia or"
      },
      {
        "start": 1492.96,
        "duration": 3.199,
        "text": "or swift type you name it there's so"
      },
      {
        "start": 1494.72,
        "duration": 3.199,
        "text": "many different third-party cloud search"
      },
      {
        "start": 1496.159,
        "duration": 5.681,
        "text": "providers now"
      },
      {
        "start": 1497.919,
        "duration": 5.921,
        "text": "um the other is that when we uh"
      },
      {
        "start": 1501.84,
        "duration": 4.719,
        "text": "update data and when we retrieve data"
      },
      {
        "start": 1503.84,
        "duration": 5.839,
        "text": "those are seen as two different types of"
      },
      {
        "start": 1506.559,
        "duration": 5.041,
        "text": "uh requests right when we retrieve data"
      },
      {
        "start": 1509.679,
        "duration": 4.161,
        "text": "um we're getting a report we're getting"
      },
      {
        "start": 1511.6,
        "duration": 3.199,
        "text": "a data set when we're updating data"
      },
      {
        "start": 1513.84,
        "duration": 4.0,
        "text": "could be updating various"
      },
      {
        "start": 1514.799,
        "duration": 5.521,
        "text": "different things um and especially in"
      },
      {
        "start": 1517.84,
        "duration": 4.4,
        "text": "uh the nosql world um we often"
      },
      {
        "start": 1520.32,
        "duration": 4.239,
        "text": "materialize different"
      },
      {
        "start": 1522.24,
        "duration": 3.039,
        "text": "sets of data for fast fortune that's you"
      },
      {
        "start": 1524.559,
        "duration": 3.681,
        "text": "know one of the"
      },
      {
        "start": 1525.279,
        "duration": 3.601,
        "text": "data modeling uh trainings on data sex"
      },
      {
        "start": 1528.24,
        "duration": 3.52,
        "text": "academy"
      },
      {
        "start": 1528.88,
        "duration": 4.48,
        "text": "it talks about you know the ideal is to"
      },
      {
        "start": 1531.76,
        "duration": 3.76,
        "text": "have one partition for query now that"
      },
      {
        "start": 1533.36,
        "duration": 4.799,
        "text": "partition may have multiple rows"
      },
      {
        "start": 1535.52,
        "duration": 5.44,
        "text": "but you may have multiple tables to"
      },
      {
        "start": 1538.159,
        "duration": 5.681,
        "text": "represent different types of queries"
      },
      {
        "start": 1540.96,
        "duration": 4.64,
        "text": "so using event sources thing we can send"
      },
      {
        "start": 1543.84,
        "duration": 5.199,
        "text": "one event and then process it and save"
      },
      {
        "start": 1545.6,
        "duration": 3.439,
        "text": "that data into several different places"
      },
      {
        "start": 1551.84,
        "duration": 5.76,
        "text": "so let's talk a little bit about spark"
      },
      {
        "start": 1555.279,
        "duration": 3.681,
        "text": "what is it uh you know how to use it why"
      },
      {
        "start": 1557.6,
        "duration": 6.24,
        "text": "to use it when to use it"
      },
      {
        "start": 1558.96,
        "duration": 6.719,
        "text": "um apache spark is uh probably the"
      },
      {
        "start": 1563.84,
        "duration": 4.24,
        "text": "second or third generation at this point"
      },
      {
        "start": 1565.679,
        "duration": 5.761,
        "text": "yeah it's a spark 3.0 now"
      },
      {
        "start": 1568.08,
        "duration": 4.479,
        "text": "um and you know if you uh i'll show you"
      },
      {
        "start": 1571.44,
        "duration": 3.04,
        "text": "at google trends"
      },
      {
        "start": 1572.559,
        "duration": 3.921,
        "text": "uh you know apache spark is the de facto"
      },
      {
        "start": 1574.48,
        "duration": 5.199,
        "text": "way to do big data now"
      },
      {
        "start": 1576.48,
        "duration": 5.36,
        "text": "um you know pretty much you can do other"
      },
      {
        "start": 1579.679,
        "duration": 2.641,
        "text": "types of uh technologies for fast data"
      },
      {
        "start": 1581.84,
        "duration": 3.12,
        "text": "but"
      },
      {
        "start": 1582.32,
        "duration": 3.92,
        "text": "spark is kind of the name there are a"
      },
      {
        "start": 1584.96,
        "duration": 2.88,
        "text": "lot more people that still"
      },
      {
        "start": 1586.24,
        "duration": 4.64,
        "text": "use sorry there's a lot of people that"
      },
      {
        "start": 1587.84,
        "duration": 5.6,
        "text": "still use you know yarn and map reviews"
      },
      {
        "start": 1590.88,
        "duration": 3.36,
        "text": "but you can use spark on top of hadoop"
      },
      {
        "start": 1593.44,
        "duration": 3.119,
        "text": "so they're not"
      },
      {
        "start": 1594.24,
        "duration": 3.12,
        "text": "mutually exclusive people use hadoop"
      },
      {
        "start": 1596.559,
        "duration": 4.881,
        "text": "hdfs"
      },
      {
        "start": 1597.36,
        "duration": 6.72,
        "text": "and then they use spark alongside it"
      },
      {
        "start": 1601.44,
        "duration": 3.599,
        "text": "what is spark it's uh it's a collection"
      },
      {
        "start": 1604.08,
        "duration": 2.56,
        "text": "of technologies"
      },
      {
        "start": 1605.039,
        "duration": 3.841,
        "text": "just like kafka has a bunch of stuff"
      },
      {
        "start": 1606.64,
        "duration": 5.519,
        "text": "that runs on top of it to make it"
      },
      {
        "start": 1608.88,
        "duration": 5.039,
        "text": "kafka apache has"
      },
      {
        "start": 1612.159,
        "duration": 4.481,
        "text": "essentially a core and on top of the"
      },
      {
        "start": 1613.919,
        "duration": 5.76,
        "text": "core we have spark sql"
      },
      {
        "start": 1616.64,
        "duration": 6.159,
        "text": "which is a hive compliant uh"
      },
      {
        "start": 1619.679,
        "duration": 4.561,
        "text": "way to correct data in spark uh well how"
      },
      {
        "start": 1622.799,
        "duration": 4.24,
        "text": "to get data in spark"
      },
      {
        "start": 1624.24,
        "duration": 3.28,
        "text": "you bring it into a data frame or uh you"
      },
      {
        "start": 1627.039,
        "duration": 4.961,
        "text": "can"
      },
      {
        "start": 1627.52,
        "duration": 5.92,
        "text": "map a hive table or a spark sql table to"
      },
      {
        "start": 1632.0,
        "duration": 2.24,
        "text": "like a cassandra data store and you can"
      },
      {
        "start": 1633.44,
        "duration": 2.719,
        "text": "do queries"
      },
      {
        "start": 1634.24,
        "duration": 4.4,
        "text": "on cassandra you can do joins on"
      },
      {
        "start": 1636.159,
        "duration": 4.801,
        "text": "cassandra tables using spark"
      },
      {
        "start": 1638.64,
        "duration": 4.0,
        "text": "spark streaming uh this has gone through"
      },
      {
        "start": 1640.96,
        "duration": 3.92,
        "text": "a couple of different iterations"
      },
      {
        "start": 1642.64,
        "duration": 4.24,
        "text": "it's a way to stream events off of"
      },
      {
        "start": 1644.88,
        "duration": 4.399,
        "text": "various different types of queues"
      },
      {
        "start": 1646.88,
        "duration": 3.12,
        "text": "uh you can also have structured"
      },
      {
        "start": 1649.279,
        "duration": 3.441,
        "text": "streaming"
      },
      {
        "start": 1650.0,
        "duration": 3.039,
        "text": "which means that when you get the event"
      },
      {
        "start": 1652.72,
        "duration": 2.959,
        "text": "it"
      },
      {
        "start": 1653.039,
        "duration": 4.401,
        "text": "looks like a table essentially and we're"
      },
      {
        "start": 1655.679,
        "duration": 4.561,
        "text": "going to look at that code"
      },
      {
        "start": 1657.44,
        "duration": 4.479,
        "text": "later we have machine learning built in"
      },
      {
        "start": 1660.24,
        "duration": 3.12,
        "text": "and there are extensions to machine"
      },
      {
        "start": 1661.919,
        "duration": 5.281,
        "text": "learning libraries that you can"
      },
      {
        "start": 1663.36,
        "duration": 6.96,
        "text": "run on top of spark and then graph"
      },
      {
        "start": 1667.2,
        "duration": 5.359,
        "text": "which now we have graph frames um"
      },
      {
        "start": 1670.32,
        "duration": 3.28,
        "text": "basically to to do graph processing uh"
      },
      {
        "start": 1672.559,
        "duration": 2.321,
        "text": "with uh"
      },
      {
        "start": 1673.6,
        "duration": 2.64,
        "text": "like if you wanted to do the page rank"
      },
      {
        "start": 1674.88,
        "duration": 3.039,
        "text": "algorithm you could do it in like five"
      },
      {
        "start": 1676.24,
        "duration": 4.72,
        "text": "line"
      },
      {
        "start": 1677.919,
        "duration": 6.24,
        "text": "in in graph uh on top of spark"
      },
      {
        "start": 1680.96,
        "duration": 5.68,
        "text": "when we make a spark job what we're"
      },
      {
        "start": 1684.159,
        "duration": 5.041,
        "text": "really doing is we're creating a"
      },
      {
        "start": 1686.64,
        "duration": 4.399,
        "text": "directed acyclic graph a directed"
      },
      {
        "start": 1689.2,
        "duration": 2.479,
        "text": "asymptotic graph you're going to find"
      },
      {
        "start": 1691.039,
        "duration": 2.081,
        "text": "this term"
      },
      {
        "start": 1691.679,
        "duration": 3.521,
        "text": "in several places things like airflow"
      },
      {
        "start": 1693.12,
        "duration": 4.0,
        "text": "we'll talk about it"
      },
      {
        "start": 1695.2,
        "duration": 3.52,
        "text": "but basically directed means it's one"
      },
      {
        "start": 1697.12,
        "duration": 2.88,
        "text": "way"
      },
      {
        "start": 1698.72,
        "duration": 3.28,
        "text": "right the graph is going one way there's"
      },
      {
        "start": 1700.0,
        "duration": 4.24,
        "text": "no loops in the graph acyclic"
      },
      {
        "start": 1702.0,
        "duration": 3.279,
        "text": "uh is uh sorry directed means that it"
      },
      {
        "start": 1704.24,
        "duration": 2.48,
        "text": "has arrows"
      },
      {
        "start": 1705.279,
        "duration": 3.12,
        "text": "there's there's not there's no two way"
      },
      {
        "start": 1706.72,
        "duration": 2.559,
        "text": "but acyclic meaning that there's no"
      },
      {
        "start": 1708.399,
        "duration": 2.88,
        "text": "loops in it"
      },
      {
        "start": 1709.279,
        "duration": 3.28,
        "text": "and it's a graph it's it's nodes and"
      },
      {
        "start": 1711.279,
        "duration": 3.601,
        "text": "edges so a"
      },
      {
        "start": 1712.559,
        "duration": 4.641,
        "text": "we're creating a directed acyclic graph"
      },
      {
        "start": 1714.88,
        "duration": 4.96,
        "text": "of the work that needs to be done"
      },
      {
        "start": 1717.2,
        "duration": 3.12,
        "text": "and we do that by writing spark code"
      },
      {
        "start": 1719.84,
        "duration": 2.319,
        "text": "spark"
      },
      {
        "start": 1720.32,
        "duration": 4.32,
        "text": "actually does this work for us it makes"
      },
      {
        "start": 1722.159,
        "duration": 4.321,
        "text": "this and what it does it figures out how"
      },
      {
        "start": 1724.64,
        "duration": 4.56,
        "text": "much of this"
      },
      {
        "start": 1726.48,
        "duration": 4.319,
        "text": "directed acyclic graph needs to be run"
      },
      {
        "start": 1729.2,
        "duration": 3.68,
        "text": "on which computers"
      },
      {
        "start": 1730.799,
        "duration": 4.961,
        "text": "so if we do it right we can have the"
      },
      {
        "start": 1732.88,
        "duration": 4.32,
        "text": "same spark job running on one computer"
      },
      {
        "start": 1735.76,
        "duration": 3.84,
        "text": "or we can have it running on 100"
      },
      {
        "start": 1737.2,
        "duration": 3.359,
        "text": "computers and that's the point at which"
      },
      {
        "start": 1739.6,
        "duration": 5.04,
        "text": "spark becomes"
      },
      {
        "start": 1740.559,
        "duration": 5.761,
        "text": "a you know cousin uh so to speak or or"
      },
      {
        "start": 1744.64,
        "duration": 2.48,
        "text": "like a best friend of cassandra and"
      },
      {
        "start": 1746.32,
        "duration": 4.16,
        "text": "kafka"
      },
      {
        "start": 1747.12,
        "duration": 6.0,
        "text": "because kafka can scale to hundreds and"
      },
      {
        "start": 1750.48,
        "duration": 3.28,
        "text": "thousands of servers cassandra can scale"
      },
      {
        "start": 1753.12,
        "duration": 3.039,
        "text": "to"
      },
      {
        "start": 1753.76,
        "duration": 3.12,
        "text": "thousands to hundreds of thousands of"
      },
      {
        "start": 1756.159,
        "duration": 2.481,
        "text": "servers"
      },
      {
        "start": 1756.88,
        "duration": 3.36,
        "text": "uh spark i think the biggest one i've"
      },
      {
        "start": 1758.64,
        "duration": 2.56,
        "text": "seen is about a thousand node cluster of"
      },
      {
        "start": 1760.24,
        "duration": 2.96,
        "text": "spark"
      },
      {
        "start": 1761.2,
        "duration": 3.92,
        "text": "right and the other cool part about"
      },
      {
        "start": 1763.2,
        "duration": 3.68,
        "text": "spark is that it can talk to a bunch of"
      },
      {
        "start": 1765.12,
        "duration": 2.48,
        "text": "stuff we can talk to any data store that"
      },
      {
        "start": 1766.88,
        "duration": 2.72,
        "text": "you're looking"
      },
      {
        "start": 1767.6,
        "duration": 4.16,
        "text": "to connect to you can bring data in you"
      },
      {
        "start": 1769.6,
        "duration": 4.64,
        "text": "can send it to these different systems"
      },
      {
        "start": 1771.76,
        "duration": 4.399,
        "text": "um and you can represent this data on"
      },
      {
        "start": 1774.24,
        "duration": 3.6,
        "text": "these different systems in a similar way"
      },
      {
        "start": 1776.159,
        "duration": 5.361,
        "text": "in data frames"
      },
      {
        "start": 1777.84,
        "duration": 6.079,
        "text": "or now data sets is a new term"
      },
      {
        "start": 1781.52,
        "duration": 4.399,
        "text": "it's a unified analytics engine but i"
      },
      {
        "start": 1783.919,
        "duration": 4.961,
        "text": "would say it's like a general purpose"
      },
      {
        "start": 1785.919,
        "duration": 3.521,
        "text": "computing engine distributed computing"
      },
      {
        "start": 1788.88,
        "duration": 2.799,
        "text": "engine"
      },
      {
        "start": 1789.44,
        "duration": 3.359,
        "text": "where if you wanted to execute just"
      },
      {
        "start": 1791.679,
        "duration": 2.48,
        "text": "tasks"
      },
      {
        "start": 1792.799,
        "duration": 3.6,
        "text": "you could use spark but you may find"
      },
      {
        "start": 1794.159,
        "duration": 4.161,
        "text": "something else is a little bit uh"
      },
      {
        "start": 1796.399,
        "duration": 3.041,
        "text": "more lightweight spark has this"
      },
      {
        "start": 1798.32,
        "duration": 2.32,
        "text": "heaviness to it which"
      },
      {
        "start": 1799.44,
        "duration": 4.479,
        "text": "only makes sense if you're really going"
      },
      {
        "start": 1800.64,
        "duration": 3.279,
        "text": "to do some big number crunching"
      },
      {
        "start": 1804.48,
        "duration": 4.4,
        "text": "yes so um just just a word on the"
      },
      {
        "start": 1807.12,
        "duration": 4.72,
        "text": "overlap architecture so"
      },
      {
        "start": 1808.88,
        "duration": 3.919,
        "text": "uh we won't dig in too much today about"
      },
      {
        "start": 1811.84,
        "duration": 3.199,
        "text": "data stacks"
      },
      {
        "start": 1812.799,
        "duration": 3.281,
        "text": "enterprise the the enterprise product of"
      },
      {
        "start": 1815.039,
        "duration": 4.401,
        "text": "the nsx"
      },
      {
        "start": 1816.08,
        "duration": 6.4,
        "text": "but in the same node we do have"
      },
      {
        "start": 1819.44,
        "duration": 4.479,
        "text": "cassandra and spark so that means if you"
      },
      {
        "start": 1822.48,
        "duration": 4.079,
        "text": "need to scale"
      },
      {
        "start": 1823.919,
        "duration": 3.041,
        "text": "so you can scale both at the same time"
      },
      {
        "start": 1826.559,
        "duration": 3.441,
        "text": "and"
      },
      {
        "start": 1826.96,
        "duration": 5.04,
        "text": "spark is what we call token aware"
      },
      {
        "start": 1830.0,
        "duration": 4.08,
        "text": "so when spark need to distribute a"
      },
      {
        "start": 1832.0,
        "duration": 3.039,
        "text": "computation around multiple nodes on"
      },
      {
        "start": 1834.08,
        "duration": 3.44,
        "text": "cassandra"
      },
      {
        "start": 1835.039,
        "duration": 3.201,
        "text": "because spark is aware of the token"
      },
      {
        "start": 1837.52,
        "duration": 3.92,
        "text": "range"
      },
      {
        "start": 1838.24,
        "duration": 4.4,
        "text": "it can start up the executor as you can"
      },
      {
        "start": 1841.44,
        "duration": 3.52,
        "text": "see here in the slide"
      },
      {
        "start": 1842.64,
        "duration": 3.36,
        "text": "exactly at the good place to get the"
      },
      {
        "start": 1844.96,
        "duration": 3.599,
        "text": "computation"
      },
      {
        "start": 1846.0,
        "duration": 3.76,
        "text": "local with the data and that's you know"
      },
      {
        "start": 1848.559,
        "duration": 3.041,
        "text": "just the neat features of the"
      },
      {
        "start": 1849.76,
        "duration": 3.519,
        "text": "saxon enterprise if you don't have that"
      },
      {
        "start": 1851.6,
        "duration": 3.679,
        "text": "you can still do it but"
      },
      {
        "start": 1853.279,
        "duration": 4.4,
        "text": "you do have a cluster for spark and a"
      },
      {
        "start": 1855.279,
        "duration": 6.161,
        "text": "cluster of cassandra you can do that"
      },
      {
        "start": 1857.679,
        "duration": 4.48,
        "text": "as an open source as well yeah datastax"
      },
      {
        "start": 1861.44,
        "duration": 3.28,
        "text": "makes it"
      },
      {
        "start": 1862.159,
        "duration": 5.281,
        "text": "too easy to do spark with cassandra like"
      },
      {
        "start": 1864.72,
        "duration": 2.72,
        "text": "once you use it"
      },
      {
        "start": 1868.48,
        "duration": 3.919,
        "text": "um but uh you know maybe we'll that's"
      },
      {
        "start": 1870.96,
        "duration": 2.88,
        "text": "that's gonna be a follow-on you know how"
      },
      {
        "start": 1872.399,
        "duration": 1.841,
        "text": "to use data stacks for all of this stuff"
      },
      {
        "start": 1873.84,
        "duration": 1.839,
        "text": "but"
      },
      {
        "start": 1874.24,
        "duration": 3.919,
        "text": "uh you know today yeah we're gonna talk"
      },
      {
        "start": 1875.679,
        "duration": 3.681,
        "text": "about astro which is basically cassandra"
      },
      {
        "start": 1878.159,
        "duration": 4.0,
        "text": "as a service and we're going to use"
      },
      {
        "start": 1879.36,
        "duration": 5.039,
        "text": "spark uh but spark with cassandra on the"
      },
      {
        "start": 1882.159,
        "duration": 4.721,
        "text": "same note is very very powerful"
      },
      {
        "start": 1884.399,
        "duration": 3.041,
        "text": "um and you know before we we end i'll"
      },
      {
        "start": 1886.88,
        "duration": 2.32,
        "text": "just show"
      },
      {
        "start": 1887.44,
        "duration": 3.28,
        "text": "kind of a comparison between if you were"
      },
      {
        "start": 1889.2,
        "duration": 2.959,
        "text": "to do this on your own"
      },
      {
        "start": 1890.72,
        "duration": 5.36,
        "text": "how much work you'd have to do versus"
      },
      {
        "start": 1892.159,
        "duration": 3.921,
        "text": "kind of using the data stacks ecosystem"
      },
      {
        "start": 1896.48,
        "duration": 3.84,
        "text": "when we make a spark program generally"
      },
      {
        "start": 1899.44,
        "duration": 4.239,
        "text": "we have"
      },
      {
        "start": 1900.32,
        "duration": 5.359,
        "text": "a driver we have a cluster manager"
      },
      {
        "start": 1903.679,
        "duration": 3.201,
        "text": "that allocates resources and then we"
      },
      {
        "start": 1905.679,
        "duration": 3.281,
        "text": "have different workers"
      },
      {
        "start": 1906.88,
        "duration": 3.6,
        "text": "so you'll see in when we bring up spark"
      },
      {
        "start": 1908.96,
        "duration": 2.16,
        "text": "we're going to bring up the master and"
      },
      {
        "start": 1910.48,
        "duration": 2.16,
        "text": "then we're going to"
      },
      {
        "start": 1911.12,
        "duration": 3.439,
        "text": "that's going to be in standalone mode"
      },
      {
        "start": 1912.64,
        "duration": 4.72,
        "text": "and we're going to bring up one worker"
      },
      {
        "start": 1914.559,
        "duration": 3.281,
        "text": "right because we we have viet pod giving"
      },
      {
        "start": 1917.36,
        "duration": 2.96,
        "text": "us"
      },
      {
        "start": 1917.84,
        "duration": 3.52,
        "text": "roughly i think 16 gigs of ram which i'm"
      },
      {
        "start": 1920.32,
        "duration": 4.479,
        "text": "impressed how much"
      },
      {
        "start": 1921.36,
        "duration": 5.76,
        "text": "did we get and"
      },
      {
        "start": 1924.799,
        "duration": 4.321,
        "text": "but if we wanted to we could have"
      },
      {
        "start": 1927.12,
        "duration": 2.32,
        "text": "thousands of nodes running and as long"
      },
      {
        "start": 1929.12,
        "duration": 3.36,
        "text": "as"
      },
      {
        "start": 1929.44,
        "duration": 4.959,
        "text": "we connect the worker to that"
      },
      {
        "start": 1932.48,
        "duration": 5.199,
        "text": "cluster manager that cluster manager"
      },
      {
        "start": 1934.399,
        "duration": 3.28,
        "text": "will see that as a new worker"
      },
      {
        "start": 1938.0,
        "duration": 6.799,
        "text": "um a couple of things so spark sql"
      },
      {
        "start": 1941.44,
        "duration": 6.479,
        "text": "uh is a way to uh query data"
      },
      {
        "start": 1944.799,
        "duration": 4.48,
        "text": "uh update and really join data from"
      },
      {
        "start": 1947.919,
        "duration": 3.201,
        "text": "various different places it has a"
      },
      {
        "start": 1949.279,
        "duration": 2.64,
        "text": "built-in optimizer that once you write"
      },
      {
        "start": 1951.12,
        "duration": 3.52,
        "text": "spark"
      },
      {
        "start": 1951.919,
        "duration": 4.961,
        "text": "sql it creates a spark job and it goes"
      },
      {
        "start": 1954.64,
        "duration": 5.6,
        "text": "grabs the data and brings it back to you"
      },
      {
        "start": 1956.88,
        "duration": 6.48,
        "text": "um you can think about a a data frame"
      },
      {
        "start": 1960.24,
        "duration": 5.2,
        "text": "like if you've ever used um"
      },
      {
        "start": 1963.36,
        "duration": 3.28,
        "text": "pant your pandas a data frame is like"
      },
      {
        "start": 1965.44,
        "duration": 4.079,
        "text": "kind of like a database"
      },
      {
        "start": 1966.64,
        "duration": 4.32,
        "text": "in memory uh and so spark when you deal"
      },
      {
        "start": 1969.519,
        "duration": 2.4,
        "text": "with spark when you do operations on"
      },
      {
        "start": 1970.96,
        "duration": 3.439,
        "text": "spark"
      },
      {
        "start": 1971.919,
        "duration": 3.281,
        "text": "it doesn't do anything until you say"
      },
      {
        "start": 1974.399,
        "duration": 2.16,
        "text": "like"
      },
      {
        "start": 1975.2,
        "duration": 3.199,
        "text": "you know do this up basically there's"
      },
      {
        "start": 1976.559,
        "duration": 4.881,
        "text": "transformations and there's actions"
      },
      {
        "start": 1978.399,
        "duration": 5.28,
        "text": "um but ultimately it only does the work"
      },
      {
        "start": 1981.44,
        "duration": 4.32,
        "text": "once you execute the you know group y or"
      },
      {
        "start": 1983.679,
        "duration": 4.401,
        "text": "aggregate function or output function"
      },
      {
        "start": 1985.76,
        "duration": 3.12,
        "text": "up until then it kind of keeps this you"
      },
      {
        "start": 1988.08,
        "duration": 3.04,
        "text": "know dag"
      },
      {
        "start": 1988.88,
        "duration": 3.12,
        "text": "but a data frame is a is a place where"
      },
      {
        "start": 1991.12,
        "duration": 4.32,
        "text": "you can have multiple"
      },
      {
        "start": 1992.0,
        "duration": 5.44,
        "text": "kind of tables uh in one object and you"
      },
      {
        "start": 1995.44,
        "duration": 4.719,
        "text": "can do operations on the same thing"
      },
      {
        "start": 1997.44,
        "duration": 3.599,
        "text": "um we're gonna look at data frames very"
      },
      {
        "start": 2000.159,
        "duration": 4.801,
        "text": "briefly"
      },
      {
        "start": 2001.039,
        "duration": 6.961,
        "text": "um but uh you know uh"
      },
      {
        "start": 2004.96,
        "duration": 5.439,
        "text": "just remember that data frames are like"
      },
      {
        "start": 2008.0,
        "duration": 4.32,
        "text": "the newer way of doing things rdds or"
      },
      {
        "start": 2010.399,
        "duration": 2.321,
        "text": "resilient data sets are the older way of"
      },
      {
        "start": 2012.32,
        "duration": 2.719,
        "text": "doing"
      },
      {
        "start": 2012.72,
        "duration": 3.199,
        "text": "things and now there's something called"
      },
      {
        "start": 2015.039,
        "duration": 3.441,
        "text": "data sets"
      },
      {
        "start": 2015.919,
        "duration": 4.081,
        "text": "which is the newer or yet still way of"
      },
      {
        "start": 2018.48,
        "duration": 1.919,
        "text": "doing things but all of these data"
      },
      {
        "start": 2020.0,
        "duration": 2.72,
        "text": "frames"
      },
      {
        "start": 2020.399,
        "duration": 3.28,
        "text": "rdds uh they're just representations of"
      },
      {
        "start": 2022.72,
        "duration": 3.12,
        "text": "your data"
      },
      {
        "start": 2023.679,
        "duration": 3.201,
        "text": "right when you connect to cassandra and"
      },
      {
        "start": 2025.84,
        "duration": 3.52,
        "text": "you say i want to"
      },
      {
        "start": 2026.88,
        "duration": 4.32,
        "text": "select from here what it does it it gets"
      },
      {
        "start": 2029.36,
        "duration": 4.96,
        "text": "that data from cassandra and brings it"
      },
      {
        "start": 2031.2,
        "duration": 5.199,
        "text": "into memory in spark"
      },
      {
        "start": 2034.32,
        "duration": 4.0,
        "text": "that's the way spark does its work when"
      },
      {
        "start": 2036.399,
        "duration": 2.88,
        "text": "you update that data frame and you say"
      },
      {
        "start": 2038.32,
        "duration": 3.839,
        "text": "save it"
      },
      {
        "start": 2039.279,
        "duration": 6.801,
        "text": "it first updates it in memory and then"
      },
      {
        "start": 2042.159,
        "duration": 6.96,
        "text": "and it saves it back to xampp"
      },
      {
        "start": 2046.08,
        "duration": 3.999,
        "text": "spark streaming is uh gone through as i"
      },
      {
        "start": 2049.119,
        "duration": 1.76,
        "text": "mentioned earlier two different"
      },
      {
        "start": 2050.079,
        "duration": 3.681,
        "text": "generations"
      },
      {
        "start": 2050.879,
        "duration": 4.321,
        "text": "um spark streaming has two ways of doing"
      },
      {
        "start": 2053.76,
        "duration": 2.72,
        "text": "things one is just basic spark"
      },
      {
        "start": 2055.2,
        "duration": 2.399,
        "text": "streaming and another is structured"
      },
      {
        "start": 2056.48,
        "duration": 2.48,
        "text": "streaming we're going to be doing"
      },
      {
        "start": 2057.599,
        "duration": 4.161,
        "text": "structured streaming"
      },
      {
        "start": 2058.96,
        "duration": 3.84,
        "text": "um the main thing about structured"
      },
      {
        "start": 2061.76,
        "duration": 4.0,
        "text": "streaming is that it"
      },
      {
        "start": 2062.8,
        "duration": 4.559,
        "text": "gives you a schema right when you're"
      },
      {
        "start": 2065.76,
        "duration": 4.72,
        "text": "getting the event from your stream"
      },
      {
        "start": 2067.359,
        "duration": 4.24,
        "text": "you're getting it as a row with columns"
      },
      {
        "start": 2070.48,
        "duration": 4.08,
        "text": "with the named columns"
      },
      {
        "start": 2071.599,
        "duration": 4.161,
        "text": "so you can do select from that stream"
      },
      {
        "start": 2074.56,
        "duration": 4.559,
        "text": "and you can do"
      },
      {
        "start": 2075.76,
        "duration": 7.76,
        "text": "spark sql transformations on that data"
      },
      {
        "start": 2079.119,
        "duration": 6.0,
        "text": "before you send it through right um"
      },
      {
        "start": 2083.52,
        "duration": 3.68,
        "text": "this is the type of stuff that's also"
      },
      {
        "start": 2085.119,
        "duration": 6.0,
        "text": "available in kafka streams"
      },
      {
        "start": 2087.2,
        "duration": 5.76,
        "text": "right with k tables um but"
      },
      {
        "start": 2091.119,
        "duration": 3.28,
        "text": "when we're dealing with spark streamings"
      },
      {
        "start": 2092.96,
        "duration": 4.879,
        "text": "and especially structure streaming"
      },
      {
        "start": 2094.399,
        "duration": 5.2,
        "text": "you have the power of spark across"
      },
      {
        "start": 2097.839,
        "duration": 3.76,
        "text": "hundreds of thousands of nodes where you"
      },
      {
        "start": 2099.599,
        "duration": 5.041,
        "text": "can distribute the work if you need to"
      },
      {
        "start": 2101.599,
        "duration": 4.0,
        "text": "a common use case for this would be you"
      },
      {
        "start": 2104.64,
        "duration": 2.08,
        "text": "have a model"
      },
      {
        "start": 2105.599,
        "duration": 3.601,
        "text": "like a machine learning model that"
      },
      {
        "start": 2106.72,
        "duration": 5.44,
        "text": "you've made already and"
      },
      {
        "start": 2109.2,
        "duration": 3.84,
        "text": "you ingest as a streamed event and you"
      },
      {
        "start": 2112.16,
        "duration": 4.24,
        "text": "evaluate"
      },
      {
        "start": 2113.04,
        "duration": 4.799,
        "text": "that data using your model in in spark"
      },
      {
        "start": 2116.4,
        "duration": 3.679,
        "text": "and then you send it through and"
      },
      {
        "start": 2117.839,
        "duration": 4.161,
        "text": "simultaneously what you can"
      },
      {
        "start": 2120.079,
        "duration": 4.801,
        "text": "say is go ahead and update my model with"
      },
      {
        "start": 2122.0,
        "duration": 5.04,
        "text": "my positive evaluation"
      },
      {
        "start": 2124.88,
        "duration": 3.44,
        "text": "a couple of use cases uh you may have"
      },
      {
        "start": 2127.04,
        "duration": 4.4,
        "text": "heard of these"
      },
      {
        "start": 2128.32,
        "duration": 6.32,
        "text": "companies uh uber pinterest"
      },
      {
        "start": 2131.44,
        "duration": 4.96,
        "text": "uh netflix ebay and viva um what you"
      },
      {
        "start": 2134.64,
        "duration": 2.4,
        "text": "know what do people do with spark i mean"
      },
      {
        "start": 2136.4,
        "duration": 4.719,
        "text": "everything"
      },
      {
        "start": 2137.04,
        "duration": 4.079,
        "text": "tell me what they don't do with spark uh"
      },
      {
        "start": 2141.839,
        "duration": 3.201,
        "text": "um know used to be that we would say you"
      },
      {
        "start": 2144.72,
        "duration": 3.52,
        "text": "know"
      },
      {
        "start": 2145.04,
        "duration": 5.36,
        "text": "etl is spark is not for etl and"
      },
      {
        "start": 2148.24,
        "duration": 3.92,
        "text": "over time spark is used for etl all the"
      },
      {
        "start": 2150.4,
        "duration": 4.8,
        "text": "time um"
      },
      {
        "start": 2152.16,
        "duration": 4.72,
        "text": "so but people now do streaming etl they"
      },
      {
        "start": 2155.2,
        "duration": 4.24,
        "text": "bring data in"
      },
      {
        "start": 2156.88,
        "duration": 3.44,
        "text": "you know they'll do they'll do elt right"
      },
      {
        "start": 2159.44,
        "duration": 3.36,
        "text": "extract it"
      },
      {
        "start": 2160.32,
        "duration": 4.24,
        "text": "load it and then transform it which is"
      },
      {
        "start": 2162.8,
        "duration": 4.08,
        "text": "kind of what we're gonna do today"
      },
      {
        "start": 2164.56,
        "duration": 3.039,
        "text": "uh to enrich information after it sits"
      },
      {
        "start": 2166.88,
        "duration": 4.239,
        "text": "somewhere"
      },
      {
        "start": 2167.599,
        "duration": 6.801,
        "text": "um i mean it's"
      },
      {
        "start": 2171.119,
        "duration": 4.0,
        "text": "it's got a lot of power um i can't do it"
      },
      {
        "start": 2174.4,
        "duration": 2.4,
        "text": "justice"
      },
      {
        "start": 2175.119,
        "duration": 4.081,
        "text": "in this workshop to tell you the power"
      },
      {
        "start": 2176.8,
        "duration": 4.0,
        "text": "of spark um"
      },
      {
        "start": 2179.2,
        "duration": 3.6,
        "text": "once you start using it you'll"
      },
      {
        "start": 2180.8,
        "duration": 5.84,
        "text": "understand that it's it's not"
      },
      {
        "start": 2182.8,
        "duration": 4.559,
        "text": "um you know it's not a kitty tool like"
      },
      {
        "start": 2186.64,
        "duration": 1.76,
        "text": "it's not a toy"
      },
      {
        "start": 2187.359,
        "duration": 3.441,
        "text": "it's got a lot of power just like"
      },
      {
        "start": 2188.4,
        "duration": 3.92,
        "text": "cassandra in kafka you can use it"
      },
      {
        "start": 2190.8,
        "duration": 4.24,
        "text": "but it's really powerful when you bring"
      },
      {
        "start": 2192.32,
        "duration": 2.72,
        "text": "these things together"
      },
      {
        "start": 2195.44,
        "duration": 4.08,
        "text": "uh and then finally you know the spark"
      },
      {
        "start": 2198.16,
        "duration": 5.04,
        "text": "um"
      },
      {
        "start": 2199.52,
        "duration": 6.8,
        "text": "ecosystem um is continues to grow"
      },
      {
        "start": 2203.2,
        "duration": 5.6,
        "text": "there's a site called spark packages um"
      },
      {
        "start": 2206.32,
        "duration": 3.84,
        "text": "you know where you can see just for the"
      },
      {
        "start": 2208.8,
        "duration": 3.6,
        "text": "tags for data sources"
      },
      {
        "start": 2210.16,
        "duration": 4.32,
        "text": "there's like 61 different data sources"
      },
      {
        "start": 2212.4,
        "duration": 4.24,
        "text": "that you can connect to um"
      },
      {
        "start": 2214.48,
        "duration": 4.08,
        "text": "you can also go to the site and use"
      },
      {
        "start": 2216.64,
        "duration": 6.16,
        "text": "there's about 500 different packages"
      },
      {
        "start": 2218.56,
        "duration": 4.24,
        "text": "just for spark right but"
      },
      {
        "start": 2223.119,
        "duration": 3.841,
        "text": "if you are in the smart casing system"
      },
      {
        "start": 2224.8,
        "duration": 4.4,
        "text": "without any of these packages"
      },
      {
        "start": 2226.96,
        "duration": 3.6,
        "text": "if you're using scala any scholar"
      },
      {
        "start": 2229.2,
        "duration": 4.399,
        "text": "libraries available for you"
      },
      {
        "start": 2230.56,
        "duration": 5.36,
        "text": "any java library is available to you um"
      },
      {
        "start": 2233.599,
        "duration": 4.0,
        "text": "there's also r if you're a statistician"
      },
      {
        "start": 2235.92,
        "duration": 2.24,
        "text": "or a data scientist sometimes people use"
      },
      {
        "start": 2237.599,
        "duration": 2.961,
        "text": "r"
      },
      {
        "start": 2238.16,
        "duration": 3.04,
        "text": "versus where it says python same thing"
      },
      {
        "start": 2240.56,
        "duration": 2.559,
        "text": "with python"
      },
      {
        "start": 2241.2,
        "duration": 3.44,
        "text": "all the things that you can do in python"
      },
      {
        "start": 2243.119,
        "duration": 3.601,
        "text": "you can do in spark you just have to"
      },
      {
        "start": 2244.64,
        "duration": 3.84,
        "text": "think about the distributed computing"
      },
      {
        "start": 2246.72,
        "duration": 4.8,
        "text": "nature uh meaning you don't want to have"
      },
      {
        "start": 2248.48,
        "duration": 5.359,
        "text": "a long running process on every world"
      },
      {
        "start": 2251.52,
        "duration": 5.12,
        "text": "i mean you think about it but you can do"
      },
      {
        "start": 2253.839,
        "duration": 3.441,
        "text": "it and then recently uh c sharp and f"
      },
      {
        "start": 2256.64,
        "duration": 3.68,
        "text": "sharp"
      },
      {
        "start": 2257.28,
        "duration": 5.2,
        "text": "um which are basically.net languages uh"
      },
      {
        "start": 2260.32,
        "duration": 5.12,
        "text": "they also have a binding for spark"
      },
      {
        "start": 2262.48,
        "duration": 5.2,
        "text": "oh really i was not aware c sharp f"
      },
      {
        "start": 2265.44,
        "duration": 2.24,
        "text": "shaft"
      },
      {
        "start": 2268.16,
        "duration": 3.04,
        "text": "yeah uh it's been there for a while it"
      },
      {
        "start": 2269.76,
        "duration": 3.76,
        "text": "used to be called mobius"
      },
      {
        "start": 2271.2,
        "duration": 3.12,
        "text": "um and then now it's just called.net"
      },
      {
        "start": 2273.52,
        "duration": 4.16,
        "text": "spark"
      },
      {
        "start": 2274.32,
        "duration": 5.68,
        "text": "um and uh and then finally kotlin"
      },
      {
        "start": 2277.68,
        "duration": 5.04,
        "text": "uh which is fairly new language compared"
      },
      {
        "start": 2280.0,
        "duration": 4.96,
        "text": "to uh in the spark in south ascala"
      },
      {
        "start": 2282.72,
        "duration": 3.84,
        "text": "um it's kind of new it's not it's kind"
      },
      {
        "start": 2284.96,
        "duration": 1.92,
        "text": "of a release candidate right now but you"
      },
      {
        "start": 2286.56,
        "duration": 1.68,
        "text": "know"
      },
      {
        "start": 2286.88,
        "duration": 3.68,
        "text": "if you're into kotlin you can check it"
      },
      {
        "start": 2288.24,
        "duration": 5.599,
        "text": "out um just remember that"
      },
      {
        "start": 2290.56,
        "duration": 5.84,
        "text": "scala and python are the only"
      },
      {
        "start": 2293.839,
        "duration": 3.841,
        "text": "supported languages to do uh read"
      },
      {
        "start": 2296.4,
        "duration": 3.52,
        "text": "evaluate print"
      },
      {
        "start": 2297.68,
        "duration": 3.04,
        "text": "loop meaning you can just start up a"
      },
      {
        "start": 2299.92,
        "duration": 3.36,
        "text": "shell"
      },
      {
        "start": 2300.72,
        "duration": 3.84,
        "text": "and start programming in spark and and"
      },
      {
        "start": 2303.28,
        "duration": 3.92,
        "text": "see things happen"
      },
      {
        "start": 2304.56,
        "duration": 3.44,
        "text": "um and then sql is available in a rupple"
      },
      {
        "start": 2307.2,
        "duration": 3.84,
        "text": "as well"
      },
      {
        "start": 2308.0,
        "duration": 5.44,
        "text": "uh in the spark sql shell as well as uh"
      },
      {
        "start": 2311.04,
        "duration": 4.4,
        "text": "if you start the thrift server"
      },
      {
        "start": 2313.44,
        "duration": 4.159,
        "text": "you can get data via jdbc so you can"
      },
      {
        "start": 2315.44,
        "duration": 4.0,
        "text": "connect a business intelligence tool"
      },
      {
        "start": 2317.599,
        "duration": 5.201,
        "text": "like tableau"
      },
      {
        "start": 2319.44,
        "duration": 7.12,
        "text": "or click or power bi"
      },
      {
        "start": 2322.8,
        "duration": 5.44,
        "text": "to a spark instance and"
      },
      {
        "start": 2326.56,
        "duration": 3.279,
        "text": "imagine right you can bring all this"
      },
      {
        "start": 2328.24,
        "duration": 4.96,
        "text": "data into spark"
      },
      {
        "start": 2329.839,
        "duration": 5.921,
        "text": "and then it once it's in there you can"
      },
      {
        "start": 2333.2,
        "duration": 3.52,
        "text": "look at it and you can do joins on it"
      },
      {
        "start": 2335.76,
        "duration": 5.76,
        "text": "and view it"
      },
      {
        "start": 2336.72,
        "duration": 6.16,
        "text": "via different tools spark also runs on"
      },
      {
        "start": 2341.52,
        "duration": 3.28,
        "text": "basically anything"
      },
      {
        "start": 2342.88,
        "duration": 4.4,
        "text": "so it runs on docker i mean we're going"
      },
      {
        "start": 2344.8,
        "duration": 5.68,
        "text": "to be running it inside a git pod docker"
      },
      {
        "start": 2347.28,
        "duration": 5.28,
        "text": "there's mesos kubernetes"
      },
      {
        "start": 2350.48,
        "duration": 3.68,
        "text": "you know you can run it basically"
      },
      {
        "start": 2352.56,
        "duration": 2.08,
        "text": "anywhere technology runs you can run"
      },
      {
        "start": 2354.16,
        "duration": 2.72,
        "text": "spark"
      },
      {
        "start": 2354.64,
        "duration": 3.28,
        "text": "because it's java it's a jvm system"
      },
      {
        "start": 2356.88,
        "duration": 2.239,
        "text": "right"
      },
      {
        "start": 2357.92,
        "duration": 4.32,
        "text": "and these are just different ways to"
      },
      {
        "start": 2359.119,
        "duration": 3.121,
        "text": "organize the cluster"
      },
      {
        "start": 2362.96,
        "duration": 6.159,
        "text": "uh just just if before switching"
      },
      {
        "start": 2366.24,
        "duration": 4.24,
        "text": "if you go back uh so we told you that"
      },
      {
        "start": 2369.119,
        "duration": 4.72,
        "text": "you can do gdbc"
      },
      {
        "start": 2370.48,
        "duration": 4.8,
        "text": "over uh spark that's you know that's"
      },
      {
        "start": 2373.839,
        "duration": 6.561,
        "text": "true sparks ql"
      },
      {
        "start": 2375.28,
        "duration": 7.2,
        "text": "and gdbc drivers like simba for instance"
      },
      {
        "start": 2380.4,
        "duration": 4.08,
        "text": "that's still a spark you know don't"
      },
      {
        "start": 2382.48,
        "duration": 5.119,
        "text": "expect real time"
      },
      {
        "start": 2384.48,
        "duration": 3.84,
        "text": "uh computation when you query a billion"
      },
      {
        "start": 2387.599,
        "duration": 3.361,
        "text": "rows"
      },
      {
        "start": 2388.32,
        "duration": 4.24,
        "text": "okay yes spark is mostly for you know in"
      },
      {
        "start": 2390.96,
        "duration": 5.119,
        "text": "this use case mostly for"
      },
      {
        "start": 2392.56,
        "duration": 4.08,
        "text": "olap queries and the response time is"
      },
      {
        "start": 2396.079,
        "duration": 3.441,
        "text": "about"
      },
      {
        "start": 2396.64,
        "duration": 4.64,
        "text": "in a few seconds even minute depending"
      },
      {
        "start": 2399.52,
        "duration": 2.72,
        "text": "on the volume the computation is still"
      },
      {
        "start": 2401.28,
        "duration": 3.2,
        "text": "distributed"
      },
      {
        "start": 2402.24,
        "duration": 4.8,
        "text": "but there are still a lot of data to"
      },
      {
        "start": 2404.48,
        "duration": 5.16,
        "text": "move over the wire here and there"
      },
      {
        "start": 2407.04,
        "duration": 5.12,
        "text": "so it's cool for tableau but you know"
      },
      {
        "start": 2409.64,
        "duration": 6.6,
        "text": "pre-computed dashboard you know"
      },
      {
        "start": 2412.16,
        "duration": 6.0,
        "text": "yeah yeah and it depends on the bi tool"
      },
      {
        "start": 2416.24,
        "duration": 3.44,
        "text": "that you use a lot of these tools will"
      },
      {
        "start": 2418.16,
        "duration": 3.6,
        "text": "cache the results and they'll you know"
      },
      {
        "start": 2419.68,
        "duration": 3.28,
        "text": "they'll pull the the spark sql to get"
      },
      {
        "start": 2421.76,
        "duration": 3.599,
        "text": "this information"
      },
      {
        "start": 2422.96,
        "duration": 3.2,
        "text": "um but uh you know if you have a lot of"
      },
      {
        "start": 2425.359,
        "duration": 2.24,
        "text": "juice"
      },
      {
        "start": 2426.16,
        "duration": 4.64,
        "text": "you have a lot of machinery a lot of"
      },
      {
        "start": 2427.599,
        "duration": 5.201,
        "text": "memory you can get pretty fast results"
      },
      {
        "start": 2430.8,
        "duration": 3.84,
        "text": "you just have to have like terabytes of"
      },
      {
        "start": 2432.8,
        "duration": 5.2,
        "text": "memory in your cluster"
      },
      {
        "start": 2434.64,
        "duration": 6.4,
        "text": "yeah yeah you need power you need power"
      },
      {
        "start": 2438.0,
        "duration": 6.4,
        "text": "exactly um this i found interesting"
      },
      {
        "start": 2441.04,
        "duration": 4.319,
        "text": "i just was curious uh to see you know"
      },
      {
        "start": 2444.4,
        "duration": 3.439,
        "text": "spark"
      },
      {
        "start": 2445.359,
        "duration": 3.521,
        "text": "versus uh big data versus you know"
      },
      {
        "start": 2447.839,
        "duration": 3.52,
        "text": "machine learning"
      },
      {
        "start": 2448.88,
        "duration": 4.32,
        "text": "you know how has it come in terms of how"
      },
      {
        "start": 2451.359,
        "duration": 4.72,
        "text": "the world sees this stuff"
      },
      {
        "start": 2453.2,
        "duration": 4.399,
        "text": "and you know notice that machine"
      },
      {
        "start": 2456.079,
        "duration": 2.961,
        "text": "learning has always been around"
      },
      {
        "start": 2457.599,
        "duration": 3.681,
        "text": "well not always it's been around and it"
      },
      {
        "start": 2459.04,
        "duration": 4.4,
        "text": "was more popular than"
      },
      {
        "start": 2461.28,
        "duration": 4.0,
        "text": "big data and spark right this only goes"
      },
      {
        "start": 2463.44,
        "duration": 8.72,
        "text": "back to december 2008"
      },
      {
        "start": 2465.28,
        "duration": 10.559,
        "text": "but around i would say 2010 or 11"
      },
      {
        "start": 2472.16,
        "duration": 5.84,
        "text": "big data started to take off um way more"
      },
      {
        "start": 2475.839,
        "duration": 5.121,
        "text": "was much more popular and then spark was"
      },
      {
        "start": 2478.0,
        "duration": 6.0,
        "text": "like slow and steady and here it comes"
      },
      {
        "start": 2480.96,
        "duration": 4.399,
        "text": "right here it comes and it's now more"
      },
      {
        "start": 2484.0,
        "duration": 2.88,
        "text": "popular than big data"
      },
      {
        "start": 2485.359,
        "duration": 3.601,
        "text": "and machine learning people can do with"
      },
      {
        "start": 2486.88,
        "duration": 5.04,
        "text": "it without spark but i'm just"
      },
      {
        "start": 2488.96,
        "duration": 4.879,
        "text": "just fascinated how spark as a term"
      },
      {
        "start": 2491.92,
        "duration": 4.48,
        "text": "apache spark is a term"
      },
      {
        "start": 2493.839,
        "duration": 3.121,
        "text": "is more popular than the term big data"
      },
      {
        "start": 2496.4,
        "duration": 3.6,
        "text": "because"
      },
      {
        "start": 2496.96,
        "duration": 4.639,
        "text": "we do big data with spark right"
      },
      {
        "start": 2500.0,
        "duration": 4.16,
        "text": "uh really interesting which you can find"
      },
      {
        "start": 2501.599,
        "duration": 5.52,
        "text": "on google trends no more pig"
      },
      {
        "start": 2504.16,
        "duration": 4.32,
        "text": "or yeah no i've no no spark is"
      },
      {
        "start": 2507.119,
        "duration": 4.641,
        "text": "everywhere"
      },
      {
        "start": 2508.48,
        "duration": 4.4,
        "text": "yeah um so"
      },
      {
        "start": 2511.76,
        "duration": 3.2,
        "text": "i said you're just going to talk a"
      },
      {
        "start": 2512.88,
        "duration": 6.08,
        "text": "little bit about astra yeah so let's"
      },
      {
        "start": 2514.96,
        "duration": 5.6,
        "text": "let's yeah yeah so can you move to the"
      },
      {
        "start": 2518.96,
        "duration": 3.84,
        "text": "next slide yeah i think"
      },
      {
        "start": 2520.56,
        "duration": 3.44,
        "text": "i would explain everything in a single"
      },
      {
        "start": 2522.8,
        "duration": 4.88,
        "text": "slide so"
      },
      {
        "start": 2524.0,
        "duration": 6.88,
        "text": "really astra in top your mind should be"
      },
      {
        "start": 2527.68,
        "duration": 7.36,
        "text": "a data platform as a service available"
      },
      {
        "start": 2530.88,
        "duration": 7.52,
        "text": "in the cloud with cassandra at the core"
      },
      {
        "start": 2535.04,
        "duration": 5.52,
        "text": "and tons of tools to um"
      },
      {
        "start": 2538.4,
        "duration": 4.32,
        "text": "you know to help you build up on top of"
      },
      {
        "start": 2540.56,
        "duration": 7.039,
        "text": "customers so api"
      },
      {
        "start": 2542.72,
        "duration": 7.2,
        "text": "monitoring you know web console"
      },
      {
        "start": 2547.599,
        "duration": 3.201,
        "text": "i kind of ide to to to shape your"
      },
      {
        "start": 2549.92,
        "duration": 4.88,
        "text": "queries"
      },
      {
        "start": 2550.8,
        "duration": 4.96,
        "text": "stuff like that so it's eliminates all"
      },
      {
        "start": 2554.8,
        "duration": 2.96,
        "text": "the operation"
      },
      {
        "start": 2555.76,
        "duration": 3.92,
        "text": "because it's software as a service it's"
      },
      {
        "start": 2557.76,
        "duration": 2.319,
        "text": "secure your data because now you access"
      },
      {
        "start": 2559.68,
        "duration": 3.439,
        "text": "them"
      },
      {
        "start": 2560.079,
        "duration": 4.161,
        "text": "through api and airbag and in simplify"
      },
      {
        "start": 2563.119,
        "duration": 2.96,
        "text": "your development because"
      },
      {
        "start": 2564.24,
        "duration": 3.359,
        "text": "you know with the api now you can use"
      },
      {
        "start": 2566.079,
        "duration": 5.441,
        "text": "either a document api"
      },
      {
        "start": 2567.599,
        "duration": 5.76,
        "text": "and use cassandra like or um"
      },
      {
        "start": 2571.52,
        "duration": 5.36,
        "text": "you know don't do that in data modeling"
      },
      {
        "start": 2573.359,
        "duration": 3.521,
        "text": "okay that's technically feasible"
      },
      {
        "start": 2576.96,
        "duration": 6.879,
        "text": "or you know pretty easy to generate"
      },
      {
        "start": 2580.079,
        "duration": 5.04,
        "text": "api on top of of tables and if you go to"
      },
      {
        "start": 2583.839,
        "duration": 3.52,
        "text": "next slide now"
      },
      {
        "start": 2585.119,
        "duration": 2.24,
        "text": "so"
      },
      {
        "start": 2588.88,
        "duration": 6.56,
        "text": "yes so at the core yes you see"
      },
      {
        "start": 2592.4,
        "duration": 5.36,
        "text": "um cassandra running multi-cloud"
      },
      {
        "start": 2595.44,
        "duration": 3.2,
        "text": "okay when you will start your instance"
      },
      {
        "start": 2597.76,
        "duration": 3.12,
        "text": "later"
      },
      {
        "start": 2598.64,
        "duration": 4.64,
        "text": "uh on the free tier i think you are"
      },
      {
        "start": 2600.88,
        "duration": 2.719,
        "text": "limited to google cloud but astra can"
      },
      {
        "start": 2603.28,
        "duration": 3.36,
        "text": "run"
      },
      {
        "start": 2603.599,
        "duration": 5.681,
        "text": "on any cloud okay and you can"
      },
      {
        "start": 2606.64,
        "duration": 3.36,
        "text": "spawn some instance on the region you"
      },
      {
        "start": 2609.28,
        "duration": 2.559,
        "text": "like"
      },
      {
        "start": 2610.0,
        "duration": 3.2,
        "text": "and it's you know high availability of"
      },
      {
        "start": 2611.839,
        "duration": 4.561,
        "text": "course that's the natures of"
      },
      {
        "start": 2613.2,
        "duration": 5.2,
        "text": "cassandra and on top of the database"
      },
      {
        "start": 2616.4,
        "duration": 3.679,
        "text": "there are some tools so astra is not"
      },
      {
        "start": 2618.4,
        "duration": 4.48,
        "text": "only a database as a service"
      },
      {
        "start": 2620.079,
        "duration": 3.601,
        "text": "it's really your platform so providing"
      },
      {
        "start": 2622.88,
        "duration": 4.8,
        "text": "api"
      },
      {
        "start": 2623.68,
        "duration": 7.439,
        "text": "rest graphql a console the studio"
      },
      {
        "start": 2627.68,
        "duration": 6.8,
        "text": "data loader you know ds bulk and maybe"
      },
      {
        "start": 2631.119,
        "duration": 5.681,
        "text": "and soon another tools coming"
      },
      {
        "start": 2634.48,
        "duration": 4.24,
        "text": "and if you want to automate the you know"
      },
      {
        "start": 2636.8,
        "duration": 3.68,
        "text": "provisioning of the database now you do"
      },
      {
        "start": 2638.72,
        "duration": 5.2,
        "text": "have the devops api"
      },
      {
        "start": 2640.48,
        "duration": 6.0,
        "text": "uh the database export the matrix and"
      },
      {
        "start": 2643.92,
        "duration": 3.439,
        "text": "if you're really into kubernetes you may"
      },
      {
        "start": 2646.48,
        "duration": 2.879,
        "text": "have heard that we"
      },
      {
        "start": 2647.359,
        "duration": 3.361,
        "text": "push pretty hard the kate sandra"
      },
      {
        "start": 2649.359,
        "duration": 3.76,
        "text": "initiative with"
      },
      {
        "start": 2650.72,
        "duration": 4.8,
        "text": "cassandra running in kubernetes with the"
      },
      {
        "start": 2653.119,
        "duration": 4.641,
        "text": "operator and all the tools i introduced"
      },
      {
        "start": 2655.52,
        "duration": 3.52,
        "text": "in the beginning well now with the"
      },
      {
        "start": 2657.76,
        "duration": 4.24,
        "text": "service broker"
      },
      {
        "start": 2659.04,
        "duration": 4.88,
        "text": "you can tell kubernetes to spawn your"
      },
      {
        "start": 2662.0,
        "duration": 6.48,
        "text": "cassandra instance directly"
      },
      {
        "start": 2663.92,
        "duration": 7.439,
        "text": "into astra now that mean that was uh"
      },
      {
        "start": 2668.48,
        "duration": 3.599,
        "text": "a service broker i mean exposing the"
      },
      {
        "start": 2671.359,
        "duration": 4.0,
        "text": "resource"
      },
      {
        "start": 2672.079,
        "duration": 6.161,
        "text": "needed for an external cube cluster"
      },
      {
        "start": 2675.359,
        "duration": 7.041,
        "text": "to you know run the pod spawn the"
      },
      {
        "start": 2678.24,
        "duration": 4.16,
        "text": "resource directly into astra"
      },
      {
        "start": 2682.56,
        "duration": 5.12,
        "text": "that's amazing uh"
      },
      {
        "start": 2685.599,
        "duration": 4.24,
        "text": "the whole service broker idea is cool"
      },
      {
        "start": 2687.68,
        "duration": 3.6,
        "text": "yes having astra available in the in the"
      },
      {
        "start": 2689.839,
        "duration": 2.0,
        "text": "cluster in the kubernetes cluster is"
      },
      {
        "start": 2691.28,
        "duration": 3.039,
        "text": "really"
      },
      {
        "start": 2691.839,
        "duration": 5.121,
        "text": "and you can create an instance for free"
      },
      {
        "start": 2694.319,
        "duration": 4.721,
        "text": "five gigabyte free forever not limited"
      },
      {
        "start": 2696.96,
        "duration": 3.2,
        "text": "in time and we will never ask you the"
      },
      {
        "start": 2699.04,
        "duration": 4.4,
        "text": "credit card it's"
      },
      {
        "start": 2700.16,
        "duration": 7.04,
        "text": "really free definitely"
      },
      {
        "start": 2703.44,
        "duration": 3.76,
        "text": "definitely very cool stuff"
      },
      {
        "start": 2707.44,
        "duration": 4.0,
        "text": "i think you went over this but um yeah"
      },
      {
        "start": 2710.079,
        "duration": 3.121,
        "text": "very very quickly so"
      },
      {
        "start": 2711.44,
        "duration": 3.52,
        "text": "you can yeah you can interact with with"
      },
      {
        "start": 2713.2,
        "duration": 2.399,
        "text": "cassandra using the cassandra query"
      },
      {
        "start": 2714.96,
        "duration": 4.48,
        "text": "language"
      },
      {
        "start": 2715.599,
        "duration": 6.881,
        "text": "and this is what we did in the first"
      },
      {
        "start": 2719.44,
        "duration": 4.08,
        "text": "session or using the api uh you do have"
      },
      {
        "start": 2722.48,
        "duration": 3.119,
        "text": "the tools and"
      },
      {
        "start": 2723.52,
        "duration": 3.28,
        "text": "look at all the drivers available so"
      },
      {
        "start": 2725.599,
        "duration": 4.72,
        "text": "that's to communicate to"
      },
      {
        "start": 2726.8,
        "duration": 6.48,
        "text": "you know native cql with cassandra"
      },
      {
        "start": 2730.319,
        "duration": 4.401,
        "text": "in astra you now also have the api"
      },
      {
        "start": 2733.28,
        "duration": 4.0,
        "text": "raised in graphql"
      },
      {
        "start": 2734.72,
        "duration": 4.879,
        "text": "but hey drivers are still uh pretty"
      },
      {
        "start": 2737.28,
        "duration": 4.559,
        "text": "efficient and you know"
      },
      {
        "start": 2739.599,
        "duration": 5.24,
        "text": "most people still use the driver"
      },
      {
        "start": 2741.839,
        "duration": 5.361,
        "text": "especially the java one"
      },
      {
        "start": 2744.839,
        "duration": 3.881,
        "text": "definitely the the java one i think is"
      },
      {
        "start": 2747.2,
        "duration": 5.28,
        "text": "probably the most widely used"
      },
      {
        "start": 2748.72,
        "duration": 6.56,
        "text": "i mean cassandra spark connector uses"
      },
      {
        "start": 2752.48,
        "duration": 4.32,
        "text": "you know it inside so definitely exactly"
      },
      {
        "start": 2755.28,
        "duration": 4.0,
        "text": "it does also mean that you know"
      },
      {
        "start": 2756.8,
        "duration": 3.44,
        "text": "the spark drivers works on astra you"
      },
      {
        "start": 2759.28,
        "duration": 2.88,
        "text": "know"
      },
      {
        "start": 2760.24,
        "duration": 3.68,
        "text": "everything's related because the spark"
      },
      {
        "start": 2762.16,
        "duration": 4.32,
        "text": "drivers wrap the"
      },
      {
        "start": 2763.92,
        "duration": 4.64,
        "text": "java drivers at this core and you know"
      },
      {
        "start": 2766.48,
        "duration": 5.119,
        "text": "that explain what it works"
      },
      {
        "start": 2768.56,
        "duration": 3.039,
        "text": "yep absolutely"
      },
      {
        "start": 2771.839,
        "duration": 7.361,
        "text": "so let's go ahead and uh launch astra"
      },
      {
        "start": 2775.359,
        "duration": 4.72,
        "text": "um so astra i have my own instance ready"
      },
      {
        "start": 2779.2,
        "duration": 4.8,
        "text": "to go"
      },
      {
        "start": 2780.079,
        "duration": 4.321,
        "text": "um and you know i'm just gonna bring up"
      },
      {
        "start": 2784.0,
        "duration": 4.48,
        "text": "my"
      },
      {
        "start": 2784.4,
        "duration": 7.56,
        "text": "my database manager um i can actually"
      },
      {
        "start": 2788.48,
        "duration": 6.48,
        "text": "just log into a good way"
      },
      {
        "start": 2791.96,
        "duration": 3.0,
        "text": "astro.dsx.com"
      },
      {
        "start": 2800.839,
        "duration": 3.0,
        "text": "and"
      },
      {
        "start": 2806.079,
        "duration": 2.24,
        "text": "yep"
      },
      {
        "start": 2811.04,
        "duration": 5.279,
        "text": "yeah i wish you guys had that when i was"
      },
      {
        "start": 2812.72,
        "duration": 8.08,
        "text": "testing it so i"
      },
      {
        "start": 2816.319,
        "duration": 6.081,
        "text": "i i have a really old account"
      },
      {
        "start": 2820.8,
        "duration": 3.039,
        "text": "i should probably connect my i like i"
      },
      {
        "start": 2822.4,
        "duration": 3.199,
        "text": "like signing you with github"
      },
      {
        "start": 2823.839,
        "duration": 3.361,
        "text": "i love science single sign-on you know i"
      },
      {
        "start": 2825.599,
        "duration": 2.561,
        "text": "don't really want to remember another"
      },
      {
        "start": 2827.2,
        "duration": 4.639,
        "text": "database"
      },
      {
        "start": 2828.16,
        "duration": 7.12,
        "text": "um so when we bring when we bring up um"
      },
      {
        "start": 2831.839,
        "duration": 5.841,
        "text": "the uh you know astra"
      },
      {
        "start": 2835.28,
        "duration": 4.72,
        "text": "dashboard uh you'll notice you have the"
      },
      {
        "start": 2837.68,
        "duration": 4.639,
        "text": "ability to have different databases"
      },
      {
        "start": 2840.0,
        "duration": 4.72,
        "text": "you can have different organizations um"
      },
      {
        "start": 2842.319,
        "duration": 4.321,
        "text": "i have a free tier um"
      },
      {
        "start": 2844.72,
        "duration": 4.399,
        "text": "just remember that if you don't use it"
      },
      {
        "start": 2846.64,
        "duration": 3.84,
        "text": "uh data stacks will automatically park"
      },
      {
        "start": 2849.119,
        "duration": 2.72,
        "text": "the database parking means that it's"
      },
      {
        "start": 2850.48,
        "duration": 4.879,
        "text": "just turned off"
      },
      {
        "start": 2851.839,
        "duration": 4.881,
        "text": "um so you know whenever you come on if"
      },
      {
        "start": 2855.359,
        "duration": 2.96,
        "text": "you haven't used the database you gotta"
      },
      {
        "start": 2856.72,
        "duration": 4.16,
        "text": "unpark it so"
      },
      {
        "start": 2858.319,
        "duration": 4.161,
        "text": "right now this the server is running um"
      },
      {
        "start": 2860.88,
        "duration": 4.4,
        "text": "and once it's running"
      },
      {
        "start": 2862.48,
        "duration": 3.359,
        "text": "um i can you know learn how to connect"
      },
      {
        "start": 2865.28,
        "duration": 2.16,
        "text": "to it"
      },
      {
        "start": 2865.839,
        "duration": 3.601,
        "text": "by clicking here it's gonna give me the"
      },
      {
        "start": 2867.44,
        "duration": 3.2,
        "text": "endpoints"
      },
      {
        "start": 2869.44,
        "duration": 3.04,
        "text": "it's gonna give me the environment"
      },
      {
        "start": 2870.64,
        "duration": 4.88,
        "text": "variables i need to connect to it"
      },
      {
        "start": 2872.48,
        "duration": 5.599,
        "text": "um the way we're connecting to"
      },
      {
        "start": 2875.52,
        "duration": 4.0,
        "text": "uh astra for the work that we've been"
      },
      {
        "start": 2878.079,
        "duration": 4.721,
        "text": "doing is via"
      },
      {
        "start": 2879.52,
        "duration": 5.52,
        "text": "the drivers yep yep um"
      },
      {
        "start": 2882.8,
        "duration": 3.36,
        "text": "and uh you know we have to download this"
      },
      {
        "start": 2885.04,
        "duration": 4.079,
        "text": "secure certificate"
      },
      {
        "start": 2886.16,
        "duration": 4.399,
        "text": "bundle yes and when we download it it's"
      },
      {
        "start": 2889.119,
        "duration": 5.041,
        "text": "just a zip file"
      },
      {
        "start": 2890.559,
        "duration": 4.321,
        "text": "um and um what we do is we upload that"
      },
      {
        "start": 2894.16,
        "duration": 2.56,
        "text": "zip file"
      },
      {
        "start": 2894.88,
        "duration": 3.6,
        "text": "into our git pod and it's really easy"
      },
      {
        "start": 2896.72,
        "duration": 3.2,
        "text": "you just kind of drag it and drag and"
      },
      {
        "start": 2898.48,
        "duration": 3.68,
        "text": "drop it in there and i've already done"
      },
      {
        "start": 2899.92,
        "duration": 5.199,
        "text": "that i'll show it to you um"
      },
      {
        "start": 2902.16,
        "duration": 3.36,
        "text": "but yeah that's a common yeah no no so"
      },
      {
        "start": 2905.119,
        "duration": 2.48,
        "text": "so"
      },
      {
        "start": 2905.52,
        "duration": 4.48,
        "text": "one might ask why do you need to"
      },
      {
        "start": 2907.599,
        "duration": 5.041,
        "text": "download a zip file whereas when i log"
      },
      {
        "start": 2910.0,
        "duration": 5.839,
        "text": "into cassandra i'm only providing"
      },
      {
        "start": 2912.64,
        "duration": 4.719,
        "text": "ipport and user password well now you"
      },
      {
        "start": 2915.839,
        "duration": 4.641,
        "text": "are using the cloud so"
      },
      {
        "start": 2917.359,
        "duration": 5.361,
        "text": "we want to create a secure"
      },
      {
        "start": 2920.48,
        "duration": 3.68,
        "text": "connection between you and i two were"
      },
      {
        "start": 2922.72,
        "duration": 2.32,
        "text": "authenticated using strong"
      },
      {
        "start": 2924.16,
        "duration": 4.159,
        "text": "authentication"
      },
      {
        "start": 2925.04,
        "duration": 5.279,
        "text": "and certificates in the zip file you do"
      },
      {
        "start": 2928.319,
        "duration": 5.681,
        "text": "have the certificate needed to open"
      },
      {
        "start": 2930.319,
        "duration": 6.641,
        "text": "that two-way communication with astra"
      },
      {
        "start": 2934.0,
        "duration": 3.599,
        "text": "and then we use some technical tips and"
      },
      {
        "start": 2936.96,
        "duration": 3.44,
        "text": "tricks"
      },
      {
        "start": 2937.599,
        "duration": 4.72,
        "text": "to do the same load balancing and"
      },
      {
        "start": 2940.4,
        "duration": 4.56,
        "text": "distribution of the load"
      },
      {
        "start": 2942.319,
        "duration": 5.601,
        "text": "you use with the java driver but in the"
      },
      {
        "start": 2944.96,
        "duration": 6.879,
        "text": "cloud environment"
      },
      {
        "start": 2947.92,
        "duration": 6.639,
        "text": "yeah and um you know there are"
      },
      {
        "start": 2951.839,
        "duration": 5.041,
        "text": "probably every i mean any cassandra"
      },
      {
        "start": 2954.559,
        "duration": 5.441,
        "text": "application that you use today"
      },
      {
        "start": 2956.88,
        "duration": 4.719,
        "text": "uh you can port it to use astra as long"
      },
      {
        "start": 2960.0,
        "duration": 2.64,
        "text": "as you make sure your connection is"
      },
      {
        "start": 2961.599,
        "duration": 3.361,
        "text": "using this"
      },
      {
        "start": 2962.64,
        "duration": 3.52,
        "text": "um you know zip file that's really what"
      },
      {
        "start": 2964.96,
        "duration": 4.72,
        "text": "it comes down to"
      },
      {
        "start": 2966.16,
        "duration": 5.36,
        "text": "um and you know we have code"
      },
      {
        "start": 2969.68,
        "duration": 3.6,
        "text": "in node python and java in the in the"
      },
      {
        "start": 2971.52,
        "duration": 4.96,
        "text": "code that i'm about to show you"
      },
      {
        "start": 2973.28,
        "duration": 4.64,
        "text": "um and spark as well and the spark"
      },
      {
        "start": 2976.48,
        "duration": 2.56,
        "text": "connectivity is basically the same way"
      },
      {
        "start": 2977.92,
        "duration": 2.8,
        "text": "we connect to java"
      },
      {
        "start": 2979.04,
        "duration": 3.519,
        "text": "right we have to give the same"
      },
      {
        "start": 2980.72,
        "duration": 4.879,
        "text": "information um and"
      },
      {
        "start": 2982.559,
        "duration": 4.961,
        "text": "um it actually is really easy um"
      },
      {
        "start": 2985.599,
        "duration": 3.281,
        "text": "i initially it was like oh i thought the"
      },
      {
        "start": 2987.52,
        "duration": 2.48,
        "text": "same thing said it goes like i have to"
      },
      {
        "start": 2988.88,
        "duration": 3.12,
        "text": "download a zip file but it's really not"
      },
      {
        "start": 2990.0,
        "duration": 3.44,
        "text": "that hard"
      },
      {
        "start": 2992.0,
        "duration": 3.2,
        "text": "if you're doing any secure connectivity"
      },
      {
        "start": 2993.44,
        "duration": 2.879,
        "text": "with cassandra you would need to have a"
      },
      {
        "start": 2995.2,
        "duration": 4.0,
        "text": "search file anyways"
      },
      {
        "start": 2996.319,
        "duration": 4.481,
        "text": "yes so this isn't really that different"
      },
      {
        "start": 2999.2,
        "duration": 4.56,
        "text": "um"
      },
      {
        "start": 3000.8,
        "duration": 4.319,
        "text": "so we have the astra up and running just"
      },
      {
        "start": 3003.76,
        "duration": 3.04,
        "text": "to kind of revisit"
      },
      {
        "start": 3005.119,
        "duration": 3.521,
        "text": "what we're trying to do before we go"
      },
      {
        "start": 3006.8,
        "duration": 4.88,
        "text": "hands-on um"
      },
      {
        "start": 3008.64,
        "duration": 4.24,
        "text": "so remember we're trying to take these"
      },
      {
        "start": 3011.68,
        "duration": 3.76,
        "text": "apis"
      },
      {
        "start": 3012.88,
        "duration": 3.199,
        "text": "and make them event driven we did it"
      },
      {
        "start": 3015.44,
        "duration": 2.48,
        "text": "back"
      },
      {
        "start": 3016.079,
        "duration": 4.0,
        "text": "in the last session what we're doing"
      },
      {
        "start": 3017.92,
        "duration": 4.32,
        "text": "today is we're going to focus on"
      },
      {
        "start": 3020.079,
        "duration": 4.24,
        "text": "uh this engine right here and we're"
      },
      {
        "start": 3022.24,
        "duration": 4.0,
        "text": "going to do two things with this engine"
      },
      {
        "start": 3024.319,
        "duration": 3.601,
        "text": "which is we're going to take a stream of"
      },
      {
        "start": 3026.24,
        "duration": 3.599,
        "text": "um"
      },
      {
        "start": 3027.92,
        "duration": 3.04,
        "text": "basically events meaning new uh"
      },
      {
        "start": 3029.839,
        "duration": 3.76,
        "text": "resources coming in"
      },
      {
        "start": 3030.96,
        "duration": 3.04,
        "text": "new url's being curated and we're going"
      },
      {
        "start": 3033.599,
        "duration": 3.841,
        "text": "to"
      },
      {
        "start": 3034.0,
        "duration": 5.28,
        "text": "save it to astra um well"
      },
      {
        "start": 3037.44,
        "duration": 3.6,
        "text": "kafka connect and these other tools"
      },
      {
        "start": 3039.28,
        "duration": 4.0,
        "text": "we've built before already save it to"
      },
      {
        "start": 3041.04,
        "duration": 4.559,
        "text": "to astra what we're going to do is we're"
      },
      {
        "start": 3043.28,
        "duration": 5.6,
        "text": "going to parse the same event"
      },
      {
        "start": 3045.599,
        "duration": 5.841,
        "text": "and materialize a table called"
      },
      {
        "start": 3048.88,
        "duration": 4.08,
        "text": "leaves by tag right so in cassandra if"
      },
      {
        "start": 3051.44,
        "duration": 2.08,
        "text": "you do the data modeling course you'll"
      },
      {
        "start": 3052.96,
        "duration": 2.24,
        "text": "note that"
      },
      {
        "start": 3053.52,
        "duration": 3.599,
        "text": "depending on how you access data you can"
      },
      {
        "start": 3055.2,
        "duration": 3.6,
        "text": "create a table so we have a query table"
      },
      {
        "start": 3057.119,
        "duration": 2.48,
        "text": "called leaves by tag meaning give me all"
      },
      {
        "start": 3058.8,
        "duration": 5.039,
        "text": "the urls"
      },
      {
        "start": 3059.599,
        "duration": 7.921,
        "text": "buy a particular tag in"
      },
      {
        "start": 3063.839,
        "duration": 5.28,
        "text": "native cassandra you know"
      },
      {
        "start": 3067.52,
        "duration": 3.28,
        "text": "technically this particular type of"
      },
      {
        "start": 3069.119,
        "duration": 3.761,
        "text": "query we could put a uh"
      },
      {
        "start": 3070.8,
        "duration": 3.519,
        "text": "you know a secondary index or we could"
      },
      {
        "start": 3072.88,
        "duration": 4.4,
        "text": "put an sai on it"
      },
      {
        "start": 3074.319,
        "duration": 3.841,
        "text": "but normally um these things have their"
      },
      {
        "start": 3077.28,
        "duration": 2.24,
        "text": "limits"
      },
      {
        "start": 3078.16,
        "duration": 4.64,
        "text": "and i think the sai is much more"
      },
      {
        "start": 3079.52,
        "duration": 6.16,
        "text": "performant but currently"
      },
      {
        "start": 3082.8,
        "duration": 4.16,
        "text": "cassandra 3 cassandra 4 like you know"
      },
      {
        "start": 3085.68,
        "duration": 3.2,
        "text": "they don't have the sai"
      },
      {
        "start": 3086.96,
        "duration": 3.04,
        "text": "so assuming that we're going to be you"
      },
      {
        "start": 3088.88,
        "duration": 4.32,
        "text": "know using"
      },
      {
        "start": 3090.0,
        "duration": 4.8,
        "text": "the core cassandra technology here um"
      },
      {
        "start": 3093.2,
        "duration": 3.52,
        "text": "more than likely we're going to go to"
      },
      {
        "start": 3094.8,
        "duration": 3.12,
        "text": "production we would end up using this"
      },
      {
        "start": 3096.72,
        "duration": 3.76,
        "text": "and"
      },
      {
        "start": 3097.92,
        "duration": 4.159,
        "text": "we test the sai or we would materialize"
      },
      {
        "start": 3100.48,
        "duration": 2.32,
        "text": "the information in solar to get these"
      },
      {
        "start": 3102.079,
        "duration": 2.401,
        "text": "tag counts"
      },
      {
        "start": 3102.8,
        "duration": 4.48,
        "text": "but we we have a table called leaves by"
      },
      {
        "start": 3104.48,
        "duration": 6.079,
        "text": "tag that gets materialized"
      },
      {
        "start": 3107.28,
        "duration": 4.72,
        "text": "in sync in real time and there's another"
      },
      {
        "start": 3110.559,
        "duration": 4.321,
        "text": "table that we're going to create"
      },
      {
        "start": 3112.0,
        "duration": 4.88,
        "text": "um which is called tags which is given"
      },
      {
        "start": 3114.88,
        "duration": 4.959,
        "text": "the tag give me the tag count"
      },
      {
        "start": 3116.88,
        "duration": 4.16,
        "text": "right so you can imagine one of those"
      },
      {
        "start": 3119.839,
        "duration": 3.28,
        "text": "it's easy to say"
      },
      {
        "start": 3121.04,
        "duration": 3.36,
        "text": "here's a new url it has tags already in"
      },
      {
        "start": 3123.119,
        "duration": 3.281,
        "text": "there i need to"
      },
      {
        "start": 3124.4,
        "duration": 3.04,
        "text": "just save and update this information in"
      },
      {
        "start": 3126.4,
        "duration": 2.8,
        "text": "my leaves by tag"
      },
      {
        "start": 3127.44,
        "duration": 3.36,
        "text": "that's one use case and that can happen"
      },
      {
        "start": 3129.2,
        "duration": 4.48,
        "text": "on a real-time basis"
      },
      {
        "start": 3130.8,
        "duration": 4.24,
        "text": "but if i need to update my tag count"
      },
      {
        "start": 3133.68,
        "duration": 2.96,
        "text": "right and we have a bunch of different"
      },
      {
        "start": 3135.04,
        "duration": 2.48,
        "text": "sources and a bunch of different streams"
      },
      {
        "start": 3136.64,
        "duration": 2.64,
        "text": "coming in"
      },
      {
        "start": 3137.52,
        "duration": 3.44,
        "text": "it probably makes sense to read all the"
      },
      {
        "start": 3139.28,
        "duration": 3.2,
        "text": "data and"
      },
      {
        "start": 3140.96,
        "duration": 3.359,
        "text": "understand what my true count is and"
      },
      {
        "start": 3142.48,
        "duration": 3.359,
        "text": "then update my tags right and that's"
      },
      {
        "start": 3144.319,
        "duration": 5.76,
        "text": "what we're going to do with the spark"
      },
      {
        "start": 3145.839,
        "duration": 5.921,
        "text": "that job you saw this before"
      },
      {
        "start": 3150.079,
        "duration": 3.121,
        "text": "this is the streaming process that's"
      },
      {
        "start": 3151.76,
        "duration": 3.52,
        "text": "going to pick from the broker"
      },
      {
        "start": 3153.2,
        "duration": 3.2,
        "text": "save to leafs by tag and then this is"
      },
      {
        "start": 3155.28,
        "duration": 2.799,
        "text": "the process that's going to read from"
      },
      {
        "start": 3156.4,
        "duration": 3.6,
        "text": "cassandra"
      },
      {
        "start": 3158.079,
        "duration": 3.841,
        "text": "do some crunching and then save it back"
      },
      {
        "start": 3160.0,
        "duration": 3.839,
        "text": "to cassandra"
      },
      {
        "start": 3161.92,
        "duration": 3.12,
        "text": "uh i think we do have a question on the"
      },
      {
        "start": 3163.839,
        "duration": 3.441,
        "text": "previous schema what"
      },
      {
        "start": 3165.04,
        "duration": 4.88,
        "text": "what is the tag tail maybe that's the"
      },
      {
        "start": 3167.28,
        "duration": 4.96,
        "text": "features on your schema right"
      },
      {
        "start": 3169.92,
        "duration": 3.919,
        "text": "it is it is it's um you'll see it i'll"
      },
      {
        "start": 3172.24,
        "duration": 4.96,
        "text": "show you the schema when we bring up"
      },
      {
        "start": 3173.839,
        "duration": 4.561,
        "text": "um the data stack studio um yeah so"
      },
      {
        "start": 3177.2,
        "duration": 2.56,
        "text": "there's basically only three tables"
      },
      {
        "start": 3178.4,
        "duration": 1.919,
        "text": "we're dealing with three tables in this"
      },
      {
        "start": 3179.76,
        "duration": 3.2,
        "text": "example"
      },
      {
        "start": 3180.319,
        "duration": 3.681,
        "text": "one is called urls another one is called"
      },
      {
        "start": 3182.96,
        "duration": 3.2,
        "text": "uh tags"
      },
      {
        "start": 3184.0,
        "duration": 3.839,
        "text": "and uh one is called leaves by tag"
      },
      {
        "start": 3186.16,
        "duration": 3.12,
        "text": "because internally we call all of the"
      },
      {
        "start": 3187.839,
        "duration": 5.201,
        "text": "urls leaves"
      },
      {
        "start": 3189.28,
        "duration": 4.799,
        "text": "um so you'll see it and i think you'll"
      },
      {
        "start": 3193.04,
        "duration": 3.6,
        "text": "understand it's just like"
      },
      {
        "start": 3194.079,
        "duration": 4.881,
        "text": "you know if you had a like a wordpress"
      },
      {
        "start": 3196.64,
        "duration": 5.199,
        "text": "blog right you have tags and categories"
      },
      {
        "start": 3198.96,
        "duration": 3.52,
        "text": "that's what it is it's just a tag to um"
      },
      {
        "start": 3201.839,
        "duration": 4.161,
        "text": "organize"
      },
      {
        "start": 3202.48,
        "duration": 6.72,
        "text": "the urls okay a business concept"
      },
      {
        "start": 3206.0,
        "duration": 5.52,
        "text": "in your use case then yeah exactly"
      },
      {
        "start": 3209.2,
        "duration": 3.919,
        "text": "um so anyways if you haven't signed up"
      },
      {
        "start": 3211.52,
        "duration": 3.2,
        "text": "for astra"
      },
      {
        "start": 3213.119,
        "duration": 3.601,
        "text": "you know the only things that you need"
      },
      {
        "start": 3214.72,
        "duration": 5.28,
        "text": "after you create the astro database"
      },
      {
        "start": 3216.72,
        "duration": 4.639,
        "text": "is really you know um your"
      },
      {
        "start": 3220.0,
        "duration": 3.359,
        "text": "your database name your key space name"
      },
      {
        "start": 3221.359,
        "duration": 3.601,
        "text": "your username and password remember"
      },
      {
        "start": 3223.359,
        "duration": 4.72,
        "text": "because you have that certificate"
      },
      {
        "start": 3224.96,
        "duration": 4.24,
        "text": "um even if i show you my password here"
      },
      {
        "start": 3228.079,
        "duration": 3.52,
        "text": "you won't be able to"
      },
      {
        "start": 3229.2,
        "duration": 4.72,
        "text": "get access to that database without my"
      },
      {
        "start": 3231.599,
        "duration": 4.081,
        "text": "secure certificate bundle"
      },
      {
        "start": 3233.92,
        "duration": 3.919,
        "text": "since i've already made the database in"
      },
      {
        "start": 3235.68,
        "duration": 4.639,
        "text": "the previous workshop i'm not going to"
      },
      {
        "start": 3237.839,
        "duration": 6.881,
        "text": "go through this exercise again"
      },
      {
        "start": 3240.319,
        "duration": 7.361,
        "text": "but if you look at the nice work that"
      },
      {
        "start": 3244.72,
        "duration": 4.56,
        "text": "my colleagues and cedric have done there"
      },
      {
        "start": 3247.68,
        "duration": 3.919,
        "text": "is a really really"
      },
      {
        "start": 3249.28,
        "duration": 4.16,
        "text": "amazing step-by-step uh you know"
      },
      {
        "start": 3251.599,
        "duration": 5.281,
        "text": "screenshot by screenshot process"
      },
      {
        "start": 3253.44,
        "duration": 5.919,
        "text": "on github on the center.api"
      },
      {
        "start": 3256.88,
        "duration": 3.679,
        "text": "uh repo which shows you how to get"
      },
      {
        "start": 3259.359,
        "duration": 2.48,
        "text": "started"
      },
      {
        "start": 3260.559,
        "duration": 4.081,
        "text": "and actually i don't even think you need"
      },
      {
        "start": 3261.839,
        "duration": 5.121,
        "text": "it like if you've used any cloud service"
      },
      {
        "start": 3264.64,
        "duration": 3.28,
        "text": "uh it's pretty self-explanatory right"
      },
      {
        "start": 3266.96,
        "duration": 3.359,
        "text": "create an account"
      },
      {
        "start": 3267.92,
        "duration": 4.399,
        "text": "make a new database fill out some forms"
      },
      {
        "start": 3270.319,
        "duration": 3.361,
        "text": "uh if you if you're starting off you're"
      },
      {
        "start": 3272.319,
        "duration": 2.24,
        "text": "gonna get google cloud as cedric"
      },
      {
        "start": 3273.68,
        "duration": 3.28,
        "text": "mentioned"
      },
      {
        "start": 3274.559,
        "duration": 3.76,
        "text": "you know you make your database you give"
      },
      {
        "start": 3276.96,
        "duration": 3.04,
        "text": "it some things um"
      },
      {
        "start": 3278.319,
        "duration": 3.52,
        "text": "it's standard i don't think it's that"
      },
      {
        "start": 3280.0,
        "duration": 3.2,
        "text": "complicated in fact the newer interface"
      },
      {
        "start": 3281.839,
        "duration": 3.681,
        "text": "gets better and better and better every"
      },
      {
        "start": 3283.2,
        "duration": 4.24,
        "text": "time i log into it yeah so"
      },
      {
        "start": 3285.52,
        "duration": 4.24,
        "text": "we change the ui a little bit you should"
      },
      {
        "start": 3287.44,
        "duration": 3.919,
        "text": "then be lost you know you should have to"
      },
      {
        "start": 3289.76,
        "duration": 3.44,
        "text": "you should provide the database name the"
      },
      {
        "start": 3291.359,
        "duration": 2.321,
        "text": "key space name user and password pretty"
      },
      {
        "start": 3293.2,
        "duration": 4.08,
        "text": "easy"
      },
      {
        "start": 3293.68,
        "duration": 5.679,
        "text": "and then you need to pick uh one tier"
      },
      {
        "start": 3297.28,
        "duration": 3.519,
        "text": "pick the free tier and then pick a"
      },
      {
        "start": 3299.359,
        "duration": 3.921,
        "text": "region and if you"
      },
      {
        "start": 3300.799,
        "duration": 3.121,
        "text": "select the free tier you are limited to"
      },
      {
        "start": 3303.28,
        "duration": 2.64,
        "text": "google i"
      },
      {
        "start": 3303.92,
        "duration": 4.08,
        "text": "think google cloud so now you do have"
      },
      {
        "start": 3305.92,
        "duration": 5.36,
        "text": "two region u.s wastes"
      },
      {
        "start": 3308.0,
        "duration": 5.68,
        "text": "europe west or us east"
      },
      {
        "start": 3311.28,
        "duration": 4.48,
        "text": "and you you can pick the one you like to"
      },
      {
        "start": 3313.68,
        "duration": 5.439,
        "text": "reduce latency"
      },
      {
        "start": 3315.76,
        "duration": 5.28,
        "text": "yep um and you know what uh"
      },
      {
        "start": 3319.119,
        "duration": 3.921,
        "text": "other stuff do you get on astra it's not"
      },
      {
        "start": 3321.04,
        "duration": 4.559,
        "text": "just the cassandra database"
      },
      {
        "start": 3323.04,
        "duration": 3.44,
        "text": "we're going to be using datastack studio"
      },
      {
        "start": 3325.599,
        "duration": 4.48,
        "text": "there's also"
      },
      {
        "start": 3326.48,
        "duration": 6.079,
        "text": "a way to get access to cqlsh"
      },
      {
        "start": 3330.079,
        "duration": 5.04,
        "text": "via the browser there's a grafana"
      },
      {
        "start": 3332.559,
        "duration": 5.921,
        "text": "dashboard to see some basic metrics"
      },
      {
        "start": 3335.119,
        "duration": 6.401,
        "text": "um so that's all built into the"
      },
      {
        "start": 3338.48,
        "duration": 3.359,
        "text": "uh the astra interface so just like a"
      },
      {
        "start": 3341.52,
        "duration": 5.279,
        "text": "quick"
      },
      {
        "start": 3341.839,
        "duration": 8.0,
        "text": "view here right"
      },
      {
        "start": 3346.799,
        "duration": 3.04,
        "text": "i can say launch studio"
      },
      {
        "start": 3354.4,
        "duration": 4.56,
        "text": "and this is a kind of a um"
      },
      {
        "start": 3360.079,
        "duration": 3.04,
        "text": "like a tightened version of dataset"
      },
      {
        "start": 3362.319,
        "duration": 3.28,
        "text": "studio"
      },
      {
        "start": 3363.119,
        "duration": 3.921,
        "text": "it just has you know marked down in cql"
      },
      {
        "start": 3365.599,
        "duration": 3.681,
        "text": "um"
      },
      {
        "start": 3367.04,
        "duration": 3.36,
        "text": "aspects that if you have datastax"
      },
      {
        "start": 3369.28,
        "duration": 2.079,
        "text": "enterprise there are some other things"
      },
      {
        "start": 3370.4,
        "duration": 4.0,
        "text": "you can do"
      },
      {
        "start": 3371.359,
        "duration": 4.881,
        "text": "uh like gremlin and and spark sql"
      },
      {
        "start": 3374.4,
        "duration": 3.12,
        "text": "uh but basically it's a way it's a"
      },
      {
        "start": 3376.24,
        "duration": 3.44,
        "text": "notebook interface"
      },
      {
        "start": 3377.52,
        "duration": 3.12,
        "text": "to set up tables like if you wanted to"
      },
      {
        "start": 3379.68,
        "duration": 2.24,
        "text": "create a schema"
      },
      {
        "start": 3380.64,
        "duration": 4.32,
        "text": "or to do queries and we're going to come"
      },
      {
        "start": 3381.92,
        "duration": 6.32,
        "text": "back to this um the other"
      },
      {
        "start": 3384.96,
        "duration": 6.879,
        "text": "really cool um interface here"
      },
      {
        "start": 3388.24,
        "duration": 3.599,
        "text": "is your console"
      },
      {
        "start": 3393.44,
        "duration": 4.399,
        "text": "which you can also connect"
      },
      {
        "start": 3396.48,
        "duration": 7.92,
        "text": "you know if you wanted to from your own"
      },
      {
        "start": 3397.839,
        "duration": 11.52,
        "text": "machine but"
      },
      {
        "start": 3404.4,
        "duration": 4.959,
        "text": "if you're learning cassandra um"
      },
      {
        "start": 3414.96,
        "duration": 4.72,
        "text": "and so at the same time we had a"
      },
      {
        "start": 3417.04,
        "duration": 4.72,
        "text": "question from arjun likes you know"
      },
      {
        "start": 3419.68,
        "duration": 4.24,
        "text": "we we keep saying astra is free and"
      },
      {
        "start": 3421.76,
        "duration": 4.0,
        "text": "everything so you're asking okay about"
      },
      {
        "start": 3423.92,
        "duration": 4.639,
        "text": "anything special about the paid and"
      },
      {
        "start": 3425.76,
        "duration": 6.0,
        "text": "premier tea and then"
      },
      {
        "start": 3428.559,
        "duration": 5.201,
        "text": "i like the question a lot so um with the"
      },
      {
        "start": 3431.76,
        "duration": 4.24,
        "text": "free tier you are limited in capacity"
      },
      {
        "start": 3433.76,
        "duration": 3.92,
        "text": "i mean you do have a couple of nodes and"
      },
      {
        "start": 3436.0,
        "duration": 4.48,
        "text": "so you are limited in space"
      },
      {
        "start": 3437.68,
        "duration": 3.52,
        "text": "and throughput you can achieve whereas"
      },
      {
        "start": 3440.48,
        "duration": 3.44,
        "text": "if you"
      },
      {
        "start": 3441.2,
        "duration": 3.52,
        "text": "jump to the to the premium mob now you"
      },
      {
        "start": 3443.92,
        "duration": 2.96,
        "text": "do have the"
      },
      {
        "start": 3444.72,
        "duration": 3.28,
        "text": "you know the capacity you will pay for"
      },
      {
        "start": 3446.88,
        "duration": 3.36,
        "text": "capacity pay"
      },
      {
        "start": 3448.0,
        "duration": 4.079,
        "text": "pay as you go and you can have you know"
      },
      {
        "start": 3450.24,
        "duration": 5.52,
        "text": "as many node as you need and"
      },
      {
        "start": 3452.079,
        "duration": 5.28,
        "text": "um you know even have advanced features"
      },
      {
        "start": 3455.76,
        "duration": 3.68,
        "text": "like vpc peering"
      },
      {
        "start": 3457.359,
        "duration": 4.081,
        "text": "if you already have nodes running"
      },
      {
        "start": 3459.44,
        "duration": 4.08,
        "text": "somewhere you can"
      },
      {
        "start": 3461.44,
        "duration": 3.119,
        "text": "pair those you know like vpc playing"
      },
      {
        "start": 3463.52,
        "duration": 4.799,
        "text": "with the three"
      },
      {
        "start": 3464.559,
        "duration": 6.721,
        "text": "the three cloud providers and you know"
      },
      {
        "start": 3468.319,
        "duration": 3.52,
        "text": "much much more now free tier is really"
      },
      {
        "start": 3471.28,
        "duration": 4.16,
        "text": "wide"
      },
      {
        "start": 3471.839,
        "duration": 6.96,
        "text": "but not everything is open"
      },
      {
        "start": 3475.44,
        "duration": 6.96,
        "text": "yeah and um you know like i look at"
      },
      {
        "start": 3478.799,
        "duration": 5.921,
        "text": "astra and datastax is doing a"
      },
      {
        "start": 3482.4,
        "duration": 3.919,
        "text": "tremendous job of basically open"
      },
      {
        "start": 3484.72,
        "duration": 3.28,
        "text": "sourcing the different components that"
      },
      {
        "start": 3486.319,
        "duration": 3.441,
        "text": "run astra like stargate"
      },
      {
        "start": 3488.0,
        "duration": 4.4,
        "text": "you can get you can download stargate"
      },
      {
        "start": 3489.76,
        "duration": 4.319,
        "text": "which is the rest in the graphql api"
      },
      {
        "start": 3492.4,
        "duration": 3.12,
        "text": "you can download kate sandra because"
      },
      {
        "start": 3494.079,
        "duration": 3.681,
        "text": "astra is basically cassandra on"
      },
      {
        "start": 3495.52,
        "duration": 5.52,
        "text": "kubernetes being managed by data size"
      },
      {
        "start": 3497.76,
        "duration": 4.799,
        "text": "so you know um you really have to do the"
      },
      {
        "start": 3501.04,
        "duration": 4.079,
        "text": "cost benefit scenario right do i really"
      },
      {
        "start": 3502.559,
        "duration": 5.76,
        "text": "want to set up a kubernetes cluster"
      },
      {
        "start": 3505.119,
        "duration": 4.72,
        "text": "and kate sandra and"
      },
      {
        "start": 3508.319,
        "duration": 3.841,
        "text": "i want to bring up stargate and i want"
      },
      {
        "start": 3509.839,
        "duration": 4.801,
        "text": "to do like do i really want to do that"
      },
      {
        "start": 3512.16,
        "duration": 4.639,
        "text": "i'm a cassandra expert all right i don't"
      },
      {
        "start": 3514.64,
        "duration": 5.76,
        "text": "want to do that"
      },
      {
        "start": 3516.799,
        "duration": 4.32,
        "text": "you know um i because right now for this"
      },
      {
        "start": 3520.4,
        "duration": 2.48,
        "text": "project that"
      },
      {
        "start": 3521.119,
        "duration": 3.44,
        "text": "we're showing it's a real project right"
      },
      {
        "start": 3522.88,
        "duration": 3.28,
        "text": "like if you go to casino.link this is a"
      },
      {
        "start": 3524.559,
        "duration": 4.481,
        "text": "real project"
      },
      {
        "start": 3526.16,
        "duration": 4.8,
        "text": "that uh runs and it's the site is"
      },
      {
        "start": 3529.04,
        "duration": 3.279,
        "text": "generated and it's got it gets a you"
      },
      {
        "start": 3530.96,
        "duration": 4.159,
        "text": "know good amount of traffic"
      },
      {
        "start": 3532.319,
        "duration": 2.8,
        "text": "we don't"
      },
      {
        "start": 3538.64,
        "duration": 3.36,
        "text": "want to make right as experts we're just"
      },
      {
        "start": 3540.4,
        "duration": 3.439,
        "text": "focusing on finding the best content"
      },
      {
        "start": 3542.0,
        "duration": 3.04,
        "text": "so uh do i really want to be managing a"
      },
      {
        "start": 3543.839,
        "duration": 2.48,
        "text": "database no"
      },
      {
        "start": 3545.04,
        "duration": 3.36,
        "text": "does anybody want to be managing a"
      },
      {
        "start": 3546.319,
        "duration": 6.48,
        "text": "database server no"
      },
      {
        "start": 3548.4,
        "duration": 6.719,
        "text": "i mean no no"
      },
      {
        "start": 3552.799,
        "duration": 4.721,
        "text": "so yeah it's worth it's worth looking"
      },
      {
        "start": 3555.119,
        "duration": 6.401,
        "text": "into but the technologies that run"
      },
      {
        "start": 3557.52,
        "duration": 9.12,
        "text": "astra you can approximate a lot more"
      },
      {
        "start": 3561.52,
        "duration": 7.279,
        "text": "time and effort to do that um"
      },
      {
        "start": 3566.64,
        "duration": 3.12,
        "text": "there's these resources by the way this"
      },
      {
        "start": 3568.799,
        "duration": 3.76,
        "text": "deck and everything will be made"
      },
      {
        "start": 3569.76,
        "duration": 4.64,
        "text": "possible i made made available on um"
      },
      {
        "start": 3572.559,
        "duration": 4.8,
        "text": "the github repo we'll link it there as"
      },
      {
        "start": 3574.4,
        "duration": 5.679,
        "text": "well as we'll have a blog post on the"
      },
      {
        "start": 3577.359,
        "duration": 3.76,
        "text": "us but um you know there's tons and tons"
      },
      {
        "start": 3580.079,
        "duration": 4.561,
        "text": "of resources"
      },
      {
        "start": 3581.119,
        "duration": 5.281,
        "text": "um you know just a quick thing spark"
      },
      {
        "start": 3584.64,
        "duration": 3.12,
        "text": "even though it's open source uh"
      },
      {
        "start": 3586.4,
        "duration": 3.679,
        "text": "databricks"
      },
      {
        "start": 3587.76,
        "duration": 3.839,
        "text": "does a hosted spark manage spark it's"
      },
      {
        "start": 3590.079,
        "duration": 4.24,
        "text": "kind of like astra"
      },
      {
        "start": 3591.599,
        "duration": 4.0,
        "text": "for spark right and it's got a nice"
      },
      {
        "start": 3594.319,
        "duration": 2.8,
        "text": "little interface and everything it's"
      },
      {
        "start": 3595.599,
        "duration": 3.921,
        "text": "really cool"
      },
      {
        "start": 3597.119,
        "duration": 3.361,
        "text": "and there's a talk that one of my"
      },
      {
        "start": 3599.52,
        "duration": 3.599,
        "text": "colleagues is doing"
      },
      {
        "start": 3600.48,
        "duration": 4.48,
        "text": "um about how to use databricks community"
      },
      {
        "start": 3603.119,
        "duration": 5.2,
        "text": "with data stacks astra"
      },
      {
        "start": 3604.96,
        "duration": 5.28,
        "text": "so free and free right check it out"
      },
      {
        "start": 3608.319,
        "duration": 3.841,
        "text": "and but there are other providers for"
      },
      {
        "start": 3610.24,
        "duration": 4.16,
        "text": "spark as well amazon's"
      },
      {
        "start": 3612.16,
        "duration": 3.36,
        "text": "aws elastic mapreduce basically is a"
      },
      {
        "start": 3614.4,
        "duration": 3.52,
        "text": "hosted spark"
      },
      {
        "start": 3615.52,
        "duration": 4.559,
        "text": "azure hd insight is a host that sparked"
      },
      {
        "start": 3617.92,
        "duration": 2.96,
        "text": "by uh by microsoft and then google"
      },
      {
        "start": 3620.079,
        "duration": 2.961,
        "text": "dataproc"
      },
      {
        "start": 3620.88,
        "duration": 3.76,
        "text": "more recent is a host of spark slash"
      },
      {
        "start": 3623.04,
        "duration": 5.2,
        "text": "hadoop in fact all of these are"
      },
      {
        "start": 3624.64,
        "duration": 6.32,
        "text": "hadoop spark variants um"
      },
      {
        "start": 3628.24,
        "duration": 4.48,
        "text": "and those are not the only ones right so"
      },
      {
        "start": 3630.96,
        "duration": 3.2,
        "text": "you can use cloudera you can use"
      },
      {
        "start": 3632.72,
        "duration": 4.0,
        "text": "i mean there's so many different ways to"
      },
      {
        "start": 3634.16,
        "duration": 5.76,
        "text": "run spark way more than"
      },
      {
        "start": 3636.72,
        "duration": 3.2,
        "text": "i think to run cassandra"
      },
      {
        "start": 3640.4,
        "duration": 3.84,
        "text": "ibm has a lot of good material on spark"
      },
      {
        "start": 3642.799,
        "duration": 2.241,
        "text": "as well they're a big supporter of the"
      },
      {
        "start": 3644.24,
        "duration": 4.319,
        "text": "project"
      },
      {
        "start": 3645.04,
        "duration": 5.92,
        "text": "um so check it out um"
      },
      {
        "start": 3648.559,
        "duration": 3.441,
        "text": "check out the center.link we uh have as"
      },
      {
        "start": 3650.96,
        "duration": 4.0,
        "text": "you can see"
      },
      {
        "start": 3652.0,
        "duration": 4.559,
        "text": "uh the only thing next to cassandra in"
      },
      {
        "start": 3654.96,
        "duration": 4.32,
        "text": "terms of the tag count"
      },
      {
        "start": 3656.559,
        "duration": 4.161,
        "text": "is spark and kafka right so there's a"
      },
      {
        "start": 3659.28,
        "duration": 2.319,
        "text": "lot of articles on consider that link on"
      },
      {
        "start": 3660.72,
        "duration": 4.399,
        "text": "how to use spark"
      },
      {
        "start": 3661.599,
        "duration": 3.52,
        "text": "with cassandra"
      },
      {
        "start": 3665.76,
        "duration": 4.559,
        "text": "we're ready for the hands-on it's going"
      },
      {
        "start": 3667.52,
        "duration": 4.4,
        "text": "to be fairly quick because a lot of the"
      },
      {
        "start": 3670.319,
        "duration": 4.0,
        "text": "stuff we had done before"
      },
      {
        "start": 3671.92,
        "duration": 3.76,
        "text": "um we're just gonna verify that our api"
      },
      {
        "start": 3674.319,
        "duration": 4.081,
        "text": "uh is up and running"
      },
      {
        "start": 3675.68,
        "duration": 3.36,
        "text": "to make sure that you know if we do a"
      },
      {
        "start": 3678.4,
        "duration": 2.719,
        "text": "process"
      },
      {
        "start": 3679.04,
        "duration": 3.92,
        "text": "it sends it to the cassandra api it's"
      },
      {
        "start": 3681.119,
        "duration": 3.68,
        "text": "gonna work we're gonna verify very"
      },
      {
        "start": 3682.96,
        "duration": 5.119,
        "text": "quickly uh"
      },
      {
        "start": 3684.799,
        "duration": 4.161,
        "text": "cassandra you know does our cockpit"
      },
      {
        "start": 3688.079,
        "duration": 4.161,
        "text": "connect work"
      },
      {
        "start": 3688.96,
        "duration": 5.04,
        "text": "and the reason is that we we want to"
      },
      {
        "start": 3692.24,
        "duration": 3.76,
        "text": "show when we create events that the"
      },
      {
        "start": 3694.0,
        "duration": 4.88,
        "text": "spark will be able to pick it up right"
      },
      {
        "start": 3696.0,
        "duration": 4.079,
        "text": "um we're not gonna do all of the kafka"
      },
      {
        "start": 3698.88,
        "duration": 4.08,
        "text": "use cases today"
      },
      {
        "start": 3700.079,
        "duration": 4.161,
        "text": "we're just gonna generate some content"
      },
      {
        "start": 3702.96,
        "duration": 3.76,
        "text": "um"
      },
      {
        "start": 3704.24,
        "duration": 4.879,
        "text": "and then you know if you've never set up"
      },
      {
        "start": 3706.72,
        "duration": 4.24,
        "text": "a spark"
      },
      {
        "start": 3709.119,
        "duration": 3.121,
        "text": "this is just a suggested way of doing it"
      },
      {
        "start": 3710.96,
        "duration": 2.8,
        "text": "on one computer"
      },
      {
        "start": 3712.24,
        "duration": 3.04,
        "text": "right now and the only reason we're"
      },
      {
        "start": 3713.76,
        "duration": 2.88,
        "text": "doing it in svt server is because i want"
      },
      {
        "start": 3715.28,
        "duration": 3.44,
        "text": "to be able to make some changes to the"
      },
      {
        "start": 3716.64,
        "duration": 3.84,
        "text": "code and then compile really quickly"
      },
      {
        "start": 3718.72,
        "duration": 3.119,
        "text": "you don't have to have an spt server you"
      },
      {
        "start": 3720.48,
        "duration": 4.4,
        "text": "can just use svt"
      },
      {
        "start": 3721.839,
        "duration": 5.681,
        "text": "command line to build packages"
      },
      {
        "start": 3724.88,
        "duration": 3.919,
        "text": "we're going to see this in action right"
      },
      {
        "start": 3727.52,
        "duration": 2.96,
        "text": "kafka to cassandra"
      },
      {
        "start": 3728.799,
        "duration": 3.76,
        "text": "and spark streaming and then we're going"
      },
      {
        "start": 3730.48,
        "duration": 3.76,
        "text": "to see this in action using spark to"
      },
      {
        "start": 3732.559,
        "duration": 5.52,
        "text": "read and then materialize data back"
      },
      {
        "start": 3734.24,
        "duration": 5.92,
        "text": "into cassandra um"
      },
      {
        "start": 3738.079,
        "duration": 3.441,
        "text": "we're going to see this one picture um"
      },
      {
        "start": 3740.16,
        "duration": 3.04,
        "text": "again um"
      },
      {
        "start": 3741.52,
        "duration": 3.68,
        "text": "these things the registry the broker the"
      },
      {
        "start": 3743.2,
        "duration": 4.879,
        "text": "rest proxy um"
      },
      {
        "start": 3745.2,
        "duration": 4.0,
        "text": "kafka gui they're running a services"
      },
      {
        "start": 3748.079,
        "duration": 2.641,
        "text": "kafka connect can"
      },
      {
        "start": 3749.2,
        "duration": 2.32,
        "text": "also run as a service but we're not"
      },
      {
        "start": 3750.72,
        "duration": 2.48,
        "text": "gonna do that we're gonna do a"
      },
      {
        "start": 3751.52,
        "duration": 3.76,
        "text": "standalone kafka process"
      },
      {
        "start": 3753.2,
        "duration": 4.639,
        "text": "anything with a dotted line is a it's a"
      },
      {
        "start": 3755.28,
        "duration": 4.24,
        "text": "process that we can start and stop"
      },
      {
        "start": 3757.839,
        "duration": 3.361,
        "text": "versus these are going to be running uh"
      },
      {
        "start": 3759.52,
        "duration": 2.96,
        "text": "all the time on this uh"
      },
      {
        "start": 3761.2,
        "duration": 3.2,
        "text": "and actually i should have put in here"
      },
      {
        "start": 3762.48,
        "duration": 2.559,
        "text": "the spark master and the spark worker"
      },
      {
        "start": 3764.4,
        "duration": 3.36,
        "text": "too but"
      },
      {
        "start": 3765.039,
        "duration": 4.881,
        "text": "i'll update that later um the"
      },
      {
        "start": 3767.76,
        "duration": 3.44,
        "text": "materialization"
      },
      {
        "start": 3769.92,
        "duration": 4.159,
        "text": "uh this is what you're asking you know"
      },
      {
        "start": 3771.2,
        "duration": 4.879,
        "text": "what is a tag so currently"
      },
      {
        "start": 3774.079,
        "duration": 3.441,
        "text": "kafka connect can take data from kafka"
      },
      {
        "start": 3776.079,
        "duration": 4.96,
        "text": "and save it to cassandra"
      },
      {
        "start": 3777.52,
        "duration": 6.88,
        "text": "and it uses cql to update this uh"
      },
      {
        "start": 3781.039,
        "duration": 6.481,
        "text": "other code in cassandra.api writes data"
      },
      {
        "start": 3784.4,
        "duration": 4.399,
        "text": "to this table directly uh you can also"
      },
      {
        "start": 3787.52,
        "duration": 2.96,
        "text": "use a producer to"
      },
      {
        "start": 3788.799,
        "duration": 3.361,
        "text": "sorry to consume from kafka and send"
      },
      {
        "start": 3790.48,
        "duration": 2.8,
        "text": "requests to a consent of api there's an"
      },
      {
        "start": 3792.16,
        "duration": 4.48,
        "text": "example for this"
      },
      {
        "start": 3793.28,
        "duration": 6.72,
        "text": "uh which then populates via rest"
      },
      {
        "start": 3796.64,
        "duration": 5.6,
        "text": "and then that then uses cql"
      },
      {
        "start": 3800.0,
        "duration": 4.559,
        "text": "and then calculus streams uh can read"
      },
      {
        "start": 3802.24,
        "duration": 5.92,
        "text": "from the queue and then properly via"
      },
      {
        "start": 3804.559,
        "duration": 7.28,
        "text": "cql as well so this table already exists"
      },
      {
        "start": 3808.16,
        "duration": 7.919,
        "text": "in astra right now um so if i go to my"
      },
      {
        "start": 3811.839,
        "duration": 5.441,
        "text": "data stack studio and"
      },
      {
        "start": 3816.079,
        "duration": 3.201,
        "text": "there's probably like a couple of"
      },
      {
        "start": 3817.28,
        "duration": 4.079,
        "text": "thousand in here but you know"
      },
      {
        "start": 3819.28,
        "duration": 3.36,
        "text": "even this limit statement isn't really"
      },
      {
        "start": 3821.359,
        "duration": 3.521,
        "text": "going to help me much"
      },
      {
        "start": 3822.64,
        "duration": 3.28,
        "text": "it's gonna it's gonna get um it's gonna"
      },
      {
        "start": 3824.88,
        "duration": 3.199,
        "text": "do a table scan"
      },
      {
        "start": 3825.92,
        "duration": 3.76,
        "text": "normally you would never do this right"
      },
      {
        "start": 3828.079,
        "duration": 4.161,
        "text": "because our primary key is"
      },
      {
        "start": 3829.68,
        "duration": 4.24,
        "text": "is uh it's not included in this query"
      },
      {
        "start": 3832.24,
        "duration": 5.359,
        "text": "but you know this data"
      },
      {
        "start": 3833.92,
        "duration": 6.399,
        "text": "um is you can look at it"
      },
      {
        "start": 3837.599,
        "duration": 4.641,
        "text": "in like json view or uh right so this is"
      },
      {
        "start": 3840.319,
        "duration": 4.161,
        "text": "the data that is inside"
      },
      {
        "start": 3842.24,
        "duration": 4.24,
        "text": "the table that i'm looking at earlier"
      },
      {
        "start": 3844.48,
        "duration": 5.2,
        "text": "okay uh it already exists"
      },
      {
        "start": 3846.48,
        "duration": 4.4,
        "text": "there are other table um that we will"
      },
      {
        "start": 3849.68,
        "duration": 2.639,
        "text": "recreate"
      },
      {
        "start": 3850.88,
        "duration": 3.52,
        "text": "uh because they already exist because i"
      },
      {
        "start": 3852.319,
        "duration": 5.441,
        "text": "rate our streaming"
      },
      {
        "start": 3854.4,
        "duration": 3.76,
        "text": "from kafka and while one process writes"
      },
      {
        "start": 3857.76,
        "duration": 3.039,
        "text": "to"
      },
      {
        "start": 3858.16,
        "duration": 3.199,
        "text": "this another spark streaming process can"
      },
      {
        "start": 3860.799,
        "duration": 3.28,
        "text": "be"
      },
      {
        "start": 3861.359,
        "duration": 3.76,
        "text": "continuously updating the leafs by tag"
      },
      {
        "start": 3864.079,
        "duration": 3.28,
        "text": "table"
      },
      {
        "start": 3865.119,
        "duration": 3.121,
        "text": "what does this table have it basically"
      },
      {
        "start": 3867.359,
        "duration": 4.24,
        "text": "has"
      },
      {
        "start": 3868.24,
        "duration": 5.119,
        "text": "given a tag show me um"
      },
      {
        "start": 3871.599,
        "duration": 3.681,
        "text": "everything that i need to basically you"
      },
      {
        "start": 3873.359,
        "duration": 3.361,
        "text": "know populate a web page for example"
      },
      {
        "start": 3875.28,
        "duration": 3.44,
        "text": "right show me the listing of all the"
      },
      {
        "start": 3876.72,
        "duration": 5.359,
        "text": "articles for this particular tag"
      },
      {
        "start": 3878.72,
        "duration": 6.72,
        "text": "and if you look at the columns"
      },
      {
        "start": 3882.079,
        "duration": 3.361,
        "text": "for this table"
      },
      {
        "start": 3889.92,
        "duration": 3.04,
        "text": "right it actually has a couple more"
      },
      {
        "start": 3890.88,
        "duration": 4.159,
        "text": "things it has a title has a url"
      },
      {
        "start": 3892.96,
        "duration": 3.92,
        "text": "because for that view that's all we need"
      },
      {
        "start": 3895.039,
        "duration": 3.28,
        "text": "right to show that particular item on a"
      },
      {
        "start": 3896.88,
        "duration": 2.4,
        "text": "page this is all we need we don't need"
      },
      {
        "start": 3898.319,
        "duration": 2.8,
        "text": "to re"
      },
      {
        "start": 3899.28,
        "duration": 3.12,
        "text": "um you know we don't need to copy"
      },
      {
        "start": 3901.119,
        "duration": 4.72,
        "text": "everything that's in this"
      },
      {
        "start": 3902.4,
        "duration": 6.399,
        "text": "main table into the leaves by tag"
      },
      {
        "start": 3905.839,
        "duration": 4.0,
        "text": "the cassandra uh so this is another"
      },
      {
        "start": 3908.799,
        "duration": 2.161,
        "text": "table called tags"
      },
      {
        "start": 3909.839,
        "duration": 2.801,
        "text": "this is the one that's going to read"
      },
      {
        "start": 3910.96,
        "duration": 2.96,
        "text": "from cassandra it's going to crunch it"
      },
      {
        "start": 3912.64,
        "duration": 4.719,
        "text": "and it's going to save it back"
      },
      {
        "start": 3913.92,
        "duration": 4.8,
        "text": "all it's really saving is um given a tag"
      },
      {
        "start": 3917.359,
        "duration": 4.401,
        "text": "it saves the count"
      },
      {
        "start": 3918.72,
        "duration": 4.879,
        "text": "so we can do a very quick query you know"
      },
      {
        "start": 3921.76,
        "duration": 3.599,
        "text": "how many like the query that you see on"
      },
      {
        "start": 3923.599,
        "duration": 5.52,
        "text": "this web page right here"
      },
      {
        "start": 3925.359,
        "duration": 6.801,
        "text": "um a great suspender has suspended my"
      },
      {
        "start": 3929.119,
        "duration": 6.161,
        "text": "my page yeah probably anyway great"
      },
      {
        "start": 3932.16,
        "duration": 4.24,
        "text": "uh great plugin makes chrome uh much"
      },
      {
        "start": 3935.28,
        "duration": 1.839,
        "text": "more usable if you have a thousand"
      },
      {
        "start": 3936.4,
        "duration": 4.399,
        "text": "windows"
      },
      {
        "start": 3937.119,
        "duration": 7.281,
        "text": "uh but like right here this uh"
      },
      {
        "start": 3940.799,
        "duration": 5.441,
        "text": "listing right is coming from"
      },
      {
        "start": 3944.4,
        "duration": 3.04,
        "text": "uh a database in my sql database we're"
      },
      {
        "start": 3946.24,
        "duration": 3.92,
        "text": "just doing a query"
      },
      {
        "start": 3947.44,
        "duration": 3.359,
        "text": "right group by and count and all that"
      },
      {
        "start": 3950.16,
        "duration": 2.959,
        "text": "but in"
      },
      {
        "start": 3950.799,
        "duration": 3.76,
        "text": "cassandra we can't do a google fly we"
      },
      {
        "start": 3953.119,
        "duration": 3.68,
        "text": "can't do account"
      },
      {
        "start": 3954.559,
        "duration": 3.601,
        "text": "in a group by so we have to materialize"
      },
      {
        "start": 3956.799,
        "duration": 2.081,
        "text": "this table as well so this is kind of"
      },
      {
        "start": 3958.16,
        "duration": 3.52,
        "text": "what it's going to"
      },
      {
        "start": 3958.88,
        "duration": 3.52,
        "text": "show whereas the leaves by tag could"
      },
      {
        "start": 3961.68,
        "duration": 2.399,
        "text": "potentially"
      },
      {
        "start": 3962.4,
        "duration": 3.28,
        "text": "power this interface right here so give"
      },
      {
        "start": 3964.079,
        "duration": 3.76,
        "text": "it a tag right"
      },
      {
        "start": 3965.68,
        "duration": 4.32,
        "text": "show me the title show me and give me"
      },
      {
        "start": 3967.839,
        "duration": 3.2,
        "text": "the url and uh maybe we have to put a"
      },
      {
        "start": 3970.0,
        "duration": 2.88,
        "text": "couple of other things in there but"
      },
      {
        "start": 3971.039,
        "duration": 5.8,
        "text": "that's kind of what we're doing we're"
      },
      {
        "start": 3972.88,
        "duration": 6.64,
        "text": "using a real use case to make these"
      },
      {
        "start": 3976.839,
        "duration": 6.601,
        "text": "tables"
      },
      {
        "start": 3979.52,
        "duration": 7.039,
        "text": "go ahead and start up my uh get pot"
      },
      {
        "start": 3983.44,
        "duration": 4.639,
        "text": "um it's uh normally"
      },
      {
        "start": 3986.559,
        "duration": 5.601,
        "text": "if i started it once it doesn't take"
      },
      {
        "start": 3988.079,
        "duration": 6.641,
        "text": "that long um"
      },
      {
        "start": 3992.16,
        "duration": 3.84,
        "text": "give it a second while it's happening um"
      },
      {
        "start": 3994.72,
        "duration": 5.599,
        "text": "just to quickly review"
      },
      {
        "start": 3996.0,
        "duration": 7.2,
        "text": "uh the gitpod ide um you have an editor"
      },
      {
        "start": 4000.319,
        "duration": 4.48,
        "text": "it's connected to get to a git repo and"
      },
      {
        "start": 4003.2,
        "duration": 2.96,
        "text": "if you pay for gitpod you can connect"
      },
      {
        "start": 4004.799,
        "duration": 2.8,
        "text": "your private repositories"
      },
      {
        "start": 4006.16,
        "duration": 3.76,
        "text": "so you can use this for your projects"
      },
      {
        "start": 4007.599,
        "duration": 5.921,
        "text": "for work um"
      },
      {
        "start": 4009.92,
        "duration": 6.96,
        "text": "again with github.com um any open source"
      },
      {
        "start": 4013.52,
        "duration": 5.839,
        "text": "repository you can pull"
      },
      {
        "start": 4016.88,
        "duration": 3.28,
        "text": "and use gitpod to test it out to play"
      },
      {
        "start": 4019.359,
        "duration": 3.361,
        "text": "around with it"
      },
      {
        "start": 4020.16,
        "duration": 3.679,
        "text": "um you also have the ability to start"
      },
      {
        "start": 4022.72,
        "duration": 4.48,
        "text": "terminals"
      },
      {
        "start": 4023.839,
        "duration": 6.401,
        "text": "bash terminals and run services"
      },
      {
        "start": 4027.2,
        "duration": 7.119,
        "text": "it can then expose the urls"
      },
      {
        "start": 4030.24,
        "duration": 7.76,
        "text": "um that are like port 8000 or 480"
      },
      {
        "start": 4034.319,
        "duration": 5.201,
        "text": "on a special url that you can test so"
      },
      {
        "start": 4038.0,
        "duration": 3.68,
        "text": "anything that you can imagine you're"
      },
      {
        "start": 4039.52,
        "duration": 2.559,
        "text": "doing in a local host you can basically"
      },
      {
        "start": 4041.68,
        "duration": 2.24,
        "text": "do"
      },
      {
        "start": 4042.079,
        "duration": 3.441,
        "text": "on github the only thing that we found"
      },
      {
        "start": 4043.92,
        "duration": 4.72,
        "text": "that you can't do right now"
      },
      {
        "start": 4045.52,
        "duration": 4.4,
        "text": "is you can't run docker inside this"
      },
      {
        "start": 4048.64,
        "duration": 3.04,
        "text": "container because this is a docker"
      },
      {
        "start": 4049.92,
        "duration": 4.32,
        "text": "container itself um"
      },
      {
        "start": 4051.68,
        "duration": 5.04,
        "text": "there's theoretically a way to do this"
      },
      {
        "start": 4054.24,
        "duration": 3.76,
        "text": "where we loaded with docker but"
      },
      {
        "start": 4056.72,
        "duration": 4.079,
        "text": "you know if you find this person named"
      },
      {
        "start": 4058.0,
        "duration": 5.68,
        "text": "free time i'm looking for them right"
      },
      {
        "start": 4060.799,
        "duration": 3.441,
        "text": "yeah and also so not only you do have"
      },
      {
        "start": 4063.68,
        "duration": 3.84,
        "text": "the full"
      },
      {
        "start": 4064.24,
        "duration": 6.48,
        "text": "ide with all the the vs extensions"
      },
      {
        "start": 4067.52,
        "duration": 4.88,
        "text": "available for you but you know"
      },
      {
        "start": 4070.72,
        "duration": 4.0,
        "text": "java is pre-installed know this"
      },
      {
        "start": 4072.4,
        "duration": 6.0,
        "text": "pre-installed python it's print style"
      },
      {
        "start": 4074.72,
        "duration": 7.28,
        "text": "so that's pretty powerful to death"
      },
      {
        "start": 4078.4,
        "duration": 3.6,
        "text": "yeah um the"
      },
      {
        "start": 4083.119,
        "duration": 6.801,
        "text": "this particular real-time repo is"
      },
      {
        "start": 4088.079,
        "duration": 3.441,
        "text": "little heavy because we've got kafka"
      },
      {
        "start": 4089.92,
        "duration": 5.04,
        "text": "we've got spark on it"
      },
      {
        "start": 4091.52,
        "duration": 5.36,
        "text": "just a little just a little bit um"
      },
      {
        "start": 4094.96,
        "duration": 3.279,
        "text": "but you know it was kind of the only way"
      },
      {
        "start": 4096.88,
        "duration": 3.6,
        "text": "to make it"
      },
      {
        "start": 4098.239,
        "duration": 3.92,
        "text": "as simple as possible but not simple"
      },
      {
        "start": 4100.48,
        "duration": 2.319,
        "text": "right otherwise we would have to have"
      },
      {
        "start": 4102.159,
        "duration": 3.2,
        "text": "you"
      },
      {
        "start": 4102.799,
        "duration": 4.081,
        "text": "uh start another git pod repo to run"
      },
      {
        "start": 4105.359,
        "duration": 4.96,
        "text": "spark"
      },
      {
        "start": 4106.88,
        "duration": 6.56,
        "text": "and so that would have been a charlie"
      },
      {
        "start": 4110.319,
        "duration": 4.081,
        "text": "so what i'm doing right here right as"
      },
      {
        "start": 4113.44,
        "duration": 3.279,
        "text": "this thing came up"
      },
      {
        "start": 4114.4,
        "duration": 3.919,
        "text": "these services got started i'm making"
      },
      {
        "start": 4116.719,
        "duration": 3.6,
        "text": "these ports public"
      },
      {
        "start": 4118.319,
        "duration": 3.44,
        "text": "right these are the different ports that"
      },
      {
        "start": 4120.319,
        "duration": 3.44,
        "text": "i can make public i don't have to"
      },
      {
        "start": 4121.759,
        "duration": 3.361,
        "text": "make all of them public i'm just making"
      },
      {
        "start": 4123.759,
        "duration": 2.721,
        "text": "them public because i want to you know"
      },
      {
        "start": 4125.12,
        "duration": 4.8,
        "text": "show you what i'm doing here"
      },
      {
        "start": 4126.48,
        "duration": 3.92,
        "text": "so um what happened when i started this"
      },
      {
        "start": 4129.92,
        "duration": 3.839,
        "text": "repo"
      },
      {
        "start": 4130.4,
        "duration": 4.799,
        "text": "this uh get pod container uh kafka"
      },
      {
        "start": 4133.759,
        "duration": 3.121,
        "text": "started up that's really what happened"
      },
      {
        "start": 4135.199,
        "duration": 4.401,
        "text": "that's why these ports are open"
      },
      {
        "start": 4136.88,
        "duration": 4.56,
        "text": "um and i'm gonna start something called"
      },
      {
        "start": 4139.6,
        "duration": 5.119,
        "text": "akhq"
      },
      {
        "start": 4141.44,
        "duration": 6.16,
        "text": "basically to um"
      },
      {
        "start": 4144.719,
        "duration": 3.44,
        "text": "show give me a gui for kafka so the"
      },
      {
        "start": 4147.6,
        "duration": 1.759,
        "text": "person"
      },
      {
        "start": 4148.159,
        "duration": 3.52,
        "text": "first and foremost what we're going to"
      },
      {
        "start": 4149.359,
        "duration": 5.281,
        "text": "do is we've got this up and running"
      },
      {
        "start": 4151.679,
        "duration": 3.841,
        "text": "um this thing can take time it doesn't"
      },
      {
        "start": 4154.64,
        "duration": 2.719,
        "text": "have to be up and running"
      },
      {
        "start": 4155.52,
        "duration": 3.319,
        "text": "immediately but we're going to go and"
      },
      {
        "start": 4157.359,
        "duration": 5.521,
        "text": "start up"
      },
      {
        "start": 4158.839,
        "duration": 7.641,
        "text": "akhq what uh i like about akhq"
      },
      {
        "start": 4162.88,
        "duration": 4.24,
        "text": "is it's free um it can work with"
      },
      {
        "start": 4166.48,
        "duration": 3.44,
        "text": "basically"
      },
      {
        "start": 4167.12,
        "duration": 3.92,
        "text": "any kafka so you can you can use akhq to"
      },
      {
        "start": 4169.92,
        "duration": 3.279,
        "text": "talk to"
      },
      {
        "start": 4171.04,
        "duration": 3.759,
        "text": "managed kafka service by amazon you can"
      },
      {
        "start": 4173.199,
        "duration": 4.64,
        "text": "use it to talk to confluent"
      },
      {
        "start": 4174.799,
        "duration": 5.841,
        "text": "in this case uh our kafka instance is"
      },
      {
        "start": 4177.839,
        "duration": 3.201,
        "text": "is kind of a confluent community edition"
      },
      {
        "start": 4180.64,
        "duration": 4.079,
        "text": "and"
      },
      {
        "start": 4181.04,
        "duration": 5.119,
        "text": "it's going to be used for um"
      },
      {
        "start": 4184.719,
        "duration": 2.64,
        "text": "just looking at and seeing like what are"
      },
      {
        "start": 4186.159,
        "duration": 2.08,
        "text": "the schemas in there you know what are"
      },
      {
        "start": 4187.359,
        "duration": 2.96,
        "text": "the"
      },
      {
        "start": 4188.239,
        "duration": 4.881,
        "text": "topics can i look at the message inside"
      },
      {
        "start": 4190.319,
        "duration": 2.801,
        "text": "the topic itself"
      },
      {
        "start": 4194.56,
        "duration": 4.24,
        "text": "so if you've done this before you can"
      },
      {
        "start": 4197.28,
        "duration": 4.8,
        "text": "fast forward to"
      },
      {
        "start": 4198.8,
        "duration": 6.32,
        "text": "um we've already gotten this running"
      },
      {
        "start": 4202.08,
        "duration": 6.24,
        "text": "um i'm just gonna quickly check to see"
      },
      {
        "start": 4205.12,
        "duration": 5.76,
        "text": "is this actually running"
      },
      {
        "start": 4208.32,
        "duration": 3.12,
        "text": "uh so because it has been started at"
      },
      {
        "start": 4210.88,
        "duration": 2.88,
        "text": "load"
      },
      {
        "start": 4211.44,
        "duration": 4.16,
        "text": "i mean there is a gitpod.yaml and you"
      },
      {
        "start": 4213.76,
        "duration": 2.32,
        "text": "simply said i want everything that's"
      },
      {
        "start": 4215.6,
        "duration": 3.92,
        "text": "running"
      },
      {
        "start": 4216.08,
        "duration": 8.4,
        "text": "when the the instance just started"
      },
      {
        "start": 4219.52,
        "duration": 8.08,
        "text": "yeah and this is i believe right"
      },
      {
        "start": 4224.48,
        "duration": 5.12,
        "text": "it's green yep"
      },
      {
        "start": 4227.6,
        "duration": 3.119,
        "text": "right this is my gitpod.yaml it"
      },
      {
        "start": 4229.6,
        "duration": 3.84,
        "text": "basically says"
      },
      {
        "start": 4230.719,
        "duration": 3.52,
        "text": "you know uh you know go ahead and start"
      },
      {
        "start": 4233.44,
        "duration": 4.16,
        "text": "confluent"
      },
      {
        "start": 4234.239,
        "duration": 5.601,
        "text": "right um it also cleans my"
      },
      {
        "start": 4237.6,
        "duration": 3.28,
        "text": "uh scala program so i can then recompile"
      },
      {
        "start": 4239.84,
        "duration": 2.56,
        "text": "it i don't necessarily"
      },
      {
        "start": 4240.88,
        "duration": 3.76,
        "text": "have like old packages in there right"
      },
      {
        "start": 4242.4,
        "duration": 5.52,
        "text": "that's what i wanted to do um"
      },
      {
        "start": 4244.64,
        "duration": 5.519,
        "text": "so we got kafka running right"
      },
      {
        "start": 4247.92,
        "duration": 3.44,
        "text": "um if i wanted to force it i could start"
      },
      {
        "start": 4250.159,
        "duration": 2.08,
        "text": "it but i think it's already working"
      },
      {
        "start": 4251.36,
        "duration": 6.0,
        "text": "right now"
      },
      {
        "start": 4252.239,
        "duration": 20.0,
        "text": "um let's see if my previous work"
      },
      {
        "start": 4257.36,
        "duration": 18.08,
        "text": "shows up which is what i run ak hq"
      },
      {
        "start": 4272.239,
        "duration": 3.201,
        "text": "so i'm going to open this up"
      },
      {
        "start": 4276.719,
        "duration": 4.241,
        "text": "and it should come up pretty quickly"
      },
      {
        "start": 4283.12,
        "duration": 5.599,
        "text": "it's a nice little interface"
      },
      {
        "start": 4286.4,
        "duration": 3.92,
        "text": "yeah so it used to be called kafka hq"
      },
      {
        "start": 4288.719,
        "duration": 4.801,
        "text": "but probably due to"
      },
      {
        "start": 4290.32,
        "duration": 6.08,
        "text": "you know the apache community not fun"
      },
      {
        "start": 4293.52,
        "duration": 4.08,
        "text": "is reusing the name it's just hq"
      },
      {
        "start": 4296.4,
        "duration": 4.88,
        "text": "trademark"
      },
      {
        "start": 4297.6,
        "duration": 6.48,
        "text": "yeah exactly um so at the very beginning"
      },
      {
        "start": 4301.28,
        "duration": 3.84,
        "text": "when confluence starts up right it it"
      },
      {
        "start": 4304.08,
        "duration": 3.599,
        "text": "has"
      },
      {
        "start": 4305.12,
        "duration": 3.119,
        "text": "some topics built in to run kafka"
      },
      {
        "start": 4307.679,
        "duration": 2.881,
        "text": "connect"
      },
      {
        "start": 4308.239,
        "duration": 4.081,
        "text": "basically this is what it's for um but"
      },
      {
        "start": 4310.56,
        "duration": 3.04,
        "text": "there's no actual topics in here so we"
      },
      {
        "start": 4312.32,
        "duration": 2.48,
        "text": "really have to go and just quickly"
      },
      {
        "start": 4313.6,
        "duration": 4.16,
        "text": "create our topics"
      },
      {
        "start": 4314.8,
        "duration": 4.24,
        "text": "um we're going to be creating a topic"
      },
      {
        "start": 4317.76,
        "duration": 5.12,
        "text": "using"
      },
      {
        "start": 4319.04,
        "duration": 5.36,
        "text": "a schema using avro"
      },
      {
        "start": 4322.88,
        "duration": 3.279,
        "text": "that's something we covered last time"
      },
      {
        "start": 4324.4,
        "duration": 5.04,
        "text": "the reason we have a schema"
      },
      {
        "start": 4326.159,
        "duration": 5.921,
        "text": "is that um without a schema"
      },
      {
        "start": 4329.44,
        "duration": 3.92,
        "text": "we cannot do structured streaming uh and"
      },
      {
        "start": 4332.08,
        "duration": 4.32,
        "text": "without a schema"
      },
      {
        "start": 4333.36,
        "duration": 4.64,
        "text": "we cannot uh do um"
      },
      {
        "start": 4336.4,
        "duration": 4.48,
        "text": "kafka connect we need to have that i"
      },
      {
        "start": 4338.0,
        "duration": 5.12,
        "text": "mean without a schema we can't do this"
      },
      {
        "start": 4340.88,
        "duration": 3.2,
        "text": "the rest proxy either it's kind of like"
      },
      {
        "start": 4343.12,
        "duration": 4.8,
        "text": "a must-have"
      },
      {
        "start": 4344.08,
        "duration": 5.44,
        "text": "um you can get into an argument about"
      },
      {
        "start": 4347.92,
        "duration": 3.52,
        "text": "um you know whether or not we should"
      },
      {
        "start": 4349.52,
        "duration": 3.04,
        "text": "have schemas in kafka with somebody else"
      },
      {
        "start": 4351.44,
        "duration": 3.6,
        "text": "because i won't have it i'm just going"
      },
      {
        "start": 4352.56,
        "duration": 5.679,
        "text": "to tell you you should have schemas"
      },
      {
        "start": 4355.04,
        "duration": 6.56,
        "text": "um so what i'm doing is i'm just listing"
      },
      {
        "start": 4358.239,
        "duration": 5.841,
        "text": "right the topics and i can see now"
      },
      {
        "start": 4361.6,
        "duration": 4.16,
        "text": "that there is a new topic called you"
      },
      {
        "start": 4364.08,
        "duration": 2.639,
        "text": "know record leaves avro this is what"
      },
      {
        "start": 4365.76,
        "duration": 2.56,
        "text": "i've made"
      },
      {
        "start": 4366.719,
        "duration": 4.081,
        "text": "uh and it works it looks like it's"
      },
      {
        "start": 4368.32,
        "duration": 6.24,
        "text": "working fine right um"
      },
      {
        "start": 4370.8,
        "duration": 7.68,
        "text": "then i want to do is i want to"
      },
      {
        "start": 4374.56,
        "duration": 3.92,
        "text": "create a bunch of messages um"
      },
      {
        "start": 4378.64,
        "duration": 3.76,
        "text": "the departments for this should already"
      },
      {
        "start": 4380.8,
        "duration": 5.04,
        "text": "be there but i'm just going to"
      },
      {
        "start": 4382.4,
        "duration": 3.44,
        "text": "make sure that"
      },
      {
        "start": 4386.08,
        "duration": 4.159,
        "text": "you still do it anyways okay it's"
      },
      {
        "start": 4387.92,
        "duration": 6.4,
        "text": "already done good"
      },
      {
        "start": 4390.239,
        "duration": 5.92,
        "text": "and i have a simple python program"
      },
      {
        "start": 4394.32,
        "duration": 3.28,
        "text": "oh i'm sorry i do need to create a"
      },
      {
        "start": 4396.159,
        "duration": 4.401,
        "text": "schema i just created the message that i"
      },
      {
        "start": 4397.6,
        "duration": 2.96,
        "text": "have not created a schema"
      },
      {
        "start": 4401.92,
        "duration": 3.04,
        "text": "now we have a schema"
      },
      {
        "start": 4406.0,
        "duration": 5.52,
        "text": "and if i see what i have"
      },
      {
        "start": 4409.84,
        "duration": 4.319,
        "text": "i don't have to go to command line if i"
      },
      {
        "start": 4411.52,
        "duration": 2.639,
        "text": "just refresh"
      },
      {
        "start": 4425.44,
        "duration": 5.44,
        "text": "yeah so um could we"
      },
      {
        "start": 4428.56,
        "duration": 4.0,
        "text": "drop the pdf of the slide after the"
      },
      {
        "start": 4430.88,
        "duration": 4.24,
        "text": "workshop it's it's it's"
      },
      {
        "start": 4432.56,
        "duration": 4.639,
        "text": "in in the repo it's not there yet so i"
      },
      {
        "start": 4435.12,
        "duration": 3.68,
        "text": "could put the pdf somewhere but that"
      },
      {
        "start": 4437.199,
        "duration": 2.96,
        "text": "would be probably better simply in the"
      },
      {
        "start": 4438.8,
        "duration": 3.919,
        "text": "repo just get"
      },
      {
        "start": 4440.159,
        "duration": 4.161,
        "text": "asked yeah yeah we can put in the repo"
      },
      {
        "start": 4442.719,
        "duration": 2.641,
        "text": "or usually what we do is we'll put it up"
      },
      {
        "start": 4444.32,
        "duration": 3.359,
        "text": "on slide"
      },
      {
        "start": 4445.36,
        "duration": 4.64,
        "text": "slideshare uh and then just embed it"
      },
      {
        "start": 4447.679,
        "duration": 5.361,
        "text": "sounds great"
      },
      {
        "start": 4450.0,
        "duration": 5.52,
        "text": "um so we got us we've got a schema right"
      },
      {
        "start": 4453.04,
        "duration": 4.48,
        "text": "everything we verified that it exists uh"
      },
      {
        "start": 4455.52,
        "duration": 5.36,
        "text": "we checked via 8khq"
      },
      {
        "start": 4457.52,
        "duration": 6.48,
        "text": "and uh you know um"
      },
      {
        "start": 4460.88,
        "duration": 5.359,
        "text": "what we have basically is a way to"
      },
      {
        "start": 4464.0,
        "duration": 3.84,
        "text": "see messages as they come in that's why"
      },
      {
        "start": 4466.239,
        "duration": 2.96,
        "text": "i like hq i don't have to have like"
      },
      {
        "start": 4467.84,
        "duration": 2.72,
        "text": "another consumer to look at it i can"
      },
      {
        "start": 4469.199,
        "duration": 2.161,
        "text": "actually see a live feel of what's"
      },
      {
        "start": 4470.56,
        "duration": 4.159,
        "text": "happening"
      },
      {
        "start": 4471.36,
        "duration": 6.4,
        "text": "um and let's go ahead and"
      },
      {
        "start": 4474.719,
        "duration": 4.641,
        "text": "run some import process here so let's go"
      },
      {
        "start": 4477.76,
        "duration": 4.8,
        "text": "to"
      },
      {
        "start": 4479.36,
        "duration": 3.2,
        "text": "i'm going to do a live tail"
      },
      {
        "start": 4487.6,
        "duration": 6.8,
        "text": "and i'm going to check out"
      },
      {
        "start": 4490.719,
        "duration": 7.121,
        "text": "this here like 50 messages at a time"
      },
      {
        "start": 4494.4,
        "duration": 3.44,
        "text": "and if i run"
      },
      {
        "start": 4505.36,
        "duration": 3.28,
        "text": "so what this is doing is it's reading"
      },
      {
        "start": 4506.88,
        "duration": 5.279,
        "text": "from like a json file and it's"
      },
      {
        "start": 4508.64,
        "duration": 6.88,
        "text": "making a bunch of uh sample um"
      },
      {
        "start": 4512.159,
        "duration": 7.361,
        "text": "you know messages and"
      },
      {
        "start": 4515.52,
        "duration": 7.199,
        "text": "it should be showing up here"
      },
      {
        "start": 4519.52,
        "duration": 6.96,
        "text": "so that's simply a loader of your topic"
      },
      {
        "start": 4522.719,
        "duration": 6.401,
        "text": "written yeah that's what we're doing"
      },
      {
        "start": 4526.48,
        "duration": 4.64,
        "text": "just kind of loading data into the queue"
      },
      {
        "start": 4529.12,
        "duration": 5.36,
        "text": "we can take a look at over here"
      },
      {
        "start": 4531.12,
        "duration": 4.88,
        "text": "so notice that we have the data"
      },
      {
        "start": 4534.48,
        "duration": 3.199,
        "text": "populated in two different topics this"
      },
      {
        "start": 4536.0,
        "duration": 3.84,
        "text": "one is with the schema"
      },
      {
        "start": 4537.679,
        "duration": 4.161,
        "text": "there's about a thousand in there right"
      },
      {
        "start": 4539.84,
        "duration": 4.399,
        "text": "and if i wanted to go in here and dig"
      },
      {
        "start": 4541.84,
        "duration": 2.399,
        "text": "deeper"
      },
      {
        "start": 4546.88,
        "duration": 4.48,
        "text": "it takes a second times to load it but i"
      },
      {
        "start": 4549.84,
        "duration": 4.56,
        "text": "can see my actual messages"
      },
      {
        "start": 4551.36,
        "duration": 3.04,
        "text": "like what did i send here"
      },
      {
        "start": 4554.96,
        "duration": 5.52,
        "text": "and that was done so there's a thousand"
      },
      {
        "start": 4558.4,
        "duration": 5.36,
        "text": "topics in here"
      },
      {
        "start": 4560.48,
        "duration": 6.16,
        "text": "and we know um that they're"
      },
      {
        "start": 4563.76,
        "duration": 3.439,
        "text": "that they're in here because akh is"
      },
      {
        "start": 4566.64,
        "duration": 3.84,
        "text": "telling us"
      },
      {
        "start": 4567.199,
        "duration": 5.201,
        "text": "now what we need to do is to take this"
      },
      {
        "start": 4570.48,
        "duration": 3.28,
        "text": "and send it over to cassandra so how are"
      },
      {
        "start": 4572.4,
        "duration": 3.52,
        "text": "we going to do that"
      },
      {
        "start": 4573.76,
        "duration": 3.76,
        "text": "we're actually actually going to use the"
      },
      {
        "start": 4575.92,
        "duration": 2.799,
        "text": "kafka connect because it's the easiest"
      },
      {
        "start": 4577.52,
        "duration": 3.6,
        "text": "one"
      },
      {
        "start": 4578.719,
        "duration": 3.041,
        "text": "krafka connect setup is fairly simple"
      },
      {
        "start": 4581.12,
        "duration": 3.28,
        "text": "you can"
      },
      {
        "start": 4581.76,
        "duration": 3.2,
        "text": "you know read it from the last example"
      },
      {
        "start": 4584.4,
        "duration": 3.68,
        "text": "but"
      },
      {
        "start": 4584.96,
        "duration": 4.0,
        "text": "um what i like about connect is all we"
      },
      {
        "start": 4588.08,
        "duration": 4.32,
        "text": "needed to do was"
      },
      {
        "start": 4588.96,
        "duration": 4.239,
        "text": "make a schema and uh you know given the"
      },
      {
        "start": 4592.4,
        "duration": 4.16,
        "text": "bundle"
      },
      {
        "start": 4593.199,
        "duration": 5.921,
        "text": "the secure bundle uh and authentication"
      },
      {
        "start": 4596.56,
        "duration": 4.48,
        "text": "um though all the work i had to do in"
      },
      {
        "start": 4599.12,
        "duration": 7.039,
        "text": "topic connect to make this work"
      },
      {
        "start": 4601.04,
        "duration": 5.119,
        "text": "was say here i'll find it"
      },
      {
        "start": 4607.76,
        "duration": 4.16,
        "text": "i needed to say this thing is equal to"
      },
      {
        "start": 4611.44,
        "duration": 2.799,
        "text": "this thing"
      },
      {
        "start": 4611.92,
        "duration": 3.68,
        "text": "this thing is equal to this thing this"
      },
      {
        "start": 4614.239,
        "duration": 4.48,
        "text": "is the mapping that i made"
      },
      {
        "start": 4615.6,
        "duration": 5.24,
        "text": "in kafka connect for it to take the data"
      },
      {
        "start": 4618.719,
        "duration": 4.561,
        "text": "from kafka and just save it to center"
      },
      {
        "start": 4620.84,
        "duration": 3.24,
        "text": "um you'll notice when we do the spark"
      },
      {
        "start": 4623.28,
        "duration": 3.04,
        "text": "aspect of it"
      },
      {
        "start": 4624.08,
        "duration": 4.0,
        "text": "that this is the same topic we're going"
      },
      {
        "start": 4626.32,
        "duration": 4.0,
        "text": "to read from to save the the leafs by"
      },
      {
        "start": 4628.08,
        "duration": 2.24,
        "text": "tag"
      },
      {
        "start": 4630.4,
        "duration": 3.52,
        "text": "and to start up connect"
      },
      {
        "start": 4635.36,
        "duration": 4.319,
        "text": "we're going to bypass some of these"
      },
      {
        "start": 4636.8,
        "duration": 2.879,
        "text": "other ways of doing it"
      },
      {
        "start": 4639.84,
        "duration": 4.8,
        "text": "as i mentioned there's a lot of"
      },
      {
        "start": 4640.8,
        "duration": 3.84,
        "text": "different ways to do this um"
      },
      {
        "start": 4645.04,
        "duration": 4.96,
        "text": "and we've already done this work we've"
      },
      {
        "start": 4647.28,
        "duration": 4.959,
        "text": "already done this work"
      },
      {
        "start": 4650.0,
        "duration": 2.239,
        "text": "and"
      },
      {
        "start": 4653.92,
        "duration": 4.319,
        "text": "go in here i wouldn't do that you just"
      },
      {
        "start": 4656.0,
        "duration": 4.08,
        "text": "need to start calculating it"
      },
      {
        "start": 4658.239,
        "duration": 3.44,
        "text": "so as you can all see this you simply"
      },
      {
        "start": 4660.08,
        "duration": 3.68,
        "text": "copy paste commands so you"
      },
      {
        "start": 4661.679,
        "duration": 4.0,
        "text": "you could do that take your time don't"
      },
      {
        "start": 4663.76,
        "duration": 4.32,
        "text": "expect to follow with us"
      },
      {
        "start": 4665.679,
        "duration": 4.401,
        "text": "live but you know the stream is recorded"
      },
      {
        "start": 4668.08,
        "duration": 4.24,
        "text": "you can go at your pace"
      },
      {
        "start": 4670.08,
        "duration": 4.079,
        "text": "but it's free go there copy paste try by"
      },
      {
        "start": 4672.32,
        "duration": 5.12,
        "text": "yourself"
      },
      {
        "start": 4674.159,
        "duration": 5.601,
        "text": "yeah we're going to stop the service"
      },
      {
        "start": 4677.44,
        "duration": 3.84,
        "text": "can fluent connect uh coffee connect"
      },
      {
        "start": 4679.76,
        "duration": 2.399,
        "text": "because we are going to do a stand-alone"
      },
      {
        "start": 4681.28,
        "duration": 4.24,
        "text": "service"
      },
      {
        "start": 4682.159,
        "duration": 6.161,
        "text": "um there is a way to have this process"
      },
      {
        "start": 4685.52,
        "duration": 4.56,
        "text": "running all the time so as data comes in"
      },
      {
        "start": 4688.32,
        "duration": 3.919,
        "text": "you can automatically always save it to"
      },
      {
        "start": 4690.08,
        "duration": 3.76,
        "text": "cassandra using kafka connect but"
      },
      {
        "start": 4692.239,
        "duration": 3.201,
        "text": "because i wanted to have some control"
      },
      {
        "start": 4693.84,
        "duration": 6.24,
        "text": "over this and be able to shut it down"
      },
      {
        "start": 4695.44,
        "duration": 4.64,
        "text": "i'm just running it stand alone so"
      },
      {
        "start": 4702.88,
        "duration": 5.04,
        "text": "this is maven doing some basic"
      },
      {
        "start": 4705.12,
        "duration": 2.8,
        "text": "compilations"
      },
      {
        "start": 4710.08,
        "duration": 11.76,
        "text": "and there's going to be some errors"
      },
      {
        "start": 4712.0,
        "duration": 9.84,
        "text": "don't worry about it"
      },
      {
        "start": 4722.719,
        "duration": 6.96,
        "text": "all right so it's up and running and"
      },
      {
        "start": 4726.48,
        "duration": 5.12,
        "text": "um it's committing a bunch of uh the"
      },
      {
        "start": 4729.679,
        "duration": 3.681,
        "text": "because we didn't consume the previously"
      },
      {
        "start": 4731.6,
        "duration": 5.04,
        "text": "you know inputted data"
      },
      {
        "start": 4733.36,
        "duration": 4.64,
        "text": "it's basically running some processes uh"
      },
      {
        "start": 4736.64,
        "duration": 3.68,
        "text": "if we were to go to"
      },
      {
        "start": 4738.0,
        "duration": 3.44,
        "text": "astra we would see you know section i'm"
      },
      {
        "start": 4740.32,
        "duration": 4.879,
        "text": "curious to see"
      },
      {
        "start": 4741.44,
        "duration": 6.719,
        "text": "if i go here to help"
      },
      {
        "start": 4745.199,
        "duration": 5.04,
        "text": "so was kafka connect started before or"
      },
      {
        "start": 4748.159,
        "duration": 5.121,
        "text": "did you just start now"
      },
      {
        "start": 4750.239,
        "duration": 4.881,
        "text": "kafka connect was started so as soon"
      },
      {
        "start": 4753.28,
        "duration": 4.879,
        "text": "yeah okay as soon as you"
      },
      {
        "start": 4755.12,
        "duration": 5.52,
        "text": "uh push stuff in the topic"
      },
      {
        "start": 4758.159,
        "duration": 3.441,
        "text": "because cafe connect was there he was"
      },
      {
        "start": 4760.64,
        "duration": 4.4,
        "text": "ready to"
      },
      {
        "start": 4761.6,
        "duration": 6.4,
        "text": "push that data somewhere"
      },
      {
        "start": 4765.04,
        "duration": 3.6,
        "text": "so you define what we called a sink"
      },
      {
        "start": 4768.0,
        "duration": 4.88,
        "text": "which is"
      },
      {
        "start": 4768.64,
        "duration": 4.24,
        "text": "here astra and boom now"
      },
      {
        "start": 4774.159,
        "duration": 3.121,
        "text": "that's a nice tune"
      },
      {
        "start": 4775.7,
        "duration": 4.14,
        "text": "[Laughter]"
      },
      {
        "start": 4777.28,
        "duration": 3.919,
        "text": "and now kafka connect on his own is"
      },
      {
        "start": 4779.84,
        "duration": 4.8,
        "text": "really pushing the data"
      },
      {
        "start": 4781.199,
        "duration": 6.881,
        "text": "into astral there is no extra stuff"
      },
      {
        "start": 4784.64,
        "duration": 5.2,
        "text": "yet no spark involved yet"
      },
      {
        "start": 4788.08,
        "duration": 4.48,
        "text": "yeah we're just testing to make sure"
      },
      {
        "start": 4789.84,
        "duration": 5.44,
        "text": "that kafka is able to do its job"
      },
      {
        "start": 4792.56,
        "duration": 4.72,
        "text": "and you know basically we can send data"
      },
      {
        "start": 4795.28,
        "duration": 5.12,
        "text": "to it and we can retrieve data to it"
      },
      {
        "start": 4797.28,
        "duration": 4.879,
        "text": "um and you know right now um"
      },
      {
        "start": 4800.4,
        "duration": 3.279,
        "text": "there's like 17 clients connected and"
      },
      {
        "start": 4802.159,
        "duration": 2.881,
        "text": "that's because connect is using a bunch"
      },
      {
        "start": 4803.679,
        "duration": 3.04,
        "text": "of different connections"
      },
      {
        "start": 4805.04,
        "duration": 3.84,
        "text": "to save data it's going to it's going to"
      },
      {
        "start": 4806.719,
        "duration": 3.681,
        "text": "do as much as it can so copycat connect"
      },
      {
        "start": 4808.88,
        "duration": 2.64,
        "text": "is pretty powerful if you just want to"
      },
      {
        "start": 4810.4,
        "duration": 3.36,
        "text": "land data"
      },
      {
        "start": 4811.52,
        "duration": 3.36,
        "text": "right from into it's it's perfect for"
      },
      {
        "start": 4813.76,
        "duration": 4.399,
        "text": "that you don't need"
      },
      {
        "start": 4814.88,
        "duration": 4.4,
        "text": "spark for that um so let's give that a"
      },
      {
        "start": 4818.159,
        "duration": 4.161,
        "text": "little bit more time"
      },
      {
        "start": 4819.28,
        "duration": 6.64,
        "text": "uh it will um"
      },
      {
        "start": 4822.32,
        "duration": 3.6,
        "text": "tell us in akhq"
      },
      {
        "start": 4827.04,
        "duration": 7.36,
        "text": "oops wrong topic"
      },
      {
        "start": 4832.639,
        "duration": 3.921,
        "text": "so uh oh actually another place we can"
      },
      {
        "start": 4834.4,
        "duration": 5.2,
        "text": "take is the dataset studio"
      },
      {
        "start": 4836.56,
        "duration": 5.76,
        "text": "um so what we're going to do is we're"
      },
      {
        "start": 4839.6,
        "duration": 2.72,
        "text": "going to do a count"
      },
      {
        "start": 4842.9,
        "duration": 6.779,
        "text": "[Music]"
      },
      {
        "start": 4844.96,
        "duration": 7.6,
        "text": "i know right you spark to count"
      },
      {
        "start": 4849.679,
        "duration": 3.281,
        "text": "yes true true true um so we had we had"
      },
      {
        "start": 4852.56,
        "duration": 2.159,
        "text": "about"
      },
      {
        "start": 4852.96,
        "duration": 3.12,
        "text": "you know a couple i think uh yeah so"
      },
      {
        "start": 4854.719,
        "duration": 4.801,
        "text": "it's kind of too long right"
      },
      {
        "start": 4856.08,
        "duration": 4.4,
        "text": "it's going to take too long to do it um"
      },
      {
        "start": 4859.52,
        "duration": 2.8,
        "text": "i believe"
      },
      {
        "start": 4860.48,
        "duration": 3.52,
        "text": "i don't really have a way to change the"
      },
      {
        "start": 4862.32,
        "duration": 4.879,
        "text": "timeout here but that's okay"
      },
      {
        "start": 4864.0,
        "duration": 4.8,
        "text": "um let me see"
      },
      {
        "start": 4867.199,
        "duration": 3.761,
        "text": "and i and i don't want to try my luck"
      },
      {
        "start": 4868.8,
        "duration": 5.52,
        "text": "into it on on the console"
      },
      {
        "start": 4870.96,
        "duration": 6.48,
        "text": "um so just give it"
      },
      {
        "start": 4874.32,
        "duration": 6.319,
        "text": "give it a second um once"
      },
      {
        "start": 4877.44,
        "duration": 6.48,
        "text": "the data shows up in uh cassandra"
      },
      {
        "start": 4880.639,
        "duration": 7.361,
        "text": "um because this data is in"
      },
      {
        "start": 4883.92,
        "duration": 6.48,
        "text": "the um uh the kafka uh"
      },
      {
        "start": 4888.0,
        "duration": 3.52,
        "text": "uh we we can potentially drop our data"
      },
      {
        "start": 4890.4,
        "duration": 4.0,
        "text": "and then recreate"
      },
      {
        "start": 4891.52,
        "duration": 5.199,
        "text": "okay so what i'm gonna actually do um is"
      },
      {
        "start": 4894.4,
        "duration": 9.44,
        "text": "i'm gonna truncate"
      },
      {
        "start": 4896.719,
        "duration": 7.121,
        "text": "table urls okay um"
      },
      {
        "start": 4904.08,
        "duration": 7.76,
        "text": "oh we don't need the okay good um"
      },
      {
        "start": 4907.679,
        "duration": 4.161,
        "text": "and then let's see what this counts as"
      },
      {
        "start": 4914.4,
        "duration": 3.12,
        "text": "okay so there's zero data in there right"
      },
      {
        "start": 4916.8,
        "duration": 5.28,
        "text": "um"
      },
      {
        "start": 4917.52,
        "duration": 8.0,
        "text": "and i'm going to go back here"
      },
      {
        "start": 4922.08,
        "duration": 7.2,
        "text": "and i'm going to produce some messages"
      },
      {
        "start": 4925.52,
        "duration": 4.8,
        "text": "and i'm going to open a new terminal"
      },
      {
        "start": 4929.28,
        "duration": 3.359,
        "text": "and this is the same way we're going to"
      },
      {
        "start": 4930.32,
        "duration": 5.28,
        "text": "produce messages when we start up spark"
      },
      {
        "start": 4932.639,
        "duration": 5.921,
        "text": "right um meaning we're just going to use"
      },
      {
        "start": 4935.6,
        "duration": 10.24,
        "text": "a python program that we had earlier"
      },
      {
        "start": 4938.56,
        "duration": 7.28,
        "text": "and just populate the heck out of it"
      },
      {
        "start": 4946.4,
        "duration": 3.52,
        "text": "and this data importer is pretty uh"
      },
      {
        "start": 4949.36,
        "duration": 4.72,
        "text": "simple"
      },
      {
        "start": 4949.92,
        "duration": 4.16,
        "text": "um you can take a look at it on your"
      },
      {
        "start": 4956.84,
        "duration": 2.92,
        "text": "time"
      },
      {
        "start": 4958.159,
        "duration": 3.761,
        "text": "all right so we're going to create a"
      },
      {
        "start": 4959.76,
        "duration": 5.52,
        "text": "bunch of messages"
      },
      {
        "start": 4961.92,
        "duration": 3.92,
        "text": "um and you know we're kafka connect is"
      },
      {
        "start": 4965.28,
        "duration": 1.76,
        "text": "running"
      },
      {
        "start": 4965.84,
        "duration": 6.16,
        "text": "right now it's going to start taking"
      },
      {
        "start": 4967.04,
        "duration": 10.159,
        "text": "some tasks"
      },
      {
        "start": 4972.0,
        "duration": 5.199,
        "text": "and in the meantime let's see"
      },
      {
        "start": 4980.08,
        "duration": 5.119,
        "text": "wow look at that thousand items in like"
      },
      {
        "start": 4983.52,
        "duration": 3.84,
        "text": "30 minutes"
      },
      {
        "start": 4985.199,
        "duration": 3.281,
        "text": "boom right so that's how we're going to"
      },
      {
        "start": 4987.36,
        "duration": 4.879,
        "text": "create messages"
      },
      {
        "start": 4988.48,
        "duration": 6.88,
        "text": "um let's go back to our"
      },
      {
        "start": 4992.239,
        "duration": 4.641,
        "text": "uh readme so we verified that cassandra"
      },
      {
        "start": 4995.36,
        "duration": 2.96,
        "text": "is up and running we verified kafka is"
      },
      {
        "start": 4996.88,
        "duration": 2.799,
        "text": "up and running we've verified cockpit"
      },
      {
        "start": 4998.32,
        "duration": 4.56,
        "text": "connect is doing its job"
      },
      {
        "start": 4999.679,
        "duration": 4.321,
        "text": "right now we're gonna start doing some"
      },
      {
        "start": 5002.88,
        "duration": 4.4,
        "text": "spark"
      },
      {
        "start": 5004.0,
        "duration": 6.719,
        "text": "um and you know and we just"
      },
      {
        "start": 5007.28,
        "duration": 5.84,
        "text": "we just basically did this um"
      },
      {
        "start": 5010.719,
        "duration": 4.48,
        "text": "we have already downloaded smart right"
      },
      {
        "start": 5013.12,
        "duration": 5.68,
        "text": "like what we did was download"
      },
      {
        "start": 5015.199,
        "duration": 4.96,
        "text": "um the latest version uh and untarded"
      },
      {
        "start": 5018.8,
        "duration": 3.439,
        "text": "uh i'm not gonna do that again because i"
      },
      {
        "start": 5020.159,
        "duration": 4.401,
        "text": "want to mess up the installation but"
      },
      {
        "start": 5022.239,
        "duration": 3.121,
        "text": "what what we see here in the spark"
      },
      {
        "start": 5024.56,
        "duration": 3.04,
        "text": "directory"
      },
      {
        "start": 5025.36,
        "duration": 3.6,
        "text": "if you get the git pod you normally"
      },
      {
        "start": 5027.6,
        "duration": 4.88,
        "text": "wouldn't have this"
      },
      {
        "start": 5028.96,
        "duration": 4.96,
        "text": "folder first but it shows uh spark uh"
      },
      {
        "start": 5032.48,
        "duration": 4.48,
        "text": "the spark bin hadoop you wouldn't see"
      },
      {
        "start": 5033.92,
        "duration": 3.04,
        "text": "that so we did that already"
      },
      {
        "start": 5037.12,
        "duration": 3.599,
        "text": "the next thing that we do is we download"
      },
      {
        "start": 5039.679,
        "duration": 4.801,
        "text": "svt"
      },
      {
        "start": 5040.719,
        "duration": 6.561,
        "text": "uh really sbts used to compile"
      },
      {
        "start": 5044.48,
        "duration": 4.56,
        "text": "scala programs you don't have to use"
      },
      {
        "start": 5047.28,
        "duration": 3.2,
        "text": "scala you can use java you can use maven"
      },
      {
        "start": 5049.04,
        "duration": 3.679,
        "text": "to compile your spark jobs"
      },
      {
        "start": 5050.48,
        "duration": 3.84,
        "text": "i'm using scala i'm using simple build"
      },
      {
        "start": 5052.719,
        "duration": 4.801,
        "text": "tool"
      },
      {
        "start": 5054.32,
        "duration": 7.12,
        "text": "we have already made these tables okay"
      },
      {
        "start": 5057.52,
        "duration": 7.28,
        "text": "um but just so that you believe me"
      },
      {
        "start": 5061.44,
        "duration": 5.84,
        "text": "that this is working code so add if not"
      },
      {
        "start": 5064.8,
        "duration": 7.04,
        "text": "exist somewhere i don't know"
      },
      {
        "start": 5067.28,
        "duration": 4.56,
        "text": "yeah right um"
      },
      {
        "start": 5074.48,
        "duration": 11.36,
        "text": "oh be careful you might"
      },
      {
        "start": 5077.76,
        "duration": 8.08,
        "text": "truncate again your url table"
      },
      {
        "start": 5086.639,
        "duration": 3.841,
        "text": "i mean i don't know what's wrong with"
      },
      {
        "start": 5088.639,
        "duration": 5.361,
        "text": "that"
      },
      {
        "start": 5090.48,
        "duration": 7.6,
        "text": "okay good uh and then tags"
      },
      {
        "start": 5094.0,
        "duration": 7.679,
        "text": "so here"
      },
      {
        "start": 5098.08,
        "duration": 3.599,
        "text": "if i go and check out what's"
      },
      {
        "start": 5104.48,
        "duration": 5.84,
        "text": "nope all right so i can just do this i"
      },
      {
        "start": 5107.36,
        "duration": 2.96,
        "text": "need to say drop table"
      },
      {
        "start": 5110.84,
        "duration": 6.68,
        "text": "tags yeah that's what i was missing"
      },
      {
        "start": 5114.32,
        "duration": 3.2,
        "text": "i was missing the table"
      },
      {
        "start": 5118.4,
        "duration": 9.44,
        "text": "and drop table leaves"
      },
      {
        "start": 5122.159,
        "duration": 5.681,
        "text": "by tag"
      },
      {
        "start": 5127.92,
        "duration": 3.04,
        "text": "and this will update look at that it's"
      },
      {
        "start": 5130.48,
        "duration": 3.28,
        "text": "gone"
      },
      {
        "start": 5130.96,
        "duration": 4.08,
        "text": "forever just kidding um so we're gonna"
      },
      {
        "start": 5133.76,
        "duration": 3.2,
        "text": "make these two tables"
      },
      {
        "start": 5135.04,
        "duration": 4.0,
        "text": "right where we're gonna materialize our"
      },
      {
        "start": 5136.96,
        "duration": 3.67,
        "text": "information"
      },
      {
        "start": 5139.04,
        "duration": 4.649,
        "text": "and and"
      },
      {
        "start": 5140.63,
        "duration": 3.059,
        "text": "[Music]"
      },
      {
        "start": 5143.92,
        "duration": 3.44,
        "text": "we're gonna start our spark master uh"
      },
      {
        "start": 5145.84,
        "duration": 4.96,
        "text": "what is a spark master"
      },
      {
        "start": 5147.36,
        "duration": 7.279,
        "text": "uh spark master is kind of like the"
      },
      {
        "start": 5150.8,
        "duration": 7.359,
        "text": "the commander for spark you give it um"
      },
      {
        "start": 5154.639,
        "duration": 3.52,
        "text": "basically um"
      },
      {
        "start": 5158.8,
        "duration": 3.6,
        "text": "uh by the way we're we're stopping uh"
      },
      {
        "start": 5161.12,
        "duration": 1.76,
        "text": "kafka connect because we don't need it"
      },
      {
        "start": 5162.4,
        "duration": 2.56,
        "text": "anymore"
      },
      {
        "start": 5162.88,
        "duration": 4.16,
        "text": "right we already have kafka data in"
      },
      {
        "start": 5164.96,
        "duration": 5.44,
        "text": "there um"
      },
      {
        "start": 5167.04,
        "duration": 6.48,
        "text": "but the the spark master is"
      },
      {
        "start": 5170.4,
        "duration": 5.839,
        "text": "just like the commander and it takes"
      },
      {
        "start": 5173.52,
        "duration": 4.88,
        "text": "requests and it plans out and then"
      },
      {
        "start": 5176.239,
        "duration": 5.44,
        "text": "delegates the work to the workers"
      },
      {
        "start": 5178.4,
        "duration": 4.72,
        "text": "um so when we start the spark master we"
      },
      {
        "start": 5181.679,
        "duration": 3.761,
        "text": "actually get a port that we can"
      },
      {
        "start": 5183.12,
        "duration": 2.32,
        "text": "view"
      },
      {
        "start": 5191.679,
        "duration": 3.04,
        "text": "kind of what's happening so right now"
      },
      {
        "start": 5192.88,
        "duration": 3.12,
        "text": "there's no workers right we don't have"
      },
      {
        "start": 5194.719,
        "duration": 3.52,
        "text": "any live workers we don't"
      },
      {
        "start": 5196.0,
        "duration": 3.76,
        "text": "have any cords available we have nothing"
      },
      {
        "start": 5198.239,
        "duration": 3.761,
        "text": "available but the spark master is up"
      },
      {
        "start": 5199.76,
        "duration": 4.879,
        "text": "saying i'm ready to accept"
      },
      {
        "start": 5202.0,
        "duration": 4.0,
        "text": "new workers right um and so we got to"
      },
      {
        "start": 5204.639,
        "duration": 4.56,
        "text": "add a worker to it"
      },
      {
        "start": 5206.0,
        "duration": 4.56,
        "text": "and uh you know what we need to do is uh"
      },
      {
        "start": 5209.199,
        "duration": 4.561,
        "text": "you know we have to go in here and get"
      },
      {
        "start": 5210.56,
        "duration": 6.32,
        "text": "the url for the spark master"
      },
      {
        "start": 5213.76,
        "duration": 6.32,
        "text": "and um you know basically"
      },
      {
        "start": 5216.88,
        "duration": 5.04,
        "text": "start the slave and say start slate map"
      },
      {
        "start": 5220.08,
        "duration": 4.4,
        "text": "and then give it the master url uh if"
      },
      {
        "start": 5221.92,
        "duration": 4.239,
        "text": "you're using um"
      },
      {
        "start": 5224.48,
        "duration": 3.36,
        "text": "you know other technologies to run"
      },
      {
        "start": 5226.159,
        "duration": 3.52,
        "text": "sparky you don't have to do this because"
      },
      {
        "start": 5227.84,
        "duration": 4.08,
        "text": "it's kind of part of that package"
      },
      {
        "start": 5229.679,
        "duration": 2.241,
        "text": "right"
      },
      {
        "start": 5236.4,
        "duration": 7.68,
        "text": "important note here is um"
      },
      {
        "start": 5240.08,
        "duration": 8.079,
        "text": "there's a lot of um different tunings"
      },
      {
        "start": 5244.08,
        "duration": 7.68,
        "text": "that you can do with spark"
      },
      {
        "start": 5248.159,
        "duration": 4.961,
        "text": "in the code in the configuration um"
      },
      {
        "start": 5251.76,
        "duration": 3.28,
        "text": "and in the configuration you can give it"
      },
      {
        "start": 5253.12,
        "duration": 3.68,
        "text": "like how many executors to use how many"
      },
      {
        "start": 5255.04,
        "duration": 4.8,
        "text": "how much memory per executor"
      },
      {
        "start": 5256.8,
        "duration": 6.24,
        "text": "um but"
      },
      {
        "start": 5259.84,
        "duration": 6.64,
        "text": "um i'm not gonna cover all that um"
      },
      {
        "start": 5263.04,
        "duration": 5.119,
        "text": "that's as i said you can expend days on"
      },
      {
        "start": 5266.48,
        "duration": 5.36,
        "text": "end talking about spark"
      },
      {
        "start": 5268.159,
        "duration": 3.681,
        "text": "um but"
      },
      {
        "start": 5272.159,
        "duration": 4.801,
        "text": "it's important that you know you cannot"
      },
      {
        "start": 5274.48,
        "duration": 4.64,
        "text": "use more resources than you have"
      },
      {
        "start": 5276.96,
        "duration": 3.04,
        "text": "right so in our case when we run the job"
      },
      {
        "start": 5279.12,
        "duration": 4.079,
        "text": "it's going to use as much"
      },
      {
        "start": 5280.0,
        "duration": 5.04,
        "text": "as possible but if we say hey"
      },
      {
        "start": 5283.199,
        "duration": 3.52,
        "text": "this streaming job only started with"
      },
      {
        "start": 5285.04,
        "duration": 3.52,
        "text": "three cores and"
      },
      {
        "start": 5286.719,
        "duration": 5.281,
        "text": "um you know you use like you know 1gb"
      },
      {
        "start": 5288.56,
        "duration": 6.0,
        "text": "each it's going to use up basically 3gb"
      },
      {
        "start": 5292.0,
        "duration": 4.32,
        "text": "and 3 cores and then we can start"
      },
      {
        "start": 5294.56,
        "duration": 4.32,
        "text": "another job so spark"
      },
      {
        "start": 5296.32,
        "duration": 3.839,
        "text": "isn't just a single uh tasker it can run"
      },
      {
        "start": 5298.88,
        "duration": 2.24,
        "text": "multiple processes you just have to have"
      },
      {
        "start": 5300.159,
        "duration": 2.56,
        "text": "enough resources"
      },
      {
        "start": 5301.12,
        "duration": 3.36,
        "text": "right and that's why it makes it"
      },
      {
        "start": 5302.719,
        "duration": 3.281,
        "text": "powerful"
      },
      {
        "start": 5304.48,
        "duration": 3.679,
        "text": "because you can have a very very big"
      },
      {
        "start": 5306.0,
        "duration": 4.4,
        "text": "cluster right"
      },
      {
        "start": 5308.159,
        "duration": 3.761,
        "text": "and with like thousands of cores and"
      },
      {
        "start": 5310.4,
        "duration": 3.279,
        "text": "terabytes of memory and you can say run"
      },
      {
        "start": 5311.92,
        "duration": 3.279,
        "text": "this spark job run that spark job"
      },
      {
        "start": 5313.679,
        "duration": 3.361,
        "text": "and depending on how big the job is"
      },
      {
        "start": 5315.199,
        "duration": 5.04,
        "text": "it'll get spread out"
      },
      {
        "start": 5317.04,
        "duration": 4.08,
        "text": "and it'll get executed um if we go back"
      },
      {
        "start": 5320.239,
        "duration": 3.92,
        "text": "to the worker"
      },
      {
        "start": 5321.12,
        "duration": 4.72,
        "text": "sorry this to the master if i refresh"
      },
      {
        "start": 5324.159,
        "duration": 4.961,
        "text": "you'll see that that worker is not"
      },
      {
        "start": 5325.84,
        "duration": 6.319,
        "text": "registered with this much available"
      },
      {
        "start": 5329.12,
        "duration": 5.519,
        "text": "resources right"
      },
      {
        "start": 5332.159,
        "duration": 4.0,
        "text": "i don't have enough resources on this"
      },
      {
        "start": 5334.639,
        "duration": 2.881,
        "text": "git pod to open up another worker so i"
      },
      {
        "start": 5336.159,
        "duration": 4.0,
        "text": "won't"
      },
      {
        "start": 5337.52,
        "duration": 3.76,
        "text": "that's still a lot remember kafka is"
      },
      {
        "start": 5340.159,
        "duration": 4.241,
        "text": "running in background"
      },
      {
        "start": 5341.28,
        "duration": 3.12,
        "text": "including connect"
      },
      {
        "start": 5346.8,
        "duration": 4.32,
        "text": "so we're going to start the spark sorry"
      },
      {
        "start": 5349.92,
        "duration": 4.08,
        "text": "the simple build tool"
      },
      {
        "start": 5351.12,
        "duration": 4.0,
        "text": "um i like having this utility to quickly"
      },
      {
        "start": 5354.0,
        "duration": 3.679,
        "text": "recompile"
      },
      {
        "start": 5355.12,
        "duration": 4.32,
        "text": "uh you know as i make some changes you"
      },
      {
        "start": 5357.679,
        "duration": 3.04,
        "text": "don't need to do this normally"
      },
      {
        "start": 5359.44,
        "duration": 3.84,
        "text": "like you don't have to have a spark"
      },
      {
        "start": 5360.719,
        "duration": 5.92,
        "text": "build server"
      },
      {
        "start": 5363.28,
        "duration": 6.48,
        "text": "so this is our kafka connect i can go"
      },
      {
        "start": 5366.639,
        "duration": 3.121,
        "text": "ahead and stop this"
      },
      {
        "start": 5371.36,
        "duration": 3.92,
        "text": "all right we don't need this anymore and"
      },
      {
        "start": 5375.36,
        "duration": 2.48,
        "text": "let's see"
      },
      {
        "start": 5382.4,
        "duration": 2.64,
        "text": "there we go"
      },
      {
        "start": 5385.44,
        "duration": 6.16,
        "text": "and all this svt server is doing for me"
      },
      {
        "start": 5388.48,
        "duration": 6.159,
        "text": "is giving me the ability to say assemble"
      },
      {
        "start": 5391.6,
        "duration": 5.76,
        "text": "avengers assemble right now"
      },
      {
        "start": 5394.639,
        "duration": 3.361,
        "text": "it's compiling and the beauty of scala"
      },
      {
        "start": 5397.36,
        "duration": 4.08,
        "text": "is that"
      },
      {
        "start": 5398.0,
        "duration": 5.679,
        "text": "when you say svt assemble"
      },
      {
        "start": 5401.44,
        "duration": 3.44,
        "text": "it only goes and checks the scala files"
      },
      {
        "start": 5403.679,
        "duration": 3.841,
        "text": "that have been"
      },
      {
        "start": 5404.88,
        "duration": 5.04,
        "text": "changed and it's a little bit more"
      },
      {
        "start": 5407.52,
        "duration": 5.52,
        "text": "elegant i think than maven like"
      },
      {
        "start": 5409.92,
        "duration": 4.16,
        "text": "it does uh much faster in fact"
      },
      {
        "start": 5413.04,
        "duration": 3.76,
        "text": "i don't know how to explain it but i"
      },
      {
        "start": 5414.08,
        "duration": 4.24,
        "text": "read about it before it uses scala"
      },
      {
        "start": 5416.8,
        "duration": 5.12,
        "text": "streams internally to basically build"
      },
      {
        "start": 5418.32,
        "duration": 3.6,
        "text": "its own software um"
      },
      {
        "start": 5422.719,
        "duration": 3.92,
        "text": "so it's starting up for the first time"
      },
      {
        "start": 5425.28,
        "duration": 4.72,
        "text": "it's getting the basic"
      },
      {
        "start": 5426.639,
        "duration": 5.361,
        "text": "um you know repos from maven right so"
      },
      {
        "start": 5430.0,
        "duration": 5.28,
        "text": "scala is a jvm system"
      },
      {
        "start": 5432.0,
        "duration": 5.36,
        "text": "that means that anything that's on maven"
      },
      {
        "start": 5435.28,
        "duration": 3.04,
        "text": "anything that you have access to on on"
      },
      {
        "start": 5437.36,
        "duration": 4.879,
        "text": "maven"
      },
      {
        "start": 5438.32,
        "duration": 11.52,
        "text": "um you can get um"
      },
      {
        "start": 5442.239,
        "duration": 7.601,
        "text": "all right so we got it"
      },
      {
        "start": 5451.04,
        "duration": 3.5,
        "text": "and"
      },
      {
        "start": 5451.41,
        "duration": 3.13,
        "text": "[Music]"
      },
      {
        "start": 5454.719,
        "duration": 5.361,
        "text": "there's a couple more things that we"
      },
      {
        "start": 5455.92,
        "duration": 4.16,
        "text": "needed for spark so it's downloading"
      },
      {
        "start": 5460.84,
        "duration": 3.799,
        "text": "that"
      },
      {
        "start": 5462.239,
        "duration": 3.041,
        "text": "and i'm making a uh what's called a fat"
      },
      {
        "start": 5464.639,
        "duration": 3.52,
        "text": "jar"
      },
      {
        "start": 5465.28,
        "duration": 3.28,
        "text": "okay um you don't have to make a fat jar"
      },
      {
        "start": 5468.159,
        "duration": 2.641,
        "text": "um"
      },
      {
        "start": 5468.56,
        "duration": 3.119,
        "text": "the reason we're making a fat jar is"
      },
      {
        "start": 5470.8,
        "duration": 3.6,
        "text": "this jar"
      },
      {
        "start": 5471.679,
        "duration": 3.601,
        "text": "has everything it needs so i can send it"
      },
      {
        "start": 5474.4,
        "duration": 3.52,
        "text": "to"
      },
      {
        "start": 5475.28,
        "duration": 4.08,
        "text": "any spark server and it'll work if that"
      },
      {
        "start": 5477.92,
        "duration": 3.759,
        "text": "spark server"
      },
      {
        "start": 5479.36,
        "duration": 4.0,
        "text": "had all of these libraries then my my"
      },
      {
        "start": 5481.679,
        "duration": 3.04,
        "text": "jar would not have to be that big"
      },
      {
        "start": 5483.36,
        "duration": 3.359,
        "text": "because i don't have to package my own"
      },
      {
        "start": 5484.719,
        "duration": 3.841,
        "text": "smart connector driver right so"
      },
      {
        "start": 5486.719,
        "duration": 3.761,
        "text": "this is just a way to ensure that my"
      },
      {
        "start": 5488.56,
        "duration": 3.119,
        "text": "libraries that i need are going to be in"
      },
      {
        "start": 5490.48,
        "duration": 3.12,
        "text": "that jar"
      },
      {
        "start": 5491.679,
        "duration": 3.601,
        "text": "that's going to get executed if you're"
      },
      {
        "start": 5493.6,
        "duration": 2.72,
        "text": "not familiar with what a jar file is a"
      },
      {
        "start": 5495.28,
        "duration": 3.12,
        "text": "jar file is a"
      },
      {
        "start": 5496.32,
        "duration": 4.48,
        "text": "glorified zip file it just ends in dot"
      },
      {
        "start": 5498.4,
        "duration": 4.64,
        "text": "jar it's a way to package"
      },
      {
        "start": 5500.8,
        "duration": 4.879,
        "text": "everything that executes in code into"
      },
      {
        "start": 5503.04,
        "duration": 4.96,
        "text": "one jar file"
      },
      {
        "start": 5505.679,
        "duration": 5.361,
        "text": "we have a properties configuration file"
      },
      {
        "start": 5508.0,
        "duration": 6.8,
        "text": "um which i edited earlier"
      },
      {
        "start": 5511.04,
        "duration": 7.199,
        "text": "but it's really just"
      },
      {
        "start": 5514.8,
        "duration": 4.64,
        "text": "a way to configure the spark job without"
      },
      {
        "start": 5518.239,
        "duration": 2.4,
        "text": "doing it on the command line but"
      },
      {
        "start": 5519.44,
        "duration": 2.0,
        "text": "everything that you see in this"
      },
      {
        "start": 5520.639,
        "duration": 3.121,
        "text": "properties"
      },
      {
        "start": 5521.44,
        "duration": 4.56,
        "text": "file you can send in the command line"
      },
      {
        "start": 5523.76,
        "duration": 5.84,
        "text": "like you can say use this different"
      },
      {
        "start": 5526.0,
        "duration": 5.04,
        "text": "file uh for the for my secure bundle"
      },
      {
        "start": 5529.6,
        "duration": 3.039,
        "text": "uh use these different views are"
      },
      {
        "start": 5531.04,
        "duration": 5.119,
        "text": "different user and password"
      },
      {
        "start": 5532.639,
        "duration": 4.801,
        "text": "um and if you can imagine the same spark"
      },
      {
        "start": 5536.159,
        "duration": 3.441,
        "text": "job could be run against different"
      },
      {
        "start": 5537.44,
        "duration": 6.16,
        "text": "cassandra servers different cassandra"
      },
      {
        "start": 5539.6,
        "duration": 6.4,
        "text": "key spaces so this spark"
      },
      {
        "start": 5543.6,
        "duration": 6.32,
        "text": "master needs to be updated because we we"
      },
      {
        "start": 5546.0,
        "duration": 3.92,
        "text": "potentially have a new spark master here"
      },
      {
        "start": 5551.44,
        "duration": 4.48,
        "text": "it should be the same because i i mean"
      },
      {
        "start": 5553.12,
        "duration": 4.64,
        "text": "uh i'll double check though"
      },
      {
        "start": 5555.92,
        "duration": 3.279,
        "text": "yeah it's actually it's not the same"
      },
      {
        "start": 5557.76,
        "duration": 5.68,
        "text": "because i've started a new uh"
      },
      {
        "start": 5559.199,
        "duration": 8.401,
        "text": "new master um and"
      },
      {
        "start": 5563.44,
        "duration": 11.199,
        "text": "now we're ready we're ready to run um"
      },
      {
        "start": 5567.6,
        "duration": 8.559,
        "text": "code and i'm gonna actually"
      },
      {
        "start": 5574.639,
        "duration": 4.08,
        "text": "all right i don't need an svt server"
      },
      {
        "start": 5576.159,
        "duration": 6.0,
        "text": "anymore i already compiled what i needed"
      },
      {
        "start": 5578.719,
        "duration": 6.641,
        "text": "um so i'm gonna run my first spark job"
      },
      {
        "start": 5582.159,
        "duration": 5.361,
        "text": "which is leaves by tag and uh be careful"
      },
      {
        "start": 5585.36,
        "duration": 4.0,
        "text": "when you copy and paste this"
      },
      {
        "start": 5587.52,
        "duration": 4.08,
        "text": "you have to give it uh you don't have to"
      },
      {
        "start": 5589.36,
        "duration": 5.279,
        "text": "give it um"
      },
      {
        "start": 5591.6,
        "duration": 4.559,
        "text": "you know all of these parameters but um"
      },
      {
        "start": 5594.639,
        "duration": 2.721,
        "text": "i wanted to show that you can always"
      },
      {
        "start": 5596.159,
        "duration": 4.161,
        "text": "override the conf"
      },
      {
        "start": 5597.36,
        "duration": 4.96,
        "text": "file uh with whatever is in the con file"
      },
      {
        "start": 5600.32,
        "duration": 5.12,
        "text": "with with your own setting here"
      },
      {
        "start": 5602.32,
        "duration": 5.359,
        "text": "um so copy"
      },
      {
        "start": 5605.44,
        "duration": 4.0,
        "text": "paste i'm just going to quickly paste it"
      },
      {
        "start": 5607.679,
        "duration": 5.761,
        "text": "here i'm not going to save my file"
      },
      {
        "start": 5609.44,
        "duration": 6.239,
        "text": "and i'm going to change this to"
      },
      {
        "start": 5613.44,
        "duration": 4.719,
        "text": "my name of my database right it's called"
      },
      {
        "start": 5615.679,
        "duration": 2.48,
        "text": "platform"
      },
      {
        "start": 5618.719,
        "duration": 6.161,
        "text": "and what is this doing spark submit"
      },
      {
        "start": 5622.239,
        "duration": 4.721,
        "text": "is saying run this class we'll take a"
      },
      {
        "start": 5624.88,
        "duration": 4.48,
        "text": "look at that code"
      },
      {
        "start": 5626.96,
        "duration": 3.199,
        "text": "using this properties file and by the"
      },
      {
        "start": 5629.36,
        "duration": 2.0,
        "text": "way"
      },
      {
        "start": 5630.159,
        "duration": 3.361,
        "text": "take a look at the zip file because"
      },
      {
        "start": 5631.36,
        "duration": 5.44,
        "text": "that's where my secure bundle is"
      },
      {
        "start": 5633.52,
        "duration": 4.96,
        "text": "and my stuff my stuff is in here"
      },
      {
        "start": 5636.8,
        "duration": 4.56,
        "text": "my stuff is in this jar that i created"
      },
      {
        "start": 5638.48,
        "duration": 6.0,
        "text": "earlier um"
      },
      {
        "start": 5641.36,
        "duration": 5.68,
        "text": "so got that ready to go"
      },
      {
        "start": 5644.48,
        "duration": 3.92,
        "text": "let's take a look at the code so if you"
      },
      {
        "start": 5647.04,
        "duration": 4.8,
        "text": "go to the spark cassandra"
      },
      {
        "start": 5648.4,
        "duration": 4.56,
        "text": "directory um you'll see in the source"
      },
      {
        "start": 5651.84,
        "duration": 4.96,
        "text": "directory"
      },
      {
        "start": 5652.96,
        "duration": 5.759,
        "text": "uh scala main blah blah blah"
      },
      {
        "start": 5656.8,
        "duration": 3.2,
        "text": "this is this is just funny business in"
      },
      {
        "start": 5658.719,
        "duration": 5.361,
        "text": "spark and scala but"
      },
      {
        "start": 5660.0,
        "duration": 5.76,
        "text": "um leaps by tag is a very simple program"
      },
      {
        "start": 5664.08,
        "duration": 3.44,
        "text": "um yeah we need all this stuff to kind"
      },
      {
        "start": 5665.76,
        "duration": 5.52,
        "text": "of connect to cassandra but"
      },
      {
        "start": 5667.52,
        "duration": 7.84,
        "text": "what is it doing it's connecting"
      },
      {
        "start": 5671.28,
        "duration": 5.2,
        "text": "to kafka and it's making a data frame"
      },
      {
        "start": 5675.36,
        "duration": 3.44,
        "text": "remember when we talked about data"
      },
      {
        "start": 5676.48,
        "duration": 5.04,
        "text": "frames it's like a database in memory"
      },
      {
        "start": 5678.8,
        "duration": 4.0,
        "text": "and we're using structured streaming so"
      },
      {
        "start": 5681.52,
        "duration": 6.56,
        "text": "what's really happening"
      },
      {
        "start": 5682.8,
        "duration": 8.399,
        "text": "is we're populating this data frame"
      },
      {
        "start": 5688.08,
        "duration": 5.52,
        "text": "with the data from the stream"
      },
      {
        "start": 5691.199,
        "duration": 4.401,
        "text": "and then when it's in there we can then"
      },
      {
        "start": 5693.6,
        "duration": 3.599,
        "text": "select data from"
      },
      {
        "start": 5695.6,
        "duration": 3.36,
        "text": "that data frame so what this is doing is"
      },
      {
        "start": 5697.199,
        "duration": 4.561,
        "text": "saying select data"
      },
      {
        "start": 5698.96,
        "duration": 3.199,
        "text": "tags as tag data.title this is sql by"
      },
      {
        "start": 5701.76,
        "duration": 3.6,
        "text": "the way"
      },
      {
        "start": 5702.159,
        "duration": 5.761,
        "text": "right and um"
      },
      {
        "start": 5705.36,
        "duration": 3.12,
        "text": "we want to explode this into kind of our"
      },
      {
        "start": 5707.92,
        "duration": 4.48,
        "text": "own"
      },
      {
        "start": 5708.48,
        "duration": 7.6,
        "text": "map and it gets this data"
      },
      {
        "start": 5712.4,
        "duration": 5.6,
        "text": "and once we're ready this data frame"
      },
      {
        "start": 5716.08,
        "duration": 4.559,
        "text": "which came from this one we can"
      },
      {
        "start": 5718.0,
        "duration": 5.84,
        "text": "basically say write that data"
      },
      {
        "start": 5720.639,
        "duration": 4.801,
        "text": "back to a table into this table into the"
      },
      {
        "start": 5723.84,
        "duration": 4.319,
        "text": "cassandra format"
      },
      {
        "start": 5725.44,
        "duration": 4.239,
        "text": "that's it we populated this we will"
      },
      {
        "start": 5728.159,
        "duration": 3.841,
        "text": "populate this uh"
      },
      {
        "start": 5729.679,
        "duration": 3.281,
        "text": "topic again this code is going to read"
      },
      {
        "start": 5732.0,
        "duration": 4.239,
        "text": "it"
      },
      {
        "start": 5732.96,
        "duration": 4.96,
        "text": "and transform it in flight into the"
      },
      {
        "start": 5736.239,
        "duration": 4.0,
        "text": "structure that we want"
      },
      {
        "start": 5737.92,
        "duration": 3.68,
        "text": "in our table in our cassandra table and"
      },
      {
        "start": 5740.239,
        "duration": 5.361,
        "text": "this code will write it"
      },
      {
        "start": 5741.6,
        "duration": 6.4,
        "text": "okay so"
      },
      {
        "start": 5745.6,
        "duration": 2.4,
        "text": "copy"
      },
      {
        "start": 5748.719,
        "duration": 3.681,
        "text": "and paste"
      },
      {
        "start": 5753.36,
        "duration": 5.279,
        "text": "oh uh i need to be in a different"
      },
      {
        "start": 5756.159,
        "duration": 2.48,
        "text": "directory"
      },
      {
        "start": 5765.119,
        "duration": 3.721,
        "text": "because i'm running spark submit right"
      },
      {
        "start": 5766.8,
        "duration": 5.04,
        "text": "so i need to make sure i'm in the spark"
      },
      {
        "start": 5768.84,
        "duration": 3.0,
        "text": "folder"
      },
      {
        "start": 5778.159,
        "duration": 3.761,
        "text": "so when a spark job works sorry when a"
      },
      {
        "start": 5780.639,
        "duration": 4.48,
        "text": "spark"
      },
      {
        "start": 5781.92,
        "duration": 7.279,
        "text": "job is running it will also"
      },
      {
        "start": 5785.119,
        "duration": 7.281,
        "text": "have its own ui which kind of tells you"
      },
      {
        "start": 5789.199,
        "duration": 6.161,
        "text": "what's happening right so this job"
      },
      {
        "start": 5792.4,
        "duration": 3.68,
        "text": "basically is running it's a stream job"
      },
      {
        "start": 5795.36,
        "duration": 4.96,
        "text": "okay"
      },
      {
        "start": 5796.08,
        "duration": 6.559,
        "text": "and um basically like i go to the master"
      },
      {
        "start": 5800.32,
        "duration": 4.319,
        "text": "i can then go to the worker but i have"
      },
      {
        "start": 5802.639,
        "duration": 2.401,
        "text": "to use the worker url that uh that i"
      },
      {
        "start": 5804.639,
        "duration": 2.48,
        "text": "have"
      },
      {
        "start": 5805.04,
        "duration": 3.679,
        "text": "from a git pod because this is using"
      },
      {
        "start": 5807.119,
        "duration": 4.961,
        "text": "kind of an internal reference"
      },
      {
        "start": 5808.719,
        "duration": 6.321,
        "text": "and then on that worker i can see"
      },
      {
        "start": 5812.08,
        "duration": 4.0,
        "text": "essentially what is happening right so"
      },
      {
        "start": 5815.04,
        "duration": 2.56,
        "text": "up until now"
      },
      {
        "start": 5816.08,
        "duration": 3.599,
        "text": "we haven't really created new messages"
      },
      {
        "start": 5817.6,
        "duration": 4.4,
        "text": "so our job is running"
      },
      {
        "start": 5819.679,
        "duration": 5.44,
        "text": "okay it's kind of doing its thing we"
      },
      {
        "start": 5822.0,
        "duration": 6.96,
        "text": "need to give it some new messages"
      },
      {
        "start": 5825.119,
        "duration": 3.841,
        "text": "and we can do that"
      },
      {
        "start": 5830.08,
        "duration": 4.48,
        "text": "back to my handy git repo"
      },
      {
        "start": 5836.32,
        "duration": 5.52,
        "text": "and send some more messages"
      },
      {
        "start": 5851.76,
        "duration": 5.6,
        "text": "so my my handy-dandy python importer um"
      },
      {
        "start": 5855.199,
        "duration": 3.601,
        "text": "is just populating the topic in the"
      },
      {
        "start": 5857.36,
        "duration": 4.96,
        "text": "meantime"
      },
      {
        "start": 5858.8,
        "duration": 7.04,
        "text": "my spark job picked up these messages"
      },
      {
        "start": 5862.32,
        "duration": 4.48,
        "text": "right and it's transforming it and it's"
      },
      {
        "start": 5865.84,
        "duration": 5.839,
        "text": "writing to"
      },
      {
        "start": 5866.8,
        "duration": 4.879,
        "text": "that table and if i refresh my jobs here"
      },
      {
        "start": 5872.4,
        "duration": 4.64,
        "text": "so you can see it did some stuff does it"
      },
      {
        "start": 5875.28,
        "duration": 4.879,
        "text": "mean the same data is read"
      },
      {
        "start": 5877.04,
        "duration": 5.679,
        "text": "twice one from the connect and one with"
      },
      {
        "start": 5880.159,
        "duration": 4.241,
        "text": "spark and written in another table is it"
      },
      {
        "start": 5882.719,
        "duration": 3.92,
        "text": "the same data that you"
      },
      {
        "start": 5884.4,
        "duration": 4.239,
        "text": "process in both cases i'm using the same"
      },
      {
        "start": 5886.639,
        "duration": 4.321,
        "text": "data and actually it's a good point"
      },
      {
        "start": 5888.639,
        "duration": 3.921,
        "text": "uh cedric that if i wanted to i could"
      },
      {
        "start": 5890.96,
        "duration": 5.44,
        "text": "have just set the offset"
      },
      {
        "start": 5892.56,
        "duration": 5.84,
        "text": "and replay the same data yeah"
      },
      {
        "start": 5896.4,
        "duration": 3.52,
        "text": "but it's right now it's effectively the"
      },
      {
        "start": 5898.4,
        "duration": 3.279,
        "text": "same data right if we were have if we"
      },
      {
        "start": 5899.92,
        "duration": 2.719,
        "text": "had the spark job running at the same"
      },
      {
        "start": 5901.679,
        "duration": 4.321,
        "text": "time"
      },
      {
        "start": 5902.639,
        "duration": 4.56,
        "text": "as the uh cockpit connect both tables"
      },
      {
        "start": 5906.0,
        "duration": 3.04,
        "text": "would have been populated"
      },
      {
        "start": 5907.199,
        "duration": 4.401,
        "text": "because kafka connect is populating one"
      },
      {
        "start": 5909.04,
        "duration": 3.84,
        "text": "table and"
      },
      {
        "start": 5911.6,
        "duration": 4.88,
        "text": "this spark job is populating another"
      },
      {
        "start": 5912.88,
        "duration": 3.6,
        "text": "table off of the same topic essentially"
      },
      {
        "start": 5917.76,
        "duration": 3.76,
        "text": "so we have the spark job it shows it's"
      },
      {
        "start": 5920.0,
        "duration": 6.639,
        "text": "running let's take a look"
      },
      {
        "start": 5921.52,
        "duration": 5.119,
        "text": "at our uh data stack studio"
      },
      {
        "start": 5926.8,
        "duration": 3.6,
        "text": "and what i want to do is see if there's"
      },
      {
        "start": 5928.56,
        "duration": 4.159,
        "text": "any data in here so"
      },
      {
        "start": 5930.4,
        "duration": 3.2,
        "text": "um well you saw me delete the table so"
      },
      {
        "start": 5932.719,
        "duration": 4.241,
        "text": "if i do a"
      },
      {
        "start": 5933.6,
        "duration": 5.76,
        "text": "query yeah hey sure it found some data"
      },
      {
        "start": 5936.96,
        "duration": 3.199,
        "text": "right there's something in there uh"
      },
      {
        "start": 5939.36,
        "duration": 3.6,
        "text": "awesome"
      },
      {
        "start": 5940.159,
        "duration": 5.601,
        "text": "um and if i want to see the actual data"
      },
      {
        "start": 5942.96,
        "duration": 2.8,
        "text": "this is what it looks like"
      },
      {
        "start": 5947.84,
        "duration": 5.2,
        "text": "right given this particular tag here are"
      },
      {
        "start": 5950.4,
        "duration": 5.759,
        "text": "the 43 results"
      },
      {
        "start": 5953.04,
        "duration": 6.159,
        "text": "okay now this is a much"
      },
      {
        "start": 5956.159,
        "duration": 6.721,
        "text": "faster query than to say"
      },
      {
        "start": 5959.199,
        "duration": 6.561,
        "text": "you know select star from the main table"
      },
      {
        "start": 5962.88,
        "duration": 3.839,
        "text": "where tag is equal to whatever um would"
      },
      {
        "start": 5965.76,
        "duration": 2.16,
        "text": "allow filtering"
      },
      {
        "start": 5966.719,
        "duration": 3.201,
        "text": "like we should never do a lot of"
      },
      {
        "start": 5967.92,
        "duration": 3.92,
        "text": "filtering right"
      },
      {
        "start": 5969.92,
        "duration": 3.12,
        "text": "and our goal with this table was to have"
      },
      {
        "start": 5971.84,
        "duration": 4.16,
        "text": "a fast tag"
      },
      {
        "start": 5973.04,
        "duration": 3.84,
        "text": "article look up and then lastly as we"
      },
      {
        "start": 5976.0,
        "duration": 2.719,
        "text": "come to a close"
      },
      {
        "start": 5976.88,
        "duration": 5.68,
        "text": "uh we have another job that we want to"
      },
      {
        "start": 5978.719,
        "duration": 9.361,
        "text": "run to populate"
      },
      {
        "start": 5982.56,
        "duration": 5.52,
        "text": "the the tags table"
      },
      {
        "start": 5988.96,
        "duration": 6.88,
        "text": "i'm going to go ahead and stop"
      },
      {
        "start": 6002.639,
        "duration": 2.401,
        "text": "and"
      },
      {
        "start": 6005.92,
        "duration": 3.84,
        "text": "my last job that i'm going to run is we"
      },
      {
        "start": 6008.88,
        "duration": 2.56,
        "text": "just verified this"
      },
      {
        "start": 6009.76,
        "duration": 3.439,
        "text": "right we've got the tags we're in the"
      },
      {
        "start": 6011.44,
        "duration": 3.6,
        "text": "second spark job"
      },
      {
        "start": 6013.199,
        "duration": 3.281,
        "text": "and so similarly with the second spark"
      },
      {
        "start": 6015.04,
        "duration": 4.88,
        "text": "job"
      },
      {
        "start": 6016.48,
        "duration": 3.44,
        "text": "i'm just going to quickly examine it"
      },
      {
        "start": 6020.08,
        "duration": 3.76,
        "text": "make sure that i'm using the right"
      },
      {
        "start": 6024.96,
        "duration": 2.56,
        "text": "zip file"
      },
      {
        "start": 6031.679,
        "duration": 4.241,
        "text": "um this spark streaming job is being"
      },
      {
        "start": 6034.48,
        "duration": 2.639,
        "text": "stubborn but i'll show you a way to kill"
      },
      {
        "start": 6035.92,
        "duration": 6.48,
        "text": "the job"
      },
      {
        "start": 6037.119,
        "duration": 7.6,
        "text": "um with the ui with the spark ui"
      },
      {
        "start": 6042.4,
        "duration": 3.2,
        "text": "we didn't talk at length about the spark"
      },
      {
        "start": 6044.719,
        "duration": 2.801,
        "text": "ui"
      },
      {
        "start": 6045.6,
        "duration": 3.92,
        "text": "but the spark ui is an excellent place"
      },
      {
        "start": 6047.52,
        "duration": 4.56,
        "text": "to start to see"
      },
      {
        "start": 6049.52,
        "duration": 3.84,
        "text": "how your spark job is performing what"
      },
      {
        "start": 6052.08,
        "duration": 4.48,
        "text": "parts of the spark job"
      },
      {
        "start": 6053.36,
        "duration": 6.64,
        "text": "are taking too long um to basically"
      },
      {
        "start": 6056.56,
        "duration": 6.72,
        "text": "better um break up the work right"
      },
      {
        "start": 6060.0,
        "duration": 3.28,
        "text": "um so"
      },
      {
        "start": 6063.36,
        "duration": 5.2,
        "text": "this is the let's go back to spark"
      },
      {
        "start": 6066.159,
        "duration": 2.401,
        "text": "master"
      },
      {
        "start": 6072.719,
        "duration": 7.121,
        "text": "i'm gonna actually go to eight"
      },
      {
        "start": 6090.84,
        "duration": 3.0,
        "text": "sorry"
      },
      {
        "start": 6099.44,
        "duration": 8.4,
        "text": "all right so this is my spark worker and"
      },
      {
        "start": 6102.88,
        "duration": 4.96,
        "text": "i'm going to go back to my spark master"
      },
      {
        "start": 6108.08,
        "duration": 6.8,
        "text": "and you know looks like"
      },
      {
        "start": 6111.679,
        "duration": 5.601,
        "text": "this application finished right it did"
      },
      {
        "start": 6114.88,
        "duration": 2.4,
        "text": "its job"
      },
      {
        "start": 6118.84,
        "duration": 5.319,
        "text": "but still thinks that"
      },
      {
        "start": 6120.88,
        "duration": 3.279,
        "text": "it's it's doing something"
      },
      {
        "start": 6124.239,
        "duration": 8.081,
        "text": "um in kafka in i cannot say kafka hq but"
      },
      {
        "start": 6128.639,
        "duration": 6.801,
        "text": "ak hq so you can brought the topic"
      },
      {
        "start": 6132.32,
        "duration": 3.76,
        "text": "can you see uh the consumer and the"
      },
      {
        "start": 6135.44,
        "duration": 2.799,
        "text": "topic"
      },
      {
        "start": 6136.08,
        "duration": 3.28,
        "text": "the the offset where they are just to"
      },
      {
        "start": 6138.239,
        "duration": 4.241,
        "text": "see if they may"
      },
      {
        "start": 6139.36,
        "duration": 4.56,
        "text": "have consumed or not yeah actually it"
      },
      {
        "start": 6142.48,
        "duration": 3.199,
        "text": "shows you the offset"
      },
      {
        "start": 6143.92,
        "duration": 3.52,
        "text": "okay uh and shows you which consumer"
      },
      {
        "start": 6145.679,
        "duration": 3.841,
        "text": "groups are attached to it"
      },
      {
        "start": 6147.44,
        "duration": 3.759,
        "text": "because it registered that registers"
      },
      {
        "start": 6149.52,
        "duration": 4.24,
        "text": "that so it's going to it's going to be"
      },
      {
        "start": 6151.199,
        "duration": 3.761,
        "text": "a second but i'm going to run the second"
      },
      {
        "start": 6153.76,
        "duration": 4.439,
        "text": "spark job"
      },
      {
        "start": 6154.96,
        "duration": 3.239,
        "text": "[Music]"
      },
      {
        "start": 6158.8,
        "duration": 5.04,
        "text": "going to populate the second table"
      },
      {
        "start": 6166.4,
        "duration": 3.6,
        "text": "and i had it right here"
      },
      {
        "start": 6174.84,
        "duration": 5.08,
        "text": "yep"
      },
      {
        "start": 6176.88,
        "duration": 5.839,
        "text": "and if i go back to my sparkmaster um"
      },
      {
        "start": 6179.92,
        "duration": 2.799,
        "text": "and i refresh"
      },
      {
        "start": 6183.199,
        "duration": 4.321,
        "text": "you see that now there's a new job right"
      },
      {
        "start": 6185.28,
        "duration": 3.2,
        "text": "and that's what i was showing like if an"
      },
      {
        "start": 6187.52,
        "duration": 4.32,
        "text": "application isn't"
      },
      {
        "start": 6188.48,
        "duration": 4.96,
        "text": "dying on you you can always kill it um"
      },
      {
        "start": 6191.84,
        "duration": 3.12,
        "text": "i think i have a runaway process on the"
      },
      {
        "start": 6193.44,
        "duration": 3.759,
        "text": "other one but that's okay"
      },
      {
        "start": 6194.96,
        "duration": 4.159,
        "text": "because the mar the master is not kind"
      },
      {
        "start": 6197.199,
        "duration": 6.321,
        "text": "of dealing with it right now"
      },
      {
        "start": 6199.119,
        "duration": 7.681,
        "text": "um this job should finish pretty quickly"
      },
      {
        "start": 6203.52,
        "duration": 7.28,
        "text": "what it's doing by the way is it's"
      },
      {
        "start": 6206.8,
        "duration": 7.359,
        "text": "reading the data from cassandra and"
      },
      {
        "start": 6210.8,
        "duration": 5.919,
        "text": "it's then rewriting the data okay"
      },
      {
        "start": 6214.159,
        "duration": 4.08,
        "text": "there it goes so that's pretty good so"
      },
      {
        "start": 6216.719,
        "duration": 4.081,
        "text": "here you do have two"
      },
      {
        "start": 6218.239,
        "duration": 3.601,
        "text": "job two different job two first is was"
      },
      {
        "start": 6220.8,
        "duration": 3.439,
        "text": "spark streaming"
      },
      {
        "start": 6221.84,
        "duration": 4.08,
        "text": "reading from kafka and the second was"
      },
      {
        "start": 6224.239,
        "duration": 4.241,
        "text": "standalone spark to"
      },
      {
        "start": 6225.92,
        "duration": 4.16,
        "text": "read from read from cassandra and back"
      },
      {
        "start": 6228.48,
        "duration": 4.08,
        "text": "to casanova which is"
      },
      {
        "start": 6230.08,
        "duration": 4.88,
        "text": "too good sample code for you to you know"
      },
      {
        "start": 6232.56,
        "duration": 4.079,
        "text": "to start building spar jobs"
      },
      {
        "start": 6234.96,
        "duration": 3.36,
        "text": "absolutely and you can see that this one"
      },
      {
        "start": 6236.639,
        "duration": 4.801,
        "text": "took 34 seconds"
      },
      {
        "start": 6238.32,
        "duration": 5.44,
        "text": "um so what cedric was talking about"
      },
      {
        "start": 6241.44,
        "duration": 5.199,
        "text": "right when you do spark sql"
      },
      {
        "start": 6243.76,
        "duration": 3.6,
        "text": "you know just be ready that sometimes"
      },
      {
        "start": 6246.639,
        "duration": 2.401,
        "text": "spark"
      },
      {
        "start": 6247.36,
        "duration": 4.0,
        "text": "the spark sql is getting made into a"
      },
      {
        "start": 6249.04,
        "duration": 3.28,
        "text": "smart job and that spark job is getting"
      },
      {
        "start": 6251.36,
        "duration": 2.799,
        "text": "executed"
      },
      {
        "start": 6252.32,
        "duration": 4.08,
        "text": "um depending on how much memory and"
      },
      {
        "start": 6254.159,
        "duration": 3.841,
        "text": "resources you have it may take a while"
      },
      {
        "start": 6256.4,
        "duration": 4.64,
        "text": "right it may take a minute but it'll"
      },
      {
        "start": 6258.0,
        "duration": 4.4,
        "text": "come back it will finish the job um"
      },
      {
        "start": 6261.04,
        "duration": 4.96,
        "text": "and it's a heck of a lot better than"
      },
      {
        "start": 6262.4,
        "duration": 3.6,
        "text": "hadoop that's for damn sure"
      },
      {
        "start": 6266.48,
        "duration": 6.4,
        "text": "that's for sure for sure"
      },
      {
        "start": 6270.96,
        "duration": 3.44,
        "text": "there we go the smart streaming job also"
      },
      {
        "start": 6272.88,
        "duration": 5.68,
        "text": "uh disconnected"
      },
      {
        "start": 6274.4,
        "duration": 5.839,
        "text": "properly um the tags code which we just"
      },
      {
        "start": 6278.56,
        "duration": 4.72,
        "text": "ran the badge code"
      },
      {
        "start": 6280.239,
        "duration": 5.521,
        "text": "to show you um"
      },
      {
        "start": 6283.28,
        "duration": 4.0,
        "text": "it's a lot simpler than the leaves by"
      },
      {
        "start": 6285.76,
        "duration": 2.479,
        "text": "tag because it's actually reading from"
      },
      {
        "start": 6287.28,
        "duration": 3.2,
        "text": "cassandra"
      },
      {
        "start": 6288.239,
        "duration": 3.841,
        "text": "and saving back to cassandra so what"
      },
      {
        "start": 6290.48,
        "duration": 5.199,
        "text": "we're doing is we're saying"
      },
      {
        "start": 6292.08,
        "duration": 5.92,
        "text": "hey get all of these tags"
      },
      {
        "start": 6295.679,
        "duration": 4.401,
        "text": "from my main table right that had a"
      },
      {
        "start": 6298.0,
        "duration": 4.4,
        "text": "thousand urls"
      },
      {
        "start": 6300.08,
        "duration": 3.28,
        "text": "and i want you to make a different data"
      },
      {
        "start": 6302.4,
        "duration": 4.319,
        "text": "frame"
      },
      {
        "start": 6303.36,
        "duration": 4.56,
        "text": "basically that uh gets the tag and then"
      },
      {
        "start": 6306.719,
        "duration": 2.881,
        "text": "it gets the count"
      },
      {
        "start": 6307.92,
        "duration": 4.48,
        "text": "and i want to save that data frame back"
      },
      {
        "start": 6309.6,
        "duration": 8.079,
        "text": "to cassandra and so that table"
      },
      {
        "start": 6312.4,
        "duration": 8.08,
        "text": "gets materialized in cassandra as"
      },
      {
        "start": 6317.679,
        "duration": 2.801,
        "text": "this table here"
      },
      {
        "start": 6321.28,
        "duration": 5.12,
        "text": "and so if we do a select star from tags"
      },
      {
        "start": 6326.8,
        "duration": 3.839,
        "text": "where tag is equal to spark we'll get"
      },
      {
        "start": 6328.32,
        "duration": 3.28,
        "text": "the same thing and because this is a"
      },
      {
        "start": 6330.639,
        "duration": 3.6,
        "text": "small table"
      },
      {
        "start": 6331.6,
        "duration": 4.96,
        "text": "um you can just do select start from"
      },
      {
        "start": 6334.239,
        "duration": 2.321,
        "text": "tags"
      },
      {
        "start": 6338.88,
        "duration": 6.08,
        "text": "so it went through a thousand"
      },
      {
        "start": 6341.92,
        "duration": 4.56,
        "text": "items in cassandra it read all of that"
      },
      {
        "start": 6344.96,
        "duration": 4.48,
        "text": "data"
      },
      {
        "start": 6346.48,
        "duration": 5.199,
        "text": "right it counted them and it saved it"
      },
      {
        "start": 6349.44,
        "duration": 2.239,
        "text": "back"
      },
      {
        "start": 6351.92,
        "duration": 4.4,
        "text": "in 34 seconds pretty cool you know even"
      },
      {
        "start": 6354.8,
        "duration": 2.72,
        "text": "with the free tier you do have some"
      },
      {
        "start": 6356.32,
        "duration": 3.919,
        "text": "power"
      },
      {
        "start": 6357.52,
        "duration": 3.44,
        "text": "you have a lot of power with this um but"
      },
      {
        "start": 6360.239,
        "duration": 4.0,
        "text": "that's"
      },
      {
        "start": 6360.96,
        "duration": 6.56,
        "text": "spark you know uh in a nutshell"
      },
      {
        "start": 6364.239,
        "duration": 4.801,
        "text": "what you can do uh is talk to any system"
      },
      {
        "start": 6367.52,
        "duration": 3.44,
        "text": "and obviously you want to talk to"
      },
      {
        "start": 6369.04,
        "duration": 3.28,
        "text": "cassandra you can read from consent you"
      },
      {
        "start": 6370.96,
        "duration": 3.04,
        "text": "can write from cassandra"
      },
      {
        "start": 6372.32,
        "duration": 3.359,
        "text": "uh you can read from kafka you can write"
      },
      {
        "start": 6374.0,
        "duration": 3.76,
        "text": "your cassandra like this"
      },
      {
        "start": 6375.679,
        "duration": 4.0,
        "text": "uh this is the latest and greatest using"
      },
      {
        "start": 6377.76,
        "duration": 6.32,
        "text": "structured streaming and data frames"
      },
      {
        "start": 6379.679,
        "duration": 6.56,
        "text": "um older spark code is not this elegant"
      },
      {
        "start": 6384.08,
        "duration": 3.36,
        "text": "it is not as cool this is as close as it"
      },
      {
        "start": 6386.239,
        "duration": 3.601,
        "text": "gets to"
      },
      {
        "start": 6387.44,
        "duration": 3.679,
        "text": "select star from this table insert into"
      },
      {
        "start": 6389.84,
        "duration": 4.799,
        "text": "this other table okay"
      },
      {
        "start": 6391.119,
        "duration": 6.321,
        "text": "yeah you can do in uh sql"
      },
      {
        "start": 6394.639,
        "duration": 3.921,
        "text": "as it gets yeah so i think it's time for"
      },
      {
        "start": 6397.44,
        "duration": 4.239,
        "text": "a question i got"
      },
      {
        "start": 6398.56,
        "duration": 5.2,
        "text": "some hold from smita from a couple of"
      },
      {
        "start": 6401.679,
        "duration": 5.52,
        "text": "minutes now even hours is"
      },
      {
        "start": 6403.76,
        "duration": 5.359,
        "text": "so we pick spark streaming um"
      },
      {
        "start": 6407.199,
        "duration": 3.04,
        "text": "why not kafka stream what is the"
      },
      {
        "start": 6409.119,
        "duration": 4.56,
        "text": "difference and"
      },
      {
        "start": 6410.239,
        "duration": 6.241,
        "text": "which one should you use when perfect"
      },
      {
        "start": 6413.679,
        "duration": 4.801,
        "text": "that's a really really good question um"
      },
      {
        "start": 6416.48,
        "duration": 5.6,
        "text": "so"
      },
      {
        "start": 6418.48,
        "duration": 7.28,
        "text": "kafka streams by default"
      },
      {
        "start": 6422.08,
        "duration": 5.92,
        "text": "gives you access to all of the topics"
      },
      {
        "start": 6425.76,
        "duration": 3.84,
        "text": "and it can even show those you can kind"
      },
      {
        "start": 6428.0,
        "duration": 4.639,
        "text": "of even do a little bit of joins"
      },
      {
        "start": 6429.6,
        "duration": 3.76,
        "text": "in between tables right but your data"
      },
      {
        "start": 6432.639,
        "duration": 3.681,
        "text": "has to be"
      },
      {
        "start": 6433.36,
        "duration": 5.12,
        "text": "put into kafka first for you to be able"
      },
      {
        "start": 6436.32,
        "duration": 6.08,
        "text": "to do stuff with that data"
      },
      {
        "start": 6438.48,
        "duration": 6.639,
        "text": "right um kafka streams also assumes"
      },
      {
        "start": 6442.4,
        "duration": 3.92,
        "text": "that you're operating off of a topic and"
      },
      {
        "start": 6445.119,
        "duration": 2.0,
        "text": "you're going to do something with that"
      },
      {
        "start": 6446.32,
        "duration": 3.04,
        "text": "data"
      },
      {
        "start": 6447.119,
        "duration": 4.321,
        "text": "and yeah kafka streams you can write a"
      },
      {
        "start": 6449.36,
        "duration": 2.96,
        "text": "kafka stream's job in java or scala or"
      },
      {
        "start": 6451.44,
        "duration": 4.08,
        "text": "anything"
      },
      {
        "start": 6452.32,
        "duration": 6.64,
        "text": "um and that's it right"
      },
      {
        "start": 6455.52,
        "duration": 6.32,
        "text": "spark is a much bigger ecosystem"
      },
      {
        "start": 6458.96,
        "duration": 4.08,
        "text": "so you're not just limited to the data"
      },
      {
        "start": 6461.84,
        "duration": 2.56,
        "text": "coming from kafka"
      },
      {
        "start": 6463.04,
        "duration": 3.28,
        "text": "you could have that data coming from"
      },
      {
        "start": 6464.4,
        "duration": 3.6,
        "text": "kinesis as a structured stream"
      },
      {
        "start": 6466.32,
        "duration": 3.919,
        "text": "you could have that data coming from sql"
      },
      {
        "start": 6468.0,
        "duration": 4.96,
        "text": "server as a structured stream"
      },
      {
        "start": 6470.239,
        "duration": 3.761,
        "text": "and then that data frame that represents"
      },
      {
        "start": 6472.96,
        "duration": 4.159,
        "text": "the kafka"
      },
      {
        "start": 6474.0,
        "duration": 4.4,
        "text": "topic and that represents the the sql"
      },
      {
        "start": 6477.119,
        "duration": 2.961,
        "text": "server topic"
      },
      {
        "start": 6478.4,
        "duration": 3.2,
        "text": "you can do joins on it you can do"
      },
      {
        "start": 6480.08,
        "duration": 3.68,
        "text": "manipulations in those"
      },
      {
        "start": 6481.6,
        "duration": 4.32,
        "text": "between those data frames uh if you"
      },
      {
        "start": 6483.76,
        "duration": 5.68,
        "text": "wanted to and then you can save that to"
      },
      {
        "start": 6485.92,
        "duration": 5.04,
        "text": "to cassandra so that's one thing that"
      },
      {
        "start": 6489.44,
        "duration": 2.719,
        "text": "you can do with spark the other is"
      },
      {
        "start": 6490.96,
        "duration": 3.12,
        "text": "by the way you can also kind of do that"
      },
      {
        "start": 6492.159,
        "duration": 3.201,
        "text": "with copycat streams but you wouldn't"
      },
      {
        "start": 6494.08,
        "duration": 3.44,
        "text": "get a data frame"
      },
      {
        "start": 6495.36,
        "duration": 4.16,
        "text": "of the sql server table right right and"
      },
      {
        "start": 6497.52,
        "duration": 3.92,
        "text": "um you wouldn't necessarily get a"
      },
      {
        "start": 6499.52,
        "duration": 4.56,
        "text": "structured stream for other stuff"
      },
      {
        "start": 6501.44,
        "duration": 4.08,
        "text": "um the other thing that spark has is"
      },
      {
        "start": 6504.08,
        "duration": 3.92,
        "text": "compute"
      },
      {
        "start": 6505.52,
        "duration": 3.199,
        "text": "it can do massive amounts of data"
      },
      {
        "start": 6508.0,
        "duration": 4.56,
        "text": "crunching"
      },
      {
        "start": 6508.719,
        "duration": 6.561,
        "text": "so if your data comes in in a topic"
      },
      {
        "start": 6512.56,
        "duration": 4.32,
        "text": "you can then essentially parse that data"
      },
      {
        "start": 6515.28,
        "duration": 3.359,
        "text": "you can transform it you can enhance it"
      },
      {
        "start": 6516.88,
        "duration": 3.52,
        "text": "you can evaluate it for machine learning"
      },
      {
        "start": 6518.639,
        "duration": 4.48,
        "text": "if that process is going to need more"
      },
      {
        "start": 6520.4,
        "duration": 5.52,
        "text": "power than one computer"
      },
      {
        "start": 6523.119,
        "duration": 3.281,
        "text": "then you can use spark if that process"
      },
      {
        "start": 6525.92,
        "duration": 2.239,
        "text": "is going to"
      },
      {
        "start": 6526.4,
        "duration": 3.68,
        "text": "take more than one computer in kafka"
      },
      {
        "start": 6528.159,
        "duration": 3.121,
        "text": "streams probably not possible you have"
      },
      {
        "start": 6530.08,
        "duration": 4.32,
        "text": "to kind of break apart the work"
      },
      {
        "start": 6531.28,
        "duration": 6.24,
        "text": "differently and then finally"
      },
      {
        "start": 6534.4,
        "duration": 3.6,
        "text": "um i would say like to differentiate the"
      },
      {
        "start": 6537.52,
        "duration": 3.44,
        "text": "two"
      },
      {
        "start": 6538.0,
        "duration": 3.92,
        "text": "if you know your whole workflow is in"
      },
      {
        "start": 6540.96,
        "duration": 3.679,
        "text": "kafka"
      },
      {
        "start": 6541.92,
        "duration": 5.12,
        "text": "like every single thing you can kind of"
      },
      {
        "start": 6544.639,
        "duration": 5.281,
        "text": "do everything in kafka streams"
      },
      {
        "start": 6547.04,
        "duration": 4.4,
        "text": "only when you have to do big like batch"
      },
      {
        "start": 6549.92,
        "duration": 2.96,
        "text": "processing then you would use spark you"
      },
      {
        "start": 6551.44,
        "duration": 1.92,
        "text": "wouldn't necessarily use spark streaming"
      },
      {
        "start": 6552.88,
        "duration": 3.759,
        "text": "for that"
      },
      {
        "start": 6553.36,
        "duration": 6.0,
        "text": "if you have kafka streams go to great"
      },
      {
        "start": 6556.639,
        "duration": 2.721,
        "text": "credence world"
      },
      {
        "start": 6559.84,
        "duration": 5.44,
        "text": "yeah um i mean"
      },
      {
        "start": 6563.119,
        "duration": 5.6,
        "text": "i did a good job on swimming all the"
      },
      {
        "start": 6565.28,
        "duration": 6.64,
        "text": "question i guess"
      },
      {
        "start": 6568.719,
        "duration": 5.52,
        "text": "it was you know pretty"
      },
      {
        "start": 6571.92,
        "duration": 5.279,
        "text": "deep dive and also step by step so"
      },
      {
        "start": 6574.239,
        "duration": 4.801,
        "text": "people can follow along"
      },
      {
        "start": 6577.199,
        "duration": 3.121,
        "text": "and so we will share with you all the"
      },
      {
        "start": 6579.04,
        "duration": 2.88,
        "text": "resources"
      },
      {
        "start": 6580.32,
        "duration": 3.6,
        "text": "and you can see that you can do it on"
      },
      {
        "start": 6581.92,
        "duration": 4.16,
        "text": "your own and with gitpod and astral"
      },
      {
        "start": 6583.92,
        "duration": 5.279,
        "text": "there is nothing for you to install"
      },
      {
        "start": 6586.08,
        "duration": 6.159,
        "text": "or to pay or to provide any info"
      },
      {
        "start": 6589.199,
        "duration": 3.92,
        "text": "just watching for question uh oh we had"
      },
      {
        "start": 6592.239,
        "duration": 4.4,
        "text": "a question about"
      },
      {
        "start": 6593.119,
        "duration": 6.881,
        "text": "um spark uh would you use"
      },
      {
        "start": 6596.639,
        "duration": 6.161,
        "text": "uh scala or java you know i"
      },
      {
        "start": 6600.0,
        "duration": 4.32,
        "text": "i used to be as well a java i i'm a java"
      },
      {
        "start": 6602.8,
        "duration": 4.16,
        "text": "hardcore programmer"
      },
      {
        "start": 6604.32,
        "duration": 3.68,
        "text": "and when it comes to to spark really i'm"
      },
      {
        "start": 6606.96,
        "duration": 3.199,
        "text": "i'm stuck"
      },
      {
        "start": 6608.0,
        "duration": 3.28,
        "text": "pretty fast with the data structures"
      },
      {
        "start": 6610.159,
        "duration": 3.201,
        "text": "they manipulate"
      },
      {
        "start": 6611.28,
        "duration": 4.0,
        "text": "you don't have the same flows i don't"
      },
      {
        "start": 6613.36,
        "duration": 5.2,
        "text": "know what you think about"
      },
      {
        "start": 6615.28,
        "duration": 4.959,
        "text": "long-age war sure"
      },
      {
        "start": 6618.56,
        "duration": 4.0,
        "text": "yeah so in sparc i think the question is"
      },
      {
        "start": 6620.239,
        "duration": 5.601,
        "text": "you know which language to use um"
      },
      {
        "start": 6622.56,
        "duration": 3.599,
        "text": "yep so you know i had to have this up"
      },
      {
        "start": 6625.84,
        "duration": 2.879,
        "text": "here"
      },
      {
        "start": 6626.159,
        "duration": 4.08,
        "text": "on one of the uh slides all the"
      },
      {
        "start": 6628.719,
        "duration": 2.321,
        "text": "different languages so let me just bring"
      },
      {
        "start": 6630.239,
        "duration": 4.4,
        "text": "that up"
      },
      {
        "start": 6631.04,
        "duration": 7.52,
        "text": "um so"
      },
      {
        "start": 6634.639,
        "duration": 7.04,
        "text": "scala spark is written in scala"
      },
      {
        "start": 6638.56,
        "duration": 6.079,
        "text": "right um and"
      },
      {
        "start": 6641.679,
        "duration": 4.801,
        "text": "you know there were features in scala"
      },
      {
        "start": 6644.639,
        "duration": 4.0,
        "text": "before there were features in java"
      },
      {
        "start": 6646.48,
        "duration": 3.28,
        "text": "and they kind of eventually get parody"
      },
      {
        "start": 6648.639,
        "duration": 4.08,
        "text": "um"
      },
      {
        "start": 6649.76,
        "duration": 3.919,
        "text": "ultimately this is a company or team"
      },
      {
        "start": 6652.719,
        "duration": 4.321,
        "text": "decision"
      },
      {
        "start": 6653.679,
        "duration": 4.161,
        "text": "um because these are the two compiled"
      },
      {
        "start": 6657.04,
        "duration": 3.119,
        "text": "languages"
      },
      {
        "start": 6657.84,
        "duration": 3.359,
        "text": "well maybe i have not tested against"
      },
      {
        "start": 6660.159,
        "duration": 4.321,
        "text": "c-sharp but"
      },
      {
        "start": 6661.199,
        "duration": 6.561,
        "text": "these are two compilable smart languages"
      },
      {
        "start": 6664.48,
        "duration": 5.6,
        "text": "that can run the fastest right the"
      },
      {
        "start": 6667.76,
        "duration": 3.839,
        "text": "one edge that scala has is that you can"
      },
      {
        "start": 6670.08,
        "duration": 4.72,
        "text": "do what's called a spark"
      },
      {
        "start": 6671.599,
        "duration": 6.481,
        "text": "shell right um and"
      },
      {
        "start": 6674.8,
        "duration": 7.76,
        "text": "i can kind of like"
      },
      {
        "start": 6678.08,
        "duration": 4.48,
        "text": "start it um by"
      },
      {
        "start": 6685.44,
        "duration": 4.239,
        "text": "kind of a different deep dive but"
      },
      {
        "start": 6687.52,
        "duration": 4.48,
        "text": "basically you can start a shell"
      },
      {
        "start": 6689.679,
        "duration": 3.361,
        "text": "and you can copy and paste this scala"
      },
      {
        "start": 6692.0,
        "duration": 3.84,
        "text": "code"
      },
      {
        "start": 6693.04,
        "duration": 3.119,
        "text": "and try it out without compiling it yeah"
      },
      {
        "start": 6695.84,
        "duration": 3.359,
        "text": "cool"
      },
      {
        "start": 6696.159,
        "duration": 5.201,
        "text": "oh yeah okay it's pretty neat right"
      },
      {
        "start": 6699.199,
        "duration": 3.201,
        "text": "right so you can say do this do this do"
      },
      {
        "start": 6701.36,
        "duration": 4.72,
        "text": "this right"
      },
      {
        "start": 6702.4,
        "duration": 5.279,
        "text": "and run this and"
      },
      {
        "start": 6706.08,
        "duration": 2.96,
        "text": "run this and then run this again and run"
      },
      {
        "start": 6707.679,
        "duration": 2.801,
        "text": "this again and so you can try out a"
      },
      {
        "start": 6709.04,
        "duration": 4.32,
        "text": "bunch of stuff"
      },
      {
        "start": 6710.48,
        "duration": 4.719,
        "text": "in real time in in a re-evaluate print"
      },
      {
        "start": 6713.36,
        "duration": 5.839,
        "text": "loop that you couldn't do with job"
      },
      {
        "start": 6715.199,
        "duration": 6.081,
        "text": "and that ability only exists in scala"
      },
      {
        "start": 6719.199,
        "duration": 3.761,
        "text": "and python to be able to do it"
      },
      {
        "start": 6721.28,
        "duration": 4.24,
        "text": "interactively"
      },
      {
        "start": 6722.96,
        "duration": 4.239,
        "text": "yes okay that's cool also you know we we"
      },
      {
        "start": 6725.52,
        "duration": 3.76,
        "text": "delivered a fat jar"
      },
      {
        "start": 6727.199,
        "duration": 3.201,
        "text": "which i find is a you know the the"
      },
      {
        "start": 6729.28,
        "duration": 4.48,
        "text": "easiest way"
      },
      {
        "start": 6730.4,
        "duration": 5.6,
        "text": "to deploy spark stuff"
      },
      {
        "start": 6733.76,
        "duration": 4.72,
        "text": "uh in a dedicated infra because it's a"
      },
      {
        "start": 6736.0,
        "duration": 5.28,
        "text": "fajr everything in the single place"
      },
      {
        "start": 6738.48,
        "duration": 3.759,
        "text": "if you are using spark hard or spark"
      },
      {
        "start": 6741.28,
        "duration": 3.839,
        "text": "python"
      },
      {
        "start": 6742.239,
        "duration": 4.641,
        "text": "it's more difficult to to package and"
      },
      {
        "start": 6745.119,
        "duration": 3.681,
        "text": "deploy you can do the same but when it"
      },
      {
        "start": 6746.88,
        "duration": 3.68,
        "text": "comes to putting that in production i"
      },
      {
        "start": 6748.8,
        "duration": 4.56,
        "text": "felt it's a bit more difficult"
      },
      {
        "start": 6750.56,
        "duration": 3.44,
        "text": "the ci cd is not as mature as the one"
      },
      {
        "start": 6753.36,
        "duration": 4.08,
        "text": "for the"
      },
      {
        "start": 6754.0,
        "duration": 6.48,
        "text": "javascale part yeah um"
      },
      {
        "start": 6757.44,
        "duration": 6.32,
        "text": "absolutely what i find is the main"
      },
      {
        "start": 6760.48,
        "duration": 4.08,
        "text": "workflow is that folks will"
      },
      {
        "start": 6763.76,
        "duration": 2.08,
        "text": "there's people from different"
      },
      {
        "start": 6764.56,
        "duration": 2.8,
        "text": "backgrounds that generally will work on"
      },
      {
        "start": 6765.84,
        "duration": 4.399,
        "text": "an analytics platform"
      },
      {
        "start": 6767.36,
        "duration": 4.56,
        "text": "so the data scientists will have r or"
      },
      {
        "start": 6770.239,
        "duration": 3.681,
        "text": "python on jupiter"
      },
      {
        "start": 6771.92,
        "duration": 3.92,
        "text": "you know the jupiter hub the web-based"
      },
      {
        "start": 6773.92,
        "duration": 2.319,
        "text": "notebook they'll try different things"
      },
      {
        "start": 6775.84,
        "duration": 2.56,
        "text": "out"
      },
      {
        "start": 6776.239,
        "duration": 4.161,
        "text": "then when they're happy with something"
      },
      {
        "start": 6778.4,
        "duration": 4.64,
        "text": "they will try spark python"
      },
      {
        "start": 6780.4,
        "duration": 3.92,
        "text": "and then when they're really happy with"
      },
      {
        "start": 6783.04,
        "duration": 2.559,
        "text": "it it needs to be faster they'll tell"
      },
      {
        "start": 6784.32,
        "duration": 2.0,
        "text": "the data engineers to then make it in"
      },
      {
        "start": 6785.599,
        "duration": 3.841,
        "text": "scala"
      },
      {
        "start": 6786.32,
        "duration": 5.2,
        "text": "in order to make it in java but the same"
      },
      {
        "start": 6789.44,
        "duration": 3.679,
        "text": "platform can support all of this"
      },
      {
        "start": 6791.52,
        "duration": 3.199,
        "text": "right the same data sets the same"
      },
      {
        "start": 6793.119,
        "duration": 3.841,
        "text": "general apis"
      },
      {
        "start": 6794.719,
        "duration": 4.641,
        "text": "um you just have to change the syntax"
      },
      {
        "start": 6796.96,
        "duration": 2.4,
        "text": "every now"
      },
      {
        "start": 6799.52,
        "duration": 3.599,
        "text": "thanks and as always don't forget to"
      },
      {
        "start": 6801.599,
        "duration": 3.6,
        "text": "click that subscribe button"
      },
      {
        "start": 6803.119,
        "duration": 3.281,
        "text": "and ring that bell to get notifications"
      },
      {
        "start": 6805.199,
        "duration": 15.601,
        "text": "for all of our future"
      },
      {
        "start": 6806.4,
        "duration": 28.33,
        "text": "upcoming workshops"
      },
      {
        "start": 6820.8,
        "duration": 24.179,
        "text": "on the same page"
      },
      {
        "start": 6834.73,
        "duration": 10.249,
        "text": "[Music]"
      },
      {
        "start": 6846.84,
        "duration": 37.2,
        "text": "me"
      },
      {
        "start": 6848.42,
        "duration": 35.62,
        "text": "[Music]"
      },
      {
        "start": 6886.0,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T21:26:13.354712+00:00"
}