{
  "video_id": "2XQjapiYFWQ",
  "title": "DS210.04 Cassandra-stress | Operations with Apache Cassandra",
  "description": "#DataStaxAcademy #DS210\nDS210.04 CASSANDRA-STRESS\nCassandra-stress is great for stress testing your cluster for benchmarking or for load testing. In this unit, we will be showing you use cases for this nifty tool.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-11T08:53:14Z",
  "thumbnail": "https://i.ytimg.com/vi/2XQjapiYFWQ/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax",
    "tutorial",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=2XQjapiYFWQ",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] okay what's next let's talk about stress testing your cluster for benchmarking or for load testing no need to stress about it we have a tool cassandra stress see what i did there what is cassandra stress weren't you listening i just told you it's a tool used for benchmarking or load testing your cluster and can simulate a user-defined load cassandra stress can be used to do the following things you can check out your schema performance figure out how your database will scale optimize your data model and figure out your capacity in a production environment so let me sum up cassandra stress is a tool that will help you try out your database before you switch it all over to production all right let's talk about the cassandra stress configuration there's going to be a special yaml file the cassandra stress yaml file that you'll use to do this configuration you can define your schema you can specify a compaction strategy or create a characteristic workload this yaml file is broken up into a few pieces schema description which defines the key space column descriptions which outline how to create the simulated data batch descriptions which define the data insertion pattern and query descriptions which define the possible queries you can run in your test we will cover each of these in a little more detail in the upcoming slides stay tuned this first section we're going to talk about will define the key space in tables if the schema already exists it just deals with those key space and tables if the schema doesn't exist this test will go ahead and create the schema let's take a look at a real example the top section here names the key space and then uses standard cql to create the key space with the replication strategy the lower part here are the cql table definitions hopefully you've already seen some cql so you don't need me to read you this slide next the yaml file can help with column definition this allows us to define how we will generate data for each column the data generated is contrived but it is created in such a way to simulate the patterns and frequency of your data these generated values can follow standard distributions like normal or gaussian or others parameters include the following the data size which is how many characters are in the data value value population which is how often values reoccur and finally cluster distribution which is the number of values for the column appearing in a partition all right i won't insult you by reading you these bullets but take a look at the possible distributions supported in cassandra stress these will allow you to model data that closely matches your real environment and data sets all right now let's see it in action let's take a look at your fancy yaml file here's an example of where you specify your column definitions and apply a different distribution per column should you need to or want to another section in the yaml describes batch configuration this is where you would configure the batch type the distribution ratio and partition distribution which is the number of partitions to update per batch okay now back to the yaml file we seem to spend a lot of time in here don't we well trust me it's easier than i'm making it seem here is where you will configure the cassandra stress batch parameters another cool thing you can do is define the queries you want to run in your cassandra stress test by defining them under the query section in the yaml file the fields parameter defines if the bind variables should be from the same row or across all the rows in the partition okay back to the yaml file i swear this is the last time well at least for this module this is where you can specify the query or queries in cql that will be executed for this test let's run an actual insert test with cassandra stress on the command line type the following code okay this test is going to start with four threads and increase them until an upper limit is hit inserts are done using native transport for example cql it's also going to use prepared statements to test the queries we're going to use the yaml file where these queries are defined in this case it's called blogpost.yaml parameters to these commands are passed on the command line oh look you can combine both inserts and queries in the same command in this example we are sending three queries for every one insert there are two single post queries and one timeline query you can mix and match whatever number of inserts and queries you want to suit your needs okay so enough of hearing me talk why don't you get your hands dirty and let's work through an exercise",
    "segments": [
      {
        "start": 1.43,
        "duration": 5.33,
        "text": "[Music]"
      },
      {
        "start": 7.12,
        "duration": 2.559,
        "text": "okay what's next"
      },
      {
        "start": 8.24,
        "duration": 3.6,
        "text": "let's talk about stress testing your"
      },
      {
        "start": 9.679,
        "duration": 2.721,
        "text": "cluster for benchmarking or for load"
      },
      {
        "start": 11.84,
        "duration": 2.24,
        "text": "testing"
      },
      {
        "start": 12.4,
        "duration": 4.16,
        "text": "no need to stress about it we have a"
      },
      {
        "start": 14.08,
        "duration": 3.199,
        "text": "tool cassandra stress see what i did"
      },
      {
        "start": 16.56,
        "duration": 2.719,
        "text": "there"
      },
      {
        "start": 17.279,
        "duration": 3.441,
        "text": "what is cassandra stress weren't you"
      },
      {
        "start": 19.279,
        "duration": 3.681,
        "text": "listening i just told you"
      },
      {
        "start": 20.72,
        "duration": 3.68,
        "text": "it's a tool used for benchmarking or"
      },
      {
        "start": 22.96,
        "duration": 4.0,
        "text": "load testing your cluster"
      },
      {
        "start": 24.4,
        "duration": 4.08,
        "text": "and can simulate a user-defined load"
      },
      {
        "start": 26.96,
        "duration": 2.8,
        "text": "cassandra stress can be used to do the"
      },
      {
        "start": 28.48,
        "duration": 2.32,
        "text": "following things"
      },
      {
        "start": 29.76,
        "duration": 3.2,
        "text": "you can check out your schema"
      },
      {
        "start": 30.8,
        "duration": 3.2,
        "text": "performance figure out how your database"
      },
      {
        "start": 32.96,
        "duration": 3.2,
        "text": "will scale"
      },
      {
        "start": 34.0,
        "duration": 3.36,
        "text": "optimize your data model and figure out"
      },
      {
        "start": 36.16,
        "duration": 2.16,
        "text": "your capacity in a production"
      },
      {
        "start": 37.36,
        "duration": 3.359,
        "text": "environment"
      },
      {
        "start": 38.32,
        "duration": 3.759,
        "text": "so let me sum up cassandra stress is a"
      },
      {
        "start": 40.719,
        "duration": 2.0,
        "text": "tool that will help you try out your"
      },
      {
        "start": 42.079,
        "duration": 1.921,
        "text": "database"
      },
      {
        "start": 42.719,
        "duration": 3.281,
        "text": "before you switch it all over to"
      },
      {
        "start": 44.0,
        "duration": 3.84,
        "text": "production all right let's talk about"
      },
      {
        "start": 46.0,
        "duration": 3.6,
        "text": "the cassandra stress configuration"
      },
      {
        "start": 47.84,
        "duration": 3.44,
        "text": "there's going to be a special yaml file"
      },
      {
        "start": 49.6,
        "duration": 2.479,
        "text": "the cassandra stress yaml file that"
      },
      {
        "start": 51.28,
        "duration": 3.36,
        "text": "you'll use"
      },
      {
        "start": 52.079,
        "duration": 3.601,
        "text": "to do this configuration you can define"
      },
      {
        "start": 54.64,
        "duration": 3.28,
        "text": "your schema"
      },
      {
        "start": 55.68,
        "duration": 4.32,
        "text": "you can specify a compaction strategy or"
      },
      {
        "start": 57.92,
        "duration": 4.319,
        "text": "create a characteristic workload"
      },
      {
        "start": 60.0,
        "duration": 3.199,
        "text": "this yaml file is broken up into a few"
      },
      {
        "start": 62.239,
        "duration": 3.121,
        "text": "pieces"
      },
      {
        "start": 63.199,
        "duration": 4.161,
        "text": "schema description which defines the key"
      },
      {
        "start": 65.36,
        "duration": 3.439,
        "text": "space column descriptions"
      },
      {
        "start": 67.36,
        "duration": 3.68,
        "text": "which outline how to create the"
      },
      {
        "start": 68.799,
        "duration": 4.481,
        "text": "simulated data batch descriptions"
      },
      {
        "start": 71.04,
        "duration": 3.68,
        "text": "which define the data insertion pattern"
      },
      {
        "start": 73.28,
        "duration": 3.04,
        "text": "and query descriptions"
      },
      {
        "start": 74.72,
        "duration": 3.52,
        "text": "which define the possible queries you"
      },
      {
        "start": 76.32,
        "duration": 3.439,
        "text": "can run in your test"
      },
      {
        "start": 78.24,
        "duration": 3.519,
        "text": "we will cover each of these in a little"
      },
      {
        "start": 79.759,
        "duration": 4.4,
        "text": "more detail in the upcoming slides"
      },
      {
        "start": 81.759,
        "duration": 3.68,
        "text": "stay tuned this first section we're"
      },
      {
        "start": 84.159,
        "duration": 2.64,
        "text": "going to talk about will define the key"
      },
      {
        "start": 85.439,
        "duration": 3.36,
        "text": "space in tables"
      },
      {
        "start": 86.799,
        "duration": 3.921,
        "text": "if the schema already exists it just"
      },
      {
        "start": 88.799,
        "duration": 4.241,
        "text": "deals with those key space and tables"
      },
      {
        "start": 90.72,
        "duration": 4.48,
        "text": "if the schema doesn't exist this test"
      },
      {
        "start": 93.04,
        "duration": 4.32,
        "text": "will go ahead and create the schema"
      },
      {
        "start": 95.2,
        "duration": 3.12,
        "text": "let's take a look at a real example the"
      },
      {
        "start": 97.36,
        "duration": 2.64,
        "text": "top section here"
      },
      {
        "start": 98.32,
        "duration": 3.92,
        "text": "names the key space and then uses"
      },
      {
        "start": 100.0,
        "duration": 4.32,
        "text": "standard cql to create the key space"
      },
      {
        "start": 102.24,
        "duration": 4.159,
        "text": "with the replication strategy"
      },
      {
        "start": 104.32,
        "duration": 3.6,
        "text": "the lower part here are the cql table"
      },
      {
        "start": 106.399,
        "duration": 3.841,
        "text": "definitions"
      },
      {
        "start": 107.92,
        "duration": 4.0,
        "text": "hopefully you've already seen some cql"
      },
      {
        "start": 110.24,
        "duration": 2.8,
        "text": "so you don't need me to read you this"
      },
      {
        "start": 111.92,
        "duration": 2.96,
        "text": "slide"
      },
      {
        "start": 113.04,
        "duration": 4.32,
        "text": "next the yaml file can help with column"
      },
      {
        "start": 114.88,
        "duration": 4.96,
        "text": "definition this allows us to define how"
      },
      {
        "start": 117.36,
        "duration": 4.64,
        "text": "we will generate data for each column"
      },
      {
        "start": 119.84,
        "duration": 4.0,
        "text": "the data generated is contrived but it"
      },
      {
        "start": 122.0,
        "duration": 4.399,
        "text": "is created in such a way to simulate the"
      },
      {
        "start": 123.84,
        "duration": 4.32,
        "text": "patterns and frequency of your data"
      },
      {
        "start": 126.399,
        "duration": 3.84,
        "text": "these generated values can follow"
      },
      {
        "start": 128.16,
        "duration": 3.92,
        "text": "standard distributions like normal or"
      },
      {
        "start": 130.239,
        "duration": 3.921,
        "text": "gaussian or others"
      },
      {
        "start": 132.08,
        "duration": 4.08,
        "text": "parameters include the following the"
      },
      {
        "start": 134.16,
        "duration": 3.52,
        "text": "data size which is how many characters"
      },
      {
        "start": 136.16,
        "duration": 3.84,
        "text": "are in the data value"
      },
      {
        "start": 137.68,
        "duration": 3.919,
        "text": "value population which is how often"
      },
      {
        "start": 140.0,
        "duration": 4.16,
        "text": "values reoccur"
      },
      {
        "start": 141.599,
        "duration": 4.321,
        "text": "and finally cluster distribution which"
      },
      {
        "start": 144.16,
        "duration": 4.0,
        "text": "is the number of values for the column"
      },
      {
        "start": 145.92,
        "duration": 4.24,
        "text": "appearing in a partition"
      },
      {
        "start": 148.16,
        "duration": 3.12,
        "text": "all right i won't insult you by reading"
      },
      {
        "start": 150.16,
        "duration": 2.56,
        "text": "you these bullets"
      },
      {
        "start": 151.28,
        "duration": 3.44,
        "text": "but take a look at the possible"
      },
      {
        "start": 152.72,
        "duration": 2.799,
        "text": "distributions supported in cassandra"
      },
      {
        "start": 154.72,
        "duration": 2.879,
        "text": "stress"
      },
      {
        "start": 155.519,
        "duration": 4.241,
        "text": "these will allow you to model data that"
      },
      {
        "start": 157.599,
        "duration": 4.321,
        "text": "closely matches your real environment"
      },
      {
        "start": 159.76,
        "duration": 4.24,
        "text": "and data sets"
      },
      {
        "start": 161.92,
        "duration": 3.92,
        "text": "all right now let's see it in action"
      },
      {
        "start": 164.0,
        "duration": 2.239,
        "text": "let's take a look at your fancy yaml"
      },
      {
        "start": 165.84,
        "duration": 2.32,
        "text": "file"
      },
      {
        "start": 166.239,
        "duration": 3.841,
        "text": "here's an example of where you specify"
      },
      {
        "start": 168.16,
        "duration": 2.88,
        "text": "your column definitions and apply a"
      },
      {
        "start": 170.08,
        "duration": 4.08,
        "text": "different distribution"
      },
      {
        "start": 171.04,
        "duration": 5.12,
        "text": "per column should you need to or want to"
      },
      {
        "start": 174.16,
        "duration": 3.439,
        "text": "another section in the yaml describes"
      },
      {
        "start": 176.16,
        "duration": 2.719,
        "text": "batch configuration"
      },
      {
        "start": 177.599,
        "duration": 3.601,
        "text": "this is where you would configure the"
      },
      {
        "start": 178.879,
        "duration": 4.241,
        "text": "batch type the distribution ratio"
      },
      {
        "start": 181.2,
        "duration": 4.8,
        "text": "and partition distribution which is the"
      },
      {
        "start": 183.12,
        "duration": 5.52,
        "text": "number of partitions to update per batch"
      },
      {
        "start": 186.0,
        "duration": 4.159,
        "text": "okay now back to the yaml file we seem"
      },
      {
        "start": 188.64,
        "duration": 3.04,
        "text": "to spend a lot of time in here don't we"
      },
      {
        "start": 190.159,
        "duration": 2.8,
        "text": "well trust me it's easier than i'm"
      },
      {
        "start": 191.68,
        "duration": 3.04,
        "text": "making it seem"
      },
      {
        "start": 192.959,
        "duration": 4.321,
        "text": "here is where you will configure the"
      },
      {
        "start": 194.72,
        "duration": 4.56,
        "text": "cassandra stress batch parameters"
      },
      {
        "start": 197.28,
        "duration": 3.2,
        "text": "another cool thing you can do is define"
      },
      {
        "start": 199.28,
        "duration": 2.959,
        "text": "the queries you want to run"
      },
      {
        "start": 200.48,
        "duration": 3.92,
        "text": "in your cassandra stress test by"
      },
      {
        "start": 202.239,
        "duration": 3.681,
        "text": "defining them under the query section in"
      },
      {
        "start": 204.4,
        "duration": 4.479,
        "text": "the yaml file"
      },
      {
        "start": 205.92,
        "duration": 3.679,
        "text": "the fields parameter defines if the bind"
      },
      {
        "start": 208.879,
        "duration": 2.64,
        "text": "variables"
      },
      {
        "start": 209.599,
        "duration": 4.161,
        "text": "should be from the same row or across"
      },
      {
        "start": 211.519,
        "duration": 4.881,
        "text": "all the rows in the partition"
      },
      {
        "start": 213.76,
        "duration": 3.839,
        "text": "okay back to the yaml file i swear this"
      },
      {
        "start": 216.4,
        "duration": 3.36,
        "text": "is the last time"
      },
      {
        "start": 217.599,
        "duration": 3.841,
        "text": "well at least for this module this is"
      },
      {
        "start": 219.76,
        "duration": 4.88,
        "text": "where you can specify the query"
      },
      {
        "start": 221.44,
        "duration": 4.32,
        "text": "or queries in cql that will be executed"
      },
      {
        "start": 224.64,
        "duration": 3.28,
        "text": "for this test"
      },
      {
        "start": 225.76,
        "duration": 3.44,
        "text": "let's run an actual insert test with"
      },
      {
        "start": 227.92,
        "duration": 3.12,
        "text": "cassandra stress"
      },
      {
        "start": 229.2,
        "duration": 3.92,
        "text": "on the command line type the following"
      },
      {
        "start": 231.04,
        "duration": 3.279,
        "text": "code okay this test is going to start"
      },
      {
        "start": 233.12,
        "duration": 3.119,
        "text": "with four threads"
      },
      {
        "start": 234.319,
        "duration": 4.48,
        "text": "and increase them until an upper limit"
      },
      {
        "start": 236.239,
        "duration": 3.2,
        "text": "is hit inserts are done using native"
      },
      {
        "start": 238.799,
        "duration": 3.121,
        "text": "transport"
      },
      {
        "start": 239.439,
        "duration": 4.321,
        "text": "for example cql it's also going to use"
      },
      {
        "start": 241.92,
        "duration": 3.36,
        "text": "prepared statements"
      },
      {
        "start": 243.76,
        "duration": 3.039,
        "text": "to test the queries we're going to use"
      },
      {
        "start": 245.28,
        "duration": 2.319,
        "text": "the yaml file where these queries are"
      },
      {
        "start": 246.799,
        "duration": 3.681,
        "text": "defined"
      },
      {
        "start": 247.599,
        "duration": 4.64,
        "text": "in this case it's called blogpost.yaml"
      },
      {
        "start": 250.48,
        "duration": 4.16,
        "text": "parameters to these commands are passed"
      },
      {
        "start": 252.239,
        "duration": 4.801,
        "text": "on the command line oh look"
      },
      {
        "start": 254.64,
        "duration": 3.599,
        "text": "you can combine both inserts and queries"
      },
      {
        "start": 257.04,
        "duration": 3.12,
        "text": "in the same command"
      },
      {
        "start": 258.239,
        "duration": 3.201,
        "text": "in this example we are sending three"
      },
      {
        "start": 260.16,
        "duration": 4.16,
        "text": "queries for every one"
      },
      {
        "start": 261.44,
        "duration": 4.4,
        "text": "insert there are two single post queries"
      },
      {
        "start": 264.32,
        "duration": 3.2,
        "text": "and one timeline query"
      },
      {
        "start": 265.84,
        "duration": 3.44,
        "text": "you can mix and match whatever number of"
      },
      {
        "start": 267.52,
        "duration": 3.679,
        "text": "inserts and queries you want to suit"
      },
      {
        "start": 269.28,
        "duration": 4.72,
        "text": "your needs"
      },
      {
        "start": 271.199,
        "duration": 4.321,
        "text": "okay so enough of hearing me talk why"
      },
      {
        "start": 274.0,
        "duration": 8.08,
        "text": "don't you get your hands dirty and let's"
      },
      {
        "start": 275.52,
        "duration": 6.56,
        "text": "work through an exercise"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T01:43:33.702991+00:00"
}