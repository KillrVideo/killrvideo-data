{
  "video_id": "G01H_Gix6Dg",
  "title": "DS320.05 Getting Started: Hello World | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.05 Getting Started: Hello World\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:25:40Z",
  "thumbnail": "https://i.ytimg.com/vi/G01H_Gix6Dg/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "getting_started",
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=G01H_Gix6Dg",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] welcome to ds320 analytics on cassandra with apache spark i'm tim berglund and i'm going to be walking you through how to use spark what it is and how to use it in conjunction with a datastax enterprise cluster now we're going to get started with a quick look at spark itself the basics of its api in scala and to do that we're going to use the word count example now i know you've seen the word count example in distributed computing demos before you can see here on the slide a word cloud of tags these are all tags applied to videos in this fictional video hosting business called killer video these are tags that are sized according to how frequently they're applied to videos in the data set let's look at how we might compute this in spark now the word count algorithm relies on four simple steps all right first we have to load data into spark from some external data source key principle that could be a file that could be a cassandra table we could even make a literal list at the scala repel and create a data set that way after we've loaded the data we need to parse the records in this case these tags into words that can be counted and then we need to count those words finally we're going to push that result into an external system or maybe just output it to the screen so bring data in parse it count the words spit the data out those basically are our four steps now we've got a csv file lying around for demo purposes that has these tags in them that we want to count we're going to load it with the text file method because it's a text file and that makes sense but what are we calling that text file method on you'll note that that variable there called sc sc stands for spark context and that's always available in the spark shell the spark shell is a fancy version of the scala reple so if you know scala you're perfectly at home here if you don't know scala don't worry we're going to give you what you need step by step to learn how to do this but a little bit of scala knowledge goes a long way for learning spark through these videos and frankly broadly speaking most of the examples in the spark world tend to be scala or python but scala really seems to be sort of the native language which is why we've picked it so we're going to call text file there on the sc object and that is going to return an object that records object which is an object of the resilient distributed data set type it's called an rdd alright so for now just think of that as a big collection of records we're going to dive much deeper into what rdds are in a little bit but we've loaded that text file in we've got this rdd and there we are now each record in that rdd in that data set becomes a string so it really is like we've just read the lines in and the rdd is this collection of strings that we've read in next we're going to parse those lines we're going to take the records in that rdd and operate on each record we're calling the flat map method we're going to dive deeper into what flat map means later but for now you can think of flat map as a thing that creates a collection it'll take some data item in and it'll output a collection of data items so it's taking something and breaking it into pieces and spitting those pieces out into the rdd it returns and flat map takes an anonymous function as a parameter some people call them closures some people call them code blocks but that's an anonymous function the body of that function gets applied to every element in the input rdd that input rdd remember is our csv file that we read in and we apply that function to every line in that file the return value of that function becomes a new record or set of records in the output rdd so what do we do inside that anonymous function if you look in there you'll see we split the text we treat that line of text as a line of text we split it based on the comma delimiter so that's going to create a collection of strings from that one string and notice what we're doing here we started creating an rdd from a text file then we called a transformation on that rdd to change it a little bit we actually didn't really change that first rdd we returned a new one and that's a key principle we're going to do that again by calling the map transformation on the words rdd now the map transformation again lets us have a little bit of flexibility in what we're going to do we get to write some code that's going to operate on every element or every record in the rdd we're transforming if you look at the code you'll see what we do is we take each word we're expecting each record in this rdd to be a word now we take each one of them and transform it into what scala calls a tuple that expression in parenthesis there is a tuple we're basically pairing the word with the number one and if you've seen word count examples before you've seen this game played where we tokenize words and we create a key value pair out of each word where we're pairing the word with the number one this is basically step one in counting words functionally speaking we're looking at every word that we've identified and we say i've counted this word one time now that expression that words dot map and then the code block in there mapping the words rdd onto this new rdd that's word tuples we're going to reduce that we're going to call reduce by key what that's going to do is it's going to gather up all of the records in this rdd that have the same key and then apply some reducing operation to each one of them if you look at the slide that reducing operation is simply adding two numbers together that expression case x y arrow x plus y that's just saying hey go look for two numbers maybe a one and a one and add those two numbers together and return them and it's going to repeatedly apply that to the records in the rdd and if you look at the flow diagram reduce by key sort of collects up all of the common tags or the common keys and adds their counts together so we end up with a count of words and if you want to look at that all in one place that's what the code looks like and this is pretty typical of the scala spark api it's a fluent interface so you can end up with fairly readable code that really efficiently expresses the sequence of transformations and actions that you're going to perform on your data even as you read it in and then spit it back out to some output source so with that a quick lightning start getting your hands dirty on some spark code and i hope that gives you an idea of a few concepts now next we're going to drill down into the data model a little bit we're going to look at what an rdd really is and how we can use them you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 5.92,
        "duration": 3.36,
        "text": "welcome to ds320 analytics on cassandra"
      },
      {
        "start": 8.24,
        "duration": 2.399,
        "text": "with apache spark"
      },
      {
        "start": 9.28,
        "duration": 2.72,
        "text": "i'm tim berglund and i'm going to be"
      },
      {
        "start": 10.639,
        "duration": 2.08,
        "text": "walking you through how to use spark"
      },
      {
        "start": 12.0,
        "duration": 2.4,
        "text": "what it is"
      },
      {
        "start": 12.719,
        "duration": 3.12,
        "text": "and how to use it in conjunction with a"
      },
      {
        "start": 14.4,
        "duration": 3.04,
        "text": "datastax enterprise cluster now we're"
      },
      {
        "start": 15.839,
        "duration": 1.921,
        "text": "going to get started with a quick look"
      },
      {
        "start": 17.44,
        "duration": 3.2,
        "text": "at"
      },
      {
        "start": 17.76,
        "duration": 3.519,
        "text": "spark itself the basics of its api in"
      },
      {
        "start": 20.64,
        "duration": 3.2,
        "text": "scala"
      },
      {
        "start": 21.279,
        "duration": 3.281,
        "text": "and to do that we're going to use the"
      },
      {
        "start": 23.84,
        "duration": 2.48,
        "text": "word count"
      },
      {
        "start": 24.56,
        "duration": 3.52,
        "text": "example now i know you've seen the word"
      },
      {
        "start": 26.32,
        "duration": 2.799,
        "text": "count example in distributed computing"
      },
      {
        "start": 28.08,
        "duration": 2.959,
        "text": "demos before"
      },
      {
        "start": 29.119,
        "duration": 4.321,
        "text": "you can see here on the slide a word"
      },
      {
        "start": 31.039,
        "duration": 2.721,
        "text": "cloud of tags these are all tags applied"
      },
      {
        "start": 33.44,
        "duration": 2.88,
        "text": "to"
      },
      {
        "start": 33.76,
        "duration": 4.0,
        "text": "videos in this fictional video hosting"
      },
      {
        "start": 36.32,
        "duration": 3.6,
        "text": "business called killer video"
      },
      {
        "start": 37.76,
        "duration": 4.08,
        "text": "these are tags that are sized according"
      },
      {
        "start": 39.92,
        "duration": 2.799,
        "text": "to how frequently they're applied to"
      },
      {
        "start": 41.84,
        "duration": 2.559,
        "text": "videos"
      },
      {
        "start": 42.719,
        "duration": 3.921,
        "text": "in the data set let's look at how we"
      },
      {
        "start": 44.399,
        "duration": 4.241,
        "text": "might compute this in spark now the word"
      },
      {
        "start": 46.64,
        "duration": 4.0,
        "text": "count algorithm relies on four"
      },
      {
        "start": 48.64,
        "duration": 4.399,
        "text": "simple steps all right first we have to"
      },
      {
        "start": 50.64,
        "duration": 3.2,
        "text": "load data into spark from some external"
      },
      {
        "start": 53.039,
        "duration": 2.561,
        "text": "data source"
      },
      {
        "start": 53.84,
        "duration": 3.52,
        "text": "key principle that could be a file that"
      },
      {
        "start": 55.6,
        "duration": 2.72,
        "text": "could be a cassandra table we could even"
      },
      {
        "start": 57.36,
        "duration": 3.44,
        "text": "make a literal"
      },
      {
        "start": 58.32,
        "duration": 4.079,
        "text": "list at the scala repel and create a"
      },
      {
        "start": 60.8,
        "duration": 3.2,
        "text": "data set that way after we've loaded the"
      },
      {
        "start": 62.399,
        "duration": 2.08,
        "text": "data we need to parse the records in"
      },
      {
        "start": 64.0,
        "duration": 2.24,
        "text": "this case"
      },
      {
        "start": 64.479,
        "duration": 4.161,
        "text": "these tags into words that can be"
      },
      {
        "start": 66.24,
        "duration": 3.12,
        "text": "counted and then we need to count those"
      },
      {
        "start": 68.64,
        "duration": 2.32,
        "text": "words"
      },
      {
        "start": 69.36,
        "duration": 3.6,
        "text": "finally we're going to push that result"
      },
      {
        "start": 70.96,
        "duration": 4.56,
        "text": "into an external system or maybe just"
      },
      {
        "start": 72.96,
        "duration": 5.12,
        "text": "output it to the screen so bring data in"
      },
      {
        "start": 75.52,
        "duration": 3.599,
        "text": "parse it count the words spit the data"
      },
      {
        "start": 78.08,
        "duration": 3.679,
        "text": "out those basically"
      },
      {
        "start": 79.119,
        "duration": 4.64,
        "text": "are our four steps now we've got a csv"
      },
      {
        "start": 81.759,
        "duration": 3.841,
        "text": "file lying around for demo purposes that"
      },
      {
        "start": 83.759,
        "duration": 2.4,
        "text": "has these tags in them that we want to"
      },
      {
        "start": 85.6,
        "duration": 1.839,
        "text": "count"
      },
      {
        "start": 86.159,
        "duration": 3.28,
        "text": "we're going to load it with the text"
      },
      {
        "start": 87.439,
        "duration": 2.72,
        "text": "file method because it's a text file and"
      },
      {
        "start": 89.439,
        "duration": 2.32,
        "text": "that makes sense"
      },
      {
        "start": 90.159,
        "duration": 3.28,
        "text": "but what are we calling that text file"
      },
      {
        "start": 91.759,
        "duration": 3.121,
        "text": "method on you'll note that that variable"
      },
      {
        "start": 93.439,
        "duration": 3.68,
        "text": "there called sc"
      },
      {
        "start": 94.88,
        "duration": 3.279,
        "text": "sc stands for spark context and that's"
      },
      {
        "start": 97.119,
        "duration": 4.0,
        "text": "always available"
      },
      {
        "start": 98.159,
        "duration": 4.96,
        "text": "in the spark shell the spark shell is a"
      },
      {
        "start": 101.119,
        "duration": 4.081,
        "text": "fancy version of the scala reple"
      },
      {
        "start": 103.119,
        "duration": 3.761,
        "text": "so if you know scala you're perfectly at"
      },
      {
        "start": 105.2,
        "duration": 2.8,
        "text": "home here if you don't know scala don't"
      },
      {
        "start": 106.88,
        "duration": 2.64,
        "text": "worry we're going to give you what you"
      },
      {
        "start": 108.0,
        "duration": 3.119,
        "text": "need step by step to learn how to do"
      },
      {
        "start": 109.52,
        "duration": 2.8,
        "text": "this but a little bit of scala knowledge"
      },
      {
        "start": 111.119,
        "duration": 3.36,
        "text": "goes a long way"
      },
      {
        "start": 112.32,
        "duration": 4.079,
        "text": "for learning spark through these videos"
      },
      {
        "start": 114.479,
        "duration": 4.561,
        "text": "and frankly broadly speaking"
      },
      {
        "start": 116.399,
        "duration": 4.08,
        "text": "most of the examples in the spark world"
      },
      {
        "start": 119.04,
        "duration": 3.2,
        "text": "tend to be scala"
      },
      {
        "start": 120.479,
        "duration": 3.28,
        "text": "or python but scala really seems to be"
      },
      {
        "start": 122.24,
        "duration": 3.04,
        "text": "sort of the native language which is why"
      },
      {
        "start": 123.759,
        "duration": 4.64,
        "text": "we've picked it so we're going to call"
      },
      {
        "start": 125.28,
        "duration": 5.44,
        "text": "text file there on the sc object"
      },
      {
        "start": 128.399,
        "duration": 3.92,
        "text": "and that is going to return an object"
      },
      {
        "start": 130.72,
        "duration": 4.159,
        "text": "that records object"
      },
      {
        "start": 132.319,
        "duration": 3.28,
        "text": "which is an object of the resilient"
      },
      {
        "start": 134.879,
        "duration": 3.921,
        "text": "distributed"
      },
      {
        "start": 135.599,
        "duration": 4.801,
        "text": "data set type it's called an rdd alright"
      },
      {
        "start": 138.8,
        "duration": 2.799,
        "text": "so for now just think of that as a big"
      },
      {
        "start": 140.4,
        "duration": 3.199,
        "text": "collection of records we're going to"
      },
      {
        "start": 141.599,
        "duration": 3.521,
        "text": "dive much deeper into what rdds are in a"
      },
      {
        "start": 143.599,
        "duration": 3.601,
        "text": "little bit but we've loaded that text"
      },
      {
        "start": 145.12,
        "duration": 5.199,
        "text": "file in we've got this rdd"
      },
      {
        "start": 147.2,
        "duration": 6.0,
        "text": "and there we are now each record in"
      },
      {
        "start": 150.319,
        "duration": 4.401,
        "text": "that rdd in that data set becomes a"
      },
      {
        "start": 153.2,
        "duration": 2.88,
        "text": "string so it really is like we've just"
      },
      {
        "start": 154.72,
        "duration": 3.36,
        "text": "read the lines in"
      },
      {
        "start": 156.08,
        "duration": 4.0,
        "text": "and the rdd is this collection of"
      },
      {
        "start": 158.08,
        "duration": 4.159,
        "text": "strings that we've read in"
      },
      {
        "start": 160.08,
        "duration": 3.92,
        "text": "next we're going to parse those lines"
      },
      {
        "start": 162.239,
        "duration": 3.041,
        "text": "we're going to take the records in that"
      },
      {
        "start": 164.0,
        "duration": 3.84,
        "text": "rdd"
      },
      {
        "start": 165.28,
        "duration": 3.679,
        "text": "and operate on each record we're calling"
      },
      {
        "start": 167.84,
        "duration": 2.72,
        "text": "the flat map"
      },
      {
        "start": 168.959,
        "duration": 3.761,
        "text": "method we're going to dive deeper into"
      },
      {
        "start": 170.56,
        "duration": 4.56,
        "text": "what flat map means later"
      },
      {
        "start": 172.72,
        "duration": 3.28,
        "text": "but for now you can think of flat map as"
      },
      {
        "start": 175.12,
        "duration": 3.199,
        "text": "a thing that"
      },
      {
        "start": 176.0,
        "duration": 3.76,
        "text": "creates a collection it'll take some"
      },
      {
        "start": 178.319,
        "duration": 3.84,
        "text": "data item in"
      },
      {
        "start": 179.76,
        "duration": 4.24,
        "text": "and it'll output a collection of data"
      },
      {
        "start": 182.159,
        "duration": 3.121,
        "text": "items so it's taking something and"
      },
      {
        "start": 184.0,
        "duration": 3.519,
        "text": "breaking it into pieces"
      },
      {
        "start": 185.28,
        "duration": 3.36,
        "text": "and spitting those pieces out into the"
      },
      {
        "start": 187.519,
        "duration": 3.281,
        "text": "rdd it returns"
      },
      {
        "start": 188.64,
        "duration": 3.679,
        "text": "and flat map takes an anonymous function"
      },
      {
        "start": 190.8,
        "duration": 2.32,
        "text": "as a parameter some people call them"
      },
      {
        "start": 192.319,
        "duration": 2.321,
        "text": "closures"
      },
      {
        "start": 193.12,
        "duration": 3.44,
        "text": "some people call them code blocks but"
      },
      {
        "start": 194.64,
        "duration": 2.8,
        "text": "that's an anonymous function the body of"
      },
      {
        "start": 196.56,
        "duration": 3.2,
        "text": "that function"
      },
      {
        "start": 197.44,
        "duration": 3.76,
        "text": "gets applied to every element in the"
      },
      {
        "start": 199.76,
        "duration": 4.32,
        "text": "input rdd"
      },
      {
        "start": 201.2,
        "duration": 3.759,
        "text": "that input rdd remember is our csv file"
      },
      {
        "start": 204.08,
        "duration": 3.28,
        "text": "that we read in"
      },
      {
        "start": 204.959,
        "duration": 3.601,
        "text": "and we apply that function to every line"
      },
      {
        "start": 207.36,
        "duration": 3.2,
        "text": "in that file"
      },
      {
        "start": 208.56,
        "duration": 4.959,
        "text": "the return value of that function"
      },
      {
        "start": 210.56,
        "duration": 5.12,
        "text": "becomes a new record or set of records"
      },
      {
        "start": 213.519,
        "duration": 3.681,
        "text": "in the output rdd so what do we do"
      },
      {
        "start": 215.68,
        "duration": 2.96,
        "text": "inside that anonymous function if you"
      },
      {
        "start": 217.2,
        "duration": 4.48,
        "text": "look in there you'll see we"
      },
      {
        "start": 218.64,
        "duration": 4.72,
        "text": "split the text we treat that line of"
      },
      {
        "start": 221.68,
        "duration": 4.32,
        "text": "text as a line of text we split it"
      },
      {
        "start": 223.36,
        "duration": 4.72,
        "text": "based on the comma delimiter so that's"
      },
      {
        "start": 226.0,
        "duration": 4.239,
        "text": "going to create a collection of strings"
      },
      {
        "start": 228.08,
        "duration": 3.519,
        "text": "from that one string and notice what"
      },
      {
        "start": 230.239,
        "duration": 3.601,
        "text": "we're doing here we started"
      },
      {
        "start": 231.599,
        "duration": 4.401,
        "text": "creating an rdd from a text file then we"
      },
      {
        "start": 233.84,
        "duration": 3.679,
        "text": "called a transformation on that rdd to"
      },
      {
        "start": 236.0,
        "duration": 3.12,
        "text": "change it a little bit"
      },
      {
        "start": 237.519,
        "duration": 4.0,
        "text": "we actually didn't really change that"
      },
      {
        "start": 239.12,
        "duration": 3.679,
        "text": "first rdd we returned a new one and"
      },
      {
        "start": 241.519,
        "duration": 3.521,
        "text": "that's a key principle"
      },
      {
        "start": 242.799,
        "duration": 5.601,
        "text": "we're going to do that again by calling"
      },
      {
        "start": 245.04,
        "duration": 5.279,
        "text": "the map transformation on the words rdd"
      },
      {
        "start": 248.4,
        "duration": 3.44,
        "text": "now the map transformation again lets us"
      },
      {
        "start": 250.319,
        "duration": 3.12,
        "text": "have a little bit of flexibility in what"
      },
      {
        "start": 251.84,
        "duration": 2.16,
        "text": "we're going to do we get to write some"
      },
      {
        "start": 253.439,
        "duration": 3.04,
        "text": "code"
      },
      {
        "start": 254.0,
        "duration": 3.44,
        "text": "that's going to operate on every element"
      },
      {
        "start": 256.479,
        "duration": 3.201,
        "text": "or every record"
      },
      {
        "start": 257.44,
        "duration": 4.0,
        "text": "in the rdd we're transforming if you"
      },
      {
        "start": 259.68,
        "duration": 4.72,
        "text": "look at the code you'll see"
      },
      {
        "start": 261.44,
        "duration": 4.72,
        "text": "what we do is we take each word we're"
      },
      {
        "start": 264.4,
        "duration": 2.4,
        "text": "expecting each record in this rdd to be"
      },
      {
        "start": 266.16,
        "duration": 2.72,
        "text": "a word"
      },
      {
        "start": 266.8,
        "duration": 4.24,
        "text": "now we take each one of them and"
      },
      {
        "start": 268.88,
        "duration": 4.0,
        "text": "transform it into what scala calls a"
      },
      {
        "start": 271.04,
        "duration": 2.24,
        "text": "tuple that expression in parenthesis"
      },
      {
        "start": 272.88,
        "duration": 2.96,
        "text": "there"
      },
      {
        "start": 273.28,
        "duration": 3.28,
        "text": "is a tuple we're basically pairing the"
      },
      {
        "start": 275.84,
        "duration": 2.639,
        "text": "word"
      },
      {
        "start": 276.56,
        "duration": 3.44,
        "text": "with the number one and if you've seen"
      },
      {
        "start": 278.479,
        "duration": 2.561,
        "text": "word count examples before you've seen"
      },
      {
        "start": 280.0,
        "duration": 2.88,
        "text": "this game played"
      },
      {
        "start": 281.04,
        "duration": 4.08,
        "text": "where we tokenize words and we create a"
      },
      {
        "start": 282.88,
        "duration": 3.36,
        "text": "key value pair out of each word where"
      },
      {
        "start": 285.12,
        "duration": 2.799,
        "text": "we're pairing the word"
      },
      {
        "start": 286.24,
        "duration": 3.44,
        "text": "with the number one this is basically"
      },
      {
        "start": 287.919,
        "duration": 3.201,
        "text": "step one in counting words"
      },
      {
        "start": 289.68,
        "duration": 3.2,
        "text": "functionally speaking we're looking at"
      },
      {
        "start": 291.12,
        "duration": 3.359,
        "text": "every word that we've identified"
      },
      {
        "start": 292.88,
        "duration": 3.2,
        "text": "and we say i've counted this word one"
      },
      {
        "start": 294.479,
        "duration": 4.081,
        "text": "time now that expression that"
      },
      {
        "start": 296.08,
        "duration": 4.8,
        "text": "words dot map and then the code block in"
      },
      {
        "start": 298.56,
        "duration": 5.84,
        "text": "there mapping the words rdd"
      },
      {
        "start": 300.88,
        "duration": 4.879,
        "text": "onto this new rdd that's word tuples"
      },
      {
        "start": 304.4,
        "duration": 1.92,
        "text": "we're going to reduce that we're going"
      },
      {
        "start": 305.759,
        "duration": 3.201,
        "text": "to call"
      },
      {
        "start": 306.32,
        "duration": 4.08,
        "text": "reduce by key what that's going to do is"
      },
      {
        "start": 308.96,
        "duration": 3.2,
        "text": "it's going to gather up"
      },
      {
        "start": 310.4,
        "duration": 3.28,
        "text": "all of the records in this rdd that have"
      },
      {
        "start": 312.16,
        "duration": 4.8,
        "text": "the same key"
      },
      {
        "start": 313.68,
        "duration": 4.799,
        "text": "and then apply some reducing operation"
      },
      {
        "start": 316.96,
        "duration": 3.92,
        "text": "to each one of them if you look at the"
      },
      {
        "start": 318.479,
        "duration": 5.28,
        "text": "slide that reducing operation"
      },
      {
        "start": 320.88,
        "duration": 3.759,
        "text": "is simply adding two numbers together"
      },
      {
        "start": 323.759,
        "duration": 3.761,
        "text": "that expression"
      },
      {
        "start": 324.639,
        "duration": 3.601,
        "text": "case x y arrow x plus y that's just"
      },
      {
        "start": 327.52,
        "duration": 3.04,
        "text": "saying hey go"
      },
      {
        "start": 328.24,
        "duration": 4.48,
        "text": "look for two numbers maybe a one and a"
      },
      {
        "start": 330.56,
        "duration": 3.359,
        "text": "one and add those two numbers together"
      },
      {
        "start": 332.72,
        "duration": 3.039,
        "text": "and return them and it's going to"
      },
      {
        "start": 333.919,
        "duration": 3.28,
        "text": "repeatedly apply that to the records in"
      },
      {
        "start": 335.759,
        "duration": 2.241,
        "text": "the rdd and if you look at the flow"
      },
      {
        "start": 337.199,
        "duration": 3.84,
        "text": "diagram"
      },
      {
        "start": 338.0,
        "duration": 6.639,
        "text": "reduce by key sort of collects up"
      },
      {
        "start": 341.039,
        "duration": 4.16,
        "text": "all of the common tags or the common"
      },
      {
        "start": 344.639,
        "duration": 2.321,
        "text": "keys"
      },
      {
        "start": 345.199,
        "duration": 3.201,
        "text": "and adds their counts together so we end"
      },
      {
        "start": 346.96,
        "duration": 2.88,
        "text": "up with a count of words"
      },
      {
        "start": 348.4,
        "duration": 3.12,
        "text": "and if you want to look at that all in"
      },
      {
        "start": 349.84,
        "duration": 3.44,
        "text": "one place that's what the code looks"
      },
      {
        "start": 351.52,
        "duration": 4.32,
        "text": "like and this is pretty typical"
      },
      {
        "start": 353.28,
        "duration": 3.52,
        "text": "of the scala spark api it's a fluent"
      },
      {
        "start": 355.84,
        "duration": 4.16,
        "text": "interface"
      },
      {
        "start": 356.8,
        "duration": 3.76,
        "text": "so you can end up with fairly readable"
      },
      {
        "start": 360.0,
        "duration": 2.639,
        "text": "code"
      },
      {
        "start": 360.56,
        "duration": 4.079,
        "text": "that really efficiently expresses the"
      },
      {
        "start": 362.639,
        "duration": 3.361,
        "text": "sequence of transformations and actions"
      },
      {
        "start": 364.639,
        "duration": 4.321,
        "text": "that you're going to perform"
      },
      {
        "start": 366.0,
        "duration": 3.52,
        "text": "on your data even as you read it in and"
      },
      {
        "start": 368.96,
        "duration": 3.12,
        "text": "then"
      },
      {
        "start": 369.52,
        "duration": 3.519,
        "text": "spit it back out to some output source"
      },
      {
        "start": 372.08,
        "duration": 2.8,
        "text": "so with that"
      },
      {
        "start": 373.039,
        "duration": 3.361,
        "text": "a quick lightning start getting your"
      },
      {
        "start": 374.88,
        "duration": 3.599,
        "text": "hands dirty on"
      },
      {
        "start": 376.4,
        "duration": 3.76,
        "text": "some spark code and i hope that gives"
      },
      {
        "start": 378.479,
        "duration": 4.321,
        "text": "you an idea of a few concepts"
      },
      {
        "start": 380.16,
        "duration": 4.08,
        "text": "now next we're going to drill down into"
      },
      {
        "start": 382.8,
        "duration": 3.519,
        "text": "the data model a little bit"
      },
      {
        "start": 384.24,
        "duration": 3.36,
        "text": "we're going to look at what an rdd"
      },
      {
        "start": 386.319,
        "duration": 8.961,
        "text": "really is"
      },
      {
        "start": 387.6,
        "duration": 9.76,
        "text": "and how we can use them"
      },
      {
        "start": 395.28,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:53:41.182077+00:00"
}