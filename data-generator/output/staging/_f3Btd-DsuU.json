{
  "video_id": "_f3Btd-DsuU",
  "title": "DS210.03 Cluster Sizing | Operations with Apache Cassandra",
  "description": "#DataStaxAcademy #DS210\nDS210.03 CLUSTER SIZING\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-11T08:50:50Z",
  "thumbnail": "https://i.ytimg.com/vi/_f3Btd-DsuU/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "datastax",
    "tutorial",
    "apache_cassandra"
  ],
  "url": "https://www.youtube.com/watch?v=_f3Btd-DsuU",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] ooh cluster sizing that seems interesting all right let's jump right in i bet cluster sizing means exactly what you think it does it's deducing the size of the cluster based on some metadata that you have some things you should think about when trying to figure out the cluster size like what is your required throughput specifically how much data do you need per second secondly your growth rate how much growth do you anticipate in your cluster and finally latency how fast do you need the cluster to respond to requests let's get into each of these just a little bit deeper throughput is measured by data movement per time period for example how many gigabits per second you want or you can achieve with apache cassandra these can be different on reads and rights so consider them independently from each other the following things can have an impact on your throughput things like your operation generators such as your users or how fast operations are generated also how big or how small each operation is as well as the mix of operations like the number of reads and writes you have in your workload let's look at a real example using our killer video domain which is the video sharing application we use in all of our data stacks academy curriculum let's start with right throughput all right let's say we have two million users and each user comments five times a day we would end up with about a hundred comments per second which equals two million times five divided by twenty four times sixty times sixty again wait this is math i hate math okay moving on each comment inserts a row and each row is about a thousand bytes what we end up with is that we are writing a hundred kilobytes per second are you ready for the next example let's do this back in our killer video domain let's display user comments which are read operations okay we still have 2 million users no one joined since i finished the last slide bummer anyway they are each looking at 10 video summaries per day now what ah yes you end up with 250 queries per second which equals 2 million times 10 divided by 24 times 60 times 60. more math ugh okay let's keep going we have four comments per video which equals four rows per query which is about a thousand bytes per comment you end up with reading one megabyte per second which is equal to 250 times four times a thousand let's move on to growth rate so there are some things that you need to think about here what size should your cluster be to hold all of your data if you know your throughput then you have to consider your new or update ratio how your replication factor comes into play and plan for additional headroom required when performing cluster operations for example a repair let's take a look at this example shall we let's say you have 100 kilobytes per second throughput with about 20 percent write updates the result of this is a growth rate of 80 kilobytes per second or a hundred kilobytes times one minus point two let's throw some replication considerations in there and see what happens in this example we have a replication value of six three replicas in each of two data centers this results in a growth rate of 480 kilobytes per second which is 80 kilobytes times 6. all right one more example i swear let's talk about the need to consider headroom when thinking about cluster sizing there are cluster operations that require additional headroom at least temporarily while they run in this example we are talking about anti-entropy operations remember you should only load your disk by about 50 because you're going to need the other 50 percent to copy data to this would result in a growth rate of 960 kilobytes per second which is 480 kilobytes per second divided by 0.5 let's put this all together let's assume you have a node that holds up to 2 terabytes max using ssd this would fill up a node each month by using the following calculation 960 kilobytes per second times the number of seconds you have in a month divided by two terabytes i think we're done with growth rate what's next oh yes latency maybe i should slow that down late 10c okay how does this affect cluster sizing it's one thing to figure out what your cluster capacity is it's another thing entirely to ensure you're adhering to your required slas make sure you understand what your slas are in terms of both throughput and latency all right what kind of things can affect your latency well for one how slow you type but but seriously the following things have an impact on latency your i o rate the shape of your workload your access patterns or in other words the queries that you plan to run table width or what your node looks like in terms of memory or the size of the node etc those things will also have an impact benchmarking is key when it comes to making estimates on cluster sizing now you are armed with the knowledge you need to get your cluster sized right at least initially remember though that requirements will change you should always keep an eye on your cluster periodically and watch for changes in your environment that indicate a need for growth make sure you plan ahead for any future growth you might anticipate cluster sizing isn't always about getting bigger though sometimes a cluster needs to be scaled back to save resources or to save money",
    "segments": [
      {
        "start": 1.43,
        "duration": 5.33,
        "text": "[Music]"
      },
      {
        "start": 7.2,
        "duration": 3.12,
        "text": "ooh"
      },
      {
        "start": 7.68,
        "duration": 4.32,
        "text": "cluster sizing that seems interesting"
      },
      {
        "start": 10.32,
        "duration": 3.6,
        "text": "all right let's jump right in"
      },
      {
        "start": 12.0,
        "duration": 4.08,
        "text": "i bet cluster sizing means exactly what"
      },
      {
        "start": 13.92,
        "duration": 4.0,
        "text": "you think it does it's deducing the size"
      },
      {
        "start": 16.08,
        "duration": 2.88,
        "text": "of the cluster based on some metadata"
      },
      {
        "start": 17.92,
        "duration": 2.4,
        "text": "that you have"
      },
      {
        "start": 18.96,
        "duration": 3.2,
        "text": "some things you should think about when"
      },
      {
        "start": 20.32,
        "duration": 3.44,
        "text": "trying to figure out the cluster size"
      },
      {
        "start": 22.16,
        "duration": 3.279,
        "text": "like what is your required throughput"
      },
      {
        "start": 23.76,
        "duration": 2.72,
        "text": "specifically how much data do you need"
      },
      {
        "start": 25.439,
        "duration": 3.521,
        "text": "per second"
      },
      {
        "start": 26.48,
        "duration": 3.68,
        "text": "secondly your growth rate how much"
      },
      {
        "start": 28.96,
        "duration": 4.48,
        "text": "growth do you anticipate"
      },
      {
        "start": 30.16,
        "duration": 5.04,
        "text": "in your cluster and finally latency how"
      },
      {
        "start": 33.44,
        "duration": 3.04,
        "text": "fast do you need the cluster to respond"
      },
      {
        "start": 35.2,
        "duration": 2.72,
        "text": "to requests"
      },
      {
        "start": 36.48,
        "duration": 3.04,
        "text": "let's get into each of these just a"
      },
      {
        "start": 37.92,
        "duration": 3.68,
        "text": "little bit deeper"
      },
      {
        "start": 39.52,
        "duration": 3.76,
        "text": "throughput is measured by data movement"
      },
      {
        "start": 41.6,
        "duration": 3.92,
        "text": "per time period"
      },
      {
        "start": 43.28,
        "duration": 4.16,
        "text": "for example how many gigabits per second"
      },
      {
        "start": 45.52,
        "duration": 3.6,
        "text": "you want or you can achieve"
      },
      {
        "start": 47.44,
        "duration": 3.279,
        "text": "with apache cassandra these can be"
      },
      {
        "start": 49.12,
        "duration": 3.36,
        "text": "different on reads and rights so"
      },
      {
        "start": 50.719,
        "duration": 2.48,
        "text": "consider them independently from each"
      },
      {
        "start": 52.48,
        "duration": 2.399,
        "text": "other"
      },
      {
        "start": 53.199,
        "duration": 3.68,
        "text": "the following things can have an impact"
      },
      {
        "start": 54.879,
        "duration": 4.081,
        "text": "on your throughput things like"
      },
      {
        "start": 56.879,
        "duration": 4.48,
        "text": "your operation generators such as your"
      },
      {
        "start": 58.96,
        "duration": 3.439,
        "text": "users or how fast operations are"
      },
      {
        "start": 61.359,
        "duration": 3.52,
        "text": "generated"
      },
      {
        "start": 62.399,
        "duration": 3.281,
        "text": "also how big or how small each operation"
      },
      {
        "start": 64.879,
        "duration": 2.721,
        "text": "is"
      },
      {
        "start": 65.68,
        "duration": 3.84,
        "text": "as well as the mix of operations like"
      },
      {
        "start": 67.6,
        "duration": 3.44,
        "text": "the number of reads and writes you have"
      },
      {
        "start": 69.52,
        "duration": 3.36,
        "text": "in your workload"
      },
      {
        "start": 71.04,
        "duration": 3.68,
        "text": "let's look at a real example using our"
      },
      {
        "start": 72.88,
        "duration": 3.76,
        "text": "killer video domain which is the video"
      },
      {
        "start": 74.72,
        "duration": 4.079,
        "text": "sharing application we use in all of our"
      },
      {
        "start": 76.64,
        "duration": 4.0,
        "text": "data stacks academy curriculum"
      },
      {
        "start": 78.799,
        "duration": 3.841,
        "text": "let's start with right throughput all"
      },
      {
        "start": 80.64,
        "duration": 4.0,
        "text": "right let's say we have two million"
      },
      {
        "start": 82.64,
        "duration": 4.0,
        "text": "users and each user comments"
      },
      {
        "start": 84.64,
        "duration": 3.519,
        "text": "five times a day we would end up with"
      },
      {
        "start": 86.64,
        "duration": 2.479,
        "text": "about a hundred comments per second"
      },
      {
        "start": 88.159,
        "duration": 3.521,
        "text": "which equals"
      },
      {
        "start": 89.119,
        "duration": 3.921,
        "text": "two million times five divided by twenty"
      },
      {
        "start": 91.68,
        "duration": 4.88,
        "text": "four times sixty"
      },
      {
        "start": 93.04,
        "duration": 4.56,
        "text": "times sixty again wait this is math i"
      },
      {
        "start": 96.56,
        "duration": 3.919,
        "text": "hate math"
      },
      {
        "start": 97.6,
        "duration": 4.799,
        "text": "okay moving on each comment inserts a"
      },
      {
        "start": 100.479,
        "duration": 2.881,
        "text": "row and each row is about a thousand"
      },
      {
        "start": 102.399,
        "duration": 2.561,
        "text": "bytes"
      },
      {
        "start": 103.36,
        "duration": 3.039,
        "text": "what we end up with is that we are"
      },
      {
        "start": 104.96,
        "duration": 4.159,
        "text": "writing a hundred"
      },
      {
        "start": 106.399,
        "duration": 4.0,
        "text": "kilobytes per second are you ready for"
      },
      {
        "start": 109.119,
        "duration": 3.601,
        "text": "the next example"
      },
      {
        "start": 110.399,
        "duration": 3.68,
        "text": "let's do this back in our killer video"
      },
      {
        "start": 112.72,
        "duration": 3.999,
        "text": "domain let's display"
      },
      {
        "start": 114.079,
        "duration": 4.72,
        "text": "user comments which are read operations"
      },
      {
        "start": 116.719,
        "duration": 3.44,
        "text": "okay we still have 2 million users no"
      },
      {
        "start": 118.799,
        "duration": 2.161,
        "text": "one joined since i finished the last"
      },
      {
        "start": 120.159,
        "duration": 3.361,
        "text": "slide"
      },
      {
        "start": 120.96,
        "duration": 4.56,
        "text": "bummer anyway they are each looking at"
      },
      {
        "start": 123.52,
        "duration": 4.64,
        "text": "10 video summaries per day"
      },
      {
        "start": 125.52,
        "duration": 3.76,
        "text": "now what ah yes you end up with 250"
      },
      {
        "start": 128.16,
        "duration": 4.24,
        "text": "queries per second"
      },
      {
        "start": 129.28,
        "duration": 3.52,
        "text": "which equals 2 million times 10 divided"
      },
      {
        "start": 132.4,
        "duration": 3.68,
        "text": "by"
      },
      {
        "start": 132.8,
        "duration": 6.48,
        "text": "24 times 60 times 60."
      },
      {
        "start": 136.08,
        "duration": 5.519,
        "text": "more math ugh okay let's keep going"
      },
      {
        "start": 139.28,
        "duration": 4.16,
        "text": "we have four comments per video which"
      },
      {
        "start": 141.599,
        "duration": 4.0,
        "text": "equals four rows per query"
      },
      {
        "start": 143.44,
        "duration": 3.12,
        "text": "which is about a thousand bytes per"
      },
      {
        "start": 145.599,
        "duration": 3.36,
        "text": "comment"
      },
      {
        "start": 146.56,
        "duration": 4.959,
        "text": "you end up with reading one megabyte per"
      },
      {
        "start": 148.959,
        "duration": 5.521,
        "text": "second which is equal to 250"
      },
      {
        "start": 151.519,
        "duration": 4.0,
        "text": "times four times a thousand let's move"
      },
      {
        "start": 154.48,
        "duration": 2.08,
        "text": "on to growth rate"
      },
      {
        "start": 155.519,
        "duration": 3.041,
        "text": "so there are some things that you need"
      },
      {
        "start": 156.56,
        "duration": 4.319,
        "text": "to think about here what size should"
      },
      {
        "start": 158.56,
        "duration": 3.759,
        "text": "your cluster be to hold all of your data"
      },
      {
        "start": 160.879,
        "duration": 3.121,
        "text": "if you know your throughput then you"
      },
      {
        "start": 162.319,
        "duration": 2.801,
        "text": "have to consider your new or update"
      },
      {
        "start": 164.0,
        "duration": 2.8,
        "text": "ratio"
      },
      {
        "start": 165.12,
        "duration": 3.759,
        "text": "how your replication factor comes into"
      },
      {
        "start": 166.8,
        "duration": 3.76,
        "text": "play and plan for additional headroom"
      },
      {
        "start": 168.879,
        "duration": 2.561,
        "text": "required when performing cluster"
      },
      {
        "start": 170.56,
        "duration": 3.44,
        "text": "operations"
      },
      {
        "start": 171.44,
        "duration": 4.24,
        "text": "for example a repair let's take a look"
      },
      {
        "start": 174.0,
        "duration": 3.519,
        "text": "at this example shall we"
      },
      {
        "start": 175.68,
        "duration": 3.279,
        "text": "let's say you have 100 kilobytes per"
      },
      {
        "start": 177.519,
        "duration": 3.681,
        "text": "second throughput with about"
      },
      {
        "start": 178.959,
        "duration": 3.601,
        "text": "20 percent write updates the result of"
      },
      {
        "start": 181.2,
        "duration": 4.399,
        "text": "this is a growth rate of"
      },
      {
        "start": 182.56,
        "duration": 3.84,
        "text": "80 kilobytes per second or a hundred"
      },
      {
        "start": 185.599,
        "duration": 3.521,
        "text": "kilobytes"
      },
      {
        "start": 186.4,
        "duration": 4.4,
        "text": "times one minus point two let's throw"
      },
      {
        "start": 189.12,
        "duration": 2.8,
        "text": "some replication considerations in there"
      },
      {
        "start": 190.8,
        "duration": 3.28,
        "text": "and see what happens"
      },
      {
        "start": 191.92,
        "duration": 3.28,
        "text": "in this example we have a replication"
      },
      {
        "start": 194.08,
        "duration": 2.879,
        "text": "value of six"
      },
      {
        "start": 195.2,
        "duration": 4.24,
        "text": "three replicas in each of two data"
      },
      {
        "start": 196.959,
        "duration": 4.64,
        "text": "centers this results in a growth rate of"
      },
      {
        "start": 199.44,
        "duration": 6.079,
        "text": "480 kilobytes per second"
      },
      {
        "start": 201.599,
        "duration": 6.481,
        "text": "which is 80 kilobytes times 6. all right"
      },
      {
        "start": 205.519,
        "duration": 4.321,
        "text": "one more example i swear let's talk"
      },
      {
        "start": 208.08,
        "duration": 3.6,
        "text": "about the need to consider headroom when"
      },
      {
        "start": 209.84,
        "duration": 3.2,
        "text": "thinking about cluster sizing"
      },
      {
        "start": 211.68,
        "duration": 3.119,
        "text": "there are cluster operations that"
      },
      {
        "start": 213.04,
        "duration": 2.64,
        "text": "require additional headroom at least"
      },
      {
        "start": 214.799,
        "duration": 3.201,
        "text": "temporarily"
      },
      {
        "start": 215.68,
        "duration": 4.559,
        "text": "while they run in this example we are"
      },
      {
        "start": 218.0,
        "duration": 4.0,
        "text": "talking about anti-entropy operations"
      },
      {
        "start": 220.239,
        "duration": 3.441,
        "text": "remember you should only load your disk"
      },
      {
        "start": 222.0,
        "duration": 2.879,
        "text": "by about 50 because you're going to need"
      },
      {
        "start": 223.68,
        "duration": 3.68,
        "text": "the other 50 percent"
      },
      {
        "start": 224.879,
        "duration": 5.44,
        "text": "to copy data to this would result in a"
      },
      {
        "start": 227.36,
        "duration": 5.36,
        "text": "growth rate of 960 kilobytes per second"
      },
      {
        "start": 230.319,
        "duration": 3.2,
        "text": "which is 480 kilobytes per second"
      },
      {
        "start": 232.72,
        "duration": 3.439,
        "text": "divided by"
      },
      {
        "start": 233.519,
        "duration": 4.161,
        "text": "0.5 let's put this all together let's"
      },
      {
        "start": 236.159,
        "duration": 4.08,
        "text": "assume you have a node that holds up to"
      },
      {
        "start": 237.68,
        "duration": 4.32,
        "text": "2 terabytes max using ssd"
      },
      {
        "start": 240.239,
        "duration": 3.761,
        "text": "this would fill up a node each month by"
      },
      {
        "start": 242.0,
        "duration": 5.04,
        "text": "using the following calculation"
      },
      {
        "start": 244.0,
        "duration": 4.72,
        "text": "960 kilobytes per second times the"
      },
      {
        "start": 247.04,
        "duration": 4.88,
        "text": "number of seconds you have in a month"
      },
      {
        "start": 248.72,
        "duration": 4.56,
        "text": "divided by two terabytes i think we're"
      },
      {
        "start": 251.92,
        "duration": 4.319,
        "text": "done with growth rate"
      },
      {
        "start": 253.28,
        "duration": 4.16,
        "text": "what's next oh yes latency maybe i"
      },
      {
        "start": 256.239,
        "duration": 3.921,
        "text": "should slow that down"
      },
      {
        "start": 257.44,
        "duration": 3.919,
        "text": "late 10c okay how does this affect"
      },
      {
        "start": 260.16,
        "duration": 2.56,
        "text": "cluster sizing"
      },
      {
        "start": 261.359,
        "duration": 3.28,
        "text": "it's one thing to figure out what your"
      },
      {
        "start": 262.72,
        "duration": 3.84,
        "text": "cluster capacity is it's another thing"
      },
      {
        "start": 264.639,
        "duration": 3.921,
        "text": "entirely to ensure you're adhering to"
      },
      {
        "start": 266.56,
        "duration": 3.68,
        "text": "your required slas"
      },
      {
        "start": 268.56,
        "duration": 3.52,
        "text": "make sure you understand what your slas"
      },
      {
        "start": 270.24,
        "duration": 3.92,
        "text": "are in terms of both throughput"
      },
      {
        "start": 272.08,
        "duration": 3.6,
        "text": "and latency all right what kind of"
      },
      {
        "start": 274.16,
        "duration": 4.08,
        "text": "things can affect your latency"
      },
      {
        "start": 275.68,
        "duration": 3.28,
        "text": "well for one how slow you type but but"
      },
      {
        "start": 278.24,
        "duration": 2.72,
        "text": "seriously"
      },
      {
        "start": 278.96,
        "duration": 3.04,
        "text": "the following things have an impact on"
      },
      {
        "start": 280.96,
        "duration": 3.2,
        "text": "latency"
      },
      {
        "start": 282.0,
        "duration": 4.0,
        "text": "your i o rate the shape of your workload"
      },
      {
        "start": 284.16,
        "duration": 3.84,
        "text": "your access patterns or in other words"
      },
      {
        "start": 286.0,
        "duration": 4.32,
        "text": "the queries that you plan to run"
      },
      {
        "start": 288.0,
        "duration": 4.0,
        "text": "table width or what your node looks like"
      },
      {
        "start": 290.32,
        "duration": 2.8,
        "text": "in terms of memory or the size of the"
      },
      {
        "start": 292.0,
        "duration": 3.28,
        "text": "node etc"
      },
      {
        "start": 293.12,
        "duration": 3.68,
        "text": "those things will also have an impact"
      },
      {
        "start": 295.28,
        "duration": 3.919,
        "text": "benchmarking is key when it comes to"
      },
      {
        "start": 296.8,
        "duration": 3.839,
        "text": "making estimates on cluster sizing"
      },
      {
        "start": 299.199,
        "duration": 3.201,
        "text": "now you are armed with the knowledge you"
      },
      {
        "start": 300.639,
        "duration": 4.0,
        "text": "need to get your cluster sized right"
      },
      {
        "start": 302.4,
        "duration": 3.519,
        "text": "at least initially remember though that"
      },
      {
        "start": 304.639,
        "duration": 2.641,
        "text": "requirements will change"
      },
      {
        "start": 305.919,
        "duration": 3.28,
        "text": "you should always keep an eye on your"
      },
      {
        "start": 307.28,
        "duration": 3.44,
        "text": "cluster periodically and watch for"
      },
      {
        "start": 309.199,
        "duration": 3.84,
        "text": "changes in your environment that"
      },
      {
        "start": 310.72,
        "duration": 4.0,
        "text": "indicate a need for growth make sure you"
      },
      {
        "start": 313.039,
        "duration": 3.041,
        "text": "plan ahead for any future growth you"
      },
      {
        "start": 314.72,
        "duration": 3.039,
        "text": "might anticipate"
      },
      {
        "start": 316.08,
        "duration": 3.36,
        "text": "cluster sizing isn't always about"
      },
      {
        "start": 317.759,
        "duration": 3.521,
        "text": "getting bigger though sometimes a"
      },
      {
        "start": 319.44,
        "duration": 6.4,
        "text": "cluster needs to be scaled back to save"
      },
      {
        "start": 321.28,
        "duration": 4.56,
        "text": "resources or to save money"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T01:44:33.810737+00:00"
}