{
  "video_id": "Becr6YPF9dQ",
  "title": "Distributed Data Show Episode 34: Spark 2.3 with Holden Karau",
  "description": "Patrick McFadin catches up with Holden Karau of Google to learn about new features of Spark 2.3, including Vectorized UDFs, Microbatch improvements, and Kubernetes support. Along the way, they explore whether API stability is an indicator that it’s time to make a career move. \n\nHighlights!\n0:15 - Welcoming Holden\n0:35 - Patrick asks Holden why Spark APIs keep changing and whether API stability and boring infrastructure is a good thing\n2:43 - Big changes in Spark 2.3 include Vectorized UDFs powered by Apache Arrow, which gives a big performance boost to transferring data between Python and the JVM (for those who aren’t fans of Scala)\n6:44 - In the new Spark Microbatch API, sources and sinks are no longer tied to batches. This gives the flexibility to process as quickly as possible when you can tolerate some data loss like some IoT and machine learning use cases\n11:38 - Kubernetes support is finally in Spark 2.3 after a few competing approaches were resolved, simplifying deployment of complex Spark apps that leverage non-JVM libraries\n14:44 Holden explains why Spark struggles with scaling down and how Kubernetes support may be part of the solution.\n18:34 - Patrick and Holden discuss when it will be safe to deploy Spark on K8S in production (hint, it should be before Spark 3)\n\n\nABOUT DATASTAX ENTERPRISE 5.1\nDataStax Enterprise 5.1, the database platform for cloud applications, includes Apache Cassandra 3.x with materialized views, tiered storage and advanced replication. Introduced in 5.1 is DataStax Enterprise Graph, the first graph database fast enough to power customer-facing applications, scale to massive datasets and integrate advanced tools to power deep analytical queries.\n\nLearn more at http://www.datastax.com/products/datastax-enterprise and https://academy.datastax.com/resources/whats-new-datastax-enterprise-50\n\nCONNECT WITH DATASTAX\nSubscribe: http://www.youtube.com/c/datastax?sub_confirmation=1 \nSite: http://datastax.com \nFacebook: https://facebook.com/data",
  "published_at": "2018-02-13T16:00:01Z",
  "thumbnail": "https://i.ytimg.com/vi/Becr6YPF9dQ/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "distributed",
    "cassandra",
    "database",
    "apache_cassandra",
    "vector",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=Becr6YPF9dQ",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "welcome to another episode of the distributed data show brought to you by data Stax Academy where we bring you the latest news and interview technical experts to help you succeed at building large-scale distributed systems here at day-to-day Texas 2018 I have holy crap author learning spark high performance park also developer advocate at Google thanks for bein here no it's really great to be here so it's time for us to catch up once again yeah I mean it's it's been six months all of the api's of chain everything's changed yeah of course we're going to talk to put spark see the moving project of spark it's getting a little more stable you know yeah it's a stable core idea of a support contract yeah we do we do there's a lot of exciting news AP estimating spark 2.3 do you have any specific ones you wanted to like tell them - well first I mean why do we have to keep changing things what is the VG isn't there a stability moment and we can have a spark or is it just what is it I mean it's a good question um and I think when wooden wrists staple we won't be interesting anymore like fundamentally we will probably reach her point or spark becomes infrastructure that you don't have to think about at that point I need to find a new job but you know everything gets a lot easier well I don't think we're there yet right there there are a lot of things which we are still relearning from the 70s to implement on today's hardware and you know then we still have to catch up with the a dress but we add another layer to keep things exciting yeah no it's good yeah totally so the biggest most exciting change for pi spark is the vectorize do DFS coming in spar two to three and they're powered by apache arrow which is this really exciting project from West McKinney the folks at 2 Sigma some of the folks said my former employer IBM and some of the data bricks and it's it's okay Jake Luciana is on the PMC so there's it's it's a really great cross industry collaboration right and it gives us this was really nice in memory format for representing data but also representing common our data which yeah we care about and it gives us a nice way of transferring data from the JVM to Python and back and it also makes it easier for us to implement vectorize operational spark which beforehand when we looked at it sounded like way too much work yeah it sounds like a lot of work yeah it's like you know I mean we could write some Fortran code but we've already got Scala developers writing Python code you really don't want Scala developers writing Python code and Fortran code that is just wrong so now we are you telling me oh the only good vectorize libraries out there unfortunate no no I'm just thinking I wouldn't I wouldn't disagree with you because Fortran has been around long enough to where it's pretty big most of the good yeah libraries have at least a Fortran things right like there is there's a like de facto standard Fortran implementation and there is like also like a GPU implementation as well which is generally not written in Fortran right CUDA is slightly different but maybe they very much take their inspiration so you're gonna be working on vectorized operations at some point yeah you have to learn import ran and that's not no yeah so so but the nice thing with with vectorizing you have some Python is that we can write Python code that will end up using these wonderful Fortran libraries and infancy you know newer CUDA libraries and its really exciting because the traditional really expensive thing and PI spark has been getting the data from the JVM and this just really accelerates it a lot and it even opens the door to further accelerations with like shared memory buffers in the future that's it's not where we are today and spurred 2.3 but it's such a good like basic UDF vectorizing of support and 2.4 is probably gonna bring like shared memory buffers I was gonna say SIMD I mean you know you put in some D ops on these yeah yeah yeah I mean this opens up a lot of doors oh yeah no it's it's great like we're switching from like lists to like actual nice representations but our CPUs and and things are optimized for well in looking at options for deployment on the hardware that's that's driving this for sure no it's big Nvidia is no longer a video card company no they really aren't and and then they're involved in some of the Aero work as well right so yeah it's not like this is just a bunch of big data people like playing around having fun like no I don't light lines and video folks get yeah there's gonna be [Applause] some where they're out there yeah right six hey Mia by tomorrow maybe you didn't announce me thought that if it's true all right so we should get out of this subject real quick before we get into trouble so my one of my personal favorite topics because I talk about it so much it's streaming yeah and some changes you know spark has always been the micro batch young does for micro batch but there's changes coming there are um and so I mean there's only so long you can be made of fun of as the micro brush processing architecture before like one of your grad students or former grad students now at this point drinks a lot of coffee that helps just writes a new engine which is the grand tradition of spark right yeah but the the changes coming into that three for this are we can see the sources and sinks are no longer tied to the concepts of batches as directly anymore we have this idea of like inserting epochs occasionally so we can have like this flow and understand where where our records are coming from but there's also options to essentially like turn off all of the safety breaks are just like yeah let's go run it yeah power through this you don't care about data integrity it's great it's tunable consistency well there are cases for that you know Ellen IOT use cases where if you lose data along the way that's okay yeah it really doesn't matter I drop and and I think like machine learning is a great place where some of the time this can certainly be the case right I have such an overflow of data coming in it's fine if I drop it - you know percent of records on the floor if I process a few twice for updating my model it's not right right simply being able to update and respond quickly is enough of a game changer that I'll take this trade off and I want to be fair like we can get out of the microbio architecture without having to make that trade-off it's just if you wanted to go like super fast well yeah you know back in the day when I was pitching you know we had this test project on github killer whether it was all these really we were doing microbats but we're also doing discrete processing but we were using akka for that okay yeah and I think we just simplified that architecture in this case yeah now you can just use work on both sides you don't have to separate things running and any solution that says less complexity I'm all for no I I think fundamentally we've seen that general-purpose systems are essentially eating the world right like yeah you don't want to have to run three different data stores you don't have to run three different processing engines as much as I like I won I want one deployment methodology I want to understand the deployment of one type of thing yeah I don't want to have to learn 20 things because I will forget the 25 no yeah and like I mean the the just looking at their O'Reilly titles coming out there are way too many of these for anyone to keep up bright light you cannot read all of the really big data books that come out and when you're in the span of like go jogging streets yeah streaming is exploding and it's like it's getting stupid but it had to happen yeah it happened in the no sequel space we went back and then it's now doing this coalescing yeah I mean it's the way the market works right we have 100 new ideas we find out 95% of them were kind of garbage yeah and then the remaining 5% fight amongst each other and eventually two or three winners come out and yeah it's great so is this pretty steady solid or is this an I couldn't test oh god yeah don't use this production this is the questions I have to ask right yeah I know sorry I should have clarified when I say a feature is new what do you mean is this is exciting and new well like it's been run on HelloWorld like a little more than hello world a little more yeah word count yeah why we use it in all of our presentations I use word count into Twitter feed oh yeah it's a pretty much yeah but you know like if you use this in production please don't work in an industry which will kill me because I do not want to end up in one of those textbooks as like the lady that killed by our own software you remember reading those engineering oh yeah thanks to the radiation machine that killed people ya know and it's like if it killed the Creator like like you're never gonna live it down right like I don't want to die um I changed myself for a career I'm gonna do stuff that will not kill people no like there is a reason that I do analytics rather than like airplanes yeah I love airplanes but like I like not being responsible for this stuff it is really too much of a challenge for me I don't wanna think about it I could sleep at night though all the time let's let's get off the topic of people dying yeah it's pretty good very good so alright that's yeah we're not going to talk about that anymore but let's live get into something a little more cheery and that's surprisingly enough I didn't realize this was a thing but could we native support for spark and it's not really what I think of kubernetes is running spark workplace you know totally kubernetes did did not start out as running analytics work right but I think as we were talking about earlier general-purpose systems if the world and if I have like a kubernetes cluster and a young cluster I look at those two things and I go why do I have two things right I can have one thing and then it's very like you know I can do the brilliant idea of scheduling my analytics workload in my spare production capacity and that works out just fine until anything has like my spare time that I can work on side projects right ya know six hours per year between 2:00 and 3:00 in the morning oh no it's that's that's my Lucky Charms time yeah you can't have less redbull no right so no I think kubernetes support in SPARC is as exciting we maybe didn't handle it the greatest out of the bat and so there's been multiple parts of spark for kubernetes support which is like as an open-source maintainer you're like this is not a good sign this is the same that I have not succeeded on my job independent Forks yeah they don't talk to each other so oh that's horrible not so good the fault of death as we call it but it's ok we brought one of them back to the falls you know show them the good book of SF way ok I I'm sure you have no feelings about that no no we're talking about kubernetes now oh yeah sorry I'm sorry oh no so um we 14:03 we're integrating this sort of first pass with kubernetes support all right in spark and there's a bunch of really interesting things coming in this one of the things which is really interesting is one of the traditional challenges with python that we were talking about earlier is sort of library support and deploying your Python libraries on yarn right about as fun as a rusty spoon to the eyeballs like I can say that on right yes okay we good so Russell spoon eyeballs yarn Python dependencies but with k-8 it's actually a lot easier to specify containers in ways which are actually you know capable of packaging all of my life specialized Fortran code from the 70s that I do not want to rewrite and that one weird COBOL app that I'm somehow still using and so a lot of legacy going on there I mean you know like this he rules the world what like at the end of the day I'm really excited because K it's gonna make it a lot easier for us to ship sort of complicated spark applications that depend on non JVM components so what about so here's the thing that I have always seen communities awesome out yeah scaling up but about well so what's what's a fair here spark is terrible that's killing that right um it has one of the worst experiences for that there's some solutions from some vendors who I won't talk about because they no longer pay me money but you know choose talk to your vendor and ask them if they will sell you a customized solution for those um write mileage may vary yeah your mileage may vary please continue to use my employer if you do but I mean scale down is a heartbroken right and especially with spark because we tend to co-locate data alongside our executives and so there's some things we can do right we can our co-locate data inside our executives what that is about as fun as performance for the rusty spoon and eyeball again right the I accept now the rusty spoon is on a string that I have to pull over to meet from the other room right should pick a different didn't mean a new analogy but we can work on that for the next time here yeah ok that's great I'm pulling here but how do I do that with the strength yeah that's alright won't work on it ok it's fine so yeah right so but where I got distracted I am we were talking about scaling down and that's a problem because you know that's an Cassander world is the same problem yeah you can but it's he didn't um it involves a lot of coordination and streaming and data getting lost it is especially so as we were talking about earlier with streaming yeah scaling down streaming applications which you know are occasionally the kinds of apps which are more likely to experience right temporary peaks that you want to scale back down from when you're already a season is over yeah we don't have a good solution for scaling down here and this is less on the individual cluster managers and more on the way how sparkers manages its memory there's some interesting work though coming in communities or in spark so both sides actually spark an ends yarn there's some interesting things in yarn coming as well so yarn actually has this idea of decommissioning all right but it does a really poor job of communicating it right now the api's are kind of not very good and kubernetes have better ideas of communicating similar concepts different words same ideas but how many different ways are gonna run here for special well I mean yeah it's true you're not alone we're gonna use a lot of different words to describe the same concept which as I like money and it seems to be the way we build this that's true because we don't talk to each other except like every six months Sketch up a news conference okay a mailing list or something yeah so I mean so there's there's that site of it's being worked on and it's pretty exciting but on the sports side we need to do a little bit of catch-up with sort of doing the data migrations intelligently I have a PR obviously in this area that I think is pretty good what that opinion is perhaps not what one could describe as universally sure are you PR pitching no no never but if someone else is on the Apache spark PMC I would love to help me review this not more seriously I don't actually want to update this PR I just want one of the things to get in and it's it's one of the things we're all thinking about so there's a few different implementations which take different approaches they're not gonna make it for spark two three I think the k8 support is gonna go in for two I mean the KS support is in for two three and essentially there's a bunch of sort of follow-up work which we're gonna have to do sort of to catch up into four and assuming that we state of the earth is would you is there any case where you would want someone running over you and comfortable putting combinations and spark into production right now whoa no okay that's that's a fair thing so is that gonna be something that you know just previewing another topic is that something that's gonna be first class citizen in three oh yeah no I think I think it's gonna be so I think I think much before three will get there much faster it's just the idea of using a new cluster manager the first time it's merge back into master listen I'm not that cautious yeah but like ya know I have my hard limits that's that's that's one that you're probably gonna want on chest for a long time and even in not trust oh no I mean I think it's it's it's fine for things like exploratory analytics it would be a really great way to sort of test it out in your organization and see if it like finding the breaking points but I would not put my production jobs on it yeah I think that's anytime I see new features you know that's just give it a while I mean it's just shiny features is it just a general rule you see shiny features let it shine don't write yeah if you yell it you find out that it's terrible risk your job I'm shiny I mean not whatever it's fine but my resume up-to-date CARICOM yeah possibly not up to do they should update my resume should update well would give you some time that's cool all right I think this has been a really great overview on two three and potentially the end of your career but ah come on oh my god it's great I can always go back to just regular software development that's okay that has a big blending nicely blend yeah yeah you blend so bad line that's why I love having you so it's great to catch up yeah thanks a lot I really appreciate you coming in and we're gonna have to do this again soon because let's keep changing it yeah strata or where you want to catch up next wherever we are all right Bud Light Lime though LED light lab okay thanks everyone we'll see you next time thank you for joining us again for the distributed data show we love your feedback so go to the distributed data show page on data Stax Academy and tell us what you think you can also find us on the data Stax Academy YouTube channel or find our podcast on itunes google play or wherever you get great podcast while you're there make sure and subscribe so you don't miss a single episode [Music]",
    "segments": [
      {
        "start": 0.03,
        "duration": 4.17,
        "text": "welcome to another episode of the"
      },
      {
        "start": 2.31,
        "duration": 4.29,
        "text": "distributed data show brought to you by"
      },
      {
        "start": 4.2,
        "duration": 4.26,
        "text": "data Stax Academy where we bring you the"
      },
      {
        "start": 6.6,
        "duration": 4.05,
        "text": "latest news and interview technical"
      },
      {
        "start": 8.46,
        "duration": 10.23,
        "text": "experts to help you succeed at building"
      },
      {
        "start": 10.65,
        "duration": 14.31,
        "text": "large-scale distributed systems here at"
      },
      {
        "start": 18.69,
        "duration": 10.02,
        "text": "day-to-day Texas 2018 I have holy crap"
      },
      {
        "start": 24.96,
        "duration": 6.83,
        "text": "author learning spark high performance"
      },
      {
        "start": 28.71,
        "duration": 5.369,
        "text": "park also developer advocate at Google"
      },
      {
        "start": 31.79,
        "duration": 5.26,
        "text": "thanks for bein here no it's really"
      },
      {
        "start": 34.079,
        "duration": 5.761,
        "text": "great to be here so it's time for us to"
      },
      {
        "start": 37.05,
        "duration": 4.89,
        "text": "catch up once again yeah I mean it's"
      },
      {
        "start": 39.84,
        "duration": 4.5,
        "text": "it's been six months all of the api's of"
      },
      {
        "start": 41.94,
        "duration": 3.84,
        "text": "chain everything's changed yeah of"
      },
      {
        "start": 44.34,
        "duration": 6.149,
        "text": "course we're going to talk to put spark"
      },
      {
        "start": 45.78,
        "duration": 6.95,
        "text": "see the moving project of spark it's"
      },
      {
        "start": 50.489,
        "duration": 5.221,
        "text": "getting a little more stable you know"
      },
      {
        "start": 52.73,
        "duration": 14.34,
        "text": "yeah it's a stable core idea of a"
      },
      {
        "start": 55.71,
        "duration": 13.56,
        "text": "support contract yeah we do we do"
      },
      {
        "start": 67.07,
        "duration": 5.89,
        "text": "there's a lot of exciting news AP"
      },
      {
        "start": 69.27,
        "duration": 5.22,
        "text": "estimating spark 2.3 do you have any"
      },
      {
        "start": 72.96,
        "duration": 6.99,
        "text": "specific ones you wanted to like tell"
      },
      {
        "start": 74.49,
        "duration": 6.51,
        "text": "them - well first I mean why do we have"
      },
      {
        "start": 79.95,
        "duration": 3.809,
        "text": "to keep changing things"
      },
      {
        "start": 81.0,
        "duration": 5.61,
        "text": "what is the VG isn't there a stability"
      },
      {
        "start": 83.759,
        "duration": 4.771,
        "text": "moment and we can have a spark or is it"
      },
      {
        "start": 86.61,
        "duration": 3.83,
        "text": "just what is it I mean it's a good"
      },
      {
        "start": 88.53,
        "duration": 6.27,
        "text": "question um"
      },
      {
        "start": 90.44,
        "duration": 6.04,
        "text": "and I think when wooden wrists staple we"
      },
      {
        "start": 94.8,
        "duration": 4.2,
        "text": "won't be interesting anymore like"
      },
      {
        "start": 96.48,
        "duration": 4.32,
        "text": "fundamentally we will probably reach her"
      },
      {
        "start": 99.0,
        "duration": 3.15,
        "text": "point or spark becomes infrastructure"
      },
      {
        "start": 100.8,
        "duration": 3.81,
        "text": "that you don't have to think about at"
      },
      {
        "start": 102.15,
        "duration": 4.29,
        "text": "that point I need to find a new job but"
      },
      {
        "start": 104.61,
        "duration": 3.54,
        "text": "you know everything gets a lot easier"
      },
      {
        "start": 106.44,
        "duration": 5.31,
        "text": "well I don't think we're there yet right"
      },
      {
        "start": 108.15,
        "duration": 5.61,
        "text": "there there are a lot of things which we"
      },
      {
        "start": 111.75,
        "duration": 5.31,
        "text": "are still relearning from the 70s to"
      },
      {
        "start": 113.76,
        "duration": 4.89,
        "text": "implement on today's hardware and you"
      },
      {
        "start": 117.06,
        "duration": 12.449,
        "text": "know then we still have to catch up with"
      },
      {
        "start": 118.65,
        "duration": 14.029,
        "text": "the a dress but we add another layer to"
      },
      {
        "start": 129.509,
        "duration": 3.17,
        "text": "keep things exciting"
      },
      {
        "start": 148.31,
        "duration": 30.459,
        "text": "yeah no it's good yeah totally so the"
      },
      {
        "start": 177.12,
        "duration": 4.38,
        "text": "biggest most exciting change for pi"
      },
      {
        "start": 178.769,
        "duration": 4.951,
        "text": "spark is the vectorize do DFS coming in"
      },
      {
        "start": 181.5,
        "duration": 3.72,
        "text": "spar two to three and they're powered by"
      },
      {
        "start": 183.72,
        "duration": 5.37,
        "text": "apache arrow which is this really"
      },
      {
        "start": 185.22,
        "duration": 5.67,
        "text": "exciting project from West McKinney the"
      },
      {
        "start": 189.09,
        "duration": 5.55,
        "text": "folks at 2 Sigma some of the folks said"
      },
      {
        "start": 190.89,
        "duration": 6.96,
        "text": "my former employer IBM and some of the"
      },
      {
        "start": 194.64,
        "duration": 5.93,
        "text": "data bricks and it's it's okay Jake"
      },
      {
        "start": 197.85,
        "duration": 5.25,
        "text": "Luciana is on the PMC so there's it's"
      },
      {
        "start": 200.57,
        "duration": 4.93,
        "text": "it's a really great cross industry"
      },
      {
        "start": 203.1,
        "duration": 4.8,
        "text": "collaboration right and it gives us this"
      },
      {
        "start": 205.5,
        "duration": 5.13,
        "text": "was really nice in memory format for"
      },
      {
        "start": 207.9,
        "duration": 5.28,
        "text": "representing data but also representing"
      },
      {
        "start": 210.63,
        "duration": 4.859,
        "text": "common our data which yeah we care about"
      },
      {
        "start": 213.18,
        "duration": 6.05,
        "text": "and it gives us a nice way of"
      },
      {
        "start": 215.489,
        "duration": 6.441,
        "text": "transferring data from the JVM to Python"
      },
      {
        "start": 219.23,
        "duration": 4.5,
        "text": "and back and it also"
      },
      {
        "start": 221.93,
        "duration": 5.52,
        "text": "makes it easier for us to implement"
      },
      {
        "start": 223.73,
        "duration": 4.53,
        "text": "vectorize operational spark which"
      },
      {
        "start": 227.45,
        "duration": 3.209,
        "text": "beforehand"
      },
      {
        "start": 228.26,
        "duration": 3.449,
        "text": "when we looked at it sounded like way"
      },
      {
        "start": 230.659,
        "duration": 3.0,
        "text": "too much work"
      },
      {
        "start": 231.709,
        "duration": 4.86,
        "text": "yeah it sounds like a lot of work yeah"
      },
      {
        "start": 233.659,
        "duration": 7.2,
        "text": "it's like you know I mean we could write"
      },
      {
        "start": 236.569,
        "duration": 6.9,
        "text": "some Fortran code but we've already got"
      },
      {
        "start": 240.859,
        "duration": 4.05,
        "text": "Scala developers writing Python code you"
      },
      {
        "start": 243.469,
        "duration": 3.63,
        "text": "really don't want Scala developers"
      },
      {
        "start": 244.909,
        "duration": 5.011,
        "text": "writing Python code and Fortran code"
      },
      {
        "start": 247.099,
        "duration": 4.651,
        "text": "that is just wrong so now we are you"
      },
      {
        "start": 249.92,
        "duration": 4.679,
        "text": "telling me oh the only good vectorize"
      },
      {
        "start": 251.75,
        "duration": 4.169,
        "text": "libraries out there unfortunate no no"
      },
      {
        "start": 254.599,
        "duration": 2.85,
        "text": "I'm just thinking I wouldn't I wouldn't"
      },
      {
        "start": 255.919,
        "duration": 2.97,
        "text": "disagree with you because Fortran has"
      },
      {
        "start": 257.449,
        "duration": 4.951,
        "text": "been around long enough to where it's"
      },
      {
        "start": 258.889,
        "duration": 5.701,
        "text": "pretty big most of the good yeah"
      },
      {
        "start": 262.4,
        "duration": 3.63,
        "text": "libraries have at least a Fortran things"
      },
      {
        "start": 264.59,
        "duration": 3.24,
        "text": "right like there is there's a like de"
      },
      {
        "start": 266.03,
        "duration": 3.72,
        "text": "facto standard Fortran implementation"
      },
      {
        "start": 267.83,
        "duration": 3.899,
        "text": "and there is like also like a GPU"
      },
      {
        "start": 269.75,
        "duration": 3.87,
        "text": "implementation as well which is"
      },
      {
        "start": 271.729,
        "duration": 4.591,
        "text": "generally not written in Fortran right"
      },
      {
        "start": 273.62,
        "duration": 5.85,
        "text": "CUDA is slightly different but maybe"
      },
      {
        "start": 276.32,
        "duration": 5.31,
        "text": "they very much take their inspiration so"
      },
      {
        "start": 279.47,
        "duration": 4.86,
        "text": "you're gonna be working on vectorized"
      },
      {
        "start": 281.63,
        "duration": 6.529,
        "text": "operations at some point yeah you have"
      },
      {
        "start": 284.33,
        "duration": 3.829,
        "text": "to learn import ran and that's not no"
      },
      {
        "start": 293.889,
        "duration": 5.141,
        "text": "yeah so so but the nice thing with with"
      },
      {
        "start": 297.5,
        "duration": 3.06,
        "text": "vectorizing you have some Python is that"
      },
      {
        "start": 299.03,
        "duration": 3.84,
        "text": "we can write Python code that will end"
      },
      {
        "start": 300.56,
        "duration": 3.99,
        "text": "up using these wonderful Fortran"
      },
      {
        "start": 302.87,
        "duration": 5.25,
        "text": "libraries and infancy"
      },
      {
        "start": 304.55,
        "duration": 7.049,
        "text": "you know newer CUDA libraries and its"
      },
      {
        "start": 308.12,
        "duration": 5.669,
        "text": "really exciting because the traditional"
      },
      {
        "start": 311.599,
        "duration": 5.011,
        "text": "really expensive thing and PI spark has"
      },
      {
        "start": 313.789,
        "duration": 5.25,
        "text": "been getting the data from the JVM and"
      },
      {
        "start": 316.61,
        "duration": 4.619,
        "text": "this just really accelerates it a lot"
      },
      {
        "start": 319.039,
        "duration": 3.991,
        "text": "and it even opens the door to further"
      },
      {
        "start": 321.229,
        "duration": 5.101,
        "text": "accelerations with like shared memory"
      },
      {
        "start": 323.03,
        "duration": 5.729,
        "text": "buffers in the future that's it's not"
      },
      {
        "start": 326.33,
        "duration": 5.04,
        "text": "where we are today and spurred 2.3 but"
      },
      {
        "start": 328.759,
        "duration": 5.071,
        "text": "it's such a good like basic UDF"
      },
      {
        "start": 331.37,
        "duration": 4.049,
        "text": "vectorizing of support and 2.4 is"
      },
      {
        "start": 333.83,
        "duration": 5.369,
        "text": "probably gonna bring like shared memory"
      },
      {
        "start": 335.419,
        "duration": 5.851,
        "text": "buffers I was gonna say SIMD I mean you"
      },
      {
        "start": 339.199,
        "duration": 4.111,
        "text": "know you put in some D ops on these yeah"
      },
      {
        "start": 341.27,
        "duration": 4.649,
        "text": "yeah yeah I mean this opens up a lot of"
      },
      {
        "start": 343.31,
        "duration": 6.27,
        "text": "doors oh yeah no it's it's great like"
      },
      {
        "start": 345.919,
        "duration": 6.841,
        "text": "we're switching from like lists to like"
      },
      {
        "start": 349.58,
        "duration": 3.97,
        "text": "actual nice representations but our CPUs"
      },
      {
        "start": 352.76,
        "duration": 3.64,
        "text": "and"
      },
      {
        "start": 353.55,
        "duration": 5.7,
        "text": "and things are optimized for well in"
      },
      {
        "start": 356.4,
        "duration": 5.579,
        "text": "looking at options for deployment on the"
      },
      {
        "start": 359.25,
        "duration": 5.97,
        "text": "hardware that's that's driving this for"
      },
      {
        "start": 361.979,
        "duration": 5.581,
        "text": "sure no it's big Nvidia is no longer a"
      },
      {
        "start": 365.22,
        "duration": 4.14,
        "text": "video card company no they really aren't"
      },
      {
        "start": 367.56,
        "duration": 3.72,
        "text": "and and then they're involved in some of"
      },
      {
        "start": 369.36,
        "duration": 3.299,
        "text": "the Aero work as well right so yeah it's"
      },
      {
        "start": 371.28,
        "duration": 3.3,
        "text": "not like this is just a bunch of big"
      },
      {
        "start": 372.659,
        "duration": 7.051,
        "text": "data people like playing around having"
      },
      {
        "start": 374.58,
        "duration": 8.989,
        "text": "fun like no I don't light lines and"
      },
      {
        "start": 379.71,
        "duration": 3.859,
        "text": "video folks get yeah there's gonna be"
      },
      {
        "start": 388.51,
        "duration": 3.1,
        "text": "[Applause]"
      },
      {
        "start": 392.12,
        "duration": 5.62,
        "text": "some where they're out there yeah right"
      },
      {
        "start": 395.25,
        "duration": 4.849,
        "text": "six hey Mia by tomorrow maybe you didn't"
      },
      {
        "start": 397.74,
        "duration": 4.35,
        "text": "announce me thought that if it's true"
      },
      {
        "start": 400.099,
        "duration": 3.341,
        "text": "all right so we should get out of this"
      },
      {
        "start": 402.09,
        "duration": 3.6,
        "text": "subject real quick before we get into"
      },
      {
        "start": 403.44,
        "duration": 4.65,
        "text": "trouble so my one of my personal"
      },
      {
        "start": 405.69,
        "duration": 6.029,
        "text": "favorite topics because I talk about it"
      },
      {
        "start": 408.09,
        "duration": 5.879,
        "text": "so much it's streaming yeah and some"
      },
      {
        "start": 411.719,
        "duration": 4.861,
        "text": "changes you know spark has always been"
      },
      {
        "start": 413.969,
        "duration": 5.07,
        "text": "the micro batch young does for micro"
      },
      {
        "start": 416.58,
        "duration": 5.76,
        "text": "batch but there's changes coming there"
      },
      {
        "start": 419.039,
        "duration": 4.891,
        "text": "are um and so I mean there's only so"
      },
      {
        "start": 422.34,
        "duration": 2.93,
        "text": "long you can be made of fun of as the"
      },
      {
        "start": 423.93,
        "duration": 5.01,
        "text": "micro brush processing architecture"
      },
      {
        "start": 425.27,
        "duration": 5.799,
        "text": "before like one of your grad students or"
      },
      {
        "start": 428.94,
        "duration": 5.819,
        "text": "former grad students now at this point"
      },
      {
        "start": 431.069,
        "duration": 6.511,
        "text": "drinks a lot of coffee that helps just"
      },
      {
        "start": 434.759,
        "duration": 6.84,
        "text": "writes a new engine which is the grand"
      },
      {
        "start": 437.58,
        "duration": 5.85,
        "text": "tradition of spark right yeah but the"
      },
      {
        "start": 441.599,
        "duration": 3.6,
        "text": "the changes coming into that three for"
      },
      {
        "start": 443.43,
        "duration": 4.979,
        "text": "this are we can see the sources and"
      },
      {
        "start": 445.199,
        "duration": 5.881,
        "text": "sinks are no longer tied to the concepts"
      },
      {
        "start": 448.409,
        "duration": 5.701,
        "text": "of batches as directly anymore we have"
      },
      {
        "start": 451.08,
        "duration": 5.04,
        "text": "this idea of like inserting epochs"
      },
      {
        "start": 454.11,
        "duration": 3.809,
        "text": "occasionally so we can have like this"
      },
      {
        "start": 456.12,
        "duration": 5.9,
        "text": "flow and understand where where our"
      },
      {
        "start": 457.919,
        "duration": 7.5,
        "text": "records are coming from but there's also"
      },
      {
        "start": 462.02,
        "duration": 5.41,
        "text": "options to essentially like turn off all"
      },
      {
        "start": 465.419,
        "duration": 3.611,
        "text": "of the safety breaks are just like yeah"
      },
      {
        "start": 467.43,
        "duration": 3.73,
        "text": "let's go run it yeah"
      },
      {
        "start": 469.03,
        "duration": 4.71,
        "text": "power through this you don't care about"
      },
      {
        "start": 471.16,
        "duration": 4.98,
        "text": "data integrity it's great it's tunable"
      },
      {
        "start": 473.74,
        "duration": 5.25,
        "text": "consistency well there are cases for"
      },
      {
        "start": 476.14,
        "duration": 5.82,
        "text": "that you know Ellen IOT use cases where"
      },
      {
        "start": 478.99,
        "duration": 5.16,
        "text": "if you lose data along the way that's"
      },
      {
        "start": 481.96,
        "duration": 4.56,
        "text": "okay yeah it really doesn't matter I"
      },
      {
        "start": 484.15,
        "duration": 4.29,
        "text": "drop and and I think like machine"
      },
      {
        "start": 486.52,
        "duration": 3.09,
        "text": "learning is a great place where some of"
      },
      {
        "start": 488.44,
        "duration": 3.69,
        "text": "the time this can certainly be the case"
      },
      {
        "start": 489.61,
        "duration": 5.31,
        "text": "right I have such an overflow of data"
      },
      {
        "start": 492.13,
        "duration": 4.74,
        "text": "coming in it's fine if I drop it - you"
      },
      {
        "start": 494.92,
        "duration": 4.53,
        "text": "know percent of records on the floor if"
      },
      {
        "start": 496.87,
        "duration": 5.67,
        "text": "I process a few twice for updating my"
      },
      {
        "start": 499.45,
        "duration": 5.82,
        "text": "model it's not right right simply being"
      },
      {
        "start": 502.54,
        "duration": 4.44,
        "text": "able to update and respond quickly is"
      },
      {
        "start": 505.27,
        "duration": 4.59,
        "text": "enough of a game changer that I'll take"
      },
      {
        "start": 506.98,
        "duration": 4.44,
        "text": "this trade off and I want to be fair"
      },
      {
        "start": 509.86,
        "duration": 3.93,
        "text": "like we can get out of the microbio"
      },
      {
        "start": 511.42,
        "duration": 4.08,
        "text": "architecture without having to make that"
      },
      {
        "start": 513.79,
        "duration": 5.28,
        "text": "trade-off it's just if you wanted to go"
      },
      {
        "start": 515.5,
        "duration": 5.97,
        "text": "like super fast well yeah you know back"
      },
      {
        "start": 519.07,
        "duration": 5.93,
        "text": "in the day when I was pitching you know"
      },
      {
        "start": 521.47,
        "duration": 5.85,
        "text": "we had this test project on github"
      },
      {
        "start": 525.0,
        "duration": 3.79,
        "text": "killer whether it was all these really"
      },
      {
        "start": 527.32,
        "duration": 3.0,
        "text": "we were doing microbats but we're also"
      },
      {
        "start": 528.79,
        "duration": 3.84,
        "text": "doing discrete processing but we were"
      },
      {
        "start": 530.32,
        "duration": 3.93,
        "text": "using akka for that okay yeah and I"
      },
      {
        "start": 532.63,
        "duration": 3.27,
        "text": "think we just simplified that"
      },
      {
        "start": 534.25,
        "duration": 3.15,
        "text": "architecture in this case yeah now you"
      },
      {
        "start": 535.9,
        "duration": 3.0,
        "text": "can just use work on both sides you"
      },
      {
        "start": 537.4,
        "duration": 4.46,
        "text": "don't have to separate things running"
      },
      {
        "start": 538.9,
        "duration": 4.11,
        "text": "and any solution that says less"
      },
      {
        "start": 541.86,
        "duration": 3.52,
        "text": "complexity"
      },
      {
        "start": 543.01,
        "duration": 4.8,
        "text": "I'm all for no I I think fundamentally"
      },
      {
        "start": 545.38,
        "duration": 4.35,
        "text": "we've seen that general-purpose systems"
      },
      {
        "start": 547.81,
        "duration": 3.96,
        "text": "are essentially eating the world right"
      },
      {
        "start": 549.73,
        "duration": 3.66,
        "text": "like yeah you don't want to have to run"
      },
      {
        "start": 551.77,
        "duration": 3.03,
        "text": "three different data stores you don't"
      },
      {
        "start": 553.39,
        "duration": 6.48,
        "text": "have to run three different processing"
      },
      {
        "start": 554.8,
        "duration": 7.74,
        "text": "engines as much as I like I won I want"
      },
      {
        "start": 559.87,
        "duration": 5.1,
        "text": "one deployment methodology I want to"
      },
      {
        "start": 562.54,
        "duration": 4.53,
        "text": "understand the deployment of one type of"
      },
      {
        "start": 564.97,
        "duration": 4.74,
        "text": "thing yeah I don't want to have to learn"
      },
      {
        "start": 567.07,
        "duration": 5.64,
        "text": "20 things because I will forget the 25"
      },
      {
        "start": 569.71,
        "duration": 4.53,
        "text": "no yeah and like I mean the the just"
      },
      {
        "start": 572.71,
        "duration": 3.48,
        "text": "looking at their O'Reilly titles coming"
      },
      {
        "start": 574.24,
        "duration": 4.8,
        "text": "out there are way too many of these for"
      },
      {
        "start": 576.19,
        "duration": 4.62,
        "text": "anyone to keep up bright light you"
      },
      {
        "start": 579.04,
        "duration": 3.66,
        "text": "cannot read all of the really big data"
      },
      {
        "start": 580.81,
        "duration": 4.53,
        "text": "books that come out and when you're in"
      },
      {
        "start": 582.7,
        "duration": 6.62,
        "text": "the span of like go jogging streets yeah"
      },
      {
        "start": 585.34,
        "duration": 7.08,
        "text": "streaming is exploding and it's like"
      },
      {
        "start": 589.32,
        "duration": 6.15,
        "text": "it's getting stupid but it had to happen"
      },
      {
        "start": 592.42,
        "duration": 5.87,
        "text": "yeah it happened in the no sequel space"
      },
      {
        "start": 595.47,
        "duration": 6.03,
        "text": "we went back and then it's now doing"
      },
      {
        "start": 598.29,
        "duration": 4.71,
        "text": "this coalescing yeah I mean it's the way"
      },
      {
        "start": 601.5,
        "duration": 3.78,
        "text": "the market works right we have 100 new"
      },
      {
        "start": 603.0,
        "duration": 4.44,
        "text": "ideas we find out 95% of them were kind"
      },
      {
        "start": 605.28,
        "duration": 4.02,
        "text": "of garbage yeah and then the remaining"
      },
      {
        "start": 607.44,
        "duration": 4.8,
        "text": "5% fight amongst each other and"
      },
      {
        "start": 609.3,
        "duration": 7.77,
        "text": "eventually two or three winners come out"
      },
      {
        "start": 612.24,
        "duration": 7.74,
        "text": "and yeah it's great so is this pretty"
      },
      {
        "start": 617.07,
        "duration": 5.04,
        "text": "steady solid or is this an I couldn't"
      },
      {
        "start": 619.98,
        "duration": 5.04,
        "text": "test oh god yeah don't use this"
      },
      {
        "start": 622.11,
        "duration": 4.86,
        "text": "production this is the questions I have"
      },
      {
        "start": 625.02,
        "duration": 3.42,
        "text": "to ask right yeah I know sorry I should"
      },
      {
        "start": 626.97,
        "duration": 3.3,
        "text": "have clarified when I say a feature is"
      },
      {
        "start": 628.44,
        "duration": 3.9,
        "text": "new what do you mean is this is exciting"
      },
      {
        "start": 630.27,
        "duration": 6.48,
        "text": "and new well like it's been run on"
      },
      {
        "start": 632.34,
        "duration": 8.93,
        "text": "HelloWorld like a little more than hello"
      },
      {
        "start": 636.75,
        "duration": 4.52,
        "text": "world a little more yeah word count yeah"
      },
      {
        "start": 642.86,
        "duration": 4.48,
        "text": "why we use it in all of our"
      },
      {
        "start": 644.67,
        "duration": 5.63,
        "text": "presentations I use word count into"
      },
      {
        "start": 647.34,
        "duration": 6.48,
        "text": "Twitter feed oh yeah it's a pretty much"
      },
      {
        "start": 650.3,
        "duration": 4.41,
        "text": "yeah but you know like if you use this"
      },
      {
        "start": 653.82,
        "duration": 3.27,
        "text": "in production"
      },
      {
        "start": 654.71,
        "duration": 4.81,
        "text": "please don't work in an industry which"
      },
      {
        "start": 657.09,
        "duration": 4.17,
        "text": "will kill me because I do not want to"
      },
      {
        "start": 659.52,
        "duration": 3.54,
        "text": "end up in one of those textbooks as like"
      },
      {
        "start": 661.26,
        "duration": 3.81,
        "text": "the lady that killed by our own software"
      },
      {
        "start": 663.06,
        "duration": 4.68,
        "text": "you remember reading those engineering"
      },
      {
        "start": 665.07,
        "duration": 3.42,
        "text": "oh yeah thanks to the radiation machine"
      },
      {
        "start": 667.74,
        "duration": 3.45,
        "text": "that killed people"
      },
      {
        "start": 668.49,
        "duration": 5.07,
        "text": "ya know and it's like if it killed the"
      },
      {
        "start": 671.19,
        "duration": 4.05,
        "text": "Creator like like you're never gonna"
      },
      {
        "start": 673.56,
        "duration": 5.13,
        "text": "live it down right like I don't want to"
      },
      {
        "start": 675.24,
        "duration": 4.86,
        "text": "die um I changed myself for a career I'm"
      },
      {
        "start": 678.69,
        "duration": 3.21,
        "text": "gonna do stuff that will not kill people"
      },
      {
        "start": 680.1,
        "duration": 3.63,
        "text": "no like there is a reason that I do"
      },
      {
        "start": 681.9,
        "duration": 4.83,
        "text": "analytics rather than like airplanes"
      },
      {
        "start": 683.73,
        "duration": 5.1,
        "text": "yeah I love airplanes but like I like"
      },
      {
        "start": 686.73,
        "duration": 3.9,
        "text": "not being responsible for this stuff it"
      },
      {
        "start": 688.83,
        "duration": 3.0,
        "text": "is really too much of a challenge for me"
      },
      {
        "start": 690.63,
        "duration": 3.12,
        "text": "I don't wanna think about it"
      },
      {
        "start": 691.83,
        "duration": 3.75,
        "text": "I could sleep at night though all the"
      },
      {
        "start": 693.75,
        "duration": 3.51,
        "text": "time let's let's get off the topic of"
      },
      {
        "start": 695.58,
        "duration": 4.259,
        "text": "people dying yeah it's pretty good very"
      },
      {
        "start": 697.26,
        "duration": 3.84,
        "text": "good so alright that's yeah we're not"
      },
      {
        "start": 699.839,
        "duration": 2.821,
        "text": "going to talk about that anymore but"
      },
      {
        "start": 701.1,
        "duration": 5.16,
        "text": "let's live get into something a little"
      },
      {
        "start": 702.66,
        "duration": 5.04,
        "text": "more cheery and that's surprisingly"
      },
      {
        "start": 706.26,
        "duration": 3.81,
        "text": "enough I didn't realize this was a thing"
      },
      {
        "start": 707.7,
        "duration": 4.46,
        "text": "but could we native support for spark"
      },
      {
        "start": 710.07,
        "duration": 4.05,
        "text": "and"
      },
      {
        "start": 712.16,
        "duration": 3.91,
        "text": "it's not really what I think of"
      },
      {
        "start": 714.12,
        "duration": 3.93,
        "text": "kubernetes is running spark workplace"
      },
      {
        "start": 716.07,
        "duration": 3.9,
        "text": "you know totally kubernetes did did not"
      },
      {
        "start": 718.05,
        "duration": 5.91,
        "text": "start out as running analytics work"
      },
      {
        "start": 719.97,
        "duration": 6.27,
        "text": "right but I think as we were talking"
      },
      {
        "start": 723.96,
        "duration": 4.38,
        "text": "about earlier general-purpose systems if"
      },
      {
        "start": 726.24,
        "duration": 4.53,
        "text": "the world and if I have like a"
      },
      {
        "start": 728.34,
        "duration": 3.99,
        "text": "kubernetes cluster and a young cluster I"
      },
      {
        "start": 730.77,
        "duration": 3.27,
        "text": "look at those two things and I go why do"
      },
      {
        "start": 732.33,
        "duration": 4.17,
        "text": "I have two things right I can have one"
      },
      {
        "start": 734.04,
        "duration": 6.18,
        "text": "thing and then it's very like you know I"
      },
      {
        "start": 736.5,
        "duration": 6.08,
        "text": "can do the brilliant idea of scheduling"
      },
      {
        "start": 740.22,
        "duration": 4.86,
        "text": "my analytics workload in my spare"
      },
      {
        "start": 742.58,
        "duration": 4.21,
        "text": "production capacity and that works out"
      },
      {
        "start": 745.08,
        "duration": 3.3,
        "text": "just fine until anything has like my"
      },
      {
        "start": 746.79,
        "duration": 4.32,
        "text": "spare time that I can work on side"
      },
      {
        "start": 748.38,
        "duration": 4.8,
        "text": "projects right ya know six hours per"
      },
      {
        "start": 751.11,
        "duration": 2.58,
        "text": "year between 2:00 and 3:00 in the"
      },
      {
        "start": 753.18,
        "duration": 5.01,
        "text": "morning"
      },
      {
        "start": 753.69,
        "duration": 8.75,
        "text": "oh no it's that's that's my Lucky Charms"
      },
      {
        "start": 758.19,
        "duration": 7.05,
        "text": "time yeah you can't have less redbull no"
      },
      {
        "start": 762.44,
        "duration": 6.82,
        "text": "right so no I think kubernetes support"
      },
      {
        "start": 765.24,
        "duration": 7.22,
        "text": "in SPARC is as exciting we maybe didn't"
      },
      {
        "start": 769.26,
        "duration": 6.3,
        "text": "handle it the greatest out of the bat"
      },
      {
        "start": 772.46,
        "duration": 5.08,
        "text": "and so there's been multiple parts of"
      },
      {
        "start": 775.56,
        "duration": 4.23,
        "text": "spark for kubernetes support which is"
      },
      {
        "start": 777.54,
        "duration": 4.89,
        "text": "like as an open-source maintainer you're"
      },
      {
        "start": 779.79,
        "duration": 4.77,
        "text": "like this is not a good sign this is the"
      },
      {
        "start": 782.43,
        "duration": 4.26,
        "text": "same that I have not succeeded on my job"
      },
      {
        "start": 784.56,
        "duration": 3.75,
        "text": "independent Forks yeah they don't talk"
      },
      {
        "start": 786.69,
        "duration": 3.63,
        "text": "to each other so oh that's horrible"
      },
      {
        "start": 788.31,
        "duration": 4.89,
        "text": "not so good the fault of death as we"
      },
      {
        "start": 790.32,
        "duration": 3.9,
        "text": "call it but it's ok we brought one of"
      },
      {
        "start": 793.2,
        "duration": 3.45,
        "text": "them back to the falls"
      },
      {
        "start": 794.22,
        "duration": 7.47,
        "text": "you know show them the good book of SF"
      },
      {
        "start": 796.65,
        "duration": 11.31,
        "text": "way ok I I'm sure you have no feelings"
      },
      {
        "start": 801.69,
        "duration": 9.18,
        "text": "about that no no we're talking about"
      },
      {
        "start": 807.96,
        "duration": 10.26,
        "text": "kubernetes now oh yeah sorry I'm sorry"
      },
      {
        "start": 810.87,
        "duration": 9.21,
        "text": "oh no so um we 14:03 we're integrating"
      },
      {
        "start": 818.22,
        "duration": 4.71,
        "text": "this sort of first pass with kubernetes"
      },
      {
        "start": 820.08,
        "duration": 3.87,
        "text": "support all right in spark and there's a"
      },
      {
        "start": 822.93,
        "duration": 3.42,
        "text": "bunch of really interesting things"
      },
      {
        "start": 823.95,
        "duration": 5.91,
        "text": "coming in this one of the things which"
      },
      {
        "start": 826.35,
        "duration": 5.58,
        "text": "is really interesting is one of the"
      },
      {
        "start": 829.86,
        "duration": 3.6,
        "text": "traditional challenges with python that"
      },
      {
        "start": 831.93,
        "duration": 3.66,
        "text": "we were talking about earlier is sort of"
      },
      {
        "start": 833.46,
        "duration": 4.5,
        "text": "library support and deploying your"
      },
      {
        "start": 835.59,
        "duration": 5.07,
        "text": "Python libraries on yarn right about as"
      },
      {
        "start": 837.96,
        "duration": 4.99,
        "text": "fun as a rusty spoon to the eyeballs"
      },
      {
        "start": 840.66,
        "duration": 4.57,
        "text": "like I can say that on"
      },
      {
        "start": 842.95,
        "duration": 3.03,
        "text": "right yes okay we good so Russell spoon"
      },
      {
        "start": 845.23,
        "duration": 3.66,
        "text": "eyeballs"
      },
      {
        "start": 845.98,
        "duration": 6.3,
        "text": "yarn Python dependencies but with k-8"
      },
      {
        "start": 848.89,
        "duration": 5.76,
        "text": "it's actually a lot easier to specify"
      },
      {
        "start": 852.28,
        "duration": 5.07,
        "text": "containers in ways which are actually"
      },
      {
        "start": 854.65,
        "duration": 3.36,
        "text": "you know capable of packaging all of my"
      },
      {
        "start": 857.35,
        "duration": 3.0,
        "text": "life"
      },
      {
        "start": 858.01,
        "duration": 4.68,
        "text": "specialized Fortran code from the 70s"
      },
      {
        "start": 860.35,
        "duration": 4.14,
        "text": "that I do not want to rewrite and that"
      },
      {
        "start": 862.69,
        "duration": 4.95,
        "text": "one weird COBOL app that I'm somehow"
      },
      {
        "start": 864.49,
        "duration": 4.8,
        "text": "still using and so a lot of legacy going"
      },
      {
        "start": 867.64,
        "duration": 2.64,
        "text": "on there I mean you know like this he"
      },
      {
        "start": 869.29,
        "duration": 3.66,
        "text": "rules the world"
      },
      {
        "start": 870.28,
        "duration": 5.07,
        "text": "what like at the end of the day I'm"
      },
      {
        "start": 872.95,
        "duration": 5.1,
        "text": "really excited because K it's gonna make"
      },
      {
        "start": 875.35,
        "duration": 4.65,
        "text": "it a lot easier for us to ship sort of"
      },
      {
        "start": 878.05,
        "duration": 5.52,
        "text": "complicated spark applications that"
      },
      {
        "start": 880.0,
        "duration": 5.25,
        "text": "depend on non JVM components so what"
      },
      {
        "start": 883.57,
        "duration": 3.81,
        "text": "about so here's the thing that I have"
      },
      {
        "start": 885.25,
        "duration": 6.93,
        "text": "always seen communities awesome out yeah"
      },
      {
        "start": 887.38,
        "duration": 7.95,
        "text": "scaling up but about well so what's"
      },
      {
        "start": 892.18,
        "duration": 6.33,
        "text": "what's a fair here spark is terrible"
      },
      {
        "start": 895.33,
        "duration": 5.03,
        "text": "that's killing that right um it has one"
      },
      {
        "start": 898.51,
        "duration": 5.37,
        "text": "of the worst experiences for that"
      },
      {
        "start": 900.36,
        "duration": 5.02,
        "text": "there's some solutions from some vendors"
      },
      {
        "start": 903.88,
        "duration": 2.75,
        "text": "who I won't talk about because they no"
      },
      {
        "start": 905.38,
        "duration": 5.28,
        "text": "longer pay me money"
      },
      {
        "start": 906.63,
        "duration": 6.07,
        "text": "but you know choose talk to your vendor"
      },
      {
        "start": 910.66,
        "duration": 5.72,
        "text": "and ask them if they will sell you a"
      },
      {
        "start": 912.7,
        "duration": 5.1,
        "text": "customized solution for those um write"
      },
      {
        "start": 916.38,
        "duration": 3.46,
        "text": "mileage may vary"
      },
      {
        "start": 917.8,
        "duration": 5.75,
        "text": "yeah your mileage may vary please"
      },
      {
        "start": 919.84,
        "duration": 6.33,
        "text": "continue to use my employer if you do"
      },
      {
        "start": 923.55,
        "duration": 5.08,
        "text": "but I mean scale down is a heartbroken"
      },
      {
        "start": 926.17,
        "duration": 5.52,
        "text": "right and especially with spark because"
      },
      {
        "start": 928.63,
        "duration": 5.4,
        "text": "we tend to co-locate data alongside our"
      },
      {
        "start": 931.69,
        "duration": 4.41,
        "text": "executives and so there's some things we"
      },
      {
        "start": 934.03,
        "duration": 4.71,
        "text": "can do right we can our co-locate data"
      },
      {
        "start": 936.1,
        "duration": 4.32,
        "text": "inside our executives what that is about"
      },
      {
        "start": 938.74,
        "duration": 3.3,
        "text": "as fun as performance for the rusty"
      },
      {
        "start": 940.42,
        "duration": 3.84,
        "text": "spoon and eyeball again right the I"
      },
      {
        "start": 942.04,
        "duration": 3.75,
        "text": "accept now the rusty spoon is on a"
      },
      {
        "start": 944.26,
        "duration": 4.59,
        "text": "string that I have to pull over to meet"
      },
      {
        "start": 945.79,
        "duration": 5.07,
        "text": "from the other room right should pick a"
      },
      {
        "start": 948.85,
        "duration": 3.15,
        "text": "different didn't mean a new analogy but"
      },
      {
        "start": 950.86,
        "duration": 3.51,
        "text": "we can work on that for the next time"
      },
      {
        "start": 952.0,
        "duration": 4.92,
        "text": "here yeah ok that's great I'm pulling"
      },
      {
        "start": 954.37,
        "duration": 4.8,
        "text": "here but how do I do that with the"
      },
      {
        "start": 956.92,
        "duration": 5.94,
        "text": "strength yeah that's alright won't work"
      },
      {
        "start": 959.17,
        "duration": 5.67,
        "text": "on it ok it's fine so yeah right so but"
      },
      {
        "start": 962.86,
        "duration": 3.54,
        "text": "where I got distracted"
      },
      {
        "start": 964.84,
        "duration": 3.63,
        "text": "I am we were talking about scaling down"
      },
      {
        "start": 966.4,
        "duration": 4.23,
        "text": "and that's a problem because you know"
      },
      {
        "start": 968.47,
        "duration": 5.01,
        "text": "that's an Cassander world is the same"
      },
      {
        "start": 970.63,
        "duration": 4.98,
        "text": "problem yeah you can but it's"
      },
      {
        "start": 973.48,
        "duration": 3.9,
        "text": "he didn't um it involves a lot of"
      },
      {
        "start": 975.61,
        "duration": 3.15,
        "text": "coordination and streaming and data"
      },
      {
        "start": 977.38,
        "duration": 3.12,
        "text": "getting lost"
      },
      {
        "start": 978.76,
        "duration": 3.87,
        "text": "it is especially so as we were talking"
      },
      {
        "start": 980.5,
        "duration": 3.81,
        "text": "about earlier with streaming yeah"
      },
      {
        "start": 982.63,
        "duration": 3.63,
        "text": "scaling down streaming applications"
      },
      {
        "start": 984.31,
        "duration": 3.51,
        "text": "which you know are occasionally the"
      },
      {
        "start": 986.26,
        "duration": 2.88,
        "text": "kinds of apps which are more likely to"
      },
      {
        "start": 987.82,
        "duration": 3.03,
        "text": "experience right"
      },
      {
        "start": 989.14,
        "duration": 3.18,
        "text": "temporary peaks that you want to scale"
      },
      {
        "start": 990.85,
        "duration": 5.76,
        "text": "back down from when you're already a"
      },
      {
        "start": 992.32,
        "duration": 6.39,
        "text": "season is over yeah we don't have a good"
      },
      {
        "start": 996.61,
        "duration": 3.99,
        "text": "solution for scaling down here and this"
      },
      {
        "start": 998.71,
        "duration": 3.84,
        "text": "is less on the individual cluster"
      },
      {
        "start": 1000.6,
        "duration": 6.0,
        "text": "managers and more on the way how"
      },
      {
        "start": 1002.55,
        "duration": 6.78,
        "text": "sparkers manages its memory there's some"
      },
      {
        "start": 1006.6,
        "duration": 6.68,
        "text": "interesting work though coming in"
      },
      {
        "start": 1009.33,
        "duration": 7.65,
        "text": "communities or in spark so both sides"
      },
      {
        "start": 1013.28,
        "duration": 5.05,
        "text": "actually spark an ends yarn there's some"
      },
      {
        "start": 1016.98,
        "duration": 3.03,
        "text": "interesting things in yarn coming as"
      },
      {
        "start": 1018.33,
        "duration": 3.99,
        "text": "well so yarn actually has this idea of"
      },
      {
        "start": 1020.01,
        "duration": 4.35,
        "text": "decommissioning all right but it does a"
      },
      {
        "start": 1022.32,
        "duration": 4.26,
        "text": "really poor job of communicating it"
      },
      {
        "start": 1024.36,
        "duration": 5.34,
        "text": "right now the api's are kind of not very"
      },
      {
        "start": 1026.58,
        "duration": 6.57,
        "text": "good and kubernetes have better ideas of"
      },
      {
        "start": 1029.7,
        "duration": 6.78,
        "text": "communicating similar concepts different"
      },
      {
        "start": 1033.15,
        "duration": 5.4,
        "text": "words same ideas but how many different"
      },
      {
        "start": 1036.48,
        "duration": 4.71,
        "text": "ways are gonna run here for special well"
      },
      {
        "start": 1038.55,
        "duration": 4.17,
        "text": "I mean yeah it's true you're not alone"
      },
      {
        "start": 1041.19,
        "duration": 3.99,
        "text": "we're gonna use a lot of different words"
      },
      {
        "start": 1042.72,
        "duration": 5.52,
        "text": "to describe the same concept which as I"
      },
      {
        "start": 1045.18,
        "duration": 4.95,
        "text": "like money and it seems to be the way we"
      },
      {
        "start": 1048.24,
        "duration": 3.69,
        "text": "build this that's true because we don't"
      },
      {
        "start": 1050.13,
        "duration": 3.24,
        "text": "talk to each other except like every six"
      },
      {
        "start": 1051.93,
        "duration": 5.25,
        "text": "months Sketch up a news conference"
      },
      {
        "start": 1053.37,
        "duration": 6.75,
        "text": "okay a mailing list or something yeah so"
      },
      {
        "start": 1057.18,
        "duration": 4.65,
        "text": "I mean so there's there's that site of"
      },
      {
        "start": 1060.12,
        "duration": 4.08,
        "text": "it's being worked on and it's pretty"
      },
      {
        "start": 1061.83,
        "duration": 3.93,
        "text": "exciting but on the sports side we need"
      },
      {
        "start": 1064.2,
        "duration": 3.18,
        "text": "to do a little bit of catch-up with sort"
      },
      {
        "start": 1065.76,
        "duration": 4.77,
        "text": "of doing the data migrations"
      },
      {
        "start": 1067.38,
        "duration": 4.47,
        "text": "intelligently I have a PR obviously in"
      },
      {
        "start": 1070.53,
        "duration": 3.96,
        "text": "this area that I think is pretty good"
      },
      {
        "start": 1071.85,
        "duration": 4.53,
        "text": "what that opinion is perhaps not what"
      },
      {
        "start": 1074.49,
        "duration": 5.46,
        "text": "one could describe as universally sure"
      },
      {
        "start": 1076.38,
        "duration": 6.18,
        "text": "are you PR pitching no no never but if"
      },
      {
        "start": 1079.95,
        "duration": 4.71,
        "text": "someone else is on the Apache spark PMC"
      },
      {
        "start": 1082.56,
        "duration": 5.4,
        "text": "I would love to help me review this not"
      },
      {
        "start": 1084.66,
        "duration": 5.25,
        "text": "more seriously I don't actually want to"
      },
      {
        "start": 1087.96,
        "duration": 5.16,
        "text": "update this PR I just want one of the"
      },
      {
        "start": 1089.91,
        "duration": 4.53,
        "text": "things to get in and it's it's one of"
      },
      {
        "start": 1093.12,
        "duration": 2.76,
        "text": "the things we're all thinking about so"
      },
      {
        "start": 1094.44,
        "duration": 3.69,
        "text": "there's a few different implementations"
      },
      {
        "start": 1095.88,
        "duration": 4.23,
        "text": "which take different approaches"
      },
      {
        "start": 1098.13,
        "duration": 2.7,
        "text": "they're not gonna make it for spark two"
      },
      {
        "start": 1100.11,
        "duration": 2.64,
        "text": "three"
      },
      {
        "start": 1100.83,
        "duration": 3.93,
        "text": "I think the k8 support is gonna go in"
      },
      {
        "start": 1102.75,
        "duration": 4.47,
        "text": "for two I mean the KS support is in for"
      },
      {
        "start": 1104.76,
        "duration": 3.81,
        "text": "two three and essentially there's a"
      },
      {
        "start": 1107.22,
        "duration": 2.88,
        "text": "bunch of sort of follow-up work which"
      },
      {
        "start": 1108.57,
        "duration": 4.38,
        "text": "we're gonna have to do sort of to catch"
      },
      {
        "start": 1110.1,
        "duration": 5.189,
        "text": "up into four and assuming that we state"
      },
      {
        "start": 1112.95,
        "duration": 3.93,
        "text": "of the earth is would you is there any"
      },
      {
        "start": 1115.289,
        "duration": 4.11,
        "text": "case where you would want someone"
      },
      {
        "start": 1116.88,
        "duration": 4.5,
        "text": "running over you and comfortable putting"
      },
      {
        "start": 1119.399,
        "duration": 5.611,
        "text": "combinations and spark into production"
      },
      {
        "start": 1121.38,
        "duration": 6.45,
        "text": "right now whoa no okay that's that's a"
      },
      {
        "start": 1125.01,
        "duration": 4.649,
        "text": "fair thing so is that gonna be something"
      },
      {
        "start": 1127.83,
        "duration": 3.42,
        "text": "that you know just previewing another"
      },
      {
        "start": 1129.659,
        "duration": 4.11,
        "text": "topic is that something that's gonna be"
      },
      {
        "start": 1131.25,
        "duration": 4.799,
        "text": "first class citizen in three oh yeah no"
      },
      {
        "start": 1133.769,
        "duration": 5.191,
        "text": "I think I think it's gonna be so I think"
      },
      {
        "start": 1136.049,
        "duration": 5.73,
        "text": "I think much before three will get there"
      },
      {
        "start": 1138.96,
        "duration": 4.709,
        "text": "much faster it's just the idea of using"
      },
      {
        "start": 1141.779,
        "duration": 6.091,
        "text": "a new cluster manager the first time"
      },
      {
        "start": 1143.669,
        "duration": 7.74,
        "text": "it's merge back into master listen I'm"
      },
      {
        "start": 1147.87,
        "duration": 5.97,
        "text": "not that cautious yeah but like ya know"
      },
      {
        "start": 1151.409,
        "duration": 3.63,
        "text": "I have my hard limits that's that's"
      },
      {
        "start": 1153.84,
        "duration": 3.449,
        "text": "that's one that you're probably gonna"
      },
      {
        "start": 1155.039,
        "duration": 4.38,
        "text": "want on chest for a long time and even"
      },
      {
        "start": 1157.289,
        "duration": 3.951,
        "text": "in not trust oh no I mean I think it's"
      },
      {
        "start": 1159.419,
        "duration": 4.531,
        "text": "it's it's fine for things like"
      },
      {
        "start": 1161.24,
        "duration": 4.48,
        "text": "exploratory analytics it would be a"
      },
      {
        "start": 1163.95,
        "duration": 3.63,
        "text": "really great way to sort of test it out"
      },
      {
        "start": 1165.72,
        "duration": 4.11,
        "text": "in your organization and see if it like"
      },
      {
        "start": 1167.58,
        "duration": 4.17,
        "text": "finding the breaking points but I would"
      },
      {
        "start": 1169.83,
        "duration": 4.65,
        "text": "not put my production jobs on it yeah I"
      },
      {
        "start": 1171.75,
        "duration": 5.429,
        "text": "think that's anytime I see new features"
      },
      {
        "start": 1174.48,
        "duration": 4.319,
        "text": "you know that's just give it a while I"
      },
      {
        "start": 1177.179,
        "duration": 3.391,
        "text": "mean it's just shiny features is it just"
      },
      {
        "start": 1178.799,
        "duration": 2.911,
        "text": "a general rule you see shiny features"
      },
      {
        "start": 1180.57,
        "duration": 3.989,
        "text": "let it shine"
      },
      {
        "start": 1181.71,
        "duration": 5.339,
        "text": "don't write yeah if you yell it you find"
      },
      {
        "start": 1184.559,
        "duration": 5.25,
        "text": "out that it's terrible risk your job I'm"
      },
      {
        "start": 1187.049,
        "duration": 6.921,
        "text": "shiny I mean not whatever it's fine but"
      },
      {
        "start": 1189.809,
        "duration": 6.151,
        "text": "my resume up-to-date CARICOM yeah"
      },
      {
        "start": 1193.97,
        "duration": 3.549,
        "text": "possibly not up to do they should update"
      },
      {
        "start": 1195.96,
        "duration": 3.15,
        "text": "my resume should update well would give"
      },
      {
        "start": 1197.519,
        "duration": 2.851,
        "text": "you some time that's cool all right I"
      },
      {
        "start": 1199.11,
        "duration": 3.96,
        "text": "think this has been a really great"
      },
      {
        "start": 1200.37,
        "duration": 4.919,
        "text": "overview on two three and potentially"
      },
      {
        "start": 1203.07,
        "duration": 3.87,
        "text": "the end of your career but ah come on oh"
      },
      {
        "start": 1205.289,
        "duration": 3.36,
        "text": "my god it's great I can always go back"
      },
      {
        "start": 1206.94,
        "duration": 3.42,
        "text": "to just regular software development"
      },
      {
        "start": 1208.649,
        "duration": 7.471,
        "text": "that's okay that has a big blending"
      },
      {
        "start": 1210.36,
        "duration": 9.6,
        "text": "nicely blend yeah yeah you blend so bad"
      },
      {
        "start": 1216.12,
        "duration": 4.649,
        "text": "line that's why I love having you so"
      },
      {
        "start": 1219.96,
        "duration": 2.4,
        "text": "it's great to catch up"
      },
      {
        "start": 1220.769,
        "duration": 2.451,
        "text": "yeah thanks a lot I really appreciate"
      },
      {
        "start": 1222.36,
        "duration": 2.26,
        "text": "you coming in"
      },
      {
        "start": 1223.22,
        "duration": 5.189,
        "text": "and we're gonna have to do this again"
      },
      {
        "start": 1224.62,
        "duration": 5.559,
        "text": "soon because let's keep changing it yeah"
      },
      {
        "start": 1228.409,
        "duration": 3.451,
        "text": "strata or where you want to catch up"
      },
      {
        "start": 1230.179,
        "duration": 3.75,
        "text": "next wherever we are"
      },
      {
        "start": 1231.86,
        "duration": 4.59,
        "text": "all right Bud Light Lime though LED"
      },
      {
        "start": 1233.929,
        "duration": 5.341,
        "text": "light lab okay thanks everyone we'll see"
      },
      {
        "start": 1236.45,
        "duration": 4.89,
        "text": "you next time thank you for joining us"
      },
      {
        "start": 1239.27,
        "duration": 3.6,
        "text": "again for the distributed data show we"
      },
      {
        "start": 1241.34,
        "duration": 3.42,
        "text": "love your feedback so go to the"
      },
      {
        "start": 1242.87,
        "duration": 3.72,
        "text": "distributed data show page on data Stax"
      },
      {
        "start": 1244.76,
        "duration": 3.33,
        "text": "Academy and tell us what you think you"
      },
      {
        "start": 1246.59,
        "duration": 3.9,
        "text": "can also find us on the data Stax"
      },
      {
        "start": 1248.09,
        "duration": 4.26,
        "text": "Academy YouTube channel or find our"
      },
      {
        "start": 1250.49,
        "duration": 4.319,
        "text": "podcast on itunes google play or"
      },
      {
        "start": 1252.35,
        "duration": 4.439,
        "text": "wherever you get great podcast while"
      },
      {
        "start": 1254.809,
        "duration": 3.781,
        "text": "you're there make sure and subscribe so"
      },
      {
        "start": 1256.789,
        "duration": 6.74,
        "text": "you don't miss a single episode"
      },
      {
        "start": 1258.59,
        "duration": 4.939,
        "text": "[Music]"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-16T06:50:28.853879+00:00"
}