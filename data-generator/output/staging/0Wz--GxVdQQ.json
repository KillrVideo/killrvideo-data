{
  "video_id": "0Wz--GxVdQQ",
  "title": "DS320.42 Spark SQL: Accessing DataFrame Schema and Rows | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.42 Spark SQL: Accessing DataFrame Schema and Rows\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:33:42Z",
  "thumbnail": "https://i.ytimg.com/vi/0Wz--GxVdQQ/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=0Wz--GxVdQQ",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] once we've got a data frame in hand let's look at how to get at the things in it now in the context of spark sql a data frame is going to come from a query on a cassandra table so it's going to have rows in it those rows are going to have columns and we're going to want programmatically to be able to get at the columns and rows of the data frame to build our application there are a few different ways of doing that let's take a look suppose you want to look at the schema of a data frame and you're just hacking in the spark shell the print schema method is super handy for that what it's going to do is it's going to dump to the shell in human readable format of the schema of the data frame so you get the column names you'll get the data types in a nice little summary for you to be able to read super handy hacking and debugging tool and that's great if you just want something human readable but suppose you need programmatic access to the schema the d types method is going to give you an array with the schema in it as you can see by the output on the slide the array is an array of two element tuples the first element of the tuple being the column name and the second element being the data type so if you need to introspect the schema of a data frame programmatically this is a great way to go about it another way to solve this same problem is the schema method on the dataframe object and that's going to do the same thing it's going to return a data structure to us that will allow us programmatically to introspect the schema of the data frame except instead of an array of tuples this time it's a struct type object which is going to contain struct field objects which themselves will tell us the column name and the data type so this is programmatic access to the dataframe schema in terms of those struct type and struct field objects that are defined in the spark sql api schema is great of course we also might want to access the data that's in a data frame as well so here we're creating a data frame with a simple sql query with that api method that we love just passing the cql string directly into that sql method we get a data frame back and we call the first method this is a convenient way to get the first element of that query back out now we have a row if you look at the type of that that's that spark sql row class that we've seen before and now we can start to interact with that row api a little bit you see the first thing we do there is we access by integer index the first field in the row so that's that print line row zero so we have zero based indexing into the columns in the data frame and that first column you just look up at the query you can remind yourself that's the title and so we get alice in wonderland back as a result next we'd like to access the second column in the data frame that's the release here at index 1. now the first thing we do since this might be null is we check to see if there's a null there that's that row is null at index 1 call there turns out it's not null we proceed at the last line of the example to just get the int at index 1 and we see alice in wonderland was released in 2010. you got to bear in mind that second approach which has the type baked in to the getter is getint that only works if the column is of a type that has a predefined getter so if there's for example a collection type something that's a list or a set or a map in the cassandra data we're going to have to get it just by its index and deal with the value that comes back because spark sql doesn't define type based getters for collection types so that first method is the most general that second one appears to be a little bit more type safe and is a little more self-documenting so you have to make the trade-off as to which one of those you're going to use so in this example we'll take it up a notch and actually query a collection type that's going to be the genres column genres is a set of strings in the movies table that we're querying so once again we'll query it we'll get our data frame we'll get the first item back so now we have that row object we can mess with we'll get the first element out of the row that's the row zero call there and we'll coerce it with that as instance of call to be a sequence of strings and that finally we call for each on that's the spark for each that we're calling on that sequence and print each one of them and we see alice in wonderland is an adventure film a family film and a fantasy film that's just a quick overview of how we access schema and data inside of data frames you can see there is not much to it which is good news it's an easy api to learn but still one that's going to let you get your work done",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 8.0,
        "duration": 2.48,
        "text": "once we've got"
      },
      {
        "start": 8.8,
        "duration": 3.12,
        "text": "a data frame in hand let's look at how"
      },
      {
        "start": 10.48,
        "duration": 3.279,
        "text": "to get at the things in it"
      },
      {
        "start": 11.92,
        "duration": 3.36,
        "text": "now in the context of spark sql a data"
      },
      {
        "start": 13.759,
        "duration": 2.481,
        "text": "frame is going to come from a query on a"
      },
      {
        "start": 15.28,
        "duration": 2.72,
        "text": "cassandra table"
      },
      {
        "start": 16.24,
        "duration": 3.28,
        "text": "so it's going to have rows in it those"
      },
      {
        "start": 18.0,
        "duration": 2.96,
        "text": "rows are going to have columns"
      },
      {
        "start": 19.52,
        "duration": 2.96,
        "text": "and we're going to want programmatically"
      },
      {
        "start": 20.96,
        "duration": 2.239,
        "text": "to be able to get at the columns and"
      },
      {
        "start": 22.48,
        "duration": 2.639,
        "text": "rows"
      },
      {
        "start": 23.199,
        "duration": 3.521,
        "text": "of the data frame to build our"
      },
      {
        "start": 25.119,
        "duration": 3.601,
        "text": "application there are a few different"
      },
      {
        "start": 26.72,
        "duration": 3.6,
        "text": "ways of doing that let's take a look"
      },
      {
        "start": 28.72,
        "duration": 3.359,
        "text": "suppose you want to look at the schema"
      },
      {
        "start": 30.32,
        "duration": 2.88,
        "text": "of a data frame and you're just hacking"
      },
      {
        "start": 32.079,
        "duration": 3.361,
        "text": "in the spark shell"
      },
      {
        "start": 33.2,
        "duration": 3.6,
        "text": "the print schema method is super handy"
      },
      {
        "start": 35.44,
        "duration": 2.959,
        "text": "for that what it's going to do is it's"
      },
      {
        "start": 36.8,
        "duration": 2.72,
        "text": "going to dump to the shell in human"
      },
      {
        "start": 38.399,
        "duration": 3.281,
        "text": "readable format"
      },
      {
        "start": 39.52,
        "duration": 3.68,
        "text": "of the schema of the data frame so you"
      },
      {
        "start": 41.68,
        "duration": 3.199,
        "text": "get the column names you'll get the data"
      },
      {
        "start": 43.2,
        "duration": 3.44,
        "text": "types in a nice little summary"
      },
      {
        "start": 44.879,
        "duration": 3.121,
        "text": "for you to be able to read super handy"
      },
      {
        "start": 46.64,
        "duration": 2.48,
        "text": "hacking and debugging tool"
      },
      {
        "start": 48.0,
        "duration": 2.559,
        "text": "and that's great if you just want"
      },
      {
        "start": 49.12,
        "duration": 3.68,
        "text": "something human readable but suppose you"
      },
      {
        "start": 50.559,
        "duration": 3.68,
        "text": "need programmatic access to the schema"
      },
      {
        "start": 52.8,
        "duration": 3.439,
        "text": "the d types method is going to give you"
      },
      {
        "start": 54.239,
        "duration": 3.681,
        "text": "an array with the schema"
      },
      {
        "start": 56.239,
        "duration": 3.361,
        "text": "in it as you can see by the output on"
      },
      {
        "start": 57.92,
        "duration": 4.72,
        "text": "the slide the array"
      },
      {
        "start": 59.6,
        "duration": 5.12,
        "text": "is an array of two element tuples"
      },
      {
        "start": 62.64,
        "duration": 4.56,
        "text": "the first element of the tuple being the"
      },
      {
        "start": 64.72,
        "duration": 4.0,
        "text": "column name and the second element being"
      },
      {
        "start": 67.2,
        "duration": 3.04,
        "text": "the data type so if you need to"
      },
      {
        "start": 68.72,
        "duration": 3.2,
        "text": "introspect the schema of a data frame"
      },
      {
        "start": 70.24,
        "duration": 2.4,
        "text": "programmatically this is a great way to"
      },
      {
        "start": 71.92,
        "duration": 2.16,
        "text": "go about it"
      },
      {
        "start": 72.64,
        "duration": 3.6,
        "text": "another way to solve this same problem"
      },
      {
        "start": 74.08,
        "duration": 3.6,
        "text": "is the schema method on the dataframe"
      },
      {
        "start": 76.24,
        "duration": 2.64,
        "text": "object and that's going to do the same"
      },
      {
        "start": 77.68,
        "duration": 2.56,
        "text": "thing it's going to return a data"
      },
      {
        "start": 78.88,
        "duration": 2.4,
        "text": "structure to us that will allow us"
      },
      {
        "start": 80.24,
        "duration": 2.64,
        "text": "programmatically"
      },
      {
        "start": 81.28,
        "duration": 3.36,
        "text": "to introspect the schema of the data"
      },
      {
        "start": 82.88,
        "duration": 2.4,
        "text": "frame except instead of an array of"
      },
      {
        "start": 84.64,
        "duration": 3.839,
        "text": "tuples"
      },
      {
        "start": 85.28,
        "duration": 5.92,
        "text": "this time it's a struct type object"
      },
      {
        "start": 88.479,
        "duration": 3.441,
        "text": "which is going to contain struct field"
      },
      {
        "start": 91.2,
        "duration": 2.879,
        "text": "objects"
      },
      {
        "start": 91.92,
        "duration": 3.68,
        "text": "which themselves will tell us the column"
      },
      {
        "start": 94.079,
        "duration": 3.761,
        "text": "name and the data type"
      },
      {
        "start": 95.6,
        "duration": 3.28,
        "text": "so this is programmatic access to the"
      },
      {
        "start": 97.84,
        "duration": 3.279,
        "text": "dataframe schema"
      },
      {
        "start": 98.88,
        "duration": 3.279,
        "text": "in terms of those struct type and struct"
      },
      {
        "start": 101.119,
        "duration": 3.68,
        "text": "field objects"
      },
      {
        "start": 102.159,
        "duration": 4.401,
        "text": "that are defined in the spark sql api"
      },
      {
        "start": 104.799,
        "duration": 3.201,
        "text": "schema is great of course we also might"
      },
      {
        "start": 106.56,
        "duration": 3.519,
        "text": "want to access the data"
      },
      {
        "start": 108.0,
        "duration": 3.36,
        "text": "that's in a data frame as well so here"
      },
      {
        "start": 110.079,
        "duration": 3.36,
        "text": "we're creating a data frame with a"
      },
      {
        "start": 111.36,
        "duration": 4.16,
        "text": "simple sql query with that api method"
      },
      {
        "start": 113.439,
        "duration": 3.68,
        "text": "that we love just passing the cql string"
      },
      {
        "start": 115.52,
        "duration": 3.68,
        "text": "directly into that sql method"
      },
      {
        "start": 117.119,
        "duration": 4.241,
        "text": "we get a data frame back and we call the"
      },
      {
        "start": 119.2,
        "duration": 4.08,
        "text": "first method this is a convenient way to"
      },
      {
        "start": 121.36,
        "duration": 2.48,
        "text": "get the first element of that query back"
      },
      {
        "start": 123.28,
        "duration": 3.519,
        "text": "out"
      },
      {
        "start": 123.84,
        "duration": 3.599,
        "text": "now we have a row if you look at the"
      },
      {
        "start": 126.799,
        "duration": 2.96,
        "text": "type of that"
      },
      {
        "start": 127.439,
        "duration": 3.361,
        "text": "that's that spark sql row class that"
      },
      {
        "start": 129.759,
        "duration": 2.401,
        "text": "we've seen before"
      },
      {
        "start": 130.8,
        "duration": 3.12,
        "text": "and now we can start to interact with"
      },
      {
        "start": 132.16,
        "duration": 3.28,
        "text": "that row api a little bit you see the"
      },
      {
        "start": 133.92,
        "duration": 4.8,
        "text": "first thing we do there is we access"
      },
      {
        "start": 135.44,
        "duration": 5.84,
        "text": "by integer index the first field"
      },
      {
        "start": 138.72,
        "duration": 4.8,
        "text": "in the row so that's that print line row"
      },
      {
        "start": 141.28,
        "duration": 5.2,
        "text": "zero so we have zero based indexing"
      },
      {
        "start": 143.52,
        "duration": 4.24,
        "text": "into the columns in the data frame and"
      },
      {
        "start": 146.48,
        "duration": 2.64,
        "text": "that first column you just look up at"
      },
      {
        "start": 147.76,
        "duration": 3.119,
        "text": "the query you can remind yourself"
      },
      {
        "start": 149.12,
        "duration": 3.36,
        "text": "that's the title and so we get alice in"
      },
      {
        "start": 150.879,
        "duration": 3.041,
        "text": "wonderland back as a result"
      },
      {
        "start": 152.48,
        "duration": 2.88,
        "text": "next we'd like to access the second"
      },
      {
        "start": 153.92,
        "duration": 2.08,
        "text": "column in the data frame that's the"
      },
      {
        "start": 155.36,
        "duration": 3.12,
        "text": "release here"
      },
      {
        "start": 156.0,
        "duration": 4.0,
        "text": "at index 1. now the first thing we do"
      },
      {
        "start": 158.48,
        "duration": 3.52,
        "text": "since this might be null"
      },
      {
        "start": 160.0,
        "duration": 4.16,
        "text": "is we check to see if there's a null"
      },
      {
        "start": 162.0,
        "duration": 5.36,
        "text": "there that's that row is null"
      },
      {
        "start": 164.16,
        "duration": 3.68,
        "text": "at index 1 call there turns out it's not"
      },
      {
        "start": 167.36,
        "duration": 1.76,
        "text": "null"
      },
      {
        "start": 167.84,
        "duration": 3.119,
        "text": "we proceed at the last line of the"
      },
      {
        "start": 169.12,
        "duration": 4.64,
        "text": "example to just get the int at"
      },
      {
        "start": 170.959,
        "duration": 4.321,
        "text": "index 1 and we see alice in wonderland"
      },
      {
        "start": 173.76,
        "duration": 2.72,
        "text": "was released in 2010."
      },
      {
        "start": 175.28,
        "duration": 3.12,
        "text": "you got to bear in mind that second"
      },
      {
        "start": 176.48,
        "duration": 3.52,
        "text": "approach which has the type baked in to"
      },
      {
        "start": 178.4,
        "duration": 3.6,
        "text": "the getter is getint"
      },
      {
        "start": 180.0,
        "duration": 3.76,
        "text": "that only works if the column is of a"
      },
      {
        "start": 182.0,
        "duration": 3.84,
        "text": "type that has a predefined"
      },
      {
        "start": 183.76,
        "duration": 3.119,
        "text": "getter so if there's for example a"
      },
      {
        "start": 185.84,
        "duration": 2.8,
        "text": "collection type"
      },
      {
        "start": 186.879,
        "duration": 3.761,
        "text": "something that's a list or a set or a"
      },
      {
        "start": 188.64,
        "duration": 4.0,
        "text": "map in the cassandra data we're going to"
      },
      {
        "start": 190.64,
        "duration": 4.0,
        "text": "have to get it just by its index"
      },
      {
        "start": 192.64,
        "duration": 3.76,
        "text": "and deal with the value that comes back"
      },
      {
        "start": 194.64,
        "duration": 2.879,
        "text": "because spark sql doesn't define type"
      },
      {
        "start": 196.4,
        "duration": 3.199,
        "text": "based getters"
      },
      {
        "start": 197.519,
        "duration": 3.841,
        "text": "for collection types so that first"
      },
      {
        "start": 199.599,
        "duration": 3.201,
        "text": "method is the most general that second"
      },
      {
        "start": 201.36,
        "duration": 2.4,
        "text": "one appears to be a little bit more type"
      },
      {
        "start": 202.8,
        "duration": 1.84,
        "text": "safe and is a little more"
      },
      {
        "start": 203.76,
        "duration": 2.16,
        "text": "self-documenting"
      },
      {
        "start": 204.64,
        "duration": 2.959,
        "text": "so you have to make the trade-off as to"
      },
      {
        "start": 205.92,
        "duration": 3.039,
        "text": "which one of those you're going to use"
      },
      {
        "start": 207.599,
        "duration": 2.881,
        "text": "so in this example we'll take it up a"
      },
      {
        "start": 208.959,
        "duration": 2.881,
        "text": "notch and actually query a collection"
      },
      {
        "start": 210.48,
        "duration": 2.08,
        "text": "type that's going to be the genres"
      },
      {
        "start": 211.84,
        "duration": 3.759,
        "text": "column"
      },
      {
        "start": 212.56,
        "duration": 5.28,
        "text": "genres is a set of strings in"
      },
      {
        "start": 215.599,
        "duration": 3.36,
        "text": "the movies table that we're querying so"
      },
      {
        "start": 217.84,
        "duration": 2.64,
        "text": "once again we'll query it"
      },
      {
        "start": 218.959,
        "duration": 3.28,
        "text": "we'll get our data frame we'll get the"
      },
      {
        "start": 220.48,
        "duration": 4.72,
        "text": "first item back so now we have that"
      },
      {
        "start": 222.239,
        "duration": 3.761,
        "text": "row object we can mess with we'll get"
      },
      {
        "start": 225.2,
        "duration": 3.52,
        "text": "the first"
      },
      {
        "start": 226.0,
        "duration": 4.0,
        "text": "element out of the row that's the row"
      },
      {
        "start": 228.72,
        "duration": 3.12,
        "text": "zero call there"
      },
      {
        "start": 230.0,
        "duration": 3.28,
        "text": "and we'll coerce it with that as"
      },
      {
        "start": 231.84,
        "duration": 4.0,
        "text": "instance of call"
      },
      {
        "start": 233.28,
        "duration": 4.56,
        "text": "to be a sequence of strings and that"
      },
      {
        "start": 235.84,
        "duration": 3.84,
        "text": "finally we call for each on that's the"
      },
      {
        "start": 237.84,
        "duration": 3.92,
        "text": "spark for each that we're calling on"
      },
      {
        "start": 239.68,
        "duration": 3.68,
        "text": "that sequence and print each one of them"
      },
      {
        "start": 241.76,
        "duration": 3.28,
        "text": "and we see alice in wonderland is an"
      },
      {
        "start": 243.36,
        "duration": 3.519,
        "text": "adventure film a family film"
      },
      {
        "start": 245.04,
        "duration": 3.279,
        "text": "and a fantasy film that's just a quick"
      },
      {
        "start": 246.879,
        "duration": 2.961,
        "text": "overview of how we access schema and"
      },
      {
        "start": 248.319,
        "duration": 3.441,
        "text": "data inside of data frames you can see"
      },
      {
        "start": 249.84,
        "duration": 4.399,
        "text": "there is not much to it which is good"
      },
      {
        "start": 251.76,
        "duration": 3.6,
        "text": "news it's an easy api to learn"
      },
      {
        "start": 254.239,
        "duration": 10.881,
        "text": "but still one that's going to let you"
      },
      {
        "start": 255.36,
        "duration": 9.76,
        "text": "get your work done"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:12:21.410565+00:00"
}