{
  "video_id": "-LwzfqQ-rtg",
  "title": "DS320.26 Spark/Cassandra Connector: Count | DataStax Enterprise Analytics",
  "description": "#DataStaxAcademy #DS320\nDS320.26 Spark/Cassandra Connector: Count\nIn this course, you will learn how to effectively and efficiently solve analytical problems with Apache Spark™, Apache Cassandra™, and DataStax Enterprise. You will learn about the Spark API, Spark-Cassandra Connector, Spark SQL, Spark Streaming, and crucial performance optimization techniques.  You will also learn the basics of the productive and robust Scala programming language for data analysis and processing in Apache Spark™.\n\nLEARN FOR FREE at https://academy.datastax.com -- access all the FREE complete courses, tutorials, and hands-on exercises.\n\nASK QUESTIONS at https://community.datastax.com -- where experts from DataStax & the Apache Cassandra community share their expertise everyday.",
  "published_at": "2020-08-16T00:30:09Z",
  "thumbnail": "https://i.ytimg.com/vi/-LwzfqQ-rtg/maxresdefault.jpg",
  "channel_title": "DataStax Developers",
  "channel_id": "UCAIQY251avaMv7bBv5PCo-A",
  "tags": [
    "cassandra",
    "tutorial",
    "apache_cassandra",
    "performance",
    "datastax"
  ],
  "url": "https://www.youtube.com/watch?v=-LwzfqQ-rtg",
  "transcript": {
    "available": true,
    "language": "English (auto-generated)",
    "language_code": "en",
    "is_generated": true,
    "text": "[Music] in a previous module we've looked at how to get data out of cassandra into spark and from spark rdds back into cassandra through the spark cassandra connector here we're going to look at a few optimizations a few little things you might look at that will make those operations run a little faster let's take a look at some straightforward but naive and sub-optimal code for counting records from a cassandra query here we do a query on the movies by actor table we're looking for all johnny depp movies released prior to 2015. at the end of that where clause we've got an rdd containing cassandra row records we can call the count action on that rdd and we'll get a count back easy enough but that's sub-optimal let's take a look at why the cassandra query is going to create an rdd with all those records and then we're going to have to iterate over all of them to create the count we would rather not move that data around if we could get the counting to happen in cassandra we don't have to serialize all those records get them out of the cassandra process into the spark process there's a bunch more work to do there that we'd rather avoid and here is cassandra count to save the day it works just like count except that you call it on an rdd that's generated from a cassandra query the counting isn't really done on the rdd it's going to be done in the cassandra process by a cql query that actually does a select count rather than taking all that data out and having spark do the count in the rdd the optimized code as you can see here is very similar to the original code except that we call cassandra count and it's going to run a lot faster now there are some situations where this is inapplicable let's look at a couple of examples up top we see a case where we would want to use the regular count because we're doing that filter operation so we do the query on all movies by actor but we only want movies whose rating is 6.0 or above now if you look at the schema over to the right you'll notice that the rating column is not a clustering column so we're not going to be able to generate cql to do that query the driver can't do that it's going to have to get all those rows back into an rdd and then filter them create a new rdd which will then count in the normal way it's something to be worried about count is going to work as well as it always has it's just not a time to pursue that optimization if you look at the second example down below count is a better choice because we need that rdd lying around to do more things with we have a three line query we're doing a select on movies by actor or actor is johnny depp and release here is less than 2015 and we do want the count of that rdd and that's that next line there print line movies count but then we also want to take that and make it into a pair rdd we want to group those movies by release year and count the movies by year we're going to do two operations on that rdd so there's no sense doing a cassandra count and then making the rdd and doing our operation on it that way we'll just go ahead and not pursue the optimization in that case in the case where all we're doing is account on a query cassandra count is a great option [Music] you",
    "segments": [
      {
        "start": 0.06,
        "duration": 3.45,
        "text": "[Music]"
      },
      {
        "start": 6.879,
        "duration": 2.001,
        "text": "in a previous module we've looked at how"
      },
      {
        "start": 8.559,
        "duration": 2.641,
        "text": "to"
      },
      {
        "start": 8.88,
        "duration": 4.879,
        "text": "get data out of cassandra into spark and"
      },
      {
        "start": 11.2,
        "duration": 4.0,
        "text": "from spark rdds back into cassandra"
      },
      {
        "start": 13.759,
        "duration": 2.401,
        "text": "through the spark cassandra connector"
      },
      {
        "start": 15.2,
        "duration": 2.4,
        "text": "here we're going to look at a few"
      },
      {
        "start": 16.16,
        "duration": 2.8,
        "text": "optimizations a few little things you"
      },
      {
        "start": 17.6,
        "duration": 2.8,
        "text": "might look at that will make those"
      },
      {
        "start": 18.96,
        "duration": 2.88,
        "text": "operations run a little faster"
      },
      {
        "start": 20.4,
        "duration": 3.119,
        "text": "let's take a look at some"
      },
      {
        "start": 21.84,
        "duration": 3.759,
        "text": "straightforward but naive"
      },
      {
        "start": 23.519,
        "duration": 4.0,
        "text": "and sub-optimal code for counting"
      },
      {
        "start": 25.599,
        "duration": 2.241,
        "text": "records from a cassandra query here we"
      },
      {
        "start": 27.519,
        "duration": 2.641,
        "text": "do"
      },
      {
        "start": 27.84,
        "duration": 3.12,
        "text": "a query on the movies by actor table"
      },
      {
        "start": 30.16,
        "duration": 2.88,
        "text": "we're looking for"
      },
      {
        "start": 30.96,
        "duration": 3.2,
        "text": "all johnny depp movies released prior to"
      },
      {
        "start": 33.04,
        "duration": 2.32,
        "text": "2015."
      },
      {
        "start": 34.16,
        "duration": 3.6,
        "text": "at the end of that where clause we've"
      },
      {
        "start": 35.36,
        "duration": 4.48,
        "text": "got an rdd containing cassandra row"
      },
      {
        "start": 37.76,
        "duration": 3.76,
        "text": "records we can call the count action on"
      },
      {
        "start": 39.84,
        "duration": 3.84,
        "text": "that rdd and we'll get a count back"
      },
      {
        "start": 41.52,
        "duration": 3.76,
        "text": "easy enough but that's sub-optimal let's"
      },
      {
        "start": 43.68,
        "duration": 3.6,
        "text": "take a look at why the cassandra query"
      },
      {
        "start": 45.28,
        "duration": 2.64,
        "text": "is going to create an rdd with all those"
      },
      {
        "start": 47.28,
        "duration": 2.32,
        "text": "records"
      },
      {
        "start": 47.92,
        "duration": 3.6,
        "text": "and then we're going to have to iterate"
      },
      {
        "start": 49.6,
        "duration": 4.4,
        "text": "over all of them to create the count"
      },
      {
        "start": 51.52,
        "duration": 3.84,
        "text": "we would rather not move that data"
      },
      {
        "start": 54.0,
        "duration": 2.8,
        "text": "around if we could get the counting to"
      },
      {
        "start": 55.36,
        "duration": 2.96,
        "text": "happen in cassandra"
      },
      {
        "start": 56.8,
        "duration": 3.04,
        "text": "we don't have to serialize all those"
      },
      {
        "start": 58.32,
        "duration": 2.239,
        "text": "records get them out of the cassandra"
      },
      {
        "start": 59.84,
        "duration": 2.8,
        "text": "process"
      },
      {
        "start": 60.559,
        "duration": 3.6,
        "text": "into the spark process there's a bunch"
      },
      {
        "start": 62.64,
        "duration": 3.68,
        "text": "more work to do there"
      },
      {
        "start": 64.159,
        "duration": 3.201,
        "text": "that we'd rather avoid and here is"
      },
      {
        "start": 66.32,
        "duration": 3.36,
        "text": "cassandra count"
      },
      {
        "start": 67.36,
        "duration": 3.759,
        "text": "to save the day it works just like count"
      },
      {
        "start": 69.68,
        "duration": 3.36,
        "text": "except that you call it"
      },
      {
        "start": 71.119,
        "duration": 3.121,
        "text": "on an rdd that's generated from a"
      },
      {
        "start": 73.04,
        "duration": 3.119,
        "text": "cassandra query"
      },
      {
        "start": 74.24,
        "duration": 3.519,
        "text": "the counting isn't really done on the"
      },
      {
        "start": 76.159,
        "duration": 4.401,
        "text": "rdd it's going to be done"
      },
      {
        "start": 77.759,
        "duration": 5.04,
        "text": "in the cassandra process by a cql query"
      },
      {
        "start": 80.56,
        "duration": 4.239,
        "text": "that actually does a select count"
      },
      {
        "start": 82.799,
        "duration": 3.281,
        "text": "rather than taking all that data out and"
      },
      {
        "start": 84.799,
        "duration": 3.281,
        "text": "having spark do the count"
      },
      {
        "start": 86.08,
        "duration": 3.44,
        "text": "in the rdd the optimized code as you can"
      },
      {
        "start": 88.08,
        "duration": 3.12,
        "text": "see here is"
      },
      {
        "start": 89.52,
        "duration": 3.2,
        "text": "very similar to the original code except"
      },
      {
        "start": 91.2,
        "duration": 2.72,
        "text": "that we call cassandra count and it's"
      },
      {
        "start": 92.72,
        "duration": 4.079,
        "text": "going to run a lot faster"
      },
      {
        "start": 93.92,
        "duration": 3.92,
        "text": "now there are some situations where this"
      },
      {
        "start": 96.799,
        "duration": 2.721,
        "text": "is inapplicable"
      },
      {
        "start": 97.84,
        "duration": 3.68,
        "text": "let's look at a couple of examples up"
      },
      {
        "start": 99.52,
        "duration": 3.44,
        "text": "top we see a case where we would want to"
      },
      {
        "start": 101.52,
        "duration": 3.36,
        "text": "use the regular count"
      },
      {
        "start": 102.96,
        "duration": 4.32,
        "text": "because we're doing that filter"
      },
      {
        "start": 104.88,
        "duration": 3.599,
        "text": "operation so we do the query on all"
      },
      {
        "start": 107.28,
        "duration": 3.6,
        "text": "movies by actor"
      },
      {
        "start": 108.479,
        "duration": 3.68,
        "text": "but we only want movies whose rating is"
      },
      {
        "start": 110.88,
        "duration": 2.72,
        "text": "6.0 or above"
      },
      {
        "start": 112.159,
        "duration": 3.841,
        "text": "now if you look at the schema over to"
      },
      {
        "start": 113.6,
        "duration": 2.879,
        "text": "the right you'll notice that the rating"
      },
      {
        "start": 116.0,
        "duration": 2.64,
        "text": "column"
      },
      {
        "start": 116.479,
        "duration": 3.841,
        "text": "is not a clustering column so we're not"
      },
      {
        "start": 118.64,
        "duration": 3.92,
        "text": "going to be able to generate cql"
      },
      {
        "start": 120.32,
        "duration": 3.52,
        "text": "to do that query the driver can't do"
      },
      {
        "start": 122.56,
        "duration": 4.32,
        "text": "that it's going to have to get"
      },
      {
        "start": 123.84,
        "duration": 4.72,
        "text": "all those rows back into an rdd and then"
      },
      {
        "start": 126.88,
        "duration": 2.96,
        "text": "filter them create a new rdd which will"
      },
      {
        "start": 128.56,
        "duration": 2.56,
        "text": "then count in the normal way"
      },
      {
        "start": 129.84,
        "duration": 2.399,
        "text": "it's something to be worried about count"
      },
      {
        "start": 131.12,
        "duration": 3.199,
        "text": "is going to work as well as it always"
      },
      {
        "start": 132.239,
        "duration": 2.881,
        "text": "has it's just not a time to pursue that"
      },
      {
        "start": 134.319,
        "duration": 2.081,
        "text": "optimization"
      },
      {
        "start": 135.12,
        "duration": 3.44,
        "text": "if you look at the second example down"
      },
      {
        "start": 136.4,
        "duration": 5.68,
        "text": "below count is a better choice because"
      },
      {
        "start": 138.56,
        "duration": 6.08,
        "text": "we need that rdd lying around to do more"
      },
      {
        "start": 142.08,
        "duration": 4.799,
        "text": "things with we have a three line query"
      },
      {
        "start": 144.64,
        "duration": 4.239,
        "text": "we're doing a select on movies by actor"
      },
      {
        "start": 146.879,
        "duration": 3.601,
        "text": "or actor is johnny depp and release here"
      },
      {
        "start": 148.879,
        "duration": 4.881,
        "text": "is less than 2015"
      },
      {
        "start": 150.48,
        "duration": 4.88,
        "text": "and we do want the count of that rdd"
      },
      {
        "start": 153.76,
        "duration": 3.199,
        "text": "and that's that next line there print"
      },
      {
        "start": 155.36,
        "duration": 3.76,
        "text": "line movies count but"
      },
      {
        "start": 156.959,
        "duration": 4.161,
        "text": "then we also want to take that and make"
      },
      {
        "start": 159.12,
        "duration": 3.92,
        "text": "it into a pair rdd we want to group"
      },
      {
        "start": 161.12,
        "duration": 4.24,
        "text": "those movies by release year"
      },
      {
        "start": 163.04,
        "duration": 4.32,
        "text": "and count the movies by year we're going"
      },
      {
        "start": 165.36,
        "duration": 3.76,
        "text": "to do two operations on that rdd"
      },
      {
        "start": 167.36,
        "duration": 4.0,
        "text": "so there's no sense doing a cassandra"
      },
      {
        "start": 169.12,
        "duration": 4.0,
        "text": "count and then making the rdd"
      },
      {
        "start": 171.36,
        "duration": 3.519,
        "text": "and doing our operation on it that way"
      },
      {
        "start": 173.12,
        "duration": 2.64,
        "text": "we'll just go ahead and not pursue the"
      },
      {
        "start": 174.879,
        "duration": 3.041,
        "text": "optimization"
      },
      {
        "start": 175.76,
        "duration": 3.119,
        "text": "in that case in the case where all we're"
      },
      {
        "start": 177.92,
        "duration": 4.92,
        "text": "doing is account"
      },
      {
        "start": 178.879,
        "duration": 5.631,
        "text": "on a query cassandra count is a great"
      },
      {
        "start": 182.84,
        "duration": 4.92,
        "text": "option"
      },
      {
        "start": 184.51,
        "duration": 5.33,
        "text": "[Music]"
      },
      {
        "start": 187.76,
        "duration": 2.08,
        "text": "you"
      }
    ],
    "error": null,
    "error_type": null
  },
  "collected_at": "2025-12-15T23:30:28.581087+00:00"
}